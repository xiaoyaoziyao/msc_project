<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
    <front>
        <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, USA</publisher-loc>
            </publisher></journal-meta>
        <article-meta><article-id pub-id-type="publisher-id">08-PLCB-RA-0635R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000291</article-id><article-categories>
                <subj-group subj-group-type="heading">
                    <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline">
                    <subject>Neuroscience</subject>
                    <subject>Neuroscience/Animal Cognition</subject>
                    <subject>Neuroscience/Theoretical Neuroscience</subject>
                </subj-group>
            </article-categories><title-group><article-title>Accurate Path Integration in Continuous Attractor Network Models of
                    Grid Cells</article-title><alt-title alt-title-type="running-head">Accurate Path Integration in the Grid-Cell
                    System</alt-title></title-group><contrib-group>
                <contrib contrib-type="author" xlink:type="simple">
                    <name name-style="western">
                        <surname>Burak</surname>
                        <given-names>Yoram</given-names>
                    </name>
                    <xref ref-type="aff" rid="aff1">
                        <sup>1</sup>
                    </xref>
                    <xref ref-type="aff" rid="aff2">
                        <sup>2</sup>
                    </xref>
                    <xref ref-type="corresp" rid="cor1">
                        <sup>*</sup>
                    </xref>
                </contrib>
                <contrib contrib-type="author" xlink:type="simple">
                    <name name-style="western">
                        <surname>Fiete</surname>
                        <given-names>Ila R.</given-names>
                    </name>
                    <xref ref-type="aff" rid="aff2">
                        <sup>2</sup>
                    </xref>
                    <xref ref-type="aff" rid="aff3">
                        <sup>3</sup>
                    </xref>
                </contrib>
            </contrib-group><aff id="aff1">
                <label>1</label>
                <addr-line>Center for Brain Science, Harvard University, Cambridge, Massachusetts,
                    United States of America</addr-line>
            </aff><aff id="aff2">
                <label>2</label>
                <addr-line>Kavli Institute for Theoretical Physics, University of California Santa
                    Barbara, Santa Barbara, California, United States of America</addr-line>
            </aff><aff id="aff3">
                <label>3</label>
                <addr-line>Computation and Neural Systems, Division of Biology, California Institute
                    of Technology, Pasadena, California, United States of America</addr-line>
            </aff><contrib-group>
                <contrib contrib-type="editor" xlink:type="simple">
                    <name name-style="western">
                        <surname>Sporns</surname>
                        <given-names>Olaf</given-names>
                    </name>
                    <role>Editor</role>
                    <xref ref-type="aff" rid="edit1"/>
                </contrib>
            </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
                <corresp id="cor1">* E-mail: <email xlink:type="simple">yburak@fas.harvard.edu</email></corresp>
                <fn fn-type="con">
                    <p>Analyzed the data: YB IRF. Wrote the paper: YB IRF. Developed the model: YB
                        IRF. Performed the simulations: YB IRF.</p>
                </fn>
            <fn fn-type="conflict">
                <p>The authors have declared that no competing interests exist.</p>
            </fn></author-notes><pub-date pub-type="collection">
                <month>2</month>
                <year>2009</year>
            </pub-date><pub-date pub-type="epub">
                <day>20</day>
                <month>2</month>
                <year>2009</year>
            </pub-date><volume>5</volume><issue>2</issue><elocation-id>e1000291</elocation-id><history>
                <date date-type="received">
                    <day>4</day>
                    <month>8</month>
                    <year>2008</year>
                </date>
                <date date-type="accepted">
                    <day>6</day>
                    <month>1</month>
                    <year>2009</year>
                </date>
            </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Burak, Fiete</copyright-holder><license><license-p>This is an open-access article distributed under the
                terms of the Creative Commons Attribution License, which permits unrestricted use,
                distribution, and reproduction in any medium, provided the original author and
                source are credited.</license-p></license></permissions><abstract>
                <p>Grid cells in the rat entorhinal cortex display strikingly regular firing
                    responses to the animal's position in 2-D space and have been
                    hypothesized to form the neural substrate for dead-reckoning. However, errors
                    accumulate rapidly when velocity inputs are integrated in existing models of
                    grid cell activity. To produce grid-cell-like responses, these models would
                    require frequent resets triggered by external sensory cues. Such inadequacies,
                    shared by various models, cast doubt on the dead-reckoning potential of the grid
                    cell system. Here we focus on the question of accurate path integration,
                    specifically in continuous attractor models of grid cell activity. We show, in
                    contrast to previous models, that continuous attractor models can generate
                    regular triangular grid responses, based on inputs that encode only the
                    rat's velocity and heading direction. We consider the role of the
                    network boundary in the integration performance of the network and show that
                    both periodic and aperiodic networks are capable of accurate path integration,
                    despite important differences in their attractor manifolds. We quantify the rate
                    at which errors in the velocity integration accumulate as a function of network
                    size and intrinsic noise within the network. With a plausible range of
                    parameters and the inclusion of spike variability, our model networks can
                    accurately integrate velocity inputs over a maximum of ∼10–100
                    meters and ∼1–10 minutes. These findings form a
                    proof-of-concept that continuous attractor dynamics may underlie velocity
                    integration in the dorsolateral medial entorhinal cortex. The simulations also
                    generate pertinent upper bounds on the accuracy of integration that may be
                    achieved by continuous attractor dynamics in the grid cell network. We suggest
                    experiments to test the continuous attractor model and differentiate it from
                    models in which single cells establish their responses independently of each
                    other.</p>
            </abstract><abstract abstract-type="summary">
                <title>Author Summary</title>
                <p>Even in the absence of external sensory cues, foraging rodents maintain an
                    estimate of their position, allowing them to return home in a roughly straight
                    line. This computation is known as dead reckoning or path integration. A
                    discovery made three years ago in rats focused attention on the dorsolateral
                    medial entorhinal cortex (dMEC) as a location in the rat's brain where
                    this computation might be performed. In this area, so-called grid cells fire
                    whenever the rat is on any vertex of a triangular grid that tiles the plane.
                    Here we propose a model that could generate grid-cell-like responses in a neural
                    network. The inputs to the model network convey information about the
                    rat's velocity and heading, consistent with known inputs projecting
                    into the dMEC. The network effectively integrates these inputs to produce a
                    response that depends on the rat's absolute position. We show that such
                    a neural network can integrate position accurately and can reproduce
                    grid-cell-like responses similar to those observed experimentally. We then
                    suggest a set of experiments that could help identify whether our suggested
                    mechanism is responsible for the emergence of grid cells and for path
                    integration in the rat's brain.</p>
            </abstract><funding-group><funding-statement>This work was partially supported by the National Science Foundation Division of
                    Physics (99-07949) to the Kavli Institute for Theoretical Physics. YB is a
                    Swartz Fellow in Theoretical Neuroscience, and IRF is a Broad Senior Research
                    Fellow in Brain Circuitry.</funding-statement></funding-group><counts>
                <page-count count="16"/>
            </counts></article-meta>
    </front>
    <body>
        <sec id="s1">
            <title>Introduction</title>
            <p>Since the discovery of grid cells in the dorsolateral band of the medial entorhinal
                cortex (dMEC) <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>, several ideas have been put forth on how
                grid-cell activity might emerge <xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Guanella1">[7]</xref>. The theoretical ideas
                suggested so far fall into two categories. In continuous attractor models (see <xref ref-type="bibr" rid="pcbi.1000291-Skaggs1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Stringer1">[15]</xref> and <xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-McNaughton1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Guanella1">[7]</xref> for the grid cell system), which are the focus of
                this work, grid cell activity arises from the collective behavior of a neural
                network. The network's state is restricted to lie in a low-dimensional
                continuous manifold of steady states, and its particular location within this
                manifold is updated in response to the rat's velocity. In the second
                category of models <xref ref-type="bibr" rid="pcbi.1000291-Burgess1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hasselmo1">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-OKeefe1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Giocomo1">[17]</xref>, grid-cell activity arises independently in
                single cells, as a result of interference between a global periodic signal and a
                cell-specific oscillation, whose frequency is modulated by the rat's
                velocity.</p>
            <p>These ideas differ radically from each other, but they share a common assumption
                about the nature of the input feeding into dMEC, namely, that the input conveys
                information primarily on the rat's velocity and heading. Within all these
                models, grid cell activity must then arise from precise integration of the
                rat's velocity.</p>
            <p>Grid cell firing exhibits remarkable accuracy: The periodic spatial tuning pattern
                remains sharp and stable over trajectories lasting 10's of minutes, with an
                accumulated length on the order of hundreds of meters <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>. Experiments performed
                in the dark show that grid cell tuning remains relatively accurate over ∼100
                meters and ∼10 minutes even after a substantial reduction of external
                sensory inputs. However, in these experiments olfactory and tactile cues were not
                eliminated, and grid cell responses may have been informed by positional information
                from such cues. Therefore, the duration and length of paths over which coherent grid
                responses are maintained without any external sensory cues is not known. For
                position estimation on the behavioral level, we searched for but found no clear
                quantitative records of the full range over which rats are capable of accurate
                dead-reckoning. Behavioral studies <xref ref-type="bibr" rid="pcbi.1000291-Mittelstaedt1">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Etienne1">[21]</xref>
                document that rats can compute the straight path home following random foraging
                trajectories that are 1–3 meters in length, in the absence of external
                sensory cues.</p>
            <p>How do theoretical models measure up, in estimating position from input velocity
                cues? The theta-oscillation model of grid cells <xref ref-type="bibr" rid="pcbi.1000291-Burgess1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hasselmo1">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-OKeefe1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Giocomo1">[17]</xref>, under idealized
                assumptions about internal connectivity, velocity inputs, and neural dynamics, is
                not able to produce accurate spatial grids over the known length- and time-scales of
                behavioral dead-reckoning if the participating theta oscillations deviate from pure
                sine waves. This is because the model is acutely vulnerable to subtle changes in the
                phase of the underlying oscillations. In reality, theta oscillations are not
                temporally coherent: cross-correlograms from <italic>in vitro</italic> intracellular
                recordings <xref ref-type="bibr" rid="pcbi.1000291-Giocomo1">[17]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Alonso1">[22]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Alonso2">[23]</xref> and <italic>in vivo</italic> extracellular
                recordings <xref ref-type="bibr" rid="pcbi.1000291-Mitchell1">[24]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Alonso3">[25]</xref> show that the phase of the theta oscillation in
                the entorhinal cortex typically decoheres or slips by half a cycle in less than 10
                cycles or about 1 second, which corresponds to a distance of only 1 meter for a run
                velocity of 1 m/s. This means that the model grid cells will entirely lose track of
                the correct phase for the present rat position within that time.</p>
            <p>For continuous attractor models, we previously showed <xref ref-type="bibr" rid="pcbi.1000291-Burak1">[3]</xref> that due to rotations and
                non-linear, anisotropic velocity responses, a detailed model <xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref> integrates velocity
                poorly, and does not produce a grid-cell firing pattern even with idealized
                connectivity and deterministic dynamics. Another model <xref ref-type="bibr" rid="pcbi.1000291-Guanella1">[7]</xref> generates grid
                responses in a small periodic network, but it includes no neural nonlinearities or
                variability in neural responses, and depends on real-time, continuous modulation of
                recurrent weights by the velocity inputs to the network.</p>
            <p>Conceptually, the existence of an integrating apparatus seems pointless if it is
                completely dependent on nearly continuous corrections coming from an external source
                that specifies absolute position. Thus, it seems reasonable to require that
                theoretical models of path integration in dMEC, if using faithful velocity inputs,
                have the ability to reproduce stable grid cell patterns for trajectories lasting a
                few minutes.</p>
            <p>Our aim, therefore, is to establish whether it is possible for model grid cells to
                accurately integrate velocity inputs. We restrict our analysis specifically to
                continuous attractor networks. As will become clear, the precision of velocity
                integration can strongly depend on various factors including network topology,
                network size, variability of neural firing, and variability in neural weights. Here
                we focus on three of these factors: boundary conditions in the wiring of the network
                (periodic vs. aperiodic), network size, and stochasticity in neural activity</p>
            <p>We quantify path integration accuracy in both periodic and aperiodic recurrent
                network models of dMEC, and demonstrate that within a biologically plausible range
                of parameters explored, such networks have maximum attainable ranges of accurate
                path integration of 1–10 minutes and 10–100 meters. Larger, less
                noisy networks occupy the high end of the range, while smaller and more stochastic
                networks occupy the low end. We end with suggestions for experiments to quantify
                integration accuracy, falsify the continuous attractor hypothesis, and determine
                whether the grid cell response is a recurrent network phenomenon or whether it
                emerges from computations occurring within single cells.</p>
        </sec>
        <sec id="s2">
            <title>Results</title>
            <p>In our model, each neuron receives inhibitory input from a surrounding ring of local
                neurons. The entire network receives broad-field feedforward excitation (<xref ref-type="sec" rid="s4">
                    <italic>Methods</italic>
                </xref>). If the inhibitory interactions are sufficiently strong, this type of
                connectivity generically produces a population response consisting of a regular
                pattern of discrete blobs of neural activity, arranged on the vertices of a regular
                triangular lattice <xref ref-type="bibr" rid="pcbi.1000291-Burak1">[3]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-McNaughton1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Murray1">[26]</xref>, <xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1A</xref>. Ignoring boundary
                effects for the moment, all possible phases (translations) of the pattern are
                equivalent steady states of the pattern formation process, and therefore form a
                continuous attractor manifold.</p>
            <fig id="pcbi-1000291-g001" position="float">
                <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g001</object-id>
                <label>Figure 1</label>
                <caption>
                    <title>Network architecture and response.</title>
                    <p>(A) Pattern formation in the neural population: Left, schematic depiction of
                        the outgoing weights of a neuron in the network. All neurons have the same
                        connectivity pattern, and the width of the inhibitory surround is
                        parameterized in our model by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e001" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">
                            <italic>Methods</italic>
                        </xref>). Center, circularly symmetric center-surround connectivity, with
                        sufficiently strong local inhibitory flanks, produces a regular triangular
                        lattice population pattern in the neural sheet through spontaneous
                        destabilization of the uniform mode (Turing instability). Right, the pattern
                        period depends on the width of the inhibitory surround. (B) The velocity
                        shift mechanism by which velocity inputs drive pattern flow: Each neuron in
                        the sheet is assigned a preferred angle (color coded), which means two
                        things. First, the outgoing weight profile, instead of being centered
                        exactly on the originating neuron, is shifted by a small amount along the
                        preferred angle in the neural sheet (left). Each patch in the neural sheet
                        contains neurons with all preferred angles. Second, the direction preference
                        means that the neuron receives input from head direction cells tuned to the
                        corresponding angle (center and right). (C) Snapshots of the population
                        activity, when the networks (periodic boundaries, above; aperiodic
                        boundaries, below) are driven by a constant velocity input in the rightward
                        direction. In the periodic network, as the pattern flows, it wraps around
                        the opposite edge. In the aperiodic network, as the pattern flows, blobs
                        move away from the left edge and new ones spontaneously form through the
                        same dynamics that govern pattern formation. (Boundaries are considered in
                        more detail in the paper and in later figures.) The green lines represent an
                        electrode at a fixed location in the neural sheet, and the circle above them
                        represents the activity state of the targeted neuron
                        (gray = inactive,
                        yellow = active). Network parameters are as
                        in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2A–C</xref>
                        and <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                        2D–F</xref>.</p>
                </caption>
                <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g001" xlink:type="simple"/>
            </fig>
            <p>To reproduce the regular single-neuron (SN) lattice patterns observed in experiment,
                the pattern formed in the neural population must be coupled to the rat's
                velocity. This coupling is arranged in such a way (<xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1B</xref> and <xref ref-type="sec" rid="s4">
                    <italic>Methods</italic>
                </xref>) that it drives translations of the pattern within the neural sheet, in
                proportion to the movements of the rat in real 2-d space, <xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1C</xref>.</p>
            <p>Briefly, velocity coupling involves distributing a set of direction labels (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e002" xlink:type="simple"/></inline-formula>) to the neurons in any patch of the network (<xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1B</xref>). The direction label <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e003" xlink:type="simple"/></inline-formula> signifies that (1) the neuron receives input from a
                speed-modulated head-direction cell tuned to that direction, and (2) the
                neuron's outgoing center-surround connectivity profile is centered not on
                itself, but is shifted by a few neurons along a corresponding direction on the
                neural sheet. The neuron tends, through its slightly asymmetric connectivity, to
                drive network activity in the direction of the shift. However, another neuron with
                the opposite direction preference will tend to drive a flow in the opposite
                direction. If all neurons have equal inputs, the opposing drives will balance each
                other, and the activity pattern will remain static. If, however, the rat moves in a
                particular direction in space, the corresponding model dMEC cells will receive
                larger input than the others, due to their head-direction inputs, and will succeed
                in driving a flow of the network pattern along their preferred direction. This
                mechanism for input-driven pattern flow is similar to that proposed in a model of
                the head-direction system <xref ref-type="bibr" rid="pcbi.1000291-Xie1">[14]</xref>. <xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1C</xref> demonstrates how a flow of the population pattern will drive
                activity at spatially periodic intervals in single neurons.</p>
            <p>To obtain spatially periodic responses in single neurons over long, curved,
                variable-speed trajectories, additional conditions must be met, as we discuss below.
                We present results from two topologically distinct networks: one with aperiodic, and
                the other with periodic, connectivity.</p>
            <sec id="s2a">
                <title>A Periodic Network Accurately Integrates Rat Velocity</title>
                <p>We simulate dynamics in a network of neurons driven by velocity inputs obtained
                    from recordings of a rat's trajectory (see <xref ref-type="sec" rid="s4">
                        <italic>Methods</italic>
                    </xref>). The network contains 128<sup>2</sup> (∼10<sup>4</sup>) neurons
                    arranged in a square sheet. Neurons close to each edge of the sheet form
                    connections with neurons on the opposite edge, such that the topology of the
                    network is that of a torus. <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                        2A</xref> shows the population activity in the network at one instant of the
                    run.</p>
                <fig id="pcbi-1000291-g002" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g002</object-id>
                    <label>Figure 2</label>
                    <caption>
                        <title>Periodic and aperiodic networks are capable of accurate path
                            integration.</title>
                        <p>Simulation of network response, with velocity inputs corresponding to a
                            rat's recorded trajectory in a 2 m circular enclosure <xref ref-type="bibr" rid="pcbi.1000291-Hafting2">[50]</xref>. The boundary conditions in the neural
                            sheet are periodic in (A–C) and aperiodic in (D–F).
                            (A,D) Instantaneous activity within the neural sheet (color represents
                            the firing rate: black corresponds to vanishing rate). The red curve in
                            (D) represents the fading profile of inputs to the network. (B,E) Grid
                            cell response: average firing rate of a single neuron (located at the
                            electrode tip in (A,D)), as a function of the rat's position
                            within the enclosure. (C,F) Velocity integration in the network: Top:
                            Actual distance of the rat from a fixed reference point (black),
                            compared to the network's integrated position estimate,
                            obtained by tracking the flow of the pattern in the population response
                            (blue). The reference point is at the left-bottom corner of the square
                            in which the circular enclosure is inscribed. Middle: Accumulated
                            distance between the integrated position estimate and the actual
                            position. Bottom: Orientation of the three main axes in the population
                            response during the trajectory. Note that there is no rotation in the
                            periodic network, and little rotation in the aperiodic one.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g002" xlink:type="simple"/>
                </fig>
                <p>A grid cell response, as reported in experimental papers, is obtained by summing
                    the firing activity of a single neuron over a full trajectory. Unlike the
                    population response, which is an instantaneous snapshot of full neural
                    population, the single-neuron response is an integrated measure over time of the
                    activity one cell. In the rest of this paper, SN response refers to the
                    accumulated response of single neurons over a trajectory.</p>
                <p>In the periodic network, the SN response, accumulated over the ∼20 minute
                    trajectory, and plotted as a function of the true rat position, shows coherent
                    grid activity, <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2B</xref>.
                    The network accurately integrates input velocity, as can verified directly by
                    comparing the cumulative network pattern phase to the rat's true
                    position, <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2C</xref>. The
                    total error, accumulated over ∼260 m and 20 minutes, is &lt;15 cm,
                    compared to a grid period of about 48 cm. This corresponds to an average
                    integration error of less than 0.1 cm per meter traveled and less than 0.01 cm
                    per second traveled. The range of rat speeds represented in the input trajectory
                    was 0–1 m/s, showing that this network is capable of accurate path
                    integration over this range of speeds.</p>
                <p>A deterministic periodic network of only 40<sup>2</sup> (∼10<sup>3</sup>)
                    neurons also performs well enough to produce coherent SN grids over the same
                    trajectory, <xref ref-type="supplementary-material" rid="pcbi.1000291.s001">Figure S1</xref>.</p>
            </sec>
            <sec id="s2b">
                <title>Equivalent Conditions for Accurate Path Integration</title>
                <p>The presence of a clear spatial grid in the SN response to velocity inputs alone
                    is a good indication of the accuracy of integration. If the rat's
                    internal estimate of position were to drift by half a grid period, the neuron
                    would fire in the middle of two existing vertices rather than on a vertex. As
                    the rat traveled over its trajectory, the neuron would fire at various
                    “wrong” locations, with the resulting SN response becoming
                    progressively blurred until no grid would be discernible. This would happen even
                    if the population pattern remained perfectly periodic throughout.</p>
                <p>Therefore, the following properties are equivalent: (1) Coherent grids in the SN
                    responses, (2) Accurate path integration of the full trajectory over which the
                    SN responses are visualized, with errors smaller than the grid period. An
                    example of this equivalence is given in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2A and 2C</xref>, which show sharp SN
                    patterning and a very small integration error.</p>
                <p>Next, because the population pattern phase accumulates errors whenever the
                    pattern slips relative to rat motion, another equivalent condition for accurate
                    path integration is (3) Linear relationship between network flow velocity and
                    input velocity over the input velocity range, independent of direction.</p>
                <p>These equivalent conditions for accurate integration apply to both periodic and
                    aperiodic network models of grid cells (discussed next).</p>
            </sec>
            <sec id="s2c">
                <title>An Appropriately Configured Aperiodic Network Can Accurately Integrate Rat
                    Velocity</title>
                <p>It is unclear whether a torus-like network topology, in which neurons along
                    opposite edges of the network are connected to form periodic boundary
                    conditions, exists in the rat's brain. Even if such connectivity
                    exists, it may require, at an earlier stage of development, an initially
                    aperiodic network (see <xref ref-type="sec" rid="s3"><italic>Discussion</italic></xref>). Hence
                    it is interesting to consider whether a network with non-periodic boundaries can
                    produce grid-cell like SN activity. The difficulty here is that as the
                    population pattern flows in response to velocity inputs, it must reform at the
                    boundaries of the neural sheet. Newly forming activity blobs must be created at
                    accurate positions, and the process must not interfere with the
                    pattern's flow.</p>
                <p>A central result of the present work on aperiodic networks is that such networks
                    can, in fact, accurately integrate velocity inputs. With an appropriate choice
                    of architecture and inputs and with deterministic dynamics, an aperiodic network
                    can produce SN responses that are as accurate as in the periodic case above.
                    This is illustrated in the example of <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D–F</xref>. At the aperiodic
                    boundaries, the same dynamics that governed the initial pattern formation
                    process also cause the pattern to continually regenerate as the pattern flows
                        (<xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1C, bottom</xref>). The
                    phases or locations of the renewing blobs at the boundary are consistent with
                    the rest of the network pattern, in part because their placement is influenced
                    by inhibition from the neighboring active neurons in the network interior.</p>
                <sec id="s2c1">
                    <title>Accurate integration in aperiodic networks is not generic</title>
                    <p>Despite the success of the model given above, accurate path integration in
                        aperiodic networks is not as generic an outcome as it was in the periodic
                        network. We describe next how accurate path integration in aperiodic
                        networks requires attention to details and tuning.</p>
                    <p>To produce a coherent SN grid in aperiodic networks, as above, it is not
                        sufficient to simply leave unconnected the opposite edges of the sheet that
                        were connected together to produce a periodic network: If the recurrent
                        connections and external inputs terminate abruptly at the network edge, the
                        population activity pattern there becomes severely distorted. Such
                        distortions disrupt the linearity of the network's response to
                        velocity inputs <xref ref-type="bibr" rid="pcbi.1000291-Burak1">[3]</xref>. As a result, population pattern
                        distortions, even when confined to the edges of the network, globally
                        destroy the possibility of generating grid-like SN responses for any neuron,
                        including those in the interior of the network where the pattern is locally
                        undistorted. In fact, even subtle distortions of the pattern near the edges
                        cause similar problems.</p>
                </sec>
                <sec id="s2c2">
                    <title>Modulation of recurrent weights vs. feedforward inputs</title>
                    <p>To ameliorate the problem of edge distortions, we considered two main types
                        of modulation in the network architecture. One of these, as in <xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref>,
                        was to smoothly modulate the strength of weights to zero near the boundary.
                        Generally speaking, this method still leads to distorted patterning near the
                        edges. To see why, consider that if weights are sufficiently weak, then
                        pattern formation, which is driven by the recurrent connectivity, does not
                        occur at all. The uniform mode, in which all neurons are equally active,
                        becomes stable. Thus fading the strength of recurrent connectivity to small
                        values at the boundaries results in distortions of the triangular lattice
                        pattern, including the formation of a band of uniformly and highly active
                        neurons along the edges (<xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Burak1">[3]</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000291.s002">Figure
                        S2</xref>). Other modulations of the weights at the edges create other types
                        of mismatch between the pattern at the edges compared to the interior.</p>
                    <p>A second approach is to keep the strength of local recurrent connectivity,
                        which is responsible for pattern formation, constant throughout the network
                        and at the edges, while tapering the strength of external feedforward inputs
                        near the edges. The result is that local patterning is robust, but at the
                        same time, neurons in boundary blobs are proportionally less active, with
                        their activation profiles fading smoothly to zero near the network edges. It
                        is straightforward to see, analytically, that if the network dynamics of Eq.
                        1 has a particular spatially patterned solution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e004" xlink:type="simple"/></inline-formula> (designating the population activity vector) for a given
                        strength of input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e005" xlink:type="simple"/></inline-formula>, the solution for the scaled input vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e006" xlink:type="simple"/></inline-formula> is the same spatial pattern, scaled in amplitude to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e007" xlink:type="simple"/></inline-formula>. Thus, if the weakening of external inputs is sufficiently
                        gradual (compared to the spacing between activity blobs in the population
                        pattern), activity must scale in proportion to the external input, without a
                        disruption in the periodicity of the pattern. Because the activity of blobs
                        at the network boundary is far lower than in the interior, these boundary
                        blobs have correspondingly less influence on overall network dynamics during
                        flow, and have a less disruptive effect on the linearity of the network
                        response to velocity inputs.</p>
                    <p>Indeed, we found in our simulations that tapered input profiles dramatically
                        improve the linearity of response to velocity inputs, compared to a
                        modulation of the weights. Throughout the manuscript, therefore, we have
                        used a tapered input profile with untapered weights. An example of faithful
                        population patterning with tapered input can be seen in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D</xref>, with the input profile plotted
                        above the population activity.</p>
                    <p>As we describe next, a population response that appears regular near the
                        edges is necessary, but not sufficient, for accurate integration.</p>
                </sec>
                <sec id="s2c3">
                    <title>Independent effects of network size and input profile on integration
                        accuracy</title>
                    <p>The input envelope of <xref ref-type="fig" rid="pcbi-1000291-g003">Figure
                        3B</xref> is somewhat sharper than in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2</xref>, yet is still smooth enough to
                        produce a regular population pattern without irregularities, and with
                        boundary neurons that are only weakly active (<xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3B</xref>). However, this network fails
                        to produce a periodic structure in the SN response (<xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3A</xref>). Recording the population
                        activity at different times reveals that the population pattern rotates
                            (<xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3B and 3C</xref>).
                        The velocity inputs, which are supposed to drive only pure translation of
                        the pattern, also induce rotation. Another reason for the network's
                        poor performance is demonstrated in <xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3D2</xref>: The flow rate of the grid
                        pattern is not precisely proportional to the rat's velocity. In
                        particular, at rat velocities below approximately 10 cm/s there is no flow
                        at all, and the pattern is “pinned”.</p>
                    <fig id="pcbi-1000291-g003" position="float">
                        <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g003</object-id>
                        <label>Figure 3</label>
                        <caption>
                            <title>Boundary conditions and network size strongly affect fidelity of
                                network response.</title>
                            <p>(A–C) Same simulation as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D–F</xref>, but with a
                                sharper input profile (red curve above B). The SN pattern has no
                                periodicity (A), the integration error is large (thick line in (C),
                                upper plot; note the different scale compared to <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2E</xref>, whose
                                error is represented by the thin line), and the population response
                                rotates frequently ((C), lower plot). (D1–D3) Network
                                velocity response as a function of different input profiles: Input
                                profile decay is least abrupt in (D1), more abrupt in (D2), and most
                                abrupt in (D3) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e008" xlink:type="simple"/></inline-formula> for (D1), (D2), and (D3), respectively; network
                                size is 128 neurons per side(<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e009" xlink:type="simple"/></inline-formula>) for all). (D4) The input profile at the
                                boundaries is identical to D2 (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e010" xlink:type="simple"/></inline-formula>), but the network is larger (256 neurons per side
                                or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e011" xlink:type="simple"/></inline-formula>). (D2) corresponds to the parameters in
                                (A–C), and (D1) corresponds to the parameters in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                                2D–F</xref>.</p>
                        </caption>
                        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g003" xlink:type="simple"/>
                    </fig>
                    <p>The network's ability to produce accurate path integration and
                        coherent SN grids is independently influenced by two factors, the activity
                        profile of neurons at the network boundary, and network size. For a fixed
                        network size, sharper input fading at the boundaries leads to more pinning
                            (<xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3, D3
                            <italic>vs.</italic> D2 <italic>vs.</italic> D1</xref>). Thus, a
                        relatively subtle difference in how activity fades near the network boundary
                        is sufficient to cause a transition from accurate path integration and
                        coherent SN grids into poor tracking and the complete absence of SN grids.
                        At the same time, for a given tapering of inputs at the boundary, increasing
                        the size of the network reduces pinning and improves the linearity of the
                        network velocity response (<xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3, D4 <italic>vs.</italic> D2</xref>), suggesting that from the
                        point of view of integration performance, the larger the network the better.</p>
                    <p>The same factors that reduce pinning (smoother input fading at network
                        boundaries and larger network size) also serve to stabilize the orientation
                        of the population pattern (data not shown), suggesting that the undesirable
                        coupling of velocity inputs to rotation is also related to the existence of
                        the boundaries.</p>
                    <p>A network with 128<sup>2</sup> (∼10<sup>4</sup>) neurons (<xref ref-type="fig" rid="pcbi-1000291-g002">Figures 2D–F</xref> and
                            <xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3D1,D4</xref>) can
                        be large enough, with deterministic dynamics and appropriately chosen
                        boundaries, to perform accurate path integration over 260 m and 20 minutes.
                        Although we did not strenuously attempt to optimize all parameters involved,
                        within our explorations we were unable to construct an aperiodic network
                        substantially smaller than 10<sup>4</sup> neurons which performs comparably
                        well. It appears, therefore, that network size strongly constrains the
                        accuracy of integration in aperiodic networks, to a greater extent than in
                        the periodic case.</p>
                </sec>
            </sec>
            <sec id="s2d">
                <title>The Attractor Manifold</title>
                <p>For the two types of networks from the previous section, the structure of the
                    state-space is schematically illustrated in <xref ref-type="fig" rid="pcbi-1000291-g004">Figure 4</xref>. The state-space illustration is
                    instrumental in synthesizing the findings of the preceding section –
                    in particular: Why does the pattern not rotate in the periodic network? Why is
                    the pattern pinned at low input velocities in the aperiodic network? Why does
                    network size matter more for aperiodic than for periodic networks? We assume
                    that the dynamics minimize an energy functional, whose local minima correspond a
                    set of fixed points (attractors) (This assumption is precisely correct in the
                    absence of a velocity-driven shift mechanism, since the connectivity matrix is
                    then symmetric <xref ref-type="bibr" rid="pcbi.1000291-Cohen1">[27]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hopfield1">[28]</xref>.)</p>
                <fig id="pcbi-1000291-g004" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g004</object-id>
                    <label>Figure 4</label>
                    <caption>
                        <title>The continuous attractor manifold.</title>
                        <p>(A) Periodic network manifold: Points within the trough represent stable
                            states of the network that will persist in the absence of perturbing
                            inputs. If the network is placed at a state outside the trough, it will
                            rapidly decay to a state within the trough. Points in the trough consist
                            of continuous translations of the population-level pattern. Rotations,
                            stretches, or other local or global deformations of the pattern lie
                            outside the trough. Rat velocity inputs drive transitions between points
                            in the trough (red arrow). (B) Aperiodic network manifold: all rotations
                            of a stable population pattern are energetically equivalent, and so form
                            a continuous attractor manifold. Translations are not equivalent
                            (rippled energy functional). Rat velocity inputs, when large enough to
                            overcome the ripple, drive translations of the population pattern;
                            however, the flat rotational mode means that the network can also
                            rotate.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g004" xlink:type="simple"/>
                </fig>
                <p>Consider first the <italic>periodic network</italic>. Starting from a steady
                    state of the dynamics, and rigidly translating the stable population pattern,
                    produces an equivalent steady state with exactly the same energy. The set of all
                    such states forms a continuous manifold of attractor states, related to each
                    other by continuous translation. This manifold can be visualized as the trough
                    of the energy surface, <xref ref-type="fig" rid="pcbi-1000291-g004">Figure
                    4A</xref>. Rotating a steady state pattern, on the other hand, produces states
                    with higher energy. (Rotation can be visualized as follows. Imagine first
                    cutting open the toroidal periodic network along the edges of the sheet that
                    were originally glued together to produce a periodic network. On the resulting
                    sheet, rotate the pattern, and rejoin the cut edges. This procedure will produce
                    discontinuities in the pattern along the rejoined edges.) Hence the attractor
                    manifold does not include continuous rotations.</p>
                <p>Inputs that induce pattern translation will stably move the network state along
                    the trough, even if the inputs are small, and the integrated value of the input
                    will be reflected in the updated network phase. On the other hand, inputs that
                    attempt to induce rotations will not produce lasting changes in network state,
                    because these states are unstable and will quickly (over a few hundred
                    milliseconds or less) decay as the pattern relaxes to its preferred orientation.
                    Similarly, distorting the pattern by stretching it, adding noise, or by removing
                    blobs from the pattern will generate an unstable state, which will rapidly decay
                    to a steady state within the attractor manifold.</p>
                <p>In the <italic>aperiodic network</italic>, translations of a steady state pattern
                    are similar but not exactly equivalent, because the phase of the activity
                    pattern relative to the boundary affects the energy of the state. Strictly
                    speaking then, these states do not form a continuous attractor manifold, <xref ref-type="fig" rid="pcbi-1000291-g004">Figure 4B</xref>. Instead, the
                    manifold is slightly rippled along the direction of translations. To drive
                    translations, velocity inputs must be large enough to overcome the ripple
                    barrier. This explains why below a critical velocity, the pattern is pinned in
                    our simulations. The ripple amplitude depends on how much influence the boundary
                    has on the network dynamics. If activity fades to zero sufficiently smoothly
                    near the boundary the ripple can be small. Pattern translation then corresponds
                    to motion along a nearly flat direction on the manifold, pinning is confined to
                    a negligibly small range of velocities, and integration of inputs can be
                    accurate. A reduction of pinning can be achieved also by increasing the network
                    size, while keeping the boundary profile fixed, because boundary effects scale
                    as the ratio of network periphery to network area.</p>
                <p>A stable population pattern state can be rotated around the center of a circular
                    aperiodic neural sheet to obtain another stable state that is identical in
                    energy to the original one. Hence, rotations correspond to a flat direction in
                    the energy surface, <xref ref-type="fig" rid="pcbi-1000291-g004">Figure
                    4B</xref>. Any input that couples even slightly with the rotational mode can
                    drive rotations in the network pattern. The velocity inputs to the network,
                    though configured to drive translational pattern flow, can weakly drive
                    rotations due to boundary effects that couple the translational drive to
                    rotational modes. In spiking networks, discussed below, rotations can be driven
                    also by noise.</p>
                <p>In the network models described here, the structure of the attractor manifold
                    (e.g., <xref ref-type="fig" rid="pcbi-1000291-g004">Figure 4A or 4B</xref>) is
                    completely determined by the matrix of pairwise weights between neurons and the
                    inputs received by each neuron. Once the weights between all pairs of neurons
                    and the inputs to each neuron are specified, the matrix does not change if the
                    locations of the neurons on the cortical sheet are shuffled, so long as the
                    weights and inputs to each neuron are held fixed (see <xref ref-type="sec" rid="s3">
                        <italic>Discussion</italic>
                    </xref>). Thus, statements about the existence of a manifold of stable network
                    states and stable SN grid responses, and the predictions that stem from them, do
                    not depend on topography, even when stated here for expositional simplicity in
                    terms of topographically arranged population-level patterns.</p>
            </sec>
            <sec id="s2e">
                <title>Spiking Networks and Noise</title>
                <p>So far we have considered errors in integration that occur in the absence of
                    noise. Unlike in the noise-free case, neural noise can induce the population
                    pattern to flow or rotate even when velocity inputs are absent. To assess how
                    noise influences the precision of the network's response, we present
                    results from spiking neural networks with the same connectivity as in the rate
                    based models. Dynamics in these networks are noisy due to the stochasticity of
                    discrete spiking events.</p>
                <p>For the same network parameters as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2</xref>, and assuming that neural firing is
                    an inhomogeneous Poisson process, we find that the periodic network continues to
                    perform well enough to produce coherent SN responses over long trajectories
                        (<xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5A</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure S3</xref>).
                    In the aperiodic network, performance with Poisson spiking neurons is
                    considerably worse than in the rate based model, enough to destroy the grid-like
                    SN response over a ∼130 meter, 10-minute trajectory, in particular due
                    to rotations (<xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure S3</xref>). Network performance improves, however, if spiking in the
                    network is more regular than implied by inhomogeneous Poisson statistics. To
                    quantify this effect, we performed simulations with sub-Poisson statistics (see
                        <xref ref-type="sec" rid="s4">
                        <italic>Methods</italic>
                    </xref>). The variance of neural firing is characterized, in our simulations, by
                    the coefficient of variation (CV) of the inter-spike interval. With a
                    sufficiently low CV, aperiodic network dynamics are precise enough to produce a
                    coherent SN response over a trajectory lasting 10 minutes and ∼130
                    meters, <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5B</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure S3</xref>.</p>
                <fig id="pcbi-1000291-g005" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g005</object-id>
                    <label>Figure 5</label>
                    <caption>
                        <title>Single neuron (SN) responses from stochastic spiking networks.</title>
                        <p>(A) SN response in a stochastic spiking periodic network. The parameters
                            and input velocity trajectory are as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2A–C</xref>, except that
                            spiking is simulated explicitly and the spikes are generated by an
                            inhomogeneous Poisson process. (B) SN response in a stochastic spiking
                            aperiodic network. The parameters are as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D–F</xref>, except that
                            spiking is simulated explicitly and the spikes are generated by a point
                            process with a CV of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e012" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">
                                <italic>Methods</italic>
                            </xref>). Each red dot represents a spike.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g005" xlink:type="simple"/>
                </fig>
                <sec id="s2e1">
                    <title>Quantification of noise-driven translational drift</title>
                    <p>Integration can be decomposed into two elements: a memory that holds onto the
                        state of the integrator, and a mechanism that correctly increments the state
                        of the integrator in response to inputs. The linearity of the velocity
                        response of the network, described earlier for noise-free networks, may be
                        viewed as an assessment of the accuracy of the increment mechanism, while
                        the degree of drift in the network state in the absence of velocity inputs
                        and external corrective cues is a quantification of the network's
                        ability to hold onto its current state. Therefore, a way to assess the
                        effect of noise on integration accuracy is to examine the drift in the
                        population state when external velocity inputs are absent.</p>
                    <p>As shown in <xref ref-type="fig" rid="pcbi-1000291-g006">Figure 6</xref>, the
                        states of both periodic and aperiodic spiking networks drift significantly
                        over measurable time-scales, in the absence of any velocity input. As
                        expected, the network state remains in the attractor manifold: Neither
                        network displays stretching or other distortions (data not shown), but the
                        aperiodic network pattern drifts in phase and orientation, while the
                        periodic network pattern drifts in phase without rotation (<xref ref-type="fig" rid="pcbi-1000291-g006">Figure 6A and 6B</xref>).</p>
                    <fig id="pcbi-1000291-g006" position="float">
                        <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g006</object-id>
                        <label>Figure 6</label>
                        <caption>
                            <title>Quantification of drift induced by neural stochasticity, in the
                                absence of velocity inputs.</title>
                            <p>Orange (blue) curves are the results of simulations in (a)periodic
                                networks. Successively darker shades (of orange or blue) represent
                                simulations with successively higher neural variability (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e013" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e014" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e015" xlink:type="simple"/></inline-formula>, and 1, respectively). Identical colors across
                                panels represent simulations with identical network parameters.
                                Velocity inputs are zero everywhere, and network size is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e016" xlink:type="simple"/></inline-formula>, except where stated otherwise. (A) Phase drift
                                and (B) angular drift of the periodic (orange,
                                CV = 1) and aperiodic (blue, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e017" xlink:type="simple"/></inline-formula>) networks. In (A), the drift in cm corresponds to
                                a measured drift in neurons by assuming the same gain factor as in
                                the simulations with a trajectory, as in <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5</xref>. (C) The summed square
                                2-d drift in position estimation as a function of elapsed time, for
                                two different values of CV, in the absence of velocity inputs. The
                                squared drift (small open circles) can be fit to straight lines
                                (dashed) over 25 seconds (for longer times the traces deviate from
                                the linear fit due to the finite time of the simulation), indicating
                                that the process is diffusive. The slope of the line yields the
                                diffusion constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e018" xlink:type="simple"/></inline-formula> for phase (translational) drift of the population
                                pattern, in units of neurons <sup>2</sup>/s. The same fitting
                                procedure applied to the squared angular drift as a function of time
                                yields the angular diffusion constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e019" xlink:type="simple"/></inline-formula>. (D) Diffusion constants measured as in (C), for
                                networks of varying size and CV. The diffusion constant is
                                approximately linear in CV<sup>2</sup>, and in the number of neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e020" xlink:type="simple"/></inline-formula>. To demonstrate the linearity in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e021" xlink:type="simple"/></inline-formula>, the plots show <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e022" xlink:type="simple"/></inline-formula> multiplied by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e023" xlink:type="simple"/></inline-formula>, upon which the data for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e024" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e025" xlink:type="simple"/></inline-formula> approximately collapse onto a single curve. (E) An
                                estimate of the time over which a periodic spiking network (with the
                                same parameters as the corresponding points in (C) and (D)) can
                                maintain a coherent grid cell response, plotted as a function of N,
                                for two values of neural stochasticity. The estimate is based on
                                taking the diffusion relationship <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e026" xlink:type="simple"/></inline-formula>, and solving for the time when the average
                                displacement <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e027" xlink:type="simple"/></inline-formula> is 10 pixels, about half the population period,
                                and estimating the diffusion constants from (D) to be
                                <italic>ND</italic>≃2500 neurons<sup>2</sup>/s. The
                                coherence time scales like <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e028" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e029" xlink:type="simple"/></inline-formula> is the period of the population pattern. (F)
                                Rotational diffusivity, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e030" xlink:type="simple"/></inline-formula>, in an aperiodic network of size 128×128
                                also increases linearly with CV<sup>2</sup>. The diffusion constant
                                was measured from simulations lasting 20 minutes.</p>
                        </caption>
                        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g006" xlink:type="simple"/>
                    </fig>
                    <p>Quantitatively, the drift in the phase of the population pattern appears
                        diffusive (<xref ref-type="fig" rid="pcbi-1000291-g006">Figure 6C</xref>,
                        periodic network): in a time interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e031" xlink:type="simple"/></inline-formula> the square of the average drift due to noise can be
                        written as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e032" xlink:type="simple"/></disp-formula>The diffusion constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e033" xlink:type="simple"/></inline-formula> decreases with network size and increases with the CV of
                        neural spiking (<xref ref-type="fig" rid="pcbi-1000291-g006">Figure
                        6D</xref>), scaling as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e034" xlink:type="simple"/></disp-formula>This result can be used to obtain an estimate for the maximal
                        expected duration of accurate integration in the presence of noise for
                        networks of different sizes and CVs. Noise can be said to
                        “decohere” or destroy the SN response when it drives the
                        network phase to drift by half the pattern period. By this measure, and with
                        the parameters used in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                            2A–C</xref>, we plot in <xref ref-type="fig" rid="pcbi-1000291-g006">Figure 6E</xref> the maximal duration of
                        accurate integration, as a function of network size, for two values of the
                        CV (1 and 0.5). This duration is about 400 s in a periodic network with
                            10<sup>4</sup> neurons and CV = 1,
                        roughly in agreement with our observations from <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure
                        S3</xref>.</p>
                    <p>We recall that in both larger and smaller versions of the deterministic
                        periodic network, integration was highly accurate, <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2A–C</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000291.s001">Figure
                        S1</xref>. The relatively weak dependence on network size in the
                        deterministic case gives way to a stronger sensitivity on size in the
                        presence of neural noise: the interval of accurate integration, set by
                        noise-driven drift, decreases linearly with decreasing network size. Thus,
                        neural noise sets limits on the minimum size of the network needed to
                        produce accurate integration, even in the periodic network.</p>
                </sec>
                <sec id="s2e2">
                    <title>Quantification of noise-driven rotational drift</title>
                    <p>In aperiodic networks, rotational drift of the population pattern can be
                        measured by tracking the orientation of the pattern as a function of time.
                        We find that this drift too is diffusive:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e035" xlink:type="simple"/></disp-formula>The diffusion constant can be measured in a similar fashion
                        to the measurement of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e036" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1000291-g006">Figure
                        6C</xref>. Roughly, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e037" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pcbi-1000291-g006">Figure
                        6F</xref>. We can use these measurements to obtain an estimate for the
                        maximal expected time until noise-driven rotations destroy the single neuron
                        pattern during path integration: Requiring that the rotational drift remain
                        smaller than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e038" xlink:type="simple"/></inline-formula>, we obtain an estimate of about 85 s for a network with
                        CV = 1, and about 680 s for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e039" xlink:type="simple"/></inline-formula>, in agreement with the time over which accurate
                        integration was observed in <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5</xref> and in <xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure S3</xref>.</p>
                    <p>Assuming that the translational drift in the aperiodic network is similar to
                        that measured in the periodic network we conclude that, in the aperiodic
                        network, rotations are the more severe source of noise-driven decoherence of
                        the SN response. This conclusion is in agreement with the observation that
                        the 128<sup>2</sup> aperiodic network required a smaller CV, compared to the
                        periodic network (where there are no rotations) to achieve a similar
                        performance, even though the two networks showed similar performance in the
                        noise-free case.</p>
                </sec>
                <sec id="s2e3">
                    <title>Variability in recorded grid cell responses</title>
                    <p>Motivated by the result that sub-Poisson spiking statistics are important for
                        accurate integration in the grid-cell network, we analyzed spike recordings
                        from neurons in dMEC <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>. Under certain conditions, cortical
                        neurons are reported to be Poisson or even super-Poisson in their firing
                        statistics <xref ref-type="bibr" rid="pcbi.1000291-Softky1">[29]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Shadlen1">[30]</xref>.
                        Interestingly, our analysis of the dMEC data suggests that grid cell firing
                        is significantly sub-Poisson (<xref ref-type="supplementary-material" rid="pcbi.1000291.s004">Figure S4</xref>).</p>
                    <p>For various reasons, it is not possible to exactly compare the CV used in our
                        simulations and the CV of the recorded cells in dMEC. For example, dMEC
                        contains numerous cell types, each of which may have different CVs. Also,
                        the effects of individual neural variability on integration performance are
                        ameliorated by averaging over the network population, but the size of the
                        actual dMEC network may not be the same as in our simulations, and the
                        actual network may contain correlations not included in our model, so that
                        even if we were able to pick the “correct” CV for
                        individual neurons, the net effect on integration performance may be
                        different in the model from that in dMEC. Finally, the CV is a
                        low-dimensional measure that does not fully characterize the spiking
                        statistics of a neuron: even if we could match the size of the dMEC network
                        and the CV of each neuron type, the statistics of our model neurons could
                        greatly differ from those in the rat.</p>
                    <p>Despite these caveats, our results suggest that a significant blurring of the
                        SN response is expected to occur on a time scale ranging between a few
                        minutes to a few tens of minutes, within a reasonable range of estimates for
                        the number of neurons in the network and the variability of neural
                    spiking.</p>
                </sec>
            </sec>
            <sec id="s2f">
                <title>Predictions of the Attractor Model</title>
                <p>Armed with the proof-of-concept results that a continuous attractor network model
                    can integrate velocity inputs accurately enough to produce SN grids, we next
                    seek to explore testable predictions of the continuous attractor hypothesis in
                    the grid cell system and contrast them with the properties of models in which
                    the grid responses emerge independently in each cell <xref ref-type="bibr" rid="pcbi.1000291-Burgess1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hasselmo1">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-OKeefe1">[16]</xref>. Unless explicitly
                    specified, all proposed tests are intended for conditions in which external,
                    spatially informative cues have been removed.</p>
                <sec id="s2f1">
                    <title>Stability of the attractor manifold</title>
                    <p>As described earlier, the low-dimensional structure of the attractor means
                        that only a very small subset of possible states of the network, defined by
                        strict inter-relationships in neural activity (population patterns), are
                        stable, while other states quickly decay away. The quantity conserved across
                        pattern translations and therefore across the attractor manifold is the
                        phase <italic>relationship</italic> between cells, defined by whether
                        neurons are co-active or active at different phases. The stability of the
                        attractor manifold and the instability of states outside it have a number of
                        implications for experiment.</p>
                </sec>
                <sec id="s2f2">
                    <title>Stability of phase relationships in absence of inputs</title>
                    <p>Due to the stability of the attractor manifold, phase relationships in the
                        periodic network should be stable over the time-scale of days (because the
                        pattern does not rotate), regardless of inevitable drifts in the absolute
                        phase of individual neurons. Even in aperiodic networks, we expect phase
                        relationships to persist over 1–10 minutes, but possibly not
                        longer due to the possibility of rotations. Under similar conditions in
                        models where the grid is generated separately by individual neurons
                        (“independent neuron models”), like temporal
                        interference models <xref ref-type="bibr" rid="pcbi.1000291-Burgess1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hasselmo1">[6]</xref>, the phase
                        relationships between cells should drift or random walk over relatively
                        short periods of time, on the same time-scale as drifts in the absolute
                        phase of single cells. This is because in independent neuron models, the
                        phase of the grid response of each cell is determined individually, in part
                        from the phase of an intrinsic oscillator. Hence, unlike the continuous
                        attractor models, phases of different neurons are untethered to each other
                        through network interactions.</p>
                </sec>
                <sec id="s2f3">
                    <title>Stability against small perturbations of neural subsets</title>
                    <p>Because the attractor dynamics are restoring, small perturbations (small
                        induced changes in the activity of neurons) of state without a component
                        along the attractor manifold should not produce lasting changes in the
                        states of these neurons or the network. Network interactions should restore
                        the state to the original state that preceded the perturbation: thus, both
                        the absolute phases of cells and their phase relationships should be
                        unchanged by the perturbation. This statement also applies to large
                        perturbations, if they have no appreciable projection along the attractor
                        manifold (e.g., large random perturbations made directly to different layer
                        II/III grid cells with low velocity sensitivity are examples of such large
                        perturbations). By contrast, following small or large perturbations to
                        subsets of cells in independent neuron models, the absolute activity states
                        of those cells, as well as their relative phase relationships with
                        unperturbed neurons should change, due to the absence of restoring network
                        interactions.</p>
                </sec>
                <sec id="s2f4">
                    <title>Coherent movement along the attractor manifold in response to incoherent
                        perturbations</title>
                    <p>Perturbations that have a large component along the attractor manifold should
                        drive a coherent transition to the point on the attractor manifold that is
                        closest to the perturbed state. Because the new state will be on the
                        attractor manifold, phase relationships between neurons should be unchanged.
                        Head direction cells provide a means to induce such a perturbation:
                        Stimulating a subset of head direction cells should drive a rigid (coherent)
                        and lasting translation of the entire population pattern, producing the same
                        shift in phase in all cells, regardless of whether or not they received
                        direct head direction input. By contrast, similar inputs provided only to
                        subsets of cells in independent neuron models should produce changes in
                        phase only in the stimulated cells.</p>
                </sec>
                <sec id="s2f5">
                    <title>Single neuron responses</title>
                    <p>The continuous attractor model predicts that all cells in the network must
                        have identical orientations, and all phases must be equally represented in
                        the population <xref ref-type="bibr" rid="pcbi.1000291-Fuhs1">[2]</xref>. Both these properties are consistent with
                        observations <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>, but are difficult to explain in
                        independent neuron models, without invoking additional mechanisms that
                        effectively turn the system into a low-dimensional attractor.</p>
                    <p>Further, in the continuous attractor model, if any cell's grid
                        response contains a reproducible irregularity of any kind (e.g., a global
                        skewing of the lattice, or a local defect, such as a local 5–7
                        pairing of neighbors instead of the usual 6), it follows that
                        <italic>every</italic> cell in the network must display the same
                        irregularity, up to a global shift in phase. Indeed, our preliminary
                        analysis of data from <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref> supports this prediction, <xref ref-type="supplementary-material" rid="pcbi.1000291.s005">Figure
                        S5</xref>.</p>
                </sec>
                <sec id="s2f6">
                    <title>Expansion or contraction of the SN grid in different environments</title>
                    <p>In experiments where a familiar enclosure is resized, the SN response is
                        observed to rescale along the rescaled dimension of the enclosure, at least
                        temporarily <xref ref-type="bibr" rid="pcbi.1000291-Barry1">[31]</xref>. Further, when the rat is placed in a
                        novel environment, the SN grid responses are observed to isotropically
                        expand or contract <xref ref-type="bibr" rid="pcbi.1000291-Fyhn1">[32]</xref>. These observations have sometimes been
                        interpreted as evidence against the continuous attractor models of grid
                        cells.</p>
                    <p>To explain why these rescaling experiments are consistent with a continuous
                        attractor model of grid cells, it is important to stress the difference
                        between the population-level and the SN responses. The attractor manifold
                        consists of the steady states of the population response, which consists of
                        translations (and in aperiodic networks, rotations) of a canonical pattern.
                        Thus, stretching and rotation of the population pattern are forbidden
                        (unstable) and cannot be invoked within the continuous attractor models to
                        explain the experimental observations.</p>
                    <p>The SN response, on the other hand, is not directly subject to constraints
                        imposed by the attractor manifold on the population pattern, because it is a
                        function of both the instantaneous population pattern and the velocity
                        response of the pattern in time. If the pattern were to flow more slowly
                        along one dimension than the other, for equivalent rat speeds, the SN
                        response would be a stretched version of the regular underlying population
                        grid, with the stretched dimension corresponding to the slow flow dimension.
                        Hence, stretching of the SN response can be explained in the continuous
                        attractor model by an amplitude modulation of head direction inputs tuned to
                        the relevant head direction, without inflicting such a deformation on the
                        population pattern (<xref ref-type="fig" rid="pcbi-1000291-g007">Figure 7A
                            and 7B</xref>). If the population pattern were not constrained by the
                        low-dimensional attractor, SN stretching could instead be effected by a
                        stretching of the population pattern in the cortical sheet, <xref ref-type="fig" rid="pcbi-1000291-g007">Figure 7B</xref> (rightmost
                        column).</p>
                    <fig id="pcbi-1000291-g007" position="float">
                        <object-id pub-id-type="doi">10.1371/journal.pcbi.1000291.g007</object-id>
                        <label>Figure 7</label>
                        <caption>
                            <title>Tests of the continuous attractor hypothesis.</title>
                            <p>Green lines represent the same fixed electrode locations in the
                                neural population, across all plots. (A) Left: Single-neuron
                                response. Right: Input head direction/velocity tuning curves, and an
                                instantaneous snapshot of the underlying population response, which
                                together produced the SN response on the left. (B) The SN grid
                                (left) expands along one direction when the amplitude of the head
                                direction/velocity inputs for that direction is lowered relative to
                                other directions (right, first panel), while the population patterns
                                remain unchanged. Alternatively, the same SN expansion could have
                                been produced by keeping the amplitude of the head
                                direction/velocity inputs fixed, if the population patterns were
                                stretched (right, second panel). The latter scenario is inconsistent
                                with the attractor hypothesis, because deformations of the pattern
                                are not part of the attractor manifold. In the former (continuous
                                attractor) scenario, the phase relationships between neurons is
                                preserved despite the SN expansion; in the second, phase
                                relationships must change. (C) The SN grid (left) rotates if the
                                head direction/velocity inputs to the network are rotated, while the
                                population remains unchanged. The same rotation could have been
                                produced by rotating the population pattern, but keeping the head
                                direction/velocity inputs intact. The latter possibility is
                                inconsistent with the attractor hypothesis. Again, the former
                                (continuous attractor) scenario can be distinguished from the latter
                                by whether phase relationships between neurons in the population are
                                preserved. (SN plots and the left column of population responses
                                were produced from a simulation with network parameters as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                                2D–F</xref>, and by appropriately scaling or rotating the
                                velocity/head direction inputs. Right population plots are
                                hypothetical.)</p>
                        </caption>
                        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.g007" xlink:type="simple"/>
                    </fig>
                    <p>How can experiments distinguish between these two possibilities? The
                        continuous attractor model predicts that the phase relationships between
                        neurons must remain unchanged upon stretching of the SN response (<xref ref-type="fig" rid="pcbi-1000291-g007">Figure 7A and 7B, middle
                        column</xref>). This prediction of the continuous attractor model will be
                        explicitly violated if stretching happens at the population level, <xref ref-type="fig" rid="pcbi-1000291-g007">Figure 7A and 7B, rightmost
                            column</xref>. Further, the continuous attractor model predicts that the
                        strength of velocity modulation in the head direction inputs to dMEC and in
                        the conjunctive heading- and velocity-sensitive grid cells <xref ref-type="bibr" rid="pcbi.1000291-Sargolini1">[33]</xref> should decrease along the grid's
                        stretched dimension, which corresponds to the expanded enclosure dimension,
                        and the percentage decrease should correspond exactly to the percentage
                        stretching of grid responses.</p>
                    <p>In contrast, if the SN stretching is due to a similar stretching in the
                        population response, there should be little to no change in the amplitude of
                        velocity modulation of the cells. In summary, changes in the phase
                        relationships between cells, or no change in the velocity modulation of the
                        head direction inputs to dMEC, when the SN responses have been stretched,
                        would be evidence against the attractor model.</p>
                    <p>Similarly, a rotation <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref> (or an isotropic stretching <xref ref-type="bibr" rid="pcbi.1000291-Fyhn1">[32]</xref>)
                        of the SN response, which happens when the cue-card is rotated (or when the
                        enclosure is novel), is predicted to be due to an isotropic rotation (or
                        scaling in the velocity-modulated amplitude) of the head direction inputs to
                        the network, while the network pattern is predicted to remain unrotated
                        (unstretched), <xref ref-type="fig" rid="pcbi-1000291-g007">Figure 7A and
                        7C</xref>. The former part of the prediction, about the rotation of head
                        direction inputs to the grid cell network, is consistent with separately
                        observed responses in head direction cells to cue card rotations <xref ref-type="bibr" rid="pcbi.1000291-Taube1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Taube2">[35]</xref>.</p>
                </sec>
                <sec id="s2f7">
                    <title>Insufficiency of feedforward input and necessity of recurrent processing
                        for spatial periodicity</title>
                    <p>Lidocaine, or another blocker of spiking activity, applied locally to dMEC
                        without affecting inputs to dMEC should abolish periodic spatial
                        responsiveness in the subthreshold activity of grid cells. This is because
                        all periodic patterning in the continuous attractor model arises from
                        recurrent interactions within dMEC. By contrast, individual-neuron models,
                        where the computation is performed within each neuron, may continue to show
                        spatially periodic responses under such a manipulation.</p>
                </sec>
                <sec id="s2f8">
                    <title>Distinguishing between attractor models</title>
                    <p>Given that both periodic and aperiodic continuous attractor network models of
                        dMEC are capable of accurate integration of rat velocity inputs, how might
                        it be possible to experimentally distinguish between the two possibilities?</p>
                    <p>A periodic network shows no pinning, and rotations of the population response
                        are forbidden. Thus, phase relationships between neurons should be
                        absolutely stable over very long times even in the absence of any sensory
                        inputs. By contrast, aperiodic networks should be pinned for sufficiently
                        low velocity inputs, and in the absence of external corrective cues, are
                        expected to rotate on slow timescales (minutes to 10's of minutes).
                        A population-wide rotation will be manifest in altered phase relationships
                        between single neurons, or it could be probed by looking at differential
                        (relative) rotations in the orientation of quickly estimated SN grids versus
                        the head direction cell population.</p>
                    <p>Next, in an aperiodic network, neurons at the boundaries must receive fading
                        input, meaning that their maximal activity is substantially lower than that
                        of neurons in the bulk; thus, the distribution of maximal rates across grid
                        cells of the same type in an aperiodic network should be wide. If the
                        maximal firing rate of every cell (of the same type) in the network is
                        roughly the same, it would be inconsistent with an aperiodic network. The
                        converse need not be true (i.e., a wide distribution of cells does not imply
                        an aperiodic network, or rule out a periodic network).</p>
                    <p>We emphasize that the boundaries of the neural population are not related to
                        physical boundaries in space. Hence the neurons at the boundaries, discussed
                        above, are not expected to bear a relationship to the recently discovered
                        cells in dMEC whose receptive field encodes the rat's proximity to
                        boundaries in the environment <xref ref-type="bibr" rid="pcbi.1000291-Savelli1">[36]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Solstad1">[37]</xref>.</p>
                    <p>Finally, if defects exist in the single neuron response, they may help
                        distinguish between a periodic and an aperiodic network. By defects, here we
                        only mean those arising spontaneously from the pattern formation process in
                        a network whose connectivity is itself defect-free. Defects arising from
                        imperfections in the weights will not flow in response to velocity inputs,
                        and are therefore not expected to produce a systematic defect in the SN
                        response. In the aperiodic case, any defect in the SN response must be
                        eliminated if the rat returns to the area where the defect was observed
                        after first moving in one direction until the defect has flowed off the
                        population pattern. Conversely, if the defect persists upon return to the
                        vicinity of the defect location even after long excursions, the lattice has
                        periodic boundaries. The Presence of a stable defect which is present in
                            <italic>all</italic> SN responses would incidentally be strong evidence
                        of a continuous attractor network.</p>
                    <p>The last two predictions can help to distinguish even a well-tuned aperiodic
                        network, which may show relatively little rotation or pinning, from a
                        periodic network.</p>
                </sec>
            </sec>
        </sec>
        <sec id="s3">
            <title>Discussion</title>
            <p>The three main contributions of this work are:</p>
            <list list-type="order">
                <list-item>
                    <p>A demonstration through modeling that under reasonable conditions grid cells
                        can be good velocity integrators, and more specifically, that continuous
                        attractor models are capable of accurate path integration.</p>
                    <p>By ‘good’ integration, we mean that if the model network
                        is given accurate velocity inputs, it produces an accurate estimate of rat
                        position over comparable distance and time-scales to those probed in
                        behavioral assays. Within a plausible range of estimates for network size
                        and neural stochasticity, higher accuracy was reached in larger and
                        relatively noise-free networks, sufficient to reproduce coherent grid cell
                        patterns in response to the full trajectories from <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>, lasting
                        10–20 minutes. Smaller networks with more stochastic dynamics were
                        capable of good integration over smaller paths, still consistent with
                        behavioral constraints.</p>
                </list-item>
                <list-item>
                    <p>Furnishing good upper bounds on idiothetic path integration accuracy within
                        dMEC.</p>
                    <p>A notable finding is that even noise-free, large networks (periodic and
                        aperiodic) have only finite integration accuracy, and this level of accuracy
                        is only a factor of 10–100 larger than known behavioral abilities.
                        We provide estimates of integration accuracy in the presence of neural
                        noise, which are in the range of 1–10 minutes. Integration
                        performance in a fixed-size periodic network is not expected to vary greatly
                        with parameter tuning; aperiodic networks are more sensitive to parameter
                        tuning, and we have not optimized all parameters. However, aperiodic
                        networks are upper-bounded in their performance by the corresponding
                        periodic network. Thus, we expect our estimates to serve as reasonable upper
                        bounds on integration accuracy in dMEC, within the continuous-attractor
                        picture.</p>
                </list-item>
                <list-item>
                    <p>Providing predictions that can falsify the continuous attractor hypothesis
                        and help distinguish between the possibilities that grid responses are
                        generated through continuous attractor networks or through independent cell
                        computations.</p>
                </list-item>
            </list>
            <p>So far, the predictions of continuous attractor models are consistent with the full
                corpus of grid cell data, and explanatory of many results from experiment,
                suggesting, when combined with conclusion (1), that continuous attractor dynamics
                are a viable, relevant mechanism for grid cell activity and path integration.</p>
            <sec id="s3a">
                <title>Assumptions of the Model</title>
                <p>Accurate behavioral dead reckoning is a cascaded result of accurate velocity
                    input (relative to the rat's motion) and accurate integration of that
                    input. Our interest in this work was in assessing how well continuous attractor
                    models of dMEC can integrate their inputs. Thus, we did not focus on potential
                    inaccuracies (noise or biases) in the velocity inputs themselves. Even if the
                    network were a perfect integrator, errors in the input would produce an
                    incorrect position estimate. Such errors are likely to play a role in reducing
                    the behavioral range over which rats display accurate dead-reckoning.</p>
                <p>A strength of attractor networks is that responses are self-averaging over the
                    full network: if the velocity inputs are unbiased estimators of rat movements,
                    but are noisy, or if the velocity inputs to the network are not perfectly
                    balanced in number for all directions, the full network will average all its
                    inputs, and the net pattern flow will only reflect this average. For accurate
                    position estimation, however, it is important and therefore likely that inputs
                    to the network are well tuned.</p>
                <p>Another factor that could degrade integration performance is inhomogeneity or
                    stochasticity in the recurrent network weights. While stochasticity in neural
                    activity causes the network state to drift along the attractor manifold,
                    variability in network connectivity modifies the structure of the attractor
                    manifold itself. If recurrent connectivity deviates significantly from the
                    translation-invariant form needed to ensure that all translations of the pattern
                    are accessible without crossing over energy barriers, the activity pattern can
                    become pinned at particular phases <xref ref-type="bibr" rid="pcbi.1000291-Ernst1">[38]</xref>, reducing the
                    fidelity of the network response to small velocity inputs.</p>
                <p>Because knowledge about synaptic strengths in the brain is exceedingly limited,
                    it is unclear what level of variability should be expected in dMEC weights, and
                    whether this amount is sufficient to cause significant pinning. A question for
                    theory, not addressed in this work, is to estimate the amount of variability in
                    the network weights that would be sufficient to reduce the accuracy of
                    integration below that observed in dead reckoning behavioral experiments. For
                    experiments, the difficult challenge is to obtain an estimate of variability in
                    dMEC connectivity.</p>
            </sec>
            <sec id="s3b">
                <title>Network Size</title>
                <p>The network size estimate in our continuous attractor model
                        (10<sup>3</sup>–10<sup>4</sup> neurons) may be viewed as a
                    wasteful proposed use of neurons, but it is broadly consistent with estimates
                    for the total number of neurons in the entorhinal cortex <xref ref-type="bibr" rid="pcbi.1000291-Amaral1">[39]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Augustinack1">[41]</xref>. By contrast, independent neuron models <xref ref-type="bibr" rid="pcbi.1000291-Burgess1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Hasselmo1">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Giocomo1">[17]</xref>,
                    which do not require populations of neurons to produce grid cell responses, make
                    far more parsimonious use of neurons. In such models, a natural question is to
                    understand what function may be served by the large number of neurons in dMEC.</p>
                <p>Within dMEC, the breakdown of total neural allocation, between neurons per grid
                    network versus the number of different grid networks, is unknown. dMEC might
                    consist of a very large number of very small networks with different grid
                    periods, which is optimal for representational capacity <xref ref-type="bibr" rid="pcbi.1000291-Fiete1">[42]</xref>. (For a fixed neuron
                    pool size, the addition of neurons per grid at the expense of the total number
                    of different grids causes a large capacity loss <xref ref-type="bibr" rid="pcbi.1000291-Fiete1">[42]</xref>.) But the dynamical
                    considerations presented here suggest otherwise, because accurate path
                    integration in each grid requires many neurons. In contradiction to optimal
                    capacity considerations, therefore, continuous attractor models predict a large
                    membership in each grid network, and correspondingly few different grids.</p>
                <p>A fascinating question is whether the discrete islands of cells observed in
                    anatomical and imaging studies of cells in layer II of the human and primate
                    entorhinal cortex <xref ref-type="bibr" rid="pcbi.1000291-Augustinack1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1000291-Hevner1">[43]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Witter1">[46]</xref>, as
                    well as indications in rodents for modular structure in dMEC <xref ref-type="bibr" rid="pcbi.1000291-Witter1">[46]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Dickson1">[47]</xref> correspond to
                    separate attractor networks, in which case the number of different grid periods
                    can be directly inferred.</p>
            </sec>
            <sec id="s3c">
                <title>Periodic versus Aperiodic Networks</title>
                <p>We have shown that both periodic and aperiodic networks can perform accurate
                    integration. Which topology is dMEC likely to posses? The models and results of
                    this work are largely agnostic on this question. However, the aperiodic network
                    requires fine-tuning of its parameters to perform nearly as well as an untuned
                    periodic network. Even after fine-tuning, integration in the periodic network
                    tends to be better, because unlike in the aperiodic case, the population pattern
                    cannot rotate. Thus, from a functional perspective, periodic boundaries are
                    preferable over aperiodic ones.</p>
                <p>Other constraints on network topology may stem from the developmental mechanism
                    of the grid-cell network. Such developmental constraints could overrule
                    potential functional preferences, in determining network topology.</p>
            </sec>
            <sec id="s3d">
                <title>Network Topography</title>
                <p>If neural locations in the cortical sheet are scrambled, while preserving the
                    neural indices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e040" xlink:type="simple"/></inline-formula> and the pairwise weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e041" xlink:type="simple"/></inline-formula> between neurons, the grid-like patterning in the cortical
                    sheet will disappear, but there will be no change in the single neuron
                    triangular lattice response or in any other dynamical property of the network.
                    The underlying structure of the attractor manifold (e.g., whether or not it is
                    continuous) is a function of network connectivity, but does not depend on the
                    layout of neurons on the cortical sheet. Thus, the lack of topography observed
                    in experiments, in which neighboring neurons have different phases, is not a
                    problem for the dynamics of continuous attractor models of grid cell activity.
                    Instead, the problem is one of learning: how does a network wire up so that the
                    intrinsic structure of the weight matrix resembles center-surround connectivity,
                    but the neurons are themselves not arranged topographically in space?</p>
            </sec>
            <sec id="s3e">
                <title>The Problem of Learning</title>
                <p>A topographic, aperiodic model network would have relatively simple wiring rules
                    (if we ignore the directional neural labels and corresponding segregation of
                    head-direction inputs and shifts in the outgoing weights required for the
                    velocity-coupling mechanism): each neuron would simply have spatially restricted
                    center-surround interactions with its neighbors. This has prompted the
                    observation that such a topographic network could serve as a starting point for
                    the development of a network with a less topographical layout and periodic
                    boundaries <xref ref-type="bibr" rid="pcbi.1000291-McNaughton1">[4]</xref>. For instance, the proposal by <xref ref-type="bibr" rid="pcbi.1000291-McNaughton1">[4]</xref>
                    for wiring an atopographic and periodic network is based on three assumptions:
                    (1) that another area, the ‘teacher’, contains an initial
                    aperiodic, topographic network with population grid patterning and no velocity
                    shift mechanism, (2) that the network pattern, when subject to intrinsic or
                    extrinsic noise, tends to translate without rotation, (3) that the network
                    projects through spatially random connectivity to the naive dMEC, and
                    activity-dependent activity mechanisms within dMEC cause neurons that are
                    coactivated by the teacher network, to wire together. However, results from the
                    present work show that the fundamental features of aperiodic networks pose a
                    problem for such a scheme.</p>
                <p>We showed that the population pattern in a deterministic aperiodic network fully
                    equipped with a translational velocity shift mechanism and driven by purely
                    translational velocity inputs, tends to rotate within a few minutes. This is the
                    short end of the time-scales over which plasticity mechanisms for network
                    development would act. If the network is entirely driven by noise and lacks a
                    specific velocity shift mechanism (as in <xref ref-type="bibr" rid="pcbi.1000291-McNaughton1">[4]</xref>), the problem is
                    far worse: undesirable rotations become as likely as translations, and the
                    pattern orientation can decohere in seconds, invalidating assumption (2). Thus,
                    the precursor network pattern will not be able to entrain a periodic grid in the
                    target network.</p>
                <p>The problem of pattern rotations over the time scale of learning is pertinent for
                    any effort to produce a periodic network from an initially aperiodic one in the
                    absence of anchoring sensory inputs and a velocity coupling mechanism.</p>
            </sec>
            <sec id="s3f">
                <title>The Elusive Hypothesis</title>
                <p>The concept of low-dimensional continuous attractors has influenced our
                    understanding of neural systems and produced successful models of a number of
                    neural integrators <xref ref-type="bibr" rid="pcbi.1000291-Skaggs1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1000291-Zhang1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Goodridge1">[13]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Xie1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Seung2">[48]</xref>,<xref ref-type="bibr" rid="pcbi.1000291-Stringer2">[49]</xref>.
                    Yet proof of continuous attractor dynamics (or some discrete approximation to
                    continuous attractor dynamics) in the brain has remained elusive: experiments in
                    supposed continuous attractor systems have failed to unearth evidence to
                    conclusively validate or falsify the continuous attractor hypothesis. The
                    relative richness (e.g., size, dimensionality of the manifold) of the grid cell
                    response compared to other possible continuous attractor systems may provide a
                    more structured and unambiguous testing ground for predictions stemming from the
                    continuous attractor hypothesis. Testing of these predictions, many based on
                    cell-cell correlations, is feasible with existing experimental technologies, and
                    such tests may help to determine whether a low-dimensional continuous attractor
                    is central to the dynamics of the grid cell system.</p>
            </sec>
        </sec>
        <sec id="s4">
            <title>Methods</title>
            <p>The dynamics of rate-based neurons is specified by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e042" xlink:type="simple"/><label>(1)</label></disp-formula></p>
            <p>The neural transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e043" xlink:type="simple"/></inline-formula> is a simple rectification nonlinearity: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e044" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e045" xlink:type="simple"/></inline-formula>, and is 0 otherwise. The synaptic activation of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e046" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e047" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e048" xlink:type="simple"/></inline-formula> is the synaptic weight from neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e049" xlink:type="simple"/></inline-formula> to neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e050" xlink:type="simple"/></inline-formula>. The time-constant of neural response is
                <italic>τ</italic> = 10 ms. The time-step
                for numerical integration is
                <italic>dt</italic> = 0.5 ms.</p>
            <p>We assume that neurons are arranged in a 2-d sheet. Neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e051" xlink:type="simple"/></inline-formula> is located at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e052" xlink:type="simple"/></inline-formula>. There are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e053" xlink:type="simple"/></inline-formula> neurons in the network, so <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e054" xlink:type="simple"/></inline-formula> ranges from (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e055" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e056" xlink:type="simple"/></inline-formula>) to (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e057" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e058" xlink:type="simple"/></inline-formula>). We use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e059" xlink:type="simple"/></inline-formula> in all figures except where specifically indicated. Each neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e060" xlink:type="simple"/></inline-formula> also has a preferred direction (W, N, S, E) designated by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e061" xlink:type="simple"/></inline-formula>. Locally, each 2×2 block on the sheet contains one
                neuron of each preferred direction, tiled uniformly.</p>
            <p>The preferred directions are restricted to N,S,E,W for convenience in modeling; in
                the rat, these preferences might span the continuum <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e062" xlink:type="simple"/></inline-formula>. The preferred orientation of a neuron is used to (1) determine
                the direction in which its outgoing weighs are shifted, and (2) determine the rat
                velocity inputs it receives.</p>
            <p>The recurrent weight matrix is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e063" xlink:type="simple"/><label>(2)</label></disp-formula>with<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e064" xlink:type="simple"/><label>(3)</label></disp-formula>The weight matrix has a center-surround shape, but is centered at the
                shifted location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e065" xlink:type="simple"/></inline-formula>. Implicit in the form of the weight matrix, where connectivity is
                a function of neural separation, is the assumption that neurons are topographically
                arranged. This is not a necessary requirement (see <xref ref-type="sec" rid="s3">
                    <italic>Discussion</italic>
                </xref>), but does greatly facilitate visualization and presentation. In all
                simulations, we used <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e066" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e067" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e068" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e069" xlink:type="simple"/></inline-formula> is approximately the periodicity of the formed lattice in the
                neural sheet. With <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e070" xlink:type="simple"/></inline-formula>, all connectivity is inhibitory; thus, local surround inhibition
                alone is sufficient to reproduce gird cell responses, but the network could include
                excitatory interactions (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e071" xlink:type="simple"/></inline-formula>) without qualitatively affecting the results.</p>
            <p>The feedforward input to neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e072" xlink:type="simple"/></inline-formula> is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e073" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e074" xlink:type="simple"/></inline-formula> is the unit vector pointing along <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e075" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e076" xlink:type="simple"/></inline-formula> is the velocity vector of the rat, measured in m/s. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e077" xlink:type="simple"/></inline-formula> (Eq. 2) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e078" xlink:type="simple"/></inline-formula> (Eq. 4), the network generates a static triangular lattice
                pattern, <xref ref-type="fig" rid="pcbi-1000291-g001">Figure 1A</xref>, with overall
                intensity modulated by the envelope function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e079" xlink:type="simple"/></inline-formula> (e.g., <xref ref-type="fig" rid="pcbi-1000291-g002">Figures
                2D</xref>, <xref ref-type="fig" rid="pcbi-1000291-g003">3B, and
                3D1–D4</xref>).</p>
            <p>If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e080" xlink:type="simple"/></inline-formula> are non-zero, they allow rat velocity (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e081" xlink:type="simple"/></inline-formula>) to couple to the network dynamics, and drive a flow of the formed
                pattern. The magnitudes of both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e082" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e083" xlink:type="simple"/></inline-formula> multiplicatively determine how strongly velocity inputs drive the
                pattern, and thus control the speed of the flow of the pattern for a fixed rat
                speed. The triangular lattice pattern is only stable for small values of the shift <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e084" xlink:type="simple"/></inline-formula> in the outgoing weights, thus we keep <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e085" xlink:type="simple"/></inline-formula> fixed so that the outgoing weights are shifted 2 neurons. With <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e086" xlink:type="simple"/></inline-formula> fixed, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e087" xlink:type="simple"/></inline-formula> determines the gain of the velocity response of the network. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e088" xlink:type="simple"/></inline-formula>, we can expect the velocity inputs to drive pattern flow without
                destroying the stability of the formed lattice. In the plots shown, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e089" xlink:type="simple"/></inline-formula>. The grid spacing of the SN response is ultimately determined by
                two factors: (i) The grid spacing of the population response, which is set by the
                shape of the symmetric weight matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e090" xlink:type="simple"/></inline-formula>, and (ii) the gain of the network's flow response to a
                velocity input, which depends on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e091" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e092" xlink:type="simple"/></inline-formula>.</p>
            <p>The envelope function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e093" xlink:type="simple"/></inline-formula> spatially modulates the strength of the inputs to the neurons, and
                can scale neural activity without disrupting the lattice pattern. This can be seen
                from Equation 1: if the input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e094" xlink:type="simple"/></inline-formula> is uniform, then scaling <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e095" xlink:type="simple"/></inline-formula> is equivalent to scaling <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e096" xlink:type="simple"/></inline-formula>. It is important to observe that the velocity inputs must also be
                modulated by the envelope <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e097" xlink:type="simple"/></inline-formula>, Eq. 4, to insure the same flow rate in the faded regions as in
                the bulk. This is because the local flow rate is given by the velocity-modulated
                component of the feedforward input divided by the total feedforward input.</p>
            <p>For the network with periodic boundary conditions, the envelope function is 1
                everywhere. For the aperiodic network,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e098" xlink:type="simple"/><label>(5)</label></disp-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e099" xlink:type="simple"/></inline-formula> is the diameter of the network and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e100" xlink:type="simple"/></inline-formula> (for example, see <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D</xref> and <xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3B,
                    D1–D4</xref>). In <xref ref-type="fig" rid="pcbi-1000291-g003">Figure
                    3 (D4)</xref>, R = 128; in all other figures,
                R = 64. The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e101" xlink:type="simple"/></inline-formula> determines the range of radii over which input tapering occurs:
                The larger <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e102" xlink:type="simple"/></inline-formula>, the more gradual the tapering. In all the aperiodic simulations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e103" xlink:type="simple"/></inline-formula>, except for <xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3
                    (A–C and D2, D4)</xref>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e104" xlink:type="simple"/></inline-formula> and <xref ref-type="fig" rid="pcbi-1000291-g003">Figure 3
                (D3)</xref>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e105" xlink:type="simple"/></inline-formula>.</p>
            <sec id="s4a">
                <title>Spiking Simulations</title>
                <p>To simulate a Poisson process (CV = 1, where CV
                    is the ratio of the inter-spike interval standard deviation with the mean), in
                    each time-step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e106" xlink:type="simple"/></inline-formula> neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e107" xlink:type="simple"/></inline-formula> spikes with probability given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e108" xlink:type="simple"/></inline-formula> (in our simulations, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e109" xlink:type="simple"/></inline-formula> is always much less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e110" xlink:type="simple"/></inline-formula>, ensuring that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e111" xlink:type="simple"/></inline-formula>). The synaptic activation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e112" xlink:type="simple"/></inline-formula> is computed from neural spiking: it increments by 1 at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e113" xlink:type="simple"/></inline-formula> if neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e114" xlink:type="simple"/></inline-formula> spiked at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e115" xlink:type="simple"/></inline-formula>, and otherwise decays according to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e116" xlink:type="simple"/><label>(6)</label></disp-formula>The process for generating spike trains with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e117" xlink:type="simple"/></inline-formula> (for integer-valued <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e118" xlink:type="simple"/></inline-formula>) is similar to that for generating a Poisson train. We first
                    subdivide each interval into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e119" xlink:type="simple"/></inline-formula> sub-intervals of length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e120" xlink:type="simple"/></inline-formula> each, and simulate on this finer time resolution a fast
                    Poisson spiking process with rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e121" xlink:type="simple"/></inline-formula>. We then decimate the fast Poisson process, retaining every
                        <italic>m</italic>-th spike and discarding all the other spikes. This
                    procedure generates a spike train with rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e122" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e123" xlink:type="simple"/></inline-formula>.</p>
            </sec>
            <sec id="s4b">
                <title>Initial Conditions</title>
                <p>Aperiodic network: initially network activity is low; neurons receive external
                    input with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e124" xlink:type="simple"/></inline-formula> in addition to a small independent random drive, which leads
                    to spontaneous pattern formation. Periodic network: we initialize an aperiodic
                    network with otherwise identical parameters, and after pattern formation apply
                    periodic boundary conditions. The parameters for the aperiodic network have to
                    be chosen to be commensurate with the size of the network to avoid excess strain
                    and the formation of defects when the boundaries are made periodic. We flow both
                    the periodic and aperiodic network states with unidirectional velocity inputs,
                    corresponding to a velocity of 0.8 m/s, in three different directions (0,<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e125" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e126" xlink:type="simple"/></inline-formula>) for 250 ms each to heal any strain and defects in the formed
                    pattern. After this healing period, we give as input to the network either real
                    rat velocity (data obtained by differentiating recorded rat trajectories
                    – published in <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref> – then linearly interpolating
                    between the recording time-steps and the time-step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e127" xlink:type="simple"/></inline-formula> in our simulations), or a sequence of velocity steps
                    (described next).</p>
            </sec>
            <sec id="s4c">
                <title>Velocity Response Curves</title>
                <p>The network is initialized to the exact same initial template state at the
                    beginning of each step (using a template pattern stored following one run of the
                    initialization process described above). Each step consists of a constant
                    velocity input, with one of four directions (0, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e128" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e129" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e130" xlink:type="simple"/></inline-formula>). The velocity is incremented in steps of 0.02 m/s. We use
                    only the second half of the 5 s long steps to compute the network's
                    velocity response.</p>
            </sec>
            <sec id="s4d">
                <title>Tracking Lattice Orientation and Flow</title>
                <p>We track how far the pattern has flowed beyond a lattice period and beyond the
                    scale of the network by continuously recording the velocity of the blob closest
                    to the center, and integrating the obtained velocity. We track the orientation
                    of the lattice by computing its Fourier transform and recording the angles of
                    the three blobs closest to the origin in Fourier space.</p>
                <p>To assign units of centimeters to the accumulated network pattern flow and
                    compare it to rat position (<xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                        2C, 2F</xref>, <xref ref-type="fig" rid="pcbi-1000291-g003">3C</xref>, <xref ref-type="supplementary-material" rid="pcbi.1000291.s001">Figure S1</xref>,
                    and <xref ref-type="supplementary-material" rid="pcbi.1000291.s003">Figure
                    S3</xref>), we must obtain the scale factor relating the network pattern flow
                    velocity to the velocity of the rat. The scale is determined by optimizing the
                    match between network flow velocity and the derivative of the rat position
                    throughout the simulation. The offset is set so that the network drift at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000291.e131" xlink:type="simple"/></inline-formula> is zero.</p>
            </sec>
        </sec>
        <sec id="s5">
            <title>Supporting Information</title>
            <supplementary-material id="pcbi.1000291.s001" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.s001" xlink:type="simple">
                <label>Figure S1</label>
                <caption>
                    <p>Path integration and generation of grid cells in a small periodic network.
                        Simulation of network response, with velocity inputs corresponding to a
                        rat's recorded trajectory in a 2 m circular enclosure <xref ref-type="bibr" rid="pcbi.1000291-Hafting2">[50]</xref>. The boundary conditions in the neural sheet
                        are periodic as in <xref ref-type="fig" rid="pcbi-1000291-g002">Figure
                            2A–C</xref>, but the network size is smaller (40<sup>2</sup>
                        network). (A) Instantaneous activity within the neural sheet (color
                        represents the firing rate: black corresponds to vanishing rate). (B) Grid
                        cell response: average firing rate of a single neuron (located at the
                        electrode tip in panel A), as a function of the rat's position
                        within the enclosure. (C) Velocity integration in the network. Top: Actual
                        distance of the rat from a fixed reference point (black), compared to the
                        network's integrated position estimate, obtained by tracking the
                        flow of the pattern in the population response (blue). The reference point
                        is at the left-bottom corner of the square in which the circular enclosure
                        is inscribed. Bottom: Accumulated difference between the integrated position
                        estimate and the actual position.</p>
                    <p>(0.73 MB EPS)</p>
                </caption>
            </supplementary-material>
            <supplementary-material id="pcbi.1000291.s002" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.s002" xlink:type="simple">
                <label>Figure S2</label>
                <caption>
                    <p>Population pattern in an aperiodic network with a modulation of weights. The
                        steady-state pattern in a network where the strengths of the outgoing
                        weights from each neuron are modulated based on the neuron's
                        location in the sheet, according to the envelope function of Equation 5. The
                        external input is spatially uniform. All parameters are identical to the
                        simulation of <xref ref-type="fig" rid="pcbi-1000291-g002">Figure 2D</xref>,
                        except that the modulation envelope is applied to the weights instead of to
                        the inputs. The formed pattern is distorted at the edges, with neurons along
                        the edge tending to be uniformly active.</p>
                    <p>(1.00 MB EPS)</p>
                </caption>
            </supplementary-material>
            <supplementary-material id="pcbi.1000291.s003" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.s003" xlink:type="simple">
                <label>Figure S3</label>
                <caption>
                    <p>Path integration in periodic and aperiodic stochastic spiking networks.
                        Simulation of network response, with velocity inputs corresponding to a
                        rat's recorded trajectory in a 2 m circular enclosure <xref ref-type="bibr" rid="pcbi.1000291-Hafting2">[50]</xref>, in stochastic spiking networks. Results are
                        shown for a periodic network with CV = 1
                        (orange), and for aperiodic networks, where successively darker shades of
                        blue represent simulations with successively higher neural CV
                        (CV = 1/√8, 1/√4, and
                        1, respectively). All other parameters are as in <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5</xref>. Colors represent the same
                        network parameters as in <xref ref-type="fig" rid="pcbi-1000291-g006">Figure
                            6</xref>, which describes drift in the absence of velocity inputs. (A)
                        Accumulated difference between the integrated position estimate and the
                        rat's actual position. (B) Orientation of the network pattern as a
                        function of time. (C) Responses of a single neuron over a rat's
                        recorded trajectory, over 10 minutes. Each red dot represents a spike. Color
                        of bars represent the same simulation parameters as in (A) and (B).
                        Top-left, Aperiodic network with CV = 1,
                        Bottom-left, CV = 1/√4,
                        Top-right, CV = 1/√8 (reproduced
                        from <xref ref-type="fig" rid="pcbi-1000291-g005">Figure 5</xref>), Bottom
                        right, aperiodic network with CV = 1
                        (reproduced from <xref ref-type="fig" rid="pcbi-1000291-g005">Figure
                        5</xref>).</p>
                    <p>(3.43 MB EPS)</p>
                </caption>
            </supplementary-material>
            <supplementary-material id="pcbi.1000291.s004" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.s004" xlink:type="simple">
                <label>Figure S4</label>
                <caption>
                    <p>Stochasticity of recorded dMEC neurons. (A) Standard deviation (σ) of
                        the inter-spike interval (ISI) distribution plotted against the mean ISI,
                        for various values of the mean ISI. Data points from multiple simultaneously
                        recorded cells (from a single electrode) in dMEC <xref ref-type="bibr" rid="pcbi.1000291-Hafting2">[50]</xref> are pooled to
                        produce this plot. Black circles, method (1). Blue squares, method (2) (see
                        below). The red dashed line corresponds to statistics that would be obtained
                        from a homogeneous Poisson process at each mean ISI value. (B) The
                        coefficient of variation
                        (CV = σ(ISI)/μ(ISI))
                        plotted as a function of spiking frequency. The red dashed line corresponds
                        to the CV of a Poisson process. Estimation of CV in neural data. The CV is a
                        normalized measure of the variation in the inter-spike intervals in a spike
                        train firing at a constant rate. To estimate the CV, we thus have to
                        identify intervals of relatively constant firing rate. This is made
                        complicated by the fact that in the stimulus and behavioral conditions
                        prevailing during the recordings (the rat is randomly running around the
                        enclosure foraging for randomly scattered food while landmarks move into or
                        out of view), there are no designated regions of stimulus or response
                        constancy. We used two methods to identify regions of constant mean firing
                        rate: (1) Identify blocks of low-velocity intervals where
                            |<bold>v</bold>|&lt;<italic>v</italic><sub>cutoff</sub> = 8
                        cm/s, which are of duration larger than
                        <italic>T</italic><sub>v</sub> = 4 s. We
                        found no blocks where the integrated displacement was more than λ/4
                        cm, meaning that the intervals represented traverses of approximately one
                        blob diameter or less, with the typical distance being much shorter. Thus,
                        the rat is likely to be either on or off a blob for the entire duration of a
                        block, and should have a roughly constant underlying firing rate. (2)
                        Identify high-rate blocks where the rate is higher than some upper cutoff
                        threshold (to locate on-blob episodes), with
                            <italic>r</italic><sub>ISI</sub>(<italic>t</italic>)&gt;<italic>r</italic><sub>high</sub>
                        for each time in the block. Only those high-rate blocks of duration longer
                        than <italic>T</italic><sub>r</sub> were retained.
                            <italic>r</italic><sub>ISI</sub> is the instantaneous firing rate,
                        computed as the reciprocal of the inter-spike interval of adjacent spikes.
                            <italic>r</italic><sub>high</sub> = 10
                        Hz was chosen to be large enough to exclude all intervals except those where
                        the rat is clearly on a blob for the recorded cell. In all the above, the
                        minimum interval duration
                        <italic>T</italic><sub>r</sub> = 5 s was
                        chosen to eliminate random (non)spike events that momentarily change the
                        rate without reflecting an actual change in the underlying firing rate of
                        the cell, while capturing as many intervals as possible for ISI analysis. In
                        each of methods (1) or (2), we compute μ(ISI) and σ(ISI) for
                        each block as a single data-point. Next, we bin together data points with
                        the same rate (in bins of 1 Hz), pooling across all cells (this is
                        reasonable because each cell individually has very similar statistics as the
                        collection). The two methods (1) and (2) are complementary in the sense that
                        interval sampling is based in the first case on rat velocity, and in the
                        second case by rate-based on-blob or off-blob considerations. Neither method
                        guarantees that the underlying firing rate within one interval is constant.
                        However, the two methods yield consistent results, and thus add a measure of
                        confidence to the analysis.</p>
                    <p>(0.68 MB EPS)</p>
                </caption>
            </supplementary-material>
            <supplementary-material id="pcbi.1000291.s005" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000291.s005" xlink:type="simple">
                <label>Figure S5</label>
                <caption>
                    <p>Deviations from a perfect triangular lattice in existing measurements. (A)
                        Comparison of grid correlation functions from three simultaneously recorded
                        cells, adapted from <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref>. The black lines were passed between pairs
                        of peaks in the correlation function. Each pair consists of two opposing
                        peaks, from the six closest peaks to the origin. Measured angles between the
                        lattice vectors, shown in the plot and in the bar plot (B), show a
                        consistent bias from 60° in the three cells. We estimate the
                        measurement error at about ±2°. The measured lengths of
                        the black segments, in arbitrary pixel units, are: 28.8, 27.2, 25.1 (I);
                        28.8, 27.5, 25.9 (II); 29.2, 28.7, 26.1 (III), with an estimated measurement
                        error of ±1. This example is limited by the low resolution images
                        adapted from <xref ref-type="bibr" rid="pcbi.1000291-Hafting1">[1]</xref> and is meant primarily as a demonstration
                        of possible deviations from a perfect triangular lattice, and how they can
                        be measured. We believe that the question of whether such deviations occur
                        consistently in cells sharing the same grid period calls for a more
                        systematic study.</p>
                    <p>(0.59 MB EPS)</p>
                </caption>
            </supplementary-material>
        </sec>
    </body>
    <back>
        <ack>
            <p>We are grateful to Mehran Kardar and Michael Cross for helpful conversations.</p>
        </ack>
        <ref-list>
            <title>References</title>
            <ref id="pcbi.1000291-Hafting1">
                <label>1</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Hafting</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Fyhn</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Molden</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>MB</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>E</given-names>
                        </name>
                    </person-group>
                    <year>2005</year>
                    <article-title>Microstructure of a spatial map in the entorhinal cortex.</article-title>
                    <source>Nature</source>
                    <volume>436</volume>
                    <fpage>801</fpage>
                    <lpage>806</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Fuhs1">
                <label>2</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Fuhs</surname>
                            <given-names>MC</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Touretzky</surname>
                            <given-names>DS</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>A spin glass model of path integration in rat medial entorhinal
                        cortex.</article-title>
                    <source>J Neurosci</source>
                    <volume>26</volume>
                    <fpage>4266</fpage>
                    <lpage>4276</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Burak1">
                <label>3</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Burak</surname>
                            <given-names>Y</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Fiete</surname>
                            <given-names>I</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>Do we understand the emergent dynamics of grid cell activity?</article-title>
                    <source>J Neurosci</source>
                    <volume>26</volume>
                    <fpage>9352</fpage>
                    <lpage>9354</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-McNaughton1">
                <label>4</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>McNaughton</surname>
                            <given-names>BL</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Battaglia</surname>
                            <given-names>FP</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jensen</surname>
                            <given-names>O</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>EI</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>MB</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>Path integration and the neural basis of the ‘cognitive
                        map’.</article-title>
                    <source>Nat Rev Neurosci</source>
                    <volume>7</volume>
                    <fpage>663</fpage>
                    <lpage>678</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Burgess1">
                <label>5</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Burgess</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Barry</surname>
                            <given-names>C</given-names>
                        </name>
                        <name name-style="western">
                            <surname>O'Keefe</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>An oscillatory interference model of grid cell firing.</article-title>
                    <source>Hippocampus</source>
                    <volume>17</volume>
                    <fpage>801</fpage>
                    <lpage>812</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Hasselmo1">
                <label>6</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Hasselmo</surname>
                            <given-names>ME</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Giocomo</surname>
                            <given-names>LM</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Zilli</surname>
                            <given-names>EA</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>Grid cell firing may arise from interference of theta frequency
                        membrane potential oscillations in single neurons.</article-title>
                    <source>Hippocampus</source>
                    <volume>17</volume>
                    <fpage>1252</fpage>
                    <lpage>1271</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Guanella1">
                <label>7</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Guanella</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Kiper</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Verschure</surname>
                            <given-names>P</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>A model of grid cells based on a twisted torus topology.</article-title>
                    <source>Int J Neural Syst</source>
                    <volume>17</volume>
                    <fpage>231</fpage>
                    <lpage>240</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Skaggs1">
                <label>8</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Skaggs</surname>
                            <given-names>WE</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Knierim</surname>
                            <given-names>JJ</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Kudrimoti</surname>
                            <given-names>HS</given-names>
                        </name>
                        <name name-style="western">
                            <surname>McNaughton</surname>
                            <given-names>BL</given-names>
                        </name>
                    </person-group>
                    <year>1995</year>
                    <article-title>A model of the neural basis of the rat's sense of
                        direction.</article-title>
                    <source>Adv Neural Inf Process Syst</source>
                    <volume>7</volume>
                    <fpage>173</fpage>
                    <lpage>180</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Seung1">
                <label>9</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Seung</surname>
                            <given-names>HS</given-names>
                        </name>
                    </person-group>
                    <year>1996</year>
                    <article-title>How the brain keeps the eyes still.</article-title>
                    <source>Proc Natl Acad Sci U S A</source>
                    <volume>93</volume>
                    <fpage>13339</fpage>
                    <lpage>13344</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Zhang1">
                <label>10</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Zhang</surname>
                            <given-names>K</given-names>
                        </name>
                    </person-group>
                    <year>1996</year>
                    <article-title>Representation of spatial orientation by the intrinsic dynamics
                        of the head-direction cell ensemble: a theory.</article-title>
                    <source>J Neurosci</source>
                    <volume>16</volume>
                    <fpage>2112</fpage>
                    <lpage>2126</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Samsonovich1">
                <label>11</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Samsonovich</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>McNaughton</surname>
                            <given-names>BL</given-names>
                        </name>
                    </person-group>
                    <year>1997</year>
                    <article-title>Path integration and cognitive mapping in a continuous attractor
                        neural network model.</article-title>
                    <source>J Neurosci</source>
                    <volume>17</volume>
                    <fpage>5900</fpage>
                    <lpage>5920</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Tsodyks1">
                <label>12</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Tsodyks</surname>
                            <given-names>M</given-names>
                        </name>
                    </person-group>
                    <year>1999</year>
                    <article-title>Attractor neural network models of spatial maps in hippocampus.</article-title>
                    <source>Hippocampus</source>
                    <volume>9</volume>
                    <fpage>481</fpage>
                    <lpage>489</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Goodridge1">
                <label>13</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Goodridge</surname>
                            <given-names>JP</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Touretzky</surname>
                            <given-names>DS</given-names>
                        </name>
                    </person-group>
                    <year>2000</year>
                    <article-title>Modeling attractor deformation in the rodent head-direction
                        system.</article-title>
                    <source>J Neurophysiol</source>
                    <volume>83</volume>
                    <fpage>3402</fpage>
                    <lpage>3410</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Xie1">
                <label>14</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Xie</surname>
                            <given-names>X</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hahnloser</surname>
                            <given-names>RHR</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Seung</surname>
                            <given-names>HS</given-names>
                        </name>
                    </person-group>
                    <year>2002</year>
                    <article-title>Double-ring network model of the head-direction system.</article-title>
                    <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>
                    <volume>66</volume>
                    <fpage>041902</fpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Stringer1">
                <label>15</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Stringer</surname>
                            <given-names>SM</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Rolls</surname>
                            <given-names>ET</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Trappenberg</surname>
                            <given-names>TP</given-names>
                        </name>
                    </person-group>
                    <year>2004</year>
                    <article-title>Self-organising continuous attractor networks with multiple
                        activity packets, and the representation of space.</article-title>
                    <source>Neural Netw</source>
                    <volume>17</volume>
                    <fpage>5</fpage>
                    <lpage>27</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-OKeefe1">
                <label>16</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>O'Keefe</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Burgess</surname>
                            <given-names>N</given-names>
                        </name>
                    </person-group>
                    <year>2005</year>
                    <article-title>Dual phase and rate coding in hippocampal place cells:
                        theoretical significance and relationship to entorhinal grid cells.</article-title>
                    <source>Hippocampus</source>
                    <volume>15</volume>
                    <fpage>853</fpage>
                    <lpage>866</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Giocomo1">
                <label>17</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Giocomo</surname>
                            <given-names>LM</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Zilli</surname>
                            <given-names>EA</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Fransen</surname>
                            <given-names>E</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hasselmo</surname>
                            <given-names>ME</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>Temporal frequency of subthreshold oscillations scales with
                        entorhinal grid cell field spacing.</article-title>
                    <source>Science</source>
                    <volume>315</volume>
                    <fpage>1719</fpage>
                    <lpage>1722</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Mittelstaedt1">
                <label>18</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Mittelstaedt</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Mittelstaedt</surname>
                            <given-names>H</given-names>
                        </name>
                    </person-group>
                    <year>1980</year>
                    <article-title>Homing by path integration in a mammal.</article-title>
                    <source>Naturwissenschaften</source>
                    <volume>67</volume>
                    <fpage>566</fpage>
                    <lpage>567</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Maaswinkel1">
                <label>19</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Maaswinkel</surname>
                            <given-names>H</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jarrard</surname>
                            <given-names>LE</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Whishaw</surname>
                            <given-names>IQ</given-names>
                        </name>
                    </person-group>
                    <year>1999</year>
                    <article-title>Hippocampectomized rats are impaired in homing by path
                        integration.</article-title>
                    <source>Hippocampus</source>
                    <volume>9</volume>
                    <fpage>553</fpage>
                    <lpage>561</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Sharp1">
                <label>20</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Sharp</surname>
                            <given-names>PE</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Tinkelman</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Cho</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>2001</year>
                    <article-title>Angular velocity and head direction signals recorded from the
                        dorsal tegmental nucleus of gudden in the rat: implications for path
                        integration in the head direction cell circuit.</article-title>
                    <source>Behav Neurosci</source>
                    <volume>115</volume>
                    <fpage>571</fpage>
                    <lpage>588</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Etienne1">
                <label>21</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Etienne</surname>
                            <given-names>AS</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jeffery</surname>
                            <given-names>KJ</given-names>
                        </name>
                    </person-group>
                    <year>2004</year>
                    <article-title>Path integration in mammals.</article-title>
                    <source>Hippocampus</source>
                    <volume>14</volume>
                    <fpage>180</fpage>
                    <lpage>192</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Alonso1">
                <label>22</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Alonso</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Llinas</surname>
                            <given-names>RR</given-names>
                        </name>
                    </person-group>
                    <year>1989</year>
                    <article-title>Subthreshold Na<sup>+</sup>-dependent theta-like
                        rhythmicity in stellate cells of entorhinal cortex layer II.</article-title>
                    <source>Nature</source>
                    <volume>342</volume>
                    <fpage>175</fpage>
                    <lpage>177</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Alonso2">
                <label>23</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Alonso</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Klink</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1993</year>
                    <article-title>Differential electroresponsiveness of stellate and pyramidal-like
                        cells of medial entorhinal cortex layer II.</article-title>
                    <source>J Neurophysiol</source>
                    <volume>70</volume>
                    <fpage>128</fpage>
                    <lpage>143</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Mitchell1">
                <label>24</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Mitchell</surname>
                            <given-names>SJ</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ranck</surname>
                            <given-names>JBJ</given-names>
                        </name>
                    </person-group>
                    <year>1980</year>
                    <article-title>Generation of theta rhythm in medial entorhinal cortex of freely
                        moving rats.</article-title>
                    <source>Brain Res</source>
                    <volume>189</volume>
                    <fpage>49</fpage>
                    <lpage>66</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Alonso3">
                <label>25</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Alonso</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Garcia-Austt</surname>
                            <given-names>E</given-names>
                        </name>
                    </person-group>
                    <year>1987</year>
                    <article-title>Neuronal sources of theta rhythm in the entorhinal cortex of the
                        rat. ii. phase relations between unit discharges and theta field potentials.</article-title>
                    <source>Exp Brain Res</source>
                    <volume>67</volume>
                    <fpage>502</fpage>
                    <lpage>509</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Murray1">
                <label>26</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Murray</surname>
                            <given-names>JD</given-names>
                        </name>
                    </person-group>
                    <year>2003</year>
                    <source>Mathematical Biology</source>
                    <publisher-loc>Berlin</publisher-loc>
                    <publisher-name>Springer</publisher-name>
                    <comment> Chapter 16</comment>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Cohen1">
                <label>27</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Cohen</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Grossberg</surname>
                            <given-names>S</given-names>
                        </name>
                    </person-group>
                    <year>1983</year>
                    <article-title>Absolute stability of global pattern-formation and parallel
                        memory storage by competitive neural networks.</article-title>
                    <source>IEEE Trans Syst Man Cybern</source>
                    <volume>13</volume>
                    <fpage>815</fpage>
                    <lpage>826</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Hopfield1">
                <label>28</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Hopfield</surname>
                            <given-names>JJ</given-names>
                        </name>
                    </person-group>
                    <year>1984</year>
                    <article-title>Neurons with graded response have collective computational
                        properties like those of two-state neurons.</article-title>
                    <source>Proc Natl Acad Sci USA</source>
                    <volume>81</volume>
                    <fpage>3088</fpage>
                    <lpage>3092</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Softky1">
                <label>29</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Softky</surname>
                            <given-names>WR</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Koch</surname>
                            <given-names>C</given-names>
                        </name>
                    </person-group>
                    <year>1993</year>
                    <article-title>The highly irregular firing of cortical cells is inconsistent
                        with temporal integration of random EPSPs.</article-title>
                    <source>J Neurosci</source>
                    <volume>13</volume>
                    <fpage>334</fpage>
                    <lpage>350</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Shadlen1">
                <label>30</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Shadlen</surname>
                            <given-names>MN</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Newsome</surname>
                            <given-names>WT</given-names>
                        </name>
                    </person-group>
                    <year>1994</year>
                    <article-title>Noise, neural codes and cortical organization.</article-title>
                    <source>Curr Opin Neurobiol</source>
                    <volume>4</volume>
                    <fpage>569</fpage>
                    <lpage>579</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Barry1">
                <label>31</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Barry</surname>
                            <given-names>C</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hayman</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Burgess</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jeffery</surname>
                            <given-names>KJ</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>Experience-dependent rescaling of entorhinal grids.</article-title>
                    <source>Nat Neurosci</source>
                    <volume>10</volume>
                    <fpage>682</fpage>
                    <lpage>684</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Fyhn1">
                <label>32</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Fyhn</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hafting</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Treves</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>MB</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>EI</given-names>
                        </name>
                    </person-group>
                    <year>2007</year>
                    <article-title>Hippocampal remapping and grid realignment in entorhinal cortex.</article-title>
                    <source>Nature</source>
                    <volume>446</volume>
                    <fpage>190</fpage>
                    <lpage>194</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Sargolini1">
                <label>33</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Sargolini</surname>
                            <given-names>F</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Fyhn</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hafting</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>McNaughton</surname>
                            <given-names>BL</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Witter</surname>
                            <given-names>MP</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2006</year>
                    <article-title>Conjunctive representation of position, direction, and velocity
                        in entorhinal cortex.</article-title>
                    <source>Science</source>
                    <volume>312</volume>
                    <fpage>758</fpage>
                    <lpage>762</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Taube1">
                <label>34</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Taube</surname>
                            <given-names>JS</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Muller</surname>
                            <given-names>RU</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ranck</surname>
                            <given-names>JB</given-names>
                            <suffix>Jr</suffix>
                        </name>
                    </person-group>
                    <year>1990</year>
                    <article-title>Head-direction cells recorded from the postsubiculum in freely
                        moving rats. I. Description and quantitative analysis.</article-title>
                    <source>J Neurosci</source>
                    <volume>10</volume>
                    <fpage>420</fpage>
                    <lpage>435</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Taube2">
                <label>35</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Taube</surname>
                            <given-names>JS</given-names>
                        </name>
                    </person-group>
                    <year>1995</year>
                    <article-title>Head direction cells recorded in the anterior thalamic nuclei of
                        freely moving rats.</article-title>
                    <source>J Neurosci</source>
                    <volume>15</volume>
                    <fpage>70</fpage>
                    <lpage>86</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Savelli1">
                <label>36</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Savelli</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Yoganarasimha</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Knierim</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>Influence of boundary removal on the spatial representations of
                        the medial entorhinal cortex.</article-title>
                    <source>Hippocampus</source>
                    <volume>18</volume>
                    <fpage>1270</fpage>
                    <lpage>1282</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Solstad1">
                <label>37</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Solstad</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Boccara</surname>
                            <given-names>CN</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Kropff</surname>
                            <given-names>E</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>MB</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>EI</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>Representation of geometric borders in the entorhinal cortex.</article-title>
                    <source>Science</source>
                    <volume>322</volume>
                    <fpage>1865</fpage>
                    <lpage>1868</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Ernst1">
                <label>38</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Ernst</surname>
                            <given-names>UA</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Pawelzik</surname>
                            <given-names>KR</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Sahar-Pikielny</surname>
                            <given-names>C</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Tsodyks</surname>
                            <given-names>MV</given-names>
                        </name>
                    </person-group>
                    <year>2001</year>
                    <article-title>Intracortical origin of visual maps.</article-title>
                    <source>Nat Neurosci</source>
                    <volume>4</volume>
                    <fpage>431</fpage>
                    <lpage>436</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Amaral1">
                <label>39</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Amaral</surname>
                            <given-names>DG</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ishizuka</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Claiborne</surname>
                            <given-names>B</given-names>
                        </name>
                    </person-group>
                    <year>1990</year>
                    <article-title>Neurons, numbers and the hippocampal network.</article-title>
                    <source>Prog Brain Res</source>
                    <volume>83</volume>
                    <fpage>1</fpage>
                    <lpage>11</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Mulders1">
                <label>40</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Mulders</surname>
                            <given-names>WH</given-names>
                        </name>
                        <name name-style="western">
                            <surname>West</surname>
                            <given-names>MJ</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Slomianka</surname>
                            <given-names>L</given-names>
                        </name>
                    </person-group>
                    <year>1997</year>
                    <article-title>Neuron numbers in the presubiculum, parasubiculum, and entorhinal
                        area of the rat.</article-title>
                    <source>J Comp Neurol</source>
                    <volume>385</volume>
                    <fpage>83</fpage>
                    <lpage>94</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Augustinack1">
                <label>41</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Augustinack</surname>
                            <given-names>JC</given-names>
                        </name>
                        <name name-style="western">
                            <surname>van der Kouwe</surname>
                            <given-names>AJW</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Blackwell</surname>
                            <given-names>ML</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Salat</surname>
                            <given-names>DH</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Wiggins</surname>
                            <given-names>CJ</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2005</year>
                    <article-title>Detection of entorhinal layer II using 7 tesla magnetic resonance
                        imaging.</article-title>
                    <source>Ann Neurol</source>
                    <volume>57</volume>
                    <fpage>489</fpage>
                    <lpage>494</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Fiete1">
                <label>42</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Fiete</surname>
                            <given-names>IR</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Burak</surname>
                            <given-names>Y</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Brookings</surname>
                            <given-names>T</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>What grid cells convey about rat location.</article-title>
                    <source>J Neurosci</source>
                    <volume>28</volume>
                    <fpage>6856</fpage>
                    <lpage>6871</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Hevner1">
                <label>43</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Hevner</surname>
                            <given-names>RF</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Wong-Riley</surname>
                            <given-names>MT</given-names>
                        </name>
                    </person-group>
                    <year>1992</year>
                    <article-title>Entorhinal cortex of the human, monkey, and rat: metabolic map as
                        revealed by cytochrome oxidase.</article-title>
                    <source>J Comp Neurol</source>
                    <volume>326</volume>
                    <fpage>451</fpage>
                    <lpage>469</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Goldenberg1">
                <label>44</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Goldenberg</surname>
                            <given-names>TM</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Bakay</surname>
                            <given-names>RA</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ribak</surname>
                            <given-names>CE</given-names>
                        </name>
                    </person-group>
                    <year>1995</year>
                    <article-title>Electron microscopy of cell islands in layer ii of the primate
                        entorhinal cortex.</article-title>
                    <source>J Comp Neurol</source>
                    <volume>355</volume>
                    <fpage>51</fpage>
                    <lpage>66</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Solodkin1">
                <label>45</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Solodkin</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Van Hoesen</surname>
                            <given-names>GW</given-names>
                        </name>
                    </person-group>
                    <year>1996</year>
                    <article-title>Entorhinal cortex modules of the human brain.</article-title>
                    <source>J Comp Neurol</source>
                    <volume>365</volume>
                    <fpage>610</fpage>
                    <lpage>617</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Witter1">
                <label>46</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Witter</surname>
                            <given-names>MP</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>EI</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>Spatial representation and the architecture of the entorhinal
                        cortex.</article-title>
                    <source>Trends Neurosci</source>
                    <volume>29</volume>
                    <fpage>671</fpage>
                    <lpage>678</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Dickson1">
                <label>47</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Dickson</surname>
                            <given-names>CT</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Biella</surname>
                            <given-names>G</given-names>
                        </name>
                        <name name-style="western">
                            <surname>de Curtis</surname>
                            <given-names>M</given-names>
                        </name>
                    </person-group>
                    <year>2000</year>
                    <article-title>Evidence for spatial modules mediated by temporal synchronization
                        of carbachol-induced gamma rhythm in medial entorhinal cortex.</article-title>
                    <source>J Neurosci</source>
                    <volume>20</volume>
                    <fpage>7846</fpage>
                    <lpage>7854</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Seung2">
                <label>48</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Seung</surname>
                            <given-names>HS</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Lee</surname>
                            <given-names>DD</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Reis</surname>
                            <given-names>BY</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Tank</surname>
                            <given-names>DW</given-names>
                        </name>
                    </person-group>
                    <year>2000</year>
                    <article-title>Stability of the memory of eye position in a recurrent network of
                        conductance-based model neurons.</article-title>
                    <source>Neuron</source>
                    <volume>26</volume>
                    <fpage>259</fpage>
                    <lpage>271</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Stringer2">
                <label>49</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Stringer</surname>
                            <given-names>SM</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Rolls</surname>
                            <given-names>ET</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Trappenberg</surname>
                            <given-names>TP</given-names>
                        </name>
                        <name name-style="western">
                            <surname>de Araujo</surname>
                            <given-names>IET</given-names>
                        </name>
                    </person-group>
                    <year>2003</year>
                    <article-title>Self-organizing continuous attractor networks and motor function.</article-title>
                    <source>Neural Netw</source>
                    <volume>16</volume>
                    <fpage>161</fpage>
                    <lpage>182</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000291-Hafting2">
                <label>50</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Hafting</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Fyhn</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Molden</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>MB</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Moser</surname>
                            <given-names>E</given-names>
                        </name>
                    </person-group>
                    <comment><ext-link ext-link-type="uri" xlink:href="http://www.ntnu.no/cbm/moser/gridcell" xlink:type="simple">http://www.ntnu.no/cbm/moser/gridcell</ext-link> (Published 2006;
                        Accessed May 2008)</comment>
                </element-citation>
            </ref>
        </ref-list>
        
    </back>
</article>