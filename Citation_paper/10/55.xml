<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02142</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004442</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Bayesian Attractor Model for Perceptual Decision Making</article-title>
<alt-title alt-title-type="running-head">A Bayesian Attractor Model for Perceptual Decision Making</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Bitzer</surname> <given-names>Sebastian</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bruineberg</surname> <given-names>Jelle</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kiebel</surname> <given-names>Stefan J.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Max Planck Institute for Human Cognitive and Brain Sciences, Department of Neurology, 04103 Leipzig, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Psychology, Technische Universität Dresden, 01062 Dresden, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Philosophy, Institute for Logic, Language and Computation, University of Amsterdam, 1012 GC, Amsterdam, the Netherlands</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Biomagnetic Centre, Hans Berger Clinic for Neurology, University Hospital Jena, 07747 Jena, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname> <given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Indiana University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: SB SJK. Performed the experiments: SB JB. Analyzed the data: SB JB. Contributed reagents/materials/analysis tools: SB. Wrote the paper: SB JB SJK.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">sebastian.bitzer@tu-dresden.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>8</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>12</day>
<month>8</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>8</issue>
<elocation-id>e1004442</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>11</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>7</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Bitzer et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004442" xlink:type="simple"/>
<abstract>
<p>Even for simple perceptual decisions, the mechanisms that the brain employs are still under debate. Although current consensus states that the brain accumulates evidence extracted from noisy sensory information, open questions remain about how this simple model relates to other perceptual phenomena such as flexibility in decisions, decision-dependent modulation of sensory gain, or confidence about a decision. We propose a novel approach of how perceptual decisions are made by combining two influential formalisms into a new model. Specifically, we embed an attractor model of decision making into a probabilistic framework that models decision making as Bayesian inference. We show that the new model can explain decision making behaviour by fitting it to experimental data. In addition, the new model combines for the first time three important features: First, the model can update decisions in response to switches in the underlying stimulus. Second, the probabilistic formulation accounts for top-down effects that may explain recent experimental findings of decision-related gain modulation of sensory neurons. Finally, the model computes an explicit measure of confidence which we relate to recent experimental evidence for confidence computations in perceptual decision tasks.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>How do we decide whether a traffic light signals stop or go? Perceptual decision making research investigates how the brain can make these simple but fundamentally important decisions. Current consensus states that the brain solves this task simply by accumulating sensory information over time to make a decision once enough information has been collected. However, there are important, open questions on how exactly this accumulation mechanism operates. For example, recent experimental evidence suggests that the sensory processing receives feedback about the ongoing decision making while standard models typically do not assume such feedback. It is also an open question how people compute their confidence about their decisions. Furthermore, current decision making models usually consider only a single decision and stop modelling once this decision has been made. However, in our natural environment, people change their decisions, for example when a traffic light changes from green to red. Here, we show that one can explain these three aspects of decision making by combining two already existing modelling techniques. This resulting new model can be used to derive novel testable predictions of how the brain makes perceptual decisions.</p>
</abstract>
<funding-group>
<funding-statement>JB was partly funded by an Erasmus Internship scholarship. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="13"/>
<table-count count="2"/>
<page-count count="35"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Research in perceptual decision making investigates how people categorise observed stimuli. By presenting stimuli embedded in large amounts of noise, experimenters prolong the time it takes a subject to make a decision about the stimulus. This makes the decision making process observable for hundreds of milliseconds and enables experiments about the underlying mechanisms [<xref ref-type="bibr" rid="pcbi.1004442.ref001">1</xref>]. For example, in the well-known random dot motion task subjects typically have to categorise a cloud of moving dots according to whether it moves in one of two opposing directions [<xref ref-type="bibr" rid="pcbi.1004442.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref004">4</xref>]. By decreasing the fraction of coherently moving dots the task is made more difficult such that subjects respond slower and make more errors.</p>
<p>Such increases in reaction time for more difficult categorisations motivated models that describe decision making as an accumulation of noisy evidence towards a bound [<xref ref-type="bibr" rid="pcbi.1004442.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref006">6</xref>]. One of the key findings is that such bounded accumulation models fit accuracy and reaction time distributions of decision makers well [<xref ref-type="bibr" rid="pcbi.1004442.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref008">8</xref>]. Furthermore, electrophysiological research has found support for an accumulation mechanism: neurons in different areas of monkey brains exhibit steadily increasing firing rates dependent on stimulus reliability, e.g. [<xref ref-type="bibr" rid="pcbi.1004442.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref012">12</xref>]. In humans, correlates of evidence accumulation have been found with functional magnetic resonance imaging [<xref ref-type="bibr" rid="pcbi.1004442.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref014">14</xref>] and magneto-/electroencephalography [<xref ref-type="bibr" rid="pcbi.1004442.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref019">19</xref>].</p>
<p>The two best-known models of perceptual decision making are drift-diffusion and attractor models. Drift-diffusion models implement accumulation to a bound using diffusion processes [<xref ref-type="bibr" rid="pcbi.1004442.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref022">22</xref>] and can be understood in terms of statistically optimal sequential decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref020">20</xref>]. Bayesian models of perceptual decisions provide a direct link between the computation of evidence from the sensory input and the statistically optimal accumulation of this evidence [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref025">25</xref>]. In contrast, attractor models were developed as neurophysiologically inspired spiking-neuron models of perceptual decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>], but can also be described by simpler firing rate models [<xref ref-type="bibr" rid="pcbi.1004442.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref028">28</xref>]. Attractor models use winner-take-all dynamics to implement accumulation which is nonlinear over time. This nonlinear accumulation is the key difference to drift-diffusion models, which are based on linear accumulation. Both types of models seem to make mostly the same predictions [<xref ref-type="bibr" rid="pcbi.1004442.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref030">30</xref>], yet exhibit subtle differences in favour of attractor models when considering experimental evidence [<xref ref-type="bibr" rid="pcbi.1004442.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref033">33</xref>] but see [<xref ref-type="bibr" rid="pcbi.1004442.ref034">34</xref>].</p>
<p>Bayesian inference provides an optimal approach for combining noisy sensory evidence with internal dynamics and seems generally useful as a basic mechanistic principle for perceptual decision making. For example, drift-diffusion models are strongly connected to Bayesian models of perceptual decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref025">25</xref>]. Therefore, the question arises what exactly a Bayesian inference approach would have to offer for attractor models. Here, we address this question by combining a variant of the nonlinear attractor model with Bayesian inference. The resulting new model, which we call the Bayesian attractor model (BAttM), combines the neurophysiological motivation of the attractor model with the explicit evidence computation formalism of the Bayesian machinery. As we will show, the BAttM is a quantitative model and fits well to behavioural data (reaction times and choice). Furthermore, we will highlight three key advantages of the BAttM that go beyond the standard features of both attractor and drift-diffusion models.</p>
<p>First, the BAttM naturally models changes in decisions that reflect changes in the underlying category. Such changes of an already made decision are an important part of our environment, e.g., a switching traffic-light, but have not been considered by previous models. Rather, drift-diffusion [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>] and attractor models [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref031">31</xref>] have been adapted to model ‘changes of mind’ which are different from ‘re-decisions’ considered here (for more details on the difference see <xref ref-type="sec" rid="sec014">Discussion</xref>).</p>
<p>Second, the BAttM provides a natural explanation for top-down modulation of the sensory gain that controls evidence extraction during the decision making process. Such gain modulation has been implicated in attentional phenomena such as found in feature-based attention [<xref ref-type="bibr" rid="pcbi.1004442.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref038">38</xref>]. In addition, early sensory neurons have been found to exhibit within-trial gain modulation that appears to depend on the final choice in a trial [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>]. The BattM explains these phenomena in terms of a state-dependent, top-down gain mechanism which is absent from both drift-diffusion and attractor models.</p>
<p>Third, the BAttM provides an explicit measure of confidence that reproduces the experimentally established dependence of confidence ratings on decision outcome and task difficulty [<xref ref-type="bibr" rid="pcbi.1004442.ref041">41</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref043">43</xref>]. In particular and in contrast to both drift-diffusion and attractor models, the probabilistic formulation of the BAttM yields a quantitative measure of confidence that reflects the decision maker’s internal expectations and provides a meaningful quantitative interpretation of the bound.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Models</title>
<p>The BAttM consists of four major components: i) an abstract model of the experimental stimuli used as input to the decision process of a decision maker, ii) a generative model of the stimuli implementing expectations of the decision maker, iii) a Bayesian inference formalism and iv) a decision criterion, see also [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>]. In the following, we define these components in turn and, particularly, clarify the role of attractor dynamics in the model and how this differs from previously suggested attractor models of perceptual decision making. We start by formalising a notion of attractor models.</p>
<sec id="sec003">
<title>Pure attractor models</title>
<p>Attractor models of perceptual decision making were originally proposed as neurophysiologically plausible implementation of noisy decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>]. In particular, [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>] introduced a spiking neuron network which implements decisions through an attractor dynamics based on two mutually inhibiting pools of neurons. By using a mean-field approach this model has been reduced to a relatively small set of differential equations [<xref ref-type="bibr" rid="pcbi.1004442.ref028">28</xref>], see also [<xref ref-type="bibr" rid="pcbi.1004442.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref032">32</xref>].</p>
<p>Apart from the neurobiological motivation, attractor models mainly differ from prevalent diffusion models of decision making by the nonlinear accumulation of evidence: The mutual inhibition between alternatives leads to faster accumulation for an alternative as more evidence for that alternative is accumulated, that is, decisions for an alternative are attracting. In the present work we capture this decisive property of attractor models with a simpler, more abstract Hopfield network [<xref ref-type="bibr" rid="pcbi.1004442.ref044">44</xref>]. The Hopfield dynamics describes how state variables <italic>z</italic><sub><italic>i</italic></sub> (the activities of units in the Hopfield network) evolve through time. Each state variable corresponds to one decision alternative. Intuitively, large values of state variable <italic>z</italic><sub><italic>i</italic></sub> indicate large amounts of evidence for decision alternative <italic>i</italic>. The Hopfield dynamics implements lateral inhibition between and self-excitation of state variables. As a result, it exhibits winner-takes-all dynamics which ensures stable and unambiguous decision making between alternatives. In particular, the Hopfield dynamics has stable fixed points <italic>ϕ</italic><sub><italic>i</italic></sub>, each identifying one decision alternative <italic>i</italic>. For further details see <xref ref-type="sec" rid="sec023">Methods</xref>.</p>
<p>By abstracting from details of the particular attractor dynamics used in different models, previous attractor models of decision making may be formalised (in discretised form) as
<disp-formula id="pcbi.1004442.e001"><alternatives><graphic id="pcbi.1004442.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>f</italic>(<bold>z</bold>) is a function defining an attractor dynamics for the vector of state variables <bold>z</bold>, which we also call decision state (cf. <xref ref-type="table" rid="pcbi.1004442.t001">Table 1</xref>). The external input <bold>I</bold><sub><italic>t</italic></sub> varies with stimulus strength, includes noise, directly drives the attractor dynamics and reflects momentary evidence in decision making (see <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1A</xref>). Typically, when one of the state variables <italic>z</italic><sub><italic>i</italic></sub> reaches a certain threshold, the model indicates a decision for the corresponding alternative <italic>i</italic>.</p>
<table-wrap id="pcbi.1004442.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.t001</object-id>
<label>Table 1</label>
<caption>
<title>Key variables and parameters of the BAttM.</title> <p>These variables are defined mathematically in the models section below.</p>
</caption>
<alternatives>
<graphic id="pcbi.1004442.t001g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.t001"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Variable</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Name</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Interpretation</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="1" colspan="1"><bold>z</bold></td>
<td align="left" rowspan="1" colspan="1"><italic>decision state</italic></td>
<td align="left" rowspan="1" colspan="1">current state of attractor dynamics; consisting of state variables <italic>z</italic><sub><italic>i</italic></sub>; one for each decision alternative</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1"><italic>s</italic></td>
<td align="left" rowspan="1" colspan="1"><italic>noise level</italic></td>
<td align="left" rowspan="1" colspan="1">the actual amount of noise with which sensory observations are corrupted</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1"><italic>r</italic></td>
<td align="left" rowspan="1" colspan="1"><italic>sensory uncertainty</italic></td>
<td align="left" rowspan="1" colspan="1">the amount of noise on sensory observations that the decision maker expects</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1"><italic>q</italic></td>
<td align="left" rowspan="1" colspan="1"><italic>dynamics uncertainty</italic></td>
<td align="left" rowspan="1" colspan="1">the amount of noise with which the decision maker expects its decision state to be corrupted in each time step; the higher this uncertainty, the easier it is for the decision maker to switch between alternatives</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="pcbi.1004442.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Schematic comparing a pure attractor model of decision making with the Bayesian attractor model.</title>
<p>Both plots show illustrative snapshots of the two evolving decision states while in transit towards a fixed point where a decision will be made. (A) In a pure attractor model, on the way to a fixed point, the decision state (violet) is evolving according to attractor dynamics (grey arrows). From an initial, unstable fixed point (empty, black circle) the decision state is driven by noisy evidence into one of two attracting, stable fixed points, each of which correspond to a decision alternative. (B) In the Bayesian attractor model the same attractor dynamics is used as generative model for sensory observations. The decision state effects, in a top-down fashion, both internal predictions and gain. These are in turn used together with sensory observations to compute gain-modulated prediction errors which drive updates of the decision state. The model represents uncertainty over the decision state (shaded, violet ellipse) and allows to define the decision criterion directly in terms of confidence in the decision. We show in Results that this recurrent principle stabilises the location of fixed points of the attractor dynamics while at the same time maintaining the ability to reliably switch decisions after a change in stimulus.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g001"/>
</fig>
<p>We refer to models of this type as ‘<italic>pure</italic> attractor models’ which include the attractor models described above [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref028">28</xref>]. Note that pure attractor models are not informed about the stimulus itself or its features. Rather, they presume that their noisy input carries some information about a stimulus which is interpreted as evidence for or against the considered alternatives. Therefore, these models implicitly postulate that evidence for a decision is extracted by lower level sensory processes which are independent of the state of an ongoing decision. Under this assumption, pure attractor models cannot exhibit top-down gain control as a mechanism, because the decision state cannot provide feedback to the lower sensory level, see <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1A</xref>.</p>
</sec>
<sec id="sec004">
<title>Input model</title>
<p>Bayesian models infer the state of an unobserved variable (here the identity of a stimulus) from realisations of an observed variable [<xref ref-type="bibr" rid="pcbi.1004442.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref045">45</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref047">47</xref>]. Here, we define these ‘observations’ and motivate them as feature representations in the brain.</p>
<p>Even though the BAttM can model tasks with multiple alternatives, we here focus on two-alternative forced choice tasks, as most commonly employed when investigating perceptual decisions. For example, in typical random dot motion (RDM) tasks subjects have to judge into which of two opposing directions a randomly moving cloud of dots moves on average [<xref ref-type="bibr" rid="pcbi.1004442.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref004">4</xref>]. By varying the percentage of coherently moving dots the task difficulty can be controlled.</p>
<p>We assume that the brain translates low-level sensory information, such as moving patters of light and dark spots on the retina, into stimulus feature vectors that are relevant for the current decision. In the RDM task a suitable feature may be the dominant motion direction in the stimulus, or a distribution over it. As the motion in the stimulus becomes less coherent, the dominant motion direction becomes more noisy.</p>
<p>The precise feature representation that the brain uses when making decisions, including the particular distribution of feature vectors, is largely unknown. Consequently, we take a suitably parsimonious approach and model (abstract) feature vectors as samples from one of two Gaussian distributions which represent the two alternatives in the decision task. In particular, a feature vector at time <italic>t</italic> is <bold>x</bold><sub><italic>t</italic></sub> ∼ 𝓝(<bold><italic>μ</italic></bold><sub><italic>i</italic></sub>, <italic>s</italic><sup>2</sup> <bold>I</bold>) where <italic>s</italic> is the standard deviation of the noise, or noise level (cf. <xref ref-type="table" rid="pcbi.1004442.t001">Table 1</xref>) and <bold><italic>μ</italic></bold><sub><italic>i</italic></sub> is the feature vector that would result, if alternative <italic>i</italic> was presented without noise. We set <bold><italic>μ</italic></bold><sub>1</sub> = [0.71,0.71]<sup><italic>T</italic></sup> (alternative 1) and <bold><italic>μ</italic></bold><sub>2</sub> = [−0.71,−0.71]<sup><italic>T</italic></sup> (alternative 2), that is, the feature vectors of the two alternatives occupy opposite positions on the unit circle.</p>
<p>This (feature) representation of the noisy stimulus has itself an interpretation as a perceptual decision making task. We use this interpretation here to illustrate the task that the brain, as decision maker, presumably solves when given noisy feature vectors as observations in a decision task: The feature vector <bold>x</bold> can be interpreted as the location of a single dot on a plane which moves randomly around one of two target positions. The single dot positions are sampled from an isotropic two-dimensional Gaussian with mean equal to one of the two targets. The task of the decision maker is to infer around which of the two target locations the single dot moves. Similarly to the RDM task, the difficulty of the task can be continuously varied by manipulating the ratio between the noise level and the distance between the two targets. In the two extremes, there is either no noise so that the correct target can be inferred easily, or the random movements are so large that one cannot infer the true target (i.e., the mean of the underlying Gaussian) with sufficient certainty. In <xref ref-type="fig" rid="pcbi.1004442.g002">Fig 2</xref> we illustrate the dot movements across an example trial in this task.</p>
<fig id="pcbi.1004442.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Example stimulus of single dot task, with a switch of target location.</title>
<p>(A) The plot shows both x- and y- positions of the single dot throughout an example trial of 1600ms length. Every 40ms a new dot position is drawn. For 800ms positions are drawn from the first target (blue), i.e., a Gaussian with mean position [0.71, 0.71] (dark blue horizontal line) and standard deviation <italic>s</italic> = 2 in both dimensions. For the next 800ms positions are drawn from the second target (orange) around the mean [-0.71, -0.71] (red horizontal line) with the same standard deviation. (B) Same data as in (A), but plotted in 2D coordinates as when presented on a screen. Note that the observer would see only a single dot of neutral colour at any time throughout the trial and would have to decide whether the dot moves around the first (lower left) or second (upper right) target (indicated by lines).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g002"/>
</fig>
</sec>
<sec id="sec005">
<title>Generative model with attractor dynamics</title>
<p>The generative model of the decision maker implements its expectations about the incoming observations. More precisely, the generative model is a probabilistic model that defines the likelihood of observations under all possible hypotheses that the decision maker considers. Compared to pure attractor models the flow of information is reversed in the generative model: The generative model predicts a probability distribution over observations based on the current decision state and its winner-take all attractor dynamics. In contrast, in pure attractor models evidence extracted from the stimulus perturbs the decision state without any feedback from the decision state to the sensory evidence (cf. <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1</xref>).</p>
<p>A previous Bayesian model of perceptual decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>] defined independent generative models for the different alternatives in the decision task. The Bayesian attractor model complements the generative model with a competition between alternatives as implemented by attractor dynamics. In particular, the generative model defines a change in decision state from one time step to the next as
<disp-formula id="pcbi.1004442.e002"><alternatives><graphic id="pcbi.1004442.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e002"/><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msqrt><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msqrt> <mml:msub><mml:mi mathvariant="bold">w</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
where <italic>f</italic>(<bold>z</bold>) is the Hopfield dynamics (<xref ref-type="sec" rid="sec023">Methods</xref>, <xref ref-type="disp-formula" rid="pcbi.1004442.e034">Eq 9</xref>). <bold>w</bold><sub><italic>t</italic></sub> is a (Gaussian) noise variable with <bold>w</bold><sub><italic>t</italic></sub> ∼ 𝓝(<bold>0</bold>,<bold>Q</bold>) where <bold>Q</bold> = (<italic>q</italic><sup>2</sup>/Δ<italic>t</italic>)<bold>I</bold> is the isotropic covariance of the noise process and we call <italic>q</italic> ‘dynamics uncertainty’. It represents the (expected) state noise at the attractor level which can be interpreted as the propensity to switch between decisions (the higher the dynamics uncertainty, the more likely the state switches between the decision alternatives).</p>
<p>Given a decision state <bold>z</bold> the generative model predicts a probability distribution over observations by interpolating prototypical observations that represent the different alternatives:
<disp-formula id="pcbi.1004442.e003"><alternatives><graphic id="pcbi.1004442.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mi mathvariant="bold-italic">σ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
where <bold>M</bold> = [<bold><italic>μ</italic></bold><sub>1</sub>,…, <bold><italic>μ</italic></bold><sub><italic>N</italic></sub>] contains the mean feature vectors defined in the input model above. This choice implements the reasonable assumption that the decision maker has learnt the average representations of the stimuli in feature space either through experience with the task, or from a suitable cue in the experiment. <bold><italic>σ</italic></bold>(<bold>z</bold>) is the sigmoid-transformed decision state, that is, all state variables <italic>z</italic><sub><italic>j</italic></sub> are mapped to values between 0 and 1. Due to the winner-take-all mechanism of the Hopfield dynamics, its stable fixed points <italic>ϕ</italic><sub><italic>i</italic></sub> will map to vectors <bold><italic>σ</italic></bold>(<italic>ϕ</italic><sub><italic>i</italic></sub>) in which all entries are approximately 0 except for one entry which is approximately 1. Hence, the linear combination <bold>M</bold> <bold><italic>σ</italic></bold>(<bold>z</bold>) associates each stable fixed point <italic>ϕ</italic><sub><italic>i</italic></sub> with feature vectors (observations) from one of the decision alternatives. When the Hopfield network is not in one of its stable fixed points, <bold>M</bold> <bold><italic>σ</italic></bold>(<bold>z</bold>) interpolates between mean feature vectors <bold><italic>μ</italic></bold><sub><italic>i</italic></sub> dependent on the sizes of individual state variables <italic>z</italic><sub><italic>j</italic></sub>. Finally, <bold>v</bold> is a (Gaussian) noise variable with <bold>v</bold><sub><italic>t</italic></sub> ∼ 𝓝(<bold>0</bold>,<bold>R</bold>) where <bold>R</bold> = <italic>r</italic><sup>2</sup> <bold>I</bold> is the expected isotropic covariance of the noise on the observations and we call <italic>r</italic> ‘sensory uncertainty’. It represents the <italic>expected</italic> noise level of the dot movement in the equivalent single dot decision task explained above (the higher the sensory uncertainty, the more noise is expected by the decision maker).</p>
</sec>
<sec id="sec006">
<title>Bayesian inference</title>
<p>By inverting the generative model using Bayesian inference we can model perceptual inference. Specifically, we use Bayesian online inference to infer the posterior distribution of the decision state <bold>z</bold><sub><italic>t</italic></sub>, that is, the state of the attractor dynamics at time <italic>t</italic>, from sensory input, that is, all the sensory observations made up to that time point: <bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub> = {<bold>x</bold><sub>Δ<italic>t</italic></sub>,…, <bold>x</bold><sub><italic>t</italic></sub>}, given the generative model (Eqs <xref ref-type="disp-formula" rid="pcbi.1004442.e002">2</xref>, <xref ref-type="disp-formula" rid="pcbi.1004442.e003">3</xref>). The generative model postulates that the observations are governed by the Hopfield dynamics. Hence, the inference must account for the assumption that observations of consecutive time points depend on each other. In this case, inference over the decision state <bold>z</bold><sub><italic>t</italic></sub> is a so-called filtering problem which could be solved optimally using the well-known Kalman filter (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004442.ref048">48</xref>]), if the generative model was linear. For nonlinear models, such as presented here, exact inference is not feasible. Therefore, we used the unscented Kalman filter (UKF) [<xref ref-type="bibr" rid="pcbi.1004442.ref049">49</xref>] to approximate the posterior distribution over the decision state <bold>z</bold><sub><italic>t</italic></sub> using Gaussians. Other approximations such as the extended Kalman filter [<xref ref-type="bibr" rid="pcbi.1004442.ref048">48</xref>], or sequential Monte Carlo methods [<xref ref-type="bibr" rid="pcbi.1004442.ref050">50</xref>] could also be used. We chose the UKF, because it provides a suitable tradeoff between the faithfulness of the approximation and computational efficiency.</p>
<p>The UKF is based on a deterministic sampling technique called the unscented transform [<xref ref-type="bibr" rid="pcbi.1004442.ref051">51</xref>][<xref ref-type="bibr" rid="pcbi.1004442.ref052">52</xref>], which provides a minimal set of sample points (sigma points). These sigma points are propagated through the nonlinear function and the approximated Gaussian prediction is found by fitting the transformed sigma points. Following [<xref ref-type="bibr" rid="pcbi.1004442.ref049">49</xref>], we use for the unscented transform the parameter values <italic>α</italic> = 0.01, <italic>β</italic> = 2, <italic>κ</italic> = 3−<italic>D</italic> where <italic>D</italic> is the dimension of the state representation inside the UKF.</p>
<p>In the following, we provide an intuitive description of the UKF computations. For the mathematical details, we refer the reader to [<xref ref-type="bibr" rid="pcbi.1004442.ref049">49</xref>]. The unscented transform is performed twice. First, it is used to approximate the distribution over the decision state in the next time step, as predicted by the generative model from the current estimate based on previous observations, with a Gaussian: <inline-formula id="pcbi.1004442.e004"><alternatives><graphic id="pcbi.1004442.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e004"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">∣</mml:mo> <mml:msub><mml:mtext mathvariant="bold">X</mml:mtext> <mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>≈</mml:mo> <mml:mo>𝓝</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Second, the unscented transform is used to approximate the predicted distribution of the corresponding next sensory observation: <inline-formula id="pcbi.1004442.e005"><alternatives><graphic id="pcbi.1004442.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e005"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">∣</mml:mo> <mml:msub><mml:mtext mathvariant="bold">X</mml:mtext> <mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>≈</mml:mo> <mml:mo>𝓝</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mo>Σ</mml:mo></mml:mrow> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The conceptual idea of Kalman filter algorithms is to compare the predicted distribution with the actual observation and update decision state estimate <inline-formula id="pcbi.1004442.e006"><alternatives><graphic id="pcbi.1004442.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e006"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> proportional to the observed discrepancy while taking the uncertainty over predictions into account. Practically, for the Gaussian approximation used in the UKF we compute a prediction error <inline-formula id="pcbi.1004442.e007"><alternatives><graphic id="pcbi.1004442.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e007"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mi>t</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> between predicted mean <inline-formula id="pcbi.1004442.e008"><alternatives><graphic id="pcbi.1004442.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e008"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and actual observation <bold>x</bold><sub><italic>t</italic></sub> and then update the decision state prediction <inline-formula id="pcbi.1004442.e009"><alternatives><graphic id="pcbi.1004442.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e009"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> via a Kalman gain <bold>K</bold><sub><italic>t</italic></sub>:
<disp-formula id="pcbi.1004442.e010"><alternatives><graphic id="pcbi.1004442.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">K</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
The Kalman gain represents the relative importance of the prediction errors with respect to the predictions and is computed from the estimated covariance of the predicted observations and the cross-covariance between predicted observations and decision state:
<disp-formula id="pcbi.1004442.e011"><alternatives><graphic id="pcbi.1004442.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e011"/><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">K</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
where <inline-formula id="pcbi.1004442.e012"><alternatives><graphic id="pcbi.1004442.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e012"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the cross-covariance between predicted decision state <inline-formula id="pcbi.1004442.e013"><alternatives><graphic id="pcbi.1004442.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e013"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and predicted observation <inline-formula id="pcbi.1004442.e014"><alternatives><graphic id="pcbi.1004442.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e014"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> which is strongly affected by dynamics uncertainty <italic>q</italic> (larger <italic>q</italic>, larger cross-covariance) and <inline-formula id="pcbi.1004442.e015"><alternatives><graphic id="pcbi.1004442.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e015"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mo mathvariant="bold">Σ</mml:mo></mml:mrow> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the covariance matrix of the predicted observations which is strongly affected by sensory uncertainty <italic>r</italic> (larger <italic>r</italic>, larger variance). These relations mean that an increase in <italic>q</italic> mostly leads to an increase in gain whereas an increase in <italic>r</italic> leads to a reduction in gain.</p>
<p>In addition to affecting the updates of the mean decision state, the Kalman gain is further used to estimate the posterior covariance <inline-formula id="pcbi.1004442.e016"><alternatives><graphic id="pcbi.1004442.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e016"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> of the state variables <italic>z</italic><sub><italic>i</italic>,<italic>t</italic></sub> which completes the UKF approximation of the posterior distribution over the decision state <italic>p</italic>(<bold>z</bold><sub><italic>t</italic></sub>∣<bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub>). <xref ref-type="fig" rid="pcbi.1004442.g003">Fig 3</xref> illustrates the described Kalman filtering scheme.</p>
<fig id="pcbi.1004442.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Illustration of the inference scheme used for decision making in the BAttM.</title>
<p>In the physical environment a stimulus is presented by the experimenter and observed by the subject. Components inside the shaded rectangle model internal processes of the subject. Sensory processes in the subject’s brain translate the stimulus into an abstract feature representation <bold>x</bold><sub><italic>t</italic></sub>. The input model (i, green) of the BAttM approximates this translation by mapping the stimulus identity (decision alternative <italic>A</italic><sub><italic>t</italic></sub> at time <italic>t</italic>) to a value <bold>x</bold><sub><italic>t</italic></sub> drawn from a Gaussian distribution with mean <bold><italic>μ</italic></bold><sub><italic>t</italic></sub> and covariance <italic>s</italic><sup>2</sup> <bold>I</bold>. The generative model (ii, orange) states that the decision state <bold>z</bold> is represented by a Gaussian <inline-formula id="pcbi.1004442.e017"><alternatives><graphic id="pcbi.1004442.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e017"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:mo>𝓝</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and evolves according to Hopfield dynamics (<xref ref-type="disp-formula" rid="pcbi.1004442.e002">Eq 2</xref>). The generative model further maps the decision state to different Gaussian densities over observations which mirror those in the input process (<xref ref-type="disp-formula" rid="pcbi.1004442.e003">Eq 3</xref>). Consequently, for the next time step, the generative model predicts the distribution of the decision state, <inline-formula id="pcbi.1004442.e018"><alternatives><graphic id="pcbi.1004442.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e018"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:mo>𝓝</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and the distribution of the observation, <inline-formula id="pcbi.1004442.e019"><alternatives><graphic id="pcbi.1004442.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e019"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mo>𝓝</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mo mathvariant="bold">Σ</mml:mo></mml:mrow> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, which critically depend on model parameters <italic>q</italic> and <italic>r</italic>, respectively. The cross-covariance between predicted decision state and predicted observation is denominated <inline-formula id="pcbi.1004442.e020"><alternatives><graphic id="pcbi.1004442.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e020"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Bayesian inference (iii, red) iteratively compares observations <bold>x</bold><sub><italic>t</italic></sub> with predictions <inline-formula id="pcbi.1004442.e021"><alternatives><graphic id="pcbi.1004442.e021g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e021"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and updates the estimate of the decision state (<xref ref-type="disp-formula" rid="pcbi.1004442.e010">Eq 4</xref>) via the Kalman gain <bold>K</bold><sub><italic>t</italic></sub> which processes the uncertainty defined by <inline-formula id="pcbi.1004442.e022"><alternatives><graphic id="pcbi.1004442.e022g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e022"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004442.e023"><alternatives><graphic id="pcbi.1004442.e023g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e023"/><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004442.e011">Eq 5</xref>). The decision criterion (iv, blue) is defined as a bound <italic>λ</italic> on an explicit measure of confidence (<xref ref-type="disp-formula" rid="pcbi.1004442.e024">Eq 6</xref>).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g003"/>
</fig>
</sec>
<sec id="sec007">
<title>Decision criterion</title>
<p>The final component of the Bayesian attractor model is its decision criterion. In decision models based on evidence accumulation the decision criterion <italic>implicitly</italic> sets a particular level of accumulated evidence that needs to be reached before the decision maker commits to a decision. In contrast, we here define the criterion directly on a measure of confidence in the decision. In particular, the model makes a decision for alternative <italic>i</italic> at time <italic>t</italic>, if
<disp-formula id="pcbi.1004442.e024"><alternatives><graphic id="pcbi.1004442.e024g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e024"/><mml:math id="M24" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>≥</mml:mo> <mml:mi>λ</mml:mi></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>p</italic>(<bold>z</bold><sub><italic>t</italic></sub> = <italic>ϕ</italic><sub><italic>i</italic></sub>∣<bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub>) is the posterior density over the decision state evaluated at the stable fixed point <italic>ϕ</italic><sub><italic>i</italic></sub> corresponding to alternative <italic>i</italic>, that is, <italic>p</italic>(<bold>z</bold><sub><italic>t</italic></sub> = <italic>ϕ</italic><sub><italic>i</italic></sub>∣<bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub>) is the posterior belief of the decision maker that alternative <italic>i</italic> is the true alternative. Then the threshold <italic>λ</italic> can directly be interpreted as a confidence level. This decision criterion requires that all state variables are at their expected values as given by the stable fixed points <italic>ϕ</italic><sub><italic>i</italic></sub>. Note that this is different from pure attractor models which do not use a bound around the fixed point location, but rather threshold individual state variables <italic>z</italic><sub><italic>j</italic></sub>, see below in results.</p>
<p>Uncertainty parameters and the confidence bound interact: Larger dynamics uncertainty leads to wider posterior distributions, faster evidence accumulation and smaller density values (<xref ref-type="fig" rid="pcbi.1004442.g004">Fig 4</xref>). For reporting results we therefore fixed the bound to <italic>λ</italic> = 0.02 in all reported experiments which was sufficiently small to be reached for all considered settings of uncertainties. Note that <italic>p</italic>(<bold>z</bold><sub><italic>t</italic></sub> = <italic>ϕ</italic><sub><italic>i</italic></sub>∣<bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub>) is not a probability, but a probability density value, that is, it can be larger than 1 and should not be expressed in %. Technically, a probability density value is the slope of the cumulative distribution function of a probability distribution evaluated at a given point in the continuous space over which it is defined.</p>
<fig id="pcbi.1004442.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Example trial showing evolution of confidence in alternative 1, <italic>p</italic>(<bold>z</bold><sub><italic>t</italic></sub> = <italic>ϕ</italic><sub>1</sub>∣<bold>X</bold><sub>Δ<italic>t</italic>:<italic>t</italic></sub>) (notice log-scale and initial, very low values), for different values of dynamics uncertainty <italic>q</italic>.</title>
<p>Larger values of <italic>q</italic> mean that only smaller confidence values can be reached even after the decision state <bold>z</bold><sub><italic>t</italic></sub> eventually settled into the stable fixed point <italic>ϕ</italic><sub>1</sub> (compare, e.g., confidence for <italic>q</italic> = 1 and <italic>q</italic> = 0.5 at 200ms, note log-scale). Horizontal dotted line: confidence value used as bound (<italic>λ</italic> = 0.02).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g004"/>
</fig>
<p>In the standard, single decision experiments below we report the decision of the first time point for which the decision-criterion (<xref ref-type="disp-formula" rid="pcbi.1004442.e024">Eq 6</xref>) was met. In the re-decision experiment we report the fraction of time in which the criterion was met for the correct alternatives.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<p>Here we show that the BAttM has ‘inherited’ several key features from the pure attractor model and, in addition, provides for several novel and useful functionalities.</p>
<p>First, we show how the Bayesian attractor model implements the speed-accuracy tradeoff underlying most perceptual decision making experiments. In particular, we show how choice accuracy and mean reaction times can be explained by a combination of input noise level <italic>s</italic> and sensory uncertainty <italic>r</italic> of the decision maker. In other words, we use relative uncertainties to explain specific speed-accuracy tradeoffs. This explanation is a simple consequence of using a probabilistic attractor model in combination with Bayesian inference.</p>
<p>Second, we show that the model can easily explain switches in already made categorical decisions when the sensory input changes. Such re-decisions under uncertainty are often made in our natural dynamic environment but do not seem to be considered by standard experiments and computational models.</p>
<p>Third, we highlight that the BAttM uses a decision state-dependent, top-down modulation of sensory gain such that sensory input affects decisions most, when the decision maker internally predicts the sensory input to be most informative about the decision. Such gain modulation has been hinted at experimentally [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref053">53</xref>], but has not been considered in the drift-diffusion and attractor models.</p>
<p>Fourth, we show that this formalism enables the explicit computation of confidence in the model. This means that the model not only computes a decision state reflecting the accumulated evidence (as for example in the pure attractor model) but also another dynamic measure, the confidence about making a specific decision. Further, we show that the BAttM can model trial-by-trial variability in confidence judgements as, for example, reported in [<xref ref-type="bibr" rid="pcbi.1004442.ref041">41</xref>].</p>
<p>Finally, we demonstrate that the BAttM can be used for quantitative analysis of standard perceptual decision making tasks. As an example, we use behavioural data taken from a recent experiment [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] and show that the Bayesian attractor model can fit these data well.</p>
<sec id="sec009">
<title>Speed-accuracy tradeoff in the BAttM</title>
<p>In the BAttM, the speed and accuracy of decisions are primarily controlled by the noise level of the sensory input (<italic>s</italic>), the sensory uncertainty (<italic>r</italic>) and the dynamics uncertainty (<italic>q</italic>). Additionally, the initial state uncertainty <italic>p</italic><sub>0</sub> (see <xref ref-type="sec" rid="sec023">Methods</xref>) influences the rate of evidence accumulation at the beginning of a trial. First, we demonstrate the effect of the sensory uncertainty <italic>r</italic>, i.e., the decision maker’s internal expectation of how noisy the input is, on decisions.</p>
<p>
<xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5</xref> shows the dynamics of the decision state over time for three different settings of the decision maker’s sensory uncertainty <italic>r</italic>. After an initial non-decision time of 200ms, the decision variables start accumulating evidence. If the sensory uncertainty is too low, i.e., the decision maker puts too much weight on the noisy input relative to the attractor dynamics (<xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5A</xref>), the decision state overshoots and initially misses the associated fixed point representing a decision. Only after hundreds of milliseconds the decision state relaxes back to a fixed point. This uncertainty setting leads to inaccurate decisions with rather long reaction times. If the sensory uncertainty is too high (<xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5C</xref>), decision making is accurate but relatively slow, because the decision maker expects a much higher noise level than the actual one. When using a suitable sensory uncertainty for the actual noise level of the input (<xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5B</xref>), decision making is fast and accurate as typically observed in subjects.</p>
<fig id="pcbi.1004442.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Example trajectories for the Bayesian attractor model on a binary decision task for varying sensory uncertainty <italic>r</italic>.</title>
<p>Each of the plots shows three example trials. Note that there are two state variables (blue: alternative 1, orange: alternative 2) for each trial. (A-C) Decision state <inline-formula id="pcbi.1004442.e025"><alternatives><graphic id="pcbi.1004442.e025g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e025"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. (D-F) Confidence (log-scale). Grey, dashed line: threshold used in the model. (A,D) <italic>r</italic> = 1, decisions are inaccurate and shoot over fixed points (located at [10, 0] and [0, 10]). (B,E) <italic>r</italic> = 2.2, decisions are relatively fast and accurate, (C,F) <italic>r</italic> = 3.0, decisions are accurate but can be slow. The same sensory input with noise level (standard deviation) <italic>s</italic> = 4.7 was used in all three cases. Dynamics uncertainty was <italic>q</italic> = 0.1 and initial state uncertainty was <italic>p</italic><sub>0</sub> = 5. Note that for clarity we plotted only the mean of the posterior distributions but not the posterior uncertainties (but see below for examples).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g005"/>
</fig>
<p>To investigate the quantitative dependence of decision state trajectories on both the noise level <italic>s</italic> and the sensory uncertainty <italic>r</italic> we systematically varied these two parameters. We sampled single trial trajectories from each parameter combination while keeping the remaining parameters of the model fixed (<italic>q</italic> = 0.1, <italic>p</italic><sub>0</sub> = 5). For more reliable results, we computed the accuracy and mean reaction time over 1,000 single trials for each parameter combination (<xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>). As expected, the accuracy (<xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6A</xref>) decreases from perfect to chance level as the noise level <italic>s</italic> increases. In general, below <italic>s</italic> &lt; 2, any setting of sensory uncertainty <italic>r</italic> leads to perfect accuracy whereas the mean reaction time (RT) increases with sensory uncertainty <italic>r</italic> (with <italic>r</italic> &gt; 10 RTs can become slower than 1000ms; we excluded these parameter settings from further analysis, see the light blue areas in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>). In contrast, when the noise is large (<italic>s</italic> &gt; 20), the random movement of the dot is too large to recover the stimulus identity reliably, whatever the setting of the sensory uncertainty <italic>r</italic>. For intermediate values of <italic>s</italic>, 3 &lt; <italic>s</italic> &lt; 20, a relatively high accuracy level can be maintained by increasing the sensory uncertainty appropriately; this is reflected by the diagonal gradient between the white and dark grey area in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6A</xref>. In <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6B</xref> there is a narrow valley of fast mean RTs stretching from the lower left to the upper right of the image. Note that the slower RTs below this valley result from trajectories as in <xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5A</xref>. Slower RTs above this valley are due to slow accumulation as seen in <xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5C</xref>. Most importantly, both fast and accurate decisions can be achieved by appropriately adapting the sensory uncertainty <italic>r</italic> to the noise level <italic>s</italic> of the stimulus. The practical use of the results shown in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref> is to fit subject behaviour, i.e., to identify parameter settings which explain the observed accuracy and mean reaction time of a subject.</p>
<fig id="pcbi.1004442.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Mapping from sensory uncertainty <italic>r</italic> and noise level <italic>s</italic> to behavioural measures.</title>
<p>(A) Log-log plot of the fraction of correct responses, i.e. accuracy. (B) Mean reaction time for correct responses in ms (including a non-decision time of 200ms, see <xref ref-type="sec" rid="sec023">Methods</xref>). Light blue areas correspond to parameter settings where more than 50% of trials resulted in time outs (RT &gt;1000ms). Light red lines show approximated contour lines (see <xref ref-type="sec" rid="sec023">Methods</xref> of the underlying grey scale map. In A the lines correspond, from right to left, to 0.6, 0.7, 0.8 and 0.9 fraction of correct responses. In B the lines correspond, from bottom to top, to 400, 500, 600 and 700 ms.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g006"/>
</fig>
</sec>
<sec id="sec010">
<title>Re-decisions</title>
<p>As our environment is dynamic, a specific stimulus may suddenly and unexpectedly change its category. For example, traffic lights turn red and other people may suddenly change their intentions and actions. In these cases one has to make a ‘re-decision’ about the category of the attended stimulus. This is different from the typical ‘single decision’ forced-choice experiments considered in the previous section. These investigate the special case in which the underlying category of a single trial does not change. The corresponding models, like the drift-diffusion model, were designed to model precisely this case and focus on the tradeoff between speed and accuracy of decisions. With re-decisions, another tradeoff, between flexibility and stability in decisions, presents itself. This tradeoff stresses the dilemma of the decision maker to either explain away evidence for an alternative as noise (stability), or rather switch to the alternative decision rapidly (flexibility).</p>
<p>Although one may consider extending the ‘single trial’ models so that re-decisions can be modelled (see <xref ref-type="sec" rid="sec014">Discussion</xref>), we found that the BAttM is already an appropriate model of re-decisions. In particular, the sensory uncertainty <italic>r</italic> and dynamics uncertainty <italic>q</italic> are two well-interpretable parameters which control the balance between flexibility and stability. Therefore, the BAttM lends itself naturally as a quantitative analysis method for reaction times and accuracy of re-decisions, as we will demonstrate next.</p>
<p>We investigated the re-decision behaviour for a range of parameter settings, see <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref>. In contrast to the above findings for single decisions, the dynamics uncertainty <italic>q</italic> here plays an important role because it enables the Bayesian attractor dynamics to display different behaviours: When <italic>q</italic> is large, the decision maker will switch readily between fixed points, i.e. decisions. When <italic>q</italic> is small, switching will occur only when sensory input very clearly indicates the alternative. As a proof of principle, we varied the sensory uncertainty <italic>r</italic> and the dynamics uncertainty <italic>q</italic> in logarithmic steps (with fixed noise level <italic>s</italic> = 4), over many (1,000) trials. In each trial, after showing noisy exemplars from one target location (blue alternative) for about 800ms, we switched to the other target (orange alternative) for the same duration (cf. <xref ref-type="fig" rid="pcbi.1004442.g002">Fig 2</xref>).</p>
<fig id="pcbi.1004442.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Re-decision behaviour of Bayesian attractor model for switching stimuli.</title>
<p>Noisy exemplars of alternative 1 (blue) and subsequently of alternative 2 (orange) were shown with a switch at 800ms (cf. <xref ref-type="fig" rid="pcbi.1004442.g002">Fig 2</xref>). For varying combinations of sensory uncertainty <italic>r</italic> and dynamics uncertainty <italic>q</italic> we plotted the mean (over 1000 trials) percentage of time spent in the correct decision state (grey shading). (A-C) Bottom panels show three example trials for the parameter combinations indicated by the corresponding points in the main panel. Top row: decision state, bottom row: confidence (log-scale) with threshold (grey, dashed line). A: fast, but sometimes fickle re-decisions, B: slower but reliable re-decisions, C: no re-decisions. For point A the mean % time spent in the correct decision is larger, because decision and re-decisions are on average faster. The overall level of confidence reached increases from A to C, as previously shown in <xref ref-type="fig" rid="pcbi.1004442.g004">Fig 4</xref>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g007"/>
</fig>
<p>As a measure for accuracy we report in <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref> the mean percentage of time spent in the correct decision state. There are three main regions in the plot: (i) uncertainty settings in the white region lead to extremely slow decisions, (ii) the grey region in which an initial decision (first 800ms) is made but not appropriately updated after a switch and (iii) the black region in which the decision dynamics is sufficiently flexible to make two appropriate decisions. As expected, and in congruence with <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>, we find that the sensory uncertainty <italic>r</italic> must be set appropriately (here approximately between 1.5 to 3.0) in relation to the sensory noise level (here <italic>s</italic> = 4.0) to make fast and accurate initial decisions. For further analysis we focus on one of these values (<italic>r</italic> = 2.4), which is consistent with the behavioural data fitting reported below (in our fitting results <italic>r</italic> = 2.4 roughly corresponds to noise level <italic>s</italic> = 4.0 and a coherence of about 25%). We selected three different settings of <italic>q</italic> (0.1, 0.5, 1) as a representative illustration of the results. We display samples of the corresponding trajectories of the decision state in <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7A–7C</xref>. To compare the impact of the dynamics uncertainty <italic>q</italic>, these samples are based on the same sensory input.</p>
<p>For high dynamics uncertainty <italic>q</italic> = 1.0 (<xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7A</xref>) both the initial decision and the re-decision are made appropriately. However, the decision maker sometimes changes its decision due to sensory noise, i.e., without an underlying switch of stimulus (see <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7A</xref> at 350ms), exhibiting a high level of flexibility. On average, as re-decisions are made correctly, the performance is relatively large (73%). Although a performance of 73% does not sound very high, it is an open experimental question how human participants would perform in the re-decision experiment. Like the model, a participant will require switching time and may experience transient false beliefs as seen in <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7A</xref>. In the model, the 73% performance compares well against the two other dynamics uncertainty settings. For example, for a smaller uncertainty (<italic>q</italic> = 0.5, <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7B</xref>) spurious, noise-induced switches are greatly reduced, but re-decisions are slower. This leads to a reduction in time spent in the correct decision state (53%) in exchange for an increased stability of the decisions. In the grey region (point location and panel C in <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref>) the dynamics uncertainty is too low (0.1) to make a re-decision based on the sensory input. Only 35% of the time was on average spent in the correct decision state with this setting of <italic>q</italic>, i.e., decisions were detrimentally stable.</p>
<p>In summary, the dynamics uncertainty <italic>q</italic> is a useful parameter for modelling the tradeoff between flexibility and stability of re-decisions. Importantly, similar to the fitting of the experimental data of [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], the mapping of parameters <italic>s</italic>, <italic>r</italic>, and <italic>q</italic> (i.e., noise level, sensory uncertainty and dynamics uncertainty) can be used to quantitatively analyse experimental data in re-decision tasks.</p>
<p>The BAttM suggests an intuitive mechanism of re-decisions: Once an initial decision has been made, the decision state is located in a stable fixed point of the attractor dynamics. As long as sensory observations are consistent with the decision maker’s expectations, the fixed point location is held. When the underlying stimulus changes, however, violated expectations, i.e., large prediction errors (see <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1B</xref>), force the decision state to move away from the currently occupied fixed point and towards the fixed point representing the identity of the new stimulus, eventually leading to a re-decision. Both sensory uncertainty and dynamics uncertainty control the gain with which prediction errors influence the decision state (cf. Eqs <xref ref-type="disp-formula" rid="pcbi.1004442.e010">4</xref> and <xref ref-type="disp-formula" rid="pcbi.1004442.e011">5</xref> in models): the sensory uncertainty primarily controls the overall amount of evidence extracted from sensory observations (high uncertainty means low evidence) while the dynamics uncertainty controls how sensory evidence is translated to the decision state (high dynamics uncertainty usually means large effects of sensory evidence on the decision state). Similarly, the gain of the sensory evidence on the decision state is influenced by the decision state itself, implementing state-dependent top-down gain modulation of sensory information. We describe this effect next.</p>
</sec>
<sec id="sec011">
<title>Top-down gain modulation</title>
<p>There is growing evidence that higher level cognitive processes modulate neural responses already in early sensory areas [<xref ref-type="bibr" rid="pcbi.1004442.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref058">58</xref>]. More specifically, recent findings [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref053">53</xref>] indicate that neural activity in early sensory areas is modulated by the final choice of subjects in simple perceptual decision tasks. These findings suggest that top-down feedback influences sensory processing already on the temporal scale of single decisions, i.e., within a trial of a perceptual decision making task. Pure attractor and drift-diffusion models, however, do not account for top-down feedback that modulates the extraction of evidence on the sensory level. In this section, we show that the BAttM offers such a top-down computational mechanism that leads to a stabilisation of the fixed points of the attractor dynamics and, consequently, allows the decision maker to make confidence-informed decisions.</p>
<p>This mechanism can be best understood by comparing the within-trial dynamics of the decision state for both pure attractor models (<xref ref-type="disp-formula" rid="pcbi.1004442.e001">Eq 1</xref>) and the BAttM. Bayesian inference in the BAttM implements a predictive coding scheme (<xref ref-type="disp-formula" rid="pcbi.1004442.e010">Eq 4</xref>) in which state predictions <inline-formula id="pcbi.1004442.e026"><alternatives><graphic id="pcbi.1004442.e026g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e026"/><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are updated with information from prediction errors <bold><italic>ϵ</italic></bold><sub><italic>t</italic></sub> dependent on a Kalman gain matrix <bold>K</bold><sub><italic>t</italic></sub> (<xref ref-type="disp-formula" rid="pcbi.1004442.e011">Eq 5</xref>) which embodies uncertainty and the relation between observations <bold>x</bold> and decision variables <bold>z</bold>. To compare the pure attractor model with the BAttM we first note that both models have the same form: After approximating the mean state prediction <inline-formula id="pcbi.1004442.e027"><alternatives><graphic id="pcbi.1004442.e027g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e027"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> with the (expected) attractor dynamics of the generative model,
<disp-formula id="pcbi.1004442.e028"><alternatives><graphic id="pcbi.1004442.e028g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e028"/><mml:math id="M28" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
we can plug this approximation into <xref ref-type="disp-formula" rid="pcbi.1004442.e010">Eq (4)</xref>. The resulting Bayesian inference formalism replicates the form of the attractor model in <xref ref-type="disp-formula" rid="pcbi.1004442.e001">Eq (1)</xref>:
<disp-formula id="pcbi.1004442.e029"><alternatives><graphic id="pcbi.1004442.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e029"/><mml:math id="M29" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>≈</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">K</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula>
The critical difference of the BAttM formalism of <xref ref-type="disp-formula" rid="pcbi.1004442.e029">Eq (8)</xref> to the pure attractor model in <xref ref-type="disp-formula" rid="pcbi.1004442.e001">Eq (1)</xref> is that the BAttM prescribes an input consisting of a prediction error scaled by the gain. In particular, the input to the Bayesian attractor model depends on the last state <inline-formula id="pcbi.1004442.e030"><alternatives><graphic id="pcbi.1004442.e030g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e030"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> both through the gain matrix <bold>K</bold><sub><italic>t</italic></sub> and the mean prediction <inline-formula id="pcbi.1004442.e031"><alternatives><graphic id="pcbi.1004442.e031g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e031"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (see <xref ref-type="sec" rid="sec002">Models</xref>). This means that sensory observations pass through two processing steps which are applied in each time step: (i) Computation of prediction error using the top-down prediction, and (ii) modulation of the prediction error by the gain which also translates the sensory information (prediction errors) into the decision space (through linear transformation by the gain matrix <bold>K</bold><sub><italic>t</italic></sub>).</p>
<p>In this model, the effect of the gain is driven by two opposing components: In general, when predictions are more certain, the gain is increased. This effect is primarily mediated by the uncertainty <italic>r</italic> at the sensory level. Importantly, the gain is also driven by the cross-covariance of the predicted decision state <inline-formula id="pcbi.1004442.e032"><alternatives><graphic id="pcbi.1004442.e032g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e032"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">z</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and predicted sensory observations <inline-formula id="pcbi.1004442.e033"><alternatives><graphic id="pcbi.1004442.e033g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e033"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">x</mml:mtext> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004442.e011">Eq 5</xref>). The cross-covariance describes the information about changes in the decision state that can explain variation in sensory observations. It defines how prediction errors in sensory observations induce necessary changes in the decision state. This effect is largest in the space between fixed points of the attractor dynamics, because here a change in the decision state almost linearly maps to a change in sensory predictions. In contrast, the effect is relatively small close to the fixed points (see <xref ref-type="sec" rid="sec023">Methods</xref> for details). As uncertainty in the decision state increases, it becomes more likely that the underlying distribution covers more of the space between fixed points, thereby increasing cross-covariance. Consequently and opposite to uncertainty at the sensory level, higher uncertainty at the decision level typically leads to larger top-down gain.</p>
<p>
<xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8</xref> demonstrates this within-trial gain modulation mediated by cross-covariance, for the empirically inferred parameters of point B of <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref> (<italic>s</italic> = 4, <italic>r</italic> = 2.4, <italic>q</italic> = 0.5). <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8A</xref> shows the inferred decision state as a function of time. After the switch of the stimulus, between 800 and 1,500ms, the decision state moved between fixed points of the attractor dynamics. As can be seen in <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8B</xref>, the predicted cross-covariances between decision state and sensory observations were large during this time period and became small again once the dynamics settled into a fixed point after 1,500ms, i.e., when a decision had been made. Similar dynamics can be seen for the initial decision around 0 to 200ms. <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8C</xref> plots the elements of the gain matrix <bold>K</bold><sub><italic>t</italic></sub> over time. The trajectories follow those of the cross-covariance closely demonstrating that within-trial changes in gain were driven nearly exclusively by changes in the cross-covariance. Although the uncertainty over the decision state also varied within the trial (<xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8A</xref>, shading), the effect on the uncertainty of predicted observations was small in comparison to the effect exerted by the sensory uncertainty <italic>r</italic>, which remained constant throughout the trial.</p>
<fig id="pcbi.1004442.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Example of a decision making trial with evolution of cross-covariance and gain for parameters of point B in <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref>.</title>
<p>Noisy exemplars of alternative 1 (blue) and subsequently of alternative 2 (orange) were shown with a switch at 800ms (cf. <xref ref-type="fig" rid="pcbi.1004442.g002">Fig 2</xref>). (A) Inferred decision state with mean state variables (lines) and two times their standard deviation (shading) indicating posterior uncertainty over decision state. State variable associated with alternative 1 shown in blue and associated with alternative 2 shown in orange. (B) Absolute cross-covariances between predicted observations and predicted decision state over time. Colours indicate cross-covariances associated with corresponding state variables as in A. Cross-covariances are large during their transition between fixed points. Once a fixed point is reached (i.e. a decision has been made) cross-covariances drop quickly. (C) Absolute gain values (elements of <bold>K</bold><sub><italic>t</italic></sub>) over time. Colouring as in B. Gain values are scaled cross-covariances, i.e., within-trial changes in gain are mostly driven by changes in cross-covariances.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g008"/>
</fig>
<p>In summary, the within-trial, state-dependent modulation of gain is a useful mechanism when making decisions: It stabilises the representation of the stimulus category (low gain close to fixed points, see below), but also implements fast accumulation of evidence, when needed (high gain between fixed points).</p>
</sec>
<sec id="sec012">
<title>Confidence-based decision criterion</title>
<p>A graded feeling of confidence appears to be a fundamental aspect of human decision making. Corresponding confidence judgements can inform about underlying decision processes [<xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref043">43</xref>]. Through the probabilistic formulation, the BAttM directly provides a continuous measure of confidence that may be compared to experimentally measured confidence judgements. In the following we describe how confidence is computed in the BAttM, explain its use within the decision criterion and demonstrate that it conforms to experimental findings about confidence judgements [<xref ref-type="bibr" rid="pcbi.1004442.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>].</p>
<p>The substantial and sudden decrease of gain close to a fixed point (e.g., <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8C</xref>, at 1,400ms) contributes to an important feature of the BAttM: The location of fixed points is the same for different stimulus strengths. As we will show in this section, stable fixed point locations are the basis for defining a decision criterion directly on an explicit measure of confidence.</p>
<p>Pure attractor models do not have stable fixed points: Because noisy evidence directly feeds onto the decision variable (see <xref ref-type="disp-formula" rid="pcbi.1004442.e001">Eq 1</xref> and <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1A</xref>), the location of fixed points depends on the magnitude of the evidence, i.e., stimulus strength. We show this effect in <xref ref-type="fig" rid="pcbi.1004442.g009">Fig 9A</xref>, see also [<xref ref-type="bibr" rid="pcbi.1004442.ref059">59</xref>]. Therefore, in pure attractor models, as long as stimulus strength is assumed to be unknown, one cannot tell how close the current decision state is to a fixed point, that is, fixed points have no particular meaning in pure attractor models except that the dynamics will eventually converge to them.</p>
<fig id="pcbi.1004442.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Evolution of decision state for pure attractor model (left) and Bayesian attractor model (right) for different input strengths or different uncertainty parameters, respectively.</title>
<p>There are two alternatives indicated by blue (alternative 1) and orange (alternative 2). Thinner lines indicate smaller stimulus strength. For the first 800ms, input reflecting alternative 1 was shown, with a switch to input caused by alternative 2 at 800ms. (A) In the pure attractor model speed and accuracy of initial and re-decisions is controlled by the input which we set to <bold>I</bold><sub><italic>t</italic></sub> = [Δ<italic>tI</italic>+<italic>v</italic><sub><italic>t</italic></sub>,0], if alternative 1 is correct, and <bold>I</bold><sub><italic>t</italic></sub> = [0,Δ<italic>tI</italic>+<italic>v</italic><sub><italic>t</italic></sub>], if alternative 2 is correct (<italic>v</italic><sub><italic>t</italic></sub> ∼ 𝓝(0,0.2<sup>2</sup>)). We varied the value of <italic>I</italic> as indicated in the plot legend. If <italic>I</italic> is large, i.e., the task is easy, initial decisions and switches are fast (thick lines). The position of the fixed point, to which the dynamics converges, depends strongly on <italic>I</italic>. (B, C): In the Bayesian attractor model timing and accuracy of initial decisions and re-decisions depend on the uncertainties in the model, but, critically, the location of the fixed points of the dynamics remain the same for different uncertainties. B and C share the same observations with noise level <italic>s</italic> = 1. In B: <italic>q</italic> = 0.5. In C: <italic>r</italic> = 1.9.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g009"/>
</fig>
<p>In contrast, in the BAttM the speed of evidence accumulation, as caused by a particular, underlying stimulus strength, can vary without affecting fixed point locations (<xref ref-type="fig" rid="pcbi.1004442.g009">Fig 9B and 9C</xref>). This is because the BAttM implicitly represents stimulus strength in its uncertainty parameters <italic>r</italic> and <italic>q</italic> such that <italic>expected</italic> stimulus strength is automatically taken into account during evidence computation from the stimulus. As a consequence of stable fixed point locations, a deviation of the decision state from a fixed point can be readily interpreted as violation of the expectations about the stimulus associated with that fixed point, irrespective of stimulus strength. In general, the more such expectations are violated, the less confident the decision maker should be about choosing one of the alternatives. We implemented this mechanism in the BattM by deriving the confidence in a decision alternative directly from the probabilistic model and using a threshold on it as decision criterion (see <xref ref-type="sec" rid="sec002">Models</xref>, <xref ref-type="disp-formula" rid="pcbi.1004442.e024">Eq 6</xref>).</p>
<p>In <xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10</xref> we illustrate how confidence values relate to the posterior density of the decision state (<xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10A</xref>), and how confidence-based decisions are made (<xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10B</xref>). Intuitively, the confidence for a specific alternative measures the distance of the current decision state (blue and orange lines in <xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10A</xref>) from the stable fixed point of that alternative (at [0, 10] or [10, 0]) scaled by the posterior uncertainty of the decision state. Consequently, the confidence for all alternatives can be tracked across time (cf. blue and orange lines in <xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10B</xref>). Strikingly, the confidence dynamics are different from the decision variable dynamics: While the decision state gradually moves towards a fixed point, thus reflecting the relatively slow gradual accumulation of evidence (e.g., time period 800 to ∼ 1100ms), the confidence rises abruptly as soon as the posterior density of the decision state starts concentrating around a fixed point (e.g., from ∼ 1100ms onwards).</p>
<fig id="pcbi.1004442.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Example evolution of the posterior density of the decision state and the associated confidence values for one trial with a switch of stimulus at 800ms (vertical, dotted line).</title>
<p>(A) Posterior density of the decision state with mean (coloured lines) and two times standard deviation (shading) of decision state variables as in <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8A</xref>. Grey, dashed lines in A show the decision times for the initial decision (92ms) and the re-decision after the switch (1160ms). (B) Solid lines indicate confidence values for both alternatives, i.e., the posterior probability density values that the decision state is in one of the stable fixed points of the attractor dynamics. The decision threshold is indicated as grey, dashed line. The parameters of the model were those of <xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7B</xref> (<italic>r</italic> = 2.4, <italic>s</italic> = 4, <italic>q</italic> = 0.5).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g010"/>
</fig>
<p>How does the confidence-based decision making formalism compare with experimental findings? Early behavioural work with humans [<xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>], indirect confidence judgements by rats [<xref ref-type="bibr" rid="pcbi.1004442.ref041">41</xref>] and general theoretical considerations [<xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref043">43</xref>] suggest that confidence in correct choices increases with stimulus strength whereas confidence in erroneous choices decreases with stimulus strength. At first glance, this seems at odds with a confidence-based decision criterion, as used by the BAttM, where the decision is made exactly when the confidence is at a specific level, independent of stimulus strength (<xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10B</xref>). This apparent contradiction can be resolved by noting that subjects, in the typical experimental setup, keep observing the stimulus for a short time after reaching the threshold, because of the delay between an internal decision and the production of the corresponding motor output, such as a button press. In standard models, this time period is usually considered to be part of the total non-decision time. Importantly, the same mechanism of continued accumulation of evidence in this time period is thought to contribute to ‘changes of mind’ observed in a reaching task [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>] where subjects revise their internal categorization before being able to fully execute the reaching movement. We implemented this mechanism in the BAttM by continuing the accumulation of evidence after crossing the confidence threshold for about half of the estimated non-decision time of 200ms, i.e., for 100ms. Critically, during this continued accumulation period, the confidence values evolve further and replicate the reported experimental results that show a dependence of confidence on stimulus strength and correctness of decision (<xref ref-type="fig" rid="pcbi.1004442.g011">Fig 11</xref>).</p>
<fig id="pcbi.1004442.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Confidence in relation to stimulus strength as predicted by the BAttM for the experiment of [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>].</title>
<p>These confidence values result from continuing accumulation of evidence for 100ms after the internal threshold was crossed but before a corresponding motor response was completed (cf. [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>]). Negative coherences: left motion stimulus, positive coherences: right motion stimulus. For each coherence level we simulated 2,500 trials (5,000 for 0% coherence) using the BAttM. Shown are mean confidence values and their standard errors. Parameters were those listed in <xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref> with <italic>q</italic> = 0.5.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g011"/>
</fig>
</sec>
<sec id="sec013">
<title>Fitting of a reaction time experiment</title>
<p>To establish the validity of the proposed model and show that the model can be used to analyse data of decision making tasks, we fit behavioural macaque monkey data on the RDM two-alternative forced choice task presented in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]. These authors used a drift-diffusion model to fit the average responses based on 15,937 trials. Stimuli were presented at eight different coherence levels ranging from 0% to 75%. We extracted the averages of the behavioural data from Figure 1 d,f in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] and re-plotted the data in <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12B and 12C</xref> (black dots). We obtained the model fit by stochastically minimising an objective function which quantified the discrepancy between values sampled from the model and the behavioural data (cf. <xref ref-type="sec" rid="sec023">Methods</xref>). The sampled RTs contained a non-decision time which was reported in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] (see <xref ref-type="sec" rid="sec023">Methods</xref> for details). We plot the fits of mean reaction time and accuracy in <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12B and 12C</xref>. In <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>, we show the fitted model parameters, noise level <italic>s</italic> and sensory uncertainty <italic>r</italic>, see also <xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>.</p>
<fig id="pcbi.1004442.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Model fit to experimental data presented in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>].</title>
<p>Eight different coherence levels ranged from 0% to 75%. (A) Model parameters (red: sensory uncertainty <italic>r</italic>, green: noise level <italic>s</italic>) inferred from the behavioural data. For each coherence and parameter we show an approximate posterior distribution estimated from 501 posterior samples (see <xref ref-type="sec" rid="sec023">Methods</xref>) where darker colours correspond to larger probability as indicated by the colour bars on the right. Both abscissa and ordinate are in log-scale. Red line: linear fit between sensory variance <italic>r</italic><sup>2</sup> and coherence that also exposes a linear relation between drift and coherence in the drift diffusion model. (B) Fit of mean RT of all responses. Black dots with light grey outline: behavioural data [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]. Greyscale rectangles: estimated posterior distribution over mean reaction time. (C) Fit of accuracy (fraction of correct responses). Format as in B. Black, horizontal bars for coherences greater than 9% indicate probabilities larger than 0.2 for an accuracy of 1. This means that for high coherences parameter values as indicated in A predicted an accuracy of 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g012"/>
</fig>
<table-wrap id="pcbi.1004442.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.t002</object-id>
<label>Table 2</label>
<caption>
<title>Fitted parameter values (best fitting sample for each coherence).</title>
</caption>
<alternatives>
<graphic id="pcbi.1004442.t002g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.t002"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>coherhence (%)</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>0</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>3.2</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>6.4</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>9</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>12</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>25.6</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>51.2</bold></th>
<th align="center" rowspan="1" colspan="1"><bold>75</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>sensory uncertainty <italic>r</italic></bold></td>
<td align="center" rowspan="1" colspan="1">18</td>
<td align="char" char="." rowspan="1" colspan="1">11.2</td>
<td align="char" char="." rowspan="1" colspan="1">7.4</td>
<td align="char" char="." rowspan="1" colspan="1">6.7</td>
<td align="char" char="." rowspan="1" colspan="1">4.8</td>
<td align="char" char="." rowspan="1" colspan="1">2.3</td>
<td align="char" char="." rowspan="1" colspan="1">0.55</td>
<td align="char" char="." rowspan="1" colspan="1">0.30</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>noise level <italic>s</italic></bold></td>
<td align="center" rowspan="1" colspan="1">56.9</td>
<td align="char" char="." rowspan="1" colspan="1">23.7</td>
<td align="char" char="." rowspan="1" colspan="1">13.6</td>
<td align="char" char="." rowspan="1" colspan="1">11.9</td>
<td align="char" char="." rowspan="1" colspan="1">8.5</td>
<td align="char" char="." rowspan="1" colspan="1">3.8</td>
<td align="char" char="." rowspan="1" colspan="1">0.16</td>
<td align="char" char="." rowspan="1" colspan="1">0.14</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>These results demonstrate that the model can fit the mean RTs and accuracy for different coherence levels by varying the sensory noise and the internal uncertainty of the decision maker. As can be seen in <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref> and <xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>, we found, as expected, that both the sensory uncertainty and the noise level decrease as a function of coherence. The estimated posterior parameter variances indicate that parameters of the model can be estimated reliably for intermediate accuracies. When accuracy reaches its ceiling at 100% for coherences greater than 25% many different noise levels <italic>s</italic> can lead to equivalent predictions, simply because noise is not needed anymore to explain erroneous choices and can be set arbitrarily small.</p>
<p>It has previously been found that the drift in a drift diffusion model scales linearly with coherence (e.g., [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]). We found an equivalent relation between the sensory uncertainty <italic>r</italic> and coherence (<xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>, red line). In particular, it has been shown for a simple probabilistic model ([<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>], Eq 22) that sensory uncertainty <italic>r</italic> relates to drift <italic>v</italic> in the drift diffusion model as <italic>r</italic><sup>2</sup> = 2/(<italic>v</italic>Δ<italic>t</italic><sup>2</sup>). If <italic>v</italic> = <italic>Kc</italic> as in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], <italic>r</italic> can be written as <italic>r</italic><sup>2</sup> = <italic>K</italic>′/<italic>c</italic>. We applied this relation to the BAttM and fitted <italic>K</italic>′ to the values of <italic>r</italic> reported in <xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref> (see <xref ref-type="sec" rid="sec023">Methods</xref> for details). The result captures the previously reported relation between coherence and sensory uncertainty well for most coherences (red line in <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>) and only deviates from the fitted parameter values for coherences greater than 25%; see <xref ref-type="sec" rid="sec014">Discussion</xref> for a potential, interesting reason.</p>
<p>In all work presented here we fixed the confidence threshold <italic>λ</italic> to a constant value. This was necessary, because <italic>λ</italic> and sensory uncertainty <italic>r</italic> have very similar effects on mean RT and, thus, are interchangeable in many conditions (cf. [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>]). To verify this relationship we repeated fitting of the data used here, but fixed <italic>r</italic> = <italic>s</italic> and allowed <italic>λ</italic> to vary. With this parameterisation, we could fit behaviour for high and intermediate coherences equally well, but observed a drop in quality of fit for low coherences (0% and 3.2%, results not shown).</p>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>We have embedded an attractor model into a Bayesian framework, resulting in a novel Bayesian attractor model (BAttM) for perceptual decision making. The model can be used as an analysis tool to fit choices and response times of subjects in standard perceptual decision making tasks (<xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>, <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>). It also extends to re-decision tasks where the participant has to detect stimulus changes and make another decision (<xref ref-type="fig" rid="pcbi.1004442.g007">Fig 7</xref>). In addition, the model predicts state-dependent, within-trial gain modulation of sensory processing by top-down feedback of the decision state (<xref ref-type="disp-formula" rid="pcbi.1004442.e029">Eq 8</xref>, <xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8</xref>). This top-down gain modulation enables an explicit measure of confidence in decisions (<xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10</xref>) that reproduces recent experimental findings about confidence judgements in perceptual decision tasks (<xref ref-type="fig" rid="pcbi.1004442.g011">Fig 11</xref>).</p>
<sec id="sec015">
<title>Re-decisions</title>
<p>In typical perceptual decision making experiments, e.g. [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], the response of the participant automatically ends a trial and the stimulus disappears. In natural conditions, however, an object typically does not disappear after the brain has made its categorisation and the object should be represented as long as it is behaviourally relevant. In addition, the brain has to be able to rapidly update a decision in response to a change in the environment, for example, when a green traffic light turns red. These decisions, which we called re-decisions, are currently rather not considered by perceptual decision making models. In particular, drift-diffusion and similar probabilistic models of perceptual decisions are not good models for behaviour in response to stimuli that switch occasionally. This is simply because the amount of accumulated evidence for a decision depends on the time the stimulus supporting the decision is observed: To switch to the alternative decision, this accumulated evidence must be overcome by an equal amount of evidence in favour of the alternative. This means that the reaction time in response to a switch would depend on how long the previous stimulus was shown. If the previous stimulus was present for several seconds, standard drift-diffusion and related models predict that the reaction time for a switch would be several seconds as well. This would clearly depart from the expected decision behaviour of participants with typical reaction times of several hundred milliseconds.</p>
<p>Pure attractor models, on the other hand, provide a basis for successful re-decisions: Once the decision state is in a fixed point no additional evidence is accumulated. Consequently, only a fixed amount of evidence for the alternative category is required to reverse an initial decision by moving the decision state into a different attractor [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>]. The BAttM enhances this property through its embedding in a probabilistic framework: It provides a single, interpretable parameter, the dynamics uncertainty <italic>q</italic> (cf. <xref ref-type="table" rid="pcbi.1004442.t001">Table 1</xref>), that controls the timing of re-decisions independently of the timing of initial decisions and, thus, implements a tradeoff between flexible and stable decisions (Figs <xref ref-type="fig" rid="pcbi.1004442.g007">7</xref>, <xref ref-type="fig" rid="pcbi.1004442.g009">9C</xref>).</p>
<p>Note that the drift diffusion model could be extended to allow for re-decisions that do not depend on the duration of the previous stimulus. In a neural model of a drift diffusion process this could be achieved by using neurons with a maximal firing rate. In mathematical formulations based on a stochastic differential equation [<xref ref-type="bibr" rid="pcbi.1004442.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref020">20</xref>], such a maximal firing rate mechanism translates to a condition which would increasingly limit the size of state changes as the maximum state value is approached. To the best of our knowledge, such a mechanism has not been described yet and would reproduce a key feature of attractor models where state changes decrease as a fixed point is approached.</p>
<p>So-called changes of mind [<xref ref-type="bibr" rid="pcbi.1004442.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>] differ from re-decisions. In [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>] a change of mind occurred very quickly to correct an initial decision, that is, without a change of stimulus subjects changed their decision, presumably, in response to stimulus information that was processed just after the initial decision had been made. In contrast, re-decisions can also occur long after a decision that was made with high confidence. Specifically, the model of changes of mind described in [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>] extended a standard drift-diffusion model with an additional bound which only comes into effect after one of the initial bounds has been crossed, that is, after an initial decision has been made. This second bound is only defined for the initially unchosen alternative. Other than in the standard drift-diffusion model, accumulation of evidence continues after the decision. If the second bound is reached within a given deadline, a change of mind is executed. There are two properties of this model which prevent modelling re-decisions in response to a change in stimulus: 1) the deadline and 2) (as described more generally for drift diffusion models above) the dependence of re-decision times on the time of the underlying stimulus switch. The deadline in the change-of-mind model was designed to capture motor costs that prevent a change-of-mind too close to the end of the trial. The deadline, therefore, could simply be dropped in a re-decision experiment. However, the more general drawback of drift diffusion models, i.e., the dependency of re-decisions on the duration of the previous stimulus, would have to be fixed more elaborately (see previous paragraph).</p>
<p>To investigate re-decisions in experiments, standard perceptual decision making paradigms need to be adapted. Especially, single trials need to be prolonged in order to present changing stimuli to the participants and allow them to react to these changes.</p>
</sec>
<sec id="sec016">
<title>Benefits of a probabilistic formulation</title>
<p>As stated above, although there may be differences in detail, pure attractor models can, in principle, explain re-decisions as well. One question is what the BAttM can offer beyond what pure attractor models can do. An important advantage of a probabilistic formulation is that it allows to define confidence measures, as discussed further below. Another crucial advantage is that the BAttM explicitly models how evidence for a decision is extracted from the concrete features of a given stimulus. This means that the BAttM can in principle predict reaction times and choices of the subject given the stimulus features of the actual stimulus shown to the subject in each single trial. Although this may appear as a technical detail, we believe this input model (see <xref ref-type="fig" rid="pcbi.1004442.g003">Fig 3</xref>) is a vital model component. For example, pure attractor models require that the modeller provides the evidence input. This ‘manual’ specification of the evidence input is not necessarily an advantage because the exact shape of the input is a key to explain the data. This would make the manual input specification an important but rather ill-constrained component of the model as there is no measure of the degrees of freedom spent on the input specification. In contrast, the BAttM explicitly constrains evidence computation via the Bayesian update equations. As a result, stimulus features shown to the subject enter the behavioural analysis in a highly constrained fashion. This formally described evidence computation also defines the top-down modulation predicted by the BAttM, as discussed next.</p>
</sec>
<sec id="sec017">
<title>Uncertainty and top-down modulation</title>
<p>In the BAttM, there are two different ways how top-down gain modulation of sensory processing emerges. The first depends on the sensory uncertainty <italic>r</italic>, which we implicitly assume here is a between-trial effect because most experiments keep the amplitude of the sensory noise constant over a trial, but see ‘Adapting stimulus expectations’ below for a discussion of this assumption. The second gain effect varies due to the dynamics of the internal decision state, which is a within-trial modulation.</p>
<p>The between-trial gain modulation offers a novel understanding of variations in reaction times caused by varying stimulus noise level. In explanations of perceptual decision making it is generally assumed that stronger stimuli, i.e., with higher signal-to-noise ratio, translate into larger pieces of evidence which lead to faster accumulation [<xref ref-type="bibr" rid="pcbi.1004442.ref001">1</xref>]. The BAttM makes this translation explicit and models higher stimulus strength by less observation noise <italic>s</italic> and correspondingly less sensory uncertainty <italic>r</italic> (<xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>, <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>). A key prediction of the BAttM is that different speeds of evidence accumulation, e.g., across task difficulty levels, are caused by different amounts of top-down gain modulation: the lower the sensory uncertainty, the higher the gain of sensory input (<xref ref-type="disp-formula" rid="pcbi.1004442.e011">Eq 5</xref>). Such a top-down mechanism has been described in general by proponents of the Bayesian brain hypothesis [<xref ref-type="bibr" rid="pcbi.1004442.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref060">60</xref>], the free energy principle [<xref ref-type="bibr" rid="pcbi.1004442.ref061">61</xref>] and predictive coding [<xref ref-type="bibr" rid="pcbi.1004442.ref062">62</xref>]. In particular, it has been suggested that internal uncertainty is tightly linked to neuronal modulator mechanisms [<xref ref-type="bibr" rid="pcbi.1004442.ref063">63</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref065">65</xref>] that implement attentional, top-down modulation of sensory areas [<xref ref-type="bibr" rid="pcbi.1004442.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref058">58</xref>].</p>
<p>In addition to these between-trial effects, experimental findings prompted the suggestion that sensory gain may be modulated within-trial by the state of an ongoing decision [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref053">53</xref>]. Drift-diffusion and pure attractor models do not account for such top-down modulation of gain, because there is no top-down connection from decision state to sensory input in these models. In the BAttM, however, this connection is provided by the state-dependent Kalman gain, see Eqs (<xref ref-type="disp-formula" rid="pcbi.1004442.e029">8</xref>, <xref ref-type="disp-formula" rid="pcbi.1004442.e011">5</xref>). In particular, the BAttM predicts that sensory gain is large when transitioning between decision alternatives and small when the decision is imminent or has been made (<xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8</xref>). This modulation is driven by the cross-covariance between predicted observations and decision states (<xref ref-type="fig" rid="pcbi.1004442.g008">Fig 8</xref>). Intuitively, this cross-covariance measures what changes can be expected on the observation level due to a change of the decision state, or, inversely, what changes in the decision state are likely to explain changes on the observation level. Therefore, the described formalism underlying within-trial gain modulation differs from the between-trial modulation which is purely based on changes in sensory uncertainty.</p>
<p>Previous experiments [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref053">53</xref>] showed only coarse-grained evidence for decision-dependent modulation of activity in sensory areas, or are currently difficult to translate into our formalisation due to the type of measurement [<xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>]. Therefore, further research is needed to test the hypothesis of specific temporal structure of gain modulation as predicted by the BAttM. Note that the BAttM was not designed by us to employ such a state-dependent top-down modulatory mechanism; rather, this property emerges from the Bayesian formulation in which decision states explicitly connect to particular sensory observations. Furthermore, the gain modulation in the BAttM has two functional benefits: First, it leads to a common, stable representation of the decision across task difficulties while still allowing decisions to be made with varying accuracy and timing. This is not the case for pure attractor models (<xref ref-type="fig" rid="pcbi.1004442.g009">Fig 9</xref>) but is useful for a neuronal implementation because the next higher level can more easily read out a stable representation. Second, within-trial gain modulation facilitates rapid updating of decisions in response to a changed stimulus, because it quickly destabilises a made decision when sufficient evidence to the contrary is available. Consequently, the increased gain speeds up the transition to an alternative decision. Note that the initial movement out of a fixed point that represents a previously made decision is mediated by prediction errors (<xref ref-type="disp-formula" rid="pcbi.1004442.e029">Eq 8</xref>) which tend to be large when the decision deviates from the real stimulus and small otherwise.</p>
<p>Although there are some reports of potential within-trial top-down gain modulation [<xref ref-type="bibr" rid="pcbi.1004442.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref053">53</xref>], the formalism implemented by the BAttM is, at the current time point, a purely theoretical prediction which may be tested in future experimental work. Diffusion models often successfully explain decision behaviour without using top-down feedback mechanisms. Therefore, it may appear that the brain does not use top-down feedback when making simple perceptual decisions. However, a simple experiment testing the existence of top-down modulation may proceed as follows: Participants would be cued about the upcoming stimulus strength only in some trials but not in others. If the predictive cue had an effect on decisions, the BAttM would predict that this was partially due to between-trial top-down modulation through updated expectations of the participants. It is harder to test the existence of within-trial top-down modulation that discriminates the BAttM from pure attractor and diffusion models. Novel tasks may be required to elicit measurable effects of such within-trial top-down modulation. For example, the BAttM predicts that top-down modulation varies strongly in experiments with longer trials including re-decisions. In addition, the BAttM could be used to test this particular question by removing within-trial top-down gain modulation in the model and comparing choices predicted from this reduced model with those predicted from the full BAttM.</p>
</sec>
<sec id="sec018">
<title>Confidence-based decisions</title>
<p>“It has been definitely shown that the recognition process is attended by varying degrees of confidence; that the correctness of recognition tends to vary directly with the degree of confidence, and that our belief-attitudes appear with varying degrees of strength, or varying degrees of confidence, assurance, or certainty.” [<xref ref-type="bibr" rid="pcbi.1004442.ref066">66</xref>] Since 1926 this account has been consolidated and given a theoretical basis [<xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>]. More recently, behavioural paradigms were developed in which confidence could be measured from non-verbal responses [<xref ref-type="bibr" rid="pcbi.1004442.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref067">67</xref>]. These developments have been accompanied by extensions of drift-diffusion and attractor models that explain measured confidence ratings: For drift-diffusion models explicit confidence values can be computed as function of the decision variable and time [<xref ref-type="bibr" rid="pcbi.1004442.ref067">67</xref>] under the assumption that subjects’ confidence equals their true probability of making an error, but see [<xref ref-type="bibr" rid="pcbi.1004442.ref068">68</xref>]. Alternatively, the decision variable itself can be related to subjective confidence in the drift-diffusion model [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>]. In pure attractor models, the decision state has been related to confidence judgements only indirectly: The increasing magnitudes of the decision state at the fixed point locations for increasing stimulus strengths (cf. <xref ref-type="fig" rid="pcbi.1004442.g009">Fig 9A</xref>) have been interpreted as increasing confidence in the decision [<xref ref-type="bibr" rid="pcbi.1004442.ref059">59</xref>]. This account assumes that the decision state continues to evolve towards the fixed points of the dynamics after the decision threshold has been reached.</p>
<p>Other than both drift-diffusion and pure attractor models, the BAttM computes an explicit (i.e., in addition to the decision state) and ongoing measure of confidence based on subjective uncertainties of the decision maker (see <xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10</xref> and <xref ref-type="fig" rid="pcbi.1004442.g004">Fig 4</xref>). This enables us to model confidence-based decisions using a threshold on the ongoing confidence (<xref ref-type="fig" rid="pcbi.1004442.g010">Fig 10B</xref>) which, in the BAttM, is defined as the posterior density that the decision state is in a stable fixed point of the generative model (cf. <xref ref-type="disp-formula" rid="pcbi.1004442.e024">Eq 6</xref> in Methods). This posterior density can be interpreted as the decision maker’s internal belief that a category is the true category of the stimulus and can be easily computed from the estimated posterior over the decision state for an arbitrary number of alternatives. Note that the threshold on confidence may be implemented by a simple threshold on firing rates of neurons that represent the corresponding posterior density. As a density, however, it cannot be expressed in percent and, therefore, lacks an intuitive connection to typical measures of confidence in behavioural experiments. This connection may instead be provided by alternative measures of confidence that can also be derived from the posterior distribution over the decision state. For example, one can compute, as a measure of confidence, the probability that any one of the decision state variables exceeds all other state variables. This probability can be expressed in percent. It is possible that subjects compute such a measure when asked to explicitly report confidence after the decision, but it is an open experimental question how to identify forms of confidence judgements actually used by the brain.</p>
<p>As the BAttM uses a threshold on the confidence to make a decision, the confidence at decision time is always equal to the threshold. This fact appears to contradict key experimental findings showing a dependence of confidence judgements on decision outcome and stimulus strength [<xref ref-type="bibr" rid="pcbi.1004442.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref043">43</xref>]. Yet, this apparent mismatch can be resolved (<xref ref-type="fig" rid="pcbi.1004442.g011">Fig 11</xref>) simply by continuing accumulation of evidence during part of the non-decision time period. This continued accumulation is motivated by a corresponding assumption in [<xref ref-type="bibr" rid="pcbi.1004442.ref059">59</xref>] and by recent experimental findings regarding changes-of-mind in decision making [<xref ref-type="bibr" rid="pcbi.1004442.ref035">35</xref>]. It has also been shown that a wide range of findings about confidence ratings can be replicated under the assumption that evidence accumulation continues until the confidence rating [<xref ref-type="bibr" rid="pcbi.1004442.ref069">69</xref>]. In further congruence, potential neural correlates of continued processing of the stimulus after reaching a threshold were reported in [<xref ref-type="bibr" rid="pcbi.1004442.ref070">70</xref>].</p>
<p>Furthermore, the BAttM predicts direct, intuitive relations between the internal uncertainties of a decision maker and the absolute level of confidence that can be reached: Larger uncertainties lead to smaller confidence (e.g., see <xref ref-type="fig" rid="pcbi.1004442.g004">Fig 4</xref>). As these uncertainties simultaneously control choices, response times and re-decision times, we propose to validate the consistency of these predicted relations in future experiments.</p>
</sec>
<sec id="sec019">
<title>Interpretation of the fit to [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]</title>
<p>We fitted the BAttM to average behaviour reported in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] and found that the BAttM explains decision making behaviour well (<xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12B and 12C</xref>) even though we assumed a simplified representation of the stimulus (cf. section input). This was expected, because 1) a similar, abstract stimulus representation was sufficient to fit behavioural data (of humans) before [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>] and 2) [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] originally used a similar computational representation to fit a drift-diffusion model to the data considered here.</p>
<p>For the BAttM, estimates of the reliability of parameter fits indicate that fitted parameter values are highly reliable for experimental conditions in which subjects exhibit intermediate accuracy in response to coherences from 3.2% to 12% (<xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>). In these conditions our fits suggest that the noise level <italic>s</italic> exceeded sensory uncertainty <italic>r</italic> in the subjects which would mean that the subjects’ generative model of the stimulus underestimated the amount of noise in the stimulus. In contrast, an optimal Bayesian decision maker should have a generative model in which, ideally, <italic>r</italic> would equal <italic>s</italic>. It has been proposed that variability in subjects’ responses may be due to suboptimal inference [<xref ref-type="bibr" rid="pcbi.1004442.ref071">71</xref>], that is, inference based on suboptimal, or wrong assumptions about the underlying statistical structure of the inference problem. Our observation that <italic>s</italic> exceeds <italic>r</italic> suggests that subjects indeed perform suboptimal inference in the corresponding choice task. This finding, however, only holds under the assumption that the confidence threshold is set to a constant, low value (<italic>λ</italic> = 0.02), because <italic>r</italic> and <italic>λ</italic> have very similar effects on accuracy and mean RT. Indeed, we also found that behaviour in most conditions could be fit equally well, when <italic>r</italic> was constrained to be equal to <italic>s</italic>, but <italic>λ</italic> was allowed to vary freely. Although the drop in quality of fit for coherences 0% and 3.2% (cf. results) indicates a disadvantage of the constraint <italic>s</italic> = <italic>r</italic> compared to the constraint <italic>λ</italic> = 0.02 we cannot draw definite conclusions about whether subjects perform suboptimal inference, or not, from the present data.</p>
<p>For coherences above about 25% parameter estimates became less reliable (<xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>), because accuracy reached its ceiling of 1 and became uninformative. We expect that parameter estimates become more reliable in these experimental conditions, if reaction time distributions are used for fitting instead of only mean reaction times [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>].</p>
<p>In the original fits of behaviour in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] the drift was constrained to be a linear function of coherence ([<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], Supp. Fig. 6), where a single parameter, the slope of the linear function replaced coherence-specific drifts. In contrast, in our fits of the BAttM to the same data we allowed both, sensory uncertainty <italic>r</italic> and noise level <italic>s</italic>, to freely vary across coherences. Although this increased flexibility of the BAttM, in principle, could have led to overfitting, it is unlikely that this is the case for our results: The noise in the data is small compared to the effect of the coherence, because the data are averages based on 15,937 trials ([<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], <xref ref-type="fig" rid="pcbi.1004442.g001">Fig 1</xref>). The low variance of parameter estimates for intermediate coherences (<xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12A</xref>) also indicates that our fitting method identified unique parameter values for these coherences. Furthermore, by relating the sensory uncertainty parameter in our fits to drift in the drift diffusion model [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>], we observed that the fitted values of sensory uncertainty <italic>r</italic> obey the linear constraint employed by [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] for coherences of up to 25% without explicitly using this constraint during fitting. It is currently unclear why the parameters for high coherences do not follow the previously assumed linear relation between drift and coherence. One possible explanation is that the urgency signal, which we did not model in the BAttM, has a larger effect for high coherences than for low ones. The estimated shape of the urgency signal ([<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], Supp. Fig. 6b) supports this speculation, because it exhibits a steep rise early in a trial such that its effect should be relatively large for fast decisions. However, clearly further research is required to substantiate this potential mechanism.</p>
</sec>
<sec id="sec020">
<title>Adapting stimulus expectations</title>
<p>The BAttM explains different behaviour in response to stimuli with different strength using particular combinations of input noise level <italic>s</italic> and sensory uncertainty <italic>r</italic> (<xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>, <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>). It, therefore, appears that decision makers adapt their expectations about the stimulus (<italic>r</italic>) to stimulus strength even before they experience the stimulus (we fixed <italic>r</italic> within trials). In experiments in which trials with the same stimulus strength are blocked, or in which stimulus strength is cued before onset of the stimulus, this is plausible. In experiments in which stimulus strength changes randomly across trials, this assumption seems flawed. This consideration has led others to discuss whether the brain implements Bayesian models [<xref ref-type="bibr" rid="pcbi.1004442.ref072">72</xref>]. Here, we speculate that decision makers rapidly adapt their expectations in parallel with decision making as they sample observations from the stimulus. Such adaptation is compatible with the timescale of short-term synaptic plasticity in the brain [<xref ref-type="bibr" rid="pcbi.1004442.ref073">73</xref>]. Also, it has previously been demonstrated that sensory reliability (akin to <italic>r</italic>) can be inferred together with stimulus identity in a Bayesian model [<xref ref-type="bibr" rid="pcbi.1004442.ref025">25</xref>].</p>
<p>Even though we believe that decision makers adapt their stimulus expectations within a trial, the BAttM currently does not employ such a mechanism. Nevertheless, assuming fixed <italic>r</italic> led to good fits of accuracy and mean RTs as recorded in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] (cf. <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>). This is not very surprising: The behavioural data has originally been fit by a drift-diffusion model with constant drift throughout a trial [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]. Such constant drift implements the assumption that the <italic>average</italic> amount of evidence extracted from the stimulus at a given moment is constant throughout the trial. Critically, the ‘evidence’ is not a fundamental, sensory quantity, but needs to be computed by the brain specifically for the given decision problem. It can further be shown [<xref ref-type="bibr" rid="pcbi.1004442.ref023">23</xref>] that ‘evidence’ depends on sensory uncertainty in probabilistic models. Therefore, the assumption of a constant drift throughout a trial is, in the BAttM, equivalent to maintaining stable expectations about the stimulus throughout the trial. As a result, keeping <italic>r</italic> fixed in the BAttM is a simplification that follows previous approaches based on drift diffusion models and still allows to fit behaviour (accuracy and mean RTs) of subjects well (see <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>). Similar to within-trial effects of top-down gain modulation, however, future work may aim at elucidating potential effects of within-trial variations in expected sensory uncertainty <italic>r</italic> due to adaptation of stimulus expectations. In particular, experiments with longer re-decision trials and continuously changing stimulus reliability may induce strong adaptations of stimulus expectations that have measurable behavioural effects.</p>
</sec>
<sec id="sec021">
<title>Bayesian inference and neurobiological implementation</title>
<p>One of the strengths of the original pure attractor models is their link to possible neurobiological implementations in networks of spiking neurons (cf. Section: pattm). We have abstracted from this perspective and have embedded a pure attractor model in a dynamic Bayesian inference framework. Consequently, the question arises how this apparently more complicated construct may map to a neurobiological substrate. The BAttM is a probabilistic filter that recursively updates posterior beliefs by evaluating the likelihood of the state of a dynamic generative model given a stream of observations (cf. models). A wide range of proposals have been made for how probabilistic filters can be implemented by networks of neurons [<xref ref-type="bibr" rid="pcbi.1004442.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref081">81</xref>]. For example, [<xref ref-type="bibr" rid="pcbi.1004442.ref080">80</xref>] discusses how computations defined by predictive coding approaches, which derive from probabilistic filters (cf. Section Bayesinf), can map onto canonical microcircuits in cortex. More abstractly, [<xref ref-type="bibr" rid="pcbi.1004442.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref077">77</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref079">79</xref>] show how networks of rate neurons may implement probabilistic filters and [<xref ref-type="bibr" rid="pcbi.1004442.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1004442.ref076">76</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref078">78</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref081">81</xref>] provide implementations based on spiking neuron networks. Given these proposals, it seems reasonable to assume that the computations defined by the BAttM can be implemented by the brain.</p>
</sec>
<sec id="sec022">
<title>Conclusion</title>
<p>We have presented a novel perceptual decision making model, the Bayesian attractor model, which combines attractor dynamics with a probabilistic formulation of decision making. The model captures important behavioural findings and makes novel predictions that can be tested in future experiments. In particular, we have highlighted a re-decision paradigm which can be used to investigate the tradeoff between flexibility and stability in perceptual decisions. Furthermore, the BAttM predicts particular, within-trial modulation of sensory gain which may explain recent experimental findings. Finally, the BAttM predicts experimentally testable links between choice, response times and confidence.</p>
</sec>
</sec>
<sec id="sec023" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec024">
<title>Hopfield dynamics</title>
<p>We used a Hopfield network as an example of a pure attractor model. Hopfield networks have originally been suggested as a neurobiologically plausible firing-rate models of recurrently connected neurons [<xref ref-type="bibr" rid="pcbi.1004442.ref044">44</xref>]. We define a general Hopfield network with <italic>N</italic> state variables as follows (here summarised in one equation using matrix notation, see <xref ref-type="fig" rid="pcbi.1004442.g013">Fig 13</xref> for a graphical representation of the binary case <italic>N</italic> = 2):
<disp-formula id="pcbi.1004442.e034"><alternatives><graphic id="pcbi.1004442.e034g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e034"/><mml:math id="M34" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">L</mml:mi> <mml:mi mathvariant="bold-italic">σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>b</mml:mi> <mml:mrow><mml:mi>l</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>g</mml:mi> <mml:mn mathvariant="bold">1</mml:mn> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
where <bold>z</bold> ∈ ℝ<sup><italic>N</italic></sup> is the decision state consisting of the state variables <italic>z</italic><sub><italic>i</italic></sub>, <italic>k</italic> is a rate constant, <bold><italic>σ</italic></bold>(⋅) is a multidimensional logistic sigmoid function and <italic>b</italic><sup><italic>lin</italic></sup> is a parameter determining the strength of a goal state attractor <bold>g</bold> = <italic>g</italic><bold>1</bold>. Lateral inhibition for winner-take-all dynamics is implemented using
<disp-formula id="pcbi.1004442.e035"><alternatives><graphic id="pcbi.1004442.e035g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e035"/><mml:math id="M35" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>o</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mspace width="2.em"/><mml:mtext>and</mml:mtext> <mml:mspace width="2.em"/><mml:mi mathvariant="bold">L</mml:mi> <mml:mo>=</mml:mo> <mml:msup><mml:mi>b</mml:mi> <mml:mrow><mml:mi>l</mml:mi> <mml:mi>a</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">I</mml:mi> <mml:mo>-</mml:mo> <mml:mn mathvariant="bold">1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
where <italic>r</italic> and <italic>o</italic> determine the slope and centre of the sigmoid function, respectively, <italic>b</italic><sup><italic>lat</italic></sup> determines the strength of the lateral inhibition, <bold>1</bold> ∈ ℝ<sup><italic>N</italic>×<italic>N</italic></sup> is a matrix of ones, and <bold>I</bold> is the identity matrix. One can see that the fixed points with one state variable <italic>z</italic><sub><italic>m</italic></sub> ≈ <italic>g</italic>, while all others are <italic>z</italic><sub><italic>j</italic> ≠ <italic>m</italic></sub> ≈ 0, are local minima of the underlying Lyapunov function and therefore stable [<xref ref-type="bibr" rid="pcbi.1004442.ref044">44</xref>] provided that <italic>o</italic> = <italic>g</italic> and <italic>b</italic><sup><italic>lat</italic></sup>/<italic>b</italic><sup><italic>lin</italic></sup> = 2<italic>g</italic>. We denote these stable fixed points as <italic>ϕ</italic><sub><italic>m</italic></sub> where <italic>m</italic> indicates the state variable that is equal to <italic>g</italic>. As parameter values we used <italic>k</italic> = 4, <italic>g</italic> = 10, <italic>r</italic> = 1, <italic>o</italic> = <italic>g</italic>, <italic>b</italic><sup><italic>lat</italic></sup> = 1.7, <italic>b</italic><sup><italic>lin</italic></sup> = <italic>b</italic><sup><italic>lat</italic></sup>/(2<italic>g</italic>) in all experiments, because these provided for numerically stable Hopfield dynamics which exhibited the desired fixed points and reasonably fast convergence to these. For interpolating observations in the generative model (<xref ref-type="disp-formula" rid="pcbi.1004442.e003">Eq 3</xref>) we use the same form of sigmoid as defined in <xref ref-type="disp-formula" rid="pcbi.1004442.e035">Eq (10)</xref>, but with parameters <italic>r</italic> = 0.7, <italic>o</italic> = <italic>g</italic>/2. This choice increases the range of values for which the sigmoid is approximately linear and increases robustness of the inference with the generative model.</p>
<fig id="pcbi.1004442.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004442.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Network diagram for two-alternative Hopfield network (cf. Eqs <xref ref-type="disp-formula" rid="pcbi.1004442.e034">9</xref>, <xref ref-type="disp-formula" rid="pcbi.1004442.e035">10</xref>) with interpolated output that was used as generative model.</title>
<p>The network is driven by constant input <italic>g</italic> modulated by self and lateral inhibition between state variables <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub>. The strength of inhibition between state variables is determined by <italic>b</italic><sup><italic>lat</italic></sup> (note that self-inhibition is not linear, but moderated by a sigmoid function <bold><italic>σ</italic></bold>(<bold>z</bold>)) while the strength of self-inhibition and the strength of the constant input is controlled by <italic>b</italic><sup><italic>lin</italic></sup>. After passing through another sigmoid function <bold><italic>σ</italic></bold>(<bold>z</bold>) the state variables interpolate target positions (cf. description of single dot task above) stored in <bold>M</bold> and consequently produce the (mean) prediction <bold><italic>μ</italic></bold>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004442.g013"/>
</fig>
</sec>
<sec id="sec025">
<title>Initial decision state</title>
<p>When modelling perceptual decisions, we follow [<xref ref-type="bibr" rid="pcbi.1004442.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004442.ref028">28</xref>] and initialise the attractor dynamics in a neutral state. In particular, we set a prior distribution over the decision state as <bold>z</bold><sub>0</sub> ∼ 𝓝(<bold><italic>μ</italic></bold><sub>0</sub>,<bold>P</bold><sub>0</sub>) where <bold><italic>μ</italic></bold><sub>0</sub> is an unstable equilibrium point of the Hopfield dynamics for which
<disp-formula id="pcbi.1004442.e036"><alternatives><graphic id="pcbi.1004442.e036g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e036"/><mml:math id="M36" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>μ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="0.277778em"/><mml:mtext>and</mml:mtext> <mml:mspace width="0.277778em"/><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mspace width="1.em"/><mml:mo>∀</mml:mo> <mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mo>⋯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>N</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula>
This starting point ensures that a relatively long time is spent close to the equilibrium, while once the dynamics has sufficiently differentiated, the decision state will rapidly move to its closest stable fixed point. We set the covariance of the initial decision state to <inline-formula id="pcbi.1004442.e037"><alternatives><graphic id="pcbi.1004442.e037g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e037"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mtext mathvariant="bold">P</mml:mtext> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mn>0</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mtext mathvariant="bold">I</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> and call <italic>p</italic><sub>0</sub> the initial state uncertainty which is a parameter of the model that controls the susceptibility of the decision state to incoming evidence at the beginning of a trial.</p>
</sec>
<sec id="sec026">
<title>Approximated contour lines</title>
<p>In <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref> we plotted contour lines. These were approximated from the noisy data points underlying the grey scale maps as follows. We defined four values for four contours for each map as reported in the caption of <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>. For each value, e.g., 500ms, we found all points in the parameter grid for which their own associated value lay within a limit to the chosen contour value (limit of 0.01 fraction correct and of 10ms). We then fitted the hyperparameters of a Gaussian process [<xref ref-type="bibr" rid="pcbi.1004442.ref082">82</xref>] to the found points in log<italic>r</italic>-log<italic>s</italic> space (one per contour line) using the GPML Matlab toolbox (<ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://mloss.org/software/view/263/">http://mloss.org/software/view/263/</ext-link>). In particular, the Gaussian process mapped the logarithm of the noise level, log<italic>s</italic>, onto the logarithm of the sensory uncertainty, log<italic>r</italic> and used a standard squared exponential covariance function with a Gaussian likelihood [<xref ref-type="bibr" rid="pcbi.1004442.ref082">82</xref>]. The contour lines in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref> represent the mean predictions of sensory uncertainty obtained from the fitted Gaussian processes for the corresponding noise level.</p>
</sec>
<sec id="sec027">
<title>Fitting of data in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]</title>
<p>To fit the data from the experiment reported in [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] we defined a temporal scaling between our discrete model and the times recorded during the experiment. This scaling corresponds to Δ<italic>t</italic> = 4ms in <xref ref-type="disp-formula" rid="pcbi.1004442.e002">Eq (2)</xref>. It was chosen as a tradeoff between sufficiently small discretisation steps and computational efficiency and means that about 200 time steps are sufficient to cover the full range of reaction times observed by [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>]. Furthermore, we used a non-decision time of <italic>T</italic><sub>0</sub> = 200ms which is roughly the value that was estimated by [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] (cf. their <xref ref-type="table" rid="pcbi.1004442.t001">Table 1</xref>). The non-decision time captures delays that are thought to be independent of the time that it takes to make a decision. These delays may be due to initial sensory processing, or due to the time that it takes to execute a motor action.</p>
<p>We used a form of stochastic optimisation based on a Markov Chain Monte Carlo (MCMC) method to find parameter values that best explained the observed behaviour in the experiment for each coherence level independently. This was necessary, because we could not analytically predict accuracy and mean reaction times from the model and had to simulate from the model to estimate these quantities. In particular, we simulated 1,000 trials per estimate of accuracy and mean RT, as done to produce <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>. We then defined an approximate Gaussian log-likelihood of the parameter set used for simulation by using the estimated values as means:
<disp-formula id="pcbi.1004442.e038"><alternatives><graphic id="pcbi.1004442.e038g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e038"/><mml:math id="M38" display="block" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>R</mml:mi> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi> <mml:mi>T</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>R</mml:mi> <mml:mi>T</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
where <italic>A</italic> and <italic>RT</italic> are the accuracy and mean RT, respectively, measured in the experiment for one of the coherences and <inline-formula id="pcbi.1004442.e039"><alternatives><graphic id="pcbi.1004442.e039g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e039"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>A</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004442.e040"><alternatives><graphic id="pcbi.1004442.e040g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004442.e040"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mrow><mml:mi>R</mml:mi> <mml:mi>T</mml:mi></mml:mrow> <mml:mo accent="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> are estimates from the model. <italic>σ</italic><sub><italic>A</italic></sub> = 0.05 and <italic>σ</italic><sub><italic>RT</italic></sub> = 10ms are ad-hoc estimates of the standard deviation of the estimates which we chose large enough to account for the variability we observed in the data of <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>. <italic>P</italic>(<italic>s</italic>,<italic>r</italic>) is a penalty function which returned values greater than 10,000, when more than half of the simulated trials were timed out (cf. light blue areas in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>) and when the particular combination of <italic>s</italic> and <italic>r</italic> lead to too strong overshoots of a state variable (cf. <xref ref-type="fig" rid="pcbi.1004442.g005">Fig 5A</xref>). We identified overshoot parameters as those which lay below a straight line from <italic>r</italic> = 0.47, <italic>s</italic> = 1.45 to <italic>r</italic> = 3.66, <italic>s</italic> = 80 in <xref ref-type="fig" rid="pcbi.1004442.g006">Fig 6</xref>. We embedded the approximate likelihood of <xref ref-type="disp-formula" rid="pcbi.1004442.e038">Eq (12)</xref> into the DRAM method of [<xref ref-type="bibr" rid="pcbi.1004442.ref083">83</xref>] (Matlab mcmcstat toolbox available at <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://helios.fmi.fi/~lainema/mcmc/">http://helios.fmi.fi/~lainema/mcmc/</ext-link>) which implements adaptive Metropolis-Hastings sampling with delayed rejection. We log-transformed the parameters to ensure that only positive samples are generated and defined wide Gaussian priors in this log-space (log<italic>s</italic> ∼ 𝓝(0,10<sup>2</sup>), log<italic>r</italic> ∼ 𝓝(0,10<sup>2</sup>)), but also constrained <italic>s</italic> &gt; 0.1 to ensure a minimum level of noise. We then ran the MCMC method for 3,000 samples, discarded the first 499 samples and chose every 5th sample to reduce correlations within the Markov chain. The resulting set of 501 parameter samples is a rough approximation of the posterior distribution over parameters for the given data. It is not statistically exact, because of the approximate likelihood, but it still indicates when parameter estimates become unreliable, as demonstrated in <xref ref-type="fig" rid="pcbi.1004442.g012">Fig 12</xref>. The parameter values reported in <xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref> are those of the sample (of the 501) which fitted the behaviour for a given coherence best, as determined by <xref ref-type="disp-formula" rid="pcbi.1004442.e038">Eq (12)</xref>.</p>
<p>Note that, different from [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], we did not a priori assume a particular relationship between coherence and the parameters of the BAttM during fitting. In [<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>] coherence linearly scaled the drift in their drift-diffusion model using a scaling parameter <italic>K</italic> that was common across coherences ([<xref ref-type="bibr" rid="pcbi.1004442.ref054">54</xref>], Supp. Fig. 6), that is, the average amount of momentary evidence accumulated in the model was determined from the coherence used in a trial. In the BAttM the fitted parameters, sensory uncertainty <italic>r</italic> and noise level <italic>s</italic>, determine how stimulus features are translated into momentary evidence. Since we did not want to assume, a priori, a specific relationship between the level of coherence and parameters <italic>s</italic> and <italic>r</italic>, we chose to let the parameters vary independently of coherence during fitting. However, we investigated whether an equivalent relation between <italic>r</italic> and coherence holds for the fitted values of <italic>r</italic>. As stated in the main text, this relation can be written as <italic>r</italic><sup>2</sup> = <italic>K</italic>′/<italic>c</italic> where <italic>c</italic> is coherence and <italic>K</italic>′ is an arbitrary constant. Consequently, we used a least-squares approach to estimate <italic>K</italic>′ from given pairs of coherence (in %) and sensory uncertainty <italic>r</italic> (<xref ref-type="table" rid="pcbi.1004442.t002">Table 2</xref>). The best fitting value was <italic>K</italic>′ = 381.9. As suggested by one reviewer, it may be useful to assume the above relation between <italic>r</italic><sup>2</sup> and <italic>c</italic> as a constraint when fitting noisy data. This can be easily done by fitting <italic>K</italic>′ to the data across coherences instead of directly fitting one <italic>r</italic> per coherence.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004442.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2007</year>) <article-title>The neural basis of decision making</article-title>. <source>Annual Review of Neuroscience</source> <volume>30</volume>: <fpage>535</fpage>–<lpage>574</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.29.051605.113038" xlink:type="simple">10.1146/annurev.neuro.29.051605.113038</ext-link></comment> <object-id pub-id-type="pmid">17600525</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Britten</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>1992</year>) <article-title>The analysis of visual-motion—a comparison of neuronal and psychophysical performance</article-title>. <source>Journal of Neuroscience</source> <volume>12</volume>: <fpage>4745</fpage>–<lpage>4765</lpage>. <object-id pub-id-type="pmid">1464765</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Pare</surname> <given-names>EB</given-names></name> (<year>1988</year>) <article-title>A selective impairment of motion perception following lesions of the middle temporal visual area (mt)</article-title>. <source>Journal of Neuroscience</source> <volume>8</volume>: <fpage>2201</fpage>–<lpage>2211</lpage>. <object-id pub-id-type="pmid">3385495</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Pilly</surname> <given-names>PK</given-names></name>, <name name-style="western"><surname>Seitz</surname> <given-names>AR</given-names></name> (<year>2009</year>) <article-title>What a difference a parameter makes: a psychophysical comparison of random dot motion algorithms</article-title>. <source>Vision Res</source> <volume>49</volume>: <fpage>1599</fpage>–<lpage>1612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2009.03.019" xlink:type="simple">10.1016/j.visres.2009.03.019</ext-link></comment> <object-id pub-id-type="pmid">19336240</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>John</surname> <given-names>ID</given-names></name> (<year>1967</year>) <article-title>A statistical decision theory of simple reaction time</article-title>. <source>Australian Journal of Psychology</source> <volume>19</volume>: <fpage>27</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/00049536708255558" xlink:type="simple">10.1080/00049536708255558</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Luce</surname> <given-names>RD</given-names></name> (<year>1986</year>) <chapter-title>Response Times: Their Role in Inferring Elementary Mental Organization</chapter-title>. <source>Number 8 in Oxford Psychology Series</source>. <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>McKoon</surname> <given-names>G</given-names></name> (<year>2008</year>) <article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title>. <source>Neural Comput</source> <volume>20</volume>: <fpage>873</fpage>–<lpage>922</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.12-06-420" xlink:type="simple">10.1162/neco.2008.12-06-420</ext-link></comment> <object-id pub-id-type="pmid">18085991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Smith</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name> (<year>2004</year>) <article-title>Psychology and neurobiology of simple decisions</article-title>. <source>Trends Neurosci</source> <volume>27</volume>: <fpage>161</fpage>–<lpage>168</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tins.2004.01.006" xlink:type="simple">10.1016/j.tins.2004.01.006</ext-link></comment> <object-id pub-id-type="pmid">15036882</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roitman</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2002</year>) <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>Journal of Neuroscience</source> <volume>22</volume>: <fpage>9475</fpage>–<lpage>9489</lpage>. <object-id pub-id-type="pmid">12417672</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name> (<year>1996</year>) <article-title>Motion perception: Seeing and deciding</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>93</volume>: <fpage>628</fpage>–<lpage>633</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.93.2.628" xlink:type="simple">10.1073/pnas.93.2.628</ext-link></comment> <object-id pub-id-type="pmid">8570606</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hernàndez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zainos</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name> (<year>2002</year>) <article-title>Temporal evolution of a decision-making process in medial premotor cortex</article-title>. <source>Neuron</source> <volume>33</volume>: <fpage>959</fpage>–<lpage>972</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(02)00613-X" xlink:type="simple">10.1016/S0896-6273(02)00613-X</ext-link></comment> <object-id pub-id-type="pmid">11906701</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hernàndez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zainos</surname> <given-names>A</given-names></name> (<year>2004</year>) <article-title>Neuronal correlates of a perceptual decision in ventral premotor cortex</article-title>. <source>Neuron</source> <volume>41</volume>: <fpage>165</fpage>–<lpage>173</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(03)00817-1" xlink:type="simple">10.1016/S0896-6273(03)00817-1</ext-link></comment> <object-id pub-id-type="pmid">14715143</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Heekeren</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Marrett</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bandettini</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name> (<year>2004</year>) <article-title>A general mechanism for perceptual decision-making in the human brain</article-title>. <source>Nature</source> <volume>431</volume>: <fpage>859</fpage>–<lpage>862</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02966" xlink:type="simple">10.1038/nature02966</ext-link></comment> <object-id pub-id-type="pmid">15483614</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Heekeren</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Marrett</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name> (<year>2008</year>) <article-title>The neural systems that mediate human perceptual decision making</article-title>. <source>Nat Rev Neurosci</source> <volume>9</volume>: <fpage>467</fpage>–<lpage>479</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2374" xlink:type="simple">10.1038/nrn2374</ext-link></comment> <object-id pub-id-type="pmid">18464792</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Siegel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name> (<year>2009</year>) <article-title>Buildup of choice-predictive activity in human motor cortex during perceptual decision making</article-title>. <source>Curr Biol</source> <volume>19</volume>: <fpage>1581</fpage>–<lpage>1585</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2009.07.066" xlink:type="simple">10.1016/j.cub.2009.07.066</ext-link></comment> <object-id pub-id-type="pmid">19747828</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Siegel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name> (<year>2011</year>) <article-title>Cortical network dynamics of perceptual decision-making in the human brain</article-title>. <source>Front Hum Neurosci</source> <volume>5</volume>: <fpage>21</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2011.00021" xlink:type="simple">10.3389/fnhum.2011.00021</ext-link></comment> <object-id pub-id-type="pmid">21427777</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>O’Connell</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Dockree</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Kelly</surname> <given-names>SP</given-names></name> (<year>2012</year>) <article-title>A supramodal accumulation-to-bound signal that determines perceptual decisions in humans</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>: <fpage>1729</fpage>-+. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3248" xlink:type="simple">10.1038/nn.3248</ext-link></comment> <object-id pub-id-type="pmid">23103963</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>de Lange</surname> <given-names>FP</given-names></name>, <name name-style="western"><surname>Rahnev</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>H</given-names></name> (<year>2013</year>) <article-title>Prestimulus oscillatory activity over motor cortex reflects perceptual expectations</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>1400</fpage>–<lpage>1410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1094-12.2013" xlink:type="simple">10.1523/JNEUROSCI.1094-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23345216</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Polanàa</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Krajbich</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Grueschow</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ruff</surname> <given-names>CC</given-names></name> (<year>2014</year>) <article-title>Neural oscillations and synchronization differentially support evidence accumulation in perceptual and value-based decision making</article-title>. <source>Neuron</source> <volume>82</volume>: <fpage>709</fpage>–<lpage>720</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.03.014" xlink:type="simple">10.1016/j.neuron.2014.03.014</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bogacz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Moehlis</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name> (<year>2006</year>) <article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source>Psychol Rev</source> <volume>113</volume>: <fpage>700</fpage>–<lpage>765</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.113.4.700" xlink:type="simple">10.1037/0033-295X.113.4.700</ext-link></comment> <object-id pub-id-type="pmid">17014301</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name> (<year>1978</year>) <article-title>A theory of memory retrieval</article-title>. <source>Psychol Rev</source> <volume>85</volume>: <fpage>59</fpage>–<lpage>108</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.85.2.59" xlink:type="simple">10.1037/0033-295X.85.2.59</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Hanks</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>T</given-names></name> (<year>2006</year>) <chapter-title>The speed and accuracy of a simple perceptual decision: a mathematical primer</chapter-title>. <source>Bayesian brain: Probabilistic approaches to neural coding</source>: <fpage>209</fpage>–<lpage>37</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bitzer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Blankenburg</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name> (<year>2014</year>) <article-title>Perceptual decision making: Drift-diffusion model is equivalent to a bayesian model</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>8</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2014.00102" xlink:type="simple">10.3389/fnhum.2014.00102</ext-link></comment> <object-id pub-id-type="pmid">24616689</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name> (<year>2008</year>) <article-title>Decision theory, reinforcement learning, and the brain</article-title>. <source>Cogn Affect Behav Neurosci</source> <volume>8</volume>: <fpage>429</fpage>–<lpage>453</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/CABN.8.4.429" xlink:type="simple">10.3758/CABN.8.4.429</ext-link></comment> <object-id pub-id-type="pmid">19033240</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Denève</surname> <given-names>S</given-names></name> (<year>2012</year>) <article-title>Making decisions with unknown sensory reliability</article-title>. <source>Front Neurosci</source> <volume>6</volume>: <fpage>75</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnins.2012.00075" xlink:type="simple">10.3389/fnins.2012.00075</ext-link></comment> <object-id pub-id-type="pmid">22679418</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name> (<year>2002</year>) <article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title>. <source>Neuron</source> <volume>36</volume>: <fpage>955</fpage>–<lpage>968</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(02)01092-9" xlink:type="simple">10.1016/S0896-6273(02)01092-9</ext-link></comment> <object-id pub-id-type="pmid">12467598</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Scarano</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Soto-Faraco</surname> <given-names>S</given-names></name> (<year>2007</year>) <article-title>Weber’s law in decision making: integrating behavioral data in humans with a neurophysiological model</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>11192</fpage>–<lpage>11200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1072-07.2007" xlink:type="simple">10.1523/JNEUROSCI.1072-07.2007</ext-link></comment> <object-id pub-id-type="pmid">17942714</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wong</surname> <given-names>KF</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name> (<year>2006</year>) <article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>: <fpage>1314</fpage>–<lpage>1328</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3733-05.2006" xlink:type="simple">10.1523/JNEUROSCI.3733-05.2006</ext-link></comment> <object-id pub-id-type="pmid">16436619</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Chaudhuri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Variance as a signature of neural computations during decision making</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>818</fpage>–<lpage>831</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.12.037" xlink:type="simple">10.1016/j.neuron.2010.12.037</ext-link></comment> <object-id pub-id-type="pmid">21338889</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roxin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ledberg</surname> <given-names>A</given-names></name> (<year>2008</year>) <article-title>Neurobiological models of two-choice decision making can be reduced to a one-dimensional nonlinear diffusion equation</article-title>. <source>PLoS Comput Biol</source> <volume>4</volume>: <fpage>e1000046</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000046" xlink:type="simple">10.1371/journal.pcbi.1000046</ext-link></comment> <object-id pub-id-type="pmid">18369436</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Albantakis</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name> (<year>2011</year>) <article-title>Changes of mind in an attractor network of decision-making</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002086</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002086" xlink:type="simple">10.1371/journal.pcbi.1002086</ext-link></comment> <object-id pub-id-type="pmid">21731482</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Miller</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Katz</surname> <given-names>DB</given-names></name> (<year>2013</year>) <article-title>Accuracy and response-time distributions for decision-making: linear perfect integrators versus nonlinear attractor-based neural circuits</article-title>. <source>J Comput Neurosci</source> <volume>35</volume>: <fpage>261</fpage>–<lpage>294</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-013-0452-x" xlink:type="simple">10.1007/s10827-013-0452-x</ext-link></comment> <object-id pub-id-type="pmid">23608921</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name> (<year>2008</year>) <article-title>Decision making in recurrent neuronal circuits</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>215</fpage>–<lpage>234</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.09.034" xlink:type="simple">10.1016/j.neuron.2008.09.034</ext-link></comment> <object-id pub-id-type="pmid">18957215</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2013</year>) <article-title>Integration of direction cues is invariant to the temporal gap between them</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>16483</fpage>–<lpage>16489</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2094-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2094-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24133253</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Resulaj</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2009</year>) <article-title>Changes of mind in decision-making</article-title>. <source>Nature</source> <volume>461</volume>: <fpage>263</fpage>–<lpage>U141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature08275" xlink:type="simple">10.1038/nature08275</ext-link></comment> <object-id pub-id-type="pmid">19693010</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kastner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name> (<year>2000</year>) <article-title>Mechanisms of visual attention in the human cortex</article-title>. <source>Annu Rev Neurosci</source> <volume>23</volume>: <fpage>315</fpage>–<lpage>341</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.23.1.315" xlink:type="simple">10.1146/annurev.neuro.23.1.315</ext-link></comment> <object-id pub-id-type="pmid">10845067</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Chelazzi</surname> <given-names>L</given-names></name> (<year>2004</year>) <article-title>Attentional modulation of visual processing</article-title>. <source>Annu Rev Neurosci</source> <volume>27</volume>: <fpage>611</fpage>–<lpage>647</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.26.041002.131039" xlink:type="simple">10.1146/annurev.neuro.26.041002.131039</ext-link></comment> <object-id pub-id-type="pmid">15217345</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Martínez Trujillo</surname> <given-names>JC</given-names></name> (<year>1999</year>) <article-title>Feature-based attention influences motion processing gain in macaque visual cortex</article-title>. <source>Nature</source> <volume>399</volume>: <fpage>575</fpage>–<lpage>579</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/21176" xlink:type="simple">10.1038/21176</ext-link></comment> <object-id pub-id-type="pmid">10376597</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Moore</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Armstrong</surname> <given-names>KM</given-names></name> (<year>2003</year>) <article-title>Selective gating of visual signals by microstimulation of frontal cortex</article-title>. <source>Nature</source> <volume>421</volume>: <fpage>370</fpage>–<lpage>373</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature01341" xlink:type="simple">10.1038/nature01341</ext-link></comment> <object-id pub-id-type="pmid">12540901</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nienborg</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Cumming</surname> <given-names>BG</given-names></name> (<year>2009</year>) <article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source>Nature</source> <volume>459</volume>: <fpage>89</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07821" xlink:type="simple">10.1038/nature07821</ext-link></comment> <object-id pub-id-type="pmid">19270683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Zariwala</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name> (<year>2008</year>) <article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title>. <source>Nature</source> <volume>455</volume>: <fpage>227</fpage>–<lpage>231</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07200" xlink:type="simple">10.1038/nature07200</ext-link></comment> <object-id pub-id-type="pmid">18690210</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="other">Vickers D (1979) Decision Processes in Visual Perception. Academic Press series in cognition and perception. Academic Press. URL <ext-link ext-link-type="uri" xlink:href="http://books.google.de/books?id=LXA-AwAAQBAJ&amp;printsec=frontcover&amp;hl=de" xlink:type="simple">http://books.google.de/books?id=LXA-AwAAQBAJ&amp;printsec=frontcover&amp;hl=de</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name> (<year>2012</year>) <article-title>A computational framework for the study of confidence in humans and animals</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>367</volume>: <fpage>1322</fpage>–<lpage>1337</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2012.0037" xlink:type="simple">10.1098/rstb.2012.0037</ext-link></comment> <object-id pub-id-type="pmid">22492750</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name> (<year>1984</year>) <article-title>Neurons with graded response have collective computational properties like those of 2-state neurons</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America-Biological Sciences</source> <volume>81</volume>: <fpage>3088</fpage>–<lpage>3092</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.81.10.3088" xlink:type="simple">10.1073/pnas.81.10.3088</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Richards</surname> <given-names>W</given-names></name>, editors (<year>1996</year>) <source>Perception as Bayesian Inference</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ishii</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>RPN</given-names></name>, editors (<year>2006</year>) <source>Bayesian Brain</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Ballard</surname> <given-names>DH</given-names></name> (<year>1997</year>) <article-title>Dynamic model of visual recognition predicts neural response properties in the visual cortex</article-title>. <source>Neural Comput</source> <volume>9</volume>: <fpage>721</fpage>–<lpage>763</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1997.9.4.721" xlink:type="simple">10.1162/neco.1997.9.4.721</ext-link></comment> <object-id pub-id-type="pmid">9161021</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Haykin</surname> <given-names>S</given-names></name>, editor (<year>2001</year>) <source>Kalman Filtering and Neural Networks</source>. <publisher-name>John Wiley &amp; Sons, Inc</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Wan</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>van der Merwe</surname> <given-names>R</given-names></name> (<year>2001</year>) <chapter-title>The unscented kalman filter</chapter-title>. In: <source>Haykin [48]</source>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Doucet</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Johansen</surname> <given-names>AM</given-names></name> (<year>2011</year>) <chapter-title>A tutorial on particle filtering and smoothing: Fifteen years later</chapter-title>. In: <source>Oxford Handbook of Nonlinear Filtering</source>, <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Julier</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Uhlmann</surname> <given-names>JK</given-names></name> (<year>1997</year>) <chapter-title>New extension of the kalman filter to nonlinear systems</chapter-title>. In: <source>Proc. SPIE 3068, Signal Processing, Sensor Fusion, and Target Recognition VI</source>. pp. <fpage>182</fpage>–<lpage>193</lpage>. URL <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1117/12.280797" xlink:type="simple">http://dx.doi.org/10.1117/12.280797</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Murphy</surname> <given-names>KP</given-names></name> (<year>2012</year>) <chapter-title>Machine learning: a probabilistic perspective</chapter-title>. <source>Adaptive computation and machine learning series</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>, <volume>xxix</volume>, <fpage>1067</fpage> p. pp.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ress</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2003</year>) <article-title>Neuronal correlates of perception in early visual cortex</article-title>. <source>Nat Neurosci</source> <volume>6</volume>: <fpage>414</fpage>–<lpage>420</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1024" xlink:type="simple">10.1038/nn1024</ext-link></comment> <object-id pub-id-type="pmid">12627164</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2008</year>) <article-title>Decision-making with multiple alternatives</article-title>. <source>Nature Neuroscience</source> <volume>11</volume>: <fpage>693</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2123" xlink:type="simple">10.1038/nn.2123</ext-link></comment> <object-id pub-id-type="pmid">18488024</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name> (<year>2001</year>) <article-title>Dynamic predictions: oscillations and synchrony in top-down processing</article-title>. <source>Nat Rev Neurosci</source> <volume>2</volume>: <fpage>704</fpage>–<lpage>716</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35094565" xlink:type="simple">10.1038/35094565</ext-link></comment> <object-id pub-id-type="pmid">11584308</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Siegel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name> (<year>2012</year>) <article-title>Spectral fingerprints of large-scale neuronal interactions</article-title>. <source>Nat Rev Neurosci</source> <volume>13</volume>: <fpage>121</fpage>–<lpage>134</lpage>. <object-id pub-id-type="pmid">22233726</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>de Lange</surname> <given-names>FP</given-names></name> (<year>2014</year>) <article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title>. <source>Nat Rev Neurosci</source> <volume>15</volume>: <fpage>745</fpage>–<lpage>756</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3838" xlink:type="simple">10.1038/nrn3838</ext-link></comment> <object-id pub-id-type="pmid">25315388</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ruff</surname> <given-names>CC</given-names></name> (<year>2013</year>) <article-title>Sensory processing: who’s in (top-down) control?</article-title> <source>Ann N Y Acad Sci</source> <volume>1296</volume>: <fpage>88</fpage>–<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/nyas.12204" xlink:type="simple">10.1111/nyas.12204</ext-link></comment> <object-id pub-id-type="pmid">23909769</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref059">
<label>59</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Grabenhorst</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name> (<year>2010</year>) <article-title>Choice, difficulty, and confidence in the brain</article-title>. <source>Neuroimage</source> <volume>53</volume>: <fpage>694</fpage>–<lpage>706</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2010.06.073" xlink:type="simple">10.1016/j.neuroimage.2010.06.073</ext-link></comment> <object-id pub-id-type="pmid">20615471</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref060">
<label>60</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name> (<year>2013</year>) <article-title>Probabilistic brains: knowns and unknowns</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>1170</fpage>—<lpage>1178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3495" xlink:type="simple">10.1038/nn.3495</ext-link></comment> <object-id pub-id-type="pmid">23955561</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref061">
<label>61</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name> (<year>2010</year>) <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nat Rev Neurosci</source> <volume>11</volume>: <fpage>127</fpage>–<lpage>138</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2787" xlink:type="simple">10.1038/nrn2787</ext-link></comment> <object-id pub-id-type="pmid">20068583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref062">
<label>62</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Ballard</surname> <given-names>DH</given-names></name> (<year>1999</year>) <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat Neurosci</source> <volume>2</volume>: <fpage>79</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/4580" xlink:type="simple">10.1038/4580</ext-link></comment> <object-id pub-id-type="pmid">10195184</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref063">
<label>63</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>2012</year>) <article-title>Twenty-five lessons from computational neuromodulation</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>240</fpage>–<lpage>256</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.09.027" xlink:type="simple">10.1016/j.neuron.2012.09.027</ext-link></comment> <object-id pub-id-type="pmid">23040818</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref064">
<label>64</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Feldman</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2010</year>) <article-title>Attention, uncertainty, and free-energy</article-title>. <source>Front Hum Neurosci</source> <volume>4</volume>: <fpage>215</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2010.00215" xlink:type="simple">10.3389/fnhum.2010.00215</ext-link></comment> <object-id pub-id-type="pmid">21160551</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref065">
<label>65</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>2005</year>) <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source> <volume>46</volume>: <fpage>681</fpage>–<lpage>692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.04.026" xlink:type="simple">10.1016/j.neuron.2005.04.026</ext-link></comment> <object-id pub-id-type="pmid">15944135</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref066">
<label>66</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lund</surname> <given-names>FH</given-names></name> (<year>1926</year>) <article-title>The criteria of confidence</article-title>. <source>The American Journal of Psychology</source> <volume>37</volume>: pp. <fpage>372</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/1413623" xlink:type="simple">10.2307/1413623</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref067">
<label>67</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2009</year>) <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source> <volume>324</volume>: <fpage>759</fpage>–<lpage>764</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1169405" xlink:type="simple">10.1126/science.1169405</ext-link></comment> <object-id pub-id-type="pmid">19423820</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref068">
<label>68</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Drugowitsch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moreno-Bote</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name> (<year>2014</year>) <article-title>Relation between belief and performance in perceptual decision making</article-title>. <source>PLoS One</source> <volume>9</volume>: <fpage>e96511</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0096511" xlink:type="simple">10.1371/journal.pone.0096511</ext-link></comment> <object-id pub-id-type="pmid">24816801</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref069">
<label>69</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Pleskac</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name> (<year>2010</year>) <article-title>Two-stage dynamic signal detection: a theory of choice, decision time, and confidence</article-title>. <source>Psychol Rev</source> <volume>117</volume>: <fpage>864</fpage>–<lpage>901</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0019737" xlink:type="simple">10.1037/a0019737</ext-link></comment> <object-id pub-id-type="pmid">20658856</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref070">
<label>70</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ding</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name> (<year>2012</year>) <article-title>Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye field</article-title>. <source>Cereb Cortex</source> <volume>22</volume>: <fpage>1052</fpage>–<lpage>1067</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhr178" xlink:type="simple">10.1093/cercor/bhr178</ext-link></comment> <object-id pub-id-type="pmid">21765183</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref071">
<label>71</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name> (<year>2012</year>) <article-title>Not noisy, just wrong: the role of suboptimal inference in behavioral variability</article-title>. <source>Neuron</source> <volume>74</volume>: <fpage>30</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.03.016" xlink:type="simple">10.1016/j.neuron.2012.03.016</ext-link></comment> <object-id pub-id-type="pmid">22500627</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref072">
<label>72</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hanks</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name> (<year>2008</year>) <chapter-title>Neurobiology of decision making: An intentional framework</chapter-title>. In: <name name-style="western"><surname>Engel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, editors, <source>Better Than Conscious? Decision Making, the Humand Mind, and Implications For Institutions</source>, <publisher-name>MIT Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref073">
<label>73</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zucker</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Regehr</surname> <given-names>WG</given-names></name> (<year>2002</year>) <article-title>Short-term synaptic plasticity</article-title>. <source>Annu Rev Physiol</source> <volume>64</volume>: <fpage>355</fpage>–<lpage>405</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.physiol.64.092501.114547" xlink:type="simple">10.1146/annurev.physiol.64.092501.114547</ext-link></comment> <object-id pub-id-type="pmid">11826273</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref074">
<label>74</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Denève</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Duhamel</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name> (<year>2007</year>) <article-title>Optimal sensorimotor integration in recurrent cortical networks: a neural implementation of kalman filters</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>5744</fpage>–<lpage>5756</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3985-06.2007" xlink:type="simple">10.1523/JNEUROSCI.3985-06.2007</ext-link></comment> <object-id pub-id-type="pmid">17522318</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref075">
<label>75</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hanks</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Probabilistic population codes for bayesian decision making</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>1142</fpage>–<lpage>1152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.09.021" xlink:type="simple">10.1016/j.neuron.2008.09.021</ext-link></comment> <object-id pub-id-type="pmid">19109917</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref076">
<label>76</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Natarajan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Huys</surname> <given-names>QJM</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zemel</surname> <given-names>RS</given-names></name> (<year>2008</year>) <article-title>Encoding and decoding spikes for dynamic stimuli</article-title>. <source>Neural Computation</source> <volume>20</volume>: <fpage>2325</fpage>–<lpage>2360</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.01-07-436" xlink:type="simple">10.1162/neco.2008.01-07-436</ext-link></comment> <object-id pub-id-type="pmid">18386986</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref077">
<label>77</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Wilson</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Finkel</surname> <given-names>L</given-names></name> (<year>2009</year>) <chapter-title>A neural implementation of the kalman filter</chapter-title>. In: <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Schuurmans</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Lafferty</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>CKI</given-names></name>, <name name-style="western"><surname>Culotta</surname> <given-names>A</given-names></name>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>22</volume>. pp. <fpage>2062</fpage>–<lpage>2070</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref078">
<label>78</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boerlin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Denève</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>Spike-based population coding and working memory</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1001080</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001080" xlink:type="simple">10.1371/journal.pcbi.1001080</ext-link></comment> <object-id pub-id-type="pmid">21379319</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref079">
<label>79</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bitzer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>S</given-names></name> (<year>2012</year>) <article-title>Recognizing recurrent neural networks (rrnn): Bayesian inference for recurrent neural networks</article-title>. <source>Biological Cybernetics</source> <volume>106</volume>: <fpage>201</fpage>–<lpage>217</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-012-0490-x" xlink:type="simple">10.1007/s00422-012-0490-x</ext-link></comment> <object-id pub-id-type="pmid">22581026</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref080">
<label>80</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bastos</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Usrey</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Mangun</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Canonical microcircuits for predictive coding</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>695</fpage>–<lpage>711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.10.038" xlink:type="simple">10.1016/j.neuron.2012.10.038</ext-link></comment> <object-id pub-id-type="pmid">23177956</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref081">
<label>81</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Legenstein</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name> (<year>2014</year>) <article-title>Ensembles of spiking neurons with noise support optimal probabilistic inference in a dynamically changing environment</article-title>. <source>PLoS Comput Biol</source> <volume>10</volume>: <fpage>e1003859</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003859" xlink:type="simple">10.1371/journal.pcbi.1003859</ext-link></comment> <object-id pub-id-type="pmid">25340749</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004442.ref082">
<label>82</label>
<mixed-citation xlink:type="simple" publication-type="other">Rasmussen CE, Williams CKI (2006) Gaussian Processes for Machine Learning. MIT Press. URL <ext-link ext-link-type="uri" xlink:href="http://www.gaussianprocess.org/gpml/" xlink:type="simple">http://www.gaussianprocess.org/gpml/</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004442.ref083">
<label>83</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Haario</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Laine</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mira</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Saksman</surname> <given-names>E</given-names></name> (<year>2006</year>) <article-title>DRAM: Efficient adaptive MCMC</article-title>. <source>Statistics and Computing</source> <volume>16</volume>: <fpage>339</fpage>–<lpage>354</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11222-006-9438-0" xlink:type="simple">10.1007/s11222-006-9438-0</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>