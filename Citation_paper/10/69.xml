<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-11-01437</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0017432</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subject>Learning and memory</subject>
              <subject>Neural networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Learning Shapes Spontaneous Activity Itinerating over Memorized States</article-title><alt-title alt-title-type="running-head">Spontaneous Dynamics Shaped by Learning</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kurikawa</surname>
            <given-names>Tomoki</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kaneko</surname>
            <given-names>Kunihiko</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
      </contrib-group><aff id="aff1">          <addr-line>Department of Basic Science, University of Tokyo, Tokyo, Japan</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">kurikawa@complex.c.u-tokyo.ac.jp</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: TK. Performed the experiments: TK. Analyzed the data: TK KK. Contributed reagents/materials/analysis tools: TK. Wrote the paper: TK KK.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>8</day>
        <month>3</month>
        <year>2011</year>
      </pub-date><volume>6</volume><issue>3</issue><elocation-id>e17432</elocation-id><history>
        <date date-type="received">
          <day>13</day>
          <month>1</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>31</day>
          <month>1</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Kurikawa, Kaneko</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Learning is a process that helps create neural dynamical systems so that an appropriate output pattern is generated for a given input. Often, such a memory is considered to be included in one of the attractors in neural dynamical systems, depending on the initial neural state specified by an input. Neither neural activities observed in the absence of inputs nor changes caused in the neural activity when an input is provided were studied extensively in the past. However, recent experimental studies have reported existence of structured spontaneous neural activity and its changes when an input is provided. With this background, we propose that memory recall occurs when the spontaneous neural activity changes to an appropriate output activity upon the application of an input, and this phenomenon is known as bifurcation in the dynamical systems theory. We introduce a reinforcement-learning-based layered neural network model with two synaptic time scales; in this network, I/O relations are successively memorized when the difference between the time scales is appropriate. After the learning process is complete, the neural dynamics are shaped so that it changes appropriately with each input. As the number of memorized patterns is increased, the generated spontaneous neural activity after learning shows itineration over the previously learned output patterns. This theoretical finding also shows remarkable agreement with recent experimental reports, where spontaneous neural activity in the visual cortex without stimuli itinerate over evoked patterns by previously applied signals. Our results suggest that itinerant spontaneous activity can be a natural outcome of successive learning of several patterns, and it facilitates bifurcation of the network when an input is provided.</p>
      </abstract><funding-group><funding-statement>Funding was provided by Grants-in-Aid for scientific research (No. 21120004) from MEXT Japan. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="11"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>One of the most important features of the brain is the ability to learn and regenerate an appropriate response to external stimuli. By modification of the synaptic strength, output responses to input stimuli are memorized. Accordingly, these input-output (I/O) mappings are embedded in synaptic structure. A wide variety of neural network models have been proposed to study how a synaptic structure is formed for memorizing the given I/O mappings. In most of the previous studies on unsupervised learning <xref ref-type="bibr" rid="pone.0017432-Willshaw1">[1]</xref>–<xref ref-type="bibr" rid="pone.0017432-Kohonen1">[3]</xref>, inputs were supplied as the initial states for neural activity, whose temporal evolution results in the generation of the desired outputs. Similarly, in supervised learning with multi-layer neural networks <xref ref-type="bibr" rid="pone.0017432-Rumelhart1">[4]</xref>, inputs are provided as the initial states to an input layer, and the neural activity in the output layer is determined on the basis of the inputs. In this manner, an input determines the initial states of the system, while an output is given by an attractor of the neural activity dynamics. Here, the learning process changes the dynamical system so that the postulated output is generated by the attractor to which the neural activity is attracted under the initial conditions. Each output pattern is thus memorized as an attractor, and this process is often referred to as “memories as attractors.”</p>
      <p>In these studies, the input is specified only as the initial neural activity. Hence, neural activity dynamics cannot be determined accurately in the absence of inputs since the initial values for neural activity are chosen on the basis of the inputs. However, many studies have indicated that for understanding the functioning of the brain, it is important to induce neural activity in the absence of inputs. In particular, recent studies have shown that in the brain, structured neural activity is observed even in the absence of external stimuli <xref ref-type="bibr" rid="pone.0017432-Luczak1">[5]</xref>; such an activity is termed “spontaneous activity.” After input is provided, this spontaneous activity is modified so that an appropriate output response is generated. In recent experiments <xref ref-type="bibr" rid="pone.0017432-Mazor1">[6]</xref> on an olfactory system, the neural dynamics have been studied in the presence and absence of odor stimuli. Steady states of the neural activity, which are different from the rest state, are generated for different odor stimuli; the neural activity returns to the rest state upon removal of the external stimulus. Hence, an input modulates spontaneous activity to generate an output rather than determines the neural state as the initial state. These observations strongly indicate a novel I/O representation in the neural activity dynamics, which also includes spontaneous activity.</p>
      <p>In this paper, we propose a novel viewpoint of the memory of I/O mapping, in order to verify the aforementioned postulate. For this purpose, we present the following questions: Can we construct an appropriate neural network model to demonstrate the learning process under biologically plausible assumptions? If so, under what conditions would learning be possible? Then, what types of spontaneous activity, which can change the desired output depending on the corresponding input, are shaped? What changes in the neural activity can bring about the output when an input is provided?</p>
      <p>In the present study, we find the answers to these questions by adopting a layered neural network model for reinforcement learning along with multiple time scales for synaptic plasticity and the associative reward-penalty algorithm (ARP) <xref ref-type="bibr" rid="pone.0017432-Barto1">[7]</xref> <xref ref-type="bibr" rid="pone.0017432-Xie1">[8]</xref>. We demonstrate that the proposed model can memorize the maximum number of I/O mappings when the time scales of the plasticity of the forward and backward synapses satisfy a certain condition.</p>
      <p>In our theoretical framework, an output for a given input is represented by an attractor of the neural dynamics in the presence of the input; this attractor may differ from that in the absence of the input. The nature of the attractor changes with the input and such a qualitative change in the attractor with the parameters of a dynamical system is referred to as “bifurcation” in the dynamical systems theory. Hence, the input-induced change in the attractor is represented as bifurcation in the dynamical systems theory. In other words, an input can be considered a bifurcation parameter for neural activity dynamics. Dynamical systems are generally represented by the flow structure in the state space, and hence this flow structure changes with the input so that a state that represents a given target output is generated. In this dynamical-system perspective, learning helps in the formation of an appropriate flow structure through bifurcations caused by changes in the strength of the applied input. When an I/O mapping is memorized, the neural dynamics undergo bifurcation, and the spontaneous dynamics attractor is converted into an attractor representing the desired output for a given input. When the learning process progresses, the neural dynamics are modified so that the aforementioned “bifurcation” occurs.</p>
      <p>We show that in the absence of an input, the neural dynamics itinerate over several states corresponding to each of the memorized output patterns after many targets have been learned. This theoretical finding is in remarkable agreement with recent experimental report <xref ref-type="bibr" rid="pone.0017432-Kenet1">[9]</xref>. This report states that in the absence of stimuli, the spontaneous neural activity in the visual cortex itinerates over patterns evoked by the visual signals. We analyze how the flow structure of the neural network is shaped by the learning process and discuss the possible relationship between our results and recent experimental observations of the external-stimuli-induced modification of spontaneous activity.</p>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>Architecture of Our Model</title>
        <p>We construct a neural network model for learning, on the basis of the following two conditions that satisfy the biological requirements for the normal functioning of the brain: (i) different error information for different individual neuron should not be required. In other words, individual error information is used commonly to all neurons. For example, in the error back-propagation algorithm <xref ref-type="bibr" rid="pone.0017432-Rumelhart1">[4]</xref>, one of the most popular learning algorithms for neural networks, information corresponding to each of the output neurons is required. In the case of biological learning with a neural system, however, it is difficult to transmit the specified information to each neuron. (ii) I/O mappings should be learned one by one sequentially, i.e., a new I/O mapping should be learned only after the previous mapping has been learned while preserving the previously learned mappings. In contrast, in most learning algorithms for neural networks, many mappings are simultaneously and iteratively learned by gradually changing the synaptic strength until all the mappings are memorized.</p>
        <p>In order to satisfy the above-mentioned conditions, we introduce a layered network model consisting of input, hidden, and output layers along with ARP algorithm for reinforcement learning (<xref ref-type="fig" rid="pone-0017432-g001">Fig. 1</xref>) <xref ref-type="bibr" rid="pone.0017432-Barto1">[7]</xref> <xref ref-type="bibr" rid="pone.0017432-Xie1">[8]</xref>. In this model, several I/O mappings are learned one by one with only a single error signal that is defined as the distance between the activity pattern of the output neurons and a given target pattern. During the learning process, the plasticity of the synaptic strength varies with the magnitude of the error signal, in accordance with the Hebbian and anti-Hebbian rules.</p>
        <fig id="pone-0017432-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Schematic representation of the network architecture of our model.</title>
            <p>FS (BS) represents the interlayer forward (backward) excitatory synapse, and IS represents the mutually inhibitory intralayer synapse. Error signal represents the difference between an output and a target pattern and regulates the plasticity of all subsequent FSs and BSs (Eq.3) (green arrows and ellipses).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g001" xlink:type="simple"/>
        </fig>
        <p>In particular, we adopt the following model with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e001" xlink:type="simple"/></inline-formula> neurons in each layer. Three types of synapses are considered: excitatory forward synapses (FSs), excitatory backward synapses (BSs), and mutually inhibitory intralayer synapses (ISs). FSs connect the neurons in the input layer to those in the hidden layer and the neurons in the hidden layer to those in the output layer. BSs connect the neurons in the output layer to those in the hidden layer, while ISs connect the neurons within a given layer (hidden or output layer). This architecture is similar to that of a simple recurrent network (SRN) <xref ref-type="bibr" rid="pone.0017432-Elman1">[10]</xref> <xref ref-type="bibr" rid="pone.0017432-Jordan1">[11]</xref>. As opposed to the study on temporal evolution of I/O mappings in an SRN, the present study deals with the shaping of neural dynamics in the presence and absence of the input through learning process.</p>
      </sec>
      <sec id="s2b">
        <title>Neural Dynamics</title>
        <p>The neural activity in the input layer is fixed at an input pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e002" xlink:type="simple"/></inline-formula>, an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e003" xlink:type="simple"/></inline-formula>-dimensional vector whose element takes the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e004" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e005" xlink:type="simple"/></inline-formula> and the magnitude of the vector is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e006" xlink:type="simple"/></inline-formula> (Eq.1). We use the rate-coding neuron model for the neural activities in the other layers (Eq.2), because this is simple but general model that has been used widely and is well suited for dynamical-system analysis.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.e007" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.e008" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e009" xlink:type="simple"/></inline-formula> is the firing rate of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e010" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e011" xlink:type="simple"/></inline-formula> is the input current applied to the neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e012" xlink:type="simple"/></inline-formula>. The input current is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e013" xlink:type="simple"/></inline-formula> for the neurons in the hidden layer and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e014" xlink:type="simple"/></inline-formula> for the neurons in the output layer. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e015" xlink:type="simple"/></inline-formula> is the strength of the forward (backward) synapse from a presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e016" xlink:type="simple"/></inline-formula> to a postsynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e017" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e018" xlink:type="simple"/></inline-formula> is the strength parameter for the mutually inhibiting IS; this parameter assumes a fixed and identical value for all ISs (set at −1.0) except for self-connected synapses (set at 0.0). <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e019" xlink:type="simple"/></inline-formula> is a time scale of neural activities and is set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e020" xlink:type="simple"/></inline-formula> in the present case. We also analyze the dependency of memory capacity on the relationship among the three time scales in the system: the time scale for neural dynamics and the time scale for the plasticity of FSs and BSs. The other parameters are set as follows: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e021" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e022" xlink:type="simple"/></inline-formula>. Because of the competition through the ISs, only one (or very few) neuron(s) in each layer is (are) excited, and this results in a sparse neural activity pattern. Once an input pattern is given as a boundary condition, the evolution of neural activities in the hidden and output layers are determined by the above-defined dynamical systems. Hence, each input modifies the flow structure of neural dynamics composed of neurons in the hidden and output layers, resulting in modifying the neural dynamics on the basis of this flow structure.</p>
      </sec>
      <sec id="s2c">
        <title>Synaptic Plasticity</title>
        <p>Synaptic plasticity is necessary for learning in a neural network. As mentioned earlier in the text, we maintain the strength of the ISs constant for simplicity and vary the strengths of the FSs and BSs. For each input pattern defined above, we prescribe a target pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e023" xlink:type="simple"/></inline-formula> as an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e024" xlink:type="simple"/></inline-formula>-dimensional vector whose element takes the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e025" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e026" xlink:type="simple"/></inline-formula>, and choose sparse patterns in which only one neuron is activated as inputs and targets. In the learning task, the neural activity in the output layer is described as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e027" xlink:type="simple"/></inline-formula>-dimensional vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e028" xlink:type="simple"/></inline-formula>, and the error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e029" xlink:type="simple"/></inline-formula> is minimized. We adopt two schemes for synaptic plasticity: multiple time scales and the ARP algorithm for reinforcement learning <xref ref-type="bibr" rid="pone.0017432-Barto1">[7]</xref> <xref ref-type="bibr" rid="pone.0017432-Xie1">[8]</xref>. First, the time scale of the plasticity of FSs (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e030" xlink:type="simple"/></inline-formula>) is different from that of the plasticity of BSs (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e031" xlink:type="simple"/></inline-formula>). Second, the synapse pattern that generates the target output is strengthened, in accordance with the Hebbian rule; otherwise, it is weakened, as per the anti-Hebbian rule. In accordance with the ARP, we assume that the synaptic dynamics depend on the activities of the pre- and postsynaptic neurons as well as on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e032" xlink:type="simple"/></inline-formula> determined from the error signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e033" xlink:type="simple"/></inline-formula>, as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.e034" xlink:type="simple"/><label>(3)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.e035" xlink:type="simple"/><label>(4)</label></disp-formula></p>
        <p>Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e036" xlink:type="simple"/></inline-formula> is the spontaneous firing rate (set at 0.1) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e037" xlink:type="simple"/></inline-formula> is set at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e038" xlink:type="simple"/></inline-formula>. The sign of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e039" xlink:type="simple"/></inline-formula> changes with the magnitude of the error signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e040" xlink:type="simple"/></inline-formula> between the output pattern and the target pattern. When the output pattern is close to the target pattern, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e041" xlink:type="simple"/></inline-formula>, the synaptic plasticity follows the Hebbian rule, which is derived by substituting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e042" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e043" xlink:type="simple"/></inline-formula> in (Eq.3). This plasticity stabilizes the ongoing neural activity pattern. Note that during this stabilization process, only the strength of the FS varies, and hence, memories of the I/O mappings are embedded in the FSs. In contrast, when the output pattern is distant from the target pattern, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e044" xlink:type="simple"/></inline-formula>, the synaptic plasticity follows the so-called anti-Hebbian rule, and hence, the ongoing neural activity pattern is destabilized. Note that with the above form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e045" xlink:type="simple"/></inline-formula>, the synapse shows negligible changes when its pre-synaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e046" xlink:type="simple"/></inline-formula> is in a low-firing state. In our model, we require only a single error term for all neurons; this is in strong contrast to error back-propagation, which requires the computation of a large number of error terms, i.e., as many error terms as the output neurons. Brief and the preliminary report of this model is given in the proceeding <xref ref-type="bibr" rid="pone.0017432-Kurikawa1">[12]</xref>.</p>
        <p>In most neural network studies, only two time scales are considered: one for neural activities and the other for synaptic plasticity. In this study, we consider a variety of time scales for synaptic plasticity and introduce two time scales for the plasticity of the FSs and BSs. As will be shown later, I/O mappings are successfully memorized when the difference between the time scales is appropriate.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>Neural Dynamics in the Learning Process</title>
        <p>We show that our model can learn I/O mappings based on our perspective. An example of the learning process is shown; the time series of the strength of some synapses, that of the neural activities in the output layer and that of the error signal during the learning process are shown in <xref ref-type="fig" rid="pone-0017432-g002">Figure 2</xref>. As the initial conditions for the network, we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e047" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e048" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e049" xlink:type="simple"/></inline-formula> and assign the synaptic strength a random value with a uniform distribution between 0 and 1, except in the case of the ISs.</p>
        <fig id="pone-0017432-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Dynamics during the learning of three input-output (I/O) mappings.</title>
            <p>I/O mappings are learned in the search phase by the anti-Hebbian rule (0<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e050" xlink:type="simple"/></inline-formula>300, 700<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e051" xlink:type="simple"/></inline-formula>950, and 1200<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e052" xlink:type="simple"/></inline-formula>1700) and in the stabilization phase by the Hebbian rule (300<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e053" xlink:type="simple"/></inline-formula>700, 950<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e054" xlink:type="simple"/></inline-formula>1200, and 1700<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e055" xlink:type="simple"/></inline-formula>2100). Color bars on the top of figures and above the time series in B) represent each set of input/target patterns. A) Dynamics of some FSs are shown. These lines represent FSs from neurons in hidden layer to the neurons to be activated in targets in output layer. These neurons are referred to as the target neurons. In particular, each color (green, blue and red) represents FSs to each target neuron (1st, 2nd and 3rd target) respectively. Three lines increasing rapidly are FSs from activated neurons in hidden layer to the target neurons. B) Raster plot of neurons in the output layer is shown. The ordinate shows the index of the neurons in the output layer. Red bar represents the high activity of each neuron (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e056" xlink:type="simple"/></inline-formula>). Blue (green) bar behind the Raster plot indicates the output corresponding to the first (second) target. C) Time series of the amplitude of the error signal between the output and target patterns. Distance <italic>d</italic> between the output pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e057" xlink:type="simple"/></inline-formula> and the target pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e058" xlink:type="simple"/></inline-formula> by the normalized Euclidean norm (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e059" xlink:type="simple"/></inline-formula>) as a function of time is plotted.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g002" xlink:type="simple"/>
        </fig>
        <p>When the error is large (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e060" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pone-0017432-g002">Fig. 2</xref>), the neural dynamics itinerate between different patterns since the present neural activity becomes unstable as per the anti-Hebbian rule. The target pattern is searched during this itineration. We term this period “search phase” in what follows. At <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e061" xlink:type="simple"/></inline-formula>, the magnitude of the error reduces to a sufficient extent, i.e., the output dynamics of the neural activity are within the neighborhood <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e062" xlink:type="simple"/></inline-formula> of the target, where the synaptic plasticity changes from the Hebbian rule to the anti-Hebbian rule. Once this occurs, the neural activity is stabilized as per the Hebbian rule (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e063" xlink:type="simple"/></inline-formula>), and the output activity remains close to the target, in accordance with the Hebbian rule; because of this, the synapses between active neurons are continuously strengthened until a new target is generated (<xref ref-type="fig" rid="pone-0017432-g002">Fig. 2</xref>). This period is called “stabilization phase.” At <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e064" xlink:type="simple"/></inline-formula>, we switch the input and the corresponding target patterns to generate new input-target pairs. Then, the distance between the output pattern and the target pattern increases again, and therefore, the search process progresses according to the anti-Hebbian rule (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e065" xlink:type="simple"/></inline-formula>) until the stabilization phase is initiated as per the Hebbian rule at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e066" xlink:type="simple"/></inline-formula> when the output activity is close to the target. Furthermore, at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e067" xlink:type="simple"/></inline-formula>, we switch the input and the target pattern to generate the third input-garget pairs and the learning process progresses in the same manner as mentioned above. In this manner, the neural activity can be made to approach the target and the target learning can be achieved by making the synaptic plasticity alternately anti-Hebbian and Hebbian, depending on the error. Note that in this phase, the target is learned in the flow structure in the presence of the corresponding input, but not in the absence of the input, i.e., an attractor in the presence of an input, but not an attractor in the absence of an input, is formed by the learning process.</p>
      </sec>
      <sec id="s3b">
        <title>Memory Capacity through the Learning Process</title>
        <p>We discuss the memory capacity through the learning process. For specificity, we use the following procedure for counting the number of memories: After each learning step, which consists of a search phase and a stabilization phase, we apply each of the inputs learned so far and check whether the output pattern matches the corresponding target pattern for most of the initial neural activity values, by fixing the synaptic strength. Here, “most” means that the fraction of the initial values reaching the target pattern is greater than one-half. (If this threshold value is changed, the number of memories is modified. However, the results below are not essentially changed, as long as it is neither too smaller nor too large.)</p>
        <p>In other words, when the I/O mapping is memorized, the neural activity comes close to the target by applying the input, irrespective of the state before applying the input. The number of memorized targets increases with the sequence of learning steps (i.e., the number of I/O mappings provided) and reaches a saturation value (or decreases) because of the loss of the earlier memory (<xref ref-type="fig" rid="pone-0017432-g003">Fig. 3</xref>). Then, the memory capacity is determined from the maximum number of memorized sets in the entire learning process.</p>
        <fig id="pone-0017432-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>The number of memories through the learning process.</title>
            <p>The number of memorized sets at each learning step is plotted for three different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e068" xlink:type="simple"/></inline-formula>, by fixing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e069" xlink:type="simple"/></inline-formula> at 64. Red, green, and blue lines represent the number of memorized sets for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e070" xlink:type="simple"/></inline-formula> (identical to that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e071" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e072" xlink:type="simple"/></inline-formula> (maximum memory capacity), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e073" xlink:type="simple"/></inline-formula>, (larger than at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e074" xlink:type="simple"/></inline-formula>), respectively. Dotted line represents the maximum possible number of memorized sets, i.e., the number of all learned I/O relations. A) Number of memorized sets at a single learning process. Memory capacity at each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e075" xlink:type="simple"/></inline-formula> is defined by the maximum number of memorized sets in the learning process, as shown by colored circles. B) Number of memorized sets averaged over learning processes. The number of learned sets is calculated by averaging over 100 learning processes for each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e076" xlink:type="simple"/></inline-formula>. Error bars indicate the standard deviations.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g003" xlink:type="simple"/>
        </fig>
        <p>In our model, the I/O mappings to be learned are provided sequentially, and the learning process where each mapping is provided only once is mainly analyzed. However, it is also possible to learn the mappings repeatedly. In our model, the synaptic strength is not limited, and therefore, the magnitude of synaptic connections between the active neurons would increase unlimitedly as a result of repeated learning. In the results shown below, we change the initial condition for the synaptic strength to 0, except in the case of the ISs, before the commencement of the learning process in order to prevent the initial network from being infected.</p>
      </sec>
      <sec id="s3c">
        <title>Dependence of Memory Capacity on Timescales</title>
        <p>As has been mentioned before, there are three time scales in our model: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e077" xlink:type="simple"/></inline-formula> for changes in the neural activity and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e078" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e079" xlink:type="simple"/></inline-formula> for the plasticity of the BSs and FSs, respectively. We analyze the dependence of the memory capacity on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e080" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e081" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e082" xlink:type="simple"/></inline-formula>. Specifically, we compute the capacity by fixing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e083" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e084" xlink:type="simple"/></inline-formula> and study the dependence of the memory capacity on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e085" xlink:type="simple"/></inline-formula>. In <xref ref-type="fig" rid="pone-0017432-g004">Figure 4</xref>, the memory capacity is plotted as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e086" xlink:type="simple"/></inline-formula> for various values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e087" xlink:type="simple"/></inline-formula>. We confirm that the memory capacity is small for any <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e088" xlink:type="simple"/></inline-formula>, unless <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e089" xlink:type="simple"/></inline-formula> is sufficiently larger than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e090" xlink:type="simple"/></inline-formula>; this is because there is no method for preserving the information about previously learned patterns that are embedded in the FSs. Thus, we focus on the capacity in the case of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e091" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pone-0017432-g005">Figure 5</xref>. Interestingly, each capacity curve in the plot shows a peak when the time scale satisfies the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e092" xlink:type="simple"/></inline-formula>, where the capacity is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e093" xlink:type="simple"/></inline-formula>, which is equal to the number of neurons in each layer. Since the present model adopts the sparse coding principle, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e094" xlink:type="simple"/></inline-formula> is the maximum possible memory capacity. When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e095" xlink:type="simple"/></inline-formula> approaches <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e096" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e097" xlink:type="simple"/></inline-formula>, the capacity is considerably smaller than the maximum capacity. Furthermore, after scaling <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e098" xlink:type="simple"/></inline-formula>, the capacity curves nearly overlap with one another. By this scaling, the position of the peak is independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e099" xlink:type="simple"/></inline-formula> unless <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e100" xlink:type="simple"/></inline-formula>.</p>
        <fig id="pone-0017432-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Memory capacity as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e101" xlink:type="simple"/></inline-formula> for various values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e102" xlink:type="simple"/></inline-formula> Memory capacity curves as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e103" xlink:type="simple"/></inline-formula> are shown (See text for the definition of capacity).</title>
            <p>The other time scale, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e104" xlink:type="simple"/></inline-formula>, is fixed at a unit value. Memory capacity shows a peak when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e105" xlink:type="simple"/></inline-formula> satisfies the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e106" xlink:type="simple"/></inline-formula> If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e107" xlink:type="simple"/></inline-formula> is sufficiently large, our model can memorize almost all learned sets (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e108" xlink:type="simple"/></inline-formula>) at the time scale satisfying this condition. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e109" xlink:type="simple"/></inline-formula> at each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e110" xlink:type="simple"/></inline-formula> is scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e111" xlink:type="simple"/></inline-formula>, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e112" xlink:type="simple"/></inline-formula> is constant. Computed from the average over 100 learning processes for each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e113" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g004" xlink:type="simple"/>
        </fig>
        <fig id="pone-0017432-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Scaled capacity curve and residence time curve.</title>
            <p>Scaled capacity curve (i) and residence time curve (ii) when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e114" xlink:type="simple"/></inline-formula> is large (64, 96, and 128) are plotted. Capacity and residence time are plotted as functions of the ratio of the logarithms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e115" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e116" xlink:type="simple"/></inline-formula> and not as functions of the logarithm of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e117" xlink:type="simple"/></inline-formula>. Here, the residence time is scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e118" xlink:type="simple"/></inline-formula>. Vertical pink and blue lines represent the values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e119" xlink:type="simple"/></inline-formula> satisfying the conditions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e120" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e121" xlink:type="simple"/></inline-formula> respectively. All capacity curves show a peak at the same value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e122" xlink:type="simple"/></inline-formula>, where the residence time takes the minimum value. Here the residence time is defined as the time at which the output neural pattern is closer to the given target than the threshold distance. To be specific, we set the threshold distance between the output and target at 0.9.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g005" xlink:type="simple"/>
        </fig>
        <p>In the search phase, the synaptic plasticity in the learning process modifies the flow structure in the phase space of the neural state so that the neural activity searches the target by itinerating various patterns including the learned target pattern. We focus on when the output activity come close to one of the previously learned target patterns in the search phase. Since this pattern differs from the current target pattern, the flow structure attracting to the previous target pattern may be destroyed by the synaptic plasticity, as stated by the anti-Hebbian rule. Thus, the flow structure in the phase space of the neural state that supports the attraction to the previously memorized pattern may be destroyed. In general, the longer the output pattern stays close to a state corresponding to a previously learned pattern, the stronger is the destabilization of the attractive flow to the state. Hence, the degree of destabilization of the previous memory is expected to increase with the residence time of the pattern in the corresponding state. Indeed, as shown in <xref ref-type="fig" rid="pone-0017432-g005">Figure 5</xref>, the residence time, when plotted as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e123" xlink:type="simple"/></inline-formula>, decreases to a minimum when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e124" xlink:type="simple"/></inline-formula> corresponds to the maximum memory capacity and increases as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e125" xlink:type="simple"/></inline-formula> approaches either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e126" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e127" xlink:type="simple"/></inline-formula>. This trend is consistent with the dependence of the memory capacity on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e128" xlink:type="simple"/></inline-formula>.</p>
        <p>Now we discuss the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e129" xlink:type="simple"/></inline-formula>. Either, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e130" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e131" xlink:type="simple"/></inline-formula> determines the time scale for the change in the flow structure itself, whereas <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e132" xlink:type="simple"/></inline-formula> determines that of the neural dynamics of a certain fixed flow structure. Moreover, because the search for the target is based on the change in the flow structure, as per the anti-Hebbian rule, the time scale of the search phase is effectively determined by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e133" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e134" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e135" xlink:type="simple"/></inline-formula>, the flow structure in the phase space is modified during the neural activity change, and hence, the approach the target pattern is often hindered. Indeed, the search for a new target pattern takes a longer time to complete as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e136" xlink:type="simple"/></inline-formula> approaches <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e137" xlink:type="simple"/></inline-formula>, and the residence time in the previously memorized patterns increases. This results in a decrease in the memory capacity.</p>
        <p>On the other hand, the time scale of the memory decay is determined by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e138" xlink:type="simple"/></inline-formula> because the memory information is embedded in the FSs (Eq.4). Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e139" xlink:type="simple"/></inline-formula> indicates that the time scale of the search phase is equal to that of the memory decay; during the search for the target, the memory of the previously learned mappings is destroyed. Thus, the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e140" xlink:type="simple"/></inline-formula> must be satisfied for successive learning.</p>
        <p>Here, we briefly discuss the dependence of memory capacity on the number of neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e141" xlink:type="simple"/></inline-formula>. As long as the sparse firing in the hidden layer is satisfied, the maximal capacity is expected to be approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e142" xlink:type="simple"/></inline-formula>, if the timescale relationship between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e143" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e144" xlink:type="simple"/></inline-formula> is fine-tuned on the basis of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e145" xlink:type="simple"/></inline-formula>. Even without such fine-tuning, the capacity increases roughly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e146" xlink:type="simple"/></inline-formula> when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e147" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e148" xlink:type="simple"/></inline-formula> (some parameters are scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e149" xlink:type="simple"/></inline-formula>; details can be found in the caption of <xref ref-type="fig" rid="pone-0017432-g006">Fig. 6</xref>). Hence, a rather high capacity is achieved. However, with an increase in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e150" xlink:type="simple"/></inline-formula>, the learning time increases, as the phase space in neural activity to be searched increases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e151" xlink:type="simple"/></inline-formula>. In fact, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e152" xlink:type="simple"/></inline-formula> the search time is so long that the memory is often destroyed during the search phase, unless the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e153" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e154" xlink:type="simple"/></inline-formula> are fine-tuned. Here after, we fix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e155" xlink:type="simple"/></inline-formula> to discuss the neural activity dynamics.</p>
        <fig id="pone-0017432-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Capacity dependence on N.</title>
            <p>Capacities for various numbers of neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e156" xlink:type="simple"/></inline-formula> are plotted. Each capacity is measured after learning the maximum number of I/O mappings (i.e., the number of neurons in each layer <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e157" xlink:type="simple"/></inline-formula>). The time scales are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e158" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e159" xlink:type="simple"/></inline-formula>, which is independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e160" xlink:type="simple"/></inline-formula>, while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e161" xlink:type="simple"/></inline-formula> are in proportion to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e162" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g006" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3d">
        <title>Shaping of Spontaneous Activity by Learning</title>
        <p>Now, we analyze how the networks memorize the I/O mappings, by imposing the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e163" xlink:type="simple"/></inline-formula>. We set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e164" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e165" xlink:type="simple"/></inline-formula>, under which conditions the capacity is close to the maximum possible value.</p>
        <p>There are two types of modifications in the neural dynamical system in our model: modification through learning (i.e., change in the synapse strength) and that by the injection of the input (i.e., change in the input strength). To understand these modifications, we first analyze the modification of spontaneous dynamics by the learning process and then study the modification upon the injection of an input. The abovementioned modification and analysis are discussed in the present and subsequent subsections, respectively. To be specific, we examine the typical orbits of neural activity in the absence of any input, by considering a dynamical system with fixed synaptic strength in the early and late stages of the learning process. <xref ref-type="fig" rid="pone-0017432-g007">Figures 7</xref>, <xref ref-type="fig" rid="pone-0017432-g008">8</xref>, and <xref ref-type="fig" rid="pone-0017432-g009">9</xref> show examples of typical orbits in the attractors, determined on the basis of the results of the 4th, 8th, and 9th learning steps. After targets 1, 2, 3, and 4 are learned, the neural activity in the output layer in the absence of any input is itinerant over three patterns that are close to three of the target patterns before the neural activity reaches a fixed point, as shown in <xref ref-type="fig" rid="pone-0017432-g007">Figure 7</xref>. The output activity approaches targets 3, 4, and 1 successively before converging to the fixed point. This itinerancy over the targets at transient time is commonly observed for several initial conditions in the orbits in the early stages of the learning process.</p>
        <fig id="pone-0017432-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Temporal evolution of neural activity in the case of fixed point.</title>
            <p>The spontaneous neural dynamics and the evoked one after four I/O mappings are learned are plotted. A) The time courses of the distance between the neural activity of the output and each target are plotted. Here, only the time courses representing the neural dynamics in the absence of input are plotted. The distance is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e166" xlink:type="simple"/></inline-formula>, The curves in different colors represent the distance from each target, while the black curve shows the distance from an unlearned target pattern, for reference. B) Neural activity in the output layer is represented as a point in the three-dimensional space and is projected from the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e167" xlink:type="simple"/></inline-formula>-dimensional space consisting of neural activities in the output layer by obtaining the product of the output activity and the target pattern(s). Each axis represents the product of neural activity and the corresponding target pattern, defined by axis1 = <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e168" xlink:type="simple"/></inline-formula>, axis2 = <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e169" xlink:type="simple"/></inline-formula>, and axis3 = <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e170" xlink:type="simple"/></inline-formula>. The orbits of neural activities after learning I/O mappings are plotted. The black line and circle represent a transient trajectory and a fixed-point attractor in the absence of inputs, respectively. The colored (red, green, and blue) lines and circles represent the trajectories and fixed-point attractors in the presence of inputs, respectively, with each color indicating the corresponding input. In the absence of an input, the neural activity once approaches some fixed point corresponding to the given target outputs and then departs, before finally converging to the fixed-point attractor. Upon the application of an input, the fixed-point attractor becomes unstable, and hence, the neural activity is attracted to a new fixed point, thereby giving rise to a target output corresponding to the input.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g007" xlink:type="simple"/>
        </fig>
        <fig id="pone-0017432-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Temporal evolution of neural activity when the attractor without inputs is a limit cycle.</title>
            <p>The spontaneous neural dynamics and the evoked one after learning eight I/O mappings are plotted, same as <xref ref-type="fig" rid="pone-0017432-g007">Fig. 7</xref>. A) The time courses of the distance between the neural activity of the output and each target are plotted. Notations are same as <xref ref-type="fig" rid="pone-0017432-g007">Fig. 7</xref> A. The time courses after transient time are plotted for focusing on limit-cycle attractor. B) Neural activity in the output layer is represented as a locus in a three-dimensional space, projected from the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e171" xlink:type="simple"/></inline-formula>-dimensional space consisting of neural activities in the output layer, by obtaining the product of the output activity and the combined target pattern(s). Each axis represents the product of the neural activity and the corresponding combined target patterns <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e172" xlink:type="simple"/></inline-formula>, defined in the figure. Plotted by using the same notations used in <xref ref-type="fig" rid="pone-0017432-g007">Fig. 7</xref>. The black curve is not a transient orbit but a limit cycle in the absence of inputs. The colored curves represent the transient trajectories when inputs are applied under two initial conditions (black squares), which are not the initial conditions for the limit cycle. In the presence of an input, the limit-cycle attractor collapses, and the neural activities reach fixed points, giving rise to the corresponding target outputs. These fixed points are represented by circles in different colors, while transient trajectories from only two initial points are shown here. However, trajectories from all points on the limit-cycle reach the corresponding target with the application of a given input. On the other hand, the limit cycle attractor in the absence of inputs approaches and deviates from the points matching the targets, which are fixed points in the presence of inputs as mentioned above. The bifurcation from the spontaneous limit-cycle attractor to the evoked fixed-point attractor is plotted in detail in <xref ref-type="fig" rid="pone-0017432-g007">Fig. 12</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g008" xlink:type="simple"/>
        </fig>
        <fig id="pone-0017432-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Temporal evolution of neural activity when the attractor without inputs is a complex limit cycle.</title>
            <p>The spontaneous neural dynamics and the evoked one after learning nine I/O mappings are plotted, same as <xref ref-type="fig" rid="pone-0017432-g007">Figs. 7</xref> and <xref ref-type="fig" rid="pone-0017432-g007">8</xref>. A) The time courses of the distance between the neural activity of the output and each target are plotted as <xref ref-type="fig" rid="pone-0017432-g007">Fig. 8</xref>. B) An example of complex spontaneous activity dynamics. Neural activity in the output layer is represented as <xref ref-type="fig" rid="pone-0017432-g007">Fig. 8</xref>. Each axis represents the product of the neural activity and the corresponding combined target patterns <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e173" xlink:type="simple"/></inline-formula>, defined in the figure. The plot shows the locus of neural activity, which yields a complex limit cycle in the absence of inputs. Green circles represent the learned targets patterns. The limit cycle approaches some of the targets more than once.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g009" xlink:type="simple"/>
        </fig>
        <p>As the learning progresses further, two prominent changes are observed in the neural dynamics in the absence of inputs. First, there is an increase in the number of attractors in the system. As shown in <xref ref-type="fig" rid="pone-0017432-g010">Figure 10</xref>, the number of fixed-point attractors increases with the number of learned mappings. With a further increase in the number of the learning steps, however, the number of fixed-point attractors begins to decrease, as these attractors are replaced by one or more limit-cycle attractors. A limit cycle, however, does not always appear, but its emergence depends on the earlier learning process.</p>
        <fig id="pone-0017432-g010" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g010</object-id>
          <label>Figure 10</label>
          <caption>
            <title>Change in the number of attractors during the learning process.</title>
            <p>Numbers of fixed-point attractors (green line) and limit-cycle attractors (blue line) and the total number of attractors (red line) in the absence of inputs as a function of the number of learning steps, i.e., number of learned targets, are plotted. In the early stages of the learning process, the number of fixed-point attractors increases, while in the later stage (after 5 or 6 learning steps), the number of fixed-point attractors decreases (fixed-point attractors are replaced by limit-cycle attractors).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g010" xlink:type="simple"/>
        </fig>
        <p>The limit-cycle orbit itinerates over target patterns as an attractor; in contrast, the orbits in the fixed-point attractor are transient. <xref ref-type="fig" rid="pone-0017432-g008">Figure 8</xref> shows an example of an orbit at a limit-cycle attractor without inputs after eight I/O mappings are learned, such that the orbit (not a transient orbit as shown in <xref ref-type="fig" rid="pone-0017432-g007">Fig. 7</xref>) itinerates over the targets in the cyclic order 1, 2, 4, 7, and 5 (12475). Here, we describe a limit cycle itinerating over targets in the order a, b, c (abc) for simplicity. Note that the number of itinerated targets is not always equal to the number of learned targets; further, the order of itineration over the targets is not same as the order of target learning, but depends on each trial of the learning process. For example, after learning five sets, some of the limit-cycle attractors cover all the memorized patterns (12345), while some others cover the memorized patterns only partially (123). In addition, some limit cycles are highly complex and visit the neighbors of the same targets a few times during a given cycle in the order (1345712589), as shown in <xref ref-type="fig" rid="pone-0017432-g009">Figure 9</xref>. In this sense, the flow of neural activities in the absence of inputs “prepares” for the target output pattern to be stabilized by the inputs. These itinerant dynamics in the absence of inputs may correspond to the spontaneous activity dynamics in the brain, as will be discussed later.</p>
        <p>In the learning process, the flow structure of the neural dynamics is modified so that the neural dynamics in the absence of inputs come closer to the learned target patterns. We compute the distance between a target and an output neural activity by starting from a given initial condition for the neural activity. Here, we define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e174" xlink:type="simple"/></inline-formula> as the minimum distance between the a target and the output activity in the time course, averaged over a variety of initial neural states after each learning step (See caption of <xref ref-type="fig" rid="pone-0017432-g011">Fig. 11</xref>). <xref ref-type="fig" rid="pone-0017432-g011">Figure 11</xref> shows the plot of the aforementioned minimum distance versus the number of learning steps. As the learning process progresses, the minimum distance between the output activity and each target learned so far successively decreases. This indicates more orbits from initial points in the phase space come close to the target patterns, after the target patterns are learned. This decrease is observed only when the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e175" xlink:type="simple"/></inline-formula> is satisfied. Indeed, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e176" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e177" xlink:type="simple"/></inline-formula>, the distance between the output activity and a few latest targets is small, but the distance between the output activity and the earlier targets is large. This observation suggests that traces of previous memories have already been erased (<xref ref-type="supplementary-material" rid="pone.0017432.s001">Figure S1</xref>).</p>
        <fig id="pone-0017432-g011" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g011</object-id>
          <label>Figure 11</label>
          <caption>
            <title>Change in the minimum distance between the activity and the target during the learning process.</title>
            <p><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e178" xlink:type="simple"/></inline-formula> gives the minimum distance between the neural activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e179" xlink:type="simple"/></inline-formula> and the target <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e180" xlink:type="simple"/></inline-formula>, averaged over phase space in the absence of inputs. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e181" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e182" xlink:type="simple"/></inline-formula> include the activity of the neurons in the output and hidden layers. The target <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e183" xlink:type="simple"/></inline-formula> becomes identical to the neural activity pattern after convergence to target <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e184" xlink:type="simple"/></inline-formula> in the output layer. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e185" xlink:type="simple"/></inline-formula> is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e186" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e187" xlink:type="simple"/></inline-formula> is the average over the initial conditions. The average <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e188" xlink:type="simple"/></inline-formula> is obtained over 1000 initial conditions for the neural activities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e189" xlink:type="simple"/></inline-formula>. The red and blue lines represent <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e190" xlink:type="simple"/></inline-formula> about all targets <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e191" xlink:type="simple"/></inline-formula> after learning one and nine (I/O) mappings, respectively. Only the minimum distance between the neural activity and the learned target decreases.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g011" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3e">
        <title>Bifurcation with the Input Strength</title>
        <p>To close the <xref ref-type="sec" rid="s3">Results</xref> section, we study how the attractor of neural dynamics changes from the attractor for spontaneous activity to that representing the desired output when the input strength is increased. We show that when an input is applied, the attractor of the spontaneous activity dynamics bifurcates into a fixed-point attractor that represents the corresponding target, we also demonstrate, that depending on the input pattern, a distinct attractor corresponding to each target pattern is generated.</p>
        <p>Examples of such changes are shown in <xref ref-type="fig" rid="pone-0017432-g007">Figures 7</xref>, <xref ref-type="fig" rid="pone-0017432-g008">8</xref>, and <xref ref-type="fig" rid="pone-0017432-g009">9</xref>, where the attractor without inputs is a fixed point or a limit cycle. When an input is applied and its strength is increased, bifurcation occurs such that the original attractor (without the input) becomes unstable, and a stable fixed point representing the correspondent target pattern emerges. To carry out bifurcation analysis, we vary the input strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e192" xlink:type="simple"/></inline-formula> continuously instead of choosing the large input value adopted in the learning process, and study the corresponding changes in the attractor. When the spontaneous attractor is a fixed point, it remains stable up to a certain value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e193" xlink:type="simple"/></inline-formula>. With an increase in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e194" xlink:type="simple"/></inline-formula> beyond the threshold, saddle-node bifurcation to a novel fixed-point attractor occurs. When the attractor in the absence of inputs is a limit cycle, it collapses as a result of non-local bifurcation, and is replaced by the fixed-point attractor corresponding to each target pattern, with an increase in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e195" xlink:type="simple"/></inline-formula>. An example of a bifurcation diagram from the limit cycle to the fixed point for the target output pattern is shown in <xref ref-type="fig" rid="pone-0017432-g012">Fig. 12</xref>, where the activity of the target neuron at the attractor is plotted as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e196" xlink:type="simple"/></inline-formula>. As shown, the changes in the attractor involve several bifurcations, and the whole bifurcation sequence becomes complicated with an increase in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e197" xlink:type="simple"/></inline-formula>. Nevertheless, there are two common characteristics: collapse of the limit cycle for the spontaneous activity, as a result of non-local bifurcation and appearance of the target fixed point by saddle-node bifurcation. The former is caused by the contact formed between the limit-cycle attractor and the basin of another fixed-point attractor upon an increase in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e198" xlink:type="simple"/></inline-formula>, while the limit-cycle and the fixed-point attractors coexist over a certain range of input values, implying hysteresis. The fixed-point attractor generated by this collapse is generally not a fixed point that gives rise to the target output. With a further increase in the input parameters, saddle-node bifurcation leads to the attractor corresponding to the target.</p>
        <fig id="pone-0017432-g012" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g012</object-id>
          <label>Figure 12</label>
          <caption>
            <title>Bifurcation diagram through the input strength.</title>
            <p>The bifurcation diagram from the spontaneous limit cycle to the fixed point matching the target pattern is shown. The x-axis and the y-axis represent the strength of input, here, input 1 in <xref ref-type="fig" rid="pone-0017432-g007">Fig. 8</xref>, and the product between the neural activity in the output layer and the corresponding target. At each strength, we compute the neural activity evolving from an initial point chosen randomly and measure the product between the neural activity and the corresponding target for some constant time after transient time. Points representing values of this product are super-positioned at each strength. In the strength at more than 0.23 (see the arrow), the target is stable fixed-point attractor. In this area, both target fixed point and other attractors are stable, and at larger strength, only the former is stable, means this target is memorized in this network.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g012" xlink:type="simple"/>
        </fig>
        <p>It is also interesting to study the neural dynamics when two learned inputs are injected simultaneously. By changing the strength of each input, bifurcation against two parameters is studied (<xref ref-type="fig" rid="pone-0017432-g013">Fig. 13</xref>). We find some characteristic neural dynamics with different input strength. If the strength of input A <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e199" xlink:type="simple"/></inline-formula> is much larger than that of input B <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e200" xlink:type="simple"/></inline-formula>, the fixed-point attractor giving rise to the target A (phase FA in <xref ref-type="fig" rid="pone-0017432-g013">Fig. 13</xref>) is generated, and vice versa. When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e201" xlink:type="simple"/></inline-formula> is smaller, but much larger than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e202" xlink:type="simple"/></inline-formula>, the limit-cycle attractor in which the neural dynamics approaches the target A (phase LA in <xref ref-type="fig" rid="pone-0017432-g013">Fig. 13</xref>) is generated, and vice versa. Furthermore, when both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e203" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e204" xlink:type="simple"/></inline-formula> are much large and of the same order, there appears a new phase in which the two fixed-point attractors matching target A and target B coexist. In this case, depending on the initial state, either of targets A or B is retrieved as an output. On the other hand, when both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e205" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e206" xlink:type="simple"/></inline-formula> are smaller, novel limit-cycle attractors in which the neural dynamics approaches neither target A nor target B are generated. Since the bifurcations by applied two inputs are complicated, it is not so easy to draw the whole bifurcation diagram; <xref ref-type="fig" rid="pone-0017432-g013">Figure 13</xref> is a rough sketch of the diagram. Detailed study on the bifurcations will be left for future.</p>
        <fig id="pone-0017432-g013" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0017432.g013</object-id>
          <label>Figure 13</label>
          <caption>
            <title>Phase diagram of the neural dynamics under the application of two inputs.</title>
            <p>After the model neural network learned several input-output relations, we applied the two learned inputs A and B with the strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e207" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e208" xlink:type="simple"/></inline-formula>. By varying these two input strengths, we checked what type of attractors the neural dynamics are attracted to. Depending on the type of attractor, rough phase diagram is depicted. Each of the phases in the figure represents the following behavior; FA and FB: Only the fixed-point attractor with the output matching with the target A or B (FA) and target B (FB), respectively. FA+FB: Coexistence of the two fixed point attractors for the target A and B, reached depending on the initial condition. LA and LB: Limit-cycle attractor in which the neural dynamics approach the target A or target B, respectively. LN: novel limit cycle attractor in which the neural dynamics approach neither the target A nor target B. Shown here is a rough diagram, and actual bifurcations are more complicated, and also depend on each learning process.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.g013" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3f">
        <title>Possible Extension to Learn Complex Mappings</title>
        <p>In the present study, we have focused on the learning of one-to-one mapping between inputs and outputs. The strength of synaptic connections turns to be either very strong or very weak after learning, and therefore, only simple one-to-one mapping is possible. However, our model can be extended to allow for complex mapping. By adding more neurons in the hidden and output layers and also by introducing the upper thresholds for synaptic strength, complex tasks in which there is as certain degree of overlap of neurons between different input patterns can be learned and memorized. For example, we have confirmed that our algorithm can learn the following task, when the abovementioned modification is made to the model. The learning task involved mapping on the basis of input patterns (1, 0), (0, 1), and (1, 1) in the input layer, while the corresponding target patterns are set as (1, 0, 0), (0, 1, 0), and (0, 0, 1) respectively. Even though tuning the upper boundary of the synaptic connections is required, we have confirmed numerically that memorizing these I/O relationships with the overlapped inputs is indeed possible. Learning more complex tasks can be made possible by appropriate adjustment of the synaptic strength. We expect that our viewpoint -learning and memorizing of I/O patterns by shaping the neural activity dynamics so that they undergo the appropriate bifurcations- can be applied to more complex cases by appropriate extension of the present model.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>In the present paper, we have proposed a novel image of memory by using a dynamical system model for I/O mapping. Memory recall is achieved as a result of the bifurcation of the neural dynamics attractor from a spontaneous activity attractor to one that matches the target pattern induced by the input. The learning process shapes the “appropriate” flow structure of spontaneous neural dynamics. Indeed, this bifurcation viewpoint is consistent with the change in neural activity observed in a olfactory system in the recent experiment <xref ref-type="bibr" rid="pone.0017432-Mazor1">[6]</xref>, which has been discussed in the <xref ref-type="sec" rid="s1">Introduction</xref>.</p>
      <p>To demonstrate the learning process on the basis of the aforementioned idea, we present a model in which the learning process shapes the flow structure of the neural dynamics, through successive presentations of inputs and the corresponding outputs. We use a three-layered network with forward synapses from an input layer to a hidden layer and from the hidden layer to the output layer, as well as backward synapses from the output layer to a hidden layer; the use of such a network allows for autonomous neural dynamics even in the absence of inputs. Such an architecture with backward connections has been adopted for SRNs <xref ref-type="bibr" rid="pone.0017432-Elman1">[10]</xref> <xref ref-type="bibr" rid="pone.0017432-Jordan1">[11]</xref>, echo state networks <xref ref-type="bibr" rid="pone.0017432-Jaeger1">[13]</xref>, and liquid-state machines <xref ref-type="bibr" rid="pone.0017432-Maass1">[14]</xref>. The neurons in the hidden layer in these models are activated not only by the input neurons but also by the neighboring neurons in the layer; consequently, the dynamics of these neuron activities are not determined solely by the inputs but can autonomously change even in the absence of inputs, as in the case of our model. Studies on these models, however, have focused mainly on responses against input streams, with the aim of analyzing temporal information processing on the basis of the input history. In contrast, our study focuses on the change (bifurcation) from spontaneous activity dynamics to evoked dynamics in the presence of inputs and on the shaping of spontaneous dynamics through the learning process.</p>
      <p>For analyzing the changes in the flow structure during the learning process, the following points are discussed. First, to achieve the maximum number of memorized patterns, the appropriate relationship has to be satisfied among the time scales of the changes in the neural activity as well as among those of the changes in the plasticity of the FSs and BSs. Second, the flow structure of the spontaneous dynamics is changed during the learning process, and then, the neural dynamics in this flow structure are itinerant over the learned output patterns. In other words, spontaneous dynamics “prepare” for the stabilization of the corresponding outputs once the inputs are provided. Now, we discuss these two points in possible relationship with the results of recent experimental studies.</p>
      <sec id="s4a">
        <title>Synaptic Plasticity</title>
        <p>We adopt two architectures for synaptic plasticity: (i) multiple timescales and (ii) the ARP algorithm. Here, we discuss how these architectures can be implemented in our brain.</p>
        <sec id="s4a1">
          <title>(i) Multiple time scales</title>
          <p>The time scale of synaptic dynamics represents the magnitude of the synaptic plasticity, such as long-term potentiation and long-term depression, and these plasticities depend on the number and/or type of receptors of neural transmitters in our brain. Hence, the time scales for synaptic plasticity are related to the number and/or type of these receptors. When two areas (say between the hippocampus and the prefrontal cortex) are mutually connected, the synaptic connections for forward and backward connections may have different characteristics, and hence, the plasticities may differ between the two.</p>
          <p>Recall that in our model, a proper relationship has to be satisfied among the time scales of the changes in the FSs and BSs and in the neural activity, to achieve the maximum number of memorized patterns. On the basis of the above argument, it is suggested that such a difference in the plasticities may be implemented by the possible difference between the number distribution and/or types of receptors in the neurons for the forward and backward connections between the given areas.</p>
        </sec>
        <sec id="s4a2">
          <title>(ii) Adaptive reward-penalty</title>
          <p>In our model, the synaptic plasticity is switched between Hebbian and anti-Hebbian rules by the ARP algorithm, depending on the magnitude of the error signal. In our brain, neural modulators such as dopamine, serotonin, norepinephrine, and acetylcholine may give rise to this error signal. In particular, dopamine modulates the synaptic plasticity at the hetero-synaptic connection <xref ref-type="bibr" rid="pone.0017432-Jay1">[15]</xref> and is projected onto the cerebral cortex broadly. Furthermore, the activity of dopamine neurons is related to the extent to which the response matches the request <xref ref-type="bibr" rid="pone.0017432-Reynolds1">[16]</xref>. Hence, dopamine can act as a global error signal carrier. Then, it is suggested that the switching between positive and negative plasticity, corresponding to that between the Hebbian and anti-Hebbian rules in our model, is regulated by the concentration of dopamine.</p>
          <p>In the present study, we show that the maximum capacity can be realized by establishing an appropriate relationship between the time scales of FS and BS plasticity, and the results suggest that such multiple timescales would be important for memorizing. Recently, Fusi et al. <xref ref-type="bibr" rid="pone.0017432-Fusi1">[17]</xref> proposed a meta-plasticity-based model, which may involve multiple timescales similar to in our model, In their model, while the synaptic plasticity changes with external stimuli, the change is only stochastic, and neither neural activity dynamics nor synaptic plasticity is considered. In contrast, in our model, the interaction between neural dynamics and synaptic plasticity plays a key role in the memory process.</p>
        </sec>
      </sec>
      <sec id="s4b">
        <title>Spontaneous Activity</title>
        <p>Next, we discuss the spontaneous activity in our model and experimental studies. Recent experimental studies have revealed the existence of spontaneous neural activity, which is not simply noise but a result of the inherent dynamics in the brain <xref ref-type="bibr" rid="pone.0017432-Luczak1">[5]</xref> <xref ref-type="bibr" rid="pone.0017432-Kenet1">[9]</xref> <xref ref-type="bibr" rid="pone.0017432-Fox1">[18]</xref> <xref ref-type="bibr" rid="pone.0017432-Luczak2">[19]</xref>. Furthermore, such activity is shown to be related to the task-evoked or stimulus-evoked activity <xref ref-type="bibr" rid="pone.0017432-Kenet1">[9]</xref> <xref ref-type="bibr" rid="pone.0017432-Fox1">[18]</xref> <xref ref-type="bibr" rid="pone.0017432-Luczak2">[19]</xref>. In particular, it has been stated that the spontaneous activity in the visual system of a cat successively changes from one pattern to another <xref ref-type="bibr" rid="pone.0017432-Kenet1">[9]</xref>. Remarkably, these patterns are found to correspond to those evoked by a directional input signal. These evoked patterns are formed depending on the environment after birth, i.e., these patterns are formed by learning. Thus, the spontaneous dynamics itinerating over the learned patterns are shaped in the manner shown in our model, in which the target pattern is considered to be identical to the pattern evoked by visual stimuli.</p>
        <p>Theoretical discussions on such itinerant dynamics of neural activities have been carried out, with attractor ruin networks <xref ref-type="bibr" rid="pone.0017432-Tsuda1">[20]</xref> <xref ref-type="bibr" rid="pone.0017432-Gros1">[21]</xref> and heteroclinic cycles <xref ref-type="bibr" rid="pone.0017432-Rabinovich1">[22]</xref> <xref ref-type="bibr" rid="pone.0017432-RabinovichMI1">[23]</xref>; experimental evidence for these dynamics has also been provided <xref ref-type="bibr" rid="pone.0017432-Sasaki1">[24]</xref>. In these studies, it has been show that the neural activity itinerates over the memorized patterns one by one, similar to the spontaneous activities in our model. However, the manner in which learning gives rise to these itinerant dynamics has not been clarified. In our study, we show the generation of spontaneous activities by the successive learning of I/O mappings through Hebbian and anti-Hebbian rules.</p>
        <p>We put forward the idea “memory as organization of flow structure” or “memory as flow,” which is in sharp contrast to the idea of “memories as attractors.” According to proposed idea, the neural dynamics in the presence and absence of different inputs are distinct and separated because of the change in the flow of neural activities. The distinct change in the flow is formulated as bifurcation, which stabilizes distinct memorized patterns (in this sense, our viewpoint can also be termed “memories as bifurcations”). This bifurcation against the input strength will be experimentally confirmed by measuring the neural activity for different external stimuli.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pone.0017432.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0017432.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p><bold>Change in the minimum distance between the activity and the target.</bold> Change in the minimum distance between the output activity and the target during the learning process are plotted. The minimum distance <italic>D<sub>min</sub></italic> at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e209" xlink:type="simple"/></inline-formula> = 1 and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e210" xlink:type="simple"/></inline-formula> = 128 is plotted in Figs. A and B, respectively. Here, <italic>D<sub>min</sub></italic> is defined in the same manner as in <xref ref-type="fig" rid="pone-0017432-g009">Figure 9</xref>. Red and blue lines represent <italic>D<sub>min</sub></italic> after one and ten learning steps, respectively. The distance to one (or a few) target(s) is small, while in <xref ref-type="fig" rid="pone-0017432-g009">Figure 9</xref>, the distance to almost all the targets is small for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0017432.e211" xlink:type="simple"/></inline-formula> = 8.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors would like to thank I. Tsuda, Y. Takahashi, and S. Ishihara for their invaluable comments.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0017432-Willshaw1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Willshaw</surname><given-names>DJ</given-names></name><name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name></person-group>             <year>1976</year>             <article-title>How patterned neural connections can be set up by Self-Organization.</article-title>             <source>Royal Society of London Proceedings Series B</source>             <volume>194</volume>             <fpage>431</fpage>             <lpage>445</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Hopfield1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group>             <year>1984</year>             <article-title>Neurons with graded response have collective computational properties like those of two-state neurons.</article-title>             <source>Proceedings of the National Academy of Sciences of the United States of America</source>             <volume>81</volume>             <fpage>3088</fpage>             <lpage>3092</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Kohonen1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kohonen</surname><given-names>T</given-names></name></person-group>             <year>1982</year>             <article-title>Self-organized formation of topologically correct feature maps.</article-title>             <source>Biological Cybernetics</source>             <volume>43</volume>             <fpage>59</fpage>             <lpage>69</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Rumelhart1">
        <label>4</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rumelhart</surname><given-names>DE</given-names></name><name name-style="western"><surname>Mcclelland</surname><given-names>JL</given-names></name></person-group>             <year>1986</year>             <article-title>Parallel distributed processing: explorations in the microstructure of cognition.</article-title>             <fpage>318</fpage>             <lpage>362</lpage>             <comment>Volume 1. Foundations. MIT Press, Cambridge, MA; None</comment>          </element-citation>
      </ref>
      <ref id="pone.0017432-Luczak1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Luczak</surname><given-names>A</given-names></name><name name-style="western"><surname>Barth</surname><given-names>P</given-names></name><name name-style="western"><surname>Marguet</surname><given-names>SL</given-names></name><name name-style="western"><surname>Buzski</surname><given-names>G</given-names></name><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name></person-group>             <year>2007</year>             <article-title>Sequential structure of neocortical spontaneous activity in vivo.</article-title>             <source>Proceedings of the National Academy of Sciences</source>             <volume>104</volume>             <fpage>347</fpage>             <lpage>352</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Mazor1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mazor</surname><given-names>O</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Transient dynamics versus fixed points in odor representations by locust antennal lobe projection neurons.</article-title>             <source>Neuron</source>             <volume>48</volume>             <fpage>661</fpage>             <lpage>673</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Barto1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barto</surname><given-names>AG</given-names></name><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name><name name-style="western"><surname>Brouwer</surname><given-names>PS</given-names></name></person-group>             <year>1981</year>             <article-title>Associative search network: A reinforcement learning associative memory.</article-title>             <source>Biological Cybernetics</source>             <volume>40</volume>             <fpage>201</fpage>             <lpage>211</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Xie1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Xie</surname><given-names>X</given-names></name><name name-style="western"><surname>Seung</surname><given-names>HS</given-names></name></person-group>             <year>2004</year>             <article-title>Learning in neural networks by reinforcement of irregular spiking.</article-title>             <source>Physical Review E</source>             <volume>69</volume>             <fpage>041909</fpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Kenet1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kenet</surname><given-names>T</given-names></name><name name-style="western"><surname>Bibitchkov</surname><given-names>D</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name><name name-style="western"><surname>Arieli</surname><given-names>A</given-names></name></person-group>             <year>2003</year>             <article-title>Spontaneously emerging cortical representations of visual attributes.</article-title>             <source>Nature</source>             <volume>425</volume>             <fpage>954</fpage>             <lpage>956</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Elman1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Elman</surname><given-names>JL</given-names></name></person-group>             <year>1990</year>             <article-title>Finding structure in time.</article-title>             <source>Cognitive Science</source>             <volume>14</volume>             <fpage>179</fpage>             <lpage>211</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Jordan1">
        <label>11</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>             <year>1990</year>             <article-title>Attractor dynamics and parallelism in a connectionist sequential machine.</article-title>             <source>Artificial neural networks: concept learning, IEEE Press</source>             <fpage>112</fpage>             <lpage>127</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Kurikawa1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kurikawa</surname><given-names>T</given-names></name><name name-style="western"><surname>Kaneko</surname><given-names>K</given-names></name></person-group>             <year>2010</year>             <article-title>Learning shapes bifurcations of neural dynamics upon external stimuli.</article-title>             <fpage>155</fpage>             <lpage>162</lpage>             <comment>Neural Information Processing Theory and Algorithms 17th International Conference, ICONIP 2010, Sydney, Australia, November 22-25, 2010, Proceedings, Part I</comment>          </element-citation>
      </ref>
      <ref id="pone.0017432-Jaeger1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jaeger</surname><given-names>H</given-names></name><name name-style="western"><surname>Haas</surname><given-names>H</given-names></name></person-group>             <year>2004</year>             <article-title>Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication.</article-title>             <source>Science</source>             <volume>304</volume>             <fpage>78</fpage>             <lpage>80</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Maass1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Maass</surname><given-names>W</given-names></name><name name-style="western"><surname>Natschlger</surname><given-names>T</given-names></name><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name></person-group>             <year>2002</year>             <article-title>Real-Time computing without stable states: A new framework for neural computation based on perturbations.</article-title>             <source>Neural Computation</source>             <volume>14</volume>             <fpage>2531</fpage>             <lpage>2560</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Jay1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jay</surname><given-names>TM</given-names></name></person-group>             <year>2003</year>             <article-title>Dopamine: a potential substrate for synaptic plasticity and memory mechanisms.</article-title>             <source>Progress in Neurobiology</source>             <volume>69</volume>             <fpage>375</fpage>             <lpage>390</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Reynolds1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Reynolds</surname><given-names>JNJ</given-names></name><name name-style="western"><surname>Hyland</surname><given-names>BI</given-names></name><name name-style="western"><surname>Wickens</surname><given-names>JR</given-names></name></person-group>             <year>2001</year>             <article-title>A cellular mechanism of reward-related learning.</article-title>             <source>Nature</source>             <volume>413</volume>             <fpage>67</fpage>             <lpage>70</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Fusi1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name><name name-style="western"><surname>Drew</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name></person-group>             <year>2005</year>             <article-title>Cascade models of synaptically stored memories.</article-title>             <source>Neuron</source>             <volume>45</volume>             <fpage>599</fpage>             <lpage>611</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Fox1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fox</surname><given-names>MD</given-names></name><name name-style="western"><surname>Snyder</surname><given-names>AZ</given-names></name><name name-style="western"><surname>Vincent</surname><given-names>JL</given-names></name><name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name><name name-style="western"><surname>Essen</surname><given-names>DCV</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks.</article-title>             <source>Proceedings of the National Academy of Sciences of the United States of America</source>             <volume>102</volume>             <fpage>9673</fpage>             <lpage>9678</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Luczak2">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Luczak</surname><given-names>A</given-names></name><name name-style="western"><surname>Barth</surname><given-names>P</given-names></name><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name></person-group>             <year>2009</year>             <article-title>Spontaneous events outline the realm of possible sensory responses in neocortical populations.</article-title>             <source>Neuron</source>             <volume>62</volume>             <fpage>413</fpage>             <lpage>425</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Tsuda1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tsuda</surname><given-names>I</given-names></name></person-group>             <year>2001</year>             <article-title>Toward an interpretation of dynamic neural activity in terms of chaotic dynamical systems.</article-title>             <source>Behavioral and Brain Sciences</source>             <volume>24</volume>             <fpage>793</fpage>             <lpage>810</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Gros1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gros</surname><given-names>C</given-names></name></person-group>             <year>2009</year>             <article-title>Cognitive computation with autonomously active neural networks: An emerging field.</article-title>             <source>Cognitive Computation</source>             <volume>1</volume>             <fpage>77</fpage>             <lpage>90</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Rabinovich1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rabinovich</surname><given-names>M</given-names></name><name name-style="western"><surname>Huerta</surname><given-names>R</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>NEUROSCIENCE: transient dynamics for neural processing.</article-title>             <source>Science</source>             <volume>321</volume>             <fpage>48</fpage>             <lpage>50</lpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-RabinovichMI1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>RabinovichMI</surname></name><name name-style="western"><surname>Huerta</surname><given-names>R</given-names></name><name name-style="western"><surname>Varona</surname><given-names>P</given-names></name><name name-style="western"><surname>Afraimovich</surname><given-names>VS</given-names></name></person-group>             <year>2008</year>             <article-title>Transient cognitive dynamics, metastability, and decision making.</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>e1000072</fpage>          </element-citation>
      </ref>
      <ref id="pone.0017432-Sasaki1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sasaki</surname><given-names>T</given-names></name><name name-style="western"><surname>Matsuki</surname><given-names>N</given-names></name><name name-style="western"><surname>Ikegaya</surname><given-names>Y</given-names></name></person-group>             <year>2007</year>             <article-title>Metastability of active CA3 networks.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>517</fpage>             <lpage>528</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>