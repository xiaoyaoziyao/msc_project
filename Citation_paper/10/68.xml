<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01106</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002250</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Coding mechanisms</subject>
                <subject>Sensory systems</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Visual system</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Systems biology</subject>
          </subj-group>
          <subj-group>
            <subject>Theoretical biology</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Physics</subject>
          <subj-group>
            <subject>Biophysics</subject>
            <subj-group>
              <subject>Biophysics theory</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Genetics and Genomics</subject>
          <subject>Neuroscience</subject>
          <subject>Physics</subject>
        </subj-group>
      </article-categories><title-group><article-title>A Sparse Coding Model with Synaptically Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of V1 Simple Cell Receptive Fields</article-title><alt-title alt-title-type="running-head">Spiking and Synaptically Local Sparse Coding Model</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Zylberberg</surname>
            <given-names>Joel</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Murphy</surname>
            <given-names>Jason Timothy</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>DeWeese</surname>
            <given-names>Michael Robert</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Physics, University of California, Berkeley, California, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Redwood Center for Theoretical Neuroscience, University of California, Berkeley, California, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Helen Wills Neuroscience Institute, University of California, Berkeley, California, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">joelz@berkeley.edu</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: JZ. Performed the experiments: JZ. Analyzed the data: JZ. Contributed reagents/materials/analysis tools: JTM. Wrote the paper: JZ MRD.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>10</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>27</day>
        <month>10</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>10</issue><elocation-id>e1002250</elocation-id><history>
        <date date-type="received">
          <day>26</day>
          <month>7</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>8</day>
          <month>9</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Zylberberg et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Sparse coding algorithms trained on natural images can accurately predict the features that excite visual cortical neurons, but it is not known whether such codes can be learned using biologically realistic plasticity rules. We have developed a biophysically motivated spiking network, relying solely on synaptically local information, that can predict the full diversity of V1 simple cell receptive field shapes when trained on natural images. This represents the first demonstration that sparse coding principles, operating within the constraints imposed by cortical architecture, can successfully reproduce these receptive fields. We further prove, mathematically, that sparseness and decorrelation are the key ingredients that allow for synaptically local plasticity rules to optimize a cooperative, linear generative image model formed by the neural representation. Finally, we discuss several interesting emergent properties of our network, with the intent of bridging the gap between theoretical and experimental studies of visual cortex.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>In a sparse coding model, individual input stimuli are represented by the activities of model neurons, the majority of which are inactive in response to any particular stimulus. For a given class of stimuli, the neurons are optimized so that the stimuli can be faithfully represented with the minimum number of co-active units. This has been proposed as a model for visual cortex. While it has previously been demonstrated that sparse coding model neurons, when trained on natural images, learn to represent the same features as do neurons in primate visual cortex, it remains to be demonstrated that this can be achieved with physiologically realistic plasticity rules. In particular, learning in cortex appears to occur by the modification of synaptic connections between neurons, which must depend only on information available locally, at the synapse, and not, for example, on the properties of large numbers of distant cells. We provide the first demonstration that synaptically local plasticity rules are sufficient to learn a sparse image code, and to account for the observed response properties of visual cortical neurons: visual cortex actually could learn a sparse image code.</p>
      </abstract><funding-group><funding-statement>The work of JZ is supported by funds from the University of California and a Fulbright international science and technology PhD fellowship. MRD gratefully acknowledges support from the National Science Foundation, the McKnight Foundation, the McDonnell Foundation, and the Hellman Family Faculty Fund. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="12"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>A central goal in systems neuroscience is to determine what underlying principles might shape sensory processing in the nervous system. Several coding optimization principles have been proposed, including redundancy reduction <xref ref-type="bibr" rid="pcbi.1002250-Attneave1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Atick1">[3]</xref>, and information maximization <xref ref-type="bibr" rid="pcbi.1002250-Linsker1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Tkaik1">[11]</xref>, which have both enjoyed some successes in predicting the behavior of real neurons <xref ref-type="bibr" rid="pcbi.1002250-Atick1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-DeWeese1">[12]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Dan1">[14]</xref>. Closely related to these notions of coding efficiency is the principle of sparseness <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, which posits that few neurons are active at any given time (population sparseness), or that individual neurons are responsive to few specific stimuli (lifetime sparseness).</p>
      <p>Sparseness is an appealing concept, in part because it provides a simple code for later stages of processing and it is in principle more quickly and easily modifiable by simple learning rules compared with more distributed codes involving many simultaneously active units <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Graham1">[18]</xref>. There is some experimental evidence for sparse coding in the cortex <xref ref-type="bibr" rid="pcbi.1002250-Graham1">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>, but there are also reports of dense neural activity <xref ref-type="bibr" rid="pcbi.1002250-Tolhurst1">[24]</xref> and mixtures of both <xref ref-type="bibr" rid="pcbi.1002250-Sakata1">[25]</xref> as well. Compounding this, it is not obvious what absolute standard should be used to assess the degree of sparseness in cortex, but it is notable that the relative level of sparseness of cortical responses to natural images increases when a larger fraction of the visual field is covered by the stimulus <xref ref-type="bibr" rid="pcbi.1002250-Vinje1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>, as a result of inhibitory interneuronal connections <xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>. Interestingly, the correlations between the neuronal activities also decreases when a larger area is stimulated, as a result of these inhibitory connections <xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>.</p>
      <p>In a landmark paper, Olshausen and Field <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref> reproduced several qualitative features of the receptive fields (RFs) of neurons in primary visual cortex (VI) without imposing any biological constraints other than their hypothesis that cortical representations simultaneously minimize the average activity of the neural population while maximizing fidelity when representing natural images. However, agreement with measured V1 simple cell receptive fields was not perfect <xref ref-type="bibr" rid="pcbi.1002250-Ringach1">[26]</xref>. Recently, a more sophisticated version of Olshausen and Field's algorithm <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref> has been developed that is capable of minimizing the number of active neurons rather than minimizing the average activity level across the neural population. This algorithm, called the sparse-set coding (SSC) network <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, learns the full set of physiologically observed RF shapes of simple cells in V1, which include small unoriented features, localized oriented features resembling Gabor wavelets, and elongated edge-detectors. We note that, under certain conditions <xref ref-type="bibr" rid="pcbi.1002250-Donoho1">[28]</xref> not necessarily satisfied by the natural image coding problem, minimizing the average activity across the neural population (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e001" xlink:type="simple"/></inline-formula>-norm minimization), as is done by Olshausen and Field's original Sparsenet algorithm, can be equivalent to minimizing the number of active units (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e002" xlink:type="simple"/></inline-formula>-norm minimization), as is achieved by Rehn and Sommer's SSC algorithm.</p>
      <p>The SSC model is the only sparse coding algorithm that has been shown to learn, from the statistics of natural scenes alone, RFs that are in quantitative agreement with those observed in V1. It has also been found that sufficiently overcomplete representations (4 times more model neurons than image pixels) that minimize the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e003" xlink:type="simple"/></inline-formula> norm can display the same qualitative variety of RF shapes, but these have not been quantitatively compared with physiologically measured RFs <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref>.</p>
      <p>Unfortunately, the lack of work on biophysically realistic sparse coding models has left in doubt whether V1 could actually employ a sparse code for natural scenes. Indeed, it is not clear how Olshausen's original algorithm <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, the highly overcomplete <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e004" xlink:type="simple"/></inline-formula>-norm minimization algorithm <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref>, or that of Rehn and Sommer <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, could be implemented in the cortex. Rather than employing local network modification rules such as the synaptic plasticity that is thought to underly learning in cortex <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref>, all three of these networks rely on learning rules requiring that each synapse has access to information about the receptive fields of many other, often distant, neurons in the network.</p>
      <p>Furthermore, both the SSC sparse coding model that has successfully reproduced the full diversity of V1 simple cell RFs <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref> as well as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e005" xlink:type="simple"/></inline-formula>-norm minimization algorithm that achieved qualitatively similar RFs <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref> involve non-spiking computational units: continuous-valued information is shared between units while inference is being performed. In cortex, however, information is transferred in discrete, stereotyped pulses of electrical activity called action potentials or spikes. Particularly for a sparse coding model with few or no spikes elicited per stimulus presentation, approximating spike trains with a graded function may not be justified. Spiking image processing networks have been studied <xref ref-type="bibr" rid="pcbi.1002250-Perrinet1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Savin1">[36]</xref>, but none of them have been shown to learn the full diversity of V1 RF shapes using local plasticity rules. It remains to be demonstrated that sparse coding can be achieved within the limitations imposed by biological architecture, and thus that it could potentially be an underlying principle of neural comptutation.</p>
      <p>Here we present a biologically-inspired variation on a network originally due to Földiàk <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref> that performs sparse coding with spiking neurons. Our model performs learning using only synaptically local rules. Using the fact that constraints imposed by such mechanisms as homeostasis and lateral inhibition cause the units in the network to remain sparse and independent throughout training, we prove mathematically that it learns to approximate the optimal linear generative model of the input, subject to constraints on the average lifetime firing rates of the units and the temporal correlations between the units' firing rates. This is the first demonstration that synaptically local plasticity rules are sufficient to account for the observed diversity of V1 simple cell RF shapes, and the first rigorous derivation of a relationship between synaptically local network modification rules and the twin properties of sparseness and decorrelation.</p>
      <p>Finally, we describe several emergent properties of our image coding network, in order to elucidate some experimentally testable hallmarks of our model. Interestingly, we observe a lognormal distribution of inhibitory connection strengths between the units in our model, when it is trained on natural images; such a distribution has previously been observed in the excitatory connections between neurons in rat V1 <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref>, but the inhibitory connection strength distribution remains unknown.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Our Sparse And Independent Local network (SAILnet) learns receptive fields that closely resemble those of V1 simple cells</title>
        <p>Our primary goal is to develop a biophysically inspired network of spiking neurons that learns to sparsely encode natural images, while employing only synaptically local learning rules. Towards this end, we implement a network of spiking, leaky integrate-and-fire units <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref> as model neurons. As in many previous models <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Hopfield1">[40]</xref>, each unit has a time dependent internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e006" xlink:type="simple"/></inline-formula> and an output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e007" xlink:type="simple"/></inline-formula> associated with it. The simulation of our network operates in discrete time. The neuronal output at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e008" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e009" xlink:type="simple"/></inline-formula>, is binary-valued: it is either 1 (spike) or 0 (no spike), whereas the internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e010" xlink:type="simple"/></inline-formula> is a continuous-valued function of time that is analogous to the membrane potential of a neuron. When this internal variable exceeds a threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e011" xlink:type="simple"/></inline-formula>, the unit fires a punctate spike of output activity that lasts for one time step. This thresholding feature plays the role of neuronal voltage-gated ion channels (represented, as in Hopfield's <xref ref-type="bibr" rid="pcbi.1002250-Hopfield1">[40]</xref> circuit model, by a diode) whose opening allows cortical neurons to fire. Other units in the network, and the inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e012" xlink:type="simple"/></inline-formula>, which are pixel intensities in an image, modify the internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e013" xlink:type="simple"/></inline-formula> by injecting current into the model neuron. The structure of our network, and circuit diagram of our neuron model, are illustrated in <xref ref-type="fig" rid="pcbi-1002250-g001">Fig. 1</xref>. The dynamics of SAILnet neurons are discussed in detail in the <xref ref-type="sec" rid="s4">Methods</xref> section.</p>
        <fig id="pcbi-1002250-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>SAILnet network architecture and neuron model.</title>
            <p>(A) Our network architecture is based on those of Rozell <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref> and Földiák <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref>, and inspired by recent physiology experiments <xref ref-type="bibr" rid="pcbi.1002250-Vinje1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Ecker1">[47]</xref>. Inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e014" xlink:type="simple"/></inline-formula> to the network (from image pixels) contact the neuron at connections (synapses) with strengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e015" xlink:type="simple"/></inline-formula>, whereas inhibitory recurrent connections between neurons <xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref> in the network have strengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e016" xlink:type="simple"/></inline-formula>. The outputs of the neurons are given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e017" xlink:type="simple"/></inline-formula>; these spiking outputs are communicated through the recurrent connections, and also on to subsequent stages of sensory processing, such as cortical area V2, which we do not include in our model. (B) Circuit diagram of our simplified leaky integrate-and-fire <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref> neuron model. The inputs from the stimulus with pixel values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e018" xlink:type="simple"/></inline-formula>, and the other neurons in the network, combine to form the input current <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e019" xlink:type="simple"/></inline-formula> to the cell. This current charges up the capacitor, while some current can leak to ground through a resistor in parallel with the capacitor. The resistors are shown as cylinders to highlight the fact that they model the collective action of ion channels in the cell membrane. The internal variable evolves in time via the differential equation for voltage across our capacitor, in response to input current <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e020" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e021" xlink:type="simple"/></inline-formula>, which we simulate in discrete time. Once that voltage exceeds threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e022" xlink:type="simple"/></inline-formula>, the diode, which models neuronal voltage-gated ion channels, opens, causing the cell to fire a punctate action potential, or spike, of activity. For sake of a complete circuit diagram, the output is denoted as the voltage, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e023" xlink:type="simple"/></inline-formula>, across some (small: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e024" xlink:type="simple"/></inline-formula>) resistance. After spiking, the unit's internal variable returns to the resting value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e025" xlink:type="simple"/></inline-formula>, from whence it can again be charged up.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g001" xlink:type="simple"/>
        </fig>
        <p>We assess the computational output of each neuron in response to a stimulus image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e026" xlink:type="simple"/></inline-formula> by counting the number of spikes emitted by that neuron, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e027" xlink:type="simple"/></inline-formula>, following stimulus onset for a brief period of time lasting five times the time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e028" xlink:type="simple"/></inline-formula> of the RC circuit. Our simulation updates the membrane potential every <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e029" xlink:type="simple"/></inline-formula>, thus there are 50 steps in the numerical integration following each stimulus presentation. Consequently, at least in principle, 50 is the maximum number of spikes we could observe from one neuron in response to any image. We note that one could instead use first-spike latencies to measure the computational output <xref ref-type="bibr" rid="pcbi.1002250-Delorme1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-VanRullen1">[35]</xref>; these two measures are highly correlated in our network, with shorter latencies corresponding to greater spike counts (data not shown). The network learns via rules similar to those of Földiák <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref>. These rules drive each unit to be active for only a small but non-zero fraction of the time (lifetime sparseness) and to maintain uncorrelated activity with respect to all other units in the network:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e030" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e031" xlink:type="simple"/></inline-formula> is the target average value for the number of spikes per image, which defines each neuron's lifetime sparseness, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e032" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e033" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e034" xlink:type="simple"/></inline-formula> are learning rates – small positive constants that determine how quickly the network modifies itself. Updating the feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e035" xlink:type="simple"/></inline-formula> in our model is achieved with Oja's implementation <xref ref-type="bibr" rid="pcbi.1002250-Oja1">[41]</xref> of Hebb's rule; this rule is what drives the network to represent the input. Note that because the firing rates are low (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e036" xlink:type="simple"/></inline-formula> spikes per image, for the results shown in this paper), and spikes can only be emitted in integer units, our model implicitly allows only small numbers of neurons to be active at any given time (so called “hard” sparseness, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e037" xlink:type="simple"/></inline-formula> sparseness), similar to what is achieved by other means in some recent non-spiking sparse coding models <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref>.</p>
        <p>These learning rules can be viewed as an approximate stochastic gradient descent approach to the <italic>constrained</italic> optimization problem in which the network seeks to minimize the error between the input pixel values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e038" xlink:type="simple"/></inline-formula>, and a linear generative model formed by all of the neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e039" xlink:type="simple"/></inline-formula>, while maintaining fixed average firing rates and no firing rate correlations. This constrained optimization interpretation of our learning rules, and the approximations involved, are discussed in the <xref ref-type="sec" rid="s4">Methods</xref> section.</p>
        <p>In <xref ref-type="fig" rid="pcbi-1002250-g002">Fig. 2</xref>, we demonstrate that the activity of the SAILnet units can be linearly decoded to recover (approximately) the input stimulus. The success of linear decoding in a model that encodes stimuli in a non-linear fashion is a product of our learning rules, and it has been observed in multiple sensory systems <xref ref-type="bibr" rid="pcbi.1002250-Bialek3">[42]</xref> and spiking neuron models optimized to maximize information transmission <xref ref-type="bibr" rid="pcbi.1002250-Bialek2">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-DeWeese1">[12]</xref>.</p>
        <fig id="pcbi-1002250-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>SAILnet activity can be linearly decoded to approximately recover the input stimulus.</title>
            <p>(A) An example of an image that was whitened using the filter of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, which is the same filter used to process the images in the training set. The image in panel (A) was not included in the training set. (B) A reconstruction of the whitened image in (A), by linear decoding of the firing rates of SAILnet neurons, which were trained on a different set of natural images. The input image was divided into non-overlapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e040" xlink:type="simple"/></inline-formula> pixel patches, each of which was preprocessed so as to have zero-mean and unit variance of the pixel values (like the training set). Each patch was presented to SAILnet, and the number of spikes were recorded from each unit in response to each patch. A linear decoding of SAILnet activity for each patch <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e041" xlink:type="simple"/></inline-formula> was formed by multiplying each unit's activity by that unit's RF and summing over all neurons. The preprocessing was then inverted, and the patches were tiled together to form the image in panel (B). The decoded image resembles the original, but is not identical, owing to the severe compression ratio; on average, each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e042" xlink:type="simple"/></inline-formula> input patch, which is defined by 256 continuous-valued parameters, is represented by only 75 binary spikes of activity, emitted by a small subset of the neural population. Linear decodability is a product of our learning rules, and it is an observed feature of multiple sensory systems <xref ref-type="bibr" rid="pcbi.1002250-Bialek3">[42]</xref> and spiking neuron models optimized to maximize information transmission <xref ref-type="bibr" rid="pcbi.1002250-Bialek2">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-DeWeese1">[12]</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g002" xlink:type="simple"/>
        </fig>
        <p>Our learning rules encourage all neurons to have the same average firing rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e043" xlink:type="simple"/></inline-formula> spikes per image, which may at first appear to be at odds with the observation <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref> that cortical neurons display a broad distribution of activities – firing rates vary from neuron to neuron.</p>
        <p>However, when trained on natural images, neurons in SAILnet can actually exhibit a fairly broad range of firing rates. Moreover, the mean firing rate distribution ranges from approximately lognormal to exponential in response to natural image stimuli, depending on the mean contrast of the stimulus ensemble with which they are probed. We discuss this further in the Firing Rates section below.</p>
        <p>We emphasize here that each of our learning rules is “synaptically” local: the information required to determine the change in the connection strength at any synaptic junction between two units is merely the activity of the pre- and post-synaptic units. The inhibitory lateral connection strengths, for example, are modified according to how many spikes arrived at the synapse, and how many times the post-synaptic unit spiked. The information required for the unit to modify its firing threshold is the unit's own firing rate. Finally, the rule for modifying the feed-forward connections requires only the pre-synaptic activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e044" xlink:type="simple"/></inline-formula>, the post-synaptic activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e045" xlink:type="simple"/></inline-formula>, and the present strength of that connection <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e046" xlink:type="simple"/></inline-formula>. This locality is a desirable model feature because learning in cortex is thought <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref> to occur by the modification of synaptic strengths and thus by necessity should depend only upon information available locally at the synapse.</p>
        <p>By contrast, much previous work <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet2">[33]</xref> has used a different learning rule for the feed forward weights: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e047" xlink:type="simple"/></inline-formula>. This rule is non-local because the update for the connection strength between input pixel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e048" xlink:type="simple"/></inline-formula> and unit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e049" xlink:type="simple"/></inline-formula> requires information about the activities and feed-forward weights of every other unit in the network (indexed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e050" xlink:type="simple"/></inline-formula>). It is unlikely that such information is available to individual synapses in cortex. Interestingly, in the limit of highly sparse and uncorrelated neuronal activities, our local learning rule approximates the non-local rule used by previous workers <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet2">[33]</xref>, when averaged over several input images; we provide a mathematical derivation of this result in the <xref ref-type="sec" rid="s4">Methods</xref> section. This suggests an additional reason why sparseness is beneficial for cortical networks, in which plasticity is local, but cooperative representations may be desired.</p>
        <p>We trained a 1536-unit SAILnet with sparseness <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e051" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e052" xlink:type="simple"/></inline-formula> pixel image patches drawn randomly from whitened natural images from the image set of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>. The network is six-times overcomplete with respect to the number of input pixels. This mimics the anatomical fact that V1 contains many more neurons than does LGN, from which it receives its inputs. Owing to the computational complexity of the problem – there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e053" xlink:type="simple"/></inline-formula> parameters to be learned in a SAILnet model containing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e054" xlink:type="simple"/></inline-formula> neurons – we found it prohibitive to consider networks that are much more than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e055" xlink:type="simple"/></inline-formula> overcomplete.</p>
        <p>Our six-times overcompleteness is in a sense analogous to the three-times overcompleteness of the SSC network described by Rehn and Sommer <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, since the outputs of their computational units could be either positive or negative, while our model neurons can output only one type of spike. Thus, each of their units can be thought of as representing a pair of our neurons, with opposite-signed receptive fields.</p>
        <p>The RFs of 196 randomly selected units from our SAILnet are shown in <xref ref-type="fig" rid="pcbi-1002250-g003">Fig. 3</xref>, as measured by their spike-triggered average activity in response to whitened natural images. These are virtually identical to the feed-forward weights of the units; in the <xref ref-type="sec" rid="s4">Methods</xref> section, we discuss why this must be the case.</p>
        <fig id="pcbi-1002250-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>SAILnet learns receptive fields (RFs) with the same diversity of shapes as those of simple cells in macaque primary visual cortex (V1).</title>
            <p>(A) 98 randomly selected receptive fields recorded from simple cells in macaque monkey V1 (courtesy of D. Ringach). Each square in the grid represents one neuronal RF. The sizes of these RFs, and their positions within the windows, have no meaning in comparison to the SAILnet data. The data to the right of the break line have an angular scale (degrees of visual angle spanned horizontally by the displayed RF window) of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e056" xlink:type="simple"/></inline-formula>, whereas those to the left of it span <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e057" xlink:type="simple"/></inline-formula>. (B) RFs of 196 randomly selected model neurons from a 1536-unit SAILnet trained on patches drawn from whitened natural images. The gray value in all squares represents zero, whereas the lighter pixels correspond to positive values, and the darker pixels correspond to negative values. All RFs are sorted by a size parameter, determined by a Gabor function best fit to the RF. The SAILnet model RFs show the same diversity of shapes as do the RFs of simple cells in macaque monkey V1 (A); both the model units and the population of recorded V1 neurons consist of small unoriented features, oriented Gabor-like wavelets containing multiple subfields, and elongated edge-detectors. (C) We fit the SAILnet and macaque RFs to Gabor functions (see <xref ref-type="sec" rid="s4">Methods</xref> section), in order to quantify their shapes. Shown are the dimensionless <italic>width</italic> and <italic>length</italic> parameters (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e058" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e059" xlink:type="simple"/></inline-formula>, respectively) of the 299 SAILnet RFs and 116 (out of 250 RFs in the dataset) macaque RFs for which the Gabor fitting routine converged. These parameters represent the size of the Gaussian envelope in either direction, in terms of the number of cycles of the sinusoid. The SAILnet data (open blue circles) span the space of the macaque data (solid red squares) from our Gabor fitting analysis; SAILnet is accounting for all of the observed RF shapes. We highlight four SAILnet RFs with distinct shapes, which are identified by the large triangular symbols that are also displayed next to the corresponding RFs in panel (B).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g003" xlink:type="simple"/>
        </fig>
        <p>To facilitate a comparison between the SAILnet RFs, and those measured in macaque V1 (courtesy of D. Ringach), we fit both the SAILnet, and the macaque RFs to Gabor functions. As in the SSC study of Rehn and Sommer <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, only those RFs that could be sensibly described by a Gabor function were included in <xref ref-type="fig" rid="pcbi-1002250-g003">Fig. 3</xref>; for example, we excluded RFs with substantial support along the square boundary, suggesting that the RF is only partly visible. In the <xref ref-type="sec" rid="s4">Methods</xref> section, we discuss the Gabor fitting routine and the quality control measures we used to define and identify meaningful fits.</p>
        <p>Our SAILnet model RFs show the same diversity of shapes observed in macaque V1, and in the non-local SSC model <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>. They consist of three qualitatively distinct classes of neuronal RFs: small unoriented features, localized and oriented Gabor-like filters, and elongated edge-detectors. Our SAILnet learning rules approximately minimize the same cost function as the SSC model <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, albeit with constraints as opposed to unconstrained optimization, which explains how it is possible for SAILnet to learn similar RFs using only local rules. Furthermore, in our model, the number of co-active units is small, owing to the low average lifetime neuronal firing rates, and the fact that spikes can only be emitted in integer numbers. This feature is similar to the L<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e060" xlink:type="simple"/></inline-formula>-norm minimization used in the SSC model of Rehn and Sommer <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref> and the LCA model of Rozell and colleagues <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref>.</p>
        <p>This is the first demonstration that a network of spiking neurons using only synaptically local plasticity rules applied to natural images can account for the observed diversity of V1 simple cell RF shapes.</p>
      </sec>
      <sec id="s2b">
        <title>SAILnet units exhibit a broad distribution of mean firing rates in response to natural images</title>
        <p>Our learning rules (Eq. 1) encourage every unit to have the same target value, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e061" xlink:type="simple"/></inline-formula>, for its average firing rate, which might appear to be inconsistent with observations <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Baddeley1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Abeles1">[44]</xref> that cortical neurons exhibit a broad distribution of mean firing rates. However, we find that SAILnet, too, can display a wide range of mean rates, as we now describe.</p>
        <p>To determine the distribution of mean firing rates across the population of model neurons in our network, we first trained a 1536-unit SAILnet on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e062" xlink:type="simple"/></inline-formula> pixel patches drawn from whitened natural images, and then presented the network with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e063" xlink:type="simple"/></inline-formula> patches taken from the training ensemble. Our measurement was performed with all learning rates set to zero, so that we were probing the properties of the network at one fixed set of learned parameter values, rather than observing changes in network properties over time.</p>
        <p>We then counted the number of spikes per image from each unit to estimate each neuron's average firing rate, as it might be measured in a physiology experiment. The distribution of these mean firing rates is fairly broad and well-described by a lognormal distribution (<xref ref-type="fig" rid="pcbi-1002250-g004">Fig. 4a</xref>). This distribution is strongly non-monotonic, clearly indicating that it is poorly fit by an exponential function.</p>
        <fig id="pcbi-1002250-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Units in SAILnet exhibit a broad range of mean firing rates, which can be lognormally or exponentially distributed depending on the choice of probe stimuli.</title>
            <p>(A) Frequency histogram of firing rates averaged over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e064" xlink:type="simple"/></inline-formula> image patches drawn from the training ensemble for each of the 1536 units of a SAILnet trained on whitened natural images. All learning rates were set to zero during probe stimulus presentation. A wide range of mean rates was observed, but as expected, the distribution is peaked near <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e065" xlink:type="simple"/></inline-formula> spikes per image, the target mean firing rate of the neurons. The paucity of units with near-zero firing rates suggests that this distribution is closer to lognormal than exponential. Accordingly, the lognormal least-squares (solid red curve) fit accounts for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e066" xlink:type="simple"/></inline-formula> of the variance in the data, whereas the exponential fit (black dashed curve) accounts for only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e067" xlink:type="simple"/></inline-formula>. (B) In response to low contrast stimuli, the firing rate distribution across the units (every unit fired at least once) in the same network as in panel (A) was similarly well fit by either an exponential (dashed black curve; accounting for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e068" xlink:type="simple"/></inline-formula> of the variance in the data) or a lognormal function (solid red curve; accounting for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e069" xlink:type="simple"/></inline-formula> of the variance). The low-contrast stimulus ensemble used to probe the network consisted of images drawn from the training set, with all pixel values reduced by a factor of three.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g004" xlink:type="simple"/>
        </fig>
        <p>Subsequently, we probed the same network (still with the learning turned off, so that the network parameters were identical in both cases) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e070" xlink:type="simple"/></inline-formula> low-contrast images consisting of patches from our training ensemble with all pixel values multiplied by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e071" xlink:type="simple"/></inline-formula>. We found that the firing rate distribution was markedly different than what we found when the network was probed with higher-contrast stimuli. In particular, it became a monotonic decreasing function that was similarly well-described by either a lognormal or an exponential function (<xref ref-type="fig" rid="pcbi-1002250-g004">Fig. 4b</xref>).</p>
        <p>From the dynamics of our leaky integrate-and-fire units, it is clear that the low contrast stimuli with reduced pixel values will cause the units to charge up more slowly and subsequently to spike less in the allotted time the network is given to view each image. Consequently, the firing rate distribution gets shifted towards lower firing rates. However, negative firing rates are impossible, so in addition to being shifted, the low-firing-rate tail of the distribution is effectively truncated. Note that truncating the lognormal distribution anywhere to the right of the peak results in a distribution that looks qualitatively similar to an exponential.</p>
        <p>Mean firing rates in primary auditory cortex (A1) have been reported by one group <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref> to obey a lognormal distribution, whether spontaneous or stimulus-evoked in both awake and anesthetized animals. However, exponentially distributed spontaneous mean firing rates have also been reported in awake rat A1 <xref ref-type="bibr" rid="pcbi.1002250-Gaese1">[45]</xref>. Although several groups have measured the distribution of firing rates over time for individual neurons <xref ref-type="bibr" rid="pcbi.1002250-Baddeley1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Abeles1">[44]</xref>, we are unaware of a published claim regarding the distribution of mean firing rates in visual cortex.</p>
        <p>Recall that our learning rules encourage the neurons to all have the same average firing rate. This fact may be puzzling at first given the spread in mean firing rates apparent in the distributions shown in <xref ref-type="fig" rid="pcbi-1002250-g004">Fig. 4</xref>. There are two main effects to consider when making sense of this: finite measurement time, and non-zero step-sizes for plasticity.</p>
        <p>The first effect relates to the fact that there is intrinsic randomness in the measurement process – which randomly selected image patches happen to fall in the ensemble of probe stimuli – so that the measured distribution tends to be broader than the “true” underlying distribution of the system. To check that this effect is not responsible for the broad distribution in firing rates, we computed the variance in the measured firing rate distribution after different numbers of images were presented to the network. The variance decreased until it reached an asymptotic value after approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e072" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e073" xlink:type="simple"/></inline-formula> image presentations (data not shown). Thus, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e074" xlink:type="simple"/></inline-formula> image sample size in our experiment is large enough to see the true distribution; finite sample-size effects do not affect the distributions that we observed.</p>
        <p>The other, more interesting, effect that gives rise to a broad distribution of firing rates is related to learning. While the network is being trained, the feed-forward weights, inhibitory lateral connections, and firing thresholds get modified in discrete jumps, after every image presentation (or every batch of images, see the <xref ref-type="sec" rid="s4">Methods</xref> section for details). Since those jumps are of a non-zero size – as determined by the learning rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e075" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e076" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e077" xlink:type="simple"/></inline-formula> – there will be times when the firing threshold gets pushed below the specific value that would lead to the unit having exactly the target firing rate, and the unit will thus spike more than the target rate. Similarly, some jumps will push the threshold above that specific value, and the unit will fire less than the target amount. Even after learning has converged, and the parameters are no longer changing <italic>on average</italic> in response to additional image presentations, the network parameters are still bouncing around their average (optimal) values; any image presentation that makes a neuron spike more than the target amount results in an increased firing threshold, while any image that makes the neuron fire less than the target amount leads to a decreased firing threshold. Recent results <xref ref-type="bibr" rid="pcbi.1002250-Clopath1">[46]</xref> suggest that the sizes of these updates (jumps) are quite large for real neurons. Interestingly, this indicates that the observed broad distributions in firing rate <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref> do not rule out the possibility that homeostatic mechanisms are driving each neuron to have the same average firing rate.</p>
        <p>Reducing the SAILnet learning rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e078" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e079" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e080" xlink:type="simple"/></inline-formula> does reduce the variance of the firing rate distributions, but our qualitative conclusions – non-monotonic, approximately lognormal firing rate distribution in response to images from the training set, and monotonic, exponential/lognormal distribution in response to low contrast images – are unchanged when we use different learning rates for the network (data not shown).</p>
      </sec>
      <sec id="s2c">
        <title>Pairs of SAILnet units have small firing rate correlations</title>
        <p>Recent experimental work <xref ref-type="bibr" rid="pcbi.1002250-Ecker1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Renart1">[48]</xref> has shown that neurons in visual cortex tend to have small correlations between their firing rates. In order to facilitate a comparison between our model, and the physiological observations, we have measured the (Pearson's) linear correlation coefficients between spike counts of SAILnet units, in response to an ensemble 30,000 natural images. These correlations (<xref ref-type="fig" rid="pcbi-1002250-g005">Fig. 5</xref>) tend to be near zero, as is observed experimentally <xref ref-type="bibr" rid="pcbi.1002250-Ecker1">[47]</xref>, while the experimental data show a larger variance in the distribution of correlation coefficients than we observe with SAILnet. We note that, like the firing rate distribution (discussed above), the distribution of correlation coefficients is affected by the update sizes (learning rates) in the simulation, with larger update sizes leading to a larger variance of the measured distribution.</p>
        <fig id="pcbi-1002250-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Pairs of SAILnet units have small firing rate correlations.</title>
            <p>The probability distribution function (PDF) of the Pearson's linear correlation coefficients between the spike-counts of pairs of SAILnet neurons responding to an ensemble of 30,000 natural images is sharply peaked near zero.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g005" xlink:type="simple"/>
        </fig>
        <p>In <xref ref-type="fig" rid="pcbi-1002250-g005">Fig. 5</xref>, the distribution appears truncated on the left. This effect arises because there is a lower bound on the correlation between the neuronal firing rates that arises when the two neurons are <italic>never</italic> co-active. The low mean firing rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e081" xlink:type="simple"/></inline-formula> used in our simulation means that this bound is not too far below zero.</p>
      </sec>
      <sec id="s2d">
        <title>Connectivity learned by SAILnet allows for further experimental tests of the model</title>
        <p>Several previous studies of sparse coding models <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref> have focused on the receptive fields learned by adaptation to naturalistic inputs, but we are aware of only one published study <xref ref-type="bibr" rid="pcbi.1002250-Garrigues1">[49]</xref> that investigated the connectivity in sparse coding models, albeit with a model that lacked biological realism. One previous study <xref ref-type="bibr" rid="pcbi.1002250-Koulakov1">[50]</xref> investigated synaptic mechanisms that could give rise to the measured distribution of connection strengths, but this work was not performed in the context of a sensory coding model. No prior work has studied the connectivity learned in a biophysically well-motivated sensory coding network, which would provide additional testable predictions for physiology experiments.</p>
        <p><xref ref-type="fig" rid="pcbi-1002250-g006">Fig. 6</xref> shows the distribution of non-zero connection strengths (non-zero elements of the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e082" xlink:type="simple"/></inline-formula>) learned by a 1536-unit SAILnet with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e083" xlink:type="simple"/></inline-formula> trained on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e084" xlink:type="simple"/></inline-formula> pixel patches drawn from whitened natural images (the same network whose receptive fields are shown in <xref ref-type="fig" rid="pcbi-1002250-g003">Fig. 3</xref>). When trained on natural images, SAILnet learns an approximately lognormal distribution of inhibitory connection strengths; a Gaussian best fit to the histogram of the logarithms of the connection strengths accounts for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e085" xlink:type="simple"/></inline-formula> of the variance in the data.</p>
        <fig id="pcbi-1002250-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002250.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Connectivity learned by SAILnet allows for further experimental tests of the model.</title>
            <p>(A) Probability Density Function (PDF) of the logarithms of the inhibitory connection strengths (non-zero elements of the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e086" xlink:type="simple"/></inline-formula>) learned by a 1536 unit SAILnet trained on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e087" xlink:type="simple"/></inline-formula> pixel patches drawn from whitened natural images. The measured values (blue points) are well-described by a Gaussian distribution (solid line), which accounts for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e088" xlink:type="simple"/></inline-formula> of the variance in the dataset. This indicates that the data are approximately lognormally distributed. Note that there are some systematic deviations between the Gaussian best fit and the true distribution, particularly on the low-connection strength tail, similar to what has been observed for excitatory connections within V1 <xref ref-type="bibr" rid="pcbi.1002250-Graham1">[18]</xref>. This plot was created using the binning procedure of Hromádka and colleagues <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref>. The histogram was normalized to have unit area under the curve. (B) The strengths of the inhibitory connections between pairs of cells are correlated with the overlap between those cells' receptive fields: cells with significantly overlapping RFs tend to have strong mutual inhibition. Data shown in panel (B) are for 5,000 randomly selected pairs of cells. Pairs of cells with significantly negatively overlapping RFs tend not to have inhibitory connections between them, hence the apparent asymmetry in the RF overlap distribution obtained by marginalizing over connection strengths in panel (B).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.g006" xlink:type="simple"/>
        </fig>
        <p>Despite this close agreement, SAILnet shows some systematic deviations from the lognormal fit, especially on the low-connection-strength tail of the distribution. Interestingly, the experimental data <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref> show an approximately lognormal distribution of excitatory connection strengths, with similar systematic deviations (<xref ref-type="fig" rid="pcbi-1002250-g005">Fig. 5b</xref> of Song <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref>). By contrast, prior theoretical work <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Koulakov1">[50]</xref> has employed learning rules tailored to create exactly lognormal connection strength distributions, and thus show no such deviations. Note also that neither of these previous studies addressed the issue of how neurons might represent sensory inputs, nor how they might learn those representations.</p>
        <p>Whereas the experimental data of Song <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref> show a roughly lognormal distribution in the strengths of excitatory connections between V1 neurons, our model makes predictions about the strengths of <italic>inhibitory</italic> connections in V1. The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e089" xlink:type="simple"/></inline-formula> time window for measuring post-synaptic potentials in the experiment of Song <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref> ensured that they measured only direct synaptic connections. However, suppressive interactions between excitatory neurons in cortex are mediated by inhibitory interneurons. Consequently, the inhibitory interactions between pairs of excitatory neurons in V1 must involve two or more synaptic connections between the cells. Thus, our model predicts that the inhibitory functional connections between excitatory simple cells in V1, like the excitatory connections measured by Song <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Song1">[38]</xref>, should follow an approximately lognormal distribution (<xref ref-type="fig" rid="pcbi-1002250-g006">Fig. 6</xref>), but it does not specify the extent to which this is achieved through variations in strength among dendritic or axonal synaptic connections of V1 inhibitory interneurons. One recent theoretical study <xref ref-type="bibr" rid="pcbi.1002250-Clopath1">[46]</xref> has uncovered some interesting relationships between coding schemes and connectivity in cortex, but it did not make any statements about the anticipated distribution of inhibitory connections.</p>
        <p>Interestingly, there is a clear correlation between the strengths of the inhibitory connection between pairs of SAILnet neurons, and the overlap (measured by vector dot product) between their receptive fields: neurons with significantly overlapping receptive fields tend to have strong inhibitory connections between them (<xref ref-type="fig" rid="pcbi-1002250-g006">Fig. 6</xref>). This correlation is expected because cells with similar RF's receive much common feed-forward input. Thus, in order to keep their activities uncorrelated, significant mutual inhibition is required. This same feature was assumed by the LCA algorithm of Rozell <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref> and colleagues, but is naturally learned by SAILnet, in response to natural stimuli.</p>
        <p>Our connectivity predictions are amenable to direct experimental testing, although that testing may be challenging, owing to the difficulty of measuring functional connectivity mediated by two or more synaptic connections between pairs of V1 excitatory simple cells.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>The present work represents the first demonstration that synaptically local plasticity rules can be used to learn a sparse code for natural images that accounts for the diverse shapes of V1 simple cell receptive fields. Our model uses purely synaptically local learning rules – connection strengths are updated based only on the number of spikes arriving at the synapse and the number of spikes generated by the post-synaptic cell. By contrast, the local competition algorithm (LCA) of Rozell and colleagues <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref> assumes that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e090" xlink:type="simple"/></inline-formula>, so that the strength of the inhibitory connection between two neurons is equal to the overlap (<italic>i.e.</italic>, vector dot product) between their receptive fields. This non-local rule requires that individual inhibitory synapses must somehow keep track of the changes in the receptive fields of many neurons throughout the network in order to update their strengths. Moreover, the LCA network does not contain spiking units, even though cortical neurons are known to communicate via discrete, indistinguishable, spikes of activity <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref>.</p>
      <p>Similarly, the units in the networks of Falconbridge <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref> and Földiák <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref> communicate via continuous-valued functions of time. Although these two models <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref> do use synaptically local plasticity rules, neither of these groups demonstrated that such local plasticity rules are sufficient to explain the diversity of simple cell RF shapes observed in V1.</p>
      <p>We note that, independent of the present work, Rozell and Shapero have recently implemented a spiking version of LCA <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref> that uses leaky integrate-and-fire units (S Shapero, D Brüderle, P Hasler, and C Rozell, CoSyne 2011 abstract). However, that work does not address the issue of how to train such a network using synaptically local plasticity rules.</p>
      <p>Some groups have used spiking units to perform image coding <xref ref-type="bibr" rid="pcbi.1002250-Perrinet1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-VanRullen1">[35]</xref>, but those studies did not address the question of whether synaptically local plasticity rules can account for the observed diversity of V1 RF shapes. Interestingly, it has been demonstrated <xref ref-type="bibr" rid="pcbi.1002250-Delorme1">[32]</xref> that orientation selectivity can arise from spike timing dependent plasticity rules applied to natural scenes. Previous work <xref ref-type="bibr" rid="pcbi.1002250-Perrinet2">[33]</xref> has also explored the addition of homeostatic mechanisms to sparse coding algorithms and found it to improve the rate at which learning converges and to qualitatively affect the shapes of the learned RFs; homeostasis is enforced in our model via modifiable firing thresholds.</p>
      <p>Finally, we note that one previous group <xref ref-type="bibr" rid="pcbi.1002250-Savin1">[36]</xref> has demonstrated that independent component analysis (ICA) can be implemented with spiking neurons and local plasticity rules. That work did not, however, account for the diverse shapes of V1 receptive fields, although they did also demonstrate that homeostasis (a mean firing rate constraint) was critical to the learning process.</p>
      <p>Our model attempts to be biophysically realistic, but it is not a perfect model of visual cortex in all of its details. In particular, like many previous models <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Olshausen3">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Perrinet2">[33]</xref>, our network alternates between brief periods of inference (the representation of the input by a specific population activity pattern in the network) and learning (the modification of synaptic strengths), which may not be realistic. Indeed, it is unclear how cortical neurons would “know” when the inference period is over and when the learning period should begin, though it is interesting to note that these iterations could be tied to the onset of saccades, given the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e091" xlink:type="simple"/></inline-formula> inference period between “learning” stages in our model.</p>
      <p>As in previous models, the inputs to our network <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e092" xlink:type="simple"/></inline-formula> are continuous-valued, whereas the actual inputs from the lateral geniculate nucleus to primary visual cortex (V1) are spiking. As mentioned above, suppressive interactions between pairs of units in our model are mediated by direct, one-way, inhibitory synaptic connections between units, rather than being mediated by a distinct population of inhibitory interneurons. We do not include the effects of spike-timing dependent plasticity <xref ref-type="bibr" rid="pcbi.1002250-Dan2">[51]</xref>, although this has been shown to have interesting theoretical implications for cortex <xref ref-type="bibr" rid="pcbi.1002250-Clopath1">[46]</xref> in general and for image coding in particular <xref ref-type="bibr" rid="pcbi.1002250-Delorme1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Masquelier1">[34]</xref>. We are currently developing models that incorporate spike timing dependent learning rules, applied to time-varying image stimuli such as natural movies.</p>
      <p>Finally, the neurons in our model have no intrinsic noise in their activities, although that noise may, in practice, be small <xref ref-type="bibr" rid="pcbi.1002250-Mainen1">[52]</xref>.</p>
      <p>Interestingly, since our model neurons require a finite amount of time to update their internal variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e093" xlink:type="simple"/></inline-formula>, there is a hysteresis effect if one presents the network with time-varying image stimuli – the content of previous frames affects how the network processes and represents the current frame. Even if the features in a movie change slowly, the optimal representation of one frame can be very different from the optimal representation of the next frame in many coding models, so this hysteresis effect can provide stability to the image representation compared to other models such as ICA <xref ref-type="bibr" rid="pcbi.1002250-Bell1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Hyvrinen1">[10]</xref> or Olshausen and Field's sparsenet <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>. This effect has previously been studied by Rozell and colleagues <xref ref-type="bibr" rid="pcbi.1002250-Rozell1">[39]</xref>, encouraging our efforts to apply SAILnet to dynamic stimuli.</p>
      <p>Though it is highly simplified, our model does captures many qualitative features of V1, such as inhibitory lateral connections <xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>, largely uncorrelated neuronal activities <xref ref-type="bibr" rid="pcbi.1002250-Ecker1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Renart1">[48]</xref>, sparse neuronal activity <xref ref-type="bibr" rid="pcbi.1002250-Vinje1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1002250-Haider1">[23]</xref>, a greater number of cortical neurons than input neurons (over-complete representation), synaptically local learning rules, and spiking neurons. Importantly, this model allows us to make several falsifiable experimental predictions about interneuronal connectivity and population activity in cortex. We hope that these predictions will help uncover the coding principles at work in the visual cortex.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>SAILnet dynamics</title>
        <p>Each of the neurons in our SAILnet follows leaky integrate-and-fire dynamics <xref ref-type="bibr" rid="pcbi.1002250-Dayan1">[30]</xref>. The neurons, indexed by subscript <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e094" xlink:type="simple"/></inline-formula>, each have a time-dependent, continuous-valued internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e095" xlink:type="simple"/></inline-formula>, analogous to a neuronal membrane potential. We explicitly model each neuron as an RC circuit (<xref ref-type="fig" rid="pcbi-1002250-g001">Fig. 1</xref>), where the internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e096" xlink:type="simple"/></inline-formula> corresponds to the voltage across the capacitor. Whenever this internal variable exceeds a threshold value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e097" xlink:type="simple"/></inline-formula> specific to that neuron, the neuron emits a punctate spike of activity. The unit's external variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e098" xlink:type="simple"/></inline-formula>, which represents the spiking output that is communicated to other neurons throughout the network, is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e099" xlink:type="simple"/></inline-formula> for a brief moment. At all other times, the unit's external variable is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e100" xlink:type="simple"/></inline-formula>.</p>
        <p>Since the thresholds <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e101" xlink:type="simple"/></inline-formula> are adapted slowly compared to the time scale of inference, they are approximately constant during inference. The same is true for the feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e102" xlink:type="simple"/></inline-formula> and the lateral connection strengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e103" xlink:type="simple"/></inline-formula>, discussed below.</p>
        <p>We model the effects of the input image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e104" xlink:type="simple"/></inline-formula> and the activities of other neurons in the network <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e105" xlink:type="simple"/></inline-formula> on the internal variable as a current, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e106" xlink:type="simple"/></inline-formula>, that is impinging on the RC circuit; here the feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e107" xlink:type="simple"/></inline-formula> and lateral connection strengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e108" xlink:type="simple"/></inline-formula> describe how much a given input (either an image pixel value, or a spike from another neuron in the network) should modify the neuron's internal variable. The internal variable evolves in time via the differential equation for voltage across our capacitor, in response to the input current <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e109" xlink:type="simple"/></inline-formula>.</p>
        <p>We simulate these dynamics in discrete time, performing numerical integration of the differential equation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e110" xlink:type="simple"/></inline-formula>. Whenever the internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e111" xlink:type="simple"/></inline-formula> exceeds the threshold (at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e112" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e113" xlink:type="simple"/></inline-formula>), the output spike occurs at the next time step: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e114" xlink:type="simple"/></inline-formula>. In the subsequent time step, the external variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e115" xlink:type="simple"/></inline-formula> returns to zero, unless the internal variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e116" xlink:type="simple"/></inline-formula> has again crossed the threshold.</p>
        <p>After the unit spikes, the internal variable returns to its resting value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e117" xlink:type="simple"/></inline-formula>, from whence the unit can again be charged up.</p>
        <p>For simplicity, our differential equation assumes that the RC time constant of the model neuron is one “unit” of time. Our simulated dynamics are allowed to run for five such units of time (with the time step of numerical integration being 0.1 units in duration), in response to each input image. At the start of these dynamics, the internal variables of all neurons are set to their resting values: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e118" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s4b">
        <title>SAILnet learning rules can be viewed as a gradient descent approach to a constrained optimization problem</title>
        <p>Unlike previous work <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, which performed unconstrained optimization on a cost function penalizing both reconstruction error and network activity, our learning rules can be viewed as a gradient descent approach to a <italic>constrained</italic> optimization problem.</p>
        <p>Given the neuronal activities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e119" xlink:type="simple"/></inline-formula> in response to an image, and their feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e120" xlink:type="simple"/></inline-formula>, one ‘can form a linear generative model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e121" xlink:type="simple"/></inline-formula> of the input stimulus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e122" xlink:type="simple"/></inline-formula>. The mean squared error between that model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e123" xlink:type="simple"/></inline-formula> and the true input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e124" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e125" xlink:type="simple"/></inline-formula>, and the creation of a high fidelity representation suggests that this error function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e126" xlink:type="simple"/></inline-formula>, or one like it, be minimized by the learning process.</p>
        <p>Let us suppose that the neuronal network is not free to choose any solution to this problem; instead it must satisfy constraints that require the neurons to have a fixed average firing rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e127" xlink:type="simple"/></inline-formula> and minimal correlation between neurons. Indeed, neurons tend to have low mean firing rates when averaged across many different images, and those firing rates span a finite range of values <xref ref-type="bibr" rid="pcbi.1002250-Hromdka1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Baddeley1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Abeles1">[44]</xref>, motivating our first constraint. The second constraint is justified by observations that neural systems tend to exhibit little or no correlation between pairs of units <xref ref-type="bibr" rid="pcbi.1002250-Ecker1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Renart1">[48]</xref>, and that the correlation between the activity of V1 neurons decreases significantly as one increases the fraction of the visual field that is stimulated <xref ref-type="bibr" rid="pcbi.1002250-Vinje2">[22]</xref>.</p>
        <p>We use the method of Lagrange multipliers to solve this problem, allowing our learning rules to adapt the network so as to minimize reconstruction error while approximately satisfying these constraints. To do this, we perform gradient descent on a Lagrange function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e128" xlink:type="simple"/></inline-formula> that contains both the error function and the constraints:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e129" xlink:type="simple"/><label>(2)</label></disp-formula>where the set's of values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e130" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e131" xlink:type="simple"/></inline-formula> are our (unknown) Lagrange multipliers. To perform constrained optimization, gradient descent is performed with respect to all of the free parameters in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e132" xlink:type="simple"/></inline-formula>: namely, the set of feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e133" xlink:type="simple"/></inline-formula>, and the Lagrange multipliers <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e134" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e135" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e136" xlink:type="simple"/><label>(3)</label></disp-formula></p>
        <p>The first two equations lead to our learning rules for inhibitory connections and firing thresholds, once we identify <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e137" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e138" xlink:type="simple"/></inline-formula>; these network parameters correspond to the Lagrange multipliers of the constrained optimization problem. This reflects the fact that the role of the variable thresholds and inhibitory connections is to enforce the sparseness and non-correlation constraints in the network, which is the same as the role of the Lagrange multipliers in the Lagrange function.</p>
        <p>We emphasize that the terms of our objective function that effectively enforce these constraints are critical for our algorithm's success. By contrast, consider the situation in which the model units had no other possibility but to maintain their fixed firing rate and lack of correlation, due to some clever parameterization of the model's state space. In that case, one could simply minimize the reconstruction error, via gradient descent, and the existence of these extra terms, or even of the analogous Lagrange multipliers, would be redundant. However, in our model, each change of the feed-forward weights (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e139" xlink:type="simple"/></inline-formula>) could change the neuron's firing rate, and the correlation between its activity and those of other neurons, unless something forces the network back towards the constraint surface. The variable firing thresholds and inhibitory inter-neuronal connection strengths in our model perform this function.</p>
        <p>The last equation from our gradient descent calculation gives the update rule for the feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e140" xlink:type="simple"/></inline-formula>. This rule, as written, is unacceptable for our SAILnet because we wish to interpret the strengths of connections in that network as the strengths of synaptic connections in cortex. In that case, learning at any given synapse should be accomplished using only information available locally, at that synapse. For updating connection strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e141" xlink:type="simple"/></inline-formula>, this could include the pre-synaptic activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e142" xlink:type="simple"/></inline-formula>, the post-synaptic activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e143" xlink:type="simple"/></inline-formula>, and the current value of the connection strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e144" xlink:type="simple"/></inline-formula>, but should not require information about the receptive fields of other neurons in the network, nor their activities, because it is not clear that that information is available at each synapse. Hence, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e145" xlink:type="simple"/></inline-formula> term that arises from gradient descent on our objective function is a problem for the biological interpretation of these learning rules. We will now show that, in the limit that the neuronal activity is sparse and uncorrelated, when averaged over several input images, the non-local gradient descent rule <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e146" xlink:type="simple"/></inline-formula> is approximately equivalent to a simpler rule, originally due to Oja <xref ref-type="bibr" rid="pcbi.1002250-Oja1">[41]</xref>, that is synaptically local.</p>
        <p>Consider the non-local update rule <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e147" xlink:type="simple"/></inline-formula>. Expanding the polynomial, and averaging over image presentations, we find'<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e148" xlink:type="simple"/><label>(4)</label></disp-formula></p>
        <p>If the learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e149" xlink:type="simple"/></inline-formula> is small, such that the feed-forward weights change only slowly over time, then we can approximate that they are constant over some (small) number of image presentations, and take them outside of the averaging brackets;<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e150" xlink:type="simple"/><label>(5)</label></disp-formula></p>
        <p>Now, so long as the neuronal activities are uncorrelated, and all units have the same average firing rate (recall these constraints are enforced by our Lagrange multipliers), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e151" xlink:type="simple"/></inline-formula>, and thus the learning rule is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e152" xlink:type="simple"/><label>(6)</label></disp-formula></p>
        <p>This last term is small compared to the first two for a few reasons. First, the neurons in the network have <italic>sparse</italic> activity, meaning they are selective to particular image features, and thus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e153" xlink:type="simple"/></inline-formula>. This can be easily seen by that fact that we use small values for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e154" xlink:type="simple"/></inline-formula>, meaning that the neurons fire, on average, much less than one spike per image. The spikes, however, can only be emitted in integer numbers, so the neurons are silent in response to most image presentations, and are thus highly selective.</p>
        <p>Furthermore, the last term, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e155" xlink:type="simple"/></inline-formula>, involves a sum over the receptive fields of many neurons in the network. Some of the RFs will be positive for a given pixel, whereas others will be negative. These random signs mean that the sum <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e156" xlink:type="simple"/></inline-formula> tends towards zero.</p>
        <p>Thus, in the limit of sparse and uncorrelated neuronal activity (the limit in which our network operates), gradient descent on the error function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e157" xlink:type="simple"/></inline-formula> yields approximately<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e158" xlink:type="simple"/><label>(7)</label></disp-formula>which is equivalent to the average update from Oja's implementation of Hebbian learning <xref ref-type="bibr" rid="pcbi.1002250-Oja1">[41]</xref>, which we use for learning in SAILnet. Thus, SAILnet learns to approximately solve the same error minimization problem as did previous, non-local sparse coding algorithms <xref ref-type="bibr" rid="pcbi.1002250-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>.</p>
        <p>Interestingly, our result suggests that, despite the highly non-linear way in which our model neurons' outputs (spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e159" xlink:type="simple"/></inline-formula>) are generated from the input, a linear decoding of the network activity should provide a good match to the input: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e160" xlink:type="simple"/></inline-formula>. This linear decodability has previously been observed in physiology experiments <xref ref-type="bibr" rid="pcbi.1002250-Bialek3">[42]</xref>, as well as models designed to maximize the information rate about input stimulus conveyed by individual spiking neurons <xref ref-type="bibr" rid="pcbi.1002250-Bialek2">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-DeWeese1">[12]</xref>, and it is indeed a property of SAILnet.</p>
        <p>We summarize the learning rules for SAILnet here.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e161" xlink:type="simple"/><label>(8)</label></disp-formula></p>
        <p>The first two rules enforce the sparseness and correlation constraints, and arise from the Lagrange multipliers in our Lagrange function. The final rule drives the SAILnet representation to form a better match to the input stimulus, as it adapts to the ensemble of training images.</p>
      </sec>
      <sec id="s4c">
        <title>Receptive fields measured by spike-triggered average are proportional to the feed-forward weights of the neurons when the probe stimulus statistics match those of the training stimuli</title>
        <p>Consider the Oja-Hebb <xref ref-type="bibr" rid="pcbi.1002250-Oja1">[41]</xref> learning rule for the feed-forward weights in our model,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e162" xlink:type="simple"/><label>(9)</label></disp-formula></p>
        <p>Once the learning has converged over some set of training stimuli, the feed-forward weights are, on average, no longer changing in response to repeated presentations of examples from the training set. Thus,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e163" xlink:type="simple"/><label>(10)</label></disp-formula></p>
        <p>Expanding the middle term in this expression, we find that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e164" xlink:type="simple"/><label>(11)</label></disp-formula>where the second equality occurs because the learning has converged, and thus the feed-forward weights are constant over repeated image presentations. Thus, we find that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e165" xlink:type="simple"/></inline-formula>; the spike-triggered average (STA) stimulus is equivalent to the set of feed-forward weights, up to a multiplicative scaling factor that can be calculated from the spike train.</p>
      </sec>
      <sec id="s4d">
        <title>Training SAILnet</title>
        <p>We start out each simulation with all inhibitory connection strengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e166" xlink:type="simple"/></inline-formula> set to zero, all firing thresholds <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e167" xlink:type="simple"/></inline-formula> set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e168" xlink:type="simple"/></inline-formula>, and the feed-forward weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e169" xlink:type="simple"/></inline-formula> initialized with Gaussian white noise. To train the network, batches <xref ref-type="bibr" rid="pcbi.1002250-Falconbridge1">[37]</xref> of 100 images with zero mean, and unit standard deviation pixel values, are presented, and the number of spikes from each neuron are counted separately for each image. After each batch, the average update for the network properties is computed (following our learning rules) over the 100-image batch. This batch-wise training lets us use matrix operations for computing the updates, which dramatically speeds up the training process. After each update, all negative values for inhibitory connections <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e170" xlink:type="simple"/></inline-formula> (which would correspond to excitatory connections) are set to zero, as in the previous work by Földiák <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref>. Relaxing this constraint, and allowing the recurrent weights to change sign does not affect our qualitative conclusions. In that case, some of the recurrent connections become excitatory, while the majority remain inhibitory, the RF's are qualitatively the same as those shown in <xref ref-type="fig" rid="pcbi-1002250-g003">Fig. 3</xref>, and the distributions of inhibitory and excitatory connection strengths are both approximately lognormal (data not shown).</p>
        <p>The relative values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e171" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e172" xlink:type="simple"/></inline-formula> were chosen based on Földiák's <xref ref-type="bibr" rid="pcbi.1002250-Fldik1">[15]</xref> observation that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e173" xlink:type="simple"/></inline-formula> must be much less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e174" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e175" xlink:type="simple"/></inline-formula> so that the neurons' activities remain sparse and uncorrelated, even in the face of changing feed-forward weights.</p>
        <p>We study the network after the properties stop changing macroscopically over time. However, as noted in the firing rates section of this paper, the network parameters continue to bounce around the final “target” state, with the size of the bounces determined by the learning rates in the network. Empirically, we find that it takes on the order of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e176" xlink:type="simple"/></inline-formula> image presentations (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e177" xlink:type="simple"/></inline-formula> steps of 100 image presentations per step) for this dynamic equilibrium to be established. For the results presented in this paper, we let the network train for roughly <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e178" xlink:type="simple"/></inline-formula> image presentations.</p>
        <p>To speed up the simulation, we start the training with large values for the learning rates, and these are eventually reduced. For the last <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e179" xlink:type="simple"/></inline-formula> batches of training (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e180" xlink:type="simple"/></inline-formula> image presentations), the learning rates were <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e181" xlink:type="simple"/></inline-formula>.</p>
        <p>All of the computer codes used to generate the results presented in this paper are available upon request.</p>
      </sec>
      <sec id="s4e">
        <title>Fitting SAILnet RFs to Gabor functions</title>
        <p>A Gabor function (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e182" xlink:type="simple"/></inline-formula>) is a common model for visual cortical receptive fields <xref ref-type="bibr" rid="pcbi.1002250-Ringach1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, which consists of a two-dimensional Gaussian multiplied by a sinusoid:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e183" xlink:type="simple"/><label>(12)</label></disp-formula></p>
        <p>The center of the shape is defined by the coordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e184" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e185" xlink:type="simple"/></inline-formula>, while the amplitude and orientation of the pattern are defined by the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e186" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e187" xlink:type="simple"/></inline-formula>, respectively. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e188" xlink:type="simple"/></inline-formula> defines the phase of the sinusoid, relative to the center of the Gaussian envelope, which has spatial extent <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e189" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e190" xlink:type="simple"/></inline-formula> in the direction along, and perpendicular to, the direction in which the sinusoid oscillates (with frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e191" xlink:type="simple"/></inline-formula>), respectively.</p>
        <p>Given a neuronal RF, our code performs unconstrained optimization to choose the Gabor parameters such that the mean squared error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e192" xlink:type="simple"/></inline-formula> is minimized. We then perform several quality control measures to ensure that our analysis only contains sensible Gabor parameters that accurately describe our RFs.</p>
        <p>The first such measure is to exclude any RF for which the deviation between the RF and the Gabor fit is large; cells with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e193" xlink:type="simple"/></inline-formula> were excluded. This is equivalent to placing a (fairly mild) restriction on the minimum allowable signal-to-noise ratio.</p>
        <p>The second quality control measure is to exclude those RFs for which the center of the pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e194" xlink:type="simple"/></inline-formula> lies either outside the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e195" xlink:type="simple"/></inline-formula> pixel patch, or within one standard deviation (of the Gaussian envelope) of the patch edge. As described by other workers <xref ref-type="bibr" rid="pcbi.1002250-Rehn1">[27]</xref>, when the center of the pattern is outside of the visible <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e196" xlink:type="simple"/></inline-formula> pixel patch, it is not clear that the shape of the RF itself is well-described by the Gabor parameters, or even well-constrained, for that matter. Our (more stringent) restriction also avoids the problem of biased shape estimates, when fitting Gabors to RFs that are truncated by the edge of the patch; the model RFs essentially tile the available space, so some of them will, by necessity, have centers that lie right along or outside of the edges of the patch. Indeed, in a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e197" xlink:type="simple"/></inline-formula> pixel space, many pixels are near the edge, thus this cut excludes many RFs.</p>
        <p>After making all of these cuts, we were left with 299 RFs, on which to perform subsequent shape analysis.</p>
        <p>We performed the same fitting and quality-control analysis on both the SAILnet and the macaque physiology RFs, although we used a gentler goodness-of-fit restriction on the macaque data, since the macaque RFs, as measured, have fairly large regions of zero support, in which any measurement noise reduces the apparent goodness-of-fit. For the macaque data, we excluded those RFs with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002250.e198" xlink:type="simple"/></inline-formula>, leaving 116 of the 250 macaque RFs for subsequent analysis.</p>
        <p>One reason for the relatively low yield of well-fit RFs is that not all RFs are actually well-described by Gabor functions. For example, there is no choice of Gabor parameters that will accurately describe a center-surround receptive field; that RF is much better described by a difference of Gaussians function, for example. We leave for future work the issue of determining the best family of functions with which to describe visual cortical receptive fields.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors are grateful to Bruno Olshausen for his role in inspiring this work and to Bruno Olshausen, Jascha Sohl-Dickstein, Fritz Sommer, and the other members of the Redwood Center for many helpful discussions. We are also very grateful to Dario Ringach for providing the macaque physiology data, and to Chris Rozell and Jascha Sohl-Dickstein for constructive comments on the manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002250-Attneave1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Attneave</surname><given-names>F</given-names></name></person-group>             <year>1954</year>             <article-title>Some informational aspects of visual psychology.</article-title>             <source>Psychol Rev</source>             <volume>61</volume>             <fpage>183</fpage>             <lpage>193</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Barlow1">
        <label>2</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name></person-group>             <year>1961</year>             <article-title>Possible principles underlying the transformation of sensory messages.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Rosenblith</surname><given-names>WA</given-names></name></person-group>             <source>Sensory Communication</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>217</fpage>             <lpage>234</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Atick1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>             <year>1992</year>             <article-title>What does the retina know about natural scenes.</article-title>             <source>Neural Comput</source>             <volume>4</volume>             <fpage>196</fpage>             <lpage>210</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Linsker1">
        <label>4</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Linsker</surname><given-names>R</given-names></name></person-group>             <year>1986</year>             <article-title>An application of the principle of maximum information preservation to linear systems.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Touretzky</surname><given-names>D</given-names></name></person-group>             <source>Advances in Neural Information Processing 1</source>             <publisher-loc>San Mateo</publisher-loc>             <publisher-name>Morgan Kaufmann</publisher-name>             <fpage>186</fpage>             <lpage>194</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Laughlin1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name></person-group>             <year>1981</year>             <article-title>A simple coding procedure enhances a neuron's information capacity.</article-title>             <source>Z Naturforsch C</source>             <volume>36</volume>             <fpage>910</fpage>             <lpage>912</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Bialek1">
        <label>6</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name><name name-style="western"><surname>Zee</surname><given-names>A</given-names></name></person-group>             <year>1991</year>             <article-title>Optimal sampling of natural images: a design principle for the visual system.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Lippman</surname><given-names>R</given-names></name><name name-style="western"><surname>Moody</surname><given-names>JE</given-names></name><name name-style="western"><surname>Touretzky</surname><given-names>D</given-names></name></person-group>             <source>Advances in Neural Information Processing 3</source>             <publisher-loc>San Mateo</publisher-loc>             <publisher-name>Morgan Kaufmann</publisher-name>             <fpage>363</fpage>             <lpage>369</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Atick2">
        <label>7</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>             <year>1992</year>             <article-title>Could information theory provide an ecological theory of sensory processing?</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <source>Princeton lectures on biophysics</source>             <publisher-loc>Singapore</publisher-loc>             <publisher-name>World Scientific</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Bialek2">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>DeWeese</surname><given-names>M</given-names></name><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name><name name-style="western"><surname>Warland</surname><given-names>D</given-names></name></person-group>             <year>1993</year>             <article-title>Bits and brains: information flow in the nervous system.</article-title>             <source>Physica A</source>             <volume>200</volume>             <fpage>581</fpage>             <lpage>592</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Bell1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1997</year>             <article-title>The “independent components” of natural scenes are edge filters.</article-title>             <source>Vis Res</source>             <volume>37</volume>             <fpage>3327</fpage>             <lpage>3328</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Hyvrinen1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name><name name-style="western"><surname>Hoyer</surname><given-names>PO</given-names></name></person-group>             <year>2001</year>             <article-title>A two-layer sparse coding model learns simple and complex cell receptive fields and topography from natural images.</article-title>             <source>Vis Res</source>             <volume>41</volume>             <fpage>2413</fpage>             <lpage>2423</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Tkaik1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tkačik</surname><given-names>G</given-names></name><name name-style="western"><surname>Prentice</surname><given-names>JS</given-names></name><name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name></person-group>             <year>2010</year>             <article-title>Optimal population coding by noisy spiking neurons.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>107</volume>             <fpage>14419</fpage>             <lpage>14424</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-DeWeese1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>DeWeese</surname><given-names>M</given-names></name></person-group>             <year>1996</year>             <article-title>Optimization principles for the neural code.</article-title>             <source>Network</source>             <volume>7</volume>             <fpage>325</fpage>             <lpage>331</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Rieke1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name><name name-style="western"><surname>Warland</surname><given-names>D</given-names></name><name name-style="western"><surname>de Ruyter Van Steveninck</surname><given-names>R</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>1999</year>             <source>Spikes: exploring the neural code</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Dan1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Reid</surname><given-names>CR</given-names></name></person-group>             <year>1996</year>             <article-title>Efficient coding of natural scenes in the lateral geniculate nucleus: experimental test of a computational theory.</article-title>             <source>J Neurosci</source>             <volume>16</volume>             <fpage>3351</fpage>             <lpage>3362</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Fldik1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Földiák</surname><given-names>P</given-names></name></person-group>             <year>1990</year>             <article-title>Forming sparse representations by a local anti-hebbian rule.</article-title>             <source>Biol Cybern</source>             <volume>64</volume>             <fpage>165</fpage>             <lpage>170</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Olshausen1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>             <year>1997</year>             <article-title>Sparse coding with an overcomplete basis set: a strategy employed by v1?</article-title>             <source>Vis Res</source>             <volume>37</volume>             <fpage>3311</fpage>             <lpage>3325</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Olshausen2">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>             <year>1996</year>             <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images.</article-title>             <source>Nature</source>             <volume>381</volume>             <fpage>607</fpage>             <lpage>609</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Graham1">
        <label>18</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Graham</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>             <year>2007</year>             <article-title>Sparse coding in the neocortex.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Kass</surname><given-names>JH</given-names></name></person-group>             <source>Evolution of the nervous system, Vol III</source>             <publisher-loc>Oxford</publisher-loc>             <publisher-name>Academic Press</publisher-name>             <fpage>181</fpage>             <lpage>187</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Lennie1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name></person-group>             <year>2003</year>             <article-title>The cost of cortical computation.</article-title>             <source>Curr Biol</source>             <volume>13</volume>             <fpage>493</fpage>             <lpage>497</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Hromdka1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hromádka</surname><given-names>T</given-names></name><name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name><name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name></person-group>             <year>2008</year>             <article-title>Sparse representation of sounds in the unanesthetized auditory cortex.</article-title>             <source>PLoS Biol</source>             <volume>6</volume>             <fpage>124</fpage>             <lpage>137</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Vinje1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name><name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name></person-group>             <year>2002</year>             <article-title>Natural stimulation of the nonclassical receptive field increases information transmission efficiency in v1.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>2904</fpage>             <lpage>2915</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Vinje2">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name><name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name></person-group>             <year>2000</year>             <article-title>Sparse coding and decorrelation in primary visual cortex during natural vision.</article-title>             <source>Science</source>             <volume>287</volume>             <fpage>1273</fpage>             <lpage>1276</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Haider1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haider</surname><given-names>BA</given-names></name><name name-style="western"><surname>Krause</surname><given-names>MR</given-names></name><name name-style="western"><surname>Duque</surname><given-names>A</given-names></name><name name-style="western"><surname>Yu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Touryan</surname><given-names>J</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Synaptic and network mechanisms of sparse and reliable visual cortical activity during nonclassical receptive field stimulation.</article-title>             <source>Neuron</source>             <volume>65</volume>             <fpage>107</fpage>             <lpage>121</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Tolhurst1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Smyth</surname><given-names>D</given-names></name><name name-style="western"><surname>Thompson</surname><given-names>ID</given-names></name></person-group>             <year>2009</year>             <article-title>The sparseness of neuronal responses in ferret primary visual cortex.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>2355</fpage>             <lpage>2370</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Sakata1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sakata</surname><given-names>S</given-names></name><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name></person-group>             <year>2009</year>             <article-title>Laminar structure of spontaneous and sensory-evoked population activity in auditory cortex.</article-title>             <source>Neuron</source>             <volume>64</volume>             <fpage>404</fpage>             <lpage>418</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Ringach1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ringach</surname><given-names>D</given-names></name></person-group>             <year>2002</year>             <article-title>Spatial structure and asymmetry of simple-cell receptive fields in macaque primary visual cortex.</article-title>             <source>J Neurophysiol</source>             <volume>88</volume>             <fpage>455</fpage>             <lpage>463</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Rehn1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rehn</surname><given-names>M</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name></person-group>             <year>2007</year>             <article-title>A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive fields.</article-title>             <source>J Comput Neurosci</source>             <volume>22</volume>             <fpage>135</fpage>             <lpage>146</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Donoho1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Donoho</surname><given-names>DL</given-names></name></person-group>             <year>2004</year>             <article-title>Compressed sensing.</article-title>             <source>IEEE trans inform theory</source>             <volume>52</volume>             <fpage>1289</fpage>             <lpage>1396</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Olshausen3">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Cadieu</surname><given-names>CF</given-names></name><name name-style="western"><surname>Warland</surname><given-names>DK</given-names></name></person-group>             <year>2009</year>             <article-title>Learning real and complex overcomplete representations from the statistics of natural images.</article-title>             <source>Proc SPIE</source>             <volume>7446</volume>             <fpage>74460S-1</fpage>             <lpage>74460S-11</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Dayan1">
        <label>30</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name></person-group>             <year>2001</year>             <source>Theoretical neuroscience: computational and mathematical modelling of neural systems</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Perrinet1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perrinet</surname><given-names>L</given-names></name><name name-style="western"><surname>Samuelides</surname><given-names>M</given-names></name><name name-style="western"><surname>Thorpe</surname><given-names>S</given-names></name></person-group>             <year>2004</year>             <article-title>Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit.</article-title>             <source>Neurocomput</source>             <volume>57</volume>             <fpage>125</fpage>             <lpage>34</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Delorme1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Delorme</surname><given-names>A</given-names></name><name name-style="western"><surname>Perrinet</surname><given-names>L</given-names></name><name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group>             <year>2000</year>             <article-title>Networks of integrate-and-fire neurons using rank order coding b: spike timing dependent plasticity and emergence of orientation selectivity.</article-title>             <source>Neurocomput</source>             <volume>38</volume>             <fpage>539</fpage>             <lpage>545</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Perrinet2">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perrinet</surname><given-names>L</given-names></name></person-group>             <year>2010</year>             <article-title>Role of homeostasis in learning sparse representations.</article-title>             <source>Neural Comput</source>             <volume>22</volume>             <fpage>1812</fpage>             <lpage>1836</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Masquelier1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Masquelier</surname><given-names>T</given-names></name><name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group>             <year>2007</year>             <article-title>Unsupervised learning of visual features through spike timing dependent plasticity.</article-title>             <source>PLoS Comput Biol</source>             <volume>3</volume>             <fpage>e31</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-VanRullen1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>VanRullen</surname><given-names>R</given-names></name><name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group>             <year>2002</year>             <article-title>Surfing a spike wave down the ventral steam.</article-title>             <source>Vis Res</source>             <volume>42</volume>             <fpage>2593</fpage>             <lpage>2615</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Savin1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Savin</surname><given-names>S</given-names></name><name name-style="western"><surname>Joshi</surname><given-names>P</given-names></name><name name-style="western"><surname>Triesch</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Independent component analysis in spiking neurons.</article-title>             <source>PLoS Comput Biol</source>             <volume>6</volume>             <fpage>e1000757</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Falconbridge1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Falconbridge</surname><given-names>MS</given-names></name><name name-style="western"><surname>Stamps</surname><given-names>RL</given-names></name><name name-style="western"><surname>Badcock</surname><given-names>DR</given-names></name></person-group>             <year>2006</year>             <article-title>A simple hebbian/anti-hebbian network learns the sparse, independent components of natural images.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>415</fpage>             <lpage>429</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Song1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name><name name-style="western"><surname>Sjöström</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Reigl</surname><given-names>M</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name><name name-style="western"><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group>             <year>2005</year>             <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits.</article-title>             <source>PLoS Biol</source>             <volume>3</volume>             <fpage>0507</fpage>             <lpage>0519</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Rozell1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rozell</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>DH</given-names></name><name name-style="western"><surname>Baraniuk</surname><given-names>RG</given-names></name><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name></person-group>             <year>2008</year>             <article-title>Sparse coding via thresholding and local competition in neural circuits.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>2526</fpage>             <lpage>2563</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Hopfield1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hopfield</surname><given-names>J</given-names></name></person-group>             <year>1984</year>             <article-title>Neurons with graded responses have collective properties like those of two-state neurons.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>81</volume>             <fpage>3088</fpage>             <lpage>3092</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Oja1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Oja</surname><given-names>E</given-names></name></person-group>             <year>1982</year>             <article-title>A simplified neuron model as a principal component analyzer.</article-title>             <source>J Math Biol</source>             <volume>15</volume>             <fpage>267</fpage>             <lpage>273</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Bialek3">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name><name name-style="western"><surname>de Ruyter Van Steveninck</surname><given-names>RR</given-names></name><name name-style="western"><surname>Warland</surname><given-names>D</given-names></name></person-group>             <year>1991</year>             <article-title>Reading a neural code.</article-title>             <source>Science</source>             <volume>252</volume>             <fpage>1854</fpage>             <lpage>1857</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Baddeley1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baddeley</surname><given-names>R</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name><name name-style="western"><surname>Booth</surname><given-names>MCA</given-names></name><name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name><name name-style="western"><surname>Freeman</surname><given-names>T</given-names></name><etal/></person-group>             <year>1997</year>             <article-title>Responses of neurons in primary and inferior temporal visual cortices.</article-title>             <source>Proc R Soc Lon B</source>             <volume>264</volume>             <fpage>1775</fpage>             <lpage>1783</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Abeles1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name><name name-style="western"><surname>Vaadia</surname><given-names>E</given-names></name><name name-style="western"><surname>Berman</surname><given-names>H</given-names></name></person-group>             <year>1990</year>             <article-title>Firing patterns of single units in the prefrontal cortex and neural network models.</article-title>             <source>Network</source>             <volume>1</volume>             <fpage>13</fpage>             <lpage>25</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Gaese1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gaese</surname><given-names>BH</given-names></name><name name-style="western"><surname>Ostwald</surname><given-names>J</given-names></name></person-group>             <year>2003</year>             <article-title>Complexity and temporal dynamics of frequency coding in the awake rat auditory cortex.</article-title>             <source>Eur J Neurosci</source>             <volume>18</volume>             <fpage>2638</fpage>             <lpage>2652</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Clopath1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name><name name-style="western"><surname>Büsing</surname><given-names>L</given-names></name><name name-style="western"><surname>Vasilaki</surname><given-names>E</given-names></name><name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name></person-group>             <year>2010</year>             <article-title>Connectivity reects coding: a model of voltage-based stdp with homeostasis.</article-title>             <source>Nat Neurosci</source>             <volume>13</volume>             <fpage>344</fpage>             <lpage>352</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Ecker1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ecker</surname><given-names>A</given-names></name><name name-style="western"><surname>Berens</surname><given-names>P</given-names></name><name name-style="western"><surname>Keliris</surname><given-names>GA</given-names></name><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Decorrelated neuronal firing in cortical microcircuits.</article-title>             <source>Science</source>             <volume>327</volume>             <fpage>584</fpage>             <lpage>587</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Renart1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Renart</surname><given-names>A</given-names></name><name name-style="western"><surname>de la Rocha</surname><given-names>J</given-names></name><name name-style="western"><surname>Bartho</surname><given-names>P</given-names></name><name name-style="western"><surname>Hollender</surname><given-names>L</given-names></name><name name-style="western"><surname>Parga</surname><given-names>N</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>The asynchronous state in cortical circuits.</article-title>             <source>Science</source>             <volume>327</volume>             <fpage>587</fpage>             <lpage>590</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Garrigues1">
        <label>49</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Garrigues</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name></person-group>             <year>2008</year>             <article-title>Learning horizontal connections in a sparse coding model of natural images.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Platt</surname><given-names>JC</given-names></name><name name-style="western"><surname>Kollar</surname><given-names>D</given-names></name><name name-style="western"><surname>Singer</surname><given-names>Y</given-names></name><name name-style="western"><surname>Roweis</surname><given-names>S</given-names></name></person-group>             <source>Advances in Neural Information Processing Systems 20</source>             <publisher-loc>San Mateo</publisher-loc>             <publisher-name>Morgan Kaufmann</publisher-name>             <fpage>505</fpage>             <lpage>512</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Koulakov1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koulakov</surname><given-names>AA</given-names></name><name name-style="western"><surname>Hromádka</surname><given-names>T</given-names></name><name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name></person-group>             <year>2009</year>             <article-title>Correlated connectivity and the distribution of firing rates in the neocortex.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>3685</fpage>             <lpage>3694</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Dan2">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Poo</surname><given-names>MM</given-names></name></person-group>             <year>2006</year>             <article-title>Spike timing-dependent plasticity: from synapse to perception.</article-title>             <source>Physiol Rev</source>             <volume>86</volume>             <fpage>1033</fpage>             <lpage>1048</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002250-Mainen1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mainen</surname><given-names>ZF</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1995</year>             <article-title>Reliability of spike timing in neocortical neurons.</article-title>             <source>Science</source>             <volume>286</volume>             <fpage>1503</fpage>             <lpage>1506</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>