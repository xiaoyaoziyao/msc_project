<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">10-PLCB-RA-1826R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000846</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Mathematics</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Avalanches in a Stochastic Model of Spiking Neurons</article-title><alt-title alt-title-type="running-head">Avalanches in a Stochastic Network Model</alt-title></title-group><contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Benayoun</surname><given-names>Marc</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Cowan</surname><given-names>Jack D.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>van Drongelen</surname><given-names>Wim</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Wallace</surname><given-names>Edward</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Pediatrics, University of Chicago, Chicago, Illinois, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Mathematics, University of Chicago, Chicago, Illinois, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Computation Institute, University of Chicago, Chicago, Illinois, United States of America</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">ewallace@math.uchicago.edu</email></corresp>
<fn fn-type="con"><p>Analyzed the data: MB EW. Wrote the paper: MB JDC WvD EW. Conceived and implemented the simulations and calculations: EW MB.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>7</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>8</day><month>7</month><year>2010</year></pub-date><volume>6</volume><issue>7</issue><elocation-id>e1000846</elocation-id><history>
<date date-type="received"><day>17</day><month>2</month><year>2010</year></date>
<date date-type="accepted"><day>2</day><month>6</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Benayoun et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Neuronal avalanches are a form of spontaneous activity widely observed in cortical slices and other types of nervous tissue, both <italic>in vivo</italic> and <italic>in vitro</italic>. They are characterized by irregular, isolated population bursts when many neurons fire together, where the number of spikes per burst obeys a power law distribution. We simulate, using the Gillespie algorithm, a model of neuronal avalanches based on stochastic single neurons. The network consists of excitatory and inhibitory neurons, first with all-to-all connectivity and later with random sparse connectivity. Analyzing our model using the system size expansion, we show that the model obeys the standard Wilson-Cowan equations for large network sizes (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e001" xlink:type="simple"/></inline-formula> neurons). When excitation and inhibition are closely balanced, networks of thousands of neurons exhibit irregular synchronous activity, including the characteristic power law distribution of avalanche size. We show that these avalanches are due to the balanced network having weakly stable functionally feedforward dynamics, which amplifies some small fluctuations into the large population bursts. Balanced networks are thought to underlie a variety of observed network behaviours and have useful computational properties, such as responding quickly to changes in input. Thus, the appearance of avalanches in such functionally feedforward networks indicates that avalanches may be a simple consequence of a widely present network structure, when neuron dynamics are noisy. An important implication is that a network need not be “critical” for the production of avalanches, so experimentally observed power laws in burst size may be a signature of noisy functionally feedforward structure rather than of, for example, self-organized criticality.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Networks of neurons display a broad variety of behavior that nonetheless can often be described in very simple statistical terms. Here we explain the basis of one particularly striking statistical rule: that in many systems, the likelihood that groups of neurons burst, or fire together, is linked to the number of neurons involved, or size of the burst, by a power law. The wide-spread presence of these so-called avalanches has been taken to mean that neuronal networks in general operate near criticality, the boundary between two different global behaviors. We model these neuronal avalanches within the context of a network of noisy excitatory and inhibitory neurons interconnected by several different connection rules. We find that neuronal avalanches arise in our model only when excitatory and inhibitory connections are balanced in such a way that small fluctuations in the difference of population activities feed forward into large fluctuations in the sum of activities, creating avalanches. In contrast with the notion that the ubiquity of neuronal avalanches implies that neuronal networks operate near criticality, our work shows that avalanches are ubiquitous because they arise naturally from a network structure, the noisy balanced network, which underlies a wide variety of models.</p>
</abstract><funding-group><funding-statement>WvD and MB would like to thank the Lynn family, Falk Foundation, Frank Family Fund Fellowship, and MSTP for financial support. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="13"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Neurons in the central nervous system are organized into recurrent networks which function dynamically, firing action potentials over time in a variety of spatiotemporal patterns. Such networks not only respond to external input, but spontaneously produce patterns of activity. Such spontaneous activity in isolated pieces of cortex has been studied since the work of B. DeLisle Burns in the early 1950s <xref ref-type="bibr" rid="pcbi.1000846-Burns1">[1]</xref>. The main result was that surgically isolated parietal cortex remained silent but excitable. A sufficently strong depolarization of a site on the surface elicited a sustained propagating response, with an all-or-none character, characteristic of an excitable medium. Such a medium has a threshold for excitation.</p>
<p>Recently, the behavior of isolated cortical slices near or at threshold was studied systematically by Beggs and Plenz <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>. They used rat somatosensory cortex, either in mature organotypic cultures, or else in acute slices, using an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e002" xlink:type="simple"/></inline-formula> microelectrode array to record local field potentials. The slices were silent until stimulated with the excitatory neurotransmitter NMDA, in combination with a dopamine <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e003" xlink:type="simple"/></inline-formula>-receptor agonist, whereupon they produced bursts of activity in the form of local field potentials recorded at microelectrodes.</p>
<p>The main result of their experiments is that these bursts of activity are <italic>avalanches</italic>, which <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref> defines as follows. The configuration of active electrodes on the array during one time bin of width <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e004" xlink:type="simple"/></inline-formula> is called a <italic>frame</italic>, and a sequence of frames preceded and followed by blank frames is called an avalanche. The <italic>size</italic> of an avalanche is the total number of electrodes activated between the blank frames. The weak correlations between successive frames show that avalanche activity is neither wave-like nor periodic. Electrode activations, while appearing to be temporally coincident on a long time scale, are roughly self-similar, as can be seen by their distinct activation times when observed at smaller time scales. This is a form of synchrony, in that electrodes are more likely to be activated closer in time to activity in other electrodes. The avalanche size distribution is close to a power law, meaning that for a wide range of sizes, the probability that a given avalanche has size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e005" xlink:type="simple"/></inline-formula> is proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e006" xlink:type="simple"/></inline-formula>.</p>
<p>Neuronal avalanches, by which we mean irregular synchronous activity with a power law burst-size distribution, have since been studied extensively. Avalanches have been observed not only in rat cortex <italic>in vitro</italic> but also <italic>in vivo</italic> <xref ref-type="bibr" rid="pcbi.1000846-Gireesh1">[3]</xref>, in organotypic cultures <xref ref-type="bibr" rid="pcbi.1000846-Mazzoni1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Pasquale1">[5]</xref>, leech ganglia <xref ref-type="bibr" rid="pcbi.1000846-Mazzoni1">[4]</xref>, and in the cortex of awake macaque <xref ref-type="bibr" rid="pcbi.1000846-Petermann1">[6]</xref>, and used to draw inferences regarding information transmission <xref ref-type="bibr" rid="pcbi.1000846-Shew1">[7]</xref>.</p>
<sec id="s1a">
<title>A theory of avalanche formation</title>
<p>In what follows we provide a theory for the formation of avalances using a stochastic version of the sigmoid rate model originally introduced to represent individual neural activity <xref ref-type="bibr" rid="pcbi.1000846-Cowan1">[8]</xref>. We call this the stochastic rate model <xref ref-type="bibr" rid="pcbi.1000846-Cowan2">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1000846-Buice2">[11]</xref>. Each neuron spikes with a probability per unit time dependent on its total synaptic input, while the resulting spiking activity decays at a constant rate. The stochastic nature of the model allows for efficient simulation via the Gillespie algorithm <xref ref-type="bibr" rid="pcbi.1000846-Gillespie1">[12]</xref>, an event-driven method.</p>
<p>We extend the stochastic rate model to explicitly deal with coupled excitatory and inhibitory populations. We show that this model, with appropriate connectivity, produces avalanches in an all-to-all connected network of excitatory and inhibitory neurons when a parameter is increased. We call this parameter the <italic>feedforward strength</italic>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e007" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>, since it measures the extent to which our recurrent network functions analogously to a feedforward network.</p>
<p>Analytically, we show that the stochastic rate model may be treated as a stochastic perturbation of the deterministic Wilson-Cowan equations <xref ref-type="bibr" rid="pcbi.1000846-Wilson1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Wilson2">[15]</xref>. The stochastic rate model produces avalanches in a range of network sizes, for example thousands of neurons, depending on the parameters; in the limit of large network size, the model obeys the Wilson-Cowan equations exactly, which do not themselves produce avalanches. This analysis allows us to address the relation of avalanche dynamics to other parameters, in particular the network size and the external input to the network, showing that these dynamics are robust to wide-ranging variations in these parameters. Finally we obtain avalanche dynamics in a network with random sparse connectivity by generalizing the notion of feedforward strength.</p>
</sec></sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Individual neurons as input-dependent stochastic switches</title>
<p>The stochastic rate model treats neurons as coupled, continuous-time, two-state Markov processes (<xref ref-type="fig" rid="pcbi-1000846-g001">figure 1A</xref>); this may be seen as analogous to a deterministic neuron with very noisy synaptic input, but is agnostic about the source of the noise. Each neuron can exist in either the <italic>active</italic> state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e008" xlink:type="simple"/></inline-formula>, representing a neuron firing an action potential and its accompanying refractory period, or a <italic>quiescent</italic> state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e009" xlink:type="simple"/></inline-formula>, representing a neuron at rest. In order to fully describe this two-state Markov process, it is only necessary to specify the transition rates between the two states. The transition probability for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e010" xlink:type="simple"/></inline-formula> neuron to decay from active to quiescent (right arrow of <xref ref-type="fig" rid="pcbi-1000846-g001">figure 1A</xref>) is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e011" xlink:type="simple"/><label>(1)</label></disp-formula>as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e012" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e013" xlink:type="simple"/></inline-formula> represents the decay rate of the active state of the neuron. The transition probability for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e014" xlink:type="simple"/></inline-formula> neuron to spike (left arrow in <xref ref-type="fig" rid="pcbi-1000846-g001">figure 1A</xref>), i.e. change from quiescent to active, is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e015" xlink:type="simple"/><label>(2)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e016" xlink:type="simple"/><label>(3)</label></disp-formula>as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e017" xlink:type="simple"/></inline-formula>. Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e018" xlink:type="simple"/></inline-formula> is the <italic>response function</italic>, giving the firing rate as a function of input, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e019" xlink:type="simple"/></inline-formula> the total synaptic input to neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e020" xlink:type="simple"/></inline-formula>, a sum of external input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e021" xlink:type="simple"/></inline-formula> and network input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e022" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e023" xlink:type="simple"/></inline-formula> are the weights of the synapses, and the activity variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e024" xlink:type="simple"/></inline-formula> if the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e025" xlink:type="simple"/></inline-formula>th neuron is active at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e026" xlink:type="simple"/></inline-formula> and zero otherwise.</p>
<fig id="pcbi-1000846-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g001</object-id><label>Figure 1</label><caption>
<title>Single neuron dynamics.</title>
<p>A, single-neuron state transitions, with the transition rates marked; for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e027" xlink:type="simple"/></inline-formula>th neuron, the total synaptic input is the sum of network input and external input, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e028" xlink:type="simple"/></inline-formula>. B, graph of the response function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e029" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e030" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g001" xlink:type="simple"/></fig>
<p>Although there is no explicit refractory state in the model, in all simulations, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e031" xlink:type="simple"/></inline-formula>, corresponding to an active state with a time constant of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e032" xlink:type="simple"/></inline-formula> (1<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e033" xlink:type="simple"/></inline-formula> for the action potential plus 9<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e034" xlink:type="simple"/></inline-formula> to approximate a refractory period where neurons are hyperpolarized). This choice of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e035" xlink:type="simple"/></inline-formula> constrains neuronal firing rates to be no greater than 100 Hz.</p>
<p>All neurons are chosen to have the same response function,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e036" xlink:type="simple"/><label>(4)</label></disp-formula>As shown in <xref ref-type="fig" rid="pcbi-1000846-g001">figure 1B</xref>, this standard choice of response function models a neuron's firing rate as zero if it is below threshold, growing close to linearly with the synaptic input as it passes threshold, and then saturating at a maximum rate further above threshold. Since we are studying spontaneous activity in this study, external input is positive but small, so that even in the absence of any network activity, some neurons have a non-zero firing rate.</p>
</sec><sec id="s2b">
<title>Population dynamics evolve according to the population master equation</title>
<p>We next consider networks of excitatory and inhibitory neurons, initially with all-to-all connectivity depending only on the cell type; at the end of the results section we address how our findings extend to sparse or inhomogenous connectivities. The outgoing synaptic weight from each excitatory neuron to each excitatory neuron is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e037" xlink:type="simple"/></inline-formula>, from excitatory to inhibitory is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e038" xlink:type="simple"/></inline-formula>, from inhibitory to excitatory is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e039" xlink:type="simple"/></inline-formula>, and from inhibitory to inhibitory is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e040" xlink:type="simple"/></inline-formula>. The effect is of one excitatory and one inhibitory population, connected with strengths shown in <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2A</xref>.</p>
<fig id="pcbi-1000846-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g002</object-id><label>Figure 2</label><caption>
<title>Network connectivity and dynamics.</title>
<p>A, schematic of connection strengths between excitatory, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e041" xlink:type="simple"/></inline-formula>, and inhibitory, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e042" xlink:type="simple"/></inline-formula>, populations, where an arrow indicates a synaptic input. B, schematic of functionally feedforward connectivity, where one mode of network excitation, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e043" xlink:type="simple"/></inline-formula>, excites another mode <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e044" xlink:type="simple"/></inline-formula>, but <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e045" xlink:type="simple"/></inline-formula> does not directly affect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e046" xlink:type="simple"/></inline-formula>. C, network dynamics visualized. If there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e047" xlink:type="simple"/></inline-formula> excitatory and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e048" xlink:type="simple"/></inline-formula> inhibitory neurons active, another excitatory neuron may become active, and network state moves rightwards one spot, at net rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e049" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e050" xlink:type="simple"/></inline-formula> is the total synaptic input to an excitatory neuron. The rates for other transitions are shown with solid arrows and discussed in the population dynamics section of the results. Dashed arrows represent transitions into the state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e051" xlink:type="simple"/></inline-formula> from adjacent states.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g002" xlink:type="simple"/></fig>
<p>The network's stochastic evolution can be thought of as a random walk between states with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e052" xlink:type="simple"/></inline-formula> excitatory and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e053" xlink:type="simple"/></inline-formula> inhibitory neurons active, where the number of active neurons can increase or decrease only by one at a time, causing the state to wander around on a lattice as shown in <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2C</xref>. Solid lines show movements out of the state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e054" xlink:type="simple"/></inline-formula> and dashed lines movements into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e055" xlink:type="simple"/></inline-formula>. The rightwards (upwards) arrow is the result of a single excitatory (inhibitory) neuron firing in response to its synaptic input. The leftwards (downwards) arrow is associated with the decay of an excitatory (inhibitory) neuron from active to quiescent, reflecting the single neuron dynamics shown in <xref ref-type="fig" rid="pcbi-1000846-g001">figure 1A</xref>.</p>
<p>To treat this analytically, we consider the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e056" xlink:type="simple"/></inline-formula> that there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e057" xlink:type="simple"/></inline-formula> excitatory, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e058" xlink:type="simple"/></inline-formula> inhibitory neurons active at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e059" xlink:type="simple"/></inline-formula>. The random walk on the lattice depicted in in <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2C</xref> is reflected by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e060" xlink:type="simple"/></inline-formula> evolving dynamically in time for each state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e061" xlink:type="simple"/></inline-formula>. The probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e062" xlink:type="simple"/></inline-formula> evolves according to the master equation (19). The equation and its derivation are detailed in methods; in fact the equation contains exactly the same information as <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2C</xref>. This is a generalization of the one population master equation for the stochastic rate model introduced in <xref ref-type="bibr" rid="pcbi.1000846-Cowan2">[9]</xref>. Note here that, in the case of identical single neurons and all-to-all connectivity the population-level master equation is an exact description of the network evolution; if the single neuron parameters and the connection strengths were drawn from probability distributions, we would have to average over these distributions to get an approximate population-level master equation.</p>
<p>We use the Gillespie algorithm <xref ref-type="bibr" rid="pcbi.1000846-Gillespie1">[12]</xref>, an event-driven method of exact simulation, for all simulations of the master equation (see <xref ref-type="sec" rid="s4">methods</xref>).</p>
</sec><sec id="s2c">
<title>How avalanches are obtained</title>
<p>We now investigate the range of parameters for which the stochastic model exhibits a transition from independent firing to irregular bursts of synchronous activity, i.e. to avalanches. We vary both inhibitory synaptic strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e063" xlink:type="simple"/></inline-formula> and the excitatory strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e064" xlink:type="simple"/></inline-formula>, while fixing the difference between them, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e065" xlink:type="simple"/></inline-formula>. We keep the other parameters constant; as we will later show, this has the effect of leaving the deterministic equilibrium or fixed point unchanged. As shown in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3A</xref>, when the total synaptic strength is small, firing rates fluctuate weakly about the fixed point predicted by the deterministic Wilson-Cowan equations, meaning that the neurons fire asynchronously. The neurons fire roughly as independent Poisson processes, as shown by their approximately exponential inter-spike-interval distribution in the insets to <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3D</xref>. The distribution of burst sizes shown in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3D</xref> fits a geometric distribution consistent with independent Poisson firing, explained in methods.</p>
<fig id="pcbi-1000846-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g003</object-id><label>Figure 3</label><caption>
<title>Transition from asynchronous firing to avalanche dynamics.</title>
<p>Simulations with parameter values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e066" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e067" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e068" xlink:type="simple"/></inline-formula>. Left column, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e069" xlink:type="simple"/></inline-formula>, middle column, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e070" xlink:type="simple"/></inline-formula>, right column <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e071" xlink:type="simple"/></inline-formula>. A,B,C: Mean firing rate of network (see Procedures) plotted over raster plot of spikes. Individual neurons correspond to rows, and are unsorted except that the lower rows represent excitatory neurons and the upper rows inhibitory. D,E,F: Network burst distribution in number of spikes, together with geometric (red) and power law (blue) fit; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e072" xlink:type="simple"/></inline-formula>, the mean inter spike interval, is the time bin used to calculate the distribution, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e073" xlink:type="simple"/></inline-formula> is the exponent of the power law fit. Inset, inter-spike interval (ISI) distribution in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e074" xlink:type="simple"/></inline-formula> for a sample of 50 neurons from the network, shown in semi-logarithmic co-ordinates, with exponential fit (green). G,H,I: Phase plane plots of excitatory and inhibitory activity showing the vector field (grey) and nullclines <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e075" xlink:type="simple"/></inline-formula> (red) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e076" xlink:type="simple"/></inline-formula> (blue), of the associated Wilson-Cowan equations and plots of a deterministic (black dashed) and a stochastic (green) trajectory starting with identical initial conditions. Note that the deterministic fixed point (black circle), where the nullclines cross, does not change as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e077" xlink:type="simple"/></inline-formula> increases, but the angle between the nullclines becomes increasingly shallow, and the stochastic trajectory becomes increasingly spread out. See also <xref ref-type="supplementary-material" rid="pcbi.1000846.s001">figure S1</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g003" xlink:type="simple"/></fig>
<p>As we increase the synaptic input, fluctuations in the firing rate grow, and we begin to see large and long-lived downwards fluctuations away from the deterministic value of the firing rate, at random times, shown in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3B–C</xref>. Episodes of near-zero firing interpose between episodes of collective firing of many neurons across the network. Looking at the statistics of these irregular bursts of synchronous activity, we find that the distribution of burst sizes, measured in number of spikes, approaches a power law distribution as the firing becomes more synchronized, shown in <xref ref-type="fig" rid="pcbi-1000846-g003">figures 3E–F</xref>. This is therefore a candidate mechanism for neuronal avalanches <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Mazzoni1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Pasquale1">[5]</xref>. In <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3F</xref>, we see that the size distribution conforms to a power law for avalanche sizes between roughly 5 and 500 spikes. Testing the goodness of fit using ordinary least-squares linear regression on the bilogarithmically transformed co-ordinates, the test of significance used in <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, we find the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e078" xlink:type="simple"/></inline-formula> value was 0.968. However, recent research has shown that to be is an inappropriate and unreliable method for detecting power laws <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref>, a point we return to in the discussion. Using the maximum likelihood estimator developed in <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref> (see <xref ref-type="sec" rid="s4">methods</xref>) we find an exponent of 1.62. However, the goodness of fit test also developed in <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref>, we reject the null hypothesis that the sample is drawn from an exact power law, for its entire range, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e079" xlink:type="simple"/></inline-formula>.</p>
<p>Considering the population activity, (i.e. the proportion active per population, as opposed to the spike firing rate), <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3G–I</xref> show that the activity also becomes increasingly prone to large fluctuations towards zero, despite the associated deterministic Wilson-Cowan equations having an unchanging single stable fixed point.</p>
</sec><sec id="s2d">
<title>Avalanches result from strong feedforward dynamics</title>
<p>We illuminate this behaviour with the help of the system size expansion <xref ref-type="bibr" rid="pcbi.1000846-vanKampen1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1000846-Wallace1">[20]</xref>, a standard technique from stochastic chemical kinetics, reviewed in <xref ref-type="supplementary-material" rid="pcbi.1000846.s002">Text S1</xref>. The inspiration for this comes from a Gaussian approximation: if the neurons were to fire independently of each other, then the total activity in each population would be Gaussian with mean proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e080" xlink:type="simple"/></inline-formula> and standard deviation proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e081" xlink:type="simple"/></inline-formula>. Accordingly, we model the number of neurons active at a given time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e082" xlink:type="simple"/></inline-formula> as the sum of a deterministic component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e083" xlink:type="simple"/></inline-formula>, scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e084" xlink:type="simple"/></inline-formula>, and a stochastic perturbation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e085" xlink:type="simple"/></inline-formula>, scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e086" xlink:type="simple"/></inline-formula>, so that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e087" xlink:type="simple"/><label>(5)</label></disp-formula>The deterministic terms obey the Wilson-Cowan equations<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e088" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e089" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e090" xlink:type="simple"/></inline-formula> are, respectively the (time-averaged) proportions of excitatory and inhibitory neurons active in a given time bin, [see <xref ref-type="bibr" rid="pcbi.1000846-Wilson1">[14]</xref>], and now the total synaptic inputs are the same to both populations, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e091" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e092" xlink:type="simple"/></inline-formula> is external input. The fluctuation variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e093" xlink:type="simple"/></inline-formula> obey a linear stochastic differential equation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e094" xlink:type="simple"/><label>(7)</label></disp-formula>to order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e095" xlink:type="simple"/></inline-formula>, where the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e096" xlink:type="simple"/></inline-formula> is the Jacobian of (6) calculated at the deterministic trajectory, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e097" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e098" xlink:type="simple"/></inline-formula> are independent white-noise variables whose amplitude is also calcuated via the deterministic trajectory. Since this equation is linear, the fluctuations are approximately Gaussian for large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e099" xlink:type="simple"/></inline-formula>. Notice that in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3G</xref> the trajectory of the master equation closely tracks the trajectory of the Wilson-Cowan equations (6). In the case of independent firing, the fluctuation term is small, but we see in <xref ref-type="fig" rid="pcbi-1000846-g003">figures 3H–I</xref> that as the network transitions to synchronous firing the fluctuations dominate and the stochastic trajectories move away from those for the deterministic system.</p>
<p>It is is easier to understand the dynamics by making a change of variables; to motivate this change of variables, note that large fluctuations tend to occur increasingly as inhibition approaches excitation, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e100" xlink:type="simple"/></inline-formula>. This is sometimes called a balanced network <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Tsodyks1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-vanVreeswijk1">[22]</xref>, in the sense that inhibition balances excitation. In this case, we can express the synaptic input in terms of the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e101" xlink:type="simple"/></inline-formula> and difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e102" xlink:type="simple"/></inline-formula> of the excitatory and inhibitory population activities, and note that the neuronal response is highly sensitive to changes in the difference and relatively insensitive to changes in the mean, described schematically in <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2B</xref>. More precisely, if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e103" xlink:type="simple"/><label>(8)</label></disp-formula>then the total synaptic input is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e104" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e105" xlink:type="simple"/></inline-formula>. From (9) we deduce that, in the balanced case where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e106" xlink:type="simple"/></inline-formula>, the input is much more sensitive to changes in the difference than in the mean. Accordingly, we make a linear change of variables from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e107" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e108" xlink:type="simple"/></inline-formula>. As shown in <xref ref-type="supplementary-material" rid="pcbi.1000846.s002">Text S1</xref>, this leads to the more transparent deterministic equations<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e109" xlink:type="simple"/><label>(10)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e110" xlink:type="simple"/><label>(11)</label></disp-formula>with unique stable solution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e111" xlink:type="simple"/></inline-formula>. The factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e112" xlink:type="simple"/></inline-formula> in (11) means that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e113" xlink:type="simple"/></inline-formula> at the fixed point, and that close to the fixed point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e114" xlink:type="simple"/></inline-formula> is only weakly sensitive to changes in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e115" xlink:type="simple"/></inline-formula>. Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e116" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e117" xlink:type="simple"/></inline-formula> depends on the sum of the weights only through the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e118" xlink:type="simple"/></inline-formula> which is zero at the fixed point, in fact the fixed point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e119" xlink:type="simple"/></inline-formula> is left unchanged by varying the sum <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e120" xlink:type="simple"/></inline-formula> while keeping the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e121" xlink:type="simple"/></inline-formula> constant. This is why the fixed point is the same in <xref ref-type="fig" rid="pcbi-1000846-g003">figures 3G–I</xref>.</p>
<p>In these new variables the linear noise approximation [see <xref ref-type="supplementary-material" rid="pcbi.1000846.s002">Text S1</xref>] is expressed as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e122" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e123" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e124" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e125" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e126" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e127" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e128" xlink:type="simple"/></inline-formula> are again independent white-noise variables. The Jacobian matrix<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e129" xlink:type="simple"/><label>(13)</label></disp-formula>is upper-triangular, and has eigenvalues <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e130" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e131" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e132" xlink:type="simple"/></inline-formula> is small and positive, so are the eigenvalue magnitudes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e133" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e134" xlink:type="simple"/></inline-formula>. To see this, note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e135" xlink:type="simple"/></inline-formula> is the sum of two small terms <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e136" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e137" xlink:type="simple"/></inline-formula>; the extra term in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e138" xlink:type="simple"/></inline-formula> is also small if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e139" xlink:type="simple"/></inline-formula> is small, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e140" xlink:type="simple"/></inline-formula>. Thus, the fixed point is weakly stable, and like the location of the fixed point, its linear stability depends on the weights only via the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e141" xlink:type="simple"/></inline-formula>.</p>
<p>The off-diagonal term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e142" xlink:type="simple"/></inline-formula> has been called a hidden feedforward term <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Ganguli1">[23]</xref>–<xref ref-type="bibr" rid="pcbi.1000846-Goldman1">[25]</xref>, feedforward because fluctuations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e143" xlink:type="simple"/></inline-formula> feed into the evolution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e144" xlink:type="simple"/></inline-formula> but not vice versa, and hidden because a change of variables is required to see this structure, not obviously present in the network connectivity (<xref ref-type="fig" rid="pcbi-1000846-g002">figure 2B</xref>). The Jacobian, with small eigenvalues but a large off-diagonal term, leads to the amplification of small values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e145" xlink:type="simple"/></inline-formula> into transient increases in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e146" xlink:type="simple"/></inline-formula> whose magnitude increases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e147" xlink:type="simple"/></inline-formula>. This effect is called <italic>balanced amplification</italic> in <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>; it may also be thought of as a shear flow in the phase plane, and is characterized by the nullclines crossing at a shallow angle. In <xref ref-type="fig" rid="pcbi-1000846-g003">figures 3G–I</xref>, one can see that the nullclines become closer to parallel as the feedforward term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e148" xlink:type="simple"/></inline-formula> increases.</p>
<p>In a noisy system, the functionally feedforward mechanism means that small spontaneous fluctuations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e149" xlink:type="simple"/></inline-formula> are amplified into transient increases in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e150" xlink:type="simple"/></inline-formula> whose size increases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e151" xlink:type="simple"/></inline-formula>. An appropriate combination of the noise being strong enough, the feedforward term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e152" xlink:type="simple"/></inline-formula> being large enough, and the eigenvalue damping the fluctuations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e153" xlink:type="simple"/></inline-formula> being small enough, leads to large sustained fluctuations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e154" xlink:type="simple"/></inline-formula>.</p>
<p>We may make this more explicit by examining the variance of the activity, calculated in <xref ref-type="supplementary-material" rid="pcbi.1000846.s002">Text S1</xref>, from the linear noise approximation as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e155" xlink:type="simple"/><label>(14)</label></disp-formula>Fluctuations predicted by the linear noise approximation grow with the strength of the functionally feedforward term, and also grow as the eigenvalues <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e156" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e157" xlink:type="simple"/></inline-formula> go to zero.</p>
<p>We may relate the above findings to the fluctuations in firing rate found in simulations, by observing how the mean and standard deviation of the time-binned spike count varies as we increase the feedforward strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e158" xlink:type="simple"/></inline-formula>. We time bin the spike counts into bins of width <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e159" xlink:type="simple"/></inline-formula>, so that the number of spikes in the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e160" xlink:type="simple"/></inline-formula>th bin is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e161" xlink:type="simple"/></inline-formula>. Then the normalized firing rate is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e162" xlink:type="simple"/></inline-formula> and the normalized standard deviation is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e163" xlink:type="simple"/></inline-formula>.</p>
<p>In <xref ref-type="fig" rid="pcbi-1000846-g004">figure 4A</xref> we see that as the feedforward strength increases, the standard deviation initially increases sharply. Meanwhile, the mean firing rate drops, and continues to drop even as the standard deviation saturates. The effect of this is that the coefficient of variation (CV), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e164" xlink:type="simple"/></inline-formula>, which measures the typical size of the fluctuations relative to the mean, increases, initially rapidly but later more slowly, as shown in <xref ref-type="fig" rid="pcbi-1000846-g004">figure 4B</xref>. (Note that this is the CV of the time-binned spike counts, not the much studied CV of the inter-spike interval.)</p>
<fig id="pcbi-1000846-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g004</object-id><label>Figure 4</label><caption>
<title>Activity and synchrony for a range of feedforward strengths.</title>
<p>A: Mean and standard deviation of time-binned firing rate and; B: coefficient of variation plotted against the sum of synaptic weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e165" xlink:type="simple"/></inline-formula>, from simulations with other parameters fixed, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e166" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e167" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e168" xlink:type="simple"/></inline-formula>. The timebin width is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e169" xlink:type="simple"/></inline-formula>. Note that the feedforward strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e170" xlink:type="simple"/></inline-formula> is proportional to the sum of weights, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e171" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g004" xlink:type="simple"/></fig>
<p>The linear noise approximation, via equation (14), predicts the increase in the standard deviation with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e172" xlink:type="simple"/></inline-formula>. Although the linear noise approximation predicts no change in the mean, correction terms at the next order, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e173" xlink:type="simple"/></inline-formula>, indicate that the mean decreases as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e174" xlink:type="simple"/></inline-formula> increases (see <xref ref-type="supplementary-material" rid="pcbi.1000846.s002">Text S1</xref>). This leads to the counterintuitive observation that the deterministic fixed point does not even accurately describe the mean value of the stochastic system when fluctuations are large.</p>
<p>Another prediction from (14) is that the fluctuations become small as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e175" xlink:type="simple"/></inline-formula> increases, in particular causing the firing rate to return to its deterministic limit. In <xref ref-type="fig" rid="pcbi-1000846-g005">figure 5</xref> we show the effect of varying the size of the network. Fluctuations do indeed die away at large size, and the firing rate barely fluctuates for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e176" xlink:type="simple"/></inline-formula> neurons per population; however, irregular bursts are still observed in networks with size of up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e177" xlink:type="simple"/></inline-formula> neurons per population. This indicates that, although the stochastic Wilson-Cowan model has as its large-scale limit the deterministic Wilson-Cowan equations, the network size may need to be extremely large for the deterministic equations to accurately describe its behavior.</p>
<fig id="pcbi-1000846-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g005</object-id><label>Figure 5</label><caption>
<title>Avalanches persist for intermediate network size and are extinguished at larger sizes.</title>
<p>Effect of varying the size per population, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e178" xlink:type="simple"/></inline-formula>, with other parameters fixed as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e179" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e180" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e181" xlink:type="simple"/></inline-formula>. A: N = 2000. B: N = 5000. C: N = 10,000. D: N = 100,000.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g005" xlink:type="simple"/></fig></sec><sec id="s2e">
<title>Response to changing input</title>
<p>We have found spontaneous dynamics organized into irregular synchronous bursts in neural networks with very weak constant input. To shed light on how networks of neurons process information, we want to know what happens when the input varies. In the simplest case - where input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e182" xlink:type="simple"/></inline-formula> to every neuron is identical, but may change over time - a change in the magnitude of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e183" xlink:type="simple"/></inline-formula> alone may be sufficient to cause the network to move from irregular to regular behaviour, shown in <xref ref-type="fig" rid="pcbi-1000846-g006">figure 6</xref>. Here a change in the input strength makes the fixed point more stable, so decreases the extent to which the network at the fixed point is functionally feedforward.</p>
<fig id="pcbi-1000846-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g006</object-id><label>Figure 6</label><caption>
<title>Response of network to change in input.</title>
<p>Here, the constant input is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e184" xlink:type="simple"/></inline-formula> for the first 500ms and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e185" xlink:type="simple"/></inline-formula> for the following 500ms; the change is indicated by the green arrow. The other parameters for this all-to-all network are, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e186" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e187" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e188" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g006" xlink:type="simple"/></fig>
<p>We can see this by tracking the changes caused in the Jacobian matrix (12) at the fixed point with respect to the mean and difference co-ordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e189" xlink:type="simple"/></inline-formula>. Increasing the external input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e190" xlink:type="simple"/></inline-formula> results in an increase in the synaptic input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e191" xlink:type="simple"/></inline-formula>, both directly as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e192" xlink:type="simple"/></inline-formula> appears in the sum, and indirectly as it causes the fixed point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e193" xlink:type="simple"/></inline-formula> to increase. This causes the eigenvalue <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e194" xlink:type="simple"/></inline-formula> to become more negative, increasingly the stability of the fixed point. Since the response function saturates, so has a decreasing derivative, the other eigenvalue <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e195" xlink:type="simple"/></inline-formula> also becomes more negative as input increases. Similarly the feedforward term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e196" xlink:type="simple"/></inline-formula> decreases. In other words, when input is high, spontaneous internal network correlations quickly decrease. This quick response to an increase in input is a computationally desirable property previously observed in balanced networks <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Tsodyks1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-vanVreeswijk1">[22]</xref>.</p>
<p>The effects of altering various parameters of the model starting from independent firing are summarized in <xref ref-type="table" rid="pcbi-1000846-t001">table 1</xref>, where an increase in the coefficient of variation means that fluctuations are proportionately greater, or that the dynamics are more avalanche-like.</p>
<table-wrap id="pcbi-1000846-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.t001</object-id><label>Table 1</label><caption>
<title>The effect of changing system parameters on the mean, variance, and coefficient of variation, estimated from the linear noise approximation.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000846-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">parameter</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e197" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e198" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e199" xlink:type="simple"/></inline-formula></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e200" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e201" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e202" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e203" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e204" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e205" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e206" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e207" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e208" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e209" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e210" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e211" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e212" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e213" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e214" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e215" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e216" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e217" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e218" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e219" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e220" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table></alternatives></table-wrap></sec><sec id="s2f">
<title>Sparse connectivity</title>
<p>The number of synapses per neuron in cortex is believed to be at most <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e221" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000846-Abeles1">[26]</xref>, so only networks with fewer than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e222" xlink:type="simple"/></inline-formula> neurons could have anything approaching all-to-all connectivity; larger networks in cortex must be sparsely connected. Our results so far deal with all-to-all connected networks, so it is reasonable to ask whether or not a sparsely connected network could produce avalanches via the same mechanism. The answer is yes: we are able to generate random sparse matrices with weakly stable fixed points and high functional feedforward connectivity which exhibit large fluctuations grouped into avalanches, as shown in <xref ref-type="fig" rid="pcbi-1000846-g007">figure 7</xref>.</p>
<fig id="pcbi-1000846-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000846.g007</object-id><label>Figure 7</label><caption>
<title>Avalanches in a sparsely connected network.</title>
<p>Results from an excitatory and inhibitory network with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e223" xlink:type="simple"/></inline-formula>, with 17% connectivity. See text for details of sparse weight matrix. A: Raster plot and mean firing rate. B: Avalanche size distribution, calculated with bin size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e224" xlink:type="simple"/></inline-formula> and showing poisson fit (red) and power law fit (blue) with exponent <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e225" xlink:type="simple"/></inline-formula>. C: Inter-spike-interval distribution with exponential fit (green).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.g007" xlink:type="simple"/></fig>
<p>We used the same single-neuron parameters and response function as the all-to-all case, changing only the connectivity matrix. To make this matrix, we generated random sparse positive matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e226" xlink:type="simple"/></inline-formula> with large eigenvalues, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e227" xlink:type="simple"/></inline-formula> with small eigenvalues, so that the weight matrix<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e228" xlink:type="simple"/><label>(15)</label></disp-formula>is random, sparse and obey's Dale's principle that every column, representing the synaptic weights outwards from a single neuron, is either all excitatory or all inhibitory <xref ref-type="bibr" rid="pcbi.1000846-Eccles1">[27]</xref>. The details of how to construct such a weight matrix are given in methods. The condition that the eigenvalues of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e229" xlink:type="simple"/></inline-formula> are much smaller than those of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e230" xlink:type="simple"/></inline-formula> is analogous to the population condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e231" xlink:type="simple"/></inline-formula> in the all-to-all case. As in the all-to-all case, this sparsely connected network has a single stable fixed point, and a change of variables to the mean and difference of the activities leads to the Jacobian at the fixed point having small negative eigenvalues and large off-diagonal elements causing strong functionally feedforward dynamics.</p>
<p>We conclude that homogenous all-to-all connectivity, which has the effect of averaging the population activity at the input to every neuron, is not a requirement for strongly synchronized fluctuations grouped into avalanches. The same mechanism produces similar fluctuations in an inhomogenous network if the functional feedforward strength is large enough.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>Using the stochastic rate model in an excitatory and inhibitory network, we simulated avalanche dynamics, or irregular synchronous activity with a power law burst size distribution. We showed that a network's propensity to produce such bursts depends on it having a functionally feedforward structure described by <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>, in the presence of noise. This is achieved by making the network balanced, meaning that the net difference between excitation and inhibition is small compared to the sum of excitation and inhibition. Bursts arise from small spontaneous fluctuations in the difference of excitatory and inhibitory activity, amplified by the functionally feedforward structure into large fluctuations in the activity of both populations. We demonstrated avalanche dynamics to be robust over a wide range of system parameters. Depending on the functional feedforward strength, this fluctuation-driven behaviour persists in networks of at least tens of thousands of neurons. Increasing the network size (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e232" xlink:type="simple"/></inline-formula> neurons, depending on other parameters) causes the network to fire asynchronously at a rate given by the deterministic Wilson-Cowan equations. However, the deterministic equations do not produce avalanches and exhibit no qualitative change in their spontaneous dynamics due to functionally feedforward connectivity, unlike the stochastic rate model. A significant increase in the external input quickly moves the stochastic network out of the functionally feedforward regime, also causing the network dynamics to behave more like the deterministic Wilson-Cowan equations. Avalanche dynamics are also robust to major changes in the synaptic connectivity - we can produce such fluctuations in a sparse randomly connected network by constraining the eigenvalue spectrum of its connectivity matrix so that it has a functionally feedforward structure.</p>
<sec id="s3a">
<title>Limitations of our findings</title>
<p>Although simplified models are commonly used to study neural network dynamics, the question remains whether a given simplification is appropriate for modeling the network at hand. Our model neurons, which are stochastic switches, are so simple as to make it difficult to relate their parameters precisely to the cells being modeled, although not as difficult as for a purely population-based model. Two-state Markov processes have been previously used for modeling neurons at longer timescales, for example the states representing a zero or nonzero firing rate in studies of attractor networks <xref ref-type="bibr" rid="pcbi.1000846-Hopfield1">[28]</xref>, or up and down states in cortex in studies of repeating patterns of activity <xref ref-type="bibr" rid="pcbi.1000846-Roxin1">[29]</xref>, contrasting with our use of a state transition to represent a single spike. Such simple stochastic models may produce qualitatively the same network dynamics as more biophysically detailed models, while their simplicity enables them to give insight into the mechanisms of emergent phenomena <xref ref-type="bibr" rid="pcbi.1000846-Wilson1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Hopfield2">[30]</xref>; we expect that further research will show the same to hold for our model. In addition, it would be interesting to see if functionally feedforward connectivity could produce avalanche dynamics at much longer timescales via the model of Roxin et al. <xref ref-type="bibr" rid="pcbi.1000846-Roxin1">[29]</xref>.</p>
<p>Another concern is that the time scales in our simulations reflect the time scales in cortex. For example our cellular firing rates are at the high end of those observed in cortex in the asynchronous case. One simple way to adjust our model is to place a time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e233" xlink:type="simple"/></inline-formula> in front of the time derivative term in the master equation, or equivalently to scale all the transition rates by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e234" xlink:type="simple"/></inline-formula>, thus slowing down the entire simulation, including firing rates, by a constant factor. One could also scale the transition rates differently for each population, since excitatory neurons tend to have lower firing rates than inhibitory neurons in cortex <xref ref-type="bibr" rid="pcbi.1000846-Connors1">[31]</xref>. Another way to slow down the rate of occurence of avalanches without changing the single-neuron parameters is, by increasing the size of the simulated network to match the size of a cortical slice, so decreasing the effective noise strength which is proportional to the square root of the size. Since the avalanches are noise-driven fluctuations, with appropriate adjustments to the connectivity parameters this would make the time between avalanches longer.</p>
<p>The lack of conduction delays in our model raises another issue with the time scales: the delay in activation of one neuron by another is accounted for solely by the random exponential time to spiking, thus meaning that a postsynaptic spike may follow a presynaptic spike at a delay shorter than is reasonable for causality in cortex. We would expect the introduction of delays to slow down the network dynamics, and also be relatively straightforward to simulate as an adaptation of the Gillespie algorithm to account for delays already exists <xref ref-type="bibr" rid="pcbi.1000846-Bratsun1">[32]</xref>. As neurons in larger networks are more likely to be far apart, we might expect conduction delays to play a bigger role in larger, spatially distributed networks.</p>
<p>Although we showed that self-organization is not needed to maintain avalanching dynamics in a network, this begs the question, what kind of self-organization can put the network in a regime where it produces avalanches? In cortical cultures from layers 2/3 of the rat, avalanche-like dynamics emerge after 6–8 days <xref ref-type="bibr" rid="pcbi.1000846-Gireesh1">[3]</xref>; similarly, in cultured networks of dissociated rat hippocampal neurons, avalanche dynamics emerge after 3–4 weeks <xref ref-type="bibr" rid="pcbi.1000846-Pasquale1">[5]</xref>. Feedforward connectivity requires the sum of excitatory and inhibitory synaptic inputs to be on average much greater than the difference, and we would expect it to take time to develop extensive enough connectivity for the total to be large. An extension of our model to involve slow modification of network properties, for example by synaptic plasticity, would be needed to account fully for these experimental results.</p>
</sec><sec id="s3b">
<title>Implications for experiments</title>
<p>If the proposed mechanism of functionally feedforward connectivity generates neuronal avalanches in an experimental system, it should be possible to probe that system in ways analogous to varying the parameters in our model. For example, the model predicts no activity in the absence of external input, since the only fixed point of the model is the origin. If the network topology already exhibits strong feedforward strength, then the addition of small concentrations of an excitant would effectively increase the external input parameter, so shifting the fixed point away from the origin and causing avalanches. This was in fact the method used by Beggs &amp; Plenz <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, who added NMDA (N-methyl-D-aspartic acid) to produce avalanches in cortical slices and cultures. If too much NMDA is added, however, then we expect an excess of excitation, so that the near balance of excitation and inhibition responsible for the strong feedforward strength of the network would be disrupted and avalanches would no longer occur.</p>
<p>A small increase in extracellular <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e235" xlink:type="simple"/></inline-formula> effectively increases both excitatory and inhibitory synaptic weights, thereby increasing the feedforwardness <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e236" xlink:type="simple"/></inline-formula> while keeping the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e237" xlink:type="simple"/></inline-formula> relatively unchanged, leading to increased burst frequency in our model. This suggests that an experimental preparation could be studied near the avalanche transition by titrating with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e238" xlink:type="simple"/></inline-formula>. If the network were in a state where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e239" xlink:type="simple"/></inline-formula> is slightly positive, as in the simulations performed here, then further addition of a small amount of an inhibitory antagonist such as bicuculline (a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e240" xlink:type="simple"/></inline-formula> antagonist) would weaken <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e241" xlink:type="simple"/></inline-formula>, thereby increasing the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e242" xlink:type="simple"/></inline-formula> and leading counterintuitively to decreased burst frequency after the addition of an inhibitory blocker. If the synaptic weights were initially elevated by increasing extracellular <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e243" xlink:type="simple"/></inline-formula>, this would ensure the feedforwardness to be much larger than the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e244" xlink:type="simple"/></inline-formula>, so that weakening <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e245" xlink:type="simple"/></inline-formula> would make a proportionately larger change to the difference. This may be the effect at work in <xref ref-type="bibr" rid="pcbi.1000846-Rutecki1">[33]</xref>, where adding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e246" xlink:type="simple"/></inline-formula> and bicuculline together produced a lower overall burst frequency than adding potassium alone, in a slice preparation of rat hippocampus.</p>
<p>If it were possible to add carefully co-ordinated amounts of an inhibitory blocker and an excitatory blocker, the model raises the possibility that a network, by becoming less functionally feedforward, could have higher mean firing rates but fewer bursts. In general, if there are pharmacological manipulations corresponding to varying the parameters as shown in <xref ref-type="table" rid="pcbi-1000846-t001">table 1</xref>, we expect the coefficient of variation of the firing rate, our proxy for the strength of avalanche dynamics, to move accordingly.</p>
</sec><sec id="s3c">
<title>Relation to previous modeling work</title>
<sec id="s3c1">
<title>The role of noise</title>
<p>In a well-known paper, van Vreeswijk and Sompolinsky <xref ref-type="bibr" rid="pcbi.1000846-vanVreeswijk1">[22]</xref> described the activity of a network of excitatory and inhibitory integrate-and-fire neurons with sparse random connectivity. They ensure that spontaneous network activity is driven by internal fluctuations by arranging that excitation and inhibition are balanced, meaning that both the mean and the standard deviation of net synaptic input scale as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e247" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e248" xlink:type="simple"/></inline-formula> is the mean number of connections per neuron, and also scaling the threshold of each neuron with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e249" xlink:type="simple"/></inline-formula>.</p>
<p>By contrast, the present study keeps the thresholds fixed while scaling the connection strengths inversely with network size. This means that the mean synaptic input scales with the threshold, as a constant; the fluctuations scale as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e250" xlink:type="simple"/></inline-formula> in the case of independent firing, but become comparable to the mean input when the network synchronizes. The analysis of <xref ref-type="bibr" rid="pcbi.1000846-vanVreeswijk1">[22]</xref> relies on firing of neurons being weakly correlated, achieved via static randomness in the weight matrix. The stochastic rate model instead undergoes a transition between uncorrelated and correlated firing achieved via random spike times of individual neurons. Other key dynamical features of the <xref ref-type="bibr" rid="pcbi.1000846-vanVreeswijk1">[22]</xref> model, that without inhibitory input a neuron fires at a high rate, but without excitatory input neurons are very unlikely to fire, are also found in our model. Thus we achieve similar ends with very different modeling assumptions, in our case relying on the network's ability to self-synchronize and on a different source of disorder.</p>
</sec><sec id="s3c2">
<title>The interpretation of power laws</title>
<p>The present paper interprets a power law distribution to mean that for a wide range of sizes, the probability that a given event has size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e251" xlink:type="simple"/></inline-formula> is proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e252" xlink:type="simple"/></inline-formula>. The avalanche size distribution in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3F</xref> indicates a good power law fit for roughly two orders of magnitude. Since biological systems are finite and measurements have limited resolution, we don't expect observed power laws to extend all the way to infinity. Power law behaviour with a small exponent, holding over significantly more than one order of magnitude, is enough to show that a phenomenon crosses several spatial or temporal scales. This is a sufficient condition to label a dataset as a power law in this loose sense, a widely shared interpretation <xref ref-type="bibr" rid="pcbi.1000846-Lowen1">[34]</xref>.</p>
<p>The analysis of such data is complicated by the lack of appropriate statistical tools to estimate and test them. Since a power law distribution corresponds to a straight line in bilogarithmically transformed co-ordinates, it would be tempting to use ordinary least squares linear regression analysis to calculate the slope of this line and assess the fit through the coefficient of determination. However, this analysis is ill-founded and the estimate of the slope of the power law is biased, as discussed thoroughly in <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref>. This method of comparison was used in experimental studies of avalanches <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, and so we analyzed our simulated data with the same method for comparison. Clauset et al <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref> also developed a maximum likelihood estimator and test for data distributed according to an exact power law; in this paper we use their estimator. More recent studies have found that cortical avalanche data from awake cat do not follow an exact power law according to these newer tests <xref ref-type="bibr" rid="pcbi.1000846-Touboul1">[35]</xref>. We are not aware of a well-developed goodness of fit test for data conforming to a power law distribution for a finite range of values; the development of such tests would be very helpful for further research in the area.</p>
</sec><sec id="s3c3">
<title>The mechanism of avalanche formation</title>
<p>A variety of models have attributed avalanches to criticality in network dynamics <xref ref-type="bibr" rid="pcbi.1000846-Abbott1">[36]</xref>–<xref ref-type="bibr" rid="pcbi.1000846-Levina1">[38]</xref>, meaning that avalanches occur when the network lies on the boundary between stability and instability. In the language of dynamical systems, this would mean that avalanches occur when an eigenvalue equals zero. This situation is extended by our model, which exhibits avalanches not only when the eigenvalues are close to zero, but when the eigenvalues are small relative to the feedforward strength. Consequently, it is not possible to infer criticality in a network from the fact that it exhibits large fluctuations whose size obeys a power law distribution.</p>
<p>Some models for neuronal avalanches have further suggested an underlying mechanism of self-organized criticality <xref ref-type="bibr" rid="pcbi.1000846-Levina1">[38]</xref>. This would mean that the network has some fast-changing dynamical variables, for example firing rate, which are maintained at the boundary of stability and instability by the movement of slow variables, such as synaptic plasticity or dendritic growth <xref ref-type="bibr" rid="pcbi.1000846-Sornette1">[39]</xref>. Because such systems often have power law statistics, the measurement of power laws is sometimes taken as evidence for an underlying self-organized critical mechanism <xref ref-type="bibr" rid="pcbi.1000846-Bak1">[40]</xref>. Our model has neither critical behavior in the fast variables, nor slow variables to modulate their dynamics, yet has the characteristic power law distribution of fluctuation size. Criticality is a sufficient but not necessary condition for the emergence of power laws.</p>
<p>Since the slope of the power law observed is dependent on the choice of bin width in experimental results <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, and also in our model (<xref ref-type="supplementary-material" rid="pcbi.1000846.s001">figure S1</xref>), we do not read any significance into the particular slope observed. This makes us skeptical that an observed slope of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e253" xlink:type="simple"/></inline-formula> in a neural network, imported from directed percolation or critical branching models <xref ref-type="bibr" rid="pcbi.1000846-Shew1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Buice1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Haldeman1">[37]</xref>, actually results from one of those models underlying the phenomenon. In our view, any good model of neuronal avalanches must reproduce the variability in the observed slope of the power law with temporal bin width.</p>
<p>Our connectivity is homogenous, or sparse and random. Another model used scale-free network connectivity, where the number of synaptic connections per neuron has a power law distribution, to generate power law distributed activity <xref ref-type="bibr" rid="pcbi.1000846-Mazzoni1">[4]</xref>. It is not surprising that such a long-tailed distribution in the connectivity results in a long-tailed distribution in the firing; however, our model produces a power law distribution of activity without requiring a power law distribution in the connectivity.</p>
<p>Since functionally feedforward dynamics for a network depends only on how spectral properties of the connectivity matrix interact with the network's input via its response function, we expect these bulk dynamics to be obtainable in a variety of different connection topologies beyond the all-to-all and random connectivities examined here. Connectivity may be made more or less sparse, more or less homogenous, more or less random, may have small-world or only local topology, while the eigenvalue spectrum is constrained so that the underlying dynamics is functionally feedforward. This may explain why neuronal avalanches are observed in vastly different anatomical structures - only a few bulk properties of the network need hold, and the network will exhibit irregular synchronous firing with a long-tailed burst size distribution. Noisy functionally feedforward structure, needing neither precise tuning of the network to criticality, nor a postulated mechanism of self-organization, nor strong assumptions on the underlying connectivity, are then a simple and general mechanism for producing neuronal avalanches.</p>
<p>Avalanches were not observed in the functionally feedforward model examined in <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>. Their investigation was restricted to a deterministic linear firing-rate model, analogous to the linear noise approximation used here, with the same change of variables revealing the feedforward structure. Because their model exhibits a strong transient response to input, in the presence of noise it also exhibits a strong transient response to fluctuations. The linear model also required excitatory synaptic strength to be less than the inhibitory strength to maintain the stability of the fixed point, as feedback inhibition is the only ingredient there that stabilizes the strong recurrent excitation. Consequently, the linear model breaks down as the excitatory strength moves closer to the inhibitory strength, as there is no nonlinear saturation term to damp oscillations. In this sense, the functionally feedforward model without noise or saturation is not robust, as addition of small amounts of noise can drastically change its behaviour. However, with the inclusion of these terms, such a model could be used to study both spontaneous and input-driven activity.</p>
</sec></sec><sec id="s3d">
<title>Conclusions</title>
<p>This study of neural network dynamics shows that the stochastic rate model may be viewed as a stochastic generalization of the Wilson-Cowan equations. In this context neither specific types of neural connectivity, nor tuning or self-organization to criticality, are necessary for the emergence of avalanche dynamics, namely spontaneous network bursts with power-law distributed burst sizes. What is important is that the net difference between excitation and inhibition should be small compared to the sum of excitation and inhibition, so that the network effectively has feedforward structure. Small random fluctuations, here provided by stochastic single neurons, are amplified by the functional feedforward structure into bursts involving many neurons across the network. Analogous deterministic models with functionally feedforward structure do not produce avalanches. Thus stochastic functionally feedforward networks are a sufficient and general condition for the emergence of avalanche dynamics, and a mechanism for the spontaneous production of network bursts.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Deriving the master equation</title>
<p>Here we show how to derive the master equation governing the evolution of the network state, visualized in <xref ref-type="fig" rid="pcbi-1000846-g002">figure 2C</xref>.</p>
<p>We consider <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e254" xlink:type="simple"/></inline-formula> active excitatory neurons, each becoming inactive at rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e255" xlink:type="simple"/></inline-formula>. This causes a flow of rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e256" xlink:type="simple"/></inline-formula> out of the state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e257" xlink:type="simple"/></inline-formula> proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e258" xlink:type="simple"/></inline-formula>, hence a term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e259" xlink:type="simple"/></inline-formula>. Similarly the flow into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e260" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e261" xlink:type="simple"/></inline-formula>, caused by one of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e262" xlink:type="simple"/></inline-formula> active excitatory neurons becoming inactive at rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e263" xlink:type="simple"/></inline-formula>, gives a term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e264" xlink:type="simple"/></inline-formula>. The net effect is a contribution<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e265" xlink:type="simple"/><label>(16)</label></disp-formula>In state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e266" xlink:type="simple"/></inline-formula>, there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e267" xlink:type="simple"/></inline-formula> quiescent excitatory neurons, each prepared to spike at rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e268" xlink:type="simple"/></inline-formula>, leading to a term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e269" xlink:type="simple"/></inline-formula>, where the total input is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e270" xlink:type="simple"/><label>(17)</label></disp-formula>Correspondingly, the flow into the state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e271" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e272" xlink:type="simple"/></inline-formula> due to excitatory spikes is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e273" xlink:type="simple"/></inline-formula>. The total contribution from excitatory spikes is then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e274" xlink:type="simple"/><label>(18)</label></disp-formula>There are analogous terms for the decay of active inhibitory neurons and the spiking of quiescent inhibitory neurons. Putting this together, the probability evolves according to the master equation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e275" xlink:type="simple"/><label>(19)</label></disp-formula></p>
</sec><sec id="s4b">
<title>Simulation method</title>
<p>We simulate the entire network as a single continuous-time Markov process, using Gillespie's exact stochastic simulation algorithm <xref ref-type="bibr" rid="pcbi.1000846-Gillespie1">[12]</xref>. The most general form of this starts with the single-neuron transition rates, that for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e276" xlink:type="simple"/></inline-formula>th neuron being:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e277" xlink:type="simple"/><label>(20)</label></disp-formula>The algorithm takes the state of the network, i.e. each neuron is specified as being either active or quiescent, and proceeds as:</p>
<list list-type="order"><list-item>
<p>Find neuronal transition rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e278" xlink:type="simple"/></inline-formula>, and network transition rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e279" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p>Pick time increment <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e280" xlink:type="simple"/></inline-formula> from an exponential distribution of rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e281" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p>Pick <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e282" xlink:type="simple"/></inline-formula>th neuron with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e283" xlink:type="simple"/></inline-formula>, change its state, and update time to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e284" xlink:type="simple"/></inline-formula>.</p>
</list-item></list>
<p>In the case of homogenous all-to-all networks, if one only wants to simulate the number of neurons active in each population, one may simplify this algorithm along the lines of Gillespie's original presentation for a well-mixed chemical system, since the upwards transition rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e285" xlink:type="simple"/></inline-formula> would be identical for all neurons in a population. The simplified algorithm uses much less memory and runs considerably faster.</p>
<p>The Gillespie algorithm is event-driven <xref ref-type="bibr" rid="pcbi.1000846-Brette1">[41]</xref> in the sense that the simulation time is moved on only when the network state is updated, and the time intervals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e286" xlink:type="simple"/></inline-formula> are random variables dependent upon the network state. It is then necessary to store only a vector of transition times and a corresponding vector of which neuron transitioned at each time. In the case of fluctuating firing rates found in avalanche dynamics, the algorithm, by its definition, adapts its time-steps to the firing rates, which can be a computational advantage.</p>
<p>All simulations were performed in Matlab 7.1 (Mathworks, Natick, MA).</p>
</sec><sec id="s4c">
<title>Temporal coarse-graining</title>
<p>To produce plots of the mean firing rate, we counted the number of spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e287" xlink:type="simple"/></inline-formula> in timebins of width <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e288" xlink:type="simple"/></inline-formula>, and smoothed the signals by convolving with a Gaussian of width <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e289" xlink:type="simple"/></inline-formula>. The phase-plane <xref ref-type="fig" rid="pcbi-1000846-g003">figures (3G–I)</xref> show an approximation to the proportion active: since active neurons decay at rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e290" xlink:type="simple"/></inline-formula>, we may calculate the activity from the spike times as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e291" xlink:type="simple"/></inline-formula>.</p>
<p>The mean firing rate, plotted in <xref ref-type="fig" rid="pcbi-1000846-g004">figure 4</xref> and over the raster plots (<xref ref-type="fig" rid="pcbi-1000846-g003">figures 3A–C</xref> etc.), and the activity, plotted in the phase plane <xref ref-type="fig" rid="pcbi-1000846-g003">figures (3G–I)</xref> and used in the calculations, are closely related. Due to the single-neuron dynamics described in (2), the firing rate, which is the rate of transitions from active to quiescent per neuron per second, is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e292" xlink:type="simple"/></inline-formula> in the all-to-all case.</p>
</sec><sec id="s4d">
<title>Defining neuronal avalanches</title>
<p>We define a neuronal avalanche as a sequence of spikes such that no two consecutive spikes in the avalanche are separated by a time greater than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e293" xlink:type="simple"/></inline-formula>. The size of an avalanche is defined as the total number of spikes belonging to the sequence. Clearly, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e294" xlink:type="simple"/></inline-formula> is small, then avalanche sizes will be small. Indeed, in the limiting case that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e295" xlink:type="simple"/></inline-formula> is smaller than the minimum time interval between any two consecutive spikes in the network, each spike becomes its own avalanche, so all avalanches have size unity. Similarly, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e296" xlink:type="simple"/></inline-formula> is chosen to be large, then avalanches will be large. Again consider a limiting case, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e297" xlink:type="simple"/></inline-formula> is on the order of the entire simulation time. Then all of the spikes belong to a single avalanche. We estimate an appropriate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e298" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e299" xlink:type="simple"/></inline-formula> as the average time interval between consecutive spikes in the network <xref ref-type="bibr" rid="pcbi.1000846-Beggs1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000846-Stewart1">[42]</xref>. More precisely, let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e300" xlink:type="simple"/></inline-formula> be the ordered sequence of spike times in the network, then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e301" xlink:type="simple"/><label>(21)</label></disp-formula>This is the same as the total number of spikes in the simulation divided by total simulation time.</p>
</sec><sec id="s4e">
<title>Avalanche size distributions</title>
<p>We fit two distributions to the avalanche size. Firstly, if each neuron spikes independently as a Poisson process, then the entire network fires as a Poisson process, with a rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e302" xlink:type="simple"/></inline-formula>. Then, the distribution of avalanche size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e303" xlink:type="simple"/></inline-formula> is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e304" xlink:type="simple"/><label>(22)</label></disp-formula>which is a geometric distribution with parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e305" xlink:type="simple"/></inline-formula>. This is the red line in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3D–F</xref>.</p>
<p>It has been hypothesized that avalanche size distributions are consistent with a power law distribution, with the size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e306" xlink:type="simple"/></inline-formula> given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e307" xlink:type="simple"/><label>(23)</label></disp-formula>for some reasonably large range of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e308" xlink:type="simple"/></inline-formula>. Note that this means the distribution is linear in bilogarithmic coordinates. The best fitting power law distribution to the avalanche size data was obtained by using a maximum likelihood estimator (MLE) for the slope of a power law probability distribution for discrete data (avalanche sizes are integer values only); the derivation and uses of this of this estimator are clearly explained by Clauset et al <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref>. According to the MLE the slope <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e309" xlink:type="simple"/></inline-formula> is given by the equation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e310" xlink:type="simple"/><label>(24)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e311" xlink:type="simple"/></inline-formula> is the number of avalanches greater than size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e312" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e313" xlink:type="simple"/></inline-formula> is the size of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e314" xlink:type="simple"/></inline-formula> avalanche. We take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e315" xlink:type="simple"/></inline-formula> = 10. This is the blue line in <xref ref-type="fig" rid="pcbi-1000846-g003">figure 3D–F</xref>. Note that this is a different method for obtaining slope values than the more common ordinary least squares linear regression analysis (LRA) of the bilogarithmically transformed data. LRA is based on the assumption that the noise in the dependent variable is independent for each value of the independent variable and normally distributed. Although this is true when the dependent variable is the probability of a certain size avalanche, it does not hold after the bilogarithmic transformation. The transformed probability distribution has log-normally distributed noise, and so a calculation of the slope from LRA methods can give spurious results <xref ref-type="bibr" rid="pcbi.1000846-Clauset1">[16]</xref>, and a biased estimate of the avalanche slope.</p>
</sec><sec id="s4f">
<title>Making the sparse connectivity matrix</title>
<p>Here we show how to make the sparse matrix with functionally feedforward connectivity; the construction is closely related to the supplementary information from <xref ref-type="bibr" rid="pcbi.1000846-Murphy1">[13]</xref>.</p>
<p>For a network with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e316" xlink:type="simple"/></inline-formula> excitatory and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e317" xlink:type="simple"/></inline-formula> inhibitory neurons, we make a connectivity matrix<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e318" xlink:type="simple"/><label>(25)</label></disp-formula>The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e319" xlink:type="simple"/></inline-formula> matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e320" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e321" xlink:type="simple"/></inline-formula> are created from random orthogonal matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e322" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e323" xlink:type="simple"/></inline-formula> and sparse diagonal matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e324" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e325" xlink:type="simple"/></inline-formula>, by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e326" xlink:type="simple"/><label>(26)</label></disp-formula>Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e327" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e328" xlink:type="simple"/></inline-formula> have sparse diagonal entries, we ensure that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e329" xlink:type="simple"/></inline-formula> is sparse. By choosing the non-zero diagonal components of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e330" xlink:type="simple"/></inline-formula> to be much smaller than those of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e331" xlink:type="simple"/></inline-formula>, we pick the eigenvalues of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e332" xlink:type="simple"/></inline-formula> to be much smaller than those of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e333" xlink:type="simple"/></inline-formula>; this condition is analogous to the population condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e334" xlink:type="simple"/></inline-formula> in the all-to-all case, and means that there will be a large feedforward component to the network dynamics. The fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e335" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e336" xlink:type="simple"/></inline-formula> are orthonormal means that both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e337" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e338" xlink:type="simple"/></inline-formula> are normal, i.e. their eigenvectors are mutually orthogonal.</p>
<p>Next we recover <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e339" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e340" xlink:type="simple"/></inline-formula> from their sum and difference in the obvious way, but adjust any negative elements of these to zero so that the resulting matrix (25) obeys Dale's principle. This perturbation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e341" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e342" xlink:type="simple"/></inline-formula> leads to a perturbation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e343" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e344" xlink:type="simple"/></inline-formula>, making them no longer exactly normal. A normal matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e345" xlink:type="simple"/></inline-formula> satisfies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e346" xlink:type="simple"/></inline-formula>, and we may measure the deviation from normalcy of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e347" xlink:type="simple"/></inline-formula> by taking the Frobenius norm, i.e. the sum of the squares of the elements, of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e348" xlink:type="simple"/></inline-formula>. For the particular matrices under study this deviation from normalcy is very small, remaining less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e349" xlink:type="simple"/></inline-formula> for both matrices after the perturbation.</p>
<p>Now we introduce a generalized Wilson-Cowan equation for the vector of neural activities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e350" xlink:type="simple"/></inline-formula> so that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e351" xlink:type="simple"/><label>(27)</label></disp-formula>where we interpret the response function as the diagonal operator <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e352" xlink:type="simple"/></inline-formula>.</p>
<p>This set of equations has a single fixed point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e353" xlink:type="simple"/></inline-formula> for the given weight matrix, due to the symmetry in input currents, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e354" xlink:type="simple"/></inline-formula>. Accordingly, we change variables to sum and difference modes<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e355" xlink:type="simple"/><label>(28)</label></disp-formula>so that equations (27) become<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e356" xlink:type="simple"/><label>(29)</label></disp-formula>where the synaptic input is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e357" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e358" xlink:type="simple"/></inline-formula>.</p>
<p>If we replace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e359" xlink:type="simple"/></inline-formula> with the population average <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e360" xlink:type="simple"/></inline-formula>, the Jacobian of the system at the fixed point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e361" xlink:type="simple"/></inline-formula> is approximated by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e362" xlink:type="simple"/><label>(30)</label></disp-formula>which is upper triangular since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e363" xlink:type="simple"/></inline-formula> is diagonal. It can be shown that since the elements of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e364" xlink:type="simple"/></inline-formula> are large, the off-diagonal elements of this matrix will be much larger than the diagonal ones, leading to strong feedforward dynamics. It should be noted that if the net input current to each neuron is the same at the fixed point, as it is in the all-to-all case, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e365" xlink:type="simple"/></inline-formula>, and (30) becomes exact.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000846.s001" mimetype="application/postscript" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.s001" xlink:type="simple"><label>Figure S1</label><caption>
<p>Avalanche size and duration distributions for different time bin sizes. Avalanche distributions from a single simulation with parameter values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e366" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e367" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e368" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e369" xlink:type="simple"/></inline-formula>. Left column, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e370" xlink:type="simple"/></inline-formula>; right column, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000846.e371" xlink:type="simple"/></inline-formula>. Upper graphs show the distribution of avalanche size in numbers of spikes, and lower graphs show the distribution of avalanche duration, i.e. the elapsed time between the first and last spike in an avalanche, in msec. Note that the data shows power law fit in all cases, but the slope of the distribution changes with the time bin size.</p>
<p>(0.71 MB EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000846.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000846.s002" xlink:type="simple"><label>Text S1</label><caption>
<p>Calculations supporting main paper.</p>
<p>(0.10 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We would like to thank John Beggs, Michael Buice, Peter Latham, Hyong Lee, and Hong Pan for many helpful discussions; Sofía Machado for her creative contributions to early editions of the simulations; and Bard Ermentrout for pointing us towards the idea of functionally feedforward structure. We would like to thank the anonymous reviewers for their helpful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000846-Burns1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Burns</surname><given-names>BD</given-names></name>
</person-group>             <year>1955</year>             <article-title>The mechanism of after-burst in cerebral cortex.</article-title>             <source>The Journal of Physiology</source>             <volume>127</volume>             <fpage>168</fpage>             <lpage>188</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Beggs1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Beggs</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Plenz</surname><given-names>D</given-names></name>
</person-group>             <year>2003</year>             <article-title>Neuronal Avalanches in Neocortical Circuits.</article-title>             <source>Journal of Neuroscience</source>             <volume>23</volume>             <fpage>11167</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Gireesh1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gireesh</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Plenz</surname><given-names>D</given-names></name>
</person-group>             <year>2008</year>             <article-title>Neuronal avalanches organize as nested theta-and beta/gamma-oscillations during development of cortical layer 2/3.</article-title>             <source>Proceedings of the National Academy of Sciences</source>             <volume>105</volume>             <fpage>7576</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Mazzoni1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mazzoni</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Broccard</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Garcia-Perez</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Bonifazi</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Ruaro</surname><given-names>M</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>On the Dynamics of the Spontaneous Activity in Neuronal Networks.</article-title>             <source>PLoS ONE</source>             <volume>2</volume>          </element-citation></ref>
<ref id="pcbi.1000846-Pasquale1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pasquale</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Massobrio</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Bologna</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Chiappalone</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Martinoia</surname><given-names>S</given-names></name>
</person-group>             <year>2008</year>             <article-title>Self-organization and neuronal avalanches in networks of dissociated cortical neurons.</article-title>             <source>Neuroscience</source>          </element-citation></ref>
<ref id="pcbi.1000846-Petermann1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Petermann</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Thiagarajan</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Lebedev</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Nicolelis</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Chialvo</surname><given-names>D</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>Spontaneous cortical activity in awake monkeys composed of neuronal avalanches.</article-title>             <source>Proceedings of the National Academy of Sciences</source>             <volume>106</volume>             <fpage>15921</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Shew1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shew</surname><given-names>WL</given-names></name>
<name name-style="western"><surname>Yang</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Petermann</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Roy</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Plenz</surname><given-names>D</given-names></name>
</person-group>             <year>2009</year>             <article-title>Neuronal Avalanches Imply Maximum Dynamic Range in Cortical Networks at Criticality.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>15595</fpage>             <lpage>15600</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Cowan1"><label>8</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1968</year>             <article-title>Statistical mechanics of nervous nets.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Caianiello</surname><given-names>ER</given-names></name>
</person-group>             <fpage>181</fpage>             <lpage>188</lpage>             <comment>Neural Networks, Springer, Berlin-Heidelberg-New York</comment>          </element-citation></ref>
<ref id="pcbi.1000846-Cowan2"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1990</year>             <article-title>Stochastic neurodynamics.</article-title>             <source>Proceedings of the 1990 conference on Advances in neural information processing systems (NIPS)</source>             <fpage>62</fpage>             <lpage>69</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Buice1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buice</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>2007</year>             <article-title>Field-theoretic approach to fluctuation effects in neural networks.</article-title>             <source>Physical Review E</source>             <volume>75</volume>             <fpage>51919</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Buice2"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buice</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Chow</surname><given-names>C</given-names></name>
</person-group>             <year>2010</year>             <article-title>Systematic fluctuation expansion for neural network activity equations.</article-title>             <source>Neural Computation</source>             <volume>22</volume>             <fpage>377</fpage>             <lpage>426</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Gillespie1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gillespie</surname><given-names>D</given-names></name>
</person-group>             <year>1977</year>             <article-title>Exact stochastic simulation of coupled chemical reactions.</article-title>             <source>The Journal of Physical Chemistry</source>             <volume>81</volume>             <fpage>2340</fpage>             <lpage>2361</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Murphy1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Murphy</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>K</given-names></name>
</person-group>             <year>2009</year>             <article-title>Balanced Amplification: A New Mechanism of Selective Amplification of Neural Activity Patterns.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>635</fpage>             <lpage>648</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Wilson1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1972</year>             <article-title>Excitatory and inhibitory interactions in localized populations of model neurons.</article-title>             <source>Biophysical Journal</source>             <volume>12</volume>             <fpage>1</fpage>             <lpage>24</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Wilson2"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1973</year>             <article-title>A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue.</article-title>             <source>Biological Cybernetics</source>             <volume>13</volume>             <fpage>55</fpage>             <lpage>80</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Clauset1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Clauset</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Shalizi</surname><given-names>CR</given-names></name>
<name name-style="western"><surname>Newman</surname><given-names>MEJ</given-names></name>
</person-group>             <year>2009</year>             <article-title>Power-law distributions in empirical data.</article-title>             <source>SIAM Review</source>             <volume>51</volume>             <fpage>661</fpage>             <lpage>703</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-vanKampen1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Kampen</surname><given-names>N</given-names></name>
</person-group>             <year>2007</year>             <article-title>Stochastic processes in physics and chemistry.</article-title>             <source>North Holland</source>          </element-citation></ref>
<ref id="pcbi.1000846-Ohira1"><label>18</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ohira</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1997</year>             <article-title>Stochastic neurodynamics and the system size expansion.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Ellacort</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Anderson</surname><given-names>I</given-names></name>
</person-group>             <source>Mathematics of neural networks: models, algorithms, and applications, Springer</source>             <fpage>290</fpage>             <lpage>294</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Bressloff1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bressloff</surname><given-names>P</given-names></name>
</person-group>             <year>2009</year>             <article-title>Stochastic neural field theory and the system-size expansion.</article-title>             <source>SIAM Journal on Applied Mathematics</source>             <volume>70</volume>             <fpage>1488</fpage>             <lpage>1521</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Wallace1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wallace</surname><given-names>E</given-names></name>
</person-group>             <year>2010</year>             <article-title>A simplified derivation of van kampen's system size expansion.</article-title>             <volume>arXiv</volume>             <fpage>10044280 [cond-mat]</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Tsodyks1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>1995</year>             <article-title>Rapid state switching in balanced cortical network models.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>6</volume>             <fpage>111</fpage>             <lpage>124</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-vanVreeswijk1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Vreeswijk</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name>
</person-group>             <year>1996</year>             <article-title>Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity.</article-title>             <source>Science</source>             <volume>274</volume>             <fpage>1724</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Ganguli1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ganguli</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Huh</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name>
</person-group>             <year>2008</year>             <article-title>Memory traces in dynamical systems.</article-title>             <source>Proceedings of the National Academy of Sciences</source>             <volume>105</volume>             <fpage>18970</fpage>             <lpage>18975</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Ganguli2"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ganguli</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Latham</surname><given-names>P</given-names></name>
</person-group>             <year>2009</year>             <article-title>Feedforward to the Past: The Relation between Neuronal Connectivity, Amplification, and Short-Term Memory.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>499</fpage>             <lpage>501</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Goldman1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Goldman</surname><given-names>M</given-names></name>
</person-group>             <year>2009</year>             <article-title>Memory without Feedback in a Neural Network.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>621</fpage>             <lpage>634</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Abeles1"><label>26</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name>
</person-group>             <year>1991</year>             <source>Corticonics: Neural Circuits of the Cerebral Cortex</source>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000846-Eccles1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Eccles</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Fatt</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Koketsu</surname><given-names>K</given-names></name>
</person-group>             <year>1954</year>             <article-title>Cholinergic and inhibitory synapses in a pathway from motor-axon collaterals to motoneurones.</article-title>             <source>The Journal of Physiology</source>             <volume>126</volume>             <fpage>524</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Hopfield1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hopfield</surname><given-names>J</given-names></name>
</person-group>             <year>1982</year>             <article-title>Neural networks and physical systems with emergent collective computational abilities.</article-title>             <source>Proceedings of the national academy of sciences</source>             <volume>79</volume>             <fpage>2554</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Roxin1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roxin</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hakim</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name>
</person-group>             <year>2008</year>             <article-title>The Statistics of Repeating Patterns of Cortical Activity Can Be Reproduced by a Model Network of Stochastic Binary Neurons.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>10734</fpage>             <lpage>10745</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Hopfield2"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hopfield</surname><given-names>J</given-names></name>
</person-group>             <year>1984</year>             <article-title>Neurons with graded response have collective computational properties like those of two-state neurons.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>81</volume>             <fpage>3088</fpage>             <lpage>3092</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Connors1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Connors</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Gutnick</surname><given-names>M</given-names></name>
</person-group>             <year>1990</year>             <article-title>Intrinsic firing patterns of diverse neocortical neurons.</article-title>             <source>Trends in Neurosciences</source>             <volume>13</volume>             <fpage>99</fpage>             <lpage>104</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Bratsun1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bratsun</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Volfson</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Tsimring</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Hasty</surname><given-names>J</given-names></name>
</person-group>             <year>2005</year>             <article-title>Delay-induced stochastic oscillations in gene regulation.</article-title>             <source>Proceedings of the National Academy of Sciences of the United States of America</source>             <volume>102</volume>             <fpage>14593</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Rutecki1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rutecki</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Lebeda</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Johnston</surname><given-names>D</given-names></name>
</person-group>             <year>1985</year>             <article-title>Epileptiform activity induced by changes in extracellular potassium in hippocampus.</article-title>             <source>Journal of neurophysiology</source>             <volume>54</volume>             <fpage>1363</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Lowen1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lowen</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Teich</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>Fractal-based point processes.</article-title>             <source>Wiley-Interscience</source>          </element-citation></ref>
<ref id="pcbi.1000846-Touboul1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Touboul</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name>
</person-group>             <year>2010</year>             <article-title>Can power-law scaling and neuronal avalanches arise from stochastic dynamics?</article-title>             <source>PLoS ONE</source>             <volume>5</volume>             <fpage>e8982</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Abbott1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Rohrkemper</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>A simple growth model constructs critical avalanche networks.</article-title>             <source>Prog Brain Res</source>             <volume>165</volume>             <fpage>13</fpage>             <lpage>9</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Haldeman1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haldeman</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Beggs</surname><given-names>J</given-names></name>
</person-group>             <year>2005</year>             <article-title>Critical Branching Captures Activity in Living Neural Networks and Maximizes the Number of Metastable States.</article-title>             <source>Physical Review Letters</source>             <volume>94</volume>             <fpage>58101</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Levina1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Levina</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Herrmann</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Geisel</surname><given-names>T</given-names></name>
</person-group>             <year>2007</year>             <article-title>Dynamical synapses causing self-organized criticality in neural networks.</article-title>             <source>Nature Physics</source>             <volume>3</volume>             <fpage>857</fpage>          </element-citation></ref>
<ref id="pcbi.1000846-Sornette1"><label>39</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sornette</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <source>Critical Phenomena in Natural Sciences: Chaos, Fractals, Selforganization and Disorder: Concepts and Tools</source>             <publisher-name>Springer Verlag</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000846-Bak1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bak</surname><given-names>P</given-names></name>
</person-group>             <year>1996</year>             <source>How nature works: the science of self-organized criticality</source>             <publisher-name>Copernicus New York</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000846-Brette1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brette</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Carnevale</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Hines</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Beeman</surname><given-names>D</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Simulation of networks of spiking neurons: A review of tools and strategies.</article-title>             <source>Journal of Computational Neuroscience</source>             <volume>23</volume>             <fpage>349</fpage>             <lpage>398</lpage>          </element-citation></ref>
<ref id="pcbi.1000846-Stewart1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stewart</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Plenz</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <article-title>Inverted-U profile of dopamine-NMDA-mediated spontaneous avalanche recurrence in superficial layers of rat prefrontal cortex.</article-title>             <source>Journal of Neuroscience</source>             <volume>26</volume>             <fpage>8148</fpage>          </element-citation></ref>
</ref-list>

</back>
</article>