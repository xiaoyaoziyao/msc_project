<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PONE-RA-13343R1</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0009571</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Experimental Psychology</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>Attribute Pair-Based Visual Recognition and Memory</article-title><alt-title alt-title-type="running-head">Attribute Pair-Based Vision</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Morita</surname><given-names>Masahiko</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Morokami</surname><given-names>Shigemitsu</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Morita</surname><given-names>Hiromi</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Intelligent Interaction Technology, Graduate School of Systems and Information Engineering, University of Tsukuba, Tsukuba, Ibaraki, Japan</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Faculty of Letters, Aichi Shukutoku University, Nagakute, Aichi, Japan</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Graduate School of Library, Information and Media Studies, University of Tsukuba, Tsukuba, Ibaraki, Japan</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Rogers</surname><given-names>Naomi</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University of Sydney, Australia</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">mor@bcl.esys.tsukuba.ac.jp</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: MM. Performed the experiments: SM HM. Analyzed the data: HM. Wrote the paper: MM. Prepared the figures: SM.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2010</year></pub-date><pub-date pub-type="epub"><day>5</day><month>3</month><year>2010</year></pub-date><volume>5</volume><issue>3</issue><elocation-id>e9571</elocation-id><history>
<date date-type="received"><day>2</day><month>10</month><year>2009</year></date>
<date date-type="accepted"><day>11</day><month>2</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Morita et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><sec>
<title>Background</title>
<p>In the human visual system, different attributes of an object, such as shape, color, and motion, are processed separately in different areas of the brain. This raises a fundamental question of how are these attributes integrated to produce a unified perception and a specific response. This “binding problem” is computationally difficult because all attributes are assumed to be bound together to form a single object representation. However, there is no firm evidence to confirm that such representations exist for general objects.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>Here we propose a paired-attribute model in which cognitive processes are based on multiple representations of paired attributes. In line with the model's prediction, we found that multiattribute stimuli can produce an illusory perception of a multiattribute object arising from erroneous integration of attribute pairs, implying that object recognition is based on parallel perception of paired attributes. Moreover, in a change-detection task, a feature change in a single attribute frequently caused an illusory perception of change in another attribute, suggesting that multiple pairs of attributes are stored in memory.</p>
</sec><sec>
<title>Conclusions/Significance</title>
<p>The paired-attribute model can account for some novel illusions and controversial findings on binocular rivalry and short-term memory. Our results suggest that many cognitive processes are performed at the level of paired attributes rather than integrated objects, which greatly facilitates the binding problem and provides simpler solutions for it.</p>
</sec></abstract><funding-group><funding-statement>This work was supported by a Grant-in-Aid for Scientific Research for Challenging Exploratory Research (19650059) from the Japan Society for the Promotion of Science and a Grant-in-Aid for Scientific Research on Priority Areas (21013007) from the Ministry of Education, Culture, Sports, Science and Technology of Japan. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="8"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>When we see an object, e.g., a falling red apple, its shape, color, and direction of motion are processed separately by different populations of neurons. This leads to the so-called binding problem <xref ref-type="bibr" rid="pone.0009571-vonderMalsburg1">[1]</xref>, <xref ref-type="bibr" rid="pone.0009571-Treisman1">[2]</xref>, i.e., how such separate attributes are integrated by us to produce a unified perception, eliciting a specific action. This question remains an important, unsolved issue in cognitive neuroscience. According to the standard theory of feature integration <xref ref-type="bibr" rid="pone.0009571-Treisman2">[3]</xref>, by focusing attention on the object, all attributes of an object are integrated into a unified representation for higher cognitive processing. Such object representations containing all attributes or “object files” <xref ref-type="bibr" rid="pone.0009571-Kahneman1">[4]</xref> are explicitly or implicitly assumed in most cognitive models, and efforts have been directed toward elucidating the binding mechanisms underlying them. However, most potential mechanisms involve some serious computational difficulties such as combinatorial explosion, and there seems no possible mechanism that can resolve all the difficulties. In this case, the presuppositions of the problem would require reconsideration.</p>
<p>Although psychological and physiological evidence <xref ref-type="bibr" rid="pone.0009571-Treisman3">[5]</xref>–<xref ref-type="bibr" rid="pone.0009571-Luck1">[11]</xref> strongly support the existence of feature binding, they do not directly support the existence of unified representations of all attributes. For example, visual short-term memory stores bound features rather than individual features, but studies conflict as to whether an integrated object is the unit of memory <xref ref-type="bibr" rid="pone.0009571-Luck1">[11]</xref>–<xref ref-type="bibr" rid="pone.0009571-Davis1">[14]</xref>. From a computational viewpoint, integrating all attributes into a single representation is generally far more difficult than integrating two attributes. This not only applies to the cardinal or “grandmother” cell representation, but also to binding by the synchronous firing of neurons <xref ref-type="bibr" rid="pone.0009571-vonderMalsburg1">[1]</xref>, <xref ref-type="bibr" rid="pone.0009571-Singer1">[15]</xref> if we consider synchrony detection <xref ref-type="bibr" rid="pone.0009571-Shadlen1">[16]</xref>. It should also be noted that in our daily life, conjunctions of two attributes are often essential to our cognition or action selection; however, presumably we rarely experience a problem such that conjunctions of three or more attributes are essential to solve it; that is, most problems seem solvable by focusing on a single pair or a few pairs of attributes.</p>
<p>Accordingly, we hypothesized that a unified representation of all attributes is not formed for an arbitrary object with more than two attributes and developed a paired-attribute model in which cognitive processes are based on multiple representations of paired attributes and their interactions. According to this model, a falling red apple is demonstrated as three separate representations: a red apple, a falling apple, and the color red falling. Conversely, predominance of these representations leads to the recognition of the falling red apple.</p>
<p>Our hypothesis does not deny that more than two attributes are integrated and recognized as a unified object, but it distinguishes such integration from binding of feature pairs: The former is indirect, is subsequent to the latter, and does not involve a unified representation that can compete or cooperate with other representations and can directly evoke an arbitrary response; whereas, the latter is rapid, in some cases occurring in rather early stages <xref ref-type="bibr" rid="pone.0009571-Holcombe1">[9]</xref>, and involves a unified representation that can operate as the basic unit of interactions. In this paper, we do not refer to the former as “binding.” We also do not deal with “intra-attribute binding,” or feature integration within a single attribute.</p>
<p>Although currently no evidence has been reported against our hypothesis, it is not supported by any direct evidence either. Here we explore the validity of our hypothesis by testing some predictions generated by the paired-attribute model.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experiment 1</title>
<p>A simple prediction of the paired-attribute model is that simultaneous activation of attribute-pair representations will produce a perception of a unified object. However, it is difficult to objectively validate this prediction under ordinary conditions. Thus, we performed Experiment 1 using binocular rivalry, which was also intended to verify another prediction that rivalry between incompatible attribute-pair representations is a major cause of visual competition.</p>
<p>In this experiment, different stimuli were presented to each eye of normal human subjects (<xref ref-type="fig" rid="pone-0009571-g001">Figure 1A</xref>). Stimuli A and B contained features of three-attribute objects: A (clockwise-rotating green flower shape) and B (counterclockwise-rotating red snow shape). Strong binocular rivalry <xref ref-type="bibr" rid="pone.0009571-Blake1">[17]</xref> occurred when all attributes were continuously presented (condition 3) and object A or B was alternately perceived.</p>
<fig id="pone-0009571-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0009571.g001</object-id><label>Figure 1</label><caption>
<title>Experiment and models on rivalry between multiattribute objects.</title>
<p>(A) Stimuli used in Experiment 1. Ten subjects with normal vision reported their perceptions by pressing buttons. (B) Mean percentage of the total period in which button A, B, or neither was pressed. Hatched bars indicate that both stimuli were perceived in different fields (mosaic dominance). Error bars indicate s.e.m. (<italic>n</italic> = 10). (C) Mean frequency of perceptual alternation between two stimuli during a single trial (60 s). Error bars indicate s.e.m. (D) Three hypothetical models for representations of multiattribute objects.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0009571.g001" xlink:type="simple"/></fig>
<p>If a series of two-attribute displays was repeatedly presented (condition 2), observers reported the same view as in condition 3, except that the background was perceived to flicker. Binocular rivalry also occurred in a similar manner (<xref ref-type="fig" rid="pone-0009571-g001">Figure 1B</xref>). Although the mean frequency of alternation decreased (<xref ref-type="fig" rid="pone-0009571-g001">Figure 1C</xref>), the difference from condition 3 was not significant (<italic>P</italic>&gt;0.05). In contrast, if displays containing single attributes were presented (condition 1), observers reported that indistinct objects were perceived. The total period during which neither stimulus was perceived increased for all subjects, and alternation frequency was significantly lower than those in conditions 2 (<italic>P</italic> = 0.012) and 3 (<italic>P</italic> = 0.004), implying weaker binocular rivalry.</p>
<p>These results are consistent with the paired-attribute model, in which each object is represented by three units facilitating one another, and competition occurs in respective attribute pairs (<xref ref-type="fig" rid="pone-0009571-g001">Figure 1D</xref>). Two- or three-attribute stimuli (conditions 2 and 3) can sufficiently activate the units, but single-attribute stimuli (condition 1) cannot. However, the results do not necessarily exclude the single-attribute and all-attribute models in which competition occurs at the individual attribute level and the integrated whole-object level, respectively.</p>
</sec><sec id="s2b">
<title>Experiment 2</title>
<p>An exclusive prediction of the paired-attribute model is that an illusory object with three or more attributes can be perceived through erroneous integration of paired attributes. We explored this possibility using model simulations and obtained a concrete prediction that rapid serial presentation of three-attribute objects sharing two features in common with an unpresented three-attribute object (target) will produce an illusory perception of the target. We performed Experiment 2 to verify this prediction.</p>
<p>In each trial, a target was selected from among 8 three-attribute objects, and a series of stimuli was presented to an observer uninformed of the target (<xref ref-type="fig" rid="pone-0009571-g002">Figure 2A</xref>, see also supporting information <xref ref-type="supplementary-material" rid="pone.0009571.s001">Video S1</xref>). Each stimulus differed from the target in motion, color, or shape, and was presented for 94 ms.</p>
<fig id="pone-0009571-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0009571.g002</object-id><label>Figure 2</label><caption>
<title>Illusory perception of multiattribute objects predicted by the paired-attribute model.</title>
<p>(A) Example of stimuli used in Experiment 2. The target object denoted by SCM changed in each trial. S, C, or M with a bar denotes the distracting feature in the shape, color, or motion attribute, respectively. Subjects orally reported their view after a 3.3-s stimulus presentation. No feedback was provided for their answers. (B) Mean percentage of trials in which the reported shape, color, and motion were those of the target. Error bars indicate s.e.m. (<italic>n</italic> = 10). (C) Paired-attribute model accountable for the empirical result. Cooperative units are interconnected with connection weight 1, and competitive units with −1. (D) Simulated activities of individual units.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0009571.g002" xlink:type="simple"/></fig>
<p>In the control condition, the stimulus series was presented simultaneously to both eyes. Most observers perceived three objects in sequence, and the percentage of trials in which the target was reported was at the chance level (12.5%). In the test condition, the series was presented with a different phase to each eye and a stable view was perceived continuously without binocular rivalry. The target was reported in about half of the trials (<xref ref-type="fig" rid="pone-0009571-g002">Figure 2B</xref>); in most of the other trials, the target was recognized but one or two distracting features were also perceived. Although there were considerable differences between subjects, many subjects clearly perceived a three-attribute object in the test condition and did not notice that it was not actually presented to them.</p>
<p>These results do not support the all-attribute model, because competition between object representations cannot account for the findings that the unpresented target object was perceived and that no binocular rivalry occurred in the test condition in which different objects were always presented to both eyes. In addition, the illusory perception of the target is not accounted for by the predominance of target features over distracting features, because target features were also dominant in the control condition. It is also not a result of misbinding of individual features or illusory conjunctions <xref ref-type="bibr" rid="pone.0009571-Treisman1">[2]</xref>, <xref ref-type="bibr" rid="pone.0009571-McLean1">[18]</xref>, which can be observed in typical rapid serial visual presentation tasks, because the target was barely perceived in the control condition.</p>
<p>A possible explanation for the observed difference between conditions might be that the illusory perception requires concurrent presentation of three target features occurring in the test condition only. This explanation, however, is inconsistent with the finding in Experiment 1 that an illusory three-attribute object was perceived in condition 2, in which three features of the object were never presented simultaneously. Thus, the experimental results are difficult to explain reasonably using any existing model or theory.</p>
<p>However, they do conform to the paired-attribute model. Let us assume for simplicity that two attributes are monocularly bound and that attribute-pair representations are binocular. Then the paired-attribute model can be demonstrated by the network shown in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2C</xref>. Each unit of this network corresponds to a feature pair and receives an external activation signal when a stimulus containing the feature pair is presented to either eye. Different units have positive or excitatory interconnections if they correspond to different attribute pairs but share one feature in common (e.g., units SC and CM), and have negative or inhibitory interconnections if they correspond to the same attribute pairs and are mutually incompatible.</p>
<p>Mathematically, this network has an “energy” (or Lyapunov) function similar to the Hopfield neural network <xref ref-type="bibr" rid="pone.0009571-Hopfield1">[19]</xref>, which ensures that the network converges to a stable equilibrium state if the external signals are fixed. The number and distribution of stable states depend on the fixed external signals; when external signals are not sufficiently large or no units are sufficiently stimulated, only the state in which all units are inactive is stable. If three units that are mutually compatible receive a strong external signal, the state in which only these units are active is generally most stable. However, if all units equally receive a sufficiently large signal, the most stable state is that in which only the three units corresponding to a pair of target features are active, because these units have four positive connections from others whereas the other units have three (note that units corresponding to a pair of distracting features are excluded from this network because they are never activated in this experiment). A similar situation is considered to occur in the test condition in which all nine units are equally and frequently stimulated.</p>
<p>In fact, the model shows behavior as shown in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2D</xref>. In the test condition, the three units SC, CM, and MS are activated to be predominant over the other units, implying that the target SCM has been recognized. On the other hand, they are not sufficiently activated in the control condition in which only three units are stimulated simultaneously and their activity decays until they are restimulated.</p>
</sec><sec id="s2c">
<title>Experiment 3</title>
<p>Another exclusive prediction of our hypothesis is that multiple attribute-pair representations are stored in memory, which could cause specific errors in a short-term memory task. We performed Experiment 3 to explore this possibility.</p>
<p>In this experiment, subjects viewed a sample display comprising 3 three-attribute objects, and after a brief delay, compared a test object with the sample object for shape, color, and direction of motion in the same location (<xref ref-type="fig" rid="pone-0009571-g003">Figure 3A</xref>, see also <xref ref-type="supplementary-material" rid="pone.0009571.s002">Video S2</xref>). Four conditions appeared randomly with equal probability: (0) no attribute changed (case None), (1) one attribute changed (cases S, C, and M), (2) two attributes changed (cases SC, CM, and MS), and (3) all attributes changed (case SCM).</p>
<fig id="pone-0009571-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0009571.g003</object-id><label>Figure 3</label><caption>
<title>Empirical and simulation data from a change-detection task.</title>
<p>(A) Procedure for a single trial in Experiment 3. (B) Distribution of subjects' answers for each case. The left value in each cell is an empirical percentage, and the right value is that calculated by the model in (D) with best fit parameters of <italic>c</italic> = 2 and <italic>p</italic> = 0.1. Blue numbers in the diagonal cells indicate correct answers, and red numbers indicate an illusory change in an attribute caused by a change in another attribute. (C) Percentage of the number of attributes judged to be changed. The red line indicates the actual percentage. Error bars indicate s.e.m. (<italic>n</italic> = 10). The differences between the two-attribute condition and the other conditions were significant (<italic>P</italic>&lt;0.01). (D) Two-layer network for converting changes in individual attributes from changes in attribute pairs.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0009571.g003" xlink:type="simple"/></fig>
<p>Subjects' answers for each case were distributed as shown in <xref ref-type="fig" rid="pone-0009571-g003">Figure 3B</xref>. Subjects most frequently judged that two attributes had changed, although the actual frequency was equal (25%) in all four conditions (<xref ref-type="fig" rid="pone-0009571-g003">Figure 3C</xref>). Interestingly, when only one attribute changed, subjects frequently misjudged that another attribute had also changed (34% of trials, 74% of errors). In contrast, when two attributes changed, error trials reflecting the misjudgment that only one attribute had changed were not that frequent (11% of trials, 33% of errors). This finding indicates that a change in a single attribute often produces an illusory change in another attribute.</p>
<p>Again these results seem difficult to explain using the single-attribute or all-attribute models, but can be well accounted for by the paired-attribute model. The illusory change phenomenon can be understood based on change detection at the attribute-pair level.</p>
<p>More specifically, let us consider a simple two-layer network (<xref ref-type="fig" rid="pone-0009571-g003">Figure 3D</xref>) in which each unit in the first layer retains the corresponding attribute pair of the sample object and sends a mismatch signal to the second layer when the attribute pair of the test object differs from the retained memory. Each unit in the second layer detects the change in the corresponding attribute by computing the weighted sum of the mismatch signals. If retained memory is never lost, this network makes no or few errors equally in all conditions (the error rate depends on the scale parameter <italic>c</italic>). However, if the memory is lost with a certain probability <italic>p</italic>, the error distribution becomes biased and a distribution similar to the empirical data is obtained, as shown in <xref ref-type="fig" rid="pone-0009571-g003">Figure 3B</xref>.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>The results of Experiments 1 and 2 indicate that parallel perceptions of multiple attribute pairs lead to recognition of a multiattribute object, and that object recognition is not necessarily based on unified object representations. They also suggest that binocular rivalry for multiattribute objects reflects competition mainly between incompatible feature pairs that are bound monocularly, which should impact the debate on whether binocular rivalry is based on eye or stimulus <xref ref-type="bibr" rid="pone.0009571-Mitchell1">[10]</xref>, <xref ref-type="bibr" rid="pone.0009571-Blake1">[17]</xref>, <xref ref-type="bibr" rid="pone.0009571-Logothetis1">[20]</xref>–<xref ref-type="bibr" rid="pone.0009571-Bonneh1">[22]</xref>.</p>
<p>The results of Experiment 3 alone might not be sufficient evidence for our hypothesis that visual short-term memory stores paired attributes rather than integrated objects, but it is consistent with the results of a recent study suggesting that the unit of memory is a feature conjunction <xref ref-type="bibr" rid="pone.0009571-Davis1">[14]</xref>. It can also partly account for the conflicting results of previous studies <xref ref-type="bibr" rid="pone.0009571-Luck1">[11]</xref>–<xref ref-type="bibr" rid="pone.0009571-Alvarez1">[13]</xref> because it predicts that memory capacity of objects will decline as three or more attributes are involved. Our model also indicates that a comparison between sample and test objects is performed in parallel for respective attribute pairs, which is consistent with the finding that a visual search for three-attribute objects or triple conjunctions can be faster than searches for two-attribute objects or standard conjunctions because the finding is considered to reflect parallel processes in a serial search <xref ref-type="bibr" rid="pone.0009571-Wolfe2">[23]</xref>.</p>
<p>We therefore conclude that our results support the paired-attribute model, suggesting that attributes of an object are integrated with one another to form multiple attribute-pair representations and that many cognitive processes are based on the network of these representations rather than unified object representations. We also consider that no more than two attributes are directly bound together to form a single representation, except for a limited number of very familiar objects, because currently there is no concrete evidence or indispensability for such total integration. For example, current evidence for “object-based” attention <xref ref-type="bibr" rid="pone.0009571-OCraven1">[8]</xref>, <xref ref-type="bibr" rid="pone.0009571-Mitchell1">[10]</xref>, <xref ref-type="bibr" rid="pone.0009571-Blaser1">[24]</xref>, <xref ref-type="bibr" rid="pone.0009571-Kanwisher1">[25]</xref> can be understood also in terms of “attribute pair-based” attention.</p>
<p>If our view is correct, the binding problem is greatly facilitated in computational theory, and many possible binding mechanisms can solve it. Then, the critical question is “what is the substance of attribute-pair representations in the brain,” rather than “what neural mechanisms are involved.”</p>
<p>Although the present study does not provide an answer to this question, we speculate that part of the neuronal population encoding an attribute is modulated by another attribute, and different parts are modulated by different attributes; thus, an attribute pair (e.g., shape and color) can be represented by two neuronal groups (“shape neurons” modulated by color and “color neurons” modulated by shape). An example of the population modulation presumed by us has been reported in a previous study <xref ref-type="bibr" rid="pone.0009571-Naya1">[26]</xref>, in which some neurons responding to a stimulus figure showed an abrupt decrease in activity when the color cue was switched. According to our computational theory, such a selective decrease in population activity (called “selective desensitization” in our theory) is a simple and reasonable method of integrating two types of information to evoke different actions depending on how they are combined <xref ref-type="bibr" rid="pone.0009571-Suemitsu1">[27]</xref>.</p>
<p>To briefly explain the essence of this theory, let us consider a very simple model in which shape and color are encoded by different population of binary (±1) elements. Assume, for example, that shape 1 and shape 2 are represented by code patterns S<sub>1</sub> = (+ + + + − − − −) and S<sub>2</sub> = (+ − − + − + + −), respectively, and that color 1 and color 2 are represented by C<sub>1</sub> = (+ + − − + + − −) and C<sub>2</sub> = (− + − + − + − +), respectively. Then, an object with shape 1 and color 1 (denoted by S<sub>1</sub>C<sub>1</sub>) can be represented as the concatenated code pattern (S<sub>1</sub>, C<sub>1</sub>) = (+ + + + − − − − + + − − + + − −), and similarly for other objects. However, this concatenation is different from the binding we described in the <xref ref-type="sec" rid="s1">Introduction</xref>, because the concatenated patterns cannot always be associated directly with arbitrary responses. For example, a generalized XOR problem, namely, associating objects S<sub>1</sub>C<sub>1</sub> and S<sub>2</sub>C<sub>2</sub> with response A, and S<sub>1</sub>C<sub>2</sub> and S<sub>2</sub>C<sub>1</sub> with response B, is unsolvable for an ordinary two-layer network. Although a three-layer network with a hidden layer can solve this problem, the required number of hidden elements increases in proportion to the number of possible combinations of shape and color.</p>
<p>However, we found that this problem can be solved without introducing hidden elements if each element in the first layer can be selectively desensitized to take a neutral value (0). Specifically, consider the case in which each “shape element” is desensitized if the corresponding “color element” is inactive (−). Then shape 1 modulated by color 1 is represented as a code pattern S<sub>1</sub>(C<sub>1</sub>) = (+ + 0 0 − − 0 0), shape 1 modulated by color 2 as S<sub>1</sub>(C<sub>2</sub>) = (0 + 0 + 0 − 0 −), and shape 2 modulated by color 1 or 2 as S<sub>2</sub>(C<sub>1</sub>) = (+ − 0 0 − + 0 0) or S<sub>2</sub>(C<sub>2</sub>) = (0 − 0 + 0 + 0 −), respectively. These patterns can be associated directly with arbitrary patterns if the number of elements is sufficient. In addition, they include enough information on both shape and color so that the original code patterns can be easily retrieved using a simple associative network. For this reason, the color signal is required only when the shape elements to be desensitized are selected, and connections between shape elements and color elements need not be direct or permanent. Thus, this theory provides a candidate mechanism of feature binding and a possible computational role of attention in it.</p>
<p>This speculation, however, requires further examination. Moreover, the paired-attribute model should be applied to many other cognitive processes and be tested to obtain direct evidence for our hypothesis. Nevertheless, we believe that our results will provide a key to the binding problem and other problems in cognitive science.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Ethics Statement</title>
<p>This research was performed in accordance with the Ethical Principles of Psychologists and Code of Conduct of the American Psychological Association. The experiments posed no danger of infringing human rights, and written informed consent was obtained from all participants. At the time this research began, institutional review board approval was not required.</p>
</sec><sec id="s4b">
<title>Experiment 1</title>
<p>The subjects were ten undergraduate and graduate students who had roughly the same eyesight for right and left eyes, did not have a squint or a very astigmatic eye, and were blinded to the experimental purpose. They all participated as paid volunteers and provided informed consent for participation.</p>
<p>Subjects viewed the stereo images through a stereoscope in a dark room. For each subject, mirrors of the stereoscope were carefully adjusted to ensure correct binocular alignment of the images with the central fixation cross and the square frame subtending 8.7 degrees, which were also presented during experimental trials to aid in the maintenance of proper convergence. The luminance of green was adjusted equal to that of gray (1.84 cd/m<sup>2</sup>), such that an alternate (10.6 Hz) green and gray presentation elicited a minimum perception of flicker. The luminance of red was adjusted equal to that of green in a similar manner. The background (outside the stimulus) was dark gray (0.45 cd/m<sup>2</sup>).</p>
<p>Subjects were instructed to hold down button A or B when stimulus A or B was perceived, respectively, and both buttons if both stimuli were partly perceived in different fields. They were also asked to avoid blinking intentionally during trials and to describe their perception after trials. For each condition, each stimulus was presented to both eyes with a notice of the type of stimulus (A or B) and the subjects orally reported their perception.</p>
<p>After practice trials, subjects performed 12 experimental trials of 60 s each: two trials in which stimuli A and B were presented to the left and right eyes, respectively, and two trials vice versa, for conditions 1, 2 and 3. These trials were divided into four blocks of three trials representing Conditions 1, 2, and 3; the order of conditions was fixed for one subject but counterbalanced across subjects.</p>
<p>The stimuli illustrated in <xref ref-type="fig" rid="pone-0009571-g001">Figure 1A</xref> are based on a circular pattern subtending 7.3 degrees composed of gray random dots (density, 0.23) on a black background. This pattern was also used as a mask presented before and after stimulus presentation. Displays S<sub>A</sub> and S<sub>B</sub> were generated by drawing black outlines and filling the inside with the dot pattern. C<sub>A</sub> and C<sub>B</sub> were generated by replacing gray dots in the pattern with green or red dots, respectively. M<sub>A</sub> and M<sub>B</sub> were generated by successively rotating the pattern in a clockwise or counterclockwise direction, respectively, by 0.4 degrees during each refresh period of 11.8 ms (34 deg/s). M<sub>A</sub>S<sub>A</sub> and M<sub>B</sub>S<sub>B</sub> were generated by rotating S<sub>A</sub> and S<sub>B</sub>, respectively, and S<sub>A</sub>C<sub>A</sub>, S<sub>B</sub>C<sub>B</sub>, C<sub>A</sub>M<sub>A</sub>, C<sub>B</sub>M<sub>B</sub>, S<sub>A</sub>C<sub>A</sub>M<sub>A</sub>, and S<sub>B</sub>C<sub>B</sub>M<sub>B</sub> were colored by replacing gray dots with green or red dots.</p>
<p>Each display in conditions 1 and 2 was presented repeatedly with an interval of 141 ms at 1.6 and 3.2 degree rotated positions, respectively, from the previously presented position, such that the dot pattern was not discontinuously rotated. Experimental parameters were determined by performing preliminary experiments with other subjects.</p>
<p>The obtained data were analyzed using repeated-measures ANOVA. The effect of conditions was significant for the data in <xref ref-type="fig" rid="pone-0009571-g001">Figure 1B and C</xref> (<italic>F</italic><xref ref-type="bibr" rid="pone.0009571-Treisman1">[2]</xref>, <xref ref-type="bibr" rid="pone.0009571-McLean1">[18]</xref> = 12.9, <italic>P</italic>&lt;0.001 and <italic>F</italic><xref ref-type="bibr" rid="pone.0009571-Treisman1">[2]</xref>, <xref ref-type="bibr" rid="pone.0009571-McLean1">[18]</xref> = 15.6, <italic>P</italic>&lt;0.001, respectively), and post hoc comparisons were performed using the Bonferroni test.</p>
</sec><sec id="s4c">
<title>Experiment 2</title>
<p>The same ten subjects from Experiment 1 participated in this experiment after Experiment 1.</p>
<p>Subjects were instructed to view the stimulus displays without blinks and orally report the shape, color, and direction of rotation that they perceived. Although subjects were asked to report as specifically as possible, unspecific answers such as “both flower and snow,” “either red or green,” and “unclear” were allowed. Each subject performed sufficient practice trials with no feedback and then performed 64 experimental trials in random order: 32 trials (four trials for each target object) for the test condition and 32 trials for the control condition.</p>
<p>Each stimulus illustrated in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2A</xref> was generated in a manner similar to Experiment 1, but the combination of features was selected from among eight cases and changed in every trial in random order. Each trial started with a 0.5-s presentation of the mask, followed by a serial presentation of three stimuli repeated for eight cycles (2.25 s) with an interval of 282 ms at a 3.2 degree rotated position and ending with a 0.5-s presentation of the mask.</p>
<p>The data obtained were subjected to the paired <italic>t</italic>-test. The difference between the conditions was significant (<italic>t</italic><xref ref-type="bibr" rid="pone.0009571-Holcombe1">[9]</xref> = 5.02, <italic>P</italic>&lt;0.001).</p>
</sec><sec id="s4d">
<title>Model Simulation for Experiment 2</title>
<p>Each unit of the model shown in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2C</xref> receives signals from other units and an external activation signal, and emits the output <italic>x<sub>i</sub></italic> according to the inner potential <italic>u<sub>i</sub></italic>. The activation signal <italic>s<sub>i</sub></italic> is 1 when a stimulus containing the corresponding feature pair is presented, and 0 otherwise. In mathematical terms, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0009571.e001" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0009571.e002" xlink:type="simple"/></inline-formula>, where <italic>w<sub>ij</sub></italic> is the connection weight (1, −1, or 0), <italic>ι</italic> is the time constant of dynamics, and <italic>a</italic> and <italic>b</italic> are positive parameters. Parameters used in the simulation shown in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2D</xref> are <italic>a</italic> = 3, <italic>b</italic> = 2, and <italic>τ</italic> = 100 ms.</p>
</sec><sec id="s4e">
<title>Experiment 3</title>
<p>A different set of ten undergraduate and graduate students with normal or corrected vision participated in this experiment. All were paid volunteers who were blinded to the experimental purpose and provided informed consent.</p>
<p>Subjects were instructed to watch a sample display, compare a test object with the sample object in the same location, and respond by clicking on icons using the mouse. To balance the tendency to hesitate from clicking on icons when the subjects were unsure about their judgment, we instructed them to mark icons corresponding to changed attributes in the first or last half (counterbalanced between subjects) of the trials and to mark icons corresponding to unchanged attributes in the other half.</p>
<p>Each subject performed sufficient practice trials with no feedback and then performed 600 experimental trials in random order (except for one subject, who performed 480 experimental trials): 150 (120) trials each for cases None and SCM and 50 (40) trials each for cases S, C, M, CM, MS, and SC.</p>
<p>The three objects in the sample display had different shapes (star, moon, and cross of the same size; 1.6 deg×1.6 deg), colors (red, green, and blue; 16.5 cd/m<sup>2</sup>), and motion directions (12, 4, and 8 o'clock at equal speed; 1.3 deg/s). The background was gray (11 cd/m<sup>2</sup>). These parameters were determined by conducting preliminary experiments with other subjects such that the percentage of correct answers would be almost independent of the type of attributes.</p>
<p>The obtained data were analyzed using repeated-measures ANOVA. The effect of attribute number in <xref ref-type="fig" rid="pone-0009571-g003">Figure 3C</xref> was significant (<italic>F</italic><xref ref-type="bibr" rid="pone.0009571-Treisman2">[3]</xref>, <xref ref-type="bibr" rid="pone.0009571-Suemitsu1">[27]</xref> = 24.2, <italic>P</italic>&lt;0.001). Post hoc comparisons were performed using the Bonferroni test.</p>
</sec><sec id="s4f">
<title>Model Simulation for Experiment 3</title>
<p>Each unit in the first layer of the model (<xref ref-type="fig" rid="pone-0009571-g003">Figure 3D</xref>) emits 2 if both the corresponding attributes are changed, 1 if one of them is changed, or 0 if neither is changed. Each unit in the second layer emits 1, indicating that a change in the corresponding attribute is detected, with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0009571.e003" xlink:type="simple"/></inline-formula>, where <italic>u</italic> denotes the weighted sum of the input signals and <italic>h</italic> denotes a threshold or bias term (<italic>h</italic> = 1 in the normal case). We assume that the memory of an attribute pair is lost with probability <italic>p</italic>; when this occurs, the corresponding unit sends no signal and <italic>h</italic> is decreased by 1 (<italic>h</italic> = 1−<italic>k</italic>, when <italic>k</italic> memories are lost).</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0009571.s001" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0009571.s001" xlink:type="simple"><label>Video S1</label><caption>
<p>Example of stimulus displays in the test condition of Experiment 2. The stimulus set is the same as that shown in <xref ref-type="fig" rid="pone-0009571-g002">Figure 2A</xref>. Although the frame rate, luminance, color balance, size, and other conditions may be considerably different from those actually used, the test trial can be experienced by fusing two stimulus images similar to the fusing done when viewing stereo images. Looking through a stereoscope (preferred) or two pipes for respective eyes is recommended. If you perceive a red snow shape rotating clockwise, you are seeing an illusion. You can also experience the control trial by viewing either image with both eyes. Note that because of individual differences and the difference in conditions, you might not see the illusion clearly.</p>
<p>(5.49 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0009571.s002" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0009571.s002" xlink:type="simple"><label>Video S2</label><caption>
<p>Example of stimulus displays in Experiment 3. Eight trials in conditions 1 and 2 appear in random order; after each trial, icons indicating changed attributes are shown, although in the actual experiment, trials in conditions 0 and 3 were also included, and the correct answer was not fed back to the subject.</p>
<p>(6.77 MB AVI)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Masashi Kotoku and Mai Ikeda for their assistance in the experiments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0009571-vonderMalsburg1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name>
</person-group>             <year>1981</year>             <article-title>The correlation theory of brain function. MPI Biophysical Chemistry, Internal Report 81-2. Reprinted.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Domany</surname><given-names>E</given-names></name>
<name name-style="western"><surname>van Hemmen</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Schulten</surname><given-names>K</given-names></name>
</person-group>             <source>Models of Neural Networks II</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer (1994)</publisher-name>             <fpage>95</fpage>             <lpage>119</lpage>          </element-citation></ref>
<ref id="pone.0009571-Treisman1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treisman</surname><given-names>A</given-names></name>
</person-group>             <year>1996</year>             <article-title>The binding problem.</article-title>             <source>Curr Opinion Neurobio</source>             <volume>6</volume>             <fpage>171</fpage>             <lpage>178</lpage>          </element-citation></ref>
<ref id="pone.0009571-Treisman2"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treisman</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Glede</surname><given-names>GA</given-names></name>
</person-group>             <year>1980</year>             <article-title>A feature integration theory of attention.</article-title>             <source>Cogn Psych</source>             <volume>12</volume>             <fpage>97</fpage>             <lpage>136</lpage>          </element-citation></ref>
<ref id="pone.0009571-Kahneman1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kahneman</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Treisman</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Gibbs</surname><given-names>BJ</given-names></name>
</person-group>             <year>1992</year>             <article-title>The reviewing of object files: Object-specific integration of information.</article-title>             <source>Cogn Psych</source>             <volume>24</volume>             <fpage>175</fpage>             <lpage>219</lpage>          </element-citation></ref>
<ref id="pone.0009571-Treisman3"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treisman</surname><given-names>A</given-names></name>
</person-group>             <year>1999</year>             <article-title>Solutions to the binding problem: Progress through controversy and convergence.</article-title>             <source>Neuron</source>             <volume>24</volume>             <fpage>105</fpage>             <lpage>110</lpage>          </element-citation></ref>
<ref id="pone.0009571-Wolfe1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wolfe</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Cave</surname><given-names>KR</given-names></name>
</person-group>             <year>1999</year>             <article-title>The psychophysical evidence for a binding problem in human vision.</article-title>             <source>Neuron</source>             <volume>24</volume>             <fpage>11</fpage>             <lpage>17</lpage>          </element-citation></ref>
<ref id="pone.0009571-Reynolds1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reynolds</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Desimone</surname><given-names>R</given-names></name>
</person-group>             <year>1999</year>             <article-title>The role of neural mechanisms of attention in solving the binding problem.</article-title>             <source>Neuron</source>             <volume>24</volume>             <fpage>19</fpage>             <lpage>29</lpage>          </element-citation></ref>
<ref id="pone.0009571-OCraven1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>O'Craven</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Downing</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>
</person-group>             <year>1999</year>             <article-title>fMRI evidence for objects as the units of attentional selection.</article-title>             <source>Nature</source>             <volume>401</volume>             <fpage>584</fpage>             <lpage>587</lpage>          </element-citation></ref>
<ref id="pone.0009571-Holcombe1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Holcombe</surname><given-names>AO</given-names></name>
<name name-style="western"><surname>Cavanagh</surname><given-names>P</given-names></name>
</person-group>             <year>2001</year>             <article-title>Early binding of feature pairs for visual perception.</article-title>             <source>Nat Neurosci</source>             <volume>4</volume>             <fpage>127</fpage>             <lpage>128</lpage>          </element-citation></ref>
<ref id="pone.0009571-Mitchell1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mitchell</surname><given-names>JF</given-names></name>
<name name-style="western"><surname>Stoner</surname><given-names>GR</given-names></name>
<name name-style="western"><surname>Reynolds</surname><given-names>JH</given-names></name>
</person-group>             <year>2004</year>             <article-title>Object-based attention determines dominance in binocular rivalry.</article-title>             <source>Nature</source>             <volume>429</volume>             <fpage>410</fpage>             <lpage>413</lpage>          </element-citation></ref>
<ref id="pone.0009571-Luck1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Luck</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Vogel</surname><given-names>EK</given-names></name>
</person-group>             <year>1997</year>             <article-title>The capacity of visual working memory for features and conjunctions.</article-title>             <source>Nature</source>             <volume>390</volume>             <fpage>279</fpage>             <lpage>281</lpage>          </element-citation></ref>
<ref id="pone.0009571-Olson1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Olson</surname><given-names>IR</given-names></name>
<name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name>
</person-group>             <year>2002</year>             <article-title>Is visual short-term memory object based? Rejection of the “strong-object” hypothesis.</article-title>             <source>Percept Psychophys</source>             <volume>64</volume>             <fpage>1055</fpage>             <lpage>1067</lpage>          </element-citation></ref>
<ref id="pone.0009571-Alvarez1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alvarez</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Cavanagh</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <article-title>The capacity of visual short-term memory is set both by visual information load and by number of objects.</article-title>             <source>Psychol Sci</source>             <volume>15</volume>             <fpage>106</fpage>             <lpage>111</lpage>          </element-citation></ref>
<ref id="pone.0009571-Davis1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Davis</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Holmes</surname><given-names>A</given-names></name>
</person-group>             <year>2005</year>             <article-title>The capacity of visual short-term memory is not a fixed number of objects.</article-title>             <source>Mem Cognit</source>             <volume>33</volume>             <fpage>185</fpage>             <lpage>195</lpage>          </element-citation></ref>
<ref id="pone.0009571-Singer1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Singer</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Gray</surname><given-names>CM</given-names></name>
</person-group>             <year>1995</year>             <article-title>Visual feature integration and the temporal correlation hypothesis.</article-title>             <source>Annu Rev Neurosc</source>             <volume>18</volume>             <fpage>555</fpage>             <lpage>586</lpage>          </element-citation></ref>
<ref id="pone.0009571-Shadlen1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
</person-group>             <year>1999</year>             <article-title>Synchrony unbound: A critical evaluation of the temporal binding hypothesis.</article-title>             <source>Neuron</source>             <volume>24</volume>             <fpage>67</fpage>             <lpage>77</lpage>          </element-citation></ref>
<ref id="pone.0009571-Blake1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name>
</person-group>             <year>2002</year>             <article-title>Visual competition.</article-title>             <source>Nat Rev Neurosci</source>             <volume>3</volume>             <fpage>13</fpage>             <lpage>23</lpage>          </element-citation></ref>
<ref id="pone.0009571-McLean1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McLean</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Broadbent</surname><given-names>DE</given-names></name>
<name name-style="western"><surname>Broadbent</surname><given-names>MH</given-names></name>
</person-group>             <year>1983</year>             <article-title>Combining attributes in rapid serial visual presentation tasks.</article-title>             <source>Quart J Exp Psychol</source>             <volume>35A</volume>             <fpage>171</fpage>             <lpage>186</lpage>          </element-citation></ref>
<ref id="pone.0009571-Hopfield1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name>
</person-group>             <year>1984</year>             <article-title>Neurons with graded response have collective computational properties like those of two-state neurons.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>81</volume>             <fpage>3088</fpage>             <lpage>3092</lpage>          </element-citation></ref>
<ref id="pone.0009571-Logothetis1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name>
<name name-style="western"><surname>Leopold</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Sheinberg</surname><given-names>DL</given-names></name>
</person-group>             <year>1996</year>             <article-title>What is rivaling during binocular rivalry?</article-title>             <source>Nature</source>             <volume>380</volume>             <fpage>621</fpage>             <lpage>624</lpage>          </element-citation></ref>
<ref id="pone.0009571-Lee1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lee</surname><given-names>SH</given-names></name>
<name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>
</person-group>             <year>1999</year>             <article-title>Rival ideas about binocular rivalry.</article-title>             <source>Vision Res</source>             <volume>39</volume>             <fpage>1447</fpage>             <lpage>1454</lpage>          </element-citation></ref>
<ref id="pone.0009571-Bonneh1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bonneh</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Sagi</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Karni</surname><given-names>AA</given-names></name>
</person-group>             <year>2001</year>             <article-title>Transition between eye and object rivalry determined by stimulus coherence.</article-title>             <source>Vision Res</source>             <volume>41</volume>             <fpage>981</fpage>             <lpage>989</lpage>          </element-citation></ref>
<ref id="pone.0009571-Wolfe2"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wolfe</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Cave</surname><given-names>KR</given-names></name>
<name name-style="western"><surname>Franzel</surname><given-names>SL</given-names></name>
</person-group>             <year>1989</year>             <article-title>Guided search: An alternative to the feature integration model for visual search.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>15</volume>             <fpage>419</fpage>             <lpage>433</lpage>          </element-citation></ref>
<ref id="pone.0009571-Blaser1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blaser</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Pylyshyn</surname><given-names>ZW</given-names></name>
<name name-style="western"><surname>Holcombe</surname><given-names>AO</given-names></name>
</person-group>             <year>2000</year>             <article-title>Tracking an object through feature space.</article-title>             <source>Nature</source>             <volume>408</volume>             <fpage>196</fpage>             <lpage>199</lpage>          </element-citation></ref>
<ref id="pone.0009571-Kanwisher1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Wojciulik</surname><given-names>E</given-names></name>
</person-group>             <year>2000</year>             <article-title>Visual attention: Insights from brain imaging.</article-title>             <source>Nat Rev Neurosc</source>             <volume>1</volume>             <fpage>91</fpage>             <lpage>100</lpage>          </element-citation></ref>
<ref id="pone.0009571-Naya1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Naya</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Sakai</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Miyashita</surname><given-names>Y</given-names></name>
</person-group>             <year>1996</year>             <article-title>Activity of primate inferotemporal neurons related to a sought target in pair-association task.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>93</volume>             <fpage>2664</fpage>             <lpage>2669</lpage>          </element-citation></ref>
<ref id="pone.0009571-Suemitsu1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Suemitsu</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Morita</surname><given-names>M</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neural network model of context-dependent neuronal activity in inferotemporal cortex.</article-title>             <source>Proc IJCNN'</source>             <volume>06</volume>             <fpage>293</fpage>             <lpage>298</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>