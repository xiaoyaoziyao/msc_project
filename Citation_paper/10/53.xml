<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004698</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-01738</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hallucinations</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hallucinations</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Hallucinations</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal tuning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Optimal Information Representation and Criticality in an Adaptive Sensory Recurrent Neuronal Network</article-title>
<alt-title alt-title-type="running-head">Optimal Information Representation and Criticality</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Shriki</surname>
<given-names>Oren</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Yellin</surname>
<given-names>Dovi</given-names>
</name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Cognitive and Brain Sciences, Ben-Gurion University of the Negev, Beer-Sheva, Israel</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Computer Science, Ben-Gurion University of the Negev, Beer-Sheva, Israel</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Zlotowski Center for Neuroscience, Ben Gurion University, Beer-Sheva, Israel</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Neurobiology, Weizmann Institute of Science, Rehovot, Israel</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname>
<given-names>Olaf</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: OS. Performed the experiments: OS DY. Analyzed the data: OS DY. Contributed reagents/materials/analysis tools: OS DY. Wrote the paper: OS DY.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">shrikio@bgu.ac.il</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>16</day>
<month>2</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>2</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>2</issue>
<elocation-id>e1004698</elocation-id>
<history>
<date date-type="received">
<day>14</day>
<month>10</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>12</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Shriki, Yellin</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004698"/>
<abstract>
<p>Recurrent connections play an important role in cortical function, yet their exact contribution to the network computation remains unknown. The principles guiding the long-term evolution of these connections are poorly understood as well. Therefore, gaining insight into their computational role and into the mechanism shaping their pattern would be of great importance. To that end, we studied the learning dynamics and emergent recurrent connectivity in a sensory network model based on a first-principle information theoretic approach. As a test case, we applied this framework to a model of a hypercolumn in the visual cortex and found that the evolved connections between orientation columns have a "Mexican hat" profile, consistent with empirical data and previous modeling work. Furthermore, we found that optimal information representation is achieved when the network operates near a critical point in its dynamics. Neuronal networks working near such a phase transition are most sensitive to their inputs and are thus optimal in terms of information representation. Nevertheless, a mild change in the pattern of interactions may cause such networks to undergo a transition into a different regime of behavior in which the network activity is dominated by its internal recurrent dynamics and does not reflect the objective input. We discuss several mechanisms by which the pattern of interactions can be driven into this supercritical regime and relate them to various neurological and neuropsychiatric phenomena.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>The recurrent interactions among cortical neurons shape the representation of incoming information but the principles governing their evolution are yet unclear. We investigate the computational role of recurrent connections in the context of sensory processing. Specifically, we study a neuronal network model in which the recurrent connections evolve to optimize the information representation of the network. Interestingly, these networks tend to operate near a "critical" point in their dynamics, namely close to a phase of "hallucinations", in which non-trivial spontaneous patterns of activity evolve even without structured input. We provide insights into this behavior by applying the framework to a network of orientation selective neurons, modeling a processing unit in the primary visual cortex. Various scenarios, such as attenuation of the external inputs or increased plasticity, can lead such networks to cross the border into the supercritical phase, which may manifest as neurological and neuropsychiatric phenomena.</p>
</abstract>
<funding-group>
<funding-statement>This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 754/14 to OS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="19"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The anatomical abundance of lateral interactions [<xref ref-type="bibr" rid="pcbi.1004698.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref002">2</xref>] between neurons of the local cerebral circuit (referred in this text as recurrent connections) suggest they play a fundamental role in cortical function. Indirect physiological evidence of their involvement in memory [<xref ref-type="bibr" rid="pcbi.1004698.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref004">4</xref>], sensory processing [<xref ref-type="bibr" rid="pcbi.1004698.ref005">5</xref>] and in other brain functions [<xref ref-type="bibr" rid="pcbi.1004698.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref007">7</xref>] reinforces this notion. Various models have been put forward in an attempt to explain the role of these lateral connections, however, an agreed framework is still missing and the topic is still far from being concluded. In the narrower scope of early visual cortex, some studies have related the role of recurrent connectivity to orientation tuning and contrast invariance [<xref ref-type="bibr" rid="pcbi.1004698.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004698.ref010">10</xref>]. Others have suggested a role in generating the accurate firing rates common to spontaneous activity [<xref ref-type="bibr" rid="pcbi.1004698.ref011">11</xref>].</p>
<p>An additional aspect of recurrently connected networks (relative to networks connected by feedforward links only) involves their dynamic properties. Networks with recurrent connections have been shown to form associative-memory related attractor states[<xref ref-type="bibr" rid="pcbi.1004698.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref013">13</xref>], exhibit self-organization leading to “neuronal avalanches” [<xref ref-type="bibr" rid="pcbi.1004698.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref015">15</xref>], and in general, have the potential to exhibit critical dynamics [<xref ref-type="bibr" rid="pcbi.1004698.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1004698.ref018">18</xref>]. The idea that brain areas may operate near criticality was proposed on theoretical grounds by several authors in the past [<xref ref-type="bibr" rid="pcbi.1004698.ref018">18</xref>–<xref ref-type="bibr" rid="pcbi.1004698.ref022">22</xref>]. There is also a growing bulk of recent experimental evidence supporting it [<xref ref-type="bibr" rid="pcbi.1004698.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1004698.ref026">26</xref>] (for reviews on near criticality in the brain see [<xref ref-type="bibr" rid="pcbi.1004698.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref027">27</xref>]). Beggs and Plenz [<xref ref-type="bibr" rid="pcbi.1004698.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref015">15</xref>] demonstrated that neural activity in acute slices and in slice cultures is organized in <italic>neural avalanches</italic>, whose size obeys a power law distribution. They interpreted their results in terms of <italic>critical branching processes</italic> [<xref ref-type="bibr" rid="pcbi.1004698.ref028">28</xref>]. Further work [<xref ref-type="bibr" rid="pcbi.1004698.ref023">23</xref>] showed that neuronal avalanches also appear in the spontaneous cortical activity of awake monkeys and in large scale human brain activity (e.g. [<xref ref-type="bibr" rid="pcbi.1004698.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref030">30</xref>]). It was also demonstrated in slice cultures that the dynamical range of the network is maximized near the critical point [<xref ref-type="bibr" rid="pcbi.1004698.ref024">24</xref>]. Although these dynamic properties have by now been well established, only few papers in the neuroscience literature have so far attempted to link them to concrete brain functions, such as the function of the visual system.</p>
<p>A central question regarding recurrent interactions, which has not yet been properly addressed, is how they evolve to facilitate the network’s computational capacity and what principles govern this evolution. Their optimal pattern within the network also remains unknown. In this work, we address these issues using a first-principle information theoretic approach, namely using the principle of maximum information preservation (also known as ‘infomax’ [<xref ref-type="bibr" rid="pcbi.1004698.ref031">31</xref>]). This principle has been successfully implemented in a variety of computational neuroscience studies. Bell &amp; Sejnowski [<xref ref-type="bibr" rid="pcbi.1004698.ref032">32</xref>] extended it to nonlinear output neurons implementing ICA (Independent Component Analysis) to achieve blind source separation. Later, they showed that the independent components of natural scenes are Gabor-like edge filters [<xref ref-type="bibr" rid="pcbi.1004698.ref033">33</xref>].</p>
<p>Tanaka et al [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] have demonstrated that the characteristics of orientation selectivity in V1 can be acquired by self-organization of recurrent neural networks according to Infomax learning. This work was recently extended by Hayakawa et al [<xref ref-type="bibr" rid="pcbi.1004698.ref035">35</xref>] to reveal a biologically plausible infomax learning algorithm.</p>
<p>The present work can be seen as a further extension of these earlier efforts, studying how the gradual development of a network’s recurrent interactions may optimize the representation of input stimuli. Unsupervised learning is applied in training networks to maximize mutual information between the input layer and an overcomplete recurrently connected output layer. The evolving pattern of recurrent interactions is investigated in a model of a hypercolumn in primary visual cortex, considered the base functional unit of V1, receiving input from both eyes, in a full representation of all possible orientations. Various constellations of input stimuli and network connectivity are examined, in aim of studying their relationship with different network measures. Methods to evaluate the optimal pattern of recurrent interactions in a neural network model and its dependence on the statistics of the external inputs were extended from Shriki et al. [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>]. We first provide an analytical and numerically simulated account of a toy hypercolumn network model. Subsequently, a more ecological network is studied, in which natural scenes are used as input for training the network. These models allow us to compare the emerging network’s properties with those arising from earlier empirical and theoretical work.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>The general scheme and many methods applied in this study can be viewed as a direct evolution of the earlier work reported in [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>]. Below, we highlight the main extensions of the current models relative to the one presented in this former work in regards to the network structure, learning algorithm and other significant model ingredients.</p>
<sec id="sec003">
<title>Network architecture and dynamics</title>
<p>The basic network model consists of two layers of neurons, <italic>N</italic> neurons at the input layer and <italic>M</italic> neurons at the output layer (<xref ref-type="fig" rid="pcbi.1004698.g001">Fig 1A</xref>), where <italic>M ≥ N</italic>. Thus, the network deterministically maps a low dimensional input space into a manifold in a higher-dimensional output space. Such a representation, which contains more output components than input components, is termed <italic>overcomplete</italic>. The feedforward interactions are described by the <italic>M</italic> × <italic>N</italic> matrix <italic>W</italic> and the recurrent interactions by the <italic>M</italic> × <italic>M</italic> matrix <italic>K</italic>.</p>
<fig id="pcbi.1004698.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004698.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Network diagrams and input statistics.</title>
<p>(A) The general network architecture characterized by an overcomplete representation with <italic>N</italic> input neurons, <italic>x</italic><sub><italic>i</italic></sub> (<italic>i</italic> = 1,…,<italic>N</italic>) and <italic>M ≥ N</italic> output neurons, <italic>s</italic><sub><italic>i</italic></sub> (<italic>i</italic> = 1,…,<italic>M</italic>). The input is linearly transformed by the feedforward connection matrix,<bold><italic>W</italic></bold>, and then nonlinearly processed by the recurrent dynamics at the output layer. The interactions among the output neurons are denoted by the matrix <bold><italic>K</italic></bold>. (B) A toy network model of a visual hypercolumn containing 2 input neurons and <italic>M</italic> output neurons. The feedforward connections are preset to unit vectors spanning all angles at equal intervals. The inputs are points on the plane with uniformly distributed angles and normally distributed distances from the origin. The distance from the origin represents the input contrast. (C) An ecological network model in which the inputs are natural images. The feedforward connections are Gabor filters with orientations equally spaced between 0° and 180°.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004698.g001" xlink:type="simple"/>
</fig>
<p>During the presentation of each input sample, the input components <italic>x</italic><sub><italic>i</italic></sub> are fixed. The dynamics of the output neurons are given by
<disp-formula id="pcbi.1004698.e001">
<alternatives>
<graphic id="pcbi.1004698.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>                    </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
Where <italic>g</italic> is some nonlinear squashing function and <italic>τ</italic> is a characteristic time scale (here we set <italic>τ =</italic> 1 and <italic>g</italic> was taken to be the logistic function, <italic>g</italic>(<italic>x</italic>) = 1/(1+<italic>e</italic><sup>−<italic>x</italic></sup>)). We assume that the activities of the output neurons reach equilibrium after some time and define the output as the steady-state pattern of activity. For the cases we studied, numerical simulations of the network dynamics indeed stabilized and proved this assumption to be consistent. The steady-state responses are given by
<disp-formula id="pcbi.1004698.e002">
<alternatives>
<graphic id="pcbi.1004698.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>                    </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
</sec>
<sec id="sec004">
<title>Objective function and learning algorithm</title>
<p>To evaluate the neuronal representation of the external inputs we used the mutual information between the input and output of the network [<xref ref-type="bibr" rid="pcbi.1004698.ref037">37</xref>]. More specifically, the mutual information between the input vector, <bold><italic>x</italic></bold>, and the output vector, <bold><italic>s</italic></bold>, can be expressed as the difference between the entropy of the output and the conditional entropy of the output given the input. The conditional entropy can also be viewed as the entropy of the output noise. Here, the network response is a deterministic function of the input, and thus the mutual information depends only on the entropy of the outputs. As shown in [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>], maximizing the output entropy (and therefore the mutual information) is equivalent to minimizing the following objective function:
<disp-formula id="pcbi.1004698.e003">
<alternatives>
<graphic id="pcbi.1004698.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mtext>ln det</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>χ</mml:mo><mml:mtext>T</mml:mtext></mml:msup><mml:mi>χ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>Tr</mml:mtext><mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>χ</mml:mo><mml:mtext>T</mml:mtext></mml:msup><mml:mi>χ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula>
where <inline-formula id="pcbi.1004698.e004"><alternatives><graphic id="pcbi.1004698.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> is the Jacobian matrix of the transformation and reflects the sensitivity of the output units to changes in the input units. We also refer to this matrix as the susceptibility matrix as it is analogous to the susceptibility of physical systems to external fields.</p>
<p>The adaptive parameters of the algorithm are the sets of feedforward and recurrent interactions, <italic>W</italic><sub><italic>ij</italic></sub> and <italic>K</italic><sub><italic>ij</italic></sub>. The learning rules for these parameters are derived from this objective function using the gradient decent method, as shown in [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>]. Here we focus only on the recurrent interactions. The gradient descent learning rule for the recurrent interactions is:
<disp-formula id="pcbi.1004698.e005">
<alternatives>
<graphic id="pcbi.1004698.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:mo>Δ</mml:mo><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo>〈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>Γ</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>ϕ</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>a</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>〉</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
Where <italic>η</italic> is the learning rate, the matrix <italic>ϕ</italic> is given by <italic>ϕ</italic> = (<italic>G</italic><sup>−1</sup>−<italic>K</italic>)<sup>−1</sup> and satisfies χ = <italic>ϕW</italic>, the matrix <italic>G</italic> is defined as <inline-formula id="pcbi.1004698.e006"><alternatives><graphic id="pcbi.1004698.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msub><mml:mtext>g'</mml:mtext><mml:mi>k</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mo>→</mml:mo><mml:msub><mml:mtext> g'</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, the matrix Γ is defined as Γ = (<italic>χ</italic><sup><italic>T</italic></sup><italic>χ</italic>)<sup>−1</sup><italic>χ</italic><sup><italic>T</italic></sup><italic>ϕ</italic> and the components of the vector <italic>a</italic> are given by <inline-formula id="pcbi.1004698.e007"><alternatives><graphic id="pcbi.1004698.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>Γ</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>k</mml:mi><mml:mo>″</mml:mo></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>k</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. The triangular brackets denote averaging over the input samples.</p>
</sec>
<sec id="sec005">
<title>Metrics of network behavior</title>
<p>We defined several measures to characterize the behavior of the network and gain further insight into its dynamics. As described in the Results section, after the learning process converges, the networks tend to operate near a critical point. Thus, it is helpful to define metrics that may behave differently when the networks approach that critical point. One such measure is the time it takes the recurrent network dynamics to reach steady-state—the <italic>convergence time</italic>. Many dynamical systems exhibit a slow-down of the dynamics near critical points, often termed <italic>critical slowing down</italic> [<xref ref-type="bibr" rid="pcbi.1004698.ref038">38</xref>]. Thus, a substantial increase in the convergence time may indicate that the system is close to a critical point.</p>
<p>To gain insight in the present context, we note that near a steady state, the linearized dynamics (in vector notation) are given by <inline-formula id="pcbi.1004698.e008"><alternatives><graphic id="pcbi.1004698.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:mo> </mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. The inverse of the matrix [<italic>I</italic>−<italic>GK</italic>] appears also in the expression for the Jacobian matrix, which determines the objective function. Optimizing the objective function leads to very large eigenvalues in the Jacobian matrix (high-susceptibility), and therefore, the eigenvalues that dominate the dynamics become very small, which manifests as slowing down.</p>
<p>To estimate the convergence time, we defined a criterion for stability of the neuronal activities and measured the time it takes the network to satisfy this criterion. This stability criterion means that for each neuron in the network, the difference in its activity between the current time step and the previous time step is smaller than a predefined small number.</p>
<p>When the network becomes supercritical, it converges onto attractor states, which reflect the underlying connectivity. In the context of orientation tuning, which we study here, a natural measure to quantify this behavior is the population vector [<xref ref-type="bibr" rid="pcbi.1004698.ref039">39</xref>]. Each neuron is associated with a complex number. The magnitude of the number is the activity of this neuron and the phase is set according to the preferred angle or orientation of the neuron (in the case of preferred orientation, the orientation is multiplied by 2, to span the range from 0° to 360°). Given a pattern of activity in the network, these complex numbers are summed to yield a resultant complex number, termed the population vector. When the network response is uniform, the magnitude of the population vector is 0. When the network response peaks at some orientation, the magnitude of the population vector is finite.</p>
</sec>
<sec id="sec006">
<title>Training using natural images</title>
<p>Similar to previous papers concerning training of networks over natural scenes [<xref ref-type="bibr" rid="pcbi.1004698.ref033">33</xref>], we used photos involving forest scenes or single trees and leaves. The photos were converted to grayscale byte value of 0 to 255 and then”cut” into patches of 25-by-25 pixels. Each patch was represented as a vector with 625 components. Using PCA (Principal Component Analysis), the dimensionality of the images was reduced from 625 to 100. The inputs were also whitened by dividing each eigenvector by the square root of the corresponding eigenvalue. These whitened 100-dimensional inputs were used to train a network with 380 output neurons. The results were robust to different manipulations of the inputs. For example, we obtained qualitatively similar results even without dimensionality reduction or whitening, using smaller image patches.</p>
<p>The feed-forward filters were set to be Gabor filters with the same center in the visual field and the same spatial frequency. The size of each Gabor filter was 25-by-25 pixels. The full feed-forward matrix was a product of two matrices: A 380-by-625 matrix containing a Gabor filter in each row, which was multiplied from the right by a 625-by-100 matrix representing the reconstruction after the dimensionality reduction.</p>
</sec>
<sec id="sec007">
<title>Running simulations in practice</title>
<p>Close to the critical point, accurate simulation of the network dynamics requires a long time due to the phenomenon of <italic>critical slowing down</italic>. To explore the characteristics and dynamics of the network as it approached the critical point, we allowed simulations to run for very long periods. Thus, simulations could take up to weeks to complete based on network size and the value of the learning rate.</p>
<p>When the evolving networks approached a critical point, the objective function tended to be very sensitive to changes in the pattern of interactions. In some cases, the objective function could even increase rather than decrease, implying that the learning rate was not small enough. To overcome this problem, we calculated the expected value of the objective function before actually updating the interactions. When an upcoming increase was identified, the learning rate was reduced by a factor of one-half and the process was repeated again.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<p>To establish the credibility of our model, we first identified conditions under which a comparison between analytical and numerical results could be facilitated. This was achieved via a toy model of a visual hypercolumn, which is amenable to analytical solution in the limit of very low contrast. An important insight from this toy model is that in the low contrast limit, optimal information representation is obtained at a critical point of the network dynamics. These results are then verified using numerical simulations of this simple model. Using similar simulation approach, we next show that critical behavior also arises in a more complex setting, when natural images are used as inputs in the training phase.</p>
<sec id="sec009">
<title>Infomax and criticality: Insights from analytical and numerical solution of a toy model</title>
<p>The architecture of the network model is presented in <xref ref-type="fig" rid="pcbi.1004698.g001">Fig 1B</xref>. Each input sample is a point on the plane, with an angle, <italic>θ</italic><sub>0</sub>, representing the orientation of a visual stimulus and amplitude (its distance from the origin), <italic>r</italic>, representing the timulus contrast (<xref ref-type="fig" rid="pcbi.1004698.g001">Fig 1B</xref>). Each point can be represented as (<italic>x</italic><sub>1</sub>,<italic>x</italic><sub>2</sub>) = r(cos<italic>θ</italic><sub>0</sub>,cos<italic>θ</italic><sub>0</sub>). For clarity, we consider periodicity of 360° rather than 180°, which is the relevant symmetry when considering orientations. The angles <italic>θ</italic><sub>0</sub> are distributed uniformly between 0 and 2<italic>π</italic>. The amplitudes <italic>r</italic> are distributed according to a Gaussian distribution with a positive mean 〈<italic>r</italic>〉, representing the mean contrast. By varying the mean value of <italic>r</italic> we study the effect of stimulus statistics on the optimal network connections.</p>
<p>The network represents this two-dimensional input by <italic>M</italic> sigmoidal neurons (<italic>M</italic>≫1) interconnected with recurrent interactions (<italic>K</italic><sub><italic>ij</italic></sub>, <italic>i</italic>,<italic>j</italic> = 1,…,<italic>M</italic>). The feedforward connections (rows of) are chosen to be unit vectors, uniformly distributed over all possible directions, i.e. (<italic>W</italic><sub><italic>i</italic>1</sub>,<italic>W</italic><sub><italic>i</italic>2</sub>) = r(cos<italic>ϕ</italic><sub><italic>i</italic></sub>,cos<italic>ϕ</italic><sub><italic>i</italic></sub>) where <italic>ϕ</italic><sub><italic>i</italic></sub> = 2π<italic>i</italic>/<italic>M</italic>, <italic>i</italic> = 1,…,<italic>M</italic>. Thus, the input to the <italic>i</italic>’th neuron has a cosine tuning function peaked at <italic>ϕ</italic><sub><italic>i</italic></sub> and the network has a ring architecture (<xref ref-type="fig" rid="pcbi.1004698.g001">Fig 1B</xref>). The feedforward connections are fixed throughout the learning. Our goal is to evaluate the matrix of recurrent connections <italic>K</italic> that maximizes the mutual information between the steady state responses of the output neurons and the stimulus. For a given input and connection matrix, the steady-state responses are given by
<disp-formula id="pcbi.1004698.e009">
<alternatives>
<graphic id="pcbi.1004698.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mtext>cos</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mtext>sin </mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where <italic>g</italic> is the logistic function (see <xref ref-type="sec" rid="sec002">Methods</xref>).</p>
<p>The sensitivity matrix, <italic>χ</italic>, is an <italic>M</italic>×2 matrix given by:
<disp-formula id="pcbi.1004698.e010">
<alternatives>
<graphic id="pcbi.1004698.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext>cos</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
<disp-formula id="pcbi.1004698.e011">
<alternatives>
<graphic id="pcbi.1004698.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext>sin</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
Where <inline-formula id="pcbi.1004698.e012"><alternatives><graphic id="pcbi.1004698.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>'</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mtext>cos</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mtext>sin </mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the derivative function of the neuronal transfer function and we have used the expression for <italic>s</italic><sub><italic>i</italic></sub> given in <xref ref-type="disp-formula" rid="pcbi.1004698.e009">Eq (5)</xref>.</p>
<p>To investigate analytically the optimal pattern of recurrent interactions when the typical input contrast is low, namely when 〈<italic>r</italic>〉→0, we assume that the interaction <italic>K</italic><sub><italic>ij</italic></sub> between the <italic>i</italic>’th and <italic>j</italic>’th neurons is an even function of the distance between the neurons on the ring,
<disp-formula id="pcbi.1004698.e013">
<alternatives>
<graphic id="pcbi.1004698.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
When 〈<italic>r</italic>〉 approaches zero, the total external input to each neuron approaches zero. We denote the value of <italic>g</italic>’ at zero input by <italic>γ</italic><sub>0</sub> = <italic>g</italic>’(0). In the case of the logistic function, <italic>γ</italic><sub>0</sub> = 1/4. Since the number of output neurons, <italic>M</italic>, is large, we can take the continuum limit and transform the summations over angles to integrals. For instance, the equation for <italic>χ</italic><sub>i1</sub> can be written as
<disp-formula id="pcbi.1004698.e014">
<alternatives>
<graphic id="pcbi.1004698.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mi>π</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>θ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>′</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mtext>cos</mml:mtext><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula>
and similarly for <italic>χ</italic><sub>i2</sub>. We define the Fourier series of <italic>K</italic> and <italic>χ</italic><sub>1</sub>
<disp-formula id="pcbi.1004698.e015">
<alternatives>
<graphic id="pcbi.1004698.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>∞</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
<disp-formula id="pcbi.1004698.e016">
<alternatives>
<graphic id="pcbi.1004698.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>Σ</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
Fourier transforming <xref ref-type="disp-formula" rid="pcbi.1004698.e014">Eq (9)</xref> yields <inline-formula id="pcbi.1004698.e017"><alternatives><graphic id="pcbi.1004698.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <italic>b</italic><sub><italic>n</italic></sub> = 0, where <italic>k</italic><sub>1</sub> is the first cosine harmonic of the interaction profile, <xref ref-type="disp-formula" rid="pcbi.1004698.e015">Eq (10)</xref>. Thus,
<disp-formula id="pcbi.1004698.e018">
<alternatives>
<graphic id="pcbi.1004698.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e018" xlink:type="simple"/>
<mml:math display="block" id="M18">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mtext>cos</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
and similarly
<disp-formula id="pcbi.1004698.e019">
<alternatives>
<graphic id="pcbi.1004698.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mtext>sin</mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
The 2 X 2 matrix <italic>χ</italic><sup><italic>T</italic></sup><italic>χ</italic> is a diagonal matrix with elements
<disp-formula id="pcbi.1004698.e020">
<alternatives>
<graphic id="pcbi.1004698.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>χ</mml:mo><mml:mtext>T</mml:mtext></mml:msup><mml:mi>χ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>χ</mml:mo><mml:mtext>T</mml:mtext></mml:msup><mml:mi>χ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
Substituting these expressions in <xref ref-type="disp-formula" rid="pcbi.1004698.e003">Eq (3)</xref>, yields
<disp-formula id="pcbi.1004698.e021">
<alternatives>
<graphic id="pcbi.1004698.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:mrow><mml:mi>ε</mml:mi><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:msubsup><mml:mi>γ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula>
<xref ref-type="disp-formula" rid="pcbi.1004698.e021">Eq (15)</xref> implies that as <italic>k</italic><sub>1</sub> approaches the critical value <inline-formula id="pcbi.1004698.e022"><alternatives><graphic id="pcbi.1004698.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msubsup><mml:mo>=</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> 2/<italic>γ</italic><sub>0</sub> the objective function diverges to −∞. This means that the optimal pattern of recurrent interactions has the form
<disp-formula id="pcbi.1004698.e023">
<alternatives>
<graphic id="pcbi.1004698.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e023" xlink:type="simple"/>
<mml:math display="block" id="M23">
<mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>γ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula>
The divergence of the objective function, that is of the sensitivity (or susceptibility) at <inline-formula id="pcbi.1004698.e024"><alternatives><graphic id="pcbi.1004698.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> reflects the fact that at this point the network undergoes a phase-transition into a state of <italic>spontaneous symmetry breaking</italic> [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>]. Formally, this can be illustrated by adding a uniform random component to the input that each neuron receives and examining the network response. As shown in [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>], the network response is very different below and above the transition point. For <inline-formula id="pcbi.1004698.e025"><alternatives><graphic id="pcbi.1004698.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>&lt;2/<italic>γ</italic><sub>0</sub>, the network settles into a homogeneous state with <italic>s</italic><sub><italic>i</italic></sub> = <italic>g</italic>(0). However, for <inline-formula id="pcbi.1004698.e026"><alternatives><graphic id="pcbi.1004698.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>&gt;2/<italic>γ</italic><sub>0</sub>, the network dynamics evolve into an inhomogeneous solution with a typical ''hill'' shape [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>], which is determined by the recurrent connections and can be interpreted as a "hallucination" of an oriented stimulus. Neurons, which are slightly more active due to the random noise, enhance the activity of neurons with similar preferred orientations, which in turn enhance the activity of the initial neurons through feedback. The winning neurons inhibit neurons with more distant preferred orientations, thus creating a "hill"-shaped profile. The location of the peak of this hill is arbitrary and depends on the specific realization of the noise in the input pattern and on the initial conditions of the neuronal activities. This dramatic change in the network behavior implies that near <inline-formula id="pcbi.1004698.e027"><alternatives><graphic id="pcbi.1004698.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> the network is extremely sensitive to small changes in the input. This enhanced sensitivity increases the mutual information between the network response and the stimulus.</p>
<p>In the limit of 〈<italic>r</italic>〉→0 the objective function depends solely on the first harmonics of the interaction profile, leaving open the question of whether the higher order corrections in <italic>r</italic> predict large values of the higher harmonics of the interaction profile. Furthermore, in the analytic derivation we have assumed translational invariance of <italic>K</italic>, which raises the question of whether there are better solutions which break this symmetry of <italic>K</italic>. To address these questions, we simulated the gradient based learning algorithm for the evolution of the interaction matrix (<xref ref-type="sec" rid="sec002">Methods</xref>; [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>]), with no restrictions on the form of the matrix. The network consisted of 2 input neurons and 141 output neurons. The nonlinear squashing function was the logistic function. The feedforward connections to each output neuron were unit vectors uniformly distributed between 0° and 360°, and were fixed throughout the learning. The initial recurrent interaction matrix was set to zero. The angle of each input was drawn from a uniform distribution, while the magnitude was drawn from a Gaussian distribution around a characteristic radius <italic>r</italic> with a standard deviation of 0.1 times the mean.</p>
<p><xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2</xref> shows the results from a simulation with 〈<italic>r</italic>〉 = 0.1, namely when the inputs are relatively weak. As can be seen, the interaction pattern (<xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2A</xref>) is translation invariant; i.e., each neuron has the same pattern of pre and postsynaptic interactions. It is important to note that we do not impose any symmetry on the connections. The resulting translation invariance is a natural result of the statistical symmetry of the inputs to the network. <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2B</xref> shows one row of the interaction matrix (representing the presynaptic connections into a single output neuron). For clarity, the values are multiplied by the number of neurons, <italic>M</italic>. This result is highly congruent with the analytical derivation presented above, <xref ref-type="disp-formula" rid="pcbi.1004698.e023">Eq (16)</xref>, that predicts a pure cosine profile with an amplitude of 8 for the logistic function. <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2C</xref> shows the response of the network as a function of the preferred orientation (PO) of the neurons (solid line) to a vertical input at the typical contrast (<italic>r</italic> = 0.1). The amplification in comparison to the network response without recurrent interactions (dashed line) is clearly seen. Responses to different contrasts are shown in <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2D</xref>.</p>
<fig id="pcbi.1004698.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004698.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Behavior of the simplified hypercolumn model in the limit of low input contrast.</title>
<p>Results of the toy model following gradient-descent learning that minimizes the objective function at a mean contrast of 〈<italic>r</italic>〉 = 0.1. (A) The optimal interaction matrix representing the strength of recurrent connections with gray level value (interaction from neuron <italic>j</italic> onto neuron <italic>i</italic> as grey level of the pixel in the <italic>i’</italic>th row and <italic>j’</italic>th column). (B) The interaction profile for the neuron tuned to 180° (the middle column of the interaction matrix). (C) Network response in presence and absence of recurrent interactions, for an input with contrast of <italic>r</italic> = 0.1. The dashed line is the response of the network without the recurrent interactions and the solid line is the response with them. (D) The network’s response amplification to inputs at different levels of contrast. (E-G) The effect of scaling the recurrent interactions on several metrics of network behavior. (E) Objective function. (F) Convergence time of the recurrent network. (G) Magnitude of the population vector of the network response. PO—preferred orientation.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004698.g002" xlink:type="simple"/>
</fig>
<sec id="sec010">
<title>Effect of scaling the interactions</title>
<p>While running the numerical simulations, we noticed that the basic shape of the interaction profile appeared already at early stages of the training. During the rest of the learning process, the main factor that changed was the scale of the profile until it reached an optimal value. In this sense, although there were <inline-formula id="pcbi.1004698.e028"><alternatives><graphic id="pcbi.1004698.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004698.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> free parameters, most of the learning took place along a single dimension in the parameter-space. Motivated by this observation, we changed the scale of the optimal recurrent interaction matrix and explored the network behavior as a function of the scaling factor (<xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2E–2G</xref>). <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2E</xref> depicts the objective function. The fact that it attains its minimum when the scaling parameter is 1, simply means that the optimal scaling is obtained for the optimal interaction matrix that was obtained from the learning process. This is an indication that the learning process indeed converged. The convergence time of the recurrent network dynamics (<xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2F</xref>; <xref ref-type="sec" rid="sec002">Methods</xref>) increases substantially near a scaling parameter of 1, indicative of critical slowing down.</p>
<p><xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2G</xref> shows that the magnitude of the population vector transitions into relatively large values near a scaling parameter of 1. This reflects the fact that above 1 the network dynamics are dominated by hill-shaped attractor states [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>]. Overall, the behavior of the convergence time and the population vector shows that indeed close to the optimal scaling factor from the learning process, the network experiences a phase transition.</p>
<p>When the mean input contrast during learning is not too low and not too high the recurrent interactions are less crucial for network performance. <xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3</xref> depicts the results from a numerical simulation with 〈<italic>r</italic> 〉 = 0.9, namely with an intermediate level of contrast. The interaction matrix (<xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3A</xref>) resembles the one for 〈<italic>r</italic> 〉 = 0.1, but the amplitude of the interaction profile is lower (~5) compared with the low contrast case (~8) and the profile contains higher harmonics. The effect of the recurrent interactions on the network response is less pronounced too (<xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3C</xref>). <xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3E–3G</xref> depict the network behavior when the recurrent interactions are scaled. The network dynamics converge on shorter time scales (<xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3F</xref>) and the magnitude of the population vector does not show a sharp transition (<xref ref-type="fig" rid="pcbi.1004698.g003">Fig 3G</xref>).</p>
<fig id="pcbi.1004698.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004698.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Behavior of the simplified hypercolumn model for intermediate input contrast.</title>
<p>Results of the toy model following gradient-descent learning that minimizes the objective function at a mean contrast of 〈<italic>r</italic> 〉 = 0.9. The figure is organized similarly to <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2</xref>. (A) Interaction matrix. (B) Interaction profile. (C) Network response with and without recurrent interactions. (D) Response amplification at different contrast levels. (E-G) Objective function (E), convergence time (F) and magnitude of the population vector (G) as a function of the scale of the recurrent interactions. Relative to the case of learning in the domain of low input contrasts, here, recurrent interactions are less crucial for performance. PO—preferred orientation.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004698.g003" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec011">
<title>Training with natural images</title>
<p>We next investigated a more complex network model of a visual hypercolumn (<xref ref-type="fig" rid="pcbi.1004698.g001">Fig 1C</xref>). In this setting, gray-level image patches from natural scenery (see <xref ref-type="sec" rid="sec002">Methods</xref>) were used as inputs to train the network [<xref ref-type="bibr" rid="pcbi.1004698.ref040">40</xref>]. The network consisted in this case of 100 input neurons and 380 output neurons. To study the pattern of recurrent interactions systematically, we manually set the feed-forward filters to be Gabor filters with the same center in the visual field and the same spatial frequency, spanning all orientations. It is worth noting that this overcomplete network can also be used to learn the feed-forward connections themselves [<xref ref-type="bibr" rid="pcbi.1004698.ref036">36</xref>], and indeed, as we established thorough numerical simulations, when trained using natural scenes, the feed-forward filters turn out to be Gabor-like filters. This result is related to the fact that the algorithm for the feed-forward connections is a simple generalization of the infomax ICA algorithm [<xref ref-type="bibr" rid="pcbi.1004698.ref032">32</xref>] from complete to overcomplete representations. Training the infomax ICA algorithm using natural scenes is known to result in Gabor-like filters [<xref ref-type="bibr" rid="pcbi.1004698.ref033">33</xref>].</p>
<p><xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4A</xref> depicts the full matrix of recurrent connections. As can be seen, the matrix is symmetric and the interaction between two neurons depends only on the distance between their preferred orientations. This finding is in line with the behavior of the simple toy model. Again, it is important to note that the interaction matrix was not constrained to be symmetric. Rather, this is a natural outcome of the learning process, reflecting the symmetry in the pattern of feedforward interactions. <xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4B</xref> plots the interaction strength as a function of the distance between the preferred orientations of the pre- and post-synaptic neurons. The emerging profile has a "Mexican hat" shape, with short-range excitation, longer-range inhibition and an oscillatory decay as the distance in preferred orientation increases.</p>
<fig id="pcbi.1004698.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004698.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Behavior of the ecological hypercolumn model after training with natural scenes.</title>
<p>The figure is organized similarly to <xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2</xref>. (A) Interaction matrix. (B) Interaction profile. (C) Network response with and without recurrent interactions to an oriented stimulus (a Gabor filter with similar properties to the preset feedforward filter). (D) Response amplification at different contrast levels. (E-G) Objective function (E), convergence time (F) and magnitude of the population vector (G) as a function of the scale of the recurrent interactions. Notably, the evolved network dynamics when exposed to natural images resembles more closely the behavior of the toy model after training with low contrast stimuli. PO—preferred orientation.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004698.g004" xlink:type="simple"/>
</fig>
<p>To characterize the network behavior after training it with natural images we examined its response to simple oriented stimuli. <xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4C</xref> depicts the steady-state profile of activity in response to a vertically oriented Gabor stimulus (solid line). The spatial frequency of the Gabor stimulus and the width of the Gaussian envelope were identical to those of the Gabor filters in the feedforward connections and the contrast was set to the mean contrast of the training stimuli. For comparison, the dashed line shows the response of the network without recurrent interactions. Clearly, the evolved recurrent interactions amplify and sharpen the response compared to the response without recurrent interactions. <xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4D</xref> shows the network response to the same vertical stimulus for various contrast levels. Notably, the width of the profile is approximately independent of the contrast, and the effect of changing the contrast is mainly multiplicative.</p>
<p><xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4E–4G</xref> show the dependence of various measures for the network behavior (see <xref ref-type="sec" rid="sec002">Methods</xref>) on the scaling factor. <xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4E</xref> shows that even small changes to the scale factor can significantly increase the objective function, resulting in poor information representation. Decreasing the scale factor reduces the amplification provided by the recurrent interactions and consequently reduces the sensitivity of the network to external inputs. Conversely, increasing the scale factor to values above 1 causes the recurrent interactions to become too dominant, and pushes the network into a <italic>pattern formation</italic> regime. In this regime, the network is again less sensitive to external inputs, but this time it is due to the attractor dynamics that govern its behavior. <xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4F</xref> shows the convergence time of the network dynamics. At the optimal point, the convergence time starts to increase to very high values, reflecting critical-slowing down at the transition into attractor-dominated dynamics. The magnitude of the population vector also rises sharply near the optimal point (<xref ref-type="fig" rid="pcbi.1004698.g004">Fig 4G</xref>). Overall, the behavior of the convergence time and the population vector shows that indeed close to the optimal scaling factor from the learning process, the network experiences a phase transition. The behavior of these metrics also resembles their behavior in the low contrast case in the toy model (<xref ref-type="fig" rid="pcbi.1004698.g002">Fig 2F–2G</xref>).</p>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<p>We studied the long-term evolution of recurrent interactions in a model of a sensory neural network and their dependence on the input statistics. We found that under very general conditions, optimal information representation is achieved when the network operates near a critical point in its dynamics.</p>
<sec id="sec013">
<title>A first-principle derivation of the pattern of recurrent interactions among orientation columns</title>
<p>The study focused on a simplified model of visual hypercolumn, a local processing unit in the visual cortex. The feedforward interactions from the input layer to the output layer were manually set such that each neuron in the output layer had a certain preferred orientation. The recurrent interactions among these neurons evolved according to learning rules that maximize the mutual information between the external input to the network and the network's steady-state output. When the inputs to the network during learning were natural images, the evolved profile of interactions had a Mexican-hat shape. The idea that neurons with similar preferred orientations should effectively excite each other and that neurons with distant preferred orientations should effectively inhibit each other has been suggested in the past based on empirical findings, e.g. [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref042">42</xref>], but here it was derived using a first-principle computational approach. This pattern of interactions helps in amplifying the external inputs and in achieving a relatively constant width for the orientation tuning curves, which is consistent with experimental findings on primary visual cortical neurons [<xref ref-type="bibr" rid="pcbi.1004698.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref044">44</xref>].</p>
<p>A learning algorithm for information maximization in recurrent neural networks was also derived in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>]. The major difference from the current work is that here the information is maximized between the external input and the steady-state output, whereas in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] the input and output refer to the patterns of activity in the recurrent network at two consecutive time steps. The approach in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] is aimed at maximizing information retention in the recurrent network, whereas here the focus is on sensory processing and on the representation of the external input. In addition, the neurons in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] are stochastic binary neurons, whereas the neurons here are deterministic and have a smooth nonlinearity. The network model in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] was also trained using natural images as external inputs, leading to Gabor-like feed-forward connections, consistent with the findings in [<xref ref-type="bibr" rid="pcbi.1004698.ref033">33</xref>]. However, the authors do not discuss the structure of the connections <italic>among</italic> the output neurons, so this important aspect cannot be compared with the present work, which focused on recurrent connectivity.</p>
<p>The present model is clearly overly simplified in many aspects as a model of the primary visual cortex. For example, the gradient-based learning rules employed here are likely to be very different from the plasticity mechanisms in the biological system, but the assumption is that they reflect the long-term evolution of the relevant neural system and converge to a similar functional behavior. Despite its simplicity, the model provides a concrete setting for examining the role of recurrent interactions in the context of sensory processing. This leads to general insights that go beyond the context of early visual processing, as we discuss below.</p>
</sec>
<sec id="sec014">
<title>The importance of near-critical recurrent networks</title>
<p>The dynamics of recurrent networks, like the one studied here, can allow the network to hold persistent activity even when the external drive is weak or absent. The network is then said to display attractor dynamics. In the context of memory systems, attractors are used to model associative memory [<xref ref-type="bibr" rid="pcbi.1004698.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref046">46</xref>]. Different attractors correspond to different memory states, and the activity patterns that form the basin of attraction of each attractor correspond to various associations of this memory. In the context of early sensory networks, however, the persistent activity at an attractor may correspond to a hallucination. In addition, the flow from different initial patterns to the attractor implies loss of information and insensitivity to changes in the external inputs, and thus may be undesired in the context of sensory processing. An important result of this study is that the evolved networks naturally tend to operate near a critical point, which can be thought of as the border between normal amplification of inputs and hallucinations. In [<xref ref-type="bibr" rid="pcbi.1004698.ref009">9</xref>], a model of a visual hypercolumn, which is similar to our toy model, was studied analytically. There, the pattern of interactions was assumed to have a cosine profile and it was shown that when the amplitude of the cosine crosses a critical value, the network transitions into an attractor regime. In this regime, the network dynamics evolve into an inhomogeneous solution with a typical ''hill'' shape, which represents a hallucination of an oriented stimulus. Here, the learning algorithm leads the network to operate close to that critical point. Scaling up the resulting pattern of synaptic interactions by a small factor pushes the network into the undesired regime of attractors, namely into hallucinations [<xref ref-type="bibr" rid="pcbi.1004698.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref048">48</xref>].</p>
<p>This tendency to operate near a critical point can be explained intuitively. The task of the network is to maximize the mutual information between input and output, which amounts to maximizing its sensitivity to changes in the external inputs. The network uses the recurrent interactions to amplify the external inputs, but too strong amplification may generate hallucinations. Thus, the learning process should settle at an optimal point, which reflects a compromise between these two factors. An interesting insight comes from comparing the network to physical systems that may experience phase-transitions in their behavior. A universal property of these systems is that their sensitivity to external influences, or in physical terminology their <italic>susceptibility</italic>, is maximized at the transition point [<xref ref-type="bibr" rid="pcbi.1004698.ref049">49</xref>]. Our adaptive sensory recurrent networks evolve to operate near a critical point in order to achieve maximal susceptibility and represent information optimally. It is important to note that neural systems respond to a wide range of inputs and that the target of the learning is to find the pattern of interactions that is optimal on average. Under certain conditions, the recurrent interactions may not contribute much to the representation. However, in many cases, especially if the typical inputs have a narrow distribution or tend to be weak, the optimal pattern of recurrent interactions is expected to be near critical. The dominance of low contrasts in natural images is therefore an important factor in driving the pattern of recurrent interactions to be near critical.</p>
<p>There are several important distinctions to be made when comparing previous research [<xref ref-type="bibr" rid="pcbi.1004698.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref051">51</xref>] on critical brain dynamics with the present study. First, the present work addresses mainly the issues of long-term plasticity and the effect of input statistics, whereas previous modeling works consider mostly networks with random connectivity, which do not adapt to input statistics. Here we demonstrated that near-criticality emerges as a result of directly optimizing a well-defined measure for network performance using a concrete learning algorithm. In addition, an important role is played by the input statistics, and depending on these statistics the network may or may not approach criticality. Moreover, the resulting connectivity matrices are not random and the specific pattern that emerges is crucial for the network performance. We note that in [<xref ref-type="bibr" rid="pcbi.1004698.ref034">34</xref>] the network can adapt to the statistics of external inputs, but there criticality was demonstrated only when the network evolved without external input. Other studies, such as [<xref ref-type="bibr" rid="pcbi.1004698.ref052">52</xref>], model plasticity in recurrent neuronal networks, but not in an ecological sensory context.</p>
<p>Second, here the critical point relates to the transition from normal amplification of external inputs to an attractor regime. At the supercritical regime, the network may present inhomogeneous activity patterns but it is not necessarily driven to saturation. In other words, the supercritical regime does not necessarily correspond to an explosive growth of the activity or to epileptic seizures. In the subcritical regime, the representation is faithful to the input and cannot generate hallucinations, but the activity does not necessarily die out. This should be compared with models based on branching processes, in which the supercritical regime generally refers to runaway activity and the subcritical regime refers to premature termination of activity. In the present model, the network may have a branching parameter of 1 in both the subcritical and supercritical regimes. In this sense, the type of criticality presented by this model can be thought of as a subspace within the space of all networks with branching parameter equal to 1. Furthermore, in contrast to [<xref ref-type="bibr" rid="pcbi.1004698.ref021">21</xref>] and [<xref ref-type="bibr" rid="pcbi.1004698.ref018">18</xref>], the supercritical regime in the present model does not correspond to chaotic behavior.</p>
<p>The issues raised above call for future experimental and theoretical work aimed at elucidating the effect of input statistics on the approach to criticality and at characterizing the type of criticality that emerges. In particular, future modeling work should consider learning algorithms that optimize information representation in spiking and conductance-based neural networks, which have richer dynamics. An interesting approach to take spike times into account is proposed in [<xref ref-type="bibr" rid="pcbi.1004698.ref053">53</xref>] but the proposed algorithm is limited to one-layer feed-forward networks. Incorporating short-term plasticity in these models would also be valuable, because networks with short-term plasticity were demonstrated to exhibit robust critical dynamics [<xref ref-type="bibr" rid="pcbi.1004698.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref046">46</xref>].</p>
</sec>
<sec id="sec015">
<title>Properties of near-critical recurrent networks</title>
<p>An interesting universal phenomenon that occurs when networks approach the critical point is a change in the effective integration times. As demonstrated here, close to the critical point the time it takes the network to settle after the presentation of an input is considerably longer. This phenomenon is termed <italic>critical slowing down</italic>, [<xref ref-type="bibr" rid="pcbi.1004698.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref054">54</xref>] and it may serve as a probe to characterize near-critical networks both in models and in experiments (e.g., by examining the power spectrum or by measuring the decay time after a perturbation). It should be pointed out that there is a trade-off between the information representation and the integration time. Near criticality, the output of the recurrent network is more sensitive to change in the inputs, but it takes more processing time. It is reasonable to assume that the brain also takes the processing time into account and not only the quality of the representation. This factor should drive networks in the brain to operate slightly below the critical point, i.e. in the subcritical regime, than would be predicted based on information representation alone.</p>
<p>Clearly, because the neurons in our network are characterized by their firing rates, the network dynamics are not rich enough to display spatiotemporal patterns of activity like neuronal avalanches, synchronized firing or chaotic behavior. Nevertheless, the rate models can often be translated to more realistic conductance-based neuronal networks, which display similar dynamics [<xref ref-type="bibr" rid="pcbi.1004698.ref055">55</xref>]. In particular, the conductance-based model of a hypercolumn that is investigated in [<xref ref-type="bibr" rid="pcbi.1004698.ref055">55</xref>] exhibits a critical point similar to the one described here, and the network state is neither synchronized nor chaotic in either side of the critical point.</p>
</sec>
<sec id="sec016">
<title>Routes to criticality</title>
<p>In real-life biological settings, the pattern of recurrent interactions in a network can be driven into the supercritical 'pattern formation' regime as a result of several possible mechanisms. One possibility is via direct application of certain drugs that increase the effective synaptic efficacy. Bressloff et al. [<xref ref-type="bibr" rid="pcbi.1004698.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref048">48</xref>] studied the dynamics of a network model of the primary visual cortex. They show that when the network's resting state becomes unstable, the various patterns of activity that spontaneously emerge correspond to known geometric visual hallucinations seen by many observers after taking hallucinogens. They propose that hallucinogens act by scaling the synaptic interactions until instabilities in the network dynamics begin to arise. Our work suggests that due to the network operating not far from the critical point, even a relatively small increase in the scale of the connections may drive it into the supercritical domain.</p>
<p>Another plausible scenario for approaching criticality is through a high degree of plasticity. In numerical simulations of the learning algorithm, an important parameter is the learning rate that controls the step size of the learning dynamics and can be biophysically interpreted as the degree of plasticity [<xref ref-type="bibr" rid="pcbi.1004698.ref056">56</xref>]. Interestingly, in simulations in which the learning rate was too high, the network did not stabilize at the optimal point near the phase transition but instead crossed it due to the large step size, resulting in poor information representation and hallucinatory behavior. This behavior suggests a potential causal relationship between abnormal neural plasticity and neurological or neuropsychiatric phenomena involving hallucinations, such as schizophrenia.</p>
<p>A third route to criticality is through attenuation of the external inputs. When the external inputs to the network are very weak the recurrent interactions at the output layer compensate by further approaching the critical point. This process increases the effective gain of the network but may lead to instabilities in the network dynamics and to false percepts. For instance, such a mechanism may play a role in the generation of hallucinations as a result of sensory deprivation. An interesting example in this context is <italic>tinnitus</italic>, a persistent and debilitating ringing in the ears [<xref ref-type="bibr" rid="pcbi.1004698.ref057">57</xref>]. Tinnitus often appears after damage to the hair cells in the ear, mostly by acoustic trauma or by pharmacological agents, such as Salicylate. It was also proposed that plasticity of the central nervous system may play a role in the etiology of Tinnitus [<xref ref-type="bibr" rid="pcbi.1004698.ref058">58</xref>]. Our model suggests that recurrent networks further along the auditory pathway may try to compensate for the attenuated signals by setting their interactions closer to the critical point. Operating too close to this instability may result in spontaneous activity that is manifested as persistent illusory sounds. The idea that sensory deprivation leads to criticality may also be related to the observation of criticality in slices and cultures [<xref ref-type="bibr" rid="pcbi.1004698.ref002">2</xref>]. A prediction of the present work would be that highly variable external stimulation will result in networks that are non-critical.</p>
<p>It is also interesting to discuss how a network that became supercritical can return to the normal subcritical regime. In principle, the gradient descent learning algorithm should drive the network to the optimal point even when it is supercritical. However, the learning is based on certain continuity assumptions regarding the mapping of input patterns to output patterns, which may be violated in the supercritical attractor regime. In particular, we assume that there is an invertible continuous mapping between input and output with a well-defined Jacobian matrix. Topologically, the output space may become disconnected with different islands corresponding to different attractor states, making the mapping non-invertible and dis-continuous. Under these conditions, the learning algorithm may not be able to optimize information representation and bring the network back to subcritical dynamics. A similar phenomenon might happen in real brains, preventing the intrinsic learning rules from getting the network back to normal healthy dynamics.</p>
</sec>
<sec id="sec017">
<title>Conclusion</title>
<p>Our findings suggest that optimal information representation in recurrent networks is often obtained when the network operates near criticality. This is consistent with a growing body of theoretical and experimental literature relating to near criticality in the brain [<xref ref-type="bibr" rid="pcbi.1004698.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1004698.ref060">60</xref>]. The uniqueness of the present study is in the rigorous approach to the role of long-term plasticity in approaching criticality and we believe that further research should be dedicated to this issue.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004698.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglas</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>KA</given-names></name>. <article-title>Recurrent neuronal circuits in the neocortex</article-title>. <source>Current biology: CB</source>. <year>2007</year>;<volume>17</volume>(<issue>13</issue>):<fpage>R496</fpage>–<lpage>500</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2007.04.024" xlink:type="simple">10.1016/j.cub.2007.04.024</ext-link></comment> <object-id pub-id-type="pmid">17610826</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaneko</surname> <given-names>T</given-names></name>. <article-title>Local connections of excitatory neurons in motor-associated cortical areas of the rat</article-title>. <source>Frontiers in neural circuits</source>. <year>2013</year>;<volume>7</volume>:<fpage>75</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncir.2013.00075" xlink:type="simple">10.3389/fncir.2013.00075</ext-link></comment> <object-id pub-id-type="pmid">23754982</object-id>; PubMed Central PMCID: PMC3664775.</mixed-citation></ref>
<ref id="pcbi.1004698.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hahnloser</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Fee</surname> <given-names>MS</given-names></name>. <article-title>An ultra-sparse code underlies the generation of neural sequences in a songbird</article-title>. <source>Nature</source>. <year>2002</year>;<volume>419</volume>(<issue>6902</issue>):<fpage>65</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature00974" xlink:type="simple">10.1038/nature00974</ext-link></comment> <object-id pub-id-type="pmid">12214232</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>MA</given-names></name>. <article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>36</volume>(<issue>6</issue>):<fpage>1183</fpage>–<lpage>94</lpage>. <object-id pub-id-type="pmid">12495631</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borg-Graham</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Monier</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fregnac</surname> <given-names>Y</given-names></name>. <article-title>Visual input evokes transient and strong shunting inhibition in visual cortical neurons</article-title>. <source>Nature</source>. <year>1998</year>;<volume>393</volume>(<issue>6683</issue>):<fpage>369</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/30735" xlink:type="simple">10.1038/30735</ext-link></comment> <object-id pub-id-type="pmid">9620800</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>. <article-title>Decision making in recurrent neuronal circuits</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>60</volume>(<issue>2</issue>):<fpage>215</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.09.034" xlink:type="simple">10.1016/j.neuron.2008.09.034</ext-link></comment> <object-id pub-id-type="pmid">18957215</object-id>; PubMed Central PMCID: PMC2710297.</mixed-citation></ref>
<ref id="pcbi.1004698.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wong</surname> <given-names>KF</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>. <article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>(<issue>4</issue>):<fpage>1314</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3733-05.2006" xlink:type="simple">10.1523/JNEUROSCI.3733-05.2006</ext-link></comment> <object-id pub-id-type="pmid">16436619</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sadeh</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Mean-field analysis of orientation selectivity in inhibition-dominated networks of spiking neurons</article-title>. <source>SpringerPlus</source>. <year>2014</year>;<volume>3</volume>:<fpage>148</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/2193-1801-3-148" xlink:type="simple">10.1186/2193-1801-3-148</ext-link></comment> <object-id pub-id-type="pmid">24790806</object-id>; PubMed Central PMCID: PMC4003001.</mixed-citation></ref>
<ref id="pcbi.1004698.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ben-Yishai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bar-Or</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Theory of orientation tuning in visual cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1995</year>;<volume>92</volume>(<issue>9</issue>):<fpage>3844</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">7731993</object-id>; PubMed Central PMCID: PMC42058.</mixed-citation></ref>
<ref id="pcbi.1004698.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shushruth</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mangapathy</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ichida</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Bressloff</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Schwabe</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Angelucci</surname> <given-names>A</given-names></name>. <article-title>Strong recurrent networks compute the orientation tuning of surround modulation in the primate primary visual cortex</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>1</issue>):<fpage>308</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3789-11.2012" xlink:type="simple">10.1523/JNEUROSCI.3789-11.2012</ext-link></comment> <object-id pub-id-type="pmid">22219292</object-id>; PubMed Central PMCID: PMC3711470.</mixed-citation></ref>
<ref id="pcbi.1004698.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Renart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>de la Rocha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bartho</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hollender</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Parga</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>The asynchronous state in cortical circuits</article-title>. <source>Science</source>. <year>2010</year>;<volume>327</volume>(<issue>5965</issue>):<fpage>587</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1179850" xlink:type="simple">10.1126/science.1179850</ext-link></comment> <object-id pub-id-type="pmid">20110507</object-id>; PubMed Central PMCID: PMC2861483.</mixed-citation></ref>
<ref id="pcbi.1004698.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>PNAS</source>. <year>1982</year>;<volume>79</volume>(<issue>8</issue>):<fpage>2554</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">6953413</object-id>; PubMed Central PMCID: PMC346238.</mixed-citation></ref>
<ref id="pcbi.1004698.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name>. <article-title>Neurons with graded response have collective computational properties like those of two-state neurons</article-title>. <source>PNAS</source>. <year>1984</year>;<volume>81</volume>(<issue>10</issue>):<fpage>3088</fpage>–<lpage>92</lpage>. <object-id pub-id-type="pmid">6587342</object-id>; PubMed Central PMCID: PMC345226.</mixed-citation></ref>
<ref id="pcbi.1004698.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beggs</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Neuronal avalanches in neocortical circuits</article-title>. <source>J Neurosci</source>. <year>2003</year>;<volume>23</volume>(<issue>35</issue>):<fpage>11167</fpage>–<lpage>77</lpage>. 23/35/11167 [pii]. <object-id pub-id-type="pmid">14657176</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beggs</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Neuronal avalanches are diverse and precise activity patterns that are stable for many hours in cortical slice cultures</article-title>. <source>J Neurosci</source>. <year>2004</year>;<volume>24</volume>(<issue>22</issue>):<fpage>5216</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0540-04.2004" xlink:type="simple">10.1523/JNEUROSCI.0540-04.2004</ext-link></comment> 24/22/5216 [pii]. <object-id pub-id-type="pmid">15175392</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beggs</surname> <given-names>J</given-names></name>. <article-title>The criticality hypothesis: how local cortical networks might optimize information processing</article-title>. <source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>. <year>2008</year>;<volume>366</volume>(<issue>1864</issue>):<fpage>329</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Hobbs</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Beggs</surname> <given-names>JM</given-names></name>. <article-title>A few strong connections: optimizing information retention in neuronal avalanches</article-title>. <source>BMC Neurosci</source>. <year>2010</year>;<volume>11</volume>:<fpage>3</fpage>. 1471-2202-11-3 [pii]<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1471-2202-11-3" xlink:type="simple">10.1186/1471-2202-11-3</ext-link></comment> <object-id pub-id-type="pmid">20053290</object-id>; PubMed Central PMCID: PMC2824798.</mixed-citation></ref>
<ref id="pcbi.1004698.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haldeman</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Beggs</surname> <given-names>J</given-names></name>. <article-title>Critical branching captures activity in living neural networks and maximizes the number of metastable states</article-title>. <source>Physical review letters</source>. <year>2005</year>;<volume>94</volume>(<issue>5</issue>):<fpage>58101</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kinouchi</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Copelli</surname> <given-names>M</given-names></name>. <article-title>Optimal dynamical range of excitable networks at criticality</article-title>. <source>Nature Physics</source>. <year>2006</year>;<volume>2</volume>(<issue>5</issue>):<fpage>348</fpage>–<lpage>51</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bienenstock</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lehmann</surname> <given-names>D</given-names></name>. <article-title>Regulated Criticality in the Brain?</article-title> <source>Advances in Complex Systems</source>. <year>1998</year>;<volume>1</volume>:<fpage>361</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bertschinger</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Natschläger</surname> <given-names>T</given-names></name>. <article-title>Real-time computation at the edge of chaos in recurrent neural networks</article-title>. <source>Neural Computation</source>. <year>2004</year>;<volume>16</volume>(<issue>7</issue>):<fpage>1413</fpage>–<lpage>36</lpage>. <object-id pub-id-type="pmid">15165396</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levina</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Herrmann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Geisel</surname> <given-names>T</given-names></name>. <article-title>Dynamical synapses causing self-organized criticality in neural networks</article-title>. <source>Nature Physics</source>. <year>2007</year>;<volume>3</volume>(<issue>12</issue>):<fpage>857</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petermann</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Thiagarajan</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Lebedev</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Nicolelis</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Chialvo</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Spontaneous cortical activity in awake monkeys composed of neuronal avalanches</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2009</year>;<volume>106</volume>(<issue>37</issue>):<fpage>15921</fpage>–<lpage>6</lpage>. 0904089106 [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0904089106" xlink:type="simple">10.1073/pnas.0904089106</ext-link></comment> <object-id pub-id-type="pmid">19717463</object-id>; PubMed Central PMCID: PMC2732708.</mixed-citation></ref>
<ref id="pcbi.1004698.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shew</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Petermann</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Roy</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Neuronal avalanches imply maximum dynamic range in cortical networks at criticality</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>(<issue>49</issue>):<fpage>15595</fpage>–<lpage>600</lpage>. 29/49/15595 [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3864-09.2009" xlink:type="simple">10.1523/JNEUROSCI.3864-09.2009</ext-link></comment> <object-id pub-id-type="pmid">20007483</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shew</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Clawson</surname> <given-names>WP</given-names></name>, <name name-style="western"><surname>Pobst</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Karimipanah</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Wessel</surname> <given-names>R</given-names></name>. <article-title>Adaptation to sensory input tunes visual cortex to criticality</article-title>. <source>Nat Phys</source>. <year>2015</year>;<volume>11</volume>(<issue>8</issue>):<fpage>659</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nphys3370" xlink:type="simple">10.1038/nphys3370</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1004698.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arviv</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Goldstein</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shriki</surname> <given-names>O</given-names></name>. <article-title>Near-Critical Dynamics in Stimulus-Evoked Activity of the Human Brain and Its Relation to Spontaneous Resting-State Activity</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>(<issue>41</issue>):<fpage>13927</fpage>–<lpage>42</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0477-15.2015" xlink:type="simple">10.1523/JNEUROSCI.0477-15.2015</ext-link></comment> <object-id pub-id-type="pmid">26468194</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Thiagarajan</surname> <given-names>TC</given-names></name>. <article-title>The organizing principles of neuronal avalanches: cell assemblies in the cortex?</article-title> <source>Trends Neurosci</source>. <year>2007</year>;<volume>30</volume>(<issue>3</issue>):<fpage>101</fpage>–<lpage>10</lpage>. S0166-2236(07)00019-7 [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tins.2007.01.005" xlink:type="simple">10.1016/j.tins.2007.01.005</ext-link></comment> <object-id pub-id-type="pmid">17275102</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref028"><label>28</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Harris</surname> <given-names>TE</given-names></name>. <source>The Theory of Branching Processes</source>. <name name-style="western"><surname>al</surname> <given-names>Be</given-names></name>, editor: <collab>Springer</collab>; <year>1963</year>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shriki</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Alstott</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Carver</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Holroyd</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Henson</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>ML</given-names></name>, <etal>et al</etal>. <article-title>Neuronal avalanches in the resting MEG of the human brain</article-title>. <source>The Journal of neuroscience</source>. <year>2013</year>;<volume>33</volume>(<issue>16</issue>):<fpage>7079</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4286-12.2013" xlink:type="simple">10.1523/JNEUROSCI.4286-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23595765</object-id>; PubMed Central PMCID: PMC3665287.</mixed-citation></ref>
<ref id="pcbi.1004698.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palva</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Zhigalov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hirvonen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Korhonen</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Linkenkaer-Hansen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Palva</surname> <given-names>S</given-names></name>. <article-title>Neuronal long-range temporal correlations and avalanche dynamics are correlated with behavioral scaling laws</article-title>. <source>PNAS</source>. <year>2013</year>;<volume>110</volume>(<issue>9</issue>):<fpage>3585</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1216855110" xlink:type="simple">10.1073/pnas.1216855110</ext-link></comment> <object-id pub-id-type="pmid">23401536</object-id>; PubMed Central PMCID: PMC3587255.</mixed-citation></ref>
<ref id="pcbi.1004698.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linsker</surname> <given-names>R</given-names></name>. <article-title>Local Synaptic Learning Rules Suffice to Maximize Mutual Information in a Linear-Network</article-title>. <source>Neural Computation</source>. <year>1992</year>;<volume>4</volume>(<issue>5</issue>):<fpage>691</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1992.4.5.691" xlink:type="simple">10.1162/neco.1992.4.5.691</ext-link></comment> ISI:A1992JT00900007.</mixed-citation></ref>
<ref id="pcbi.1004698.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name>. <article-title>An information-maximization approach to blind separation and blind deconvolution</article-title>. <source>Neural Computation</source>. <year>1995</year>;<volume>7</volume>(<issue>6</issue>):<fpage>1129</fpage>–<lpage>59</lpage>. <object-id pub-id-type="pmid">7584893</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name>. <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision research</source>. <year>1997</year>;<volume>37</volume>(<issue>23</issue>):<fpage>3327</fpage>. <object-id pub-id-type="pmid">9425547</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tanaka</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kaneko</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Aoyagi</surname> <given-names>T</given-names></name>. <article-title>Recurrent infomax generates cell assemblies, neuronal avalanches, and simple cell-like selectivity</article-title>. <source>Neural Comput</source>. <year>2009</year>;<volume>21</volume>(<issue>4</issue>):<fpage>1038</fpage>–<lpage>67</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.03-08-727" xlink:type="simple">10.1162/neco.2008.03-08-727</ext-link></comment> <object-id pub-id-type="pmid">18928369</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayakawa</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kaneko</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Aoyagi</surname> <given-names>T</given-names></name>. <article-title>A biologically plausible learning rule for the Infomax on recurrent neural networks</article-title>. <source>Frontiers in computational neuroscience</source>. <year>2014</year>;<volume>8</volume>:<fpage>143</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2014.00143" xlink:type="simple">10.3389/fncom.2014.00143</ext-link></comment> <object-id pub-id-type="pmid">25505404</object-id>; PubMed Central PMCID: PMC4243565.</mixed-citation></ref>
<ref id="pcbi.1004698.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shriki</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>. <article-title>An information maximization approach to overcomplete and recurrent representations</article-title>. <source>Advances in neural information processing systems</source>. <year>2001</year>:<fpage>612</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref037"><label>37</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Cover</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>JA</given-names></name>. <source>Elements of information theory</source>. <edition>2nd ed</edition>. <name name-style="western"><surname>Hoboken</surname> <given-names>N.J.</given-names></name>: <publisher-name>Wiley-Interscience</publisher-name>; <year>2006</year>. <volume>xxiii</volume>, <fpage>748</fpage> p. p.</mixed-citation></ref>
<ref id="pcbi.1004698.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scheffer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bascompte</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Brock</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Brovkin</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Carpenter</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Dakos</surname> <given-names>V</given-names></name>, <etal>et al</etal>. <article-title>Early-warning signals for critical transitions</article-title>. <source>Nature</source>. <year>2009</year>;<volume>461</volume>(<issue>7260</issue>):<fpage>53</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature08227" xlink:type="simple">10.1038/nature08227</ext-link></comment> <object-id pub-id-type="pmid">19727193</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Georgopoulos</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Lurito</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Petrides</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Massey</surname> <given-names>JT</given-names></name>. <article-title>Mental rotation of the neuronal population vector</article-title>. <source>Science</source>. <year>1989</year>;<volume>243</volume>(<issue>4888</issue>):<fpage>234</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">2911737</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDonald</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Tadmor</surname> <given-names>Y</given-names></name>. <article-title>The perceived contrast of texture patches embedded in natural images</article-title>. <source>Vision Res</source>. <year>2006</year>;<volume>46</volume>(<issue>19</issue>):<fpage>3098</fpage>–<lpage>104</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2006.04.014" xlink:type="simple">10.1016/j.visres.2006.04.014</ext-link></comment> <object-id pub-id-type="pmid">16765406</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kang</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shelley</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Mexican hats and pinwheels in visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2003</year>;<volume>100</volume>(<issue>5</issue>):<fpage>2848</fpage>. <object-id pub-id-type="pmid">12601163</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Somers</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sur</surname> <given-names>M</given-names></name>. <article-title>An emergent model of orientation selectivity in cat visual cortical simple cells</article-title>. <source>Journal of Neuroscience</source>. <year>1995</year>;<volume>15</volume>(<issue>8</issue>):<fpage>5448</fpage>. <object-id pub-id-type="pmid">7643194</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sclar</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>R</given-names></name>. <article-title>Orientation selectivity in the cat's striate cortex is invariant with stimulus contrast</article-title>. <source>Experimental Brain Research</source>. <year>1982</year>;<volume>46</volume>(<issue>3</issue>):<fpage>457</fpage>–<lpage>61</lpage>. <object-id pub-id-type="pmid">7095050</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skottun</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Bradley</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sclar</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ohzawa</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>R</given-names></name>. <article-title>The effects of contrast on visual orientation and spatial frequency discrimination: a comparison of single cells and behavior</article-title>. <source>Journal of Neurophysiology</source>. <year>1987</year>;<volume>57</volume>(<issue>3</issue>):<fpage>773</fpage>. <object-id pub-id-type="pmid">3559701</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bonachela</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>de Franciscis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Torres</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Munoz</surname> <given-names>MA</given-names></name>. <article-title>Self-organization without conservation: are neuronal avalanches generically critical?</article-title> <source>J Stat Mech-Theory E</source>. <year>2010</year>. Artn P02015 <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2010/02/P02015" xlink:type="simple">10.1088/1742-5468/2010/02/P02015</ext-link></comment> ISI:000274936300017.</mixed-citation></ref>
<ref id="pcbi.1004698.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Costa</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Copelli</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kinouchi</surname> <given-names>O</given-names></name>. <article-title>Can dynamical synapses produce true self-organized criticality?</article-title> <source>J Stat Mech-Theory E</source>. <year>2015</year>. Artn P06004 <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2015/06/P06004" xlink:type="simple">10.1088/1742-5468/2015/06/P06004</ext-link></comment> ISI:000357407300006.</mixed-citation></ref>
<ref id="pcbi.1004698.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bressloff</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Golubitsky</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wiener</surname> <given-names>M</given-names></name>. <article-title>Geometric visual hallucinations, Euclidean symmetry and the functional architecture of striate cortex</article-title>. <source>Philosophical Transactions B</source>. <year>2001</year>;<volume>356</volume>(<issue>1407</issue>):<fpage>299</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bressloff</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Golubitsky</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wiener</surname> <given-names>M</given-names></name>. <article-title>What geometric visual hallucinations tell us about the visual cortex</article-title>. <source>Neural Computation</source>. <year>2002</year>;<volume>14</volume>(<issue>3</issue>):<fpage>473</fpage>–<lpage>91</lpage>. <object-id pub-id-type="pmid">11860679</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref049"><label>49</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Stanley</surname> <given-names>HE</given-names></name>. <source>Introduction to Phase Transitions and Critical Phenomena</source>: <publisher-name>Oxford University Press</publisher-name>; <year>1971</year>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Neuronal avalanches and coherence potentials</article-title>. <source>The European Physical Journal-Special Topics</source>. <year>2012</year>;<volume>205</volume>(<issue>1</issue>):<fpage>259</fpage>–<lpage>301</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shew</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Roy</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Information capacity and transmission are maximized in balanced cortical networks with neuronal avalanches</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>(<issue>1</issue>):<fpage>55</fpage>–<lpage>63</lpage>. 31/1/55 [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4637-10.2011" xlink:type="simple">10.1523/JNEUROSCI.4637-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21209189</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pipa</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Triesch</surname> <given-names>J</given-names></name>. <article-title>SORN: a self-organizing recurrent neural network</article-title>. <source>Frontiers in computational neuroscience</source>. <year>2009</year>;<volume>3</volume>:<fpage>23</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.10.023.2009" xlink:type="simple">10.3389/neuro.10.023.2009</ext-link></comment> <object-id pub-id-type="pmid">19893759</object-id>; PubMed Central PMCID: PMC2773171.</mixed-citation></ref>
<ref id="pcbi.1004698.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parra</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bell</surname> <given-names>A</given-names></name>. <article-title>On the maximization of information flow between spiking neurons</article-title>. <source>Neural Computation</source>. <year>2009</year>;<volume>21</volume>(<issue>11</issue>):<fpage>2991</fpage>–<lpage>3009</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2009.04-06-184" xlink:type="simple">10.1162/neco.2009.04-06-184</ext-link></comment> <object-id pub-id-type="pmid">19635018</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Lopes</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Mendes</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Goltsev</surname> <given-names>AV</given-names></name>. <article-title>Critical phenomena and noise-induced phase transitions in neuronal networks</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>. <year>2014</year>;<volume>89</volume>(<issue>1</issue>):<fpage>012701</fpage>. <object-id pub-id-type="pmid">24580251</object-id>.</mixed-citation></ref>
<ref id="pcbi.1004698.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shriki</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Hansel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Rate models for conductance-based cortical neuronal networks</article-title>. <source>Neural Computation</source>. <year>2003</year>;<volume>15</volume>(<issue>8</issue>):<fpage>1809</fpage>–<lpage>41</lpage>. <object-id pub-id-type="pmid">14511514</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van de Leemput</surname> <given-names>IA</given-names></name>, <name name-style="western"><surname>Wichers</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cramer</surname> <given-names>AOJ</given-names></name>, <name name-style="western"><surname>Borsboom</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tuerlinckx</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kuppens</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Critical slowing down as early warning for the onset and termination of depression</article-title>. <source>PNAS</source>. <year>2014</year>;<volume>111</volume>(<issue>1</issue>):<fpage>87</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1312114110" xlink:type="simple">10.1073/pnas.1312114110</ext-link></comment> ISI:000329350700043. <object-id pub-id-type="pmid">24324144</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Henry</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dennis</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schechter</surname> <given-names>M</given-names></name>. <article-title>General review of tinnitus: prevalence, mechanisms, effects, and management</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>2005</year>;<volume>48</volume>(<issue>5</issue>):<fpage>1204</fpage>. <object-id pub-id-type="pmid">16411806</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saunders</surname> <given-names>J</given-names></name>. <article-title>The role of central nervous system plasticity in tinnitus</article-title>. <source>Journal of communication disorders</source>. <year>2007</year>;<volume>40</volume>(<issue>4</issue>):<fpage>313</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">17418230</object-id></mixed-citation></ref>
<ref id="pcbi.1004698.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname> <given-names>CV</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Homeostasis of neuronal avalanches during postnatal cortex development in vitro</article-title>. <source>J Neurosci Methods</source>. <year>2008</year>;<volume>169</volume>(<issue>2</issue>):<fpage>405</fpage>–<lpage>16</lpage>. S0165-0270(07)00533-X [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2007.10.021" xlink:type="simple">10.1016/j.jneumeth.2007.10.021</ext-link></comment> <object-id pub-id-type="pmid">18082894</object-id>; PubMed Central PMCID: PMC2743406.</mixed-citation></ref>
<ref id="pcbi.1004698.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Jirsa</surname> <given-names>VK</given-names></name>. <article-title>Ongoing Cortical Activity at Rest: Criticality, Multistability, and Ghost Attractors</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>10</issue>):<fpage>3366</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/Jneurosci.2523-11.2012" xlink:type="simple">10.1523/Jneurosci.2523-11.2012</ext-link></comment> ISI:000301295300011. <object-id pub-id-type="pmid">22399758</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>