<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">10-PONE-RA-18390R2</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0014413</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Biochemistry/Theory and Simulation</subject><subject>Computational Biology/Metabolic Networks</subject><subject>Computational Biology/Systems Biology</subject><subject>Mathematics/Nonlinear Dynamics</subject><subject>Molecular Biology/Bioinformatics</subject><subject>Physiology/Integrative Physiology</subject></subj-group></article-categories><title-group><article-title>Balancing Robustness against the Dangers of Multiple Attractors in a Hopfield-Type Model of Biological Attractors</article-title><alt-title alt-title-type="running-head">Attractors and Disease</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Anafi</surname><given-names>Ron C.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bates</surname><given-names>Jason H. T.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Division of Sleep Medicine, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Medicine, University of Vermont, Burlington, Vermont, United States of America</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Peccoud</surname><given-names>Jean</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Virginia Tech, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">jason.h.bates@uvm.edu</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: RCA JB. Performed the experiments: RCA. Analyzed the data: RCA JB. Wrote the paper: JB.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2010</year></pub-date><pub-date pub-type="epub"><day>22</day><month>12</month><year>2010</year></pub-date><volume>5</volume><issue>12</issue><elocation-id>e14413</elocation-id><history>
<date date-type="received"><day>27</day><month>4</month><year>2010</year></date>
<date date-type="accepted"><day>6</day><month>12</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Anafi, Bates</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><sec>
<title>Background</title>
<p>Many chronic human diseases are of unclear origin, and persist long beyond any known insult or instigating factor. These diseases may represent a structurally normal biologic network that has become trapped within the basin of an abnormal attractor.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>We used the Hopfield net as the archetypical example of a dynamic biological network. By progressively removing the links of fully connected Hopfield nets, we found that a designated attractor of the nets could still be supported until only slightly more than 1 link per node remained. As the number of links approached this minimum value, the rate of convergence to this attractor from an arbitrary starting state increased dramatically. Furthermore, with more than about twice the minimum of links, the net became increasingly able to support a second attractor.</p>
</sec><sec>
<title>Conclusions/Significance</title>
<p>We speculate that homeostatic biological networks may have evolved to assume a degree of connectivity that balances robustness and agility against the dangers of becoming trapped in an abnormal attractor.</p>
</sec></abstract><funding-group><funding-statement>The authors acknowledge the financial support of an American Sleep Medicine Physician Scientist grant and the NIH (NCRR COBRE RR15557 and HL87788). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="7"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Biological control networks share many formal similarities with artificial neural networks <xref ref-type="bibr" rid="pone.0014413-Detours1">[1]</xref>, <xref ref-type="bibr" rid="pone.0014413-Bray1">[2]</xref>, <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref>, <xref ref-type="bibr" rid="pone.0014413-Ribeiro1">[4]</xref>, <xref ref-type="bibr" rid="pone.0014413-Segel1">[5]</xref>. In particular, the Hopfield net is a recurrent type of neural network with a dynamic state defined at any instant by the set of output levels at each of its nodes This state moves around on a multi-dimensional energy landscape having one or more local minima that act as attractors for states located nearby. Through appropriate adjustment of the weights of the links between the nodes (the analog of synaptic strengths between real neurons), the Hopfield net can differentiate between classes of initial state based on the particular attractors they converge toward <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>. This makes the Hopfield net suited for performing associative or content addressable memory tasks. Real neuronal networks actually appear to have more limited connectivity, but small world Hopfield nets can also have multiple attractors <xref ref-type="bibr" rid="pone.0014413-Oshima1">[7]</xref>, <xref ref-type="bibr" rid="pone.0014413-BarYam1">[8]</xref>, <xref ref-type="bibr" rid="pone.0014413-Stauffer1">[9]</xref>, <xref ref-type="bibr" rid="pone.0014413-PerezCastillo1">[10]</xref>. The nonlinear summing junctions and variable link weights of the Hopfield net thus embody what many consider to be the essential information-processing elements of networks of real biological neurons. We are concerned here, however, with the relevance of the Hopfield net for non-neuronal biological networks, such as those pertaining to metabolism or gene transcription, and which have also been shown to have the ubiquitous small world topology <xref ref-type="bibr" rid="pone.0014413-Barabasi1">[11]</xref>, <xref ref-type="bibr" rid="pone.0014413-Ravasz1">[12]</xref>.</p>
<p>Important for the modeling of general biological networks is the fact that the functional attributes of the Hopfield net are not contingent upon the nonlinear characteristics of the nodes being step functions <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>. In fact, any suitably saturating nonlinearity will do. In particular that small-world networks based on the Hopfield architecture can have multiple attractors when their nodal nonlinearities conform to the Michaelis-Menten equation frequently encountered in biochemical reaction kinetics <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref>. Like biological networks, Hopfield nets contain numerous excitatory links. Thus, any real world implementation of these networks must consume energy, which is an essential requirement for all biological systems in order that they maintain a state far from thermodynamic equilibrium <xref ref-type="bibr" rid="pone.0014413-Macklem1">[14]</xref>, <xref ref-type="bibr" rid="pone.0014413-Prigogine1">[15]</xref>. Hopfield nets thus share some key operational characteristics in common with biological systems. Furthermore, in contrast to simple analogue control systems that create directed restoring forces designed to return a system to a pre-programmed set point, Hopfield nets exhibit attractor dynamics while at the same time reflecting the complexity of biological systems.</p>
<p>Here, however, we encounter an intriguing dichotomy. When using a Hopfield net in its classic application related to content addressable memory tasks, a key design goal is to maximize the number of distinct attractors in the net's energy landscape, while keeping their basins of attraction as deep as possible. This combination allows optimal discrimination among distinct attractors and thereby maximizes the number of distinct entities that the net can “remember” reliably <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>. By contrast, one of the fundamental requirements for living systems is to be able to maintain homeostasis in the face of varied and ongoing environmental inputs, often of a noxious variety. Continued health depends on the system's ability to mount an appropriate response to such inputs and, subsequently, to return toward a state of normality regardless of what regions of the energy landscape its state had to visit in the meantime. A functional biochemical interaction network would thus seem to be best served by an energy landscape consisting of a single large basin of attraction that funnels all aberrant states toward a single attractor corresponding to the “normal state” of the network. The alternative (i.e. having more than one attractor) would seem to pose the risk of having a biochemically normal network become functionally entrapped in a “pathological attractor”, should it receive the right stimulus.</p>
<p>We thus face two possibilities for biological networks. One is that multiple attractors do exist for such networks, in which case we have to deal with the possibility of entrapment in a non-normal attractor <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref>, <xref ref-type="bibr" rid="pone.0014413-Segel1">[5]</xref>. It is not clear whether or not this actually happens in living systems, but if it does it might explain the existence of some of the many chronic diseases currently labeled as “idiopathic” <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref> in which the body seems to operate in an abnormal fashion for no obvious reason. In fact, the theory of networks as applied to the immune system is already well developed <xref ref-type="bibr" rid="pone.0014413-Detours1">[1]</xref>, and a multiple-attractor Hopfield-type theory has been invoked to explain the effects of vaccination on immunological status <xref ref-type="bibr" rid="pone.0014413-Segel1">[5]</xref>. In a similar vein, Kauffman has long posited that the various cellular phenotypes found in the body correspond to attractors in the landscape defined by the network of gene interactions <xref ref-type="bibr" rid="pone.0014413-Ribeiro1">[4]</xref>, <xref ref-type="bibr" rid="pone.0014413-Kauffman1">[16]</xref> and that, given sufficiently large perturbations, cells can be moved so dramatically from their normal attractor that cell type itself can be changed <xref ref-type="bibr" rid="pone.0014413-Sul1">[17]</xref>.</p>
<p>The other possibility for networks in living systems is that they are dominated by single attractors, in which case we have to ask how this could be. Given that multiple attractors can potentially exist in large networks governed by the Michaelis-Menten nonlinearity <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref>, the question arises as to what structural constraints must be in place to ensure only one attractor. It is this question that we attempt to probe herein. We present evidence that there is a critical degree of network connectivity beyond which multiple attractors can be supported, and suggest that the connectivity of real biological networks may have evolved to balance the dangers of multiple attractors against the need for agility and robustness.</p>
</sec><sec id="s2">
<title>Results</title>
<p>We first investigated how the existence of a single attractor in a Hopfield-type network is influenced by its connectivity. Following the methods of Hopfield, <xref ref-type="bibr" rid="pone.0014413-Detours1">[1]</xref> we began with several fully connected networks with <italic>N</italic> equal to 50, 100, 200, or 400 nodes. Each network was constructed so as to have only a single designated attractor. We then randomly eliminated inter-nodal connections, each time checking to see if the designated attractor remained intact. We checked for convergence to the designated attractor from 100 different, randomly chosen initial states. The net was iterated 500 times from each initial state or until it converged to either a steady state or a limit cycle up to period 4. (In eliminating individual links, the symmetry of the initially fully connected net was lost along with the Hopfield structure that guarantees the existence of only fixed-point attractors, thereby allowing for the possibility of limit cycles). If the net converged toward the designated attractor for all initial conditions, the links were permanently eliminated. Otherwise they were reinstated and the elimination of a different set of links was assessed.</p>
<p><xref ref-type="fig" rid="pone-0014413-g001">Figure 1</xref> shows examples of fully pruned networks that retained the ability to converge to their respective designated attractors. These final configurations show some degree of variation, but in terms of overall structure they share strong similarities. In particular, the network configurations shown in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref> are very sparse with few circular pathways. Indeed, while a network with <italic>N</italic> nodes starts with <italic>N</italic><sup>2</sup> connection, we were able to reduce this number to only slightly more than <italic>N</italic> while retaining the designated attractor. Most of the nodes thus end up receiving very few connections, ranging from 1 to 7. To characterize this connectivity more fully, we pruned 10 different 200-node networks and found that the final network configurations had between 201 and 207 connections in total. Furthermore, the frequency distribution of nodes as a function of the number of connections decreased monotonically (<xref ref-type="fig" rid="pone-0014413-g002">Fig. 2</xref>). This is reminiscent, both in shape and magnitude, of the small world connectivity distributions that have been widely reported for metabolic and genetic networks <xref ref-type="bibr" rid="pone.0014413-Ravasz1">[12]</xref>, <xref ref-type="bibr" rid="pone.0014413-Paris1">[18]</xref>, <xref ref-type="bibr" rid="pone.0014413-Li1">[19]</xref>.</p>
<fig id="pone-0014413-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014413.g001</object-id><label>Figure 1</label><caption>
<title>The final configurations (nodes and their directed interconnections) of randomly generated Hopfield nets having 200 (top), 100 (middle) and 50 (bottom) nodes.</title>
<p>These nets began fully connected with their link weights chosen to define a single attractor (the designated attractor). Links were removed until the nets were no longer able to support their designated attractors. The configurations shown are those with the fewest connections that can support each attractor.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.g001" xlink:type="simple"/></fig><fig id="pone-0014413-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014413.g002</object-id><label>Figure 2</label><caption>
<title>Histogram showing frequency (the number of nodes having a given number of links both arriving and leaving) versus number of links for a fully pruned 200-node net (average of 10 independent runs).</title>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.g002" xlink:type="simple"/></fig>
<p>By design, the final network configurations shown in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref> are extremely fragile in the sense that elimination of even one more link will destroy the designated attractor. In contrast, random elimination of 95% of the original full set of links usually left the designated attractor intact. This illustrates a powerful tradeoff between parsimony and robustness. The cost of parsimony is more than just fragility, however, as there is also a tradeoff against the speed with which the network can respond to external perturbations <xref ref-type="bibr" rid="pone.0014413-Oshima1">[7]</xref>. As the links were pruned from the network, the average number of iterations they required to converge to the designated attractor from a random starting state increased, rising dramatically as the number of links neared the minimum value; <xref ref-type="fig" rid="pone-0014413-g003">Fig. 3</xref> shows that the number of iterations increases sharply as the average number of links per node drops below about 3. The rate of convergence was also found to scale with the natural logarithm of the network size (<italic>N</italic>). Thus, when the number of iterations required for convergence is normalized by ln(<italic>N</italic>) and plotted against the mean number of links per node, a universal curve emerges (<xref ref-type="fig" rid="pone-0014413-g003">Fig. 3</xref>). With this empirical scaling law we can extrapolate our result to networks of arbitrary size.</p>
<fig id="pone-0014413-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014413.g003</object-id><label>Figure 3</label><caption>
<title>Number of iterations of the Hopfield net required to achieve convergence to the designated attractor from an arbitrary starting state as a function of the number of links per node in the net, for nets of <italic>N</italic> = 50, 100, 200 and 400 nodes.</title>
<p>The vertical axis has been normalized by ln(<italic>N</italic>).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.g003" xlink:type="simple"/></fig>
<p>We also evaluated how changes in network connectivity impacted the ability of the network to support a second attractor, and identified another tradeoff that may have important implications for chronic disease. This relates to the ability of the network to support a second attractor. Although we set up our networks so that each had only a single designated attractor from the outset, a fully connected Hopfield net can support multiple attractors if its link weights are chosen appropriately <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>, <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>. Indeed, the maximum storage capacity of a fully connected <italic>N</italic>-node Hopfield net is in the order of <italic>N</italic>/ln(<italic>N</italic>) <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>. On the other hand, the fragile networks shown in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref> are unable to sustain any more than their single designated attractors. Therefore, somewhere between the fully connected condition and the sparse connectivities illustrated in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref> is the point where these nets are able to support a second attractor.</p>
<p>We searched for the second attractor point by adding several thousand links back to individual examples of fully pruned networks (such as those shown in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref>), with the weights of these new links adjusted so that the network supported both the original designated attractor and a second designated attractor that was orthogonal to the first. We then randomly removed these new links without touching the minimal set of links previously found necessary to support the first attractor. At each step in this process, the network was launched from 200 random initial configurations, all of which were required to converge to one or other of the two designated attractors before the links were permanently deleted. As the new links were pruned, the fraction of the runs that converged to the second attractor decreased (<xref ref-type="fig" rid="pone-0014413-g004">Fig. 4</xref>). These results also scaled with network size so that, regardless of <italic>N</italic>, the chance of convergence to the second attractor became extremely small when the network was reduced to approximately 3<italic>N</italic> connections. When fewer than about 2 connections per node remained, the second designated attractor was no longer supported as a fixed point of the system. There thus appears to be a range of networks connectivities between 1 to 2 connections per node that can support a single designated attractor but not a second one. This degree of sparsity, however, comes at the cost of both network fragility and speed, as <xref ref-type="fig" rid="pone-0014413-g003">Fig. 3</xref> indicates a sharp decline in convergence speed as connectivity falls below 3 connections per node.</p>
<fig id="pone-0014413-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014413.g004</object-id><label>Figure 4</label><caption>
<title>Fraction of times that networks converged to a second orthogonal attractor versus the number of links per node in the network, for nets of <italic>N</italic> = 50, 100, 200 and 400 nodes.</title>
<p>The minimal set of links previously determined to support the first designated attractor in each net were not affected during the link pruning process.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.g004" xlink:type="simple"/></fig></sec><sec id="s3">
<title>Discussion</title>
<p>Biological networks are sparse, each agent communicating directly with only a very few of its possible counterparts <xref ref-type="bibr" rid="pone.0014413-Ravasz1">[12]</xref>, <xref ref-type="bibr" rid="pone.0014413-Paris1">[18]</xref>, <xref ref-type="bibr" rid="pone.0014413-Li1">[19]</xref>. Our minimal networks (<xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref>) are also sparse, and have connectivity distributions (e.g. <xref ref-type="fig" rid="pone-0014413-g002">Fig. 2</xref>) that decrease monotonically, reminiscent of a number of biological networks <xref ref-type="bibr" rid="pone.0014413-Ravasz1">[12]</xref>. Our results thus suggest that a sparse small-world network is suited to operating within a dynamic basic of attraction. This would allow the network to always return toward normality following the continual and varied perturbations it receives from the environment. These networks thus accomplish homeostatic control in a manner that resembles true biological systems more closely than do <italic>ad hoc</italic> control models based on a pre-programmed restoring force. One the other hand, the sparseness of these networks obviously mitigates against robustness to damage. The minimal networks shown in <xref ref-type="fig" rid="pone-0014413-g001">Fig. 1</xref> are fragile to the extent that elimination of a single link will render each of them unable to support their designated attractor. This would seem to be a precarious position to be in from the point of view of survival. Biologic networks would do well to have at least some redundancy built into their structures by having more than the minimal set of links required to support the dynamic attractor corresponding to health; one can imagine that minimally connected networks would not have fared well in the contest for natural selection. Indeed, the actual degree of sparseness seen in naturally occurring networks has been suggested to result from evolutionary forces construing to produce a balance between robustness and parsimony <xref ref-type="bibr" rid="pone.0014413-Leclerc1">[20]</xref>.</p>
<p>We have identified in the present study, however, two other aspects of sparseness that have opposing advantages, and which we speculate have to be balanced in some way by biological networks. One of the tradeoffs we found is illustrated in <xref ref-type="fig" rid="pone-0014413-g003">Fig. 3</xref>, which shows that a higher density of links enables a network to return more rapidly toward its attractor state following a perturbation. This obviously bodes well for the ongoing maintenance of homeostasis, and so might be considered another factor giving survival advantage to an increase in the link density of a biologic network. On the other hand, as the link density increases above the minimum level required to maintain a given attractor state, there comes a point at which it is able to support a second attractor (<xref ref-type="fig" rid="pone-0014413-g004">Fig. 4</xref>). The requirement that a biological network be both robust and agile may thus require a degree of connectivity that supports the existence of aberrant or pathologic attractors. In such a situation, an inopportune interaction with the environment could potentially drive the network into the clutches of an abnormal attractor.</p>
<p>Of course, the conclusions drawn in this study are based on an idealized model that is highly simplified relative to real biological systems. We have assumed, for example, that homeostasis is characterized by a single “normal” attractor, and that all other attractors are pathologic in some way. It is likely that normality in a real biological network is defined by a cluster of attractors that allow for flexibility in dealing with different environmental conditions or developmental stages. If such attractors are localized in some sense, then a pathologic attractor could likely be defined by its distance away from the normal cluster. Furthermore, in probing for the existence of multiple network attractors, we experimented with random environmental perturbations (i.e. initial states) drawn from a uniform probability distribution. In reality, the perturbations impinging on an organism are more likely to follow a probability distribution having some central tendency determined by the particular environment that the organism lives in. Such a biological network could exist comfortably with an aberrant attractor if the vast majority of perturbations it is likely to experience remain within the neighborhood of the normal attractor. Finally, the behavior of the nodes in our networks was characterized by step-functions, as in the classic Hopfield. Such nets are straightforward to set up, and may even be amenable to analytical investigation <xref ref-type="bibr" rid="pone.0014413-Derrida1">[21]</xref>. Of course, actual metabolic or genetic networks almost certainly involve more complicated nodal decision functions, the Michaelis-Menten equation perhaps being the simplest possibility <xref ref-type="bibr" rid="pone.0014413-Bates1">[3]</xref>, so our networks are not linked to any particular biological system but rather are designed to embody the essential features which we believe ought to be found in any biological network. These important details might allow the “sweet spot” for network connectivity to be somewhat larger than <xref ref-type="fig" rid="pone-0014413-g004">Fig. 4</xref> implies. These caveats, however, do not change the overall message of our study, which is that the density of biological network links may be an important evolutionary design feature that balances speed and flexibility against stability.</p>
<p>We thus speculate that functional entrapment of a structurally normal biological network in an abnormal attractor might underlie the pathogenesis of some chronic disease states. We do not yet know which, if any, real diseases result from this type of process. However, if our speculation is true then it has certain important and sobering implications. First, while there would be clear functional evidence of disease when a biologic network succumbs to an abnormal attractor, the structure of the network and its individual components would remain completely normal. Furthermore, the instigating factor that pushed the network out of its normal basin of attraction might be long gone by the time the disease is investigated, contributing to the mystery surrounding its nature and origins. Trying to treat a disease of this nature might also be problematic, as it would require applying just the right combination of perturbations to push the network back into its normal attractor. One approach to achieving this might be to apply large random perturbations that, in analogy with the numerical technique known as simulated annealing <xref ref-type="bibr" rid="pone.0014413-Cavalcante1">[22]</xref>, could cause the system to eventually find its way back to normality by chance. In any case, there remains much to be done to establish the validity of this theory, which will likely require an improved understanding of the signaling and/or metabolic pathways involved in candidate chronic diseases. One such disease might be idiopathic pulmonary fibrosis, which manifests as the inappropriate progression of processes in the lung that are normally only seen transiently in the repair of tissue injury <xref ref-type="bibr" rid="pone.0014413-Agostini1">[23]</xref>. Chronic insomnia also shares features with this disease model. Insomnia is often precipitated by an acute event but may persist for years after the resolution of the inciting stressor <xref ref-type="bibr" rid="pone.0014413-Perlis1">[24]</xref>. Indeed one of the most effective treatments, sleep restriction therapy, is a controlled form of partial sleep deprivation <xref ref-type="bibr" rid="pone.0014413-Morin1">[25]</xref> and may be viewed as an attempt to provide a sufficiently large perturbation in sleep-wake dynamics so as to move the patient back into the basin of attraction corresponding to the normal state. Certain types of autoimmune disease and cancer might also be usefully viewed from the perspective of entrapment in an aberrant attractor. In any case, we believe this may be a direction worth pursuing, in view of the number of chronic diseases that remain recalcitrant to understanding and treatment.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>The model development and computations described below were performed using Mathematica™ (Wolfram Research Inc., Champaign, IL).</p>
<p>The Hopfield net is a recurrent type of artificial neural network consisting of an array of nodes, each of which links directly to every other node, and possibly also to itself <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>, <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>. The nodes are nonlinear summing junctions that receive input from all other nodes, with each input being weighted by a strength associated with the corresponding incoming link. The links are symmetric in the sense that the link strength from node <italic>a</italic> to node <italic>b</italic> is the same from <italic>b</italic> to <italic>a</italic>. Also, these links may be positive (excitatory) or negative (inhibitory). Each node has a value that marks it as is either quiescent (value  = −1) or active (value  = 1) based on whether the sum of the weighted inputs the node receives from the other nodes exceeds a certain threshold (taken to be zero in the present case). The network is recursively iterated by multiplying the value of each node by the strengths of its links to the other nodes in order to create inputs to these other nodes at the next time step. The state of a Hopfield net, defined by the set of values of each of its nodes, defines an energy landscape having one or more local minima. As the net is iterated, its state will converge from a given starting point toward a stable attractor that sits at the bottom of the basin of attraction in which the initial state is located <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>, <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>. In general, the energy landscape of a Hopfield net contains numerous attractors that each act as collection points for states located nearby. Importantly, the locations of the attractors in the energy landscape are determined by the link strengths between the nodes, and these strengths can be chosen to place the attractors at desired locations. The Hopfield net can thus be used to differentiate between classes of initial state on the basis of the particular attractors the various states converge toward. This allows the Hopfield net to function as an content addressable memory device in which the different attractors may correspond to particular objects of interest <xref ref-type="bibr" rid="pone.0014413-Haykin1">[6]</xref>.</p>
<p>We began with a fully connected Hopfield networks with <italic>N</italic> equal to 50, 100, 200 or 400 nodes. Each node had a value of either −1 or 1 depending on whether its inputs summed to &lt;0 or ≥0, respectively. The weights of the links were assigned according to the algorithm described by Hopfield <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref> so that there was only a single attractor state, which we call the designated attractor. The designated attractor of a network was specified as follows. A <italic>N</italic>-dimensional vector <bold>s</bold> was generated by randomly assigning to each of its component, <italic>s<sub>i</sub></italic>, a value of −1 or 1. The link strengths of the connectivity matrix <bold>T</bold> were then chosen to make this vector the single designated attractor of the network, following Hopfield <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>, by taking <bold>T</bold> to be the dyad product of <bold>s</bold> with itself. That is,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.e001" xlink:type="simple"/><label>(1)</label></disp-formula></p>
<p>This causes <bold>T</bold> to have a single non-zero eigenvalue associated with the eigenvector <bold>s</bold>. Furthermore, for any vector <bold>x</bold>, the inner product <bold>T⋅x</bold> is either the null vector or a vector in the direction of <bold>s</bold>. (Note that the complement of <bold>T</bold> is also an attractor of the network, but we will focus here only on <bold>T</bold> itself, as there is no guarantee that its complement in a real biological system would be physically or physiologically reachable.)</p>
<p>The networks were iterated as follows. Starting from a random initial state vector <bold>x[</bold>0<bold>]</bold>, the state of the system at time step <italic>n</italic>, denoted by <bold>x[</bold><italic>n</italic><bold>]</bold>, was generated, again following Hopfield <xref ref-type="bibr" rid="pone.0014413-Hopfield1">[13]</xref>, as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.e002" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>The system was iterated 500 times or until it converged to a fixed point. For networks that had been pruned and thereby lost their initial symmetry, we also evaluated for convergence to a stable limit cycle of period 4 or below. This process was repeated for each of 200 randomly generated <bold>x[</bold>0<bold>]</bold>, and the existence of the designated attractor was taken as confirmed if the net converged to this attractor for all initial conditions. We also recorded the average number of iterations required for the system to converge to the designated attractor. We then removed the vast majority of connection so that on average there remained only 10 connections per node. Connections were removed by setting the corresponding <italic>T<sub>ij</sub></italic> values to 0, and networks were re-tested for the persistence of the designated attractor in the reduced configuration. Invariably, this sharp reduction in network size did not impact the continued existence of the single attractor state. We then randomly removed one connection at a time. At each step in this removal process the network was probed, starting from 200 random initial states, for the continued existence and global stability of its designated attractor. If one or more of the initial states failed to converge to the designated attractor at any step, the connections that had been removed at the previous step were reinstated and a different set of random connections was removed. The configuration of the network during the pruning process was saved periodically for later evaluation. The connectivity matrix describing the minimal set of connections necessary to preserve the functioning of the network was denoted <bold>T<sup>*</sup></bold>. <xref ref-type="fig" rid="pone-0014413-g001">Figure 1</xref> demonstrates a plot of representative examples of the T* networks that emerged from the process using different sized starting networks. This process was then repeated for 10, 200 node networks each with a distinct randomly chosen designated attractor. <xref ref-type="fig" rid="pone-0014413-g002">Figure 2</xref> demonstrates the a histogram of network connectivity (shown as mean +/− Standard Error).</p>
<p>In order to test the ability of the network to support a second attractor, a state vector <bold>r</bold> was randomly generated subject to the constraint that it be orthogonal to <bold>s,</bold> such that <bold>r⋅s = 0</bold>. Connections were added to <bold>T<sup>*</sup></bold> so that <bold>s</bold> and <bold>r</bold> became attractors for the network with a combined basin of attraction spanning the whole domain. The new connectivity matrix U was constructed through a modification of Hopfield's original formulation as follows: <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.e003" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.e004" xlink:type="simple"/></disp-formula></p>
<p>Thus the connectivity matrix <bold>U</bold> differed from the original Hopfield formulation for a network with attractors r and s, only at the approximately <italic>N</italic> of the <italic>N</italic> squared connections inherited from <bold>T<sup>*</sup></bold>.</p>
<p>The fully connected network was tested with 1000 randomly generated initial conditions to ensure that the network would eventually converge to one of the two designated attractors. The connections that had been added to the skeleton of <bold>T<sup>*</sup></bold> were then randomly pruned. We initially removed the vast majority of connection so that, on average, only 15 connections per node remained by setting the remaining <italic>U<sub>ij</sub></italic> values to 0. Individual connections were then randomly selected one connection at a time for sequential deletion. At each step, we tested to ensure that both <bold>s</bold> and <bold>r</bold> remained fixed points of the network, and we by launched it from 200 randomly generated initial configurations to ensure that their combined basins of attraction spanned the configuration space. All starting configurations were required to converge to one of the designated attractors before the links were permanently deleted. Both the average number of iterations required for the network to converge and the fraction of initial conditions that converged to each of the two designated attractors was tabulated for each configuration.</p>
<p>Mathematica™ codes for performing the above calculations are included in the supporting information (<xref ref-type="supplementary-material" rid="pone.0014413.s002">Appendixes S2</xref> and <xref ref-type="supplementary-material" rid="pone.0014413.s003">S3</xref>). The codes are explained in <xref ref-type="supplementary-material" rid="pone.0014413.s001">Appendix S1</xref>.</p>
</sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0014413.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.s001" xlink:type="simple"><label>Appendix S1</label><caption>
<p>(0.02 MB DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pone.0014413.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.s002" xlink:type="simple"><label>Appendix S2</label><caption>
<p>Network Pruning Mathematica code</p>
<p>(0.11 MB DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pone.0014413.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0014413.s003" xlink:type="simple"><label>Appendix S3</label><caption>
<p>Dual attractor network Mathematica code</p>
<p>(0.09 MB PDF)</p>
</caption></supplementary-material>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0014413-Detours1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Detours</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Sulzer</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Perelson</surname><given-names>AS</given-names></name>
</person-group>             <year>1996</year>             <article-title>Size and connectivity of the idiotypic network are independent of the discreteness of the affinity distribution.</article-title>             <source>J Theor Biol</source>             <volume>183</volume>             <fpage>409</fpage>             <lpage>416</lpage>          </element-citation></ref>
<ref id="pone.0014413-Bray1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bray</surname><given-names>D</given-names></name>
</person-group>             <year>2003</year>             <article-title>Molecular networks: the top-down view.</article-title>             <source>Science</source>             <volume>301</volume>             <fpage>1864</fpage>             <lpage>1865</lpage>          </element-citation></ref>
<ref id="pone.0014413-Bates1"><label>3</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bates</surname><given-names>JHT</given-names></name>
</person-group>             <article-title>Nonlinear network theory of complex disease.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Bar-Yam</surname><given-names>Y</given-names></name>
</person-group>             <publisher-loc>Boston, MA</publisher-loc>             <publisher-name>New England Complex Systems Institute</publisher-name>             <comment>2006;</comment> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">28</size>           </element-citation></ref>
<ref id="pone.0014413-Ribeiro1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ribeiro</surname><given-names>AS</given-names></name>
<name name-style="western"><surname>Kauffman</surname><given-names>SA</given-names></name>
</person-group>             <year>2007</year>             <article-title>Noisy attractors and ergodic sets in models of gene regulatory networks.</article-title>             <source>J Theor Biol</source>             <volume>247</volume>             <fpage>743</fpage>             <lpage>755</lpage>          </element-citation></ref>
<ref id="pone.0014413-Segel1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Segel</surname><given-names>LA</given-names></name>
</person-group>             <year>1998</year>             <article-title>Multiple attractors in immunology: theory and experiment.</article-title>             <source>Biophys Chem</source>             <volume>72</volume>             <fpage>223</fpage>             <lpage>230</lpage>          </element-citation></ref>
<ref id="pone.0014413-Haykin1"><label>6</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haykin</surname><given-names>S</given-names></name>
</person-group>             <year>2009</year>             <comment>Neural networks and Learning Machines (3rd Edition): Pearson Education, Upper Saddle River, NJ</comment>          </element-citation></ref>
<ref id="pone.0014413-Oshima1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Oshima</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Odagaki</surname><given-names>T</given-names></name>
</person-group>             <year>2007</year>             <article-title>Storage capacity and retrieval time of small-world neural networks.</article-title>             <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>             <volume>76</volume>             <fpage>036114</fpage>          </element-citation></ref>
<ref id="pone.0014413-BarYam1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bar-Yam</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Epstein</surname><given-names>IR</given-names></name>
</person-group>             <year>2004</year>             <article-title>Response of complex networks to stimuli.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>101</volume>             <fpage>4341</fpage>             <lpage>4345</lpage>          </element-citation></ref>
<ref id="pone.0014413-Stauffer1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stauffer</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Aharony</surname><given-names>A</given-names></name>
<name name-style="western"><surname>da Fontoura Costa</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Adler</surname><given-names>J</given-names></name>
</person-group>             <year>2003</year>             <article-title>Efficient Hopfield pattern recognition on a scale-free neural network.</article-title>             <source>Eur Phys J</source>             <volume>32</volume>             <fpage>395</fpage>             <lpage>399</lpage>          </element-citation></ref>
<ref id="pone.0014413-PerezCastillo1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Perez Castillo</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Wemmenhove</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Hatchett</surname><given-names>JPL</given-names></name>
<name name-style="western"><surname>Coolen</surname><given-names>ACC</given-names></name>
<name name-style="western"><surname>Skantzos</surname><given-names>NS</given-names></name>
<etal/></person-group>             <year>2004</year>             <article-title>Analytic solution of attractor neural networks on scale-free graphs.</article-title>             <source>J Phys A: Math Gen</source>             <volume>37</volume>             <fpage>8789</fpage>             <lpage>8799</lpage>          </element-citation></ref>
<ref id="pone.0014413-Barabasi1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barabasi</surname><given-names>AL</given-names></name>
<name name-style="western"><surname>Albert</surname><given-names>R</given-names></name>
</person-group>             <year>1999</year>             <article-title>Emergence of scaling in random networks.</article-title>             <source>Science</source>             <volume>286</volume>             <fpage>509</fpage>             <lpage>512</lpage>          </element-citation></ref>
<ref id="pone.0014413-Ravasz1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ravasz</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Somera</surname><given-names>AL</given-names></name>
<name name-style="western"><surname>Mongru</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Oltvai</surname><given-names>ZN</given-names></name>
<name name-style="western"><surname>Barabasi</surname><given-names>AL</given-names></name>
</person-group>             <year>2002</year>             <article-title>Hierarchical organization of modularity in metabolic networks.</article-title>             <source>Science</source>             <volume>297</volume>             <fpage>1551</fpage>             <lpage>1555</lpage>          </element-citation></ref>
<ref id="pone.0014413-Hopfield1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name>
</person-group>             <year>1984</year>             <article-title>Neurons with graded response have collective computational properties like those of two-state neurons.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>81</volume>             <fpage>3088</fpage>             <lpage>3092</lpage>          </element-citation></ref>
<ref id="pone.0014413-Macklem1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Macklem</surname><given-names>PT</given-names></name>
</person-group>             <year>2008</year>             <article-title>Emergent phenomena and the secrets of life.</article-title>             <source>J Appl Physiol</source>             <volume>104</volume>             <fpage>1844</fpage>             <lpage>1846</lpage>          </element-citation></ref>
<ref id="pone.0014413-Prigogine1"><label>15</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Prigogine</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Stengers</surname><given-names>I</given-names></name>
</person-group>             <year>1984</year>             <article-title>Order Out of Chaos.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Bantam</publisher-name>          </element-citation></ref>
<ref id="pone.0014413-Kauffman1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kauffman</surname><given-names>S</given-names></name>
</person-group>             <year>1971</year>             <article-title>Differentiation of malignant to benign cells.</article-title>             <source>J Theor Biol</source>             <volume>31</volume>             <fpage>429</fpage>             <lpage>451</lpage>          </element-citation></ref>
<ref id="pone.0014413-Sul1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sul</surname><given-names>JY</given-names></name>
<name name-style="western"><surname>Wu</surname><given-names>CW</given-names></name>
<name name-style="western"><surname>Zeng</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Jochems</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Lee</surname><given-names>MT</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>Transcriptome transfer produces a predictable cellular phenotype.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>106</volume>             <fpage>7624</fpage>             <lpage>7629</lpage>          </element-citation></ref>
<ref id="pone.0014413-Paris1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Paris</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Bazzoni</surname><given-names>G</given-names></name>
</person-group>             <year>2008</year>             <article-title>The protein interaction network of the epithelial junctional complex: a system-level analysis.</article-title>             <source>Mol Biol Cell</source>             <volume>19</volume>             <fpage>5409</fpage>             <lpage>5421</lpage>          </element-citation></ref>
<ref id="pone.0014413-Li1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Li</surname><given-names>X</given-names></name>
<name name-style="western"><surname>Chen</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Huang</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Su</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Martinez</surname><given-names>JD</given-names></name>
</person-group>             <year>2007</year>             <article-title>Global mapping of gene/protein interactions in PubMed abstracts: a framework and an experiment with P53 interactions.</article-title>             <source>J Biomed Inform</source>             <volume>40</volume>             <fpage>453</fpage>             <lpage>464</lpage>          </element-citation></ref>
<ref id="pone.0014413-Leclerc1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Leclerc</surname><given-names>RD</given-names></name>
</person-group>             <year>2008</year>             <article-title>Survival of the sparsest: robust gene networks are parsimonious.</article-title>             <source>Mol Syst Biol</source>             <volume>4</volume>             <fpage>213</fpage>          </element-citation></ref>
<ref id="pone.0014413-Derrida1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Derrida</surname><given-names>B</given-names></name>
</person-group>             <year>1988</year>             <article-title>Distribution of the activities in a diluted neural network.</article-title>             <source>J Phys A: Math Gen</source>             <volume>22</volume>             <fpage>2069</fpage>             <lpage>2080</lpage>          </element-citation></ref>
<ref id="pone.0014413-Cavalcante1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cavalcante</surname><given-names>FS</given-names></name>
<name name-style="western"><surname>Ito</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Brewer</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Sakai</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Alencar</surname><given-names>AM</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Mechanical interactions between collagen and proteoglycans: implications for the stability of lung tissue.</article-title>             <source>J Appl Physiol</source>             <volume>98</volume>             <fpage>672</fpage>             <lpage>679</lpage>          </element-citation></ref>
<ref id="pone.0014413-Agostini1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Agostini</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Gurrieri</surname><given-names>C</given-names></name>
</person-group>             <year>2006</year>             <article-title>Chemokine/cytokine cocktail in idiopathic pulmonary fibrosis.</article-title>             <source>Proc Am Thorac Soc</source>             <volume>3</volume>             <fpage>357</fpage>             <lpage>363</lpage>          </element-citation></ref>
<ref id="pone.0014413-Perlis1"><label>24</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Perlis</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Smiht</surname><given-names>MT</given-names></name>
<name name-style="western"><surname>Pigeon</surname><given-names>WR</given-names></name>
</person-group>             <year>2005</year>             <article-title>Etiology and Pathophysiology of Insomnia.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Kreyger</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Roth</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Dement</surname><given-names>WC</given-names></name>
</person-group>             <source>Principles and Practice of Sleep Medicine. 4th ed</source>             <publisher-loc>Philadelphia</publisher-loc>             <publisher-name>Elsevier Saunders</publisher-name>             <fpage>726</fpage>             <lpage>717</lpage>          </element-citation></ref>
<ref id="pone.0014413-Morin1"><label>25</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morin</surname><given-names>CM</given-names></name>
</person-group>             <year>2005</year>             <article-title>Psychological and Behavioral Treatments for Primary Insomnia.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Kreyger</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Roth</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Dement</surname><given-names>WC</given-names></name>
</person-group>             <source>Principles and Practice of Sleep Medicine. 4th ed</source>             <publisher-loc>Philadelphia</publisher-loc>             <publisher-name>Elsevier Saunders</publisher-name>          </element-citation></ref>
</ref-list>

</back>
</article>