<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-05871</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0089642</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Social and behavioral sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subject>Experimental psychology</subject><subject>Psychometrics</subject><subject>Sensory perception</subject><subject>Social psychology</subject></subj-group></subj-group><subj-group><subject>Sociology</subject><subj-group><subject>Culture</subject><subj-group><subject>Cultural resources</subject></subj-group></subj-group><subj-group><subject>Social stratification</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>The Musicality of Non-Musicians: An Index for Assessing Musical Sophistication in the General Population</article-title>
<alt-title alt-title-type="running-head">The Musicality of Non-Musicians</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Müllensiefen</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gingras</surname><given-names>Bruno</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Musil</surname><given-names>Jason</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Stewart</surname><given-names>Lauren</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Psychology, Goldsmiths, University of London, London, United Kingdom</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Cognitive Biology, University of Vienna, Vienna, Austria</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Snyder</surname><given-names>Joel</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>UNLV, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">d.mullensiefen@gold.ac.uk</email></corresp>
<fn fn-type="conflict"><p>The authors have the following interests: The technical implementation of the large internet survey was carried out by BBC Lab UK. However, it needs to be noted that BBC Lab UK did not give any funding towards the research. This does not alter the authors’ adherence to all the PLOS ONE policies on sharing data and materials, as detailed online in the guide for authors.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: DM BG JM LS. Performed the experiments: DM BG JM LS. Analyzed the data: DM JM. Contributed reagents/materials/analysis tools: DM JM. Wrote the paper: DM LS BG.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>26</day><month>2</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>2</issue>
<elocation-id>e89642</elocation-id>
<history>
<date date-type="received"><day>5</day><month>2</month><year>2013</year></date>
<date date-type="accepted"><day>24</day><month>1</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Müllensiefen et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Musical skills and expertise vary greatly in Western societies. Individuals can differ in their repertoire of musical behaviours as well as in the level of skill they display for any single musical behaviour. The types of musical behaviours we refer to here are broad, ranging from performance on an instrument and listening expertise, to the ability to employ music in functional settings or to communicate about music. In this paper, we first describe the concept of ‘musical sophistication’ which can be used to describe the multi-faceted nature of musical expertise. Next, we develop a novel measurement instrument, the Goldsmiths Musical Sophistication Index (Gold-MSI) to assess self-reported musical skills and behaviours on multiple dimensions in the general population using a large Internet sample (n = 147,636). Thirdly, we report results from several lab studies, demonstrating that the Gold-MSI possesses good psychometric properties, and that self-reported musical sophistication is associated with performance on two listening tasks. Finally, we identify occupation, occupational status, age, gender, and wealth as the main socio-demographic factors associated with musical sophistication. Results are discussed in terms of theoretical accounts of implicit and statistical music learning and with regard to social conditions of sophisticated musical engagement.</p>
</abstract>
<funding-group><funding-statement>The research was supported by a Goldsmiths Early Career Development grant awarded to Daniel Mullensiefen in 2010. The technical implementation of the large internet survey was supported and carried by BBC Lab UK. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="23"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>The ability to engage with music in sophisticated ways is a unique and universal human ability <xref ref-type="bibr" rid="pone.0089642-Merriam1">[1]</xref>. Participation in musical activities occurs in every known human culture <xref ref-type="bibr" rid="pone.0089642-Blacking1">[2]</xref>. However, the ways in which members of a society differentiate and specialise in their engagement with music varies greatly between cultures. Blacking <xref ref-type="bibr" rid="pone.0089642-Blacking2">[3]</xref> observed and described in detail how some cultures lack any notion of hierarchy according to musicianship status while others–particularly Western societies–make very clear distinctions between individuals, according to their ascribed specialist music skills and roles. This hierarchical notion of expertise in music persists in Western societies across almost all popular and art music styles and types of engagement. Success, excellence, and expertise can be ascribed to performing musicians, composers/song writers, music producers, recording engineers, DJs, music critics, music academics and avid music ‘connoisseurs’ alike.</p>
<p>However, as Levitin <xref ref-type="bibr" rid="pone.0089642-Levitin1">[4]</xref> recently argued, almost all of the scientific instruments used to study musicality and musical achievements in Western society are centred on the ability to play an instrument and the expertise of performing musicians in Western art music, ignoring the skills necessary for successfully engaging with music in other ways besides playing an instrument. The recent works of Hallam <xref ref-type="bibr" rid="pone.0089642-Hallam1">[5]</xref>, as well as Hallam and Prince <xref ref-type="bibr" rid="pone.0089642-Hallam2">[6]</xref>, suggest a more multifaceted and nuanced view of musicality that is broader than that typically assessed via traditional tests, which includes musical understanding, appreciation, evaluation, and communication alongside playing an instrument, improvisation and having a good sense of pitch and rhythm. However, to date no measurement tool has been created following these lines of thought.</p>
<p>This paper describes the development and evaluation of the Goldsmiths Musical Sophistication Index (Gold-MSI), a novel instrument that measures musical sophistication in a comprehensive way by explicitly considering a wide range of facets of musical expertise as they occur in a Western society. The instrument is designed to measure the broad range of individual differences in the general population, while placing less importance on the much smaller pathological groups (e.g. ‘amusics’ <xref ref-type="bibr" rid="pone.0089642-Hyde1">[7]</xref>, <xref ref-type="bibr" rid="pone.0089642-Stewart1">[8]</xref>) and highly specialist populations (professional musicians). Data from 147,633 individuals, who took both the self-report inventory as well as the battery of listening tests from the Gold-MSI, are presented. Relating self-reported musical behaviour to the performance on the listening tests enables us to determine the extent to which skill acquisition and expertise may be related to reported patterns of musical engagement. Since many musical skills are not explicitly trained, but are developed through repeated and focused engagement with music, the results from this large sample highlight the processes of implicit learning that take place during enculturation with Western music. Finally, using socio-economic data from 90,474 British participants in our sample, we describe the typical conditions under which musical sophistication develops, and discuss mechanisms by which individuals can continue to engage with music at a high level throughout the lifespan.</p>
<sec id="s1a">
<title>Assessing Musical Abilities and Musical Behaviour</title>
<p>The assessment of musical abilities and achievements has a relatively long scientific history. Seashore published the initial version of his test of ‘musical talents’ in 1919 and since then a number of tests <xref ref-type="bibr" rid="pone.0089642-Bentley1">[9]</xref>–<xref ref-type="bibr" rid="pone.0089642-Law1">[14]</xref> have been developed to assess musical abilities, the potential to develop musical skills, or musical achievements. Boyle and Radocy <xref ref-type="bibr" rid="pone.0089642-Boyle1">[15]</xref> provide a systematic summary of musical aptitude tests published over the course of the 20<sup>th</sup> century and describe how most of them were intentionally designed for specific purposes in (Western) music education. In addition to this long tradition of musical aptitude tests primarily designed for use in music education, a number of listening tests have been developed more recently with a focus on academic research and suitability for an adult population. Gordon’s Advanced Measures of Audiation <xref ref-type="bibr" rid="pone.0089642-Gordon1">[10]</xref> comprise a “same” versus “different” comparison task for pairs of newly created single line melodies with increasing complexity and length where participants also have to indicate whether the difference between two melodies is rhythmical or tonal in nature and the respective responses give rise to a rhythmic and a tonal test score. The Musical Ear Test <xref ref-type="bibr" rid="pone.0089642-Wallentin1">[12]</xref> employs a very similar experimental paradigm and stimuli, but tests melody and rhythm perception with two different subtests. The Montreal Battery for the Evaluation of Amusia <xref ref-type="bibr" rid="pone.0089642-Hyde1">[7]</xref> also makes use of the same-different comparison paradigm with short melodic or rhythmic single line sequences as stimuli across 4 of its 5 subtests where tests differ in the quality of change that can occur between the paired items. The most recent musical perception battery is the Profile of Music Perception Skills (PROMS) <xref ref-type="bibr" rid="pone.0089642-Law1">[14]</xref> which also makes exclusive use of the same-different comparison paradigm for its 9 subtests. However, the stimulus material of the PROMS extends beyond pairs of melodic and rhythmic single line sequences and also includes samples of instrumental tones and sinusoids as well as multi-layer sequences. It is worth noting that none of these test batteries includes a self-report inventory. Furthermore, almost all of the aforementioned batteries use artificially created experimental stimuli. This strategy is helpful in order to control for familiarity effects but bears the risk of producing musical stimuli of little ecological validity and little resemblance to real music, and which are fairly remote from the participants’ musical experiences and listening expertise and therefore can advantage participants who have learned to engage with more abstract musical material, e.g. through instrumental lessons or ear training. The educational perspective of most of the earlier musical aptitude tests explains the similarity to ear-training exercises, such as those used in Western art music education where individual elements of musical structure (most often melody, rhythm, or harmony) are commonly presented in isolation and assessment tasks often seem artificial compared to most people’s real-world listening behaviours. Perhaps unsurprisingly, therefore, individuals with formal training in Western art music typically achieve higher scores on these tests. However, these traditional tests of musical achievement overlook a variety of musical achievements or skills <xref ref-type="bibr" rid="pone.0089642-Murphy1">[16]</xref>, such as the abilities to verbally communicate about music at a high level, to use music effectively to manipulate one’s own emotional states and those of others, and to compare music stylistically. Many of these skills form the basis of musical professions such as DJing, music journalism, or music production.</p>
<p>Similarly, items in traditional musical aptitude tests are often taken from or created in the style of simple pieces of Western art music or the folk song repertoire, and in almost all cases ignore multi-instrument textures and sound quality as relevant dimensions in many Western music styles. For instance, neither musical sound or timbre, nor musical excerpts with several instruments playing together feature in either of the two most commonly used musicality tests <xref ref-type="bibr" rid="pone.0089642-Gordon1">[10]</xref>–<xref ref-type="bibr" rid="pone.0089642-Seashore1">[11]</xref>. Seashore <xref ref-type="bibr" rid="pone.0089642-Seashore2">[17]</xref> justifies a focus on more simple musical stimuli by arguing that the correct processing of structural musical ‘atoms’ is a pre-condition for the successful decoding of more complex musical contents and hence testing the ability to process musical ‘atoms’ would be a valid proxy for indexing higher musical skills (see pp. 3–4 <xref ref-type="bibr" rid="pone.0089642-Law1">[14]</xref> for a similar argument regarding the basic and abstract sound patterns predominately employed as stimuli in PROMS). This argument probably holds true for predicting achievements in traditional Western music education but is perhaps less relevant for the skilled engagement with music in other forms and for expertise with other types of Western music.</p>
<p>Indeed, one motivation for the development of the Gold-MSI inventory and test battery was to devise tasks for assessing musical skills that are more akin to real-world skilled listening behaviours and that would incorporate stimulus items from a wider range of musical styles.</p>
<p>Compared with the long history of musical aptitude tests, most self-report questionnaires for the assessment of musical behaviour are relatively recent <xref ref-type="bibr" rid="pone.0089642-Chin1">[18]</xref>–<xref ref-type="bibr" rid="pone.0089642-Werner1">[22]</xref>. However, to our knowledge, none of these self-report instruments focus on the expertise or the differentiation of skilled musical behaviours, aside from formal musical training. Hence, one of the main goals of the Gold-MSI project was to develop a self-assessment instrument that can measure expertise with regard to a variety of musical activities, not only instrumental expertise. The combination of a self-assessment instrument and high-level musical listening tests that include complex musical material and employ different testing paradigms is the second main goal of this study, which distinguishes the Gold-MSI from existing musical test batteries and makes it a research tool that complements the musical ability tests referenced above.</p>
</sec><sec id="s1b">
<title>Defining Musical Sophistication</title>
<p>In line with Ollen <xref ref-type="bibr" rid="pone.0089642-Ollen1">[21]</xref>, we deliberately adopt ‘musical sophistication’ as a term that has been used infrequently in earlier research and is therefore less loaded with biases and preconceptions than more commonly used terms such as musicality, musical talent, ability, aptitude, or musical potential (see <xref ref-type="bibr" rid="pone.0089642-Boyle1">[15]</xref>, <xref ref-type="bibr" rid="pone.0089642-Gembris1">[23]</xref>, <xref ref-type="bibr" rid="pone.0089642-McPherson1">[24]</xref> for discussion of different terms and concepts). In our conceptualisation, musical sophistication is a psychometric construct that can refer to musical skills, expertise, achievements, and related behaviours across a range of facets that are measured on different subscales. We assume that multiple facets of musical sophistication can develop through active engagement with music in its many different forms and that individuals vary in their level of sophistication on these different facets (see <xref ref-type="bibr" rid="pone.0089642-Karma1">[25]</xref> for the close relationship between ecological validity and multi-dimensionality of musical aptitude tests). We posit that high levels of musical sophistication are generally characterised by a) higher frequencies of exerting musical skills or behaviours, b) greater ease, accuracy or effect of musical behaviours when executed, and c) a greater and more varied repertoire of musical behaviour patterns. This means that highly musically sophisticated individuals are able to respond to a greater range of musical situations, are more flexible in their responses, and possess more effective means of achieving their goals when engaging with music. Note that this definition of musical sophistication is sufficiently abstract to apply equally to performing musicians of all styles as well as to music writers and commentators, and to individuals who apply music in functional ways such as DJs, music educators, producers, or music engineers. We further assume that differences in observable behaviour are related to levels of differentiation in categorising and processing music in the cognitive system of individuals. In line with expertise research literature from other domains <xref ref-type="bibr" rid="pone.0089642-Augustin1">[26]</xref>–<xref ref-type="bibr" rid="pone.0089642-Yau1">[32]</xref>, we assume that, with greater expertise, the representational cognitive system for a domain will differ in its level of sophistication, i.e. cognitive representations will be more structured, and will exhibit a clearer hierarchical organization as explained and defined by e.g. Ericsson and Smith <xref ref-type="bibr" rid="pone.0089642-Ericsson1">[33]</xref>, Glaser <xref ref-type="bibr" rid="pone.0089642-Glaser1">[34]</xref>, and Honeck, Firment, and Case <xref ref-type="bibr" rid="pone.0089642-Honeck1">[35]</xref>. However, this definition makes no assumption with regard to how musical sophistication is acquired and whether it mainly stems from natural talent <xref ref-type="bibr" rid="pone.0089642-McPherson2">[36]</xref>, genetic predispositions <xref ref-type="bibr" rid="pone.0089642-Ukkola1">[37]</xref>–<xref ref-type="bibr" rid="pone.0089642-Granot1">[40]</xref>, or is largely a result of learning processes.</p>
<p>Our definition of musical sophistication builds on concepts that are similar to those introduced by Hallam and Prince <xref ref-type="bibr" rid="pone.0089642-Hallam2">[6]</xref>, and Ollen <xref ref-type="bibr" rid="pone.0089642-Ollen1">[21]</xref> who also stressed the multi-dimensional nature of musical sophistication, including aural skills, receptive responses, and the different abilities to make music <xref ref-type="bibr" rid="pone.0089642-Ollen1">[21]</xref>. However, our conceptualisation and implementation of musical sophistication differs from these earlier characterisations in that it emphasises other skilled musical behaviours besides instrumental practice, is not biased towards art music, includes a self-assessment of musical skills, models musical sophistication as a continuous parameter, and is explicitly linked to cognitive theories of expertise in other domains.</p>
</sec><sec id="s1c">
<title>Musical Skills in ‘Non-musicians’</title>
<p>Much previous music-related research has been preoccupied with measuring behavioural, cognitive, and brain structural/functional differences between musicians and non-musicians, where the criteria used to define these groups have mostly emphasised musical abilities conferred by musical training, including variations in terms of the criteria used to establish the groups of interest <xref ref-type="bibr" rid="pone.0089642-Aheadi1">[41]</xref>–<xref ref-type="bibr" rid="pone.0089642-Schmithorst1">[46]</xref>. But the emphasis on formal musical training (on an instrument, including voice) has likely overlooked the possible effects of a type of expertise that does not involve theoretical or technical knowledge of music, and can be present in people who consider themselves non-musicians. Studies published over the past decade have suggested that music listening expertise does not need to be taught; in fact, the knowledge gained through formal musical training may be rather tangential to the skills required to be an expert listener. Young infants, before they have had the opportunity to receive formalised training, demonstrate sophisticated musical abilities, including the ability to distinguish intervals, recognise folk songs <xref ref-type="bibr" rid="pone.0089642-Zentner1">[47]</xref>, and detect metrical deviations in music from their own musical culture as well as from a non-native one <xref ref-type="bibr" rid="pone.0089642-Hannon1">[48]</xref>. Thus, as with speech <xref ref-type="bibr" rid="pone.0089642-Werker1">[49]</xref>–<xref ref-type="bibr" rid="pone.0089642-Werker2">[50]</xref>, musical enculturation shapes perceptual capacities via exposure. Implicit learning of this sort relies upon the brain’s ability to internalise statistical regularities from its exposure to auditory stimuli <xref ref-type="bibr" rid="pone.0089642-Jonaitis1">[51]</xref>–<xref ref-type="bibr" rid="pone.0089642-Tillmann2">[56]</xref>. The fact that implicit learning takes place incidentally, without awareness, and can rarely be verbalised tends to result in a general underestimation of the musical abilities of people without formal training. Nevertheless, there is clear evidence that these individuals can possess considerable implicit knowledge of musical structure across a range of different tasks (see overviews provided by <xref ref-type="bibr" rid="pone.0089642-Bigand1">[57]</xref>–<xref ref-type="bibr" rid="pone.0089642-Honing2">[59]</xref> and the related notion of ‘musical sleepers’ <xref ref-type="bibr" rid="pone.0089642-Law1">[14]</xref>), and that differences in musical listening patterns can also affect non-musical abilities <xref ref-type="bibr" rid="pone.0089642-Chin2">[60]</xref>.</p>
<p>The fact that knowledge of musical regularities and structure can be gained implicitly does not entail that the exposure to music is necessarily ‘passive’. Although it may seem effortless, listening to music is an active process, engaging the listener in a process of parsing, segmenting, and encoding a complex stream of auditory events, and extracting structure at multiple hierarchical levels, requiring concerted neural activity across auditory association areas in the temporal lobes, auditory working memory areas in the frontal lobes, and emotional centres in the limbic system <xref ref-type="bibr" rid="pone.0089642-Peretz1">[61]</xref>–<xref ref-type="bibr" rid="pone.0089642-Stewart2">[62]</xref>. Recent work has stressed the extent to which certain aspects of musical listening can result in top-down interactions from cortical to subcortical areas, in order to better encode the most relevant features of the incoming stimulus <xref ref-type="bibr" rid="pone.0089642-Kraus1">[63]</xref>. Clearly, the ways in which individuals actively engage with music can vary, and are related to many factors including the amount of focused listening per day, the importance attached to music in everyday life, the extent to which an individual responds emotionally to music, and the degree to which an individual takes part in music in informal ways (e.g. singing along to tunes, exchanging views on music with others). Hence, a major goal of the present study is to provide a standardised measurement instrument to examine musical sophistication, which will allow future studies to examine how differences across this profile (or in facets of it) may relate to differences in perceptual, cognitive, neurological, or even immune system function.</p>
</sec><sec id="s1d">
<title>Overview of Studies</title>
<p>This paper comprises five studies relating to the development and refinement of the Gold-MSI, a comparison of objective and self-reported assessments of musical sophistication, and finally an analysis of the socio-demographic correlates of musical sophistication in a large sample of British participants. Study 1 reports the development of the Gold-MSI self-report inventory on a large data sample gathered through an online survey with BBC Lab UK. Study 2 uses a different sample (from the same survey) to confirm the measurement structure of the self-report instrument and reports the structural relationships between different facets of musical sophistication using a confirmatory approach. Study 3 reports psychometric indicators of internal reliability, and external convergent and discriminant validity of the self-report inventory as well as correlations with a standard personality inventory. Study 4 compares the results from the self-reported facets of musical sophistication with results from two musical listening tasks from the Gold-MSI battery, and investigates how self-reported musical behaviour and objectively measurable listening abilities are related. Finally, Study 5 explores the socio-economic conditions of musical sophistication by relating scores from self-report inventory and listening tests to variables of socio-economic status, such as education level, occupational status, and wealth. The Ethics Board of Goldsmiths, University of London approved the research undertaken and reported in the manuscript.</p>
</sec></sec><sec id="s2">
<title>Study 1: Developing a Self-Report Inventory for Musical Sophistication</title>
<p>The development of the self-report inventory was based on a systematic review of the existing literature described above, covering questionnaire instruments of musical behaviour <xref ref-type="bibr" rid="pone.0089642-Chin1">[18]</xref>–<xref ref-type="bibr" rid="pone.0089642-Werner1">[22]</xref>, <xref ref-type="bibr" rid="pone.0089642-Chin2">[60]</xref>, tests of musical abilities <xref ref-type="bibr" rid="pone.0089642-Bentley1">[9]</xref>–<xref ref-type="bibr" rid="pone.0089642-Boyle1">[15]</xref>, and inventories for assessing expertise in other domains (e.g. physics <xref ref-type="bibr" rid="pone.0089642-Chi1">[27]</xref>; wine <xref ref-type="bibr" rid="pone.0089642-Hughson1">[28]</xref>–<xref ref-type="bibr" rid="pone.0089642-Hughson2">[29]</xref>; computer programming <xref ref-type="bibr" rid="pone.0089642-Weiser1">[31]</xref>; badminton <xref ref-type="bibr" rid="pone.0089642-Yau1">[32]</xref>). The objective of the review was the development of a new self-report inventory measuring the most common forms of skilled musical behaviour in the general Western population by deriving sub-scales for different facets of ‘musical sophistication’. On the basis of the literature review as well as the conceptual definition of musical sophistication given above we initially posited five distinct hypothetical dimensions of musical sophistication merely to provide conceptual guidance at the item writing stage, namely resource allocation to music, music making, functional use of music, ability to verbalise musical experiences, and perceptual-cognitive skills.</p>
<p>The five hypothetical dimensions served to orient the writing of the initial pool of inventory items in the form of statements that could be endorsed to varying degrees on a rating scale. In item writing we ensured as much as possible that, within each dimension, positively and negatively phrased statements were balanced, that statements would apply to any musical style and any age group, and that as many potential behaviours of interest as possible would be covered for each dimension. The target population for responding to the items was composed of adults with a range of levels of formal musical training (from no training up to professional level), and we calibrated the items towards the level of musical behaviour and abilities that could be expected in the general population by using appropriate adverbs (e.g. ‘mostly’, ‘rarely’, ‘never’, ‘always’). We did not try to capture finer grained differences between high-level or professional musicians. The first iteration of the inventory comprised 153 statements written independently by three of the authors (DM, BG, LS). Each item was then jointly scrutinised and ambiguous items, quasi-synonymous items, items that did not fit with the overall concept of musical sophistication, and items that would potentially apply to only a small subpopulation were eliminated from the item pool. The remaining 111 items were then used in a pilot survey. For each of the five hypothetical dimensions we ensured that roughly equal proportions of items were stated positively. We adopted the same seven-point scale for all items ranging from complete agreement to complete disagreement. This scale includes a middle (i.e. neutral) category and represents a compromise between an interval scale providing data for subsequent parametric analyses and a manageable number of categories where each category retains a meaning that can be expressed verbally.</p>
<p>A pilot survey using an online questionnaire with these 111 items was launched via the BBC’s main Science webpage <xref ref-type="bibr" rid="pone.0089642-BBC1">[64]</xref> for one week. This yielded responses from 488 participants from a broad age range. The data of the pilot survey were then subjected to a series of factor analytic techniques. In addition, we employed individual item analyses using classical test theory as well as item response models to reduce the pool of items. The analytic steps of this process are analogous to how the item reduction was carried out on the actual dataset of Study 1 reported in the results section below. In addition, the details of the analysis of the pilot data are given in Textual Description S1 and in a publicly available technical report <xref ref-type="bibr" rid="pone.0089642-Mllensiefen1">[65]</xref>. Eventually, this pilot data gave rise to a solution comprising 70 items on 7 factors and explaining 53.6% of the variance, with the 7 subscales having very good psychometric properties (values of Cronbach’s alpha ranging between .693 and .921).</p>
<sec id="s2a">
<title>Method</title>
<p>The 70-item self-report inventory was launched in January 2011 as part of the online test battery <italic>How Musical Are You?</italic> <xref ref-type="bibr" rid="pone.0089642-BBC2">[66]</xref>, developed by BBC Lab UK and promoted across the BBC broadcast network. 148,037 participants completed the self-report inventory as part of the test battery in 2011. From this sample we excluded individuals who mainly chose the same response category across the 70 (unreversed) items (i.e. variance &lt;2 <italic>SDs</italic> below mean variance). This excluded 404 participants and left 147,633 in the sample. In order not to overfit the data, and to obtain unbiased estimates of model fit, we split the full sample into a training dataset (n = 73,894) used for the development of the inventory reported in Study 1, and a test dataset (n = 73,739) used for the confirmatory analysis in Study 2.</p>
<sec id="s2a1">
<title>Participants</title>
<p>45.2% of the participants from the training sample were female and 54.7% were male. Mean age was 35.2 years (<italic>SD = </italic>15). Participants were mainly UK residents (66.9%) but because the <italic>How Musical Are You?</italic> test battery was an open online application, the sample also included participants from other, albeit mainly Western and English-speaking, countries (most frequently named: USA: 14.2%, Canada: 2.3%, Australia: 1.1%). The ethnic background of the participants was mostly white (84.1%) but also included a wide range of participants from non-white backgrounds (most frequent: Asian/Indian/Pakistani/Bangladeshi: 3.4%; Mixed Race: 2.3%, East/South-East Asian: 1.8%). The sample contained a large spread in terms of education (undergraduate degree/professional qualification: 34.1%, still in education: 23.4%, postgraduate degree: 19%, second school degree around 18 years (e.g. British A-levels): 11.8%, first school degree around 16 years (e.g. British GCSE/O-levels): 7.5%, etc.) as well as in terms of the current profession of the participants (Other: 19.4%, Education/Training: 12.4%, Unemployed: 10.7%, Information technology: 7.1%, etc.). Only 1.8% stated ‘Music’ as their occupation. There was no incentive for the participants other than the individual feedback that was based on the data norms derived from the pilot.</p>
</sec><sec id="s2a2">
<title>Procedure</title>
<p>Participants were required to obtain an online-identifier from the BBC (the BBC-ID) and then log into the actual test battery. They completed the self-report inventory along with a short demographic questionnaire and four tests of musical ability. If taken without pauses, the entire testing procedure took about 25 minutes. Participants were then given online feedback on their ‘relationship with music’ in the form of the percentile of their scores as well as short interpretations of the numerical score. In addition, participants were given the results of the four musical ability tests, and debriefing information about the online study itself. Participants were only able to take the test once with the same BBC-ID. However, it was technically possible for an individual to create a second BBC-ID and to re-take the entire test and we therefore included a question to identify a small number of re-takers (0.02% of the full sample) which were left in the data sample. The data were fully anonymised before analysis and the research team did not have access to information that could lead to personal identification, such as email or IP addresses.</p>
</sec></sec><sec id="s2b">
<title>Results and Discussion</title>
<sec id="s2b1">
<title>Identifying the factor structure of the self-report inventory</title>
<p>Identifying the dimensionality of the data in factor analysis is crucial, especially if the aim of the analysis is to develop a multi-dimensional measure with corresponding sub-scales. We therefore looked at the convergence of different criteria for deciding on the appropriate number of dimensions. We used different factor extraction methods (maximum likelihood factor analysis, principal axis factoring using an iterative least squares optimisation, minimum residual factor analysis) and as criteria employed the screeplot <xref ref-type="bibr" rid="pone.0089642-Cattell1">[67]</xref>, Kaiser’s criterion of eigenvalues &gt;1, parallel analysis on random and resampled datasets of the same size <xref ref-type="bibr" rid="pone.0089642-Montanelli1">[68]</xref>–<xref ref-type="bibr" rid="pone.0089642-Dinno1">[69]</xref>, Velicer’s Minimum Average Partial (MAP) criterion <xref ref-type="bibr" rid="pone.0089642-Velicer1">[70]</xref>, and Revelle and Rocklin’s Very Simple Structure (VSS) criterion <xref ref-type="bibr" rid="pone.0089642-Revelle1">[71]</xref> (all analyses were carried out using the R software environment and the R package psych <xref ref-type="bibr" rid="pone.0089642-R1">[72]</xref>). Initially, we did not find any convergence for the different methods, obtaining indications for optimal solutions ranging from 1 to 16 factors. One potential reason for the disagreement of the different criteria can be the presence of a strong general factor that can eclipse less strong group factors. When we investigated this possibility we found that the Very Simple Structure Criterion for a solution with complexity level 1, as well as the ratio of the eigenvalue of first factor to the number of variables (0.298; <xref ref-type="bibr" rid="pone.0089642-Musek1">[73]</xref>), indeed suggested that a general factor (second-order factor) might be present in the data, accounting for the correlations between the first-order group factors. We tested for the presence of a general hierarchical factor using McDonald’s coefficient omega <xref ref-type="bibr" rid="pone.0089642-McDonald2">[74]</xref> which has been shown to be the most sensitive and the most reliable measure for testing for the presence of a hierarchical factor <xref ref-type="bibr" rid="pone.0089642-Revelle2">[75]</xref>–<xref ref-type="bibr" rid="pone.0089642-Zinbarg1">[76]</xref>. For all hierarchical factor solutions (based on maximum likelihood factor analysis) with one general factor and 3 to 16 group factors we obtained values of omega ranging from 0.721 to 0.834, giving clear evidence of a general factor of musical sophistication (regardless of the true number of group factors). However, the absolute fit indices for a simple model having only a general factor and no group factors indicated only a mediocre fit (RMSEA = .079, Tucker-Lewis Index =  .589, Bentler CFI =  .601). Adding group factors into the model increased the absolute, as well as the comparative fit, as measured by the BIC (range from 1040.747 to 139.912 for 1- to 16-factor solutions), clearly suggesting that group factors are necessary in addition to the general factor to account for the data.</p>
<p>In order to discount this strong general factor in the search for the correct number of dimensions, we performed a 1-factor maximum likelihood factor analysis and extracted the matrix of residuals for a subsequent analysis of the dimensionality of the data using the same criteria as above. For all extraction and rotation methods employed on this input matrix, the MAP criterion always indicated 6 dimensions to be optimal. In addition, the 6<sup>th</sup> factor received an eigenvalue of 0.99 in principal axis, maximum likelihood, and minimum residual factoring and the VSS criterion indicated for most extraction methods (using oblique rotation) and most complexity levels that a solution with 6 factors was optimal. We interpreted this as a clear indication of the presence of 6 group factors in addition to a hierarchical general factor in our data.</p>
<p>On the training dataset we fitted a model with a hierarchical factor and 6 group factors using maximum likelihood extraction, oblimin rotation and the Schmid-Leiman procedure <xref ref-type="bibr" rid="pone.0089642-Schmid1">[77]</xref> to extract the general factor from the inter-correlations of the group factors. The model had a high value of omega (.74) and a very good overall data fit (RMSEA = .046, TLI = .858). The eigenvalue of the general factor was 16.2 and the 6 group factors had eigenvalues in the range from 4.5 to 1.7.</p>
<p>In order to obtain a simple factorial structure, and to construct non-ambiguous subscales of musical sophistication, we fitted a variant of this model as a structural equation model with a general factor, 6 group factors, and where each of the 70 items was only related to the one group factor where the loading was highest. This model still possessed a very good absolute fit (χ<sup>2</sup> = 473746, df = 2275, RMSEA = 0.053, TLI = .813, CFI = .823) with the general factor having an eigenvalue of 19.2 and the 6 group factors ranging between 2.9 and 1.2. We accepted this simple model as a good enough fit to our data to use it as a starting point for the subsequent refinement of the subscales. It is important to note that the construction of the six-plus-one factor model does not represent a ‘natural’ or ‘true’ model of musical sophistication but is partially due to our theory-driven approach that was also informed by evidence from prior literature. A less theoretical approach might have yielded a different set of dimensions, both in kind and in number.</p>
</sec><sec id="s2b2">
<title>Refinement of subscales</title>
<p>We first inspected each of the 6 factors in terms of their content, their psychometric properties, and their compatibility with the general concept of musical sophistication. All items except two loaded positively on a single factor. The two negatively loading items were excluded from all further analyses. This initial version of the 6 subscales comprised between 7 and 20 items per subscale with values of Cronbach’s alpha ranging between .803 and .918.</p>
<p>Factor 1 comprised 20 items that covered a range of active musical engagement behaviours (e.g. “I keep track of new music that I come across”, “I often read or search the internet for things related to music”) as well as the deliberate allocation of time and money on musical activities (e.g. “I don’t spend much of my disposable income on music”, “I listen attentively to music for _ hours per day”). We therefore named this factor <italic>Active Engagement</italic>.</p>
<p>Factor 2 had 15 items, each representing the self-assessment of a cognitive musical ability, and most of them related to music listening skills (e.g. “I can compare and discuss differences between two performances or versions of a musical piece”, “I can tell when people sing or play out of tune”). We termed this factor <italic>Perceptual Abilities</italic>.</p>
<p>The 11 items of Factor 3 combined questions about the extent of musical training and practice (e.g. “I engaged in regular daily practice of a musical instrument including voice for __ years”, “At the peak of my interest I practised on my primary instrument including voice for __ hours per day”), and about the degree of self-assessed musicianship (“I would not consider myself a musician”, “I have never been complimented for my talents as a musical performer”). We termed this factor <italic>Musical Training</italic>.</p>
<p>Factor 4 consisted of seven items that reflected different skills and activities related to singing (e.g. “After hearing a new song two or three times I can usually sing it by myself”, “I am not able to sing in harmony when somebody is singing a familiar tune”) and was termed <italic>Singing Abilities</italic>.</p>
<p>Factor 5 had eight items describing reactive behaviours that are generally carried out in response to an external music source, and where subjects do not plan or seek out the behaviour in advance (e.g. “I hardly ever hum or sing along to music”, “I rarely tap or clap along when listening to music”, “When I hear a catchy tune I find myself moving to the beat”). Unlike the items of the other factors (e.g. Factor 2, <italic>Perceptual Abilities</italic>), the items of this factor did not suggest that behaviours could become more skilful or varied or sophisticated, rather that they happen more frequently. This is in line with the notion that we do not regard people to be more musically sophisticated merely when they find themselves tapping to music more frequently, but also when their tapping is more precise, accurate, or executed along with more complex stimuli. Also, the behaviours described by the items on Factor 5 all expressed rather reactive behaviours in response to incidental music listening rather than goal-directed active engagement with music, which seemed to go against the general idea of musical sophistication as a repertoire of skilled and adaptive behaviours that develop through active involvement with music. This view was supported by the fact that Factor 5 had a substantially lower association with the General Musical Sophistication factor than any other factor in the hierarchical structural equation model (parameter estimate<sub>factor 5</sub> = 1.03; mean estimate<sub>other factors</sub> = 1.48, CI<sub>95%</sub> = 1.09; 1.86). Thus, the items of this factor seemed to have little content validity and this factor was statistically less associated with the general factor. We therefore decided to discard Factor 5 and the items associated with it during the subsequent development of the self-report inventory.</p>
<p>Factor 6 had nine items associated with it that covered different and mainly active behaviours related to emotional responses to music (e.g. “I am able to talk about the emotions that a piece of music evokes in me”, “I sometimes choose music that can trigger shivers down my spine”). We termed this factor <italic>Emotions</italic>.</p>
<p>It is worth noting that Factors 1 (active engagement) and 3 (musical training) mainly comprise items that describe past or current music-related behaviour while Factor 2 (perceptual abilities), Factor 4 (singing abilities), and the new Factor 5 (emotions) mainly contain items where different aspects of a musical skill are self-assessed. Combining these two qualitatively different types of factor/items provides an assessment of musical sophistication that includes a quantifiable record of relevant behaviours potentially leading to the acquisition and refinement of skills, as well as subjective judgements regarding the skill level attained.</p>
<p>The goal of the refinement of the subscales was to reduce the number of items while retaining the good psychometric properties of each subscale. The item response theory approach <xref ref-type="bibr" rid="pone.0089642-Baker1">[78]</xref>–<xref ref-type="bibr" rid="pone.0089642-VanderLinden1">[79]</xref> was used to reduce the number of items per subscale. We fitted constrained and unconstrained graded response models (GRM) <xref ref-type="bibr" rid="pone.0089642-Samejima1">[80]</xref> to the items of each subscale using the training dataset (we used the R-package <italic>ltm</italic> for the GRM <xref ref-type="bibr" rid="pone.0089642-Rizopoulos1">[81]</xref>). In all cases, the unconstrained model (which lets the discrimination parameter vary across items) fitted the subscale data significantly better (<italic>p</italic>&lt;.001). For the unconstrained GRM of each subscale, we inspected the plots of the item information curves, the total test information value, the individual item information values, the item discrimination parameters, and the distribution of overall scores for the subscale. With the aim of reducing the number of items per subscale, we carried out the following analytical steps: a) a subset of items that covered the full range of the latent ability scale having high item information values were identified, b) items that contributed little in terms of the overall test information were excluded, and c) the item with the highest item information value was selected where items were overlapping in content. Following this procedure we arrived at considerably shorter scales that comprised between 6 and 9 items but maintained similar values of Cronbach’s alpha as an indicator of their reliabilities (ranging between .789 and .900, see Table S1 in <xref ref-type="supplementary-material" rid="pone.0089642.s001">File S1</xref> for the assignment of the 38 items to the five sub-scales).</p>
<p>In summary, the exploratory analysis presented in Study 1 identified a strong general factor of musical sophistication as well as 6 group factors, 5 of which were clearly compatible with the initial definition and overall notion of musical sophistication that arose from a comprehensive examination of the relevant literature. With the help of item response analysis, we were able to reduce the number of items in order to form shorter subscales. Despite the reduction in items, we were able to achieve good levels of reliability across all subscales. Study 2 used the test dataset (which had not been used to derive the factor structure of the inventory) to investigate whether the scale and subscale model would still achieve an acceptable model fit on a different set of data using a confirmatory approach.</p>
</sec></sec></sec><sec id="s3">
<title>Study 2: Assessing the Adequacy of the New Self-Report Inventory</title>
<p>The purpose of this study was to assess, on a new dataset, the unbiased fit of the reduced self-report inventory that was developed on the training dataset. In addition, we also tested the hypothesis that there was indeed a strong general factor of musical sophistication or, alternatively, that the data could be equally well accounted for by a simpler factor structure, not taking the relationships between factors into account. Therefore, we specified four models that differed both in complexity, and also in whether and how inter-factor correlations were accounted for.</p>
<sec id="s3a">
<title>Method</title>
<sec id="s3a1">
<title>Participants</title>
<p>The test dataset was used for this analysis. This dataset comprised 73,739 individuals of which 45.2% were female. The distributions of the countries of residence as well as the education levels and professions were highly similar to those reported above for the training dataset (the differences were in the order of 0.1%) and details are therefore not reported here.</p>
</sec><sec id="s3a2">
<title>Procedure</title>
<p>The procedure was identical to that used in Study 1.</p>
</sec></sec><sec id="s3b">
<title>Results and Discussion</title>
<p>We specified four models differing in their factor structure: Model 1 was specified as a hierarchical model where a general factor was hypothesised to impact on the five group level factors, which in turn were suggested to impact on the individual items associated with them. In terms of model complexity, this model requires 81 free parameters. Model 2 was the Schmid-Leiman transformed variant of the hierarchical model where the general factor is partialled out from the group factors and impacts directly on the 38 items in addition to the influence of the individual group factors. This model has 114 free parameters to estimate. Model 3 is a simple confirmatory factor analysis model without a general factor and where only the relations between group factors and items are modelled and therefore only 76 free parameters are required. Model 4 is similar to the non-hierarchical Model 3 but allows for factor inter-correlations between the five group factors and needs to estimate 86 parameters.</p>
<p>The χ<sup>2</sup> values of all models showed a highly significant departure from an exact fit, which is not surprising given the large sample size. Because the four models are not nested into each other, we used the Bayesian Information Criterion (BIC) to compare models which gave rise to the following order (from best to worst) Model 2&gt; Model 4&gt; Model 1&gt; Model 3.</p>
<p>Thus, in line with the high values of McDonald’s coefficient omega obtained on the training dataset in Study 1, we found that the three models that take into account the inter-factor relationships, either in the form of individual inter-factor correlations (see Table S2 in <xref ref-type="supplementary-material" rid="pone.0089642.s001">File S1</xref>) or modelled as a general factor, fitted the data significantly better than Model 3, which assumes independence between factors.</p>
<p>The approximate fit indices for Models 1, 2, and 4 indicate a reasonably good fit to the data in absolute terms. In addition, all parameters (regression coefficients, co-variances and variances) in Models 1, 2, and 4 were highly significant and in no instance did the value of a parameter’s standard error exceed the threshold of 1/n<sup>1/2</sup> as suggested by McDonald (<xref ref-type="bibr" rid="pone.0089642-McDonald2">[74]</xref> p.187). The fact that Model 2 (the Schmid-Leiman variant) fitted the data best suggests that its additional free parameters are justified to explain the structure in the data.</p>
<p>However, for the practical purposes of the development of a new inventory of musical sophistication, the difference in fit between Models 1, 2, and 4 has no consequences, except for the construction of a general scale of musical sophistication indexing the general factor. To this end we inspected the distribution of regression coefficients ordered by coefficient size from the 38 items onto the general factor in Model 2. The ordered distribution, which has a format similar to a screeplot, has several discontinuities and we decided to include items above a break in the plot that splits the number of items approximately in half. This led us to select 18 items with a coefficient above 0.88 to index musical sophistication in general. These 18 items were drawn from all five subscales but there was a clear preponderance of items from the Musical Training and the Singing Abilities subscales. The factor structure and regression coefficients of Model 2 are given in <xref ref-type="fig" rid="pone-0089642-g001">Figure 1</xref>.</p>
<fig id="pone-0089642-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g001</object-id><label>Figure 1</label><caption>
<title>Factor structure of reduced self-report inventory as formalised by model 2, the Schmid-Leiman variant of the confirmatory factor model.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g001" position="float" xlink:type="simple"/></fig>
<p>In summary, the results of Study 2 confirmed that the structural and measurement models of the self-report inventory developed in Study 1 hold true on an evaluation dataset and that our data on musical sophistication are best modelled using a general factor as well as 5 group factors to index different facets of musically sophisticated behaviour.</p>
</sec></sec><sec id="s4">
<title>Study 3: Reliability, Validity and Correlates of the Self-Report Inventory</title>
<p>Studies 1 and 2 developed and confirmed the adequacy of the item and factor structure of a new self-report inventory for musical sophistication. In Study 3, we looked at the reliability and validity of the new inventory in comparison with other music-related self-report scales as well as how it correlated with two short personality inventories <xref ref-type="bibr" rid="pone.0089642-Eysenck1">[82]</xref>–<xref ref-type="bibr" rid="pone.0089642-Gosling1">[83]</xref>, following suggestions that musical behaviour and engagement may be linked to certain dimensions of personality <xref ref-type="bibr" rid="pone.0089642-Rentfrow1">[84]</xref>.</p>
<p>However, as with self-report inventories for skills and abilities in other domains, it cannot be taken for granted that self-assessed and actual skill levels correlate highly, or indeed that they converge at all. For example, Paulhus, Lysy, and Yik <xref ref-type="bibr" rid="pone.0089642-Paulhus1">[85]</xref> found only low correlations (&lt;.3) between several self-report measures of intelligence and scores on an intelligence test. However, Furnham’s test of self-assessed multiple intelligences <xref ref-type="bibr" rid="pone.0089642-Furnham1">[86]</xref> achieved correlations of at least between.3 and.5 with standard intelligence tests <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic1">[87]</xref>. Reasons for the low correlations between self-assessed and actual levels of skill can be related to differences in the psychometric constructs compared, low levels of self-awareness in the particular domain, or an inappropriate frame of comparison for the self-assessment, as well as biases potentially introduced by social desirability, extreme levels of self-confidence, or other personality traits. Hence Study 3 also compares scores from the Gold-MSI self-report inventory with the performance on Gordon’s Advanced Measures of Audiation (AMMA) <xref ref-type="bibr" rid="pone.0089642-Gordon1">[10]</xref>, an established musical aptitude test that is widely used for evaluation and prediction of achievements in Western music education <xref ref-type="bibr" rid="pone.0089642-Young1">[88]</xref>–<xref ref-type="bibr" rid="pone.0089642-Gordon4">[93]</xref>, as well as in behavioural <xref ref-type="bibr" rid="pone.0089642-Ruthsatz1">[94]</xref>–<xref ref-type="bibr" rid="pone.0089642-Droves1">[95]</xref> and neuroscientific research <xref ref-type="bibr" rid="pone.0089642-Herdener1">[96]</xref>–<xref ref-type="bibr" rid="pone.0089642-Seppnen1">[97]</xref>.</p>
<p>Because we used different samples of participants we subdivided Study 3 into four sub-studies. Study 3a made use of the full (“BBC”) sample to derive data norms, as well as indicators of internal reliability for the five subscales and the general factor. Study 3b reports on the test-retest reliability of the self-report inventory over two different time intervals, as well as on correlations with the AMMA listening tests to assess external validity.</p>
<p>Study 3c also investigated the convergent validity of the self-report inventory by looking at correlations with the Musical Engagement Questionnaire (MEQ) <xref ref-type="bibr" rid="pone.0089642-Werner1">[22]</xref>. The MEQ was designed as a ‘broad-based questionnaire measuring the experience of music’ and assessing the spectrum of psychological facets of musical experiences (p. 331). The MEQ is not primarily concerned with the degree of sophistication of musical behaviours. However, the MEQ consists of six subscales, two of which can be hypothesised to measure constructs related to subscales of the Gold-MSI self-report inventory while we expected lower correlations for the other subscales.</p>
<p>Finally, Study 3d explored the relationships between the six sub-scales of musical sophistication and two standard personality inventories: the Ten-Item Personality Inventory (TIPI) <xref ref-type="bibr" rid="pone.0089642-Gosling1">[83]</xref> measuring the ‘Big Five’ personality traits as well as Eysenck’s <xref ref-type="bibr" rid="pone.0089642-Eysenck1">[82]</xref> 12-item extraversion scale. A number of studies in the past have found clear correlations between personality traits and measures of musical behaviour <xref ref-type="bibr" rid="pone.0089642-McCrae1">[98]</xref>–<xref ref-type="bibr" rid="pone.0089642-Vuoskoski1">[105]</xref>. Among the ‘Big Five’ personality traits, openness to experience has been suggested to be closely linked to musical engagement. Openness to experience can be understood as the desire to broaden the range of experience in a lifetime and individuals scoring high on this construct tend to have a good awareness of the arts <xref ref-type="bibr" rid="pone.0089642-McCrae1">[98]</xref>. Ample support has linked openness to experience with aesthetic interest in general <xref ref-type="bibr" rid="pone.0089642-McManus1">[99]</xref>–<xref ref-type="bibr" rid="pone.0089642-Furnham2">[100]</xref> and to music in particular. With regards to music, links with openness to experience have been discovered with the appreciation of unfamiliar music <xref ref-type="bibr" rid="pone.0089642-Hunter1">[101]</xref>, musical preferences <xref ref-type="bibr" rid="pone.0089642-Rentfrow1">[84]</xref>, <xref ref-type="bibr" rid="pone.0089642-Rentfrow2">[102]</xref>, musical listening styles <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic2">[103]</xref>, self-assessed musical intelligence <xref ref-type="bibr" rid="pone.0089642-Furnham1">[86]</xref>, and more diverse music tastes <xref ref-type="bibr" rid="pone.0089642-Ladinig1">[104]</xref>. In addition to this greater general engagement with the arts and music, openness to experience has also been suggested to correlate with greater emotional appreciation for aesthetic stimuli and music in particular. Vuoskoski and Eerola <xref ref-type="bibr" rid="pone.0089642-Vuoskoski1">[105]</xref> correlated ‘Big Five’ personality factors with the intensity of felt emotions in response to music and found that people scoring highly on openness to experience were more likely to experience the most powerful emotional reactions when listening to sad-sounding and gentle music. In addition to these strong links between music and openness to experience in the general population, there has been a considerable number of studies investigating the personality structure of accomplished performers. Several hypotheses have been put forward within this research strand, including the stereotype of the ‘bold introvert’ <xref ref-type="bibr" rid="pone.0089642-Kemp1">[106]</xref> (for a critique see <xref ref-type="bibr" rid="pone.0089642-Woody1">[107]</xref>), and personality differences between players of different instrumental groups, such as string players, brass players, or singers <xref ref-type="bibr" rid="pone.0089642-Builione1">[108]</xref>–<xref ref-type="bibr" rid="pone.0089642-Wilson1">[112]</xref>. However, possibly due to the lack of a valid and reliable measurement instrument, the relationship between personality and musical abilities in the general population has generally been overlooked so far.</p>
<sec id="s4a">
<title>Method</title>
<sec id="s4a1">
<title>Participants</title>
<p>For Study 3a we combined the data training- and test sets. This dataset comprised 147,633 participants, of which 45.2% were females. The distributions of the countries of residence as well as the education levels and professions only differed from the training dataset reported above in the order of 0.1% and are therefore not reported here.</p>
<p>For Study 3b, 53 participants took the self-report inventory twice in a controlled lab environment in two testing sessions that were scheduled 64 days apart on average (minimum of two weeks) to minimise memory effects. 44 of these participants were also tested on the AMMA musical listening test. Participants were mainly university students from Goldsmiths, University of London, as well as other higher education institutions in London. Of the 53 participants, 52.8% were males and mean age was 26.3 years (<italic>SD = </italic>9.6).</p>
<p>For Study 3c the MEQ and the Gold-MSI were administered to 141 participants who were recruited from the Goldsmiths undergraduate community and tested in a classroom environment in the summer and autumn of 2011. 73% were female and mean age was 21.3 years (<italic>SD = </italic>5.9).</p>
<p>Study 3d used the data from 224 participants who were assessed with a paper version of the TIPI personality inventory <xref ref-type="bibr" rid="pone.0089642-Gosling1">[83]</xref> as well as the musical sophistication self-report inventory. About half of the participants were undergraduate students at Goldsmiths while the other half were young adults from the London area. 73.2% were females and mean age was 24.6 years (<italic>SD = </italic>11.4). Several studies <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic3">[113]</xref>–<xref ref-type="bibr" rid="pone.0089642-Litle1">[116]</xref> found that Introversion-Extraversion correlates with aspects of musical behaviour but results with respect to the direction of the correlation are ambiguous. We therefore also included Eysenck’s <xref ref-type="bibr" rid="pone.0089642-Eysenck1">[82]</xref> more comprehensive Extraversion scale in addition to the 2-item extraversion short scale as part of the TIPI.</p>
</sec><sec id="s4a2">
<title>Procedure</title>
<p>The procedure of Study 3a was identical to that described in Study 1. In Study 3b the self-report inventory was administered on screen and in a controlled lab environment. As part of the two testing sessions, participants were tested on the AMMA musicality test as well as a range of other measures of cognitive ability (not reported here). Participants were remunerated with £20 for their participation after the second session.</p>
<p>For studies 3c and 3d participants were administered a paper version of the different self-report inventories and were not remunerated.</p>
</sec></sec><sec id="s4b">
<title>Results and Discussion</title>
<sec id="s4b1">
<title>Study 3a</title>
<p>We calculated three different (but related) measures of internal reliability (Cronbach’s alpha, McDonald’s omega total <xref ref-type="bibr" rid="pone.0089642-Zinbarg1">[76]</xref>, and Guttman’s lambda6 <xref ref-type="bibr" rid="pone.0089642-Guttman1">[117]</xref>) for the five subscales and the general musical sophistication scale. As <xref ref-type="table" rid="pone-0089642-t001">Table 1</xref> shows, all scales possess good or very good estimates of internal reliability. Thus, in terms of reliability the five subscales as well as the scale for general sophistication seem to be suitable for testing individual differences.</p>
<table-wrap id="pone-0089642-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t001</object-id><label>Table 1</label><caption>
<title>The fit statistics of the four structural equation models confirming the factor structure of the self-report inventory on the data test set (n = 73,739).</title>
</caption><alternatives><graphic id="pone-0089642-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Model 1</td>
<td align="left" rowspan="1" colspan="1">Model 2</td>
<td align="left" rowspan="1" colspan="1">Model 3</td>
<td align="left" rowspan="1" colspan="1">Model 4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">(Hierarchical)</td>
<td align="left" rowspan="1" colspan="1">(Schmid-Leiman)</td>
<td align="left" rowspan="1" colspan="1">(Simple Factor)</td>
<td align="left" rowspan="1" colspan="1">(Factor Inter-Correlations)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">?<sup>2</sup></td>
<td align="left" rowspan="1" colspan="1">215093</td>
<td align="left" rowspan="1" colspan="1">166170</td>
<td align="left" rowspan="1" colspan="1">382428</td>
<td align="left" rowspan="1" colspan="1">196363</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">df</td>
<td align="left" rowspan="1" colspan="1">660</td>
<td align="left" rowspan="1" colspan="1">627</td>
<td align="left" rowspan="1" colspan="1">665</td>
<td align="left" rowspan="1" colspan="1">665</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BIC</td>
<td align="left" rowspan="1" colspan="1">216001</td>
<td align="left" rowspan="1" colspan="1">167448</td>
<td align="left" rowspan="1" colspan="1">383279</td>
<td align="left" rowspan="1" colspan="1">197326</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">TLI</td>
<td align="left" rowspan="1" colspan="1">.841</td>
<td align="left" rowspan="1" colspan="1">.874</td>
<td align="left" rowspan="1" colspan="1">.718</td>
<td align="left" rowspan="1" colspan="1">.853</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CFI</td>
<td align="left" rowspan="1" colspan="1">.850</td>
<td align="left" rowspan="1" colspan="1">.884</td>
<td align="left" rowspan="1" colspan="1">.734</td>
<td align="left" rowspan="1" colspan="1">.863</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">RMSEA</td>
<td align="left" rowspan="1" colspan="1">.066</td>
<td align="left" rowspan="1" colspan="1">.060</td>
<td align="left" rowspan="1" colspan="1">.088</td>
<td align="left" rowspan="1" colspan="1">.064</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">SPMR</td>
<td align="left" rowspan="1" colspan="1">.068</td>
<td align="left" rowspan="1" colspan="1">.064</td>
<td align="left" rowspan="1" colspan="1">.276</td>
<td align="left" rowspan="1" colspan="1">.059</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Footnote. BIC = Bayesian Information Criterion, TLI = Tucker-Lewis Index, CFI = Bentler’s Comparative Fit Index, RMSEA = Root Mean Square Error of Approximation, SPMR = Standardized Root Mean Square Residual.</p></fn></table-wrap-foot></table-wrap>
<p><xref ref-type="table" rid="pone-0089642-t002">Table 2</xref> also gives the ranges, means, and standard deviations of the data norms derived from the subscale raw scores (using unit weighting of the items) for all five subscales as well as the general musical sophistication scale. The full data norms including all percentile scores are given in Table S3 in <xref ref-type="supplementary-material" rid="pone.0089642.s001">File S1</xref>.</p>
<table-wrap id="pone-0089642-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t002</object-id><label>Table 2</label><caption>
<title>Summary statistics and indicators of reliability for Gold-MSI subscales and general musical sophistication factor (n = 147,633).</title>
</caption><alternatives><graphic id="pone-0089642-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Active Engagement</td>
<td align="left" rowspan="1" colspan="1">Perceptual Abilities</td>
<td align="left" rowspan="1" colspan="1">Musical Training</td>
<td align="left" rowspan="1" colspan="1">Singing Abilities</td>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">General Sophistication</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Mean (SD)</td>
<td align="left" rowspan="1" colspan="1">41.52 (10.36)</td>
<td align="left" rowspan="1" colspan="1">50.20 (7.86)</td>
<td align="left" rowspan="1" colspan="1">26.52 (11.44)</td>
<td align="left" rowspan="1" colspan="1">31.67 (8.72)</td>
<td align="left" rowspan="1" colspan="1">34.66 (5.04)</td>
<td align="left" rowspan="1" colspan="1">81.58 (20.62)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Scale Maximum</td>
<td align="left" rowspan="1" colspan="1">63</td>
<td align="left" rowspan="1" colspan="1">63</td>
<td align="left" rowspan="1" colspan="1">49</td>
<td align="left" rowspan="1" colspan="1">49</td>
<td align="left" rowspan="1" colspan="1">42</td>
<td align="left" rowspan="1" colspan="1">126</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Scale Minimum</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">18</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">alpha</td>
<td align="left" rowspan="1" colspan="1">.872</td>
<td align="left" rowspan="1" colspan="1">.873</td>
<td align="left" rowspan="1" colspan="1">.903</td>
<td align="left" rowspan="1" colspan="1">.870</td>
<td align="left" rowspan="1" colspan="1">.791</td>
<td align="left" rowspan="1" colspan="1">.926</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">omega.tot</td>
<td align="left" rowspan="1" colspan="1">.874</td>
<td align="left" rowspan="1" colspan="1">.874</td>
<td align="left" rowspan="1" colspan="1">.904</td>
<td align="left" rowspan="1" colspan="1">.871</td>
<td align="left" rowspan="1" colspan="1">.792</td>
<td align="left" rowspan="1" colspan="1">.927</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">G6</td>
<td align="left" rowspan="1" colspan="1">.864</td>
<td align="left" rowspan="1" colspan="1">.867</td>
<td align="left" rowspan="1" colspan="1">.905</td>
<td align="left" rowspan="1" colspan="1">.866</td>
<td align="left" rowspan="1" colspan="1">.768</td>
<td align="left" rowspan="1" colspan="1">.938</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap></sec><sec id="s4b2">
<title>Study 3b</title>
<p>All test-retest correlations for the five subscales and the general factor were found to be very high (between.857 and.972) and significant as seen in <xref ref-type="table" rid="pone-0089642-t003">Table 3</xref>, which also reports the correlations between the dimensions of self-reported musical sophistication and the three scores (tonal, rhythm, total) from the AMMA listening test.</p>
<table-wrap id="pone-0089642-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t003</object-id><label>Table 3</label><caption>
<title>Test-retest correlation for subscales of the Gold-MSI self-report inventory.</title>
</caption><alternatives><graphic id="pone-0089642-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Test-retest correlations (n = 53)</td>
<td align="left" rowspan="1" colspan="1">AMMA tonal score(n = 44)</td>
<td align="left" rowspan="1" colspan="1">AMMA rhythm score(n = 44)</td>
<td align="left" rowspan="1" colspan="1">AMMA total score(n = 44)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Active Engagement</td>
<td align="left" rowspan="1" colspan="1">.899**</td>
<td align="left" rowspan="1" colspan="1">.368*</td>
<td align="left" rowspan="1" colspan="1">.427**</td>
<td align="left" rowspan="1" colspan="1">.414**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Perceptual Abilities</td>
<td align="left" rowspan="1" colspan="1">.894**</td>
<td align="left" rowspan="1" colspan="1">.486**</td>
<td align="left" rowspan="1" colspan="1">.485**</td>
<td align="left" rowspan="1" colspan="1">.510**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Musical Training</td>
<td align="left" rowspan="1" colspan="1">.974**</td>
<td align="left" rowspan="1" colspan="1">.412*</td>
<td align="left" rowspan="1" colspan="1">.420**</td>
<td align="left" rowspan="1" colspan="1">.433**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Singing Abilities</td>
<td align="left" rowspan="1" colspan="1">.940**</td>
<td align="left" rowspan="1" colspan="1">.393**</td>
<td align="left" rowspan="1" colspan="1">.438**</td>
<td align="left" rowspan="1" colspan="1">.430**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">.857**</td>
<td align="left" rowspan="1" colspan="1">.305*</td>
<td align="left" rowspan="1" colspan="1">.323*</td>
<td align="left" rowspan="1" colspan="1">.332**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">General Musical Sophistication</td>
<td align="left" rowspan="1" colspan="1">.972**</td>
<td align="left" rowspan="1" colspan="1">.463**</td>
<td align="left" rowspan="1" colspan="1">.502**</td>
<td align="left" rowspan="1" colspan="1">.503**</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt102"><label/><p>Footnote. Values of Pearson’s correlation coefficient are reported for test-retest reliability and correlations with the Advanced Measures of Musical Audiation (AMMA). *indicates a p-level of &lt;.05 and ** a level of &lt;.01.</p></fn></table-wrap-foot></table-wrap>
<p>The correlations between the self-report inventory and the test scores of the AMMA were all in the range of.30 to.51, which is in the upper range of what is usually reported as the correlation between a ‘paper-based’ self-report measure and actual perceptual or cognitive ability tests <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic1">[87]</xref>. In particular the high correlations between the AMMA scores and self-estimated perceptual abilities as well as the general musical sophistication scores are very encouraging and even suggest that the new self-report inventory can potentially serve as a surrogate when perceptual testing of musical abilities is not available.</p>
</sec><sec id="s4b3">
<title>Study 3c</title>
<p>According to Werner, Swope, and Heide <xref ref-type="bibr" rid="pone.0089642-Werner1">[22]</xref>, the six subscales of the MEQ are grouped into two larger scale factors. Factor 1 is termed “Subjective/Physical Reactions” and includes subscales Affective Reaction, Positive Psychotropic effects, and Reactive Musical Behaviour. MEQ’s Factor 2 is termed Active Involvement and subsumes subscales Commitment to Music, Innovative Musical Aptitude, Positive Psychotropic Effects, and Social Uplift. On the face of the definitions of the subscales given by Werner et al. (<xref ref-type="bibr" rid="pone.0089642-Werner1">[22]</xref> p.331), the MEQ’s Commitment to Music and Innovative Musical Aptitude scales seemed the most likely candidates to relate to the concept of musical sophistication in general, and to the Gold-MSI subscales Active Engagement and Musical Training in particular.</p>
<p>The correlations between the six MEQ subscales and the scales of the Gold-MSI are given in <xref ref-type="table" rid="pone-0089642-t004">Table 4</xref>.</p>
<table-wrap id="pone-0089642-t004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t004</object-id><label>Table 4</label><caption>
<title>Correlations between subscales from MEQ and Gold-MSI.</title>
</caption><alternatives><graphic id="pone-0089642-t004-4" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t004" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">ActiveEngagement</td>
<td align="left" rowspan="1" colspan="1">PerceptualAbilities</td>
<td align="left" rowspan="1" colspan="1">MusicalTraining</td>
<td align="left" rowspan="1" colspan="1">SingingAbilities</td>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">GeneralSophistication</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Commitment to Music</td>
<td align="left" rowspan="1" colspan="1">.241**</td>
<td align="left" rowspan="1" colspan="1">.206*</td>
<td align="left" rowspan="1" colspan="1">.223*</td>
<td align="left" rowspan="1" colspan="1">.292**</td>
<td align="left" rowspan="1" colspan="1">.255**</td>
<td align="left" rowspan="1" colspan="1">.309**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Innovative Musical Aptitude</td>
<td align="left" rowspan="1" colspan="1">.203*</td>
<td align="left" rowspan="1" colspan="1">.319**</td>
<td align="left" rowspan="1" colspan="1">.395**</td>
<td align="left" rowspan="1" colspan="1">.422**</td>
<td align="left" rowspan="1" colspan="1">.189*</td>
<td align="left" rowspan="1" colspan="1">.449**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Social Uplift</td>
<td align="left" rowspan="1" colspan="1">.111</td>
<td align="left" rowspan="1" colspan="1">.168</td>
<td align="left" rowspan="1" colspan="1">.139</td>
<td align="left" rowspan="1" colspan="1">.289**</td>
<td align="left" rowspan="1" colspan="1">.159</td>
<td align="left" rowspan="1" colspan="1">.229*</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Positive Psychotropic Effects</td>
<td align="left" rowspan="1" colspan="1">.181*</td>
<td align="left" rowspan="1" colspan="1">.200*</td>
<td align="left" rowspan="1" colspan="1">.198*</td>
<td align="left" rowspan="1" colspan="1">.300**</td>
<td align="left" rowspan="1" colspan="1">.237**</td>
<td align="left" rowspan="1" colspan="1">.282**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Affective Reactions</td>
<td align="left" rowspan="1" colspan="1">.076</td>
<td align="left" rowspan="1" colspan="1">.146</td>
<td align="left" rowspan="1" colspan="1">.142</td>
<td align="left" rowspan="1" colspan="1">.222*</td>
<td align="left" rowspan="1" colspan="1">.142</td>
<td align="left" rowspan="1" colspan="1">.182*</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Reactive Musical Behaviour</td>
<td align="left" rowspan="1" colspan="1">.126</td>
<td align="left" rowspan="1" colspan="1">.195*</td>
<td align="left" rowspan="1" colspan="1">.198*</td>
<td align="left" rowspan="1" colspan="1">.312**</td>
<td align="left" rowspan="1" colspan="1">.159</td>
<td align="left" rowspan="1" colspan="1">.264**</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt103"><label/><p>Footnote. Values of Pearson’s correlation coefficient are reported for correlations between the six dimensions (rows) of the Music Experience Questionnaire (MEQ) and the 5+1 dimensions of the Gold-MSI. * indicates a p-level of &lt;.05 and ** a level of &lt;.01.</p></fn></table-wrap-foot></table-wrap>
<p>All correlations between the subscales of the musical self-report inventories were of a low to moderate magnitude, which indicates that the inventories measure somewhat related, but certainly not identical constructs. Among all MEQ subscales, the Innovative Musical Aptitude scale, which includes ‘self-reports of musical performance ability’, is the one that correlated most highly with Gold-MSI subscales. This is not surprising since this is the only subscale that assesses self-reported abilities and skills at different levels. As expected, it correlated with General Musical Sophistication, and Musical Training as well as Singing Abilities, but only at a moderate level of about.4. While the MEQ’s Commitment to Music showed significant correlations with all Gold-MSI subscales, it had only a very moderate, albeit significant correlation, with the Gold-MSI’s Active Engagement scale (<italic>r</italic> = .241). The correlation between the Gold-MSI Emotions subscale and the MEQ’s Affective Reactions reached only.142 and was not significant, suggesting that the skills of emotional usage of music measured by the Gold-MSI are only weakly related to the more passive Affective Reactions measured by the MEQ.</p>
<p>Overall the results from Study 3c suggest convergent validity with the MEQ subscale <italic>Innovative Musical Aptitude</italic>, and discriminant validity with regards to constructs that clearly have little in common with the concept of musical sophistication, as indicated for example by the low correlations with the MEQ subscales Social Uplift, Affective Reactions, and Reactive Musical Behaviour, despite the fact that both inventories operate in the same domain.</p>
</sec><sec id="s4b4">
<title>Study 3d</title>
<p>The pattern of correlations between the five Gold-MSI subscales/general factor and the ‘Big Five’ from the TIPI is given in <xref ref-type="table" rid="pone-0089642-t005">Table 5</xref>.</p>
<table-wrap id="pone-0089642-t005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t005</object-id><label>Table 5</label><caption>
<title>Correlations between ‘Big Five’ personality traits as measured by the TIPI and Eysenck’s Extraversion scale and the subscales of the Gold-MSI self-report inventory.</title>
</caption><alternatives><graphic id="pone-0089642-t005-5" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t005" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">M (SD)</td>
<td align="left" rowspan="1" colspan="1">ActiveEngagement</td>
<td align="left" rowspan="1" colspan="1">PerceptualAbilities</td>
<td align="left" rowspan="1" colspan="1">MusicalTraining</td>
<td align="left" rowspan="1" colspan="1">SingingAbilities</td>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">GeneralSophistication</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Big Five</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Extraversion</td>
<td align="left" rowspan="1" colspan="1">9.2 (2.9)</td>
<td align="left" rowspan="1" colspan="1">.204**</td>
<td align="left" rowspan="1" colspan="1">.281**</td>
<td align="left" rowspan="1" colspan="1">.266**</td>
<td align="left" rowspan="1" colspan="1">.343**</td>
<td align="left" rowspan="1" colspan="1">.181*</td>
<td align="left" rowspan="1" colspan="1">.325**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Agreeableness</td>
<td align="left" rowspan="1" colspan="1">10.0 (2.3)</td>
<td align="left" rowspan="1" colspan="1">.103</td>
<td align="left" rowspan="1" colspan="1">.187**</td>
<td align="left" rowspan="1" colspan="1">.102</td>
<td align="left" rowspan="1" colspan="1">.188*</td>
<td align="left" rowspan="1" colspan="1">.136*</td>
<td align="left" rowspan="1" colspan="1">.177*</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Conscientiousness</td>
<td align="left" rowspan="1" colspan="1">10.0 (2.9)</td>
<td align="left" rowspan="1" colspan="1">−.128</td>
<td align="left" rowspan="1" colspan="1">−.076</td>
<td align="left" rowspan="1" colspan="1">−.117</td>
<td align="left" rowspan="1" colspan="1">−.123</td>
<td align="left" rowspan="1" colspan="1">−.161*</td>
<td align="left" rowspan="1" colspan="1">−.164*</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Emotional Stability</td>
<td align="left" rowspan="1" colspan="1">9.0 (2.8)</td>
<td align="left" rowspan="1" colspan="1">.083</td>
<td align="left" rowspan="1" colspan="1">.180*</td>
<td align="left" rowspan="1" colspan="1">.131</td>
<td align="left" rowspan="1" colspan="1">.132</td>
<td align="left" rowspan="1" colspan="1">.035</td>
<td align="left" rowspan="1" colspan="1">.159*</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Openness</td>
<td align="left" rowspan="1" colspan="1">10.6 (2.3)</td>
<td align="left" rowspan="1" colspan="1">.392**</td>
<td align="left" rowspan="1" colspan="1">.361**</td>
<td align="left" rowspan="1" colspan="1">.296**</td>
<td align="left" rowspan="1" colspan="1">.326**</td>
<td align="left" rowspan="1" colspan="1">.409**</td>
<td align="left" rowspan="1" colspan="1">.428**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Eysenck</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Extraversion</td>
<td align="left" rowspan="1" colspan="1">8.2 (2.3)</td>
<td align="left" rowspan="1" colspan="1">.325**</td>
<td align="left" rowspan="1" colspan="1">.307**</td>
<td align="left" rowspan="1" colspan="1">.186*</td>
<td align="left" rowspan="1" colspan="1">.438**</td>
<td align="left" rowspan="1" colspan="1">.282**</td>
<td align="left" rowspan="1" colspan="1">.345**</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt104"><label/><p>Footnote. For all correlations n = 224, except for those involving Singing Abilities, where n = 161 due to a technical error. Means and standard deviations of the summed personality scores (range TIPI: 2–14, range Eysenck: 0–12) are also given. * indicates a p-level of &lt;.05 and ** a level of &lt;.01.</p></fn></table-wrap-foot></table-wrap>
<p><xref ref-type="table" rid="pone-0089642-t005">Table 5</xref> demonstrates an interesting pattern of relationships between personality traits and aspects of musical abilities. Openness and Extraversion seem to be at least moderately related to all facets of musical sophistication and almost all correlations were highly significant. The extraversion scale from the TIPI and from Eysenck’s scale yielded very similar results, both correlating positively with all aspects of musical sophistication. Thus, for our sample of non-specialists we cannot find any support for the notion that higher levels of introversion help the development of musical abilities <xref ref-type="bibr" rid="pone.0089642-Kemp4">[118]</xref>. Interestingly, conscientiousness showed a negative, albeit very low, correlation with all facets of musical sophistication that does not support the wide-spread belief that skilful engagement with music requires a high degree of conscientiousness. Agreeableness and Emotional Stability were positively related to musical sophistication but correlations were generally lower than for Extraversion and Openness. The high correlation between Openness and musical sophistication is in line with the fact that Openness is commonly found to be the strongest correlate with achievements in tests of cognitive ability <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic1">[87]</xref>, and is also very much in line with the literature discussed above that highlights the close links between musical engagement and Openness, almost to a degree where musical behaviour becomes a constituent of this personality trait.</p>
<p>Taken together, the data of Study 3d suggest that individuals who are open to new experiences and rank highly on extraversion possess high levels of musical sophistication. It is however unclear whether openness and extraversion are a cause or effect of more frequent and more intense musical behaviours, along with the resulting higher levels of musical sophistication.</p>
</sec></sec></sec><sec id="s5">
<title>Study 4: Self-Reported Musical Sophistication and Objective Listening Tests in a Large Sample</title>
<p>The Gold-MSI self-report inventory measures self-assessed levels of musical abilities, skills, and the degree of sophistication in musical behaviours. In Studies 1 to 3 we showed that the Gold-MSI has good psychometric properties with regards to the content validity of its individual items, the construct validity of its subscales as tested on a very large sample, the test-retest reliability, and with regards to concurrent and discriminant validity as evidenced by the correlations with other related and less related scales and musicality tests. In addition, we have been able to gain some insight into the relationships that musical sophistication has with other psychological constructs such as personality traits and general musical behaviours.</p>
<p>Having obtained a valid and reliable self-report measure of sophisticated musical behaviour, our next goal was to investigate which musical production and perception skills benefit from, or are at least associated with, which musical behaviours. Hence Study 4 compared scores from the Gold-MSI self-report inventory with the results of two specific listening tests across a large sample to assess the correlation between musical abilities and self-reported levels of musical sophistication. The two listening tests were chosen to assess distinct musical abilities that can be thought of as being very different but similarly important musical skills, namely melodic memory and musical beat perception. The nature of this set of tests is different from educational musical aptitude tests, such as the AMMA used above, which aim to test the general aptitude of students for musical achievement (in traditional Western music education).</p>
<p>In contrast with the AMMA, the two tests reported here relied mostly on excerpts from naturalistic musical stimuli. Both tasks test the ability to focus on a certain musical parameter (i.e. pitch interval structure, the musical beat) in the context of many other concurrent musical parameters. Neither of the response procedures required specialist music knowledge, which made the tests suitable for the general adult population. Both tests were modelled on well-known test procedures from the music cognition literature where the underlying cognitive mechanisms and experimental factors that affect test scores are well-understood (see descriptions and references to prior studies for each test in the Method section below).</p>
<sec id="s5a">
<title>Method</title>
<sec id="s5a1">
<title>Participants</title>
<p>We used the combined training- and test datasets which comprised all 148,119 participants (with useable data) who had taken the BBC’s <italic>How Musical Are You?</italic> online test in 2011. Whereas almost all participants had completed the self-report inventory (n = 148,037), we had slightly fewer participants for the two listening tests, namely 139,481 for the beat perception test, and 138,469 for the melodic memory test. 134,984 participants provided complete data for all two tests plus the self-report inventory. In fact, the participants of the <italic>How Musical Are You?</italic> online test also took a sound similarity as well as a beat production test, the results of which are not reported in this current paper.</p>
<p>The demographic statistics of the subset of participants used in Study 4 are virtually identical to the figures given in Study 1. In addition, a study was carried out to assess test-retest reliability and concurrent validity with the relevant subscales from the self-report inventory under more controlled conditions. 48 (test session) and 39 (retest session) participants were tested through an online interface at their homes. 34 individuals (16 women) with a mean age of 36.9 year (<italic>SD</italic> = 15.1) completed both test sessions which were 23 days apart on average (<italic>SD</italic> = 9.2, range: 10 to 64 days).</p>
</sec><sec id="s5a2">
<title>Melodic memory test: materials and procedure</title>
<p>Memory for melodies and tone sequences has been tested extensively for more than 50 years (see <xref ref-type="bibr" rid="pone.0089642-White1">[119]</xref> for an early paper, and see <xref ref-type="bibr" rid="pone.0089642-Halpern1">[120]</xref> for a recent summary). In addition, most established musical aptitude tests include a melody memory subtest as a core component <xref ref-type="bibr" rid="pone.0089642-Hyde1">[7]</xref>, <xref ref-type="bibr" rid="pone.0089642-Bentley1">[9]</xref>–<xref ref-type="bibr" rid="pone.0089642-Seashore1">[11]</xref>, <xref ref-type="bibr" rid="pone.0089642-Wing2">[121]</xref>. A very common paradigm is based on a same-different comparison of two short melodies, where participants have to judge whether the two melodies played successively are identical or different (in one or more notes). Thanks to the large number of publications using this paradigm, the cognitive mechanisms and determinants of melodic memory are fairly well understood <xref ref-type="bibr" rid="pone.0089642-Bartlett1">[122]</xref>. The test battery is inspired by the cognitive paradigms used by Cuddy and Lyons <xref ref-type="bibr" rid="pone.0089642-Cuddy2">[123]</xref> as well as Dowling and Bartlett <xref ref-type="bibr" rid="pone.0089642-Bartlett1">[122]</xref>. Based on their findings, we designed a set of stimuli that balance several factors that have been shown to influence melodic memory, i.e. preservation of the contour of the intervallic structure vs. violations of contour, in-key vs. out-of-key errors, and near key vs. far key transposition distance (along the circle of fifths). The test battery uses the same AB comparison paradigm that has been used in previous cognitive studies <xref ref-type="bibr" rid="pone.0089642-Bartlett1">[122]</xref>: each item consisted of two short melodies (containing between 10 and 17 notes) with the second melody always transposed and presented at a different pitch level than the first one. Harmonic distance, as measured on the cycle of fifths, was balanced across trials by presenting the second melody transposed either by a fifth or by a semitone. Participants were required to indicate whether the two tunes had an identical pitch interval structure or not, and to rate the confidence of their judgement on a 3-point scale (“I’m totally sure”, “I think so”, “I’m guessing”). Confidence ratings were not used for the derivation of the participants’ accuracy or d’ scores. 12 melody items were newly created following the approach described by Halpern, Bartlett, and Dowling <xref ref-type="bibr" rid="pone.0089642-Halpern2">[124]</xref> for generating novel melodic stimuli on the basis of the distributions for pitch intervals and tone durations from existing and well-known Western folksongs. The 12 trials consisted of 6 different- and 6 same-tune trials. The manipulations of the 6 different-tune trials comprised three melody items where melodic contour (and interval) was changed and three items where contour was preserved and only the pitch interval structure was changed. All manipulated items had two notes changed and overall item difficulty was calibrated in a small pilot sample. Participants were presented with two training items at the beginning of the test where the concept of transposition was explained in lay terms and the correct answer was given for each item. Items were screened individually for their contribution to the reliability of the overall test which led to the exclusion of one item that contributed negatively to the tests’ reliability as measured by Cronbach’s alpha. The alpha coefficients from the test and the retest sessions were.61 and.68 for the resulting 11-item testset. Test-retest reliability was computed from the participants’ <italic>d’</italic> test scores using Pearson’s r and Spearman’s rho correlation coefficients as well as the single-measure intra-class correlation coefficient (ICC) with a 2-way random model with absolute agreement (ICC = .54, <italic>r</italic> = .57, rho = .60, all <italic>p</italic>&lt;.001). The psychometric properties of the melodic memory and beat perception tests have subsequently been optimised since the <italic>How Musical Are You?</italic> data were collected. As a result of several lab studies we have been able to create versions of the tests that are shorter in length and have better psychometric properties. The details of the test optimisations and results from the lab studies are currently being written-up in separate manuscripts. Therefore, for use in future research we recommend using the optimised versions of the tests, which have been compiled as version 1.0 of the Gold-MSI test battery and are fully documented and freely available from <ext-link ext-link-type="uri" xlink:href="http://www.gold.ac.uk/music-mind-brain/gold-msi/" xlink:type="simple">http://www.gold.ac.uk/music-mind-brain/gold-msi/</ext-link>. For more details on individual stimulus generation and all stimuli in music notation see Müllensiefen et al. <xref ref-type="bibr" rid="pone.0089642-Mllensiefen1">[65]</xref>.</p>
</sec><sec id="s5a3">
<title>Beat perception test: materials and procedure</title>
<p>Beat perception was assessed via a newly created variant of the Beat Alignment Test <xref ref-type="bibr" rid="pone.0089642-Iversen1">[125]</xref>. The test required participants to listen to 18 short instrumental excerpts (10–16 seconds). Tracks were overlaid with a metronome-like beep track that was exactly on the implied beat of the music for half of the items, or manipulated in one of three ways for the other half of the items: phase shift by 10% or 17.5% of the beat period, or tempo alteration by 2% relative to the beat of the music track. The participants’ task was to indicate whether the beep track coincided with the beat of the music or not, and to rate their confidence on the same scale used for the melody memory task (again, confidence ratings were not used for the derivation of the participants’ accuracy or d’ scores). The 18 tracks were taken from 9 different musical pieces belonging to three different genres (rock, jazz, and popular classical). The tempo of the musical pieces varied between 85 and 165 beats per minute. Six of the musical pieces were in duple meter while three items (one from each genre) were in triple meter. Items were screened individually for their contribution to the reliability of the overall test which led to the exclusion of three items that contributed negatively to the tests’ reliability as measured by Cronbach’s alpha. For the 15-item testset, the alpha coefficients from the test and the retest sessions were.87 and.92. Test-retest reliability was computed from the <italic>d’</italic> scores (ICC = .63, <italic>r</italic> = 70, rho = 72, all <italic>p</italic>&lt;.001). Again, for use in future research we recommend using the optimised versions of the beat perception test which is part of version 1.0 of the Gold-MSI test battery and fully documented and freely available from <ext-link ext-link-type="uri" xlink:href="http://www.gold.ac.uk/music-mind-brain/gold-msi/" xlink:type="simple">http://www.gold.ac.uk/music-mind-brain/gold-msi/</ext-link>. For links to the soundfiles of the nine original music pieces see Müllensiefen et al. <xref ref-type="bibr" rid="pone.0089642-Mllensiefen1">[65]</xref>.</p>
</sec></sec><sec id="s5b">
<title>Results and Discussion</title>
<p>For both tests, the overall mean accuracy scores were in a middle range between chance level (50% accuracy) and a perfect score. For the melodic memory test mean accuracy was.75 (<italic>SD</italic> = .17) and <italic>d’</italic>, a bias-free measure of performance, was at 1.55 (<italic>SD</italic> = 1.10). Mean accuracy for the beat perception task was.77 (<italic>SD</italic> = .16) and <italic>d’</italic> was 1.70 (<italic>SD</italic> = 1.19). Accuracy and <italic>d’</italic> scores for were highly correlated (<italic>r</italic> &gt;.98) for both tasks. We therefore mainly report the conceptually simpler accuracy scores in the following results.</p>
<p>The correlation between the performances on both tests was very moderate (<italic>r</italic> = .26 for the accuracy scores and <italic>r</italic> = .27 for the <italic>d’</italic> scores), indicating that the two tests largely measure different abilities. The correlation between the performances on both tests was very moderate (<italic>r</italic> = .26 for the accuracy scores and <italic>r</italic> = .27 for the <italic>d’</italic> scores), indicating that the two tests largely measure different abilities. This low correlation between the two tests does not suggest the creation of a combined sum-score for measuring general musical sophistication from perceptual tests. In addition, we believe that musical sophistication is a broader psychological attribute that comprises more than melodic memory and beat perception ability and, while we are ultimately interested in a single perceptual index, we will explore carefully in a future study with a more comprehensive perceptual test battery whether the perceptual data can be modeled with the help of a general musical sophistication latent factor.</p>
<p><xref ref-type="table" rid="pone-0089642-t006">Table 6</xref> shows the correlation between the scales of the self-report inventory and the scores on the listening tests. The table contains the correlations from the large online sample as well as from the smaller sample of the test-retest study.</p>
<table-wrap id="pone-0089642-t006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t006</object-id><label>Table 6</label><caption>
<title>Correlations between sub-scales of the self-report inventory and performance on the two listening tests.</title>
</caption><alternatives><graphic id="pone-0089642-t006-6" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t006" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Active Engagement</td>
<td align="left" rowspan="1" colspan="1">Perceptual Abilities</td>
<td align="left" rowspan="1" colspan="1">Musical Training</td>
<td align="left" rowspan="1" colspan="1">Singing Abilities</td>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">General Sophistication</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Listening Tests</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Online Sample</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Melodic Memory</td>
<td align="left" rowspan="1" colspan="1">.103***</td>
<td align="left" rowspan="1" colspan="1">.261***</td>
<td align="left" rowspan="1" colspan="1">.301***</td>
<td align="left" rowspan="1" colspan="1">.259***</td>
<td align="left" rowspan="1" colspan="1">.128***</td>
<td align="left" rowspan="1" colspan="1">.285***</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Beat Perception</td>
<td align="left" rowspan="1" colspan="1">.224***</td>
<td align="left" rowspan="1" colspan="1">.342***</td>
<td align="left" rowspan="1" colspan="1">.356***</td>
<td align="left" rowspan="1" colspan="1">.305***</td>
<td align="left" rowspan="1" colspan="1">.218***</td>
<td align="left" rowspan="1" colspan="1">.375***</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Test-Retest Sample</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Melodic Memory</td>
<td align="left" rowspan="1" colspan="1">.344*</td>
<td align="left" rowspan="1" colspan="1">.407*</td>
<td align="left" rowspan="1" colspan="1">.521**</td>
<td align="left" rowspan="1" colspan="1">.358*</td>
<td align="left" rowspan="1" colspan="1">.423**</td>
<td align="left" rowspan="1" colspan="1">.511**</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Beat Perception</td>
<td align="left" rowspan="1" colspan="1">.216</td>
<td align="left" rowspan="1" colspan="1">.325</td>
<td align="left" rowspan="1" colspan="1">.354*</td>
<td align="left" rowspan="1" colspan="1">.353*</td>
<td align="left" rowspan="1" colspan="1">.308</td>
<td align="left" rowspan="1" colspan="1">.379*</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt105"><label/><p>Footnote. Sample sizes differed slightly between bivariate correlations from the online sample and ranged from n = 136,924 to n = 139,062. Sample size for the test-retest sample was n = 34.</p></fn></table-wrap-foot></table-wrap>
<p>As expected, the highest correlations were obtained with the musical training and perceptual abilities subscales, as well as with the general musical sophistication scale. In particular, the correlations of self-reported general musical sophistication with beat perception (<italic>r</italic> = .38) and melodic memory performance (<italic>r</italic> = .51) obtained from the test-retest sample indicate a convergent validity of self-report inventory and perceptual tests. The magnitude of these correlations is in a similar range to the correlations between self-report inventory and the scores on the AMMA musicality test in Study 3b (<italic>r</italic> = .50 for General Musical Sophistication and AMMA rhythm score and <italic>r</italic> = .46 for General Musical Sophistication and AMMA tonal score, see <xref ref-type="table" rid="pone-0089642-t003">Table 3</xref>). This suggests that the lower correlations obtained from the large online sample are at least partly due to the difference in testing conditions. We had no control over the conditions under which the large sample of participants of the <italic>How Musical Are You?</italic> study took the listening tests. A decrease in effect size between controlled lab experiments and uncontrolled online studies is fairly common and has been reported repeatedly <xref ref-type="bibr" rid="pone.0089642-Birnbaum1">[126]</xref>–<xref ref-type="bibr" rid="pone.0089642-Reimers1">[129]</xref>. However, in practice the greater amount of noise in online data is often compensated for by larger sample sizes. Indeed, the sample size of the <italic>How Musical Are You?</italic> study is several orders of magnitude larger than both the sample from Study 3b, and also the test-retest study validating the two listening tests.</p>
<p>We derived a structural equation model from the correlations between the five dimensions of musical sophistication and the scores on the two listening tests. The model included all inter-subscale and inter-test correlations as well as paths from all 5 subscales to each listening test. We removed two paths with non-significant parameter estimates and the resulting model fitted the data extremely well (χ<sup>2</sup> = 1.92, df = 2, <italic>p</italic> = .384; TLI = 1, CFI = 1, RMSEA &lt;.001, SPMR &lt;.001), and is graphically depicted in <xref ref-type="fig" rid="pone-0089642-g002">Figure 2</xref>.</p>
<fig id="pone-0089642-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g002</object-id><label>Figure 2</label><caption>
<title>Structural equation model relating subscales of the self-report inventory to performance scores on the two listening tests.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g002" position="float" xlink:type="simple"/></fig>
<p>As the regression weights in <xref ref-type="fig" rid="pone-0089642-g002">Figure 2</xref> show, Musical Training and Perceptual Abilities have relatively strong relations with the beat perception and melody memory tests. Performance on both tests clearly benefits from the amount of musical training an individual has had. Self-reported perceptual abilities also have a significantly positive relation with performance on the two listening tests and, as expected, singing abilities are also positively related to melodic memory performance, but only to a small degree to beat perception. Interestingly, the influence of active engagement and emotional musical sophistication on melodic memory scores is negative once the influence of all other dimensions of musical sophistication is controlled for. This suggests that detecting fine differences between different versions of the same melody is a skill that depends to a large degree on instrumental training and conversely, that high levels of listening engagement and a focus on the emotional functions of music might not be helpful when the task is to focus on subtle differences in melodic structure.</p>
<p>We constructed a second structural equation model relating General Musical Sophistication to the performance on the two listening tests. The model fitted the data very well (indices were indicating essentially a perfect fit) and is graphically shown in <xref ref-type="fig" rid="pone-0089642-g003">Figure 3</xref>. General Musical Sophistication was positively related to both listening tasks and relatively strong regression coefficients were obtained for beat perception (.37) and melodic memory (.28), while the correlation between both tests after accounting for self-reported General Musical Sophistication was fairly low (.16).</p>
<fig id="pone-0089642-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g003</object-id><label>Figure 3</label><caption>
<title>Structural equation model demonstrating the influence of self-reported general musical sophistication on the performance on the objective listening tasks.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g003" position="float" xlink:type="simple"/></fig>
<p>In summary, the results of Study 4 show that the general musical sophistication scale indexes both listening tasks positively, and we can hence speak of a coherent set of tests. This is despite the fact that the two tasks measure very different musical skills.</p>
</sec></sec><sec id="s6">
<title>Study 5: The Socio-Demographic Conditions of Musical Sophistication</title>
<p>Studies 1 to 3 established a new self-report inventory of musical sophistication while Study 4 compared self-reported musical skills and behaviours to objective tests of two different musical abilities. The aim of Study 5 was to determine the degree to which musical sophistication and performance on the listening tests are associated with socio-demographic variables once the degrees of musical training and of active engagement with music have been controlled for. We used the large sample gathered from the BBC’s <italic>How Musical Are You?</italic> online implementation. This implementation did not include a formal inventory of socio-economic status (SES), but it comprised several questions covering the social context of participants as well as aspects of education and occupation as core constituents of SES. With regards to wealth as the third chief constituent of SES, we were able to aggregate participants’ scores from the <italic>How Musical Are You?</italic> test at the level of British local authorities and compare them to income data available from the UK Office for National Statistics. In general, it is unclear whether there is a causal relationship between musical sophistication and socio-economic variables and what the directions of causes and effects are <xref ref-type="bibr" rid="pone.0089642-Schellenberg1">[130]</xref>. Thus, in the following analysis we alternate between a strictly correlational description and an analytical perspective in which musical sophistication represents the dependent variable and socio-economic factors act as independent predictors.</p>
<sec id="s6a">
<title>Method</title>
<sec id="s6a1">
<title>Participants</title>
<p>In order to work with a culturally homogeneous sample, we selected for this study only those 90,474 participants from the large Internet sample who had indicated that they were currently residing in the UK, and had spent the formative years of their childhood and youth in the UK. The mean age of the selected participants was 37.2 years (<italic>SD</italic> = 15.2) and 43.6% were female. For 70,097 of the British participants we had a valid postcode (with the last two digits truncated to preserve anonymity), and this allowed us to average participants’ test scores at the level of 379 local authorities in England, Scotland and Wales.</p>
</sec><sec id="s6a2">
<title>Materials and methods</title>
<p>Apart from age and gender, participants indicated the highest level of education obtained (6 categories) and/or the highest level of education they were expecting to achieve (5 categories), their ethnic group (9 categories), their occupational status (8 categories) and their occupation (24 categories). In addition to these socio-economic variables, we also included the subscale scores for musical training and active engagement as predictor variables.</p>
<p>These predictor variables were related to scores on the General Musical Sophistication factor and to the scores from the two listening tests described in Study 4. We split the sample of participants into a training- (n = 45,647) and a test (n = 45,482) dataset, and analysed the association of musical sophistication with socio-economic variables in three analysis steps.</p>
<p>First, we ran a random forest regression (using the R package <italic>randomForest</italic> for the computations <xref ref-type="bibr" rid="pone.0089642-Liaw1">[131]</xref>) on the training dataset to determine the relative importance of each socio-economic variable in predicting musical sophistication (see <xref ref-type="bibr" rid="pone.0089642-Breiman1">[132]</xref>, for the initial concept of random forest classification and regression, and <xref ref-type="bibr" rid="pone.0089642-Hastie1">[133]</xref> for a summary overview). Random forests are able to make use of information in ‘weaker’ explanatory variables, in that they model complex variable interactions. They also have the additional advantage that results can be generalised to new datasets, because they do not tend to overfit on training data <xref ref-type="bibr" rid="pone.0089642-Breiman2">[134]</xref>. As a second analysis step we used conditional inference significance tests, implemented in the R package <italic>coin</italic> <xref ref-type="bibr" rid="pone.0089642-Hothorn1">[135]</xref> and based on permutation statistics <xref ref-type="bibr" rid="pone.0089642-Hothorn2">[136]</xref>, as post-hoc tests to identify the categories within these variables for which significant main effects could be observed. Permutation tests do not make any distributional assumptions, but take the shape of the empirical distribution into account and are therefore not affected by large sample sizes or skewed distributions. We adjusted <italic>p</italic>-values for multiple comparisons using the ‘single-step’ procedure suggested by Westfall and Young <xref ref-type="bibr" rid="pone.0089642-Westfall1">[137]</xref>. In the third analysis step, the test dataset served to confirm the results derived from the training dataset and to summarise them in easily interpretable tree models based on recursive partitioning <xref ref-type="bibr" rid="pone.0089642-Strobl1">[138]</xref>.</p>
<p>In sum the three analysis steps deliver different insights into this large and complex dataset: the random forest model indicates the importance of each variable, taking into account main effects as well as all complex variable interactions, whereas the permutation tests inform about the positive or negative main effects of each variable, and the tree model synthesises both approaches by picking the most important variables and partitioning the data into homogeneous subsets. Thus, the latter approach models interactions and indicates which combination of variables (or categories of variables) leads to higher versus lower musical sophistication and performance scores.</p>
<p>Finally, for self-reported musical sophistication scores as well as listening test scores we used the accompanying truncated postcodes of individuals to aggregate scores at the level of the 379 British local authorities via the geographical data of the Ordnance Survey <xref ref-type="bibr" rid="pone.0089642-Ordnance1">[139]</xref>. This allowed us to correlate musical scores with the median weekly gross income as published in the Annual Survey of Hours and Earnings collected in 2011 by the Office for National Statistics <xref ref-type="bibr" rid="pone.0089642-Office1">[140]</xref>.</p>
</sec></sec><sec id="s6b">
<title>Results</title>
<p>Within the random forest model, the importance of each independent variable is computed as the percentage increase of the mean squared error in the dependent variable when the given predictor is excluded from the model. <xref ref-type="table" rid="pone-0089642-t007">Table 7</xref> reports the importance of the 8 socio-demographic variables and the two subscale scores for predicting self-reported General Musical Sophistication and the performance on the two listening tests. It is worth noting that, despite being recognised as a powerful statistical prediction model, the random forests including all socio-economic variables were only able to explain small proportions (i.e. between 4.7% and 13.6%) of the variance in the scores for self-reported musical sophistication and the two tests.</p>
<table-wrap id="pone-0089642-t007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t007</object-id><label>Table 7</label><caption>
<title>Variable importance according to random forest model.</title>
</caption><alternatives><graphic id="pone-0089642-t007-7" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t007" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">General Musical Sophistication</td>
<td align="left" rowspan="1" colspan="1">Melody Memory</td>
<td align="left" rowspan="1" colspan="1">Beat Perception</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Age</td>
<td align="left" rowspan="1" colspan="1">247</td>
<td align="left" rowspan="1" colspan="1">96</td>
<td align="left" rowspan="1" colspan="1">96</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Gender</td>
<td align="left" rowspan="1" colspan="1">100</td>
<td align="left" rowspan="1" colspan="1">26</td>
<td align="left" rowspan="1" colspan="1">62</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Ethnic Group</td>
<td align="left" rowspan="1" colspan="1">38</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">7</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Occupation</td>
<td align="left" rowspan="1" colspan="1">263</td>
<td align="left" rowspan="1" colspan="1">76</td>
<td align="left" rowspan="1" colspan="1">73</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Occupational Status</td>
<td align="left" rowspan="1" colspan="1">218</td>
<td align="left" rowspan="1" colspan="1">62</td>
<td align="left" rowspan="1" colspan="1">93</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Level of Education Obtained</td>
<td align="left" rowspan="1" colspan="1">156</td>
<td align="left" rowspan="1" colspan="1">62</td>
<td align="left" rowspan="1" colspan="1">65</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Level of Education Expected to Obtain</td>
<td align="left" rowspan="1" colspan="1">105</td>
<td align="left" rowspan="1" colspan="1">55</td>
<td align="left" rowspan="1" colspan="1">66</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Musical Training</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">187</td>
<td align="left" rowspan="1" colspan="1">208</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Active Engagement</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">32</td>
<td align="left" rowspan="1" colspan="1">48</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>R</italic><sup>2</sup></td>
<td align="left" rowspan="1" colspan="1">.047</td>
<td align="left" rowspan="1" colspan="1">.110</td>
<td align="left" rowspan="1" colspan="1">.136</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt106"><label/><p><italic>Footnote.</italic> Numerical values represent % increase in mean squared error if variable is omitted from model and hence higher values mean greater importance. Note that the model predicting general musical sophistication did not use the subscale scores for music training and active engagement.</p></fn></table-wrap-foot></table-wrap><sec id="s6b1">
<title>General musical sophistication</title>
<p><xref ref-type="table" rid="pone-0089642-t007">Table 7</xref> shows that the socio-economic variables most predictive of self-reported Musical Sophistication are Occupation, Age, Occupational Status, and Level of Education Obtained. According to the subsequent permutation tests, younger participants, participants working as music or media professionals or working in education, and participants currently at school or university, or having completed A-levels reported significantly higher levels of musical sophistication (values of the standardised test statistic and corresponding <italic>p</italic>-values from the permutation tests for the levels of all variables are given in Table S4 in <xref ref-type="supplementary-material" rid="pone.0089642.s001">File S1</xref>). In contrast, retired participants reported significantly lower levels of musical sophistication.</p>
<p>These relationships were confirmed by the regression tree model run on the test dataset and are summarised graphically in <xref ref-type="fig" rid="pone-0089642-g004">Figure 4</xref>. We limited the depth of the tree to a level where terminal nodes would contain at least 10% of participants (after excluding participants with missing data from the sample). The graph shows that the highest level of self-reported musical sophistication (average score of 88.5) is found for participants who are either still at school or are working as self-employed, in education, media and music professions (node 4), while self-reported musical sophistication was lowest (average score of 73.4) for participants over the age of 38 working in administrative or customer service professions (node 15).</p>
<fig id="pone-0089642-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g004</object-id><label>Figure 4</label><caption>
<title>Conditional inference regression tree modelling general musical sophistication with variables of socio-economic status.</title>
<p>The tree model is interpreted by starting at the top of the tree, following each branch down from each node, to arrive at a terminal node with the average scores given inside the squares on the graph. For example, descending to the right from node 1 (‘Occupation’) down the ‘Finance, Medical, Engineering, Administration, etc.’ branch, then descending to the right at node 9 (‘Age’) down the ‘&gt;38’ branch, and finally descending the right branch (‘Administration, Customer Service, etc’) going off node 13 (‘Occupation’) to arrive at terminal node 15, this can be interpreted as follows: People working in administrative or customer service occupation and being older than 38 years will obtain on average a general musical sophistication score of 73.4. Technically, the logical combinations of these two conditions can be regarded as an interaction of the two predictor variables. The significance values for each split are given within the oval nodes and are derived from a Monte Carlo resampling procedure that adjusts for multiple testing.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g004" position="float" xlink:type="simple"/></fig></sec><sec id="s6b2">
<title>Melody memory task</title>
<p>The random forest analysis identified Musical Training, Age, Occupation, Occupational Status, and the Highest Educational Degree obtained as the five most important variables for predicting performance on the melodic memory task. Results from the permutation tests showed that older participants and participants who self-reported more musical training performed significantly better on this task. Several significant main effects for categories of occupational status, occupation, and education level obtained seemed to be related to this age effect, e.g. participants still at school or university or having only obtained school qualifications (GCSE, or A-level) scored significantly worse than expected. On the other hand participants with university degrees, those being in full-time employment or working as self-employed, and those working in education/training, media or music professions achieved significantly higher scores.</p>
<p>The importance of musical training and certain categories of occupational status that are associated with older ages (e.g. employed, homemaker) for scoring high on the melodic memory task is reflected in the summarising tree model in <xref ref-type="fig" rid="pone-0089642-g005">Figure 5</xref>.</p>
<fig id="pone-0089642-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g005</object-id><label>Figure 5</label><caption>
<title>Conditional inference regression tree modelling accuracy scores (percentage scale from 0 to 100 where 50 indicates chance level) in the melody memory task using self-reported musical training and variables of socio-economic status as predictors.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g005" position="float" xlink:type="simple"/></fig></sec><sec id="s6b3">
<title>Beat perception task</title>
<p>According to the random forest analysis, the five most important variables for predicting performance on the beat perception task were self-reported musical training, age, occupational status, occupation, and the levels of education obtained and aspired to. The permutation tests indicated that musical training had a positive main effect on test scores but age was negatively related to performance on this task. Participants at university, in full-time employment, or those that were self-employed, especially those working in IT, media, or music professions scored better on this task while homemakers, retired participants, and those still at school or having obtained only a GCSE qualification scored significantly worse. Additionally, women achieved significantly lower beat perception scores than men. The tree model in <xref ref-type="fig" rid="pone-0089642-g006">Figure 6</xref> summarises these findings and shows how other variables interacted with musical training, which was the most important variable for predicting beat perception abilities. For example, the graph depicts how, for low levels of musical training, more active musical engagement leads to better test performance (terminal nodes 6 and 7), and how musical training was beneficial for test performance for both genders despite an overall higher achievement level for men (terminal nodes 16 vs. 17).</p>
<fig id="pone-0089642-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g006</object-id><label>Figure 6</label><caption>
<title>Conditional inference regression tree modelling accuracy scores (percentage scale from 0 to 100 where 50 indicates chance level) in the beat perception task using self-reported musical training, active engagement, and variables of socio-economic status as predictors.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g006" position="float" xlink:type="simple"/></fig></sec><sec id="s6b4">
<title>Relating regional income to musical sophistication</title>
<p>Looking at the data across the 379 local authorities in the UK, we found several significant correlations with data from the national income survey. <xref ref-type="table" rid="pone-0089642-t008">Table 8</xref> shows that the highest correlations with median weekly gross income are for musical training, general musical sophistication, and the performance on the two listening tests. The amount of variance that regional income can explain in certain musical variables was fairly high, in particular with respect to the performance on the two listening tests where 8.3% (melodic memory) and 12.6% (beat perception) of the variance was accounted for by regional income as the only predictor variable. On the other hand, Active Engagement and Musical Emotions yielded near-zero correlations with median weekly income of the local authority.</p>
<table-wrap id="pone-0089642-t008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.t008</object-id><label>Table 8</label><caption>
<title>Pearson correlations across 379 local authorities between median weekly gross income and the subscales of the self-report inventory as well as the performance scores from the listening tests.</title>
</caption><alternatives><graphic id="pone-0089642-t008-8" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.t008" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Correlations w/weekly gross income (n = 379)</td>
<td align="left" rowspan="1" colspan="1">Adjusted R<sup>2</sup></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Active Engagement</td>
<td align="left" rowspan="1" colspan="1">.049</td>
<td align="left" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Perceptual Abilities</td>
<td align="left" rowspan="1" colspan="1">.173**</td>
<td align="left" rowspan="1" colspan="1">.027</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Musical Training</td>
<td align="left" rowspan="1" colspan="1">.339**</td>
<td align="left" rowspan="1" colspan="1">.113</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Singing Abilities</td>
<td align="left" rowspan="1" colspan="1">.150**</td>
<td align="left" rowspan="1" colspan="1">.020</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Emotions</td>
<td align="left" rowspan="1" colspan="1">.024</td>
<td align="left" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">General Musical Sophistication</td>
<td align="left" rowspan="1" colspan="1">.165**</td>
<td align="left" rowspan="1" colspan="1">.025</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Melody Memory</td>
<td align="left" rowspan="1" colspan="1">.291**</td>
<td align="left" rowspan="1" colspan="1">.083</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Beat Perception</td>
<td align="left" rowspan="1" colspan="1">.358**</td>
<td align="left" rowspan="1" colspan="1">.126</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt107"><label/><p><italic>Footnote</italic>. Pearson’s correlation coefficients and adjusted R<sup>2</sup> values from a linear regression model having only weekly income (in addition to an intercept) as predictor. *indicates a p-level of &lt;.05 and ** a level of &lt;.01.</p></fn></table-wrap-foot></table-wrap>
<p>Because the correlations with income were obtained across geographical regions, it is possible to plot maps of the distributions of dimensions of musical sophistication and compare them to the distribution of regional income. <xref ref-type="fig" rid="pone-0089642-g007">Figure 7</xref> shows that there is a clear concentration of high-income local authorities in and around London and the so-called ‘Home Counties’ (e.g. Buckinghamshire, Hertfordshire, Essex, Kent, Surrey, Sussex). The medium-sized correlations with musical sophistication and musical training are visible especially in urban areas in Scotland and Northwest England (Manchester and Liverpool). This seems to support the notion that certain types of musical engagement, especially musical training, are associated with greater wealth. However, the maps also show some clear differences between income levels and aspects of musical sophistication. For example, in the West Country and in parts of Wales, participants reported relatively high levels of general musical sophistication despite generally lower income levels. This might be due to regional musical traditions, such as choirs and amateur music ensembles, which are particularly strong in these regions (<xref ref-type="bibr" rid="pone.0089642-Davies2">[141]</xref> p. 597).</p>
<fig id="pone-0089642-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0089642.g007</object-id><label>Figure 7</label><caption>
<title>Distribution of median weekly gross income according to the 2011 Annual Survey of Hours and Earnings survey (Office for National Statistics, 2012) and general musical sophistication, musical training and active engagement across 379 local authorities of Great Britain.</title>
<p>Values for all four variables were each split into 9 quantiles with approximately equal numbers of local authorities.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0089642.g007" position="float" xlink:type="simple"/></fig>
<p>Finally, the independence of active musical engagement (i.e. active musical listening, concert attendance, amount of money spent on music, reading and writing about music) from regional income (<italic>r</italic> = .049, n.s.) is clearly visible from the two respective maps. London and the Home Counties, the wealthiest regions in Great Britain, did not report particularly high levels of active musical engagement.</p>
</sec></sec></sec><sec id="s7">
<title>Discussion</title>
<p>The first aim of this paper was to develop and evaluate a novel instrument for measuring self-reported individual differences in skilled musical behaviours in the general (i.e. non-specialist) population. We have termed this psychometric construct ‘musical sophistication’. Drawing on a very large data sample from a non-specialist adult population (n = 147,663), we found the construct to be best described as comprising five different factors in addition to one general factor that drives skilled musical behaviours on all dimensions. We implemented the five factors and the general factor as subscales and demonstrated that, with this 5+1 structure, the new self-report inventory possesses high internal consistency as well as test-retest reliability, and has been externally validated through comparisons with another music-related self-report inventory and a standard auditory musicality test. Having a reliable measurement instrument at hand then allowed us to investigate correlates and conditions of musical sophistication, in order to identify other aspects of human personality and behaviour that potentially interact with the development of musical skills.</p>
<p>In a separate but smaller sample (n = 224) we found significant correlations between Extraversion and all 5+1 subscales of the self-report inventory in line with previous research that reported a positive influence of high extraversion traits on different musical listening styles <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic3">[113]</xref>, <xref ref-type="bibr" rid="pone.0089642-ChamorroPremuzic4">[142]</xref>. These findings are in contrast with earlier claims <xref ref-type="bibr" rid="pone.0089642-Kemp4">[118]</xref> that high levels of introversion are more common in highly musically skilled individuals (the ‘bold introvert’ <xref ref-type="bibr" rid="pone.0089642-Kemp1">[106]</xref>). Given that these earlier studies exclusively recruited professional or semi-professional musicians, we suspect that introversion as well as higher levels of conscientiousness are only associated with high musical skills in the specialist population of (classical) professional musicians. However, our data indicates that for the non-specialist population skilled musical behaviour is positively correlated with extraversion and even more strongly with openness to experience.</p>
<p>The unique sample (n = 147,663) derived from the BBC’s online implementation of our test provided us with the opportunity to compare self-reported musical skills with the performance on two listening tasks: testing memory for melodies and the accuracy in the perception of a musical beat. A structural equation model showed that formal musical training has a positive influence on the ability to memorise melodies and on the perception of small deviations in musical timing. This is not surprising given that most methods of musical training in our cultural sphere focus on the accurate performance of musical structure (such as melody) and also emphasise the importance of an accurate musical pulse (e.g. for ensemble playing). In contrast, self-reported active musical engagement did not have a positive influence on the performance on the melodic memory test but it did affect the performance on the beat perception test positively, especially for those individuals with very low levels of musical training (on an instrument), as indicated by the regression tree model in <xref ref-type="fig" rid="pone-0089642-g006">Figure 6</xref>. Given that the active engagement subscale combines a number of activities related to focused music listening, we take this to suggest that active music listening and deliberate aural processing can train certain musical abilities even in the absence of formal musical training. This is in line with empirical evidence summarised in the introduction <xref ref-type="bibr" rid="pone.0089642-Bigand1">[57]</xref>–<xref ref-type="bibr" rid="pone.0089642-Honing2">[59]</xref> showing that a range of musical skills are acquired through aural processing via statistical learning and leading to considerable amounts of implicit musical knowledge (see also Part 3 in <xref ref-type="bibr" rid="pone.0089642-Honing3">[143]</xref>). Following this line of reasoning, an interesting avenue for future research would be to investigate whether it is possible to identify musical abilities that are enhanced by intensive listening behaviour but not by training on an instrument and vice versa.</p>
<p>Finally, we compared self-reported musical sophistication and performance on the two listening tests to socio-economic data from a sub-sample of British participants from the large-scale and online implementation. Overall, and despite the fact that we used a powerful data-mining technique, socio-economic variables were able to ‘explain’ only small proportions of the variance in the musical data. However, the variables with the strongest associations were related to occupation, occupational status, education, and age, while gender and ethnic group had far less predictive power. A possible interpretation of the influence of these variables on the self-report data is that musically sophisticated behaviour is strongly linked to an early stage in life when people are able to organise their time in a flexible way (e.g. when they are at school or university or when they are self-employed). This interpretation does not hold true for retired people, however, supporting the fact that age is an important factor, with younger ages reporting higher levels of musically sophisticated behaviour. In addition, certain professions that have a natural link with music (music, media, and educational professions) seem to extend the period of musically sophisticated behaviour beyond the early and flexible stage in life.</p>
<p>Music and media professions and self-employed or full-time working participants also generally achieved the highest scores across the listening tests. But performance on the tests was partly related to other socio-economic variables as well, and we found some differences between the two tests. Increased age was associated with a better performance on the melodic memory test, while younger participants did better on the beat perception test. These differences might be explained partly by a cohort effect of musical listening styles (beat-based vs. melody-focused) that may differ for the different age groups gathered in this sample <xref ref-type="bibr" rid="pone.0089642-Hargreaves1">[144]</xref>.</p>
<p>We interpret these results from developmental perspective suggesting that musically sophisticated behaviour often develops at an early and flexible stage of life (end of secondary school to end of undergraduate university degree or beginning of working life) where most people have the time and motivation to engage with music in sophisticated ways, including musical training on an instrument and extensive listening engagement. Along with the musical training received in this phase, skills on an instrument are acquired and certain auditory skills such as melodic memory are trained by extension. At least some of the acquired skills are retained in older age and remain with the individual beyond the period of high musical engagement. This interpretation can explain the positive effect of age on the melodic memory task. In contrast, it is possible that other skills, such as the ability to detect subtle deviations from a musical beat, require continued sophisticated engagement with music to be preserved. A longitudinal study would be necessary to determine whether aural skills like beat perception are diminished as the effects of musical training and active engagement with music are gradually reduced across the life span, or whether the cohort effects of familiarity and listening styles are responsible for the differences in performance that we found in this cross-sectional study. Similarly, further work is needed to understand the interesting gender differences found in the beat perception task.</p>
<p>The clear and significant correlations between several facets of self-reported musical sophistication (i.e. musical training, perceptual abilities, general musical sophistication, singing abilities) and the performance on the two listening tasks on the one hand, and income at the regional level on the other hand are surprising and also merit further investigation in future studies. The direction of the influence between these variables is not clear from an a priori perspective. It is worth noting that the adult participants of the <italic>How Musical Are You?</italic> test were only asked to enter their current postcode. Therefore, it is impossible to evaluate from this individual correlation whether participants had received more musical training because they live in a more wealthy area or whether musical training did in any way support their professional development such that they achieved a higher socio-economic status and settled in more wealthy areas. A third, and perhaps more likely explanation, is that a common factor drives both wealth/socio-economic status on one hand, and also musical training/sophistication on the other. This common factor could be general cognitive ability or intelligence, which has been shown to correlate with musical training and academic achievements in a number of previous studies <xref ref-type="bibr" rid="pone.0089642-Schellenberg1">[130]</xref>, <xref ref-type="bibr" rid="pone.0089642-Schellenberg2">[145]</xref>. However, considering the significant correlations between listening test scores and regional income, other possible common factors could include personality traits such as competitiveness, general test taking abilities or support from parents in early life stages, which might have had a positive influence on both active engagement with music and academic/professional achievements (see <xref ref-type="bibr" rid="pone.0089642-Schellenberg3">[146]</xref>–<xref ref-type="bibr" rid="pone.0089642-Schellenberg4">[147]</xref> for suggestions of similar explanatory mechanisms).</p>
<p>In conclusion, this paper makes three contributions to the field; firstly, we have developed ‘musical sophistication’ as a concept for describing the different types (facets) of skilled musical behaviour in the general population of Western societies. Secondly, we have used a large sample of participants to develop the Goldsmiths Musical Sophistication Index as a new self-report inventory that quantifies musical sophistication in its different facets. The Gold-MSI is a multidimensional construct that covers very different facets of skilled musical behaviour, but data analysis showed that there is also a general factor of musical sophistication that arises from the correlations between these various facets. The Gold-MSI has been calibrated to capture the large variations in musical skills and expertise found in the general population, including non-musicians. Moreover, Gold-MSI scores are related to performance on a number of objective listening tests. Thirdly, we have investigated psychological correlates and socio-demographic contexts of musical sophistication with the aim of elucidating the conditions that are associated with individual differences in musical sophistication in general. We found musical sophistication to be related to certain personality traits (foremost, openness to experience and extraversion) and also to be associated with socio-demographic and socio-economic markers. These markers point to a stage in late adolescence and early adulthood where sophisticated engagement with music peaks for large parts of the population. For older participants, we found the extent of musically sophisticated behaviours to be generally lower, unless individuals have the opportunity through their profession (e.g. educational, media, and music-related professions) to maintain engagement with music at a high level. We therefore believe that the concept of musical sophistication, as implemented in the Goldsmiths Musical Sophistication Index, is a robust and comprehensive empirical construct that is directly related to real-world experiences in Western societies.</p>
<p>Returning to the title of this paper–The musicality of non-musicians–we are able to conclude that musical sophistication varies across the general population of Western societies and people differ greatly in the types and extent of skilled musical behaviours that they report, as well as in the musical listening skills that we were able to measure. However, we found that musical listening skills and musical behaviours are very clearly related, and our data support theories of explicit as well as implicit learning of music, while demonstrating the extent to which sophisticated engagement with music is very much part of people’s social reality.</p>
</sec><sec id="s8">
<title>Supporting Information</title>
<supplementary-material id="pone.0089642.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pone.0089642.s001" position="float" xlink:type="simple"><label>File S1</label><caption>
<p><bold>Table S1, Items of self-report inventory.</bold> Values of Cronbach’s alpha are derived from the full sample of 147,633 participants. <bold>Table S2, Inter-factor correlations for confirmatory model 4. Table S3, Data norms for subscales and general sophistication (sample n = 147,633). Table S4, Values of the test statistic and corresponding p-values derived from the conditional inference permutation tests for all socio-economic variables as well as self-reported musical training and active engagement influencing General Musical Sophistication scores as well as performance on the two listening tests.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material><supplementary-material id="pone.0089642.s002" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0089642.s002" position="float" xlink:type="simple"><label>Textual Description S1</label><caption>
<p>(DOC)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors would like to thank several individuals who have contributed to the research presented in this paper and the preparation of the manuscript: Amit Avron, Katharina Bauer, Thenille Braun, Klaus Frieler, Monika Ruszczynski (Spencer), and Naoko Skiada. We especially thank BBC Lab UK and in particular Joseph Bell, Richard Cable, Joseph Coulson, and Michael Orwell for the great opportunity and the support with the <italic>How Musical Are You?</italic> test. BBC Lab UK is an online project developed by the BBC to provide a platform for academic researchers to design surveys and experiments and to create large datasets from the BBC’s audience. It has already collected over two million cases and has committed to making data available to the wider academic community for appropriate research, educational and non-profit applications. <ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/labuk/" xlink:type="simple">http://www.bbc.co.uk/labuk/</ext-link>.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0089642-Merriam1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Merriam AP (1964) The anthropology of music. Chicago: Northwestern University Press.</mixed-citation>
</ref>
<ref id="pone.0089642-Blacking1"><label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">Blacking J (1995) Music, culture and experience. London: University of Chicago.</mixed-citation>
</ref>
<ref id="pone.0089642-Blacking2"><label>3</label>
<mixed-citation publication-type="other" xlink:type="simple">Blacking J (1973) How musical is man? London: Faber &amp; Faber.</mixed-citation>
</ref>
<ref id="pone.0089642-Levitin1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levitin</surname><given-names>DJ</given-names></name> (<year>2012</year>) <article-title>What does it mean to be musical?</article-title> <source>Neuron</source> <volume>73</volume>: <fpage>635</fpage>–<lpage>637</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hallam1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hallam</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>21st century conceptions of musical ability</article-title>. <source>Psychology of Music</source> <volume>38</volume>: <fpage>308</fpage>–<lpage>330</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hallam2"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hallam</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Prince</surname><given-names>V</given-names></name> (<year>2003</year>) <article-title>Conceptions of musical ability</article-title>. <source>Research Studies in Music Education</source> <volume>20</volume>: <fpage>2</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hyde1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyde</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name> (<year>2003</year>) <article-title>“Out-of-pitch” but still “in-time:” An auditory psychophysical study in congenital amusic adults</article-title>. <source>Neurosciences and Music</source> <volume>999</volume>: <fpage>173</fpage>–<lpage>176</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Stewart1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname><given-names>L</given-names></name> (<year>2011</year>) <article-title>Characterizing congenital amusia</article-title>. <source>Q J Exp Psychol</source> <volume>64</volume>: <fpage>625</fpage>–<lpage>638</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Bentley1"><label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">Bentley A (1966) Bentley measures of musical abilities. London: Harrap.</mixed-citation>
</ref>
<ref id="pone.0089642-Gordon1"><label>10</label>
<mixed-citation publication-type="other" xlink:type="simple">Gordon EE (1989) Advanced measures of music audiation. Chicago: Riverside Publishing Company.</mixed-citation>
</ref>
<ref id="pone.0089642-Seashore1"><label>11</label>
<mixed-citation publication-type="other" xlink:type="simple">Seashore CE, Lewis D, Saetveit JG (1960) Seashore measures of musical talent. New York: The Psychological Corporation.</mixed-citation>
</ref>
<ref id="pone.0089642-Wallentin1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallentin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nielsen</surname><given-names>AH</given-names></name>, <name name-style="western"><surname>Friis-Olivarius</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Vuust</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Vuust</surname><given-names>P</given-names></name> (<year>2010</year>) <article-title>The musical ear test, a new reliable test for measuring musical competence</article-title>. <source>Learn Individ Differ</source> <volume>20</volume>: <fpage>188</fpage>–<lpage>196</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Wing1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Wing HD (1962b) Wing standardized tests of musical intelligence. Windsor: National Foundation for Educational Research.</mixed-citation>
</ref>
<ref id="pone.0089642-Law1"><label>14</label>
<mixed-citation publication-type="other" xlink:type="simple">Law L, Zentner M (2012) Assessing musical abilities objectively: Construction and validation of the Profile of Music Perception Skills. PLoS ONE: 7.</mixed-citation>
</ref>
<ref id="pone.0089642-Boyle1"><label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">Boyle JD, Radocy RE (1987) Measurement and evaluation of musical experiences. New York: Schirmer Books.</mixed-citation>
</ref>
<ref id="pone.0089642-Murphy1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Murphy</surname><given-names>C</given-names></name> (<year>1999</year>) <article-title>How far do tests of musical ability shed light on the nature of musical intelligence?</article-title> <source>British Journal of Music Education</source> <volume>16</volume>: <fpage>39</fpage>–<lpage>50</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Seashore2"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Seashore CE (1938) Psychology of Music. New York: McGraw-Hill.</mixed-citation>
</ref>
<ref id="pone.0089642-Chin1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chin</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Rickard</surname><given-names>N</given-names></name> (<year>2012</year>) <article-title>The music USE (MUSE) questionnaire: An instrument to measure engagement in music</article-title>. <source>Music Percept</source> <volume>29</volume>: <fpage>429</fpage>–<lpage>446</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Cuddy1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cuddy</surname><given-names>LL</given-names></name>, <name name-style="western"><surname>Balkwill</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Holden</surname><given-names>RR</given-names></name> (<year>2005</year>) <article-title>Musical difficulties are rare: A study of “tone deafness” among university students</article-title>. <source>Ann N Y Acad Sci</source> <volume>1060</volume>: <fpage>311</fpage>–<lpage>317</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McDonald1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDonald</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Stewart</surname><given-names>L</given-names></name> (<year>2008</year>) <article-title>Uses and functions of music in congenital amusia</article-title>. <source>Music Percept</source> <volume>25</volume>: <fpage>345</fpage>–<lpage>355</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Ollen1"><label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">Ollen JE (2006) A criterion-related validity test of selected indicators of musical sophistication using expert ratings. Doctoral thesis, Ohio State University: Ohio.</mixed-citation>
</ref>
<ref id="pone.0089642-Werner1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werner</surname><given-names>PD</given-names></name>, <name name-style="western"><surname>Swope</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Heide</surname><given-names>FJ</given-names></name> (<year>2006</year>) <article-title>The music experience questionnaire: Development and correlates</article-title>. <source>J Psychol</source> <volume>140</volume>: <fpage>329</fpage>–<lpage>345</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Gembris1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gembris</surname><given-names>H</given-names></name> (<year>1999</year>) <article-title>Historical phases in the definition of “musicality”</article-title>. <source>Psychomusicology</source> <volume>16</volume>: <fpage>17</fpage>–<lpage>25</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McPherson1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">McPherson G, Hallam S (2009) Musical potential. In: Hallam S Cross I, Thaut M editors. Oxford Handbook of Music Psychology. Oxford: Oxford University Press. 225–254.</mixed-citation>
</ref>
<ref id="pone.0089642-Karma1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karma</surname><given-names>K</given-names></name> (<year>2007</year>) <article-title>Musical aptitude definition and measure validation: Ecological validity can endanger the construct validity of musical aptitude tests</article-title>. <source>Psychomusicology</source> <volume>19</volume>: <fpage>79</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Augustin1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Augustin</surname><given-names>MD</given-names></name>, <name name-style="western"><surname>Leder</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Art expertise: A study of concepts and conceptual spaces</article-title>. <source>Psychology Science</source> <volume>48</volume>: <fpage>135</fpage>–<lpage>156</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Chi1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chi</surname><given-names>MT</given-names></name>, <name name-style="western"><surname>Feltovich</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Glaser</surname><given-names>R</given-names></name> (<year>1981</year>) <article-title>Categorization and representation of physics problems by experts and novices</article-title>. <source>Cogn Sci</source> <volume>5</volume>: <fpage>121</fpage>–<lpage>152</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hughson1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hughson</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Boakes</surname><given-names>RA</given-names></name> (<year>2002</year>) <article-title>The knowing nose: The role of knowledge in wine expertise</article-title>. <source>Food Qual Prefer</source> <volume>13</volume>: <fpage>463</fpage>–<lpage>472</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hughson2"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hughson</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Boakes</surname><given-names>RA</given-names></name> (<year>2009</year>) <article-title>Passive perceptual learning in relation to wine: Short-term recognition and verbal description</article-title>. <source>Q J Exp Psychol</source> <volume>62</volume>: <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Leder1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leder</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Belke</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Oeberst</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Augustin</surname><given-names>MD</given-names></name> (<year>2004</year>) <article-title>A model of aesthetic appreciation and aesthetic judgments</article-title>. <source>Br J Psychol</source> <volume>95</volume>: <fpage>489</fpage>–<lpage>508</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Weiser1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiser</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Shertz</surname><given-names>J</given-names></name> (<year>1983</year>) <article-title>Programming problem representation in novice programmers.Int J Man Mach Stud</article-title>. <volume>19</volume>: <fpage>391</fpage>–<lpage>398</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Yau1"><label>32</label>
<mixed-citation publication-type="other" xlink:type="simple">Yau H (1999) A construction of criterion-referenced for badminton test battery. National College of Physical Education and Sports. Taoyuan - Taiwan: ROC.</mixed-citation>
</ref>
<ref id="pone.0089642-Ericsson1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Ericsson KA, Smith J (1991) Toward a general theory of exercise: Prospects and limits. Cambridge - England: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pone.0089642-Glaser1"><label>34</label>
<mixed-citation publication-type="other" xlink:type="simple">Glaser R (1994) Expertise. In: Eysenck MW <etal>et al</etal>.. editors. The Blackwell Dictionary of Cognitive Psychology. Cambridge: Blackwell. pp. 139–142.</mixed-citation>
</ref>
<ref id="pone.0089642-Honeck1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honeck</surname><given-names>RP</given-names></name>, <name name-style="western"><surname>Firment</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Case</surname><given-names>TJS</given-names></name> (<year>1987</year>) <article-title>Expertise and categorization</article-title>. <source>Bull Psychon Soc</source> <volume>25</volume>: <fpage>431</fpage>–<lpage>434</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McPherson2"><label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">McPherson GE, Williamon A (2006) Giftedness and talent. In: McPherson GE, editor. The child as musician: A handbook of musical development. Oxford University Press: pp. 239–256.</mixed-citation>
</ref>
<ref id="pone.0089642-Ukkola1"><label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Ukkola L, Onkamo P, Raijas P, Karma K, Järvelä I (2009) Musical aptitude is associated with AVPR1A-h aplotypes. PLoS One: 4.</mixed-citation>
</ref>
<ref id="pone.0089642-Draynal1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Draynal</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Manichaikull</surname><given-names>A</given-names></name>, <name name-style="western"><surname>De Lange</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Snieder</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Spector</surname><given-names>T</given-names></name> (<year>2001</year>) <article-title>Genetic correlates of musical pitch recognition in humans</article-title>. <source>Science</source> <volume>291</volume>: <fpage>1969</fpage>–<lpage>1972</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Park1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Park</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Ju</surname><given-names>YS</given-names></name>, <name name-style="western"><surname>Shin</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Comprehensive genomic analyses associate UGT8 variants with musical ability in a Mongolian population</article-title>. <source>Journal of Medical Genetics</source> <volume>49</volume>: <fpage>747</fpage>–<lpage>752</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Granot1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Granot</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Frankel</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gritsenko</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Lerer</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Gritsenko</surname><given-names>I</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Provisional evidence that the arginine vasopressin 1a receptor gene is associated with musical memory</article-title>. <source>Evol Hum Behav</source> <volume>28</volume>: <fpage>313</fpage>–<lpage>318</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Aheadi1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aheadi</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Dixon</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Glover</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>A limiting feature of the Mozart effect: Listening enhances mental rotation abilities in non-musicians but not musicians</article-title>. <source>Psychology of Music</source> <volume>38</volume>: <fpage>107</fpage>–<lpage>117</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Gaser1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gaser</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Schlaug</surname><given-names>G</given-names></name> (<year>2003</year>) <article-title>Brain structures differ between musicians and non-musicians</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>9240</fpage>–<lpage>9245</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hassler1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hassler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gupta</surname><given-names>D</given-names></name> (<year>1993</year>) <article-title>Functional brain organization, handedness, and immune vulnerability in musicians and non-musicians</article-title>. <source>Neuropsychologia</source> <volume>31</volume>: <fpage>655</fpage>–<lpage>660</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Koelsch1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koelsch</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gunter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Friederici</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Schroger</surname><given-names>E</given-names></name> (<year>2000</year>) <article-title>Brain indices of music processing: “Non-musicians” are musical</article-title>. <source>J Cogn Neurosci</source> <volume>12</volume>: <fpage>520</fpage>–<lpage>541</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Paraskevopoulos1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paraskevopoulos</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Kuchenbuch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Herholz</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name> (<year>2012</year>) <article-title>Statistical learning effects in musicians and non-musicians: An MEG study</article-title>. <source>Neuropsychologia</source> <volume>50</volume>: <fpage>341</fpage>–<lpage>349</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schmithorst1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmithorst</surname><given-names>VJ</given-names></name>, <name name-style="western"><surname>Wilke</surname><given-names>M</given-names></name> (<year>2002</year>) <article-title>Differences in white matter architecture between musicians and non-musicians: A diffusion tensor imaging study</article-title>. <source>Neurosci Lett</source> <volume>321</volume>: <fpage>57</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Zentner1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zentner</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Kagan</surname><given-names>J</given-names></name> (<year>1996</year>) <article-title>Perception of music by infants</article-title>. <source>Nature</source> <volume>383</volume>: <fpage>29</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hannon1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hannon</surname><given-names>EE</given-names></name>, <name name-style="western"><surname>Trehub</surname><given-names>SE</given-names></name> (<year>2005</year>) <article-title>Tuning in to musical rhythms: Infants learn more readily than adults</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>102</volume>: <fpage>12639</fpage>–<lpage>12643</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Werker1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werker</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Tees</surname><given-names>RC</given-names></name> (<year>1984</year>) <article-title>Phonemic and phonetic factors in adult cross-language speech-perception</article-title>. <source>J Acoust Soc Am</source> <volume>75</volume>: <fpage>1866</fpage>–<lpage>1878</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Werker2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werker</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Lalonde</surname><given-names>CE</given-names></name> (<year>1988</year>) <article-title>Cross-language speech-perception: Initial capabilities and developmental change</article-title>. <source>Dev Psychol</source> <volume>24</volume>: <fpage>672</fpage>–<lpage>683</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Jonaitis1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jonaitis</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Saffran</surname><given-names>JR</given-names></name> (<year>2009</year>) <article-title>Learning harmony: The role of serial statistics</article-title>. <source>Cogn Sci</source> <volume>33</volume>: <fpage>951</fpage>–<lpage>968</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Saffran1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saffran</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Aslin</surname><given-names>RN</given-names></name>, <name name-style="western"><surname>Newport</surname><given-names>EL</given-names></name> (<year>1996</year>) <article-title>Statistical learning by 8-month-old infants</article-title>. <source>Science</source> <volume>274</volume>: <fpage>1926</fpage>–<lpage>1928</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Saffran2"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saffran</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Loman</surname><given-names>MM</given-names></name>, <name name-style="western"><surname>Robertson</surname><given-names>RRW</given-names></name> (<year>2000</year>) <article-title>Infant memory for musical experiences Cognition</article-title>. <volume>77</volume>: <fpage>B15</fpage>–<lpage>B23</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Smith1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>DGK</given-names></name>, <name name-style="western"><surname>Grohshkopf</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Appleton</surname><given-names>T</given-names></name> (<year>1994</year>) <article-title>What child is this - what interval was that - familiar tunes and music perception in novice listeners</article-title>. <source>Cognition</source> <volume>52</volume>: <fpage>23</fpage>–<lpage>54</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Tillmann1"><label>55</label>
<mixed-citation publication-type="other" xlink:type="simple">Tillmann B, Bharucha JJ, Bigand E (2000) Implicit learning of regularities in Western tonal music by self-organization. Connectionist Models of Learning, Development and Evolution. pp. 175–184.</mixed-citation>
</ref>
<ref id="pone.0089642-Tillmann2"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tillmann</surname><given-names>B</given-names></name>, <name name-style="western"><surname>McAdams</surname><given-names>S</given-names></name> (<year>2004</year>) <article-title>Implicit learning of musical timbre sequences: Statistical regularities confronted with acoustical (dis)similarities</article-title>. <source>J Exp Psychol Learn Mem Cogn</source> <volume>30</volume>: <fpage>1131</fpage>–<lpage>1142</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Bigand1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bigand</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Poulin-Charronnat</surname><given-names>B</given-names></name> (<year>2006</year>) <article-title>Are we “experienced listeners”? A review of the musical capacities that do not depend on formal musical training</article-title>. <source>Cognition</source> <volume>100</volume>: <fpage>100</fpage>–<lpage>130</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Honing1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honing</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Computational modeling of music cognition: A case study on model selection</article-title>. <source>Music Percept</source> <volume>23</volume>: <fpage>365</fpage>–<lpage>376</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Honing2"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honing</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Annals</surname><given-names>NYA</given-names></name> (<year>2012</year>) <article-title>Without it no music: Beat induction as a fundamental musical trait</article-title>. <source>Neurosciences and Music IV: Learning and Memory</source> <volume>1252</volume>: <fpage>85</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Chin2"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chin</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Rickard</surname><given-names>N</given-names></name> (<year>2010</year>) <article-title>Nonperformance, as well as performance, based music engagements predicts verbal recall</article-title>. <source>Music Percept</source> <volume>27</volume>: <fpage>197</fpage>–<lpage>208</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Peretz1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name> (<year>2005</year>) <article-title>Brain organization for music processing</article-title>. <source>Annu Rev Psychol</source> <volume>56</volume>: <fpage>89</fpage>–<lpage>114</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Stewart2"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname><given-names>L</given-names></name>, <name name-style="western"><surname>von Kriegstein</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name> (<year>2006</year>) <article-title>Music and the brain: Disorders of musical listening</article-title>. <source>Brain</source> <volume>129</volume>: <fpage>2533</fpage>–<lpage>2553</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Kraus1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kraus</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Chandrasekaran</surname><given-names>B</given-names></name> (<year>2010</year>) <article-title>Science and society: Music training for the development of auditory skills</article-title>. <source>Nat Rev Neurosci</source> <volume>11</volume>: <fpage>599</fpage>–<lpage>605</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-BBC1"><label>64</label>
<mixed-citation publication-type="other" xlink:type="simple">BBC Science (nd) Gold-MSI BBC Pilot Survey on BBC Science website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/science/" xlink:type="simple">http://www.bbc.co.uk/science/</ext-link>. Accessed 2010 Nov 10.</mixed-citation>
</ref>
<ref id="pone.0089642-Mllensiefen1"><label>65</label>
<mixed-citation publication-type="other" xlink:type="simple">Müllensiefen D, Gingras B, Stewart L, Musil J (2011) The Goldsmiths Musical Sophistication Index (Gold-MSI): Technical Report and Documentation v0.9. London: Goldsmiths, University of London.</mixed-citation>
</ref>
<ref id="pone.0089642-BBC2"><label>66</label>
<mixed-citation publication-type="other" xlink:type="simple">BBC LabUK (nd)How Musical Are You? Test on BBC LabUK website. Available: <ext-link ext-link-type="uri" xlink:href="https://www.bbc.co.uk/labuk/experiments/musicality/" xlink:type="simple">https://www.bbc.co.uk/labuk/experiments/musicality/</ext-link>. Accessed 2012 May 15.</mixed-citation>
</ref>
<ref id="pone.0089642-Cattell1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cattell</surname><given-names>RB</given-names></name> (<year>1966</year>) <article-title>Scree test for number of factors</article-title>. <source>Multivariate Behav Res</source> <volume>1</volume>: <fpage>245</fpage>–<lpage>276</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Montanelli1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Montanelli</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Humphreys</surname><given-names>LG</given-names></name> (<year>1976</year>) <article-title>Latent roots of random data correlation matrices with squared multiple correlations on the diagonal: A Monte Carlo study</article-title>. <source>Psychometrika</source> <volume>41</volume>: <fpage>341</fpage>–<lpage>348</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Dinno1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dinno</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Implementing Horn’s parallel analysis for principal component analysis and factor analysis</article-title>. <source>Stata J</source> <volume>9</volume>: <fpage>291</fpage>–<lpage>298</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Velicer1"><label>70</label>
<mixed-citation publication-type="other" xlink:type="simple">Velicer WF (1976) Determining the number of components from the matrix of partial correlations. Psychometrika: 41, 321–327.</mixed-citation>
</ref>
<ref id="pone.0089642-Revelle1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Revelle</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Rocklin</surname><given-names>T</given-names></name> (<year>1979</year>) <article-title>Very simple structure: An alternative procedure for estimating the optimal number of interpretable factors</article-title>. <source>Multivariate Behav Res</source> <volume>14</volume>: <fpage>403</fpage>–<lpage>414</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-R1"><label>72</label>
<mixed-citation publication-type="other" xlink:type="simple">R Core Team (2012) R: A language and environment for statistical computing. R Foundation for Statistical Computing. Vienna: Austria. Available: <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/" xlink:type="simple">http://www.R-project.org/</ext-link>. Accessed 2014 Jan 25.</mixed-citation>
</ref>
<ref id="pone.0089642-Musek1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Musek</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>A general factor of personality: Evidence for the Big One in the five-factor model</article-title>. <source>J Res Pers</source> <volume>41</volume>: <fpage>1213</fpage>–<lpage>1233</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McDonald2"><label>74</label>
<mixed-citation publication-type="other" xlink:type="simple">McDonald RP (1999) Test theory: A unified treatment. Mahwah - NJ: Erlbaum.</mixed-citation>
</ref>
<ref id="pone.0089642-Revelle2"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Revelle</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Wilt</surname><given-names>J</given-names></name> (<year>2013</year>) <article-title>The general factor of personality: A general critique</article-title>. <source>J Res Pers</source> <volume>47</volume>: <fpage>493</fpage>–<lpage>504</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Zinbarg1"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zinbarg</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Revelle</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Yovel</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>W</given-names></name> (<year>2005</year>) <article-title>Cronbach’s alpha, Revelle’s beta, and McDonald’s (omega H): Their relations with each other and two alternative conceptualizations of reliability</article-title>. <source>Psychometrika</source> <volume>70</volume>: <fpage>123</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schmid1"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmid</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Leiman</surname><given-names>JM</given-names></name> (<year>1957</year>) <article-title>The development of hierarchical factor solutions: Psychometrika</article-title>. <volume>22</volume>: <fpage>53</fpage>–<lpage>61</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Baker1"><label>78</label>
<mixed-citation publication-type="other" xlink:type="simple">Baker F, Kim SH (2004) Item response theory: Parameter estimation techniques. New York: Marcel Dekker.</mixed-citation>
</ref>
<ref id="pone.0089642-VanderLinden1"><label>79</label>
<mixed-citation publication-type="other" xlink:type="simple">Van der Linden W, Hambleton R (1997) Handbook of modern item response theory. New York: Springer.</mixed-citation>
</ref>
<ref id="pone.0089642-Samejima1"><label>80</label>
<mixed-citation publication-type="other" xlink:type="simple">Samejima F (1969) Estimation of latent ability using a response pattern of graded scores. Richmond - VA: Psychometric Society.</mixed-citation>
</ref>
<ref id="pone.0089642-Rizopoulos1"><label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rizopoulos</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>ltm: An R package for latent variable modelling and item response theory analyses</article-title>. <source>J Stat Softw</source> <volume>17</volume>: <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Eysenck1"><label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eysenck</surname><given-names>MW</given-names></name> (<year>1979</year>) <article-title>Anxiety, learning and memory: A reconceptualization</article-title>. <source>J Res Pers</source> <volume>13</volume>: <fpage>363</fpage>–<lpage>385</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Gosling1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gosling</surname><given-names>SD</given-names></name>, <name name-style="western"><surname>Rentfrow</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Swann</surname><given-names>WB</given-names></name> (<year>2003</year>) <article-title>A very brief measure of the Big-Five personality domains</article-title>. <source>J Res Pers</source> <volume>37</volume>: <fpage>504</fpage>–<lpage>528</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Rentfrow1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rentfrow</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Gosling</surname><given-names>SD</given-names></name> (<year>2003</year>) <article-title>The do re mi’s of everyday life: The structure and personality correlates of music preferences</article-title>. <source>J Pers Soc Psychol</source> <volume>84</volume>: <fpage>1236</fpage>–<lpage>1256</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Paulhus1"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paulhus</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Lysy</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Yik</surname><given-names>MSN</given-names></name> (<year>1998</year>) <article-title>Self-report measures of intelligence: Are they useful as proxy IQ tests?</article-title> <source>J Pers</source> <volume>66</volume>: <fpage>525</fpage>–<lpage>554</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Furnham1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>The validity of a new, self-report measure of multiple intelligence</article-title>. <source>Curr Psychol</source> <volume>28</volume>: <fpage>225</fpage>–<lpage>239</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-ChamorroPremuzic1"><label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chamorro-Premuzic</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Moutafi</surname><given-names>J</given-names></name> (<year>2004</year>) <article-title>The relationship between estimated and psychometric personality and intelligence scores</article-title>. <source>J Res Pers</source> <volume>38</volume>: <fpage>505</fpage>–<lpage>513</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Young1"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Young</surname><given-names>WT</given-names></name> (<year>1971</year>) <article-title>The role of musical aptitude, intelligence, and academic achievement in predicting the musical attainment of elementary instrumental music students</article-title>. <source>J Res Music Ed</source> <volume>19</volume>: <fpage>385</fpage>–<lpage>398</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Gordon2"><label>89</label>
<mixed-citation publication-type="other" xlink:type="simple">Gordon EE (1975) Fourth year and fifth year results of a longitudinal study of the musical achievement of culturally disadvantaged students. Research in the Psychology of Music 10 (Iowa City: University of Iowa Press, 1975), 24.</mixed-citation>
</ref>
<ref id="pone.0089642-Young2"><label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Young</surname><given-names>WT</given-names></name> (<year>1976</year>) <article-title>A longitudinal comparison of four music achievement and music aptitude tests</article-title>. <source>Journal of Research in Music Education</source> <volume>24</volume>: <fpage>97</fpage>–<lpage>109</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schleuter1"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schleuter</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Schleuter</surname><given-names>LJ</given-names></name> (<year>1978</year>) <article-title>A predictive study of an experimental college version of the musical aptitude profile with music achievement of non-music majors</article-title>. <source>Contributions to Music Education</source> <volume>6</volume>: <fpage>2</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Gordon3"><label>92</label>
<mixed-citation publication-type="other" xlink:type="simple">Gordon EE (1990) Predictive validity of AMMA. Chicago: GIA Publications, Inc.</mixed-citation>
</ref>
<ref id="pone.0089642-Gordon4"><label>93</label>
<mixed-citation publication-type="other" xlink:type="simple">Gordon EE (1991) A factor analytic study of the Advanced Measures of Music Audiation. In: The advanced measures of music audiation and the instrument timbre preference test: Three research studies. Chicago: GIA Publications, Inc. 1–21.</mixed-citation>
</ref>
<ref id="pone.0089642-Ruthsatz1"><label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruthsatz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Detterman</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Griscom</surname><given-names>WS</given-names></name>, <name name-style="western"><surname>Cirullo</surname><given-names>BA</given-names></name> (<year>2008</year>) <article-title>Becoming an expert in the musical domain: It takes more than just practice</article-title>. <source>Intelligence</source> <volume>36</volume>: <fpage>330</fpage>–<lpage>338</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Droves1"><label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Droves</surname><given-names>TJ</given-names></name> (<year>2008</year>) <article-title>Music achievement, self-esteem, and aptitude in a college songwriting class</article-title>. <source>Bulletin of the Council for Research in Music Education</source> <volume>178</volume>: <fpage>35</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Herdener1"><label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herdener</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Esposito</surname><given-names>F</given-names></name>, <name name-style="western"><surname>di Salle</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Boller</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Hilti</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Musical training induces functional plasticity in human hippocampus</article-title>. <source>Neurosci</source> <volume>30</volume>: <fpage>1377</fpage>–<lpage>1384</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Seppnen1"><label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seppänen</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Brattico</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Tervaniemi</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Practice strategies of musicians modulate neural processing and the learning of sound-patterns</article-title>. <source>Neurobiol Learn Mem</source> <volume>87</volume>: <fpage>236</fpage>–<lpage>247</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McCrae1"><label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McCrae</surname><given-names>RR</given-names></name> (<year>2007</year>) <article-title>Aesthetic chills as a universal marker of openness to experience</article-title>. <source>Motiv Emot</source> <volume>31</volume>: <fpage>5</fpage>–<lpage>11</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-McManus1"><label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McManus</surname><given-names>IC</given-names></name>, <name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Aesthetic activities and aesthetic attitudes: Influences of education, background and personality on interest and involvement in the arts</article-title>. <source>Br J Psychol</source> <volume>97</volume>: <fpage>555</fpage>–<lpage>587</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Furnham2"><label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Chamorro-Premuzic</surname><given-names>T</given-names></name> (<year>2004</year>) <article-title>Personality, intelligence, and art</article-title>. <source>Pers Individ Dif</source> <volume>36</volume>: <fpage>705</fpage>–<lpage>715</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hunter1"><label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hunter</surname><given-names>PG</given-names></name>, <name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name> (<year>2011</year>) <article-title>Interactive effects of personality and frequency of exposure on liking for music</article-title>. <source>Pers Individ Dif</source> <volume>50</volume>: <fpage>175</fpage>–<lpage>179</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Rentfrow2"><label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rentfrow</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Gosling</surname><given-names>SD</given-names></name> (<year>2006</year>) <article-title>Message in a ballad</article-title>. <source>Psychol Sci</source> <volume>17</volume>: <fpage>236</fpage>–<lpage>242</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-ChamorroPremuzic2"><label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chamorro-Premuzic</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Personality and music: Can traits explain how people use music in everyday life?</article-title> <source>Br J Psychol</source> <volume>98</volume>: <fpage>175</fpage>–<lpage>185</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Ladinig1"><label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ladinig</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name> (<year>2012</year>) <article-title>Liking unfamiliar music: Effects of felt emotion and individual differences</article-title>. <source>Psychology of Aesthetics Creativity and the Arts</source> <volume>6</volume>: <fpage>146</fpage>–<lpage>154</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Vuoskoski1"><label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vuoskoski</surname><given-names>JK</given-names></name>, <name name-style="western"><surname>Eerola</surname><given-names>T</given-names></name> (<year>2011</year>) <article-title>Measuring music-induced emotion: A comparison of emotion models, personality biases, and intensity of experiences</article-title>. <source>Music Sci</source> <volume>15</volume>: <fpage>159</fpage>–<lpage>173</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Kemp1"><label>106</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kemp</surname><given-names>AE</given-names></name> (<year>1981</year>) <article-title>The personality structure of the musician. I. Identifying a profile of traits for the performer</article-title>. <source>Psychology of Music</source> <volume>9</volume>: <fpage>3</fpage>–<lpage>14</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Woody1"><label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woody</surname><given-names>RH</given-names></name> (<year>1999</year>) <article-title>The musician’s personality</article-title>. <source>Creat Res J</source> <volume>12</volume>: <fpage>241</fpage>–<lpage>250</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Builione1"><label>108</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Builione</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Lipton</surname><given-names>JP</given-names></name> (<year>1983</year>) <article-title>Stereotypes and personality of classical musicians</article-title>. <source>Psychomusicology</source> <volume>3</volume>: <fpage>36</fpage>–<lpage>43</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Davies1"><label>109</label>
<mixed-citation publication-type="other" xlink:type="simple">Davies JB (1978) The psychology of music. London: Hutchinson.</mixed-citation>
</ref>
<ref id="pone.0089642-Kemp2"><label>110</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kemp</surname><given-names>AE</given-names></name> (<year>1981</year>) <article-title>Personality differences between the players of string, woodwind, brass and keyboard instruments, and singers</article-title>. <source>Bulletin of the Council for Research in Music Education</source> <volume>66–67</volume>: <fpage>33</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Lipton1"><label>111</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lipton</surname><given-names>JP</given-names></name> (<year>1987</year>) <article-title>Stereotypes concerning musicians within symphony orchestras</article-title>. <source>J Psychol</source> <volume>121</volume>: <fpage>85</fpage>–<lpage>93</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Wilson1"><label>112</label>
<mixed-citation publication-type="other" xlink:type="simple">Wilson GD (2002) Psychology for performing artists. London: Whurr Publishers.</mixed-citation>
</ref>
<ref id="pone.0089642-ChamorroPremuzic3"><label>113</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chamorro-Premuzic</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Goma-i-Freixanet</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Muro</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Personality, self-estimated intelligence, and uses of music: A Spanish replication and extension using structural equation modeling</article-title>. <source>Psychology of Aesthetics Creativity and the Arts</source> <volume>3</volume>: <fpage>149</fpage>–<lpage>155</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Furnham3"><label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Strbac</surname><given-names>L</given-names></name> (<year>2002</year>) <article-title>Music is as distracting as noise: The differential distraction of background music and noise on the cognitive test performance of introverts and extraverts</article-title>. <source>Ergonomics</source> <volume>45</volume>: <fpage>203</fpage>–<lpage>217</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Kemp3"><label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kemp</surname><given-names>AE</given-names></name> (<year>1982</year>) <article-title>The personality structure of the musician. IV. Incorporating group profiles into a comprehensive model</article-title>. <source>Psychology of Music</source> <volume>10</volume>: <fpage>3</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Litle1"><label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Litle</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Zuckerman</surname><given-names>M</given-names></name> (<year>1986</year>) <article-title>Sensation seeking and music preferences</article-title>. <source>Pers Individ Dif</source> <volume>7</volume>: <fpage>575</fpage>–<lpage>578</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Guttman1"><label>117</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guttman</surname><given-names>L</given-names></name> (<year>1945</year>) <article-title>A basis for analyzing test-retest reliability</article-title>. <source>Psychometrika</source> <volume>10</volume>: <fpage>255</fpage>–<lpage>282</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Kemp4"><label>118</label>
<mixed-citation publication-type="other" xlink:type="simple">Kemp AE (1996) The musical temperament: Psychology and personality of musicians. Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pone.0089642-White1"><label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>B</given-names></name> (<year>1960</year>) <article-title>Recognition of distorted melodies</article-title>. <source>Am J Psychol</source> <volume>73</volume>: <fpage>100</fpage>–<lpage>107</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Halpern1"><label>120</label>
<mixed-citation publication-type="other" xlink:type="simple">Halpern AR, Bartlett JC (2010) Memory for melodies. In: Jones MR, Popper AN, Fay RR, editors. Music Perception. New York: Springer. pp. 233–258.</mixed-citation>
</ref>
<ref id="pone.0089642-Wing2"><label>121</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wing</surname><given-names>HD</given-names></name> (<year>1962</year>) <article-title>A revision of the “Wing musical aptitude test”</article-title>. <source>Journal of Research in Music Education</source> <volume>10</volume>: <fpage>39</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Bartlett1"><label>122</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartlett</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Dowling</surname><given-names>WJ</given-names></name> (<year>1980</year>) <article-title>Recognition of transposed melodies: A key-distance effect in developmental perspective</article-title>. <source>J Exp Psychol</source> <volume>6</volume>: <fpage>501</fpage>–<lpage>515</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Cuddy2"><label>123</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cuddy</surname><given-names>LL</given-names></name>, <name name-style="western"><surname>Lyons</surname><given-names>HI</given-names></name> (<year>1981</year>) <article-title>Musical pattern recognition: A comparison of listening to and studying tonal structures and tonal ambiguities</article-title>. <source>Psychomusicology</source> <volume>1</volume>: <fpage>15</fpage>–<lpage>33</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Halpern2"><label>124</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Halpern</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Bartlett</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Dowling</surname><given-names>WJ</given-names></name> (<year>1995</year>) <article-title>Aging and experience in the recognition of musical transpositions</article-title>. <source>Psychol Aging</source> <volume>10</volume>: <fpage>325</fpage>–<lpage>342</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Iversen1"><label>125</label>
<mixed-citation publication-type="other" xlink:type="simple">Iversen JR, Patel AD (2008) The Beat Alignment Test (BAT): Surveying beat processing abilities in the general population. In: Proceedings of the 10th International Conference on Music Perception and Cognition (ICMPC 10). Sapporo: Japan. p. 465.</mixed-citation>
</ref>
<ref id="pone.0089642-Birnbaum1"><label>126</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Birnbaum</surname><given-names>MH</given-names></name> (<year>2004</year>) <article-title>Human research and data collection via the Internet</article-title>. <source>Annu Rev Psychol</source> <volume>55</volume>: <fpage>803</fpage>–<lpage>832</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Dandurand1"><label>127</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dandurand</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Shultz</surname><given-names>TR</given-names></name>, <name name-style="western"><surname>Onishi</surname><given-names>KH</given-names></name> (<year>2008</year>) <article-title>Comparing online and lab methods in a problem solving experiment</article-title>. <source>Behav Res Methods</source> <volume>40</volume>: <fpage>428</fpage>–<lpage>434</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-DuarteBoniniCampos1"><label>128</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duarte Bonini Campos</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Zucoloto</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Sampaio Bonafe</surname><given-names>FS</given-names></name>, <name name-style="western"><surname>Jordani</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Maroco</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Reliability and validity of self-reported burnout in college students: A cross randomized comparison of paper-and-pencil vs. online administration</article-title>. <source>Comput Human Behav</source> <volume>27</volume>: <fpage>1875</fpage>–<lpage>1883</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Reimers1"><label>129</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reimers</surname><given-names>S</given-names></name> (<year>2007</year>) <article-title>The BBC internet study: General methodology</article-title>. <source>Arch Sex Behav</source> <volume>36</volume>: <fpage>147</fpage>–<lpage>161</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schellenberg1"><label>130</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name> (<year>2011</year>) <article-title>Examining the association between music lessons and intelligence</article-title>. <source>Br J Psychol</source> <volume>102</volume>: <fpage>283</fpage>–<lpage>302</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Liaw1"><label>131</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liaw</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wiener</surname><given-names>M</given-names></name> (<year>2002</year>) <article-title>Classification and regression by randomForest</article-title>. <source>R News</source> <volume>2</volume>: <fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Breiman1"><label>132</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Breiman</surname><given-names>L</given-names></name> (<year>2001</year>) <article-title>Random forests</article-title>. <source>Mach Learn</source> <volume>45</volume>: <fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hastie1"><label>133</label>
<mixed-citation publication-type="other" xlink:type="simple">Hastie T, Tibshirani R, Friedmann J (2009) The elements of statistical learning: Data mining, inference and prediction. New York: Springer.</mixed-citation>
</ref>
<ref id="pone.0089642-Breiman2"><label>134</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Breiman</surname><given-names>L</given-names></name> (<year>2001</year>) <article-title>Statistical modeling: The two cultures</article-title>. <source>Stat Sci</source> <volume>16</volume>: <fpage>199</fpage>–<lpage>231</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hothorn1"><label>135</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hothorn</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hornik</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Van de Weil</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Zeileis</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Implementing a class of permutation tests: The coin package</article-title>. <source>J Stat Softw</source> <volume>28</volume>: <fpage>1</fpage>–<lpage>23</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Hothorn2"><label>136</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hothorn</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hornik</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Van de Wiel</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Zeileis</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>A Lego system for conditional inference</article-title>. <source>Am Stat</source> <volume>60</volume>: <fpage>257</fpage>–<lpage>263</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Westfall1"><label>137</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Westfall</surname><given-names>PH</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>SS</given-names></name> (<year>1993</year>) <article-title>On adjusting p-values for multiplicity</article-title>. <source>Biometrics</source> <volume>49</volume>: <fpage>941</fpage>–<lpage>944</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Strobl1"><label>138</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strobl</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Malley</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Tutz</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>An introduction to recursive partitioning: Rationale, application and characteristics of classification and regression trees, bagging and random forests</article-title>. <source>Psychol Methods</source> <volume>14</volume>: <fpage>323</fpage>–<lpage>348</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Ordnance1"><label>139</label>
<mixed-citation publication-type="other" xlink:type="simple">Ordnance Survey (2012) Available: <ext-link ext-link-type="uri" xlink:href="https://www.ordnancesurvey.co.uk/opendatadownload/products.html" xlink:type="simple">https://www.ordnancesurvey.co.uk/opendatadownload/products.html</ext-link>.Accessed 2014 Jan 29.</mixed-citation>
</ref>
<ref id="pone.0089642-Office1"><label>140</label>
<mixed-citation publication-type="other" xlink:type="simple">Office for National Statistics (2012) Annual survey of hours and earnings - resident analysis. Office for national statistics website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nomisweb.co.uk/" xlink:type="simple">http://www.nomisweb.co.uk/</ext-link>. Accessed 2014 Jan 29.</mixed-citation>
</ref>
<ref id="pone.0089642-Davies2"><label>141</label>
<mixed-citation publication-type="other" xlink:type="simple">Davies J, Jenkins N (2008) The Welsh academy encyclopaedia of Wales. Cardiff: University of Wales Press.</mixed-citation>
</ref>
<ref id="pone.0089642-ChamorroPremuzic4"><label>142</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chamorro-Premuzic</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Furnham</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>The big five personality traits and uses of music: A replication using structural equation modeling</article-title>. <source>Journal of Individual Differences</source> <volume>30</volume>: <fpage>20</fpage>–<lpage>27</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Honing3"><label>143</label>
<mixed-citation publication-type="other" xlink:type="simple">Honing HJ (2011) Musical cognition: A science of listening. Piscataway: Transaction Publishers.</mixed-citation>
</ref>
<ref id="pone.0089642-Hargreaves1"><label>144</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hargreaves</surname><given-names>D</given-names></name>, <name name-style="western"><surname>North</surname><given-names>A</given-names></name> (<year>2002</year>) <article-title>Musical development and learning - Response</article-title>. <source>Br J Educ Psychol</source> <volume>72</volume>: <fpage>139</fpage>–<lpage>140</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schellenberg2"><label>145</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name> (<year>2006</year>) <article-title>Long-term positive associations between music lessons and IQ</article-title>. <source>J Educ Psychol</source> <volume>98</volume>: <fpage>457</fpage>–<lpage>468</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schellenberg3"><label>146</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name> (<year>2011</year>) <article-title>Music lessons, emotional intelligence, and IQ</article-title>. <source>Music Percept</source> <volume>29</volume>: <fpage>185</fpage>–<lpage>194</lpage>.</mixed-citation>
</ref>
<ref id="pone.0089642-Schellenberg4"><label>147</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schellenberg</surname><given-names>EG</given-names></name>, <name name-style="western"><surname>Winner</surname><given-names>E</given-names></name> (<year>2011</year>) <article-title>Music training and non-musical abilities: An introduction</article-title>. <source>Music Percept</source> <volume>29</volume>: <fpage>129</fpage>–<lpage>132</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>