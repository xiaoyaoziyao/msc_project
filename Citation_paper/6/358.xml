<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-11-17766</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0027926</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
              <subj-group>
                <subject>Cognition</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory perception</subject>
              <subj-group>
                <subject>Psychophysics</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Cognitive psychology</subject>
              <subj-group>
                <subject>Learning</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Experimental psychology</subject>
              <subject>Psychophysics</subject>
              <subject>Sensory perception</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Learned Value Magnifies Salience-Based Attentional Capture</article-title><alt-title alt-title-type="running-head">Value and Attentional Priority</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Anderson</surname>
            <given-names>Brian A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Laurent</surname>
            <given-names>Patryk A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Yantis</surname>
            <given-names>Steven</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
      </contrib-group><aff id="aff1">          <addr-line>Department of Psychological and Brain Sciences, Johns Hopkins University, Baltimore, Maryland, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Lauwereyns</surname>
            <given-names>Jan</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Kyushu University, Japan</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">bander33@jhu.edu</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: BAA PAL SY. Performed the experiments: BAA. Analyzed the data: BAA PAL. Wrote the paper: BAA PAL SY.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>21</day>
        <month>11</month>
        <year>2011</year>
      </pub-date><volume>6</volume><issue>11</issue><elocation-id>e27926</elocation-id><history>
        <date date-type="received">
          <day>12</day>
          <month>9</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>27</day>
          <month>10</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Anderson et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Visual attention is captured by physically salient stimuli (termed <italic>salience-based attentional capture</italic>), and by otherwise task-irrelevant stimuli that contain goal-related features (termed <italic>contingent attentional capture</italic>). Recently, we reported that physically nonsalient stimuli associated with value through reward learning also capture attention involuntarily (Anderson, Laurent, &amp; Yantis, <italic>PNAS</italic>, 2011). Although it is known that physical salience and goal-relatedness both influence attentional priority, it is unknown whether or how attentional capture by a salient stimulus is modulated by its associated value. Here we show that a physically salient, task-irrelevant distractor previously associated with a large reward slows visual search more than an equally salient distractor previously associated with a smaller reward. This magnification of salience-based attentional capture by learned value extinguishes over several hundred trials. These findings reveal a broad influence of learned value on involuntary attentional capture.</p>
      </abstract><funding-group><funding-statement>The research was supported by the National Institutes of Health grant R01-DA013165 to Steven Yantis. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="6"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Objects in the visual world compete for perceptual representation in the mind and brain. Selective attention resolves this competition, biasing perception in favor of behaviorally relevant and salient stimuli <xref ref-type="bibr" rid="pone.0027926-Corbetta1">[1]</xref>–<xref ref-type="bibr" rid="pone.0027926-Serences2">[4]</xref>. Because perception is limited in its representational capacity, which stimuli are selected by attention has important implications for the survival and well-being of an organism.</p>
      <p>Attentional selection can proceed either voluntarily, according to context-specific goals and priorities, or involuntarily, according to the physical properties of a stimulus within a given task context. When a stimulus is selected via attention involuntarily, that stimulus is said to have captured attention. Attentional capture can be adaptive when a stimulus signals danger or opportunity <xref ref-type="bibr" rid="pone.0027926-Laurent1">[5]</xref>, but comes at a cost in performance when those stimuli distract from ongoing goal-related processes.</p>
      <p>It is well established that both physical salience and ongoing task goals influence the attentional priority of a stimulus. Physically salient but task-irrelevant stimuli slow visual search for a target in a spatially-specific manner (e.g., <xref ref-type="bibr" rid="pone.0027926-Theeuwes1">[6]</xref>–<xref ref-type="bibr" rid="pone.0027926-Yantis1">[10]</xref>); this is termed <italic>salience-based attentional capture</italic>. Irrelevant stimuli possessing goal-related features also capture attention involuntarily; for example, a red distractor captures attention when the searched-for target stimulus is partly defined by the color red <xref ref-type="bibr" rid="pone.0027926-Folk1">[11]</xref>, <xref ref-type="bibr" rid="pone.0027926-Anderson1">[12]</xref>. This is termed <italic>contingent attentional capture</italic> <xref ref-type="bibr" rid="pone.0027926-Folk2">[13]</xref>.</p>
      <p>Salience-based and contingent attentional capture are known to jointly determine attentional priority. For example, contingent attentional capture is more pronounced for more salient distractors, even when the target of visual search is nonsalient <xref ref-type="bibr" rid="pone.0027926-Lamy1">[14]</xref>. These and related findings suggest that stimulus salience and ongoing task goals have a combined influence on attentional priority.</p>
      <p>Physical salience and goal-relevance are not the only properties that influence attentional priority, however. A growing body of evidence has established that reward-related stimuli compete effectively for perceptual representation <xref ref-type="bibr" rid="pone.0027926-DellaLibera1">[15]</xref>–<xref ref-type="bibr" rid="pone.0027926-Shuler1">[27]</xref>. Attention to reward-related stimuli is often explicitly a behavioral goal; it is therefore necessary to design task contingencies such that it is possible to distinguish between the voluntary and involuntary deployment of attention to valuable stimuli <xref ref-type="bibr" rid="pone.0027926-Maunsell1">[28]</xref>.</p>
      <p>Recently, we reported that otherwise nonsalient and task-irrelevant stimuli that had previously been associated with reward capture attention involuntarily <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. In a training phase, participants received a monetary reward for identifying an oriented bar contained within a target stimulus that was unpredictably red or green; the target appeared in an array of other differently-colored items. Both high and low amounts of reward were given as feedback following each trial; one target color was associated with a high probability of a large reward while the other was associated with a high probability of a small reward. Thus, the amount of reward delivered on a given trial was not associated with a particular motor response, but was probabilistically related to the color of the target stimulus. Following the training phase, participants engaged in a test phase in which they searched for a shape-singleton target in extinction; no rewards were given, and color was irrelevant to the task. On half the trials, one of the nontarget items was rendered in the color of a formerly rewarded stimulus. Critically, the nontarget items were all differently colored, making the shape-singleton target the most physically salient stimulus in the display. The results revealed that distractors rendered in formerly rewarded colors consistently slowed visual search in a spatially-specific manner, even though they were nonsalient, task-irrelevant, and did not share any identifying features in common with the target <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. This finding demonstrates that valuable stimuli capture attention involuntarily, in a manner that is distinct from other mechanisms of attentional control.</p>
      <p>Although there is ample evidence that salience-based and contingency-based mechanisms of attentional control jointly determine attentional priority, it is unknown whether or how salience-based attentional priority is modulated by the learned value of a stimulus. This is an important question, as ecologically valuable stimuli are often visually salient. One possibility is that the attentional priority of a salient stimulus cannot be modulated by learned value, either because its priority is already maximal or because value and salience provide redundant information about attentional priority. Another possibility, however, is that stimulus salience and stimulus value combine to determine attentional priority, much as salience increases the attentional priority of goal-related stimuli in contingent capture <xref ref-type="bibr" rid="pone.0027926-Lamy1">[14]</xref>; this would result in a value-driven increase in attentional priority above and beyond that afforded by physical salience alone. Such a value-driven increase in attentional priority could either operate at the level of selection, effectively increasing salience, or at the post-selection level by prolonging attentional dwell time following purely salience-driven capture. In the present study, we distinguish between these two competing possibilities, and conclude that stimulus salience and stimulus value have combined effects on attentional priority.</p>
    </sec>
    <sec id="s2">
      <title>Experiment 1</title>
      <p>The design of <xref ref-type="sec" rid="s2">Experiment 1</xref> was similar to that of Anderson et al. <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. During the training phase, participants searched for a red or green target among differently colored nontargets (<xref ref-type="fig" rid="pone-0027926-g001">Figure 1a</xref>), and received visual feedback at the end of each trial indicating a monetary reward for a correct response; one of the two colors was associated with a high reward and the other with a low reward. During the test phase, which utilizes a variant of the additional singleton paradigm (e.g., <xref ref-type="bibr" rid="pone.0027926-Theeuwes1">[6]</xref>, <xref ref-type="bibr" rid="pone.0027926-Theeuwes3">[9]</xref>, <xref ref-type="bibr" rid="pone.0027926-Bacon1">[30]</xref>), participants searched for a unique shape in an array of usually all white elements (<xref ref-type="fig" rid="pone-0027926-g001">Figure 1b</xref>). On half the trials, one of the nontarget elements, the <italic>distractor</italic>, was rendered in red or green. Participants were informed that color was irrelevant and should be ignored, and the target was never red or green. No reward was provided during the test phase.</p>
      <fig id="pone-0027926-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0027926.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Behavioral Task.</title>
          <p>Sequence of events and time course for a trial during training (<italic>a</italic>) and at test (<italic>b</italic>) in <xref ref-type="sec" rid="s2">Experiment 1</xref>.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0027926.g001" xlink:type="simple"/>
      </fig>
      <p>Color-singleton distractors capture attention robustly in a shape-search task by virtue of their physical salience (e.g., <xref ref-type="bibr" rid="pone.0027926-Theeuwes1">[6]</xref>, <xref ref-type="bibr" rid="pone.0027926-Theeuwes3">[9]</xref>, <xref ref-type="bibr" rid="pone.0027926-Bacon1">[30]</xref>). Our primary focus here was to determine whether a salient high-value distractor would capture attention more robustly than a salient low-value distractor. If salience completely dominates value, then high- and low-value color singletons should produce similar slowing in visual search. If learned value combines with physical salience, then the formerly high-reward distractors should slow responses more than formerly low-reward distractors.</p>
      <sec id="s2a">
        <title>Materials and Methods</title>
        <sec id="s2a1">
          <title>Participants</title>
          <p>Eighteen participants were recruited from the Johns Hopkins University community. All were screened for normal or corrected-to-normal visual acuity and color vision. Participants were provided monetary compensation that varied between $21 and $28 (mean = $25.22), depending on their accuracy. All participants read and signed an informed consent form prior to participating in the experiments. Throughout the research project leading to this publication, the rights of the participants were protected and the applicable guidelines concerning the use of human subjects for the purposes of research were followed. The study was approved by the Johns Hopkins University Institutional Review Board.</p>
        </sec>
        <sec id="s2a2">
          <title>Apparatus and Stimuli</title>
          <p>A Mac Mini equipped with Matlab software and Psychophysics Toolbox extensions was used to present the stimuli on a Dell P991 monitor. The participants viewed the monitor from a distance of approximately 50 cm in a dimly lit room.</p>
          <p>The sequence of events and time course for the training and test phases are shown in <xref ref-type="fig" rid="pone-0027926-g001">Figure 1a and 1b</xref>, respectively. Each trial consisted of three displays: a fixation display, a search display, and a feedback display. During both the training and test phases, the fixation display consisted of a white fixation cross (.5°×.5° visual angle) presented in the center of the screen against a black background, and the search display consisted of the fixation cross surrounded by six shapes (2.3°×2.3° visual angle) placed at equal intervals along an imaginary circle with a 5° radius.</p>
          <p>Training Phase: During the training phase, the six shapes that comprised the search display were all circles of different colors (red, green, blue, cyan, pink, orange, yellow, and white). Targets were defined as either a red or green circle, one of which was presented on every trial in a randomly-selected location. Inside the target shape, a white line segment was oriented either vertically or horizontally, and inside each of the nontarget shapes, a white line segment was tilted at 45° to the left or to the right. The feedback display informed participants of the reward earned on the current trial, as well as total reward accumulated thus far.</p>
          <p>Test Phase: During the test phase, the search display consisted of a white circle among white diamonds or a white diamond among white circles, and the target on each trial was defined as the unique shape. On a randomly-selected half of the trials, one of the nontarget elements, the <italic>distractor</italic>, was rendered in red or green (equally often). The feedback display at test only informed participants whether their response on the current trial was correct.</p>
        </sec>
        <sec id="s2a3">
          <title>Design</title>
          <p>The experiment consisted of a single session of 1008 training trials followed by 480 test trials. Participants were provided with 50 practice trials prior to the training phase, and 20 practice trials prior to the test phase. After every 100 trials and between the two phases, participants were provided with a short break. Target identity, target location, distractor color, and distractor location were fully crossed and counterbalanced, and trials were presented in a random order.</p>
          <p>Correct responses in the training phase were followed by visual feedback indicating monetary reward. High-reward targets were followed by high-reward feedback ($0.05) on 80% of trials and low-reward feedback ($0.01) on the remaining 20%; for low-reward targets, the percentages were reversed. High-reward targets were red for half of the participants, and green for the other half. No reward feedback was provided during the initial practice block, and no reward feedback was provided during the test phase. Upon completion of the experiment, participants were given the cumulative reward they had earned.</p>
        </sec>
        <sec id="s2a4">
          <title>Procedure</title>
          <p>Each participant performed the experiment individually over the course of a single two-hour session. Each session took place inside a dimly lit laboratory room. The experimenter familiarized all participants with each task by providing written and oral descriptions of the stimuli and procedures. Participants were instructed to respond “as quickly as possible while minimizing errors.”</p>
          <p>Each trial began with the presentation of the fixation display for a randomly varying interval of 400, 500, or 600 ms. The search display then appeared and remained on screen until a response was made or the trial timed out. The training task was performed under time pressure, with trials terminating after 600 ms; during test, time pressure was lifted by lengthening this time limit to 1500 ms.</p>
          <p>Participants made a forced-choice target identification by pressing the “z” and the “m” keys for the vertically and horizontally orientated targets, respectively. Response time (RT) was measured from the onset of the target display until a response was made or the trial timed out. The computer emitted a 500 ms 1000 Hz feedback tone to inform the participant when a trial timed out. Only correct responses were included in the analysis, and all RTs more than three standard deviations above and below the mean of their respective conditions were excluded from the analysis.</p>
        </sec>
      </sec>
      <sec id="s2b">
        <title>Results and Discussion</title>
        <p>During training, mean RT to high- and low-reward targets did not differ significantly, although there was a trend toward faster responses to the target color associated with high reward, suggesting increased attentional priority [mean difference = 3.4 ms, <italic>t</italic>(17) = 1.57, <italic>p</italic> = .135]. To assess how the effect of reward on target selection changed over the course of the training phase, we analyzed the data from the training phase separately in ten bins of roughly 100 trials each. There was no interaction between reward and trial bin [<italic>F</italic>(9,153) = 1.43, <italic>p</italic> = .179], indicating that the influence of reward on RT did not change significantly over time. The main effect of trial bin was significant [<italic>F</italic>(9,153) = 4.92, <italic>p</italic>&lt;.001, η<italic><sub>p</sub></italic><sup>2</sup> = .224], however, showing that participants generally responded faster with more experience. The data for the training phase are presented in <xref ref-type="fig" rid="pone-0027926-g002">Figure 2</xref>.</p>
        <fig id="pone-0027926-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0027926.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Behavioral Results for the Training Phase of <xref ref-type="sec" rid="s2">Experiment 1</xref>.</title>
            <p>Mean response time ± within-subjects s.e.m. for high- and low-reward targets over the course of the training phase. Only the main effect of trial block was significant [<italic>F</italic>(9,153) = 4.92, <italic>p</italic>&lt;.001, η<italic><sub>p</sub></italic><sup>2</sup> = .224].</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0027926.g002" xlink:type="simple"/>
        </fig>
        <p>Of particular interest were the data from the test phase. Reward-color mapping (i.e., red vs. green as the high-reward color in the training phase) did not interact with the effect of value on performance in the test phase (<italic>F</italic>&lt;1), so further analyses collapsed across color. Response times (RTs) in the test phase differed significantly in the three distractor conditions [<xref ref-type="fig" rid="pone-0027926-g003">Figure 3</xref>, <italic>F</italic>(2,34) = 48.57, <italic>p</italic>&lt;.001, η<italic><sub>p</sub></italic><sup>2</sup> = .741]. Planned comparisons confirmed that both the high-value and low-value distractors slowed RT compared to when no distractor was presented [<italic>t</italic>(17) = 8.45, <italic>p</italic>&lt;.001, <italic>d</italic> = 1.99 and <italic>t</italic>(17) = 6.31, <italic>p</italic>&lt;.001, <italic>d</italic> = 1.47, respectively]. This replicates many previous demonstrations of attentional capture by irrelevant but physically salient feature singletons (e.g., <xref ref-type="bibr" rid="pone.0027926-Theeuwes1">[6]</xref>, <xref ref-type="bibr" rid="pone.0027926-Theeuwes2">[7]</xref>).</p>
        <fig id="pone-0027926-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0027926.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Behavioral Results for the Test Phase of <xref ref-type="sec" rid="s2">Experiment 1.</xref></title>
            <p>Mean response time ± within-subjects s.e.m. for each distractor condition over the course of the test phase. The difference in RT on trials containing a high-value vs. a low-value distractor represents the effect of learned value on salience-driven attentional capture.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0027926.g003" xlink:type="simple"/>
        </fig>
        <p>We next examined the effect of reward history on performance in the test phase. High-value distractors slowed RT significantly more than did low-value distractors [<italic>t</italic>(17) = 3.37, <italic>p</italic> = .004, <italic>d</italic> = .81]. This modulation of attentional capture by reward history cannot be attributed to differences in physical salience, and occurred despite the irrelevance of the color items to the shape-search task. To assess how the effect of reward history on attentional capture changed over the course of the test phase, we analyzed the data from the test phase separately in four equally-sized 120-trial bins. The effect of learned value on performance gradually extinguished over the course of the unrewarded test trials, as revealed by a linear trend in the difference between RTs for high- and low-value distractor trials over trial bin [<italic>F</italic>(1,17) = 17.22, <italic>p</italic> = .001, η<italic><sub>p</sub></italic><sup>2</sup> = .503]. There was no significant difference in error rates between the three distractor conditions (<xref ref-type="table" rid="pone-0027926-t001">Table 1</xref>, F&lt;1).</p>
        <table-wrap id="pone-0027926-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0027926.t001</object-id><label>Table 1</label><caption>
            <title>Response times (in milliseconds) and error rates by distractor condition for Experiments 1 and 2.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0027926-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0027926.t001" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="3" rowspan="1">Distractor Condition in<xref ref-type="sec" rid="s2">Experiment 1</xref></td>
                <td align="left" colspan="3" rowspan="1">Distractor Condition in<xref ref-type="sec" rid="s3">Experiment 2</xref></td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <underline>None</underline>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <underline>Low-Value</underline>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <underline>High-Value</underline>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <underline>None</underline>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <underline>Non-Target Colored</underline>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <underline>Target Colored</underline>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">655(5.5)</td>
                <td align="left" colspan="1" rowspan="1">710(3.9)</td>
                <td align="left" colspan="1" rowspan="1">728(3.8)</td>
                <td align="left" colspan="1" rowspan="1">588(3.6)</td>
                <td align="left" colspan="1" rowspan="1">632(4.1)</td>
                <td align="left" colspan="1" rowspan="1">634(4.8)</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">.09(.003)</td>
                <td align="left" colspan="1" rowspan="1">.10(.004)</td>
                <td align="left" colspan="1" rowspan="1">.10(.005)</td>
                <td align="left" colspan="1" rowspan="1">.11(.003)</td>
                <td align="left" colspan="1" rowspan="1">.13(.005)</td>
                <td align="left" colspan="1" rowspan="1">.13(.005)</td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt101">
              <label/>
              <p>Error terms, in parentheses, reflect the within-subjects standard error of the mean (s.e.m.).</p>
            </fn>
          </table-wrap-foot></table-wrap>
        <p>These results reveal that learned value magnifies attentional capture by salient stimuli. As the learned stimulus-value associations extinguished in the absence of reward, so did the effect of reward history on performance. However, extinction occurred gradually over many trials, resulting in a robust effect of prior reward on involuntary attention allocation for the first several hundred trials of the test phase. Taken together, these results provide strong evidence that learned value can magnify the effect of physical salience on attentional priority.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Experiment 2</title>
      <p>Despite the fact that attentional capture in <xref ref-type="sec" rid="s2">Experiment 1</xref> was significantly modulated by value, it could be that the effect of value on salience-based attentional capture was not critically dependent upon a learned association between stimuli and prior reward. Instead, it is possible that participants continued to maintain a search set for the training-phase target colors even in the test phase. Although it is known that participants can rapidly adjust task-related attentional priorities with changing task demands <xref ref-type="bibr" rid="pone.0027926-Lien1">[31]</xref>, former targets can continue to draw attention under certain conditions <xref ref-type="bibr" rid="pone.0027926-Kyllingbaek1">[32]</xref>, <xref ref-type="bibr" rid="pone.0027926-Shiffrin1">[33]</xref>. Thus, it is important to rule out this possible explanation of our results.</p>
      <p>We tested eighteen new participants who engaged in a training phase that was similar to that used in <xref ref-type="sec" rid="s2">Experiment 1</xref>, with two critical differences. First, no reward feedback was provided during training or at any point during the experiment; instead, participants were compensated with a flat rate that matched the average earnings of participants in the main experiment ($25). Second, targets were now either red or blue (with green occurring as one of the nontargets) for half of the participants, and green or blue (with red occurring as one of the nontargets) for the other participants. The test phase for all participants was identical to that of <xref ref-type="sec" rid="s2">Experiment 1</xref>. Thus, in the test phase, one color-singleton distractor had been a target color during the training phase, and the other color-singleton distractor had always been a nontarget color. If persisting priority for a former target color alone drove our main findings, we would expect an equally large – or indeed even larger – difference in RT on trials containing the color distractor that was used as a target during training versus trials containing the color distractor that was never used as a target during training.</p>
      <sec id="s3a">
        <title>Materials and Methods</title>
        <sec id="s3a1">
          <title>Participants</title>
          <p>Eighteen participants were recruited from the Johns Hopkins University community. All were screened for normal or corrected-to-normal visual acuity and color vision. Participants were compensated with $25. None of the participants had participated in <xref ref-type="sec" rid="s2">Experiment 1</xref>.</p>
        </sec>
        <sec id="s3a2">
          <title>Apparatus and Stimuli</title>
          <p>The apparatus and stimuli were identical to <xref ref-type="sec" rid="s2">Experiment 1</xref> with the following exceptions. Targets during training were either a blue or green circle (for half of the participants), or a blue or red circle. On half of the trials containing each target color, one of the nontarget-colored items was colored either red (for participants searching for green and blue targets) or green (for participants searching for red and blue targets). The feedback display during training only informed participants whether their previous response was correct.</p>
        </sec>
        <sec id="s3a3">
          <title>Design and Procedure</title>
          <p>The design and procedure were identical to <xref ref-type="sec" rid="s2">Experiment 1</xref>, with the exception that no monetary reward feedback was provided.</p>
        </sec>
      </sec>
      <sec id="s3b">
        <title>Results and Discussion</title>
        <p>Distractors at test were classified as being either the color of a former target or the color of a former nontarget. During the test phase, responses were significantly slowed by both former target-colored and former nontarget-colored distractors [<xref ref-type="fig" rid="pone-0027926-g004">Figure 4</xref>, <italic>t</italic>(17) = 7.27, <italic>p</italic>&lt;.001, <italic>d</italic> = 1.71 and <italic>t</italic>(17) = 6.13, <italic>p</italic>&lt;.001, <italic>d</italic> = 1.44, respectively]. However, we observed no difference in RT between those two distractor conditions [<xref ref-type="table" rid="pone-0027926-t001">Table 1</xref>, <italic>t</italic>(17) = 0.34, <italic>p</italic> = .740]. The magnitude of slowing caused by the former target color distractors did not decrease over the course of the test phase (<italic>F</italic>&lt;1), in contrast to <xref ref-type="sec" rid="s2">Experiment 1</xref>. As in <xref ref-type="sec" rid="s2">Experiment 1</xref>, there was no significant difference in error rates among the three conditions [<xref ref-type="table" rid="pone-0027926-t001">Table 1</xref>, <italic>F</italic>(2,34) = 2.20, <italic>p</italic> = .127].</p>
        <fig id="pone-0027926-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0027926.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Behavioral Results for the Test Phase of <xref ref-type="sec" rid="s3">Experiment 2</xref>.</title>
            <p>Mean response time ± within-subjects s.e.m. for each distractor condition over the course of the test phase.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0027926.g004" xlink:type="simple"/>
        </fig>
        <p>The slowing caused by the high-value distractor in <xref ref-type="sec" rid="s2">Experiment 1</xref> was significantly greater than that caused by the former target-colored distractor in <xref ref-type="sec" rid="s3">Experiment 2</xref> [mean difference = 27 ms, <italic>t</italic>(34) = 2.29, <italic>p</italic> = .025, <italic>d</italic> = .79]. This outcome demonstrates that value associations are necessary to produce the modulation of distraction observed in <xref ref-type="sec" rid="s2">Experiment 1</xref>, and that this modulation cannot be explained merely in terms of a persisting intention to search for former targets.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>General Discussion</title>
      <p>It is well established that physical salience and ongoing task goals influence attentional priority involuntarily (e.g., <xref ref-type="bibr" rid="pone.0027926-Theeuwes1">[6]</xref>, <xref ref-type="bibr" rid="pone.0027926-Folk2">[13]</xref>), and recent research indicates that the learned value of a stimulus also plays a direct role in determining its attentional priority <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. Although salience-based and contingency-based mechanisms of attentional control are known to jointly influence attentional priority, it is unknown whether attentional priority to salient stimuli is similarly modulated by learned value. In the present study, we addressed this question and show that the physical salience and learned value of a stimulus have a combined effect on attentional priority, with learned value increasing attentional priority above and beyond the level afforded by salience alone.</p>
      <p>Our results demonstrate that a salient but otherwise neutral stimulus, when previously associated with high reward, magnifies distraction even after that stimulus no longer predicts reward. This finding cannot be attributed to differences in physical salience, and <xref ref-type="sec" rid="s3">Experiment 2</xref> rules out persisting intention to search for a former target as an explanation. Instead, our results reveal a broad influence of learned value in determining attentional priority, one that combines with salience-based mechanisms of attentional control such that more valuable stimuli receive increased attentional priority in addition to the priority afforded by their physical salience.</p>
      <p>Navalpakkam et al. <xref ref-type="bibr" rid="pone.0027926-Navalpakkam1">[22]</xref> showed that attentional selection reflects an optimal weighting of the conspicuity of a stimulus afforded by its physical salience and its associated reward value, suggesting that value-based and salience-based attentional priority can be independently adjusted according to the relative importance of each factor given the demands of the task. There are multiple mechanisms through which value and salience might be combined in order to jointly determine attentional priority in this way. One is that learned value directly modulates the visual salience or pertinence <xref ref-type="bibr" rid="pone.0027926-Bundesen1">[34]</xref> of reward-associated stimulus features, thereby increasing their attentional priority. This possibility is supported by evidence showing that reward-associated stimulus features are represented more robustly in early visual areas of the brain <xref ref-type="bibr" rid="pone.0027926-Serences3">[25]</xref>, <xref ref-type="bibr" rid="pone.0027926-Serences4">[26]</xref>. Another possibility is that the learned value of stimuli increases attentional dwell time – that is, the time required to disengage attention after it has been captured <xref ref-type="bibr" rid="pone.0027926-Theeuwes2">[7]</xref>, <xref ref-type="bibr" rid="pone.0027926-Belopolsky1">[35]</xref>, <xref ref-type="bibr" rid="pone.0027926-Duncan1">[36]</xref>. However, we have previously shown that the learned value of stimuli is sufficient to drive attention allocation in the absence of prior attentional capture on that trial by salience or goal-relevance; similar value-driven slowing of response time has been reported for nonsalient stimuli as well <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. Thus, although a post-capture dwell time account of value-based attentional priority is plausible and cannot be ruled out in the present study, it does not provide a complete account of how learned value is known to influence attention. A third possibility is that associating targets with value causes individuals to perseverate with goal-related priorities that have been rewarded previously. This could be likened to contingent attentional capture on the basis of a reward-motivated goal state that cannot be easily overcome by virtue of its association with reward. However, because attention to valuable stimuli ran counter the goals of the task in the test phase, it is clear that the reported effects on attentional priority reflect an involuntary modulation of attentional priority by previous reward history.</p>
      <p>Our results contribute to a growing body of work that highlights an important role for reward in perception and attention <xref ref-type="bibr" rid="pone.0027926-DellaLibera1">[15]</xref>–<xref ref-type="bibr" rid="pone.0027926-Shuler1">[27]</xref>, <xref ref-type="bibr" rid="pone.0027926-Anderson2">[29]</xref>. Attentional priority to reward-related stimuli will often be adaptive, serving to maximize reward procurement. However, an inability to ignore formerly rewarding stimuli that run counter to current behavioral goals, such as desired abstinence from a drug of abuse, can be highly maladaptive. In this way, the value-based modulation of attention may play a key role in a variety of clinical syndromes in which both attention and reward have been critically implicated, including drug addiction <xref ref-type="bibr" rid="pone.0027926-Field1">[37]</xref>–<xref ref-type="bibr" rid="pone.0027926-Robinson1">[39]</xref>, obesity <xref ref-type="bibr" rid="pone.0027926-Davis1">[40]</xref>, attention-deficit hyperactivity disorder <xref ref-type="bibr" rid="pone.0027926-Bush1">[41]</xref>, and obsessive-compulsive disorder <xref ref-type="bibr" rid="pone.0027926-Sheppard1">[42]</xref>. All four of these conditions are highly comorbid <xref ref-type="bibr" rid="pone.0027926-Bush1">[41]</xref>, <xref ref-type="bibr" rid="pone.0027926-Sheppard1">[42]</xref>, suggesting a common underlying mechanism that may be related to susceptibility to the value-based modulation of attentional priority.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank H. Egeth, J. Flombaum, L. Gmeindl, and P. Holland for comments and suggestions, and E. Wampler for help in data collection.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0027926-Corbetta1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name><name name-style="western"><surname>Shulman</surname><given-names>GL</given-names></name></person-group>             <year>2002</year>             <article-title>Control of goal-directed and stimulus driven attention in the brain.</article-title>             <source>Nat Rev Neurosci</source>             <volume>3</volume>             <fpage>201</fpage>             <lpage>215</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Desimone1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Desimone</surname><given-names>R</given-names></name><name name-style="western"><surname>Duncan</surname><given-names>J</given-names></name></person-group>             <year>1995</year>             <article-title>Neural mechanisms of selective visual attention.</article-title>             <source>Annu Rev Neurosci</source>             <volume>18</volume>             <fpage>193</fpage>             <lpage>222</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Serences1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serences</surname><given-names>JT</given-names></name><name name-style="western"><surname>Shomstein</surname><given-names>S</given-names></name><name name-style="western"><surname>Leber</surname><given-names>AB</given-names></name><name name-style="western"><surname>Golay</surname><given-names>X</given-names></name><name name-style="western"><surname>Egeth</surname><given-names>HE</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Coordination of voluntary and stimulus-driven attentional control in human cortex.</article-title>             <source>Psychol Sci</source>             <volume>16</volume>             <fpage>114</fpage>             <lpage>122</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Serences2">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serences</surname><given-names>JT</given-names></name><name name-style="western"><surname>Yantis</surname><given-names>S</given-names></name></person-group>             <year>2007</year>             <article-title>Representation of attentional priority in human occipital, parietal, and frontal cortex.</article-title>             <source>Cereb Cortex</source>             <volume>17</volume>             <fpage>284</fpage>             <lpage>293</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Laurent1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Laurent</surname><given-names>PA</given-names></name></person-group>             <year>2008</year>             <article-title>The emergence of saliency and novelty responses from reinforcement learning principles.</article-title>             <source>Neural Netw</source>             <volume>21</volume>             <fpage>1493</fpage>             <lpage>1499</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Theeuwes1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>1992</year>             <article-title>Perceptual selectivity for color and form.</article-title>             <source>Percept Psychophys</source>             <volume>51</volume>             <fpage>599</fpage>             <lpage>606</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Theeuwes2">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Top-down and bottom-up control of visual selection.</article-title>             <source>Acta Psychol</source>             <volume>135</volume>             <fpage>77</fpage>             <lpage>99</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Hickey1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hickey</surname><given-names>C</given-names></name><name name-style="western"><surname>McDonald</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>Electrophysiological evidence for the capture of visual attention.</article-title>             <source>J Cogn Neurosci</source>             <volume>18</volume>             <fpage>604</fpage>             <lpage>613</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Theeuwes3">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name><name name-style="western"><surname>Godijn</surname><given-names>R</given-names></name></person-group>             <year>2002</year>             <article-title>Irrelevant singletons capture attention: Evidence from inhibition of return.</article-title>             <source>Percept Psychophys</source>             <volume>64</volume>             <fpage>764</fpage>             <lpage>770</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Yantis1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yantis</surname><given-names>S</given-names></name><name name-style="western"><surname>Jonides</surname><given-names>J</given-names></name></person-group>             <year>1984</year>             <article-title>Abrupt visual onsets and selective attention: Evidence from visual search.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>10</volume>             <fpage>350</fpage>             <lpage>374</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Folk1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Folk</surname><given-names>CL</given-names></name><name name-style="western"><surname>Remington</surname><given-names>R</given-names></name></person-group>             <year>1998</year>             <article-title>Selectivity in distraction by irrelevant featural singletons: Evidence for two forms of attentional capture.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>24</volume>             <fpage>847</fpage>             <lpage>858</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Anderson1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>BA</given-names></name><name name-style="western"><surname>Folk</surname><given-names>CL</given-names></name></person-group>             <year>2010</year>             <article-title>Variations in the magnitude of attentional capture: Testing a two-process model.</article-title>             <source>Attn Percept Psychophys</source>             <volume>72</volume>             <fpage>342</fpage>             <lpage>352</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Folk2">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Folk</surname><given-names>CL</given-names></name><name name-style="western"><surname>Remington</surname><given-names>RW</given-names></name><name name-style="western"><surname>Johnston</surname><given-names>JC</given-names></name></person-group>             <year>1992</year>             <article-title>Involuntary covert orienting is contingent on attentional control settings.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>18</volume>             <fpage>1030</fpage>             <lpage>1044</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Lamy1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lamy</surname><given-names>D</given-names></name><name name-style="western"><surname>Leber</surname><given-names>A</given-names></name><name name-style="western"><surname>Egeth</surname><given-names>HE</given-names></name></person-group>             <year>2004</year>             <article-title>Effects of task relevance and stimulus-driven salience in feature-search mode.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>30</volume>             <fpage>1019</fpage>             <lpage>1031</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-DellaLibera1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Della Libera</surname><given-names>C</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name></person-group>             <year>2006</year>             <article-title>Visual selective attention and the effects of monetary reward.</article-title>             <source>Psychol Sci</source>             <volume>17</volume>             <fpage>222</fpage>             <lpage>227</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-DellaLibera2">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Della Libera</surname><given-names>C</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name></person-group>             <year>2009</year>             <article-title>Learning to attend and to ignore is a matter of gains and losses.</article-title>             <source>Psychol Sci</source>             <volume>20</volume>             <fpage>778</fpage>             <lpage>784</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-DellaLibera3">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Della Libera</surname><given-names>C</given-names></name><name name-style="western"><surname>Perlato</surname><given-names>A</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name></person-group>             <year>2011</year>             <article-title>Dissociable effects of reward on attentional learning: From passive associations to active monitoring.</article-title>             <source>PLoS ONE</source>             <volume>6</volume>             <issue>4</issue>             <fpage>e19460</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0019460" xlink:type="simple">10.1371/journal.pone.0019460</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0027926-Hickey2">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hickey</surname><given-names>C</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Reward changes salience in human vision via the anterior cingulate.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>11096</fpage>             <lpage>11103</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Hickey3">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hickey</surname><given-names>C</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Reward guides vision when it's your thing: Trait reward-seeking in reward-mediated visual priming.</article-title>             <source>PLoS ONE</source>             <volume>5</volume>             <issue>11</issue>             <fpage>e14087</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0014087" xlink:type="simple">10.1371/journal.pone.0014087</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0027926-Hickey4">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hickey</surname><given-names>C</given-names></name><name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2011</year>             <article-title>Reward has a residual impact on target selection in visual search, but not on the suppression of distract.</article-title>             <source>Vis Cogn</source>             <volume>19</volume>             <fpage>117</fpage>             <lpage>128</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Krebs1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Krebs</surname><given-names>RM</given-names></name><name name-style="western"><surname>Boehler</surname><given-names>CN</given-names></name><name name-style="western"><surname>Woldorff</surname><given-names>MG</given-names></name></person-group>             <year>2010</year>             <article-title>The influence of reward associations on conflict processing in the Stroop task.</article-title>             <source>Cognition</source>             <volume>117</volume>             <fpage>341</fpage>             <lpage>347</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Navalpakkam1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Navalpakkam</surname><given-names>V</given-names></name><name name-style="western"><surname>Koch</surname><given-names>C</given-names></name><name name-style="western"><surname>Rangel</surname><given-names>A</given-names></name><name name-style="western"><surname>Perona</surname><given-names>P</given-names></name></person-group>             <year>2010</year>             <article-title>Optimal reward harvesting in complex perceptual environments.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>107</volume>             <fpage>5232</fpage>             <lpage>5237</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Peck1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Peck</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Jangraw</surname><given-names>DC</given-names></name><name name-style="western"><surname>Suzuki</surname><given-names>M</given-names></name><name name-style="western"><surname>Efem</surname><given-names>R</given-names></name><name name-style="western"><surname>Gottlieb</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Reward modulates attention independently of action value in posterior parietal cortex.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>11182</fpage>             <lpage>11191</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Raymond1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Raymond</surname><given-names>JE</given-names></name><name name-style="western"><surname>O'Brien</surname><given-names>JL</given-names></name></person-group>             <year>2009</year>             <article-title>Selective visual attention and motivation: The consequences of value learning in an attentional blink task.</article-title>             <source>Psychol Sci</source>             <volume>20</volume>             <fpage>981</fpage>             <lpage>988</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Serences3">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serences</surname><given-names>JT</given-names></name></person-group>             <year>2008</year>             <article-title>Value-based modulations in human visual cortex.</article-title>             <source>Neuron</source>             <volume>60</volume>             <fpage>1169</fpage>             <lpage>1181</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Serences4">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serences</surname><given-names>JT</given-names></name><name name-style="western"><surname>Saproo</surname><given-names>S</given-names></name></person-group>             <year>2010</year>             <article-title>Population response profiles in early visual cortex are biased in favor of more valuable stimuli.</article-title>             <source>J Neurophysiol</source>             <volume>104</volume>             <fpage>76</fpage>             <lpage>87</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Shuler1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shuler</surname><given-names>MG</given-names></name><name name-style="western"><surname>Bear</surname><given-names>MF</given-names></name></person-group>             <year>2006</year>             <article-title>Reward timing in the primary visual cortex.</article-title>             <source>Science</source>             <volume>311</volume>             <fpage>1606</fpage>             <lpage>1609</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Maunsell1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group>             <year>2004</year>             <article-title>Neuronal representations of cognitive state: Reward or attention?</article-title>             <source>Trends Cogn Sci</source>             <volume>8</volume>             <fpage>261</fpage>             <lpage>265</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Anderson2">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>BA</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>PA</given-names></name><name name-style="western"><surname>Yantis</surname><given-names>S</given-names></name></person-group>             <year>2011</year>             <article-title>Value-driven attentional capture.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>108</volume>             <fpage>10367</fpage>             <lpage>10371</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Bacon1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bacon</surname><given-names>WF</given-names></name><name name-style="western"><surname>Egeth</surname><given-names>HE</given-names></name></person-group>             <year>1994</year>             <article-title>Overriding stimulus-driven attentional capture.</article-title>             <source>Percept Psychophys</source>             <volume>55</volume>             <fpage>485</fpage>             <lpage>496</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Lien1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lien</surname><given-names>M-C</given-names></name><name name-style="western"><surname>Ruthruff</surname><given-names>E</given-names></name><name name-style="western"><surname>Johnston</surname><given-names>JV</given-names></name></person-group>             <year>2010</year>             <article-title>Attentional capture with rapidly changing attentional control settings.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>36</volume>             <fpage>1</fpage>             <lpage>16</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Kyllingbaek1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kyllingbaek</surname><given-names>S</given-names></name><name name-style="western"><surname>Schneider</surname><given-names>WX</given-names></name><name name-style="western"><surname>Bundesen</surname><given-names>C</given-names></name></person-group>             <year>2001</year>             <article-title>Automatic attraction of attention to former targets in visual displays of letters.</article-title>             <source>Percept Psychophys</source>             <volume>63</volume>             <fpage>85</fpage>             <lpage>98</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Shiffrin1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shiffrin</surname><given-names>RM</given-names></name><name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name></person-group>             <year>1977</year>             <article-title>Controlled and automatic human information processing II: Perceptual learning, automatic attending, and general theory.</article-title>             <source>Psychol Rev</source>             <volume>84</volume>             <fpage>127</fpage>             <lpage>190</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Bundesen1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bundesen</surname><given-names>C</given-names></name></person-group>             <year>1990</year>             <article-title>A theory of visual attention.</article-title>             <source>Psychol Rev</source>             <volume>97</volume>             <fpage>523</fpage>             <lpage>547</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Belopolsky1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Belopolsky</surname><given-names>AV</given-names></name><name name-style="western"><surname>Schreij</surname><given-names>D</given-names></name><name name-style="western"><surname>Theeuwes</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>What is top-down about contingent capture?</article-title>             <source>Attn Percept Psychophys</source>             <volume>72</volume>             <fpage>326</fpage>             <lpage>341</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Duncan1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Duncan</surname><given-names>J</given-names></name><name name-style="western"><surname>Ward</surname><given-names>R</given-names></name><name name-style="western"><surname>Shapiro</surname><given-names>K</given-names></name></person-group>             <year>1994</year>             <article-title>Direct measurement of attentional dwell time in human vision.</article-title>             <source>Nature</source>             <volume>369</volume>             <fpage>313</fpage>             <lpage>315</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Field1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Field</surname><given-names>M</given-names></name><name name-style="western"><surname>Cox</surname><given-names>WM</given-names></name></person-group>             <year>2008</year>             <article-title>Attentional bias in addictive behaviors: A review of its development, causes, and consequences.</article-title>             <source>Drug Alcohol Depend</source>             <volume>97</volume>             <fpage>1</fpage>             <lpage>20</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Garavan1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Garavan</surname><given-names>H</given-names></name><name name-style="western"><surname>Hester</surname><given-names>R</given-names></name></person-group>             <year>2007</year>             <article-title>The role of cognitive control in cocaine dependence.</article-title>             <source>Neuropsychol Rev</source>             <volume>17</volume>             <fpage>337</fpage>             <lpage>345</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Robinson1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Robinson</surname><given-names>TE</given-names></name><name name-style="western"><surname>Berridge</surname><given-names>KC</given-names></name></person-group>             <year>2008</year>             <article-title>The incentive sensitization theory of addiction: some current issues.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>363</volume>             <fpage>3137</fpage>             <lpage>3146</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Davis1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Davis</surname><given-names>C</given-names></name></person-group>             <year>2010</year>             <article-title>Attention-deficit/hyperactivity disorder: associations with overeating and obesity.</article-title>             <source>Curr Psychiatry Rep</source>             <volume>12</volume>             <fpage>389</fpage>             <lpage>395</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Bush1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bush</surname><given-names>G</given-names></name></person-group>             <year>2010</year>             <article-title>Attention-deficit/hyperactivity disorder and attention networks.</article-title>             <source>Neuropsychopharmacology</source>             <volume>35</volume>             <fpage>278</fpage>             <lpage>300</lpage>          </element-citation>
      </ref>
      <ref id="pone.0027926-Sheppard1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sheppard</surname><given-names>B</given-names></name><name name-style="western"><surname>Chavira</surname><given-names>D</given-names></name><name name-style="western"><surname>Azzam</surname><given-names>A</given-names></name><name name-style="western"><surname>Grados</surname><given-names>MA</given-names></name><name name-style="western"><surname>Umaña</surname><given-names>P</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>ADHD prevalence and association with hoarding behaviors in childhood onset OCD.</article-title>             <source>Depress Anxiety</source>             <volume>27</volume>             <fpage>667</fpage>             <lpage>674</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>