<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00239</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003179</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subject>Regulatory networks</subject><subject>Systems biology</subject></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group><subject>Systems biology</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Stochasticity, Bistability and the Wisdom of Crowds: A Model for Associative Learning in Genetic Regulatory Networks</article-title>
<alt-title alt-title-type="running-head">Stochasticity, Bistability and the Wisdom of Crowds</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sorek</surname><given-names>Matan</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Balaban</surname><given-names>Nathalie Q.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Loewenstein</surname><given-names>Yonatan</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Edmond and Lily Safra Center for Brain Sciences and the Interdisciplinary Center for Neural Computation, The Hebrew University of Jerusalem, Jerusalem, Israel</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Genetics, The Alexander Silberman Institute of Life Sciences, The Hebrew University of Jerusalem, Jerusalem, Israel</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Racah Institute of Physics, Center for Nanoscience and Nanotechnology and Sudarsky Center for Computational Biology, The Hebrew University of Jerusalem, Jerusalem, Israel</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Department of Neurobiology and the Center for the Study of Rationality, The Hebrew University of Jerusalem, Jerusalem, Israel</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>de Polavieja</surname><given-names>Gonzalo G.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Cajal Institute, Consejo Superior de Investigaciones Científicas, Spain</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">matan.sorek@mail.huji.ac.il</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: MS NQB YL. Performed the experiments: MS YL. Analyzed the data: MS NQB YL. Contributed reagents/materials/analysis tools: MS NQB YL. Wrote the paper: MS NQB YL.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>8</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>22</day><month>8</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>8</issue>
<elocation-id>e1003179</elocation-id>
<history>
<date date-type="received"><day>7</day><month>2</month><year>2013</year></date>
<date date-type="accepted"><day>1</day><month>7</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Sorek et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>It is generally believed that associative memory in the brain depends on multistable synaptic dynamics, which enable the synapses to maintain their value for extended periods of time. However, multistable dynamics are not restricted to synapses. In particular, the dynamics of some genetic regulatory networks are multistable, raising the possibility that even single cells, in the absence of a nervous system, are capable of learning associations. Here we study a standard genetic regulatory network model with bistable elements and stochastic dynamics. We demonstrate that such a genetic regulatory network model is capable of learning multiple, general, overlapping associations. The capacity of the network, defined as the number of associations that can be simultaneously stored and retrieved, is proportional to the square root of the number of bistable elements in the genetic regulatory network. Moreover, we compute the capacity of a clonal population of cells, such as in a colony of bacteria or a tissue, to store associations. We show that even if the cells do not interact, the capacity of the population to store associations substantially exceeds that of a single cell and is proportional to the number of bistable elements. Thus, we show that even single cells are endowed with the computational power to learn associations, a power that is substantially enhanced when these cells form a population.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>It has been known since the pioneering studies of Ivan Petrovich Pavlov that changes in the nervous system enable animals to associate neutral stimuli with stimuli of ecological significance. The goal of this paper is to study whether genetic regulatory networks that govern the production and degradation of proteins in all living cells are capable of a similar associative learning. We show that a standard model of a genetic regulatory network is capable of learning multiple overlapping associations, similar to a neural network. These results demonstrate that even bacteria that are devoid of a nervous system can learn associations. Moreover, as cells often reside in large clonal populations, as in a colony of bacteria or in tissue, we consider the ability of a large population of identical cells to learn associations. We show that even if the cells do not interact, the computational capabilities of the population far exceed those of the single cell. This result is a first demonstration of “wisdom of crowds” in clonal populations of cells. Finally, we provide specific guidelines for the experimental detection of associative learning in populations of bacteria, a phenomenon that may have been overlooked in standard experiments.</p>
</abstract>
<funding-group><funding-statement>This work was supported by an Innovative Research grant from the Hebrew University (to YL and NQB), the Israel Science Foundation (grant # 592/10 to NQB and grant # 868/08 to YL), the Gatsby Charitable Foundation (to YL) and the European Research Council (grant # 260871 to NQB). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="15"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<sec id="s1a">
<title>Associative learning</title>
<p>Almost all animals can associate neutral stimuli and stimuli of ecological significance <xref ref-type="bibr" rid="pcbi.1003179-Pavlov1">[1]</xref>. An extensively studied example is eye-blink conditioning (<xref ref-type="fig" rid="pcbi-1003179-g001">Figure 1</xref>) <xref ref-type="bibr" rid="pcbi.1003179-Kitazawa1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Medina1">[3]</xref>. Naïve rabbits respond to an airpuff to the cornea (Unconditioned Stimulus, US) with eyelid closure (Unconditioned Response, UR). By contrast, a weak auditory or visual stimulus (Conditioned Stimulus, CS) does not elicit such an overt response. Repeated pairing of the CS and the US forms a cognitive association between the CS and the US such that the trained animal responds to the CS with eyelid closure, a response known as Conditioned Response (CR). Two important characteristics of associative learning are (1) specificity and (2) generality. The CR does not reflect a general arousal. Rather, the animal learns to respond specifically to the CS. The generality is reflected by the fact that a large family of potential stimuli can serve as a CS if paired with the US.</p>
<fig id="pcbi-1003179-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g001</object-id><label>Figure 1</label><caption>
<title>A schematic illustration of eye-blink conditioning.</title>
<p>(A) Naïve animal responds to the presentation of an airpuff (the US) by eyelid closure. (B) By contrast, a tone (the CS) does not elicit any overt response. (C) During conditioning the CS and the US are repeatedly paired. (D) After conditioning the animal responds to the CS with eyelid closure (the CR).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g001" position="float" xlink:type="simple"/></fig>
<p>Neuronal networks are particularly adapted to performing this association and in the last few decades there has been considerable progress in understanding the ways in which experience-based changes in synapses in the nervous system underlie this associative learning process <xref ref-type="bibr" rid="pcbi.1003179-Rumpel1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Nakazawa1">[5]</xref>. Neural network models for associative memory, which explain how both specificity and generality are maintained, are typically based on three elements: (1) Synapses are the physical loci of the memory; (2) synaptic plasticity underlies memory encoding; (3) neural network dynamics, in which the activities of neurons depend on the synaptic efficacies, underlie the retrieval of the learned memories in response to the CS.</p>
</sec><sec id="s1b">
<title>Genetic regulatory networks</title>
<p>Genetic regulatory networks (GRN) describe the interaction of genes in the cell through their RNA and protein products <xref ref-type="bibr" rid="pcbi.1003179-Smolen1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-GarciaOjalvo1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Alon1">[8]</xref>. Previous studies have pointed out the similarity between the dynamics of GRNs and the dynamics of neural networks <xref ref-type="bibr" rid="pcbi.1003179-Bray1">[9]</xref>. For example, GRNs, like neural networks, can implement logic-like circuits, where the concentration of a protein (high or low) corresponds to the binary state of the gate <xref ref-type="bibr" rid="pcbi.1003179-Buchler1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Wang1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Anderson1">[12]</xref>. These findings prompted us to evaluate the capacity of GRNs to learn associations.</p>
<p>Considering associative learning in animals, the US is typically a stimulus of biological significance, such as food or a noxious stimulus that elicits a response (UR) in the naïve animal, either in the form of muscle activation or gland secretion. The GRN correlate of a pain-inducing stimulus is stress. Stressful conditions such as heat, extreme pH, or toxic chemicals often result in a substantial change in the expression level of many different proteins in the cell. For example, <italic>Escherichia coli</italic> (<italic>E. coli</italic>) bacteria respond to a variety of stress conditions by a general stress response mechanism in which the master regulator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e001" xlink:type="simple"/></inline-formula> controls the expression of many genes <xref ref-type="bibr" rid="pcbi.1003179-HenggeAronis1">[13]</xref>. These stressful conditions can be regarded as a US and the resultant change in the expression level of the proteins can be regarded as a UR. By contrast, other stimuli may result in a narrow or absence of a response of the cell and in that sense can be referred to as potential CS. Learning in this framework would correspond to the formation of an association between these potential CS and US such that following the repeated pairing of the CS and US, the presentation of the CS would elicit a UR-like response (CR).</p>
<p>The responsiveness of the GRNs to different stimuli has been shown to change over time in response to evolutionary pressure in a manner that resembles associative learning <xref ref-type="bibr" rid="pcbi.1003179-Mitchell1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Tagkopoulos1">[15]</xref>. These changes take place on time scales that are substantially longer than the lifetime of a single cell and in contrast to associative learning in animals, entail modifications of the genome through mutations. On a shorter timescale, there is some evidence that the single-celled <italic>Paramecium</italic> can learn to associate a CS with a US within its lifetime <xref ref-type="bibr" rid="pcbi.1003179-Hennessey1">[16]</xref>. However, these findings have been disputed <xref ref-type="bibr" rid="pcbi.1003179-Armus1">[17]</xref> and the question of whether <italic>Paramecia</italic> can learn associations and the characteristics of this learning await further experimental validation. The capacity of GRNs to learn associations in shorter, non-evolutionary time-scales has also been studied theoretically using GRN models. Learning in these models is restricted to a small subset of predefined stimuli <xref ref-type="bibr" rid="pcbi.1003179-Fritz1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Fernando1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Gandhi1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Ginsburg1">[21]</xref> and thus the computational capabilities of these GRN models are limited compared to neural network models.</p>
<p>Here we show that a GRN based on bistable elements and stochastic transitions can learn associations while retaining both specificity and generality. We further compute the capacity of the network and show that the number of different learned associations that the network can simultaneously retain is proportional to the square root of the number of bistable elements. Moreover, this capacity is substantially enhanced when considering a clonal population of GRNs. These results imply that even bacteria are endowed with the capacity to learn multiple associations.</p>
</sec></sec><sec id="s2">
<title>Results</title>
<p>Our Genetic Associative Memory model (GAM) for associative learning is based on three components: (1) a memory module that provides the long time-scale necessary for the maintenance of memories for long periods of time; (2) a mechanism for encoding the desired memories and (3) a response mechanism for the readout or retrieval of the stored memories in response to the relevant stimuli. We describe the three components separately in the simpler case of a predefined association and then generalize to the case of multiple associations and to the case of a population of GAMs.</p>
<sec id="s2a">
<title>Learning a predefined association</title>
<sec id="s2a1">
<title>Memory</title>
<p>A necessary condition for associative learning is the ability to maintain memories. Memories require a long time-scale, which characterizes multistable dynamics <xref ref-type="bibr" rid="pcbi.1003179-Loewenstein1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Loewenstein2">[23]</xref>. For example, the ability of flip-flop devices in electronic circuits to maintain memories is based on their bistable dynamics. Bistability naturally emerges in dynamical systems if two conditions are fulfilled: positive feedback and saturation <xref ref-type="bibr" rid="pcbi.1003179-Ferrell1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Wilhelm1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Koulakov1">[26]</xref>. Both these requirements characterize many GRNs, and bistability has been found in both artificially engineered <xref ref-type="bibr" rid="pcbi.1003179-Gardner1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-AjoFranklin1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Kramer1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Isaacs1">[30]</xref> and natural GRNs <xref ref-type="bibr" rid="pcbi.1003179-Novick1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Ferrell2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Xiong1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Bagowski1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Hasty1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Pomerening1">[36]</xref>. For example, the response of the lactose promoter in <italic>E. coli</italic> to intermediate induction levels was shown to be bistable because of the positive feedback loop on the import of the inducer in the cell <xref ref-type="bibr" rid="pcbi.1003179-Ozbudak1">[37]</xref>.</p>
<p>In our GAM, we assume a positive feedback loop between a gene and its protein product. The gene encodes for a protein <italic>M</italic> which binds cooperatively, as a transcription factor, to the promoter of that gene, resulting in further synthesis of <italic>M</italic>. The kinetic reactions describing the dynamics of <italic>M</italic> appear in <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in the Supporting Information, and their deterministic approximation <xref ref-type="bibr" rid="pcbi.1003179-GarciaOjalvo1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Alon1">[8]</xref> is equivalent to those of positive feedback loops such as the lac system <xref ref-type="bibr" rid="pcbi.1003179-Mahaffy1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Yildirim1">[39]</xref>:<disp-formula id="pcbi.1003179.e002"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e002" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e003" xlink:type="simple"/></inline-formula> reflects the nonlinear positive feedback (see <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). The second term in <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> denotes the protein degradation, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e004" xlink:type="simple"/></inline-formula> is a parameter. The third term models the contribution of external factors to the dynamics of <italic>M</italic> (see below).</p>
<p>The function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e005" xlink:type="simple"/></inline-formula>, depicted in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref> (top), is N-shaped and is characterized by three zero-crossings. The two outermost zero-crossings (red arrows in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref>, top) correspond to the two stable states (or fixed-points): a low expression level of <italic>M</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e006" xlink:type="simple"/></inline-formula> (left) and a high expression level, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e007" xlink:type="simple"/></inline-formula> (right). It can be readily shown that the intermediate zero-crossing (black arrow) corresponds to an unstable fixed-point of the dynamics. Thus, the dynamics of <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> converge to one of the equilibrium values, the low or high expression level of <italic>M</italic>, depending on the initial conditions. This bistability of the dynamics of <italic>M</italic> endows the GRN with the capacity to store binary memories in the form of the level of expression of <italic>M</italic>. For this reason we refer to <italic>M</italic> as a ‘pseudo-synapse’.</p>
<fig id="pcbi-1003179-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g002</object-id><label>Figure 2</label><caption>
<title>The bistable dynamics of the memory element.</title>
<p>(<bold>A–C</bold>) The dynamics described by <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> for three different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e008" xlink:type="simple"/></inline-formula>. Top, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e009" xlink:type="simple"/></inline-formula>; bottom, the corresponding energy function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e010" xlink:type="simple"/></inline-formula>. The red and black arrows denote the stable and unstable fixed points, respectively (zero crossings of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e011" xlink:type="simple"/></inline-formula>, top and extrema of the energy function, bottom). The value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e012" xlink:type="simple"/></inline-formula> determines the offset of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e013" xlink:type="simple"/></inline-formula> and hence the energy gaps. (<bold>B</bold>) The larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e014" xlink:type="simple"/></inline-formula> is, the smaller the energy gap corresponding to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e015" xlink:type="simple"/></inline-formula>. (<bold>C</bold>) The smaller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e016" xlink:type="simple"/></inline-formula> is, the smaller the energy gap corresponding to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e017" xlink:type="simple"/></inline-formula>. The values of the external inputs are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e018" xlink:type="simple"/></inline-formula> in A–C, respectively.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g002" position="float" xlink:type="simple"/></fig>
<p>It is useful to rewrite <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> using an ‘energy’ function such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e019" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e020" xlink:type="simple"/></inline-formula>. The energy function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e021" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref>, bottom) is characterized by two minima (red arrows) and one local maximum (black arrow). The two minima correspond to the two stable fixed points of the dynamics of <italic>M</italic> and the maximum corresponds to the intermediate unstable fixed point.</p>
<p>The differences between the value of the energy function at the maximum and the values at the minima are known as the energy gaps and are denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e022" xlink:type="simple"/></inline-formula>. In <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref> the two energy gaps are approximately equal. However, an increase in the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e023" xlink:type="simple"/></inline-formula> raises the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e024" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2B</xref> top), resulting in a smaller energy gap for the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e025" xlink:type="simple"/></inline-formula> fixed point, and a larger energy gap for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e026" xlink:type="simple"/></inline-formula> fixed point (<xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2B</xref> bottom). By contrast, a decrease in the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e027" xlink:type="simple"/></inline-formula> lowers the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e028" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2C</xref> top), resulting in the opposite effect: a larger energy gap for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e029" xlink:type="simple"/></inline-formula>, and a smaller energy gap for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e030" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2C</xref> bottom).</p>
<p>It should be noted that <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> is a deterministic approximation of the biochemical dynamics. Biochemical processes such as the bursting activity of the transcriptional machinery are stochastic <xref ref-type="bibr" rid="pcbi.1003179-Raj1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Raj2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Golding1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Bialek1">[43]</xref>. One way to account for the stochasticity is by adding white noise to <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref> such that<disp-formula id="pcbi.1003179.e031"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e031" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e032" xlink:type="simple"/></inline-formula> is a Gaussian white noise, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e033" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e034" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e035" xlink:type="simple"/></inline-formula> is the magnitude of the noise and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e036" xlink:type="simple"/></inline-formula> is the Dirac delta “function”.</p>
<p>One consequence of this stochasticity is that the noise is expected to occasionally induce transitions between the two fixed points. A well-known result from the field of stochastic processes is that if the noise is sufficiently weak, the rate of transitions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e037" xlink:type="simple"/></inline-formula> from one minimum to the other is exponentially dependent on the energy gap, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e038" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e039" xlink:type="simple"/></inline-formula> (e.g., see <xref ref-type="bibr" rid="pcbi.1003179-Neiman1">[44]</xref>, and see also <xref ref-type="bibr" rid="pcbi.1003179-VanKampen1">[45]</xref> for a more accurate approximation). Consequently, even a small change in the energy gap is expected to result in a large change in the transition rate. Thus, although the three energy functions in <xref ref-type="fig" rid="pcbi-1003179-g001">Figure 1A–C</xref> are qualitatively similar, they represent very different dynamics. For sufficiently weak noise, the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e040" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e041" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2B</xref> is negligible compared to the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e042" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e043" xlink:type="simple"/></inline-formula>. Similarly, the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e044" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e045" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2C</xref> is negligible compared to the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e046" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e047" xlink:type="simple"/></inline-formula>. Moreover, the rates of transition between the two stable states in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref> are both negligible compared to the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e048" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e049" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2B</xref> or the rate of transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e050" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e051" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2C</xref>. Thus, the transitions between the states are highly dependent on the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e052" xlink:type="simple"/></inline-formula>. We utilize these results when modeling the memory encoding in the next section.</p>
</sec><sec id="s2a2">
<title>Encoding</title>
<p>In associative learning, memory is encoded in response to the contiguity of the CS and the US. To implement this idea in the framework of the GAM, we assume that the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e053" xlink:type="simple"/></inline-formula> is determined by external cues, the CS and US. Formally, we assume that the CS and the US induce the expression of proteins <italic>C</italic> and <italic>U</italic>, respectively. The value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e054" xlink:type="simple"/></inline-formula> is determined by the concentrations of <italic>C</italic> and <italic>U</italic> such that the US is effectively a repressor of <italic>M</italic> but the co-occurrence of US and CS activates the expression of <italic>M</italic> (see <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In other words, <italic>U</italic> in isolation decreases <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e055" xlink:type="simple"/></inline-formula> but when bound to <italic>C</italic> it increases <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e056" xlink:type="simple"/></inline-formula>. This mode of regulation has already been observed; e.g., in the osmotic response regulatory system in yeast <xref ref-type="bibr" rid="pcbi.1003179-Proft1">[46]</xref>.</p>
<p>For simplicity we assume in our model that the expression levels of <italic>C</italic> and <italic>U</italic> are binary, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e057" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e058" xlink:type="simple"/></inline-formula>, reflecting the presence or absence of the CS and US, respectively. Moreover, we assume that independently of the external cues, the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e059" xlink:type="simple"/></inline-formula> is such that the dynamics of the pseudo-synapse are bistable (as in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2</xref>). Thus, the co-occurrence of the CS and US increases the transition rate to the high expression level of <italic>M</italic> (as in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2B</xref>) whereas an exposure of the GAM to the US alone increases the transition rate to the low expression level of <italic>M</italic> (as in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2C</xref>).</p>
<p>The computational implications of these dynamics are that a repeated exposure of the GAM to the co-occurrence of the CS and US is expected to result in a high state of <italic>M</italic>, whereas a repeated exposure of the GAM to the US in the absence of the CS is expected to result in a low state of <italic>M</italic>. In this sense, the state of <italic>M</italic> is the physical correlate of the memory of the association between the CS and US and a high level of <italic>M</italic> indicates an association between the CS and US. Assuming that in the absence of the US, the two energy gaps are high (as in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2A</xref>), the transition rates between the two states of the pseudo-synapse, in both directions, would be low. Thus, in the absence of the US, information about the existence of an association, as well as its absence, would be maintained for long periods of time. These dynamics are reminiscent of a multiplexer. A multiplexer is a device that selects one of several input signals and forwards the selected input into a single line. In the dynamics of <italic>M</italic>, the US selects whether <italic>M</italic> will be maintained (in the absence of the US) or whether the value of <italic>M</italic> is determined by the CS (in the presence of the US), as in <xref ref-type="bibr" rid="pcbi.1003179-Fritz1">[18]</xref>. However, in contrast to a standard multiplexer, transitions in our model are stochastic. Thus, the dynamics depicted in <xref ref-type="fig" rid="pcbi-1003179-g002">Figure 2</xref> resemble a stochastic multiplexer. This difference implies that multiple repetitions are needed in order to change the state of <italic>M</italic> with a high probability.</p>
</sec><sec id="s2a3">
<title>Retrieval</title>
<p>The last component of our GAM is a readout scheme that decodes the state of <italic>M</italic> in the presence of a CS such that the CS elicits a response if and only if the expression level of <italic>M</italic> is high. To implement this, we assume that the UR and the CR manifest in the GAM as the production of a response protein <italic>R</italic>. The expression of <italic>R</italic> is regulated by two mechanisms: the US regulates the expression of <italic>R</italic> through the binding of <italic>U</italic> to a promoter of <italic>R</italic>, and the CS-pseudo-synapse pair regulates the expression of <italic>R</italic> by cooperative binding of <italic>C</italic> and <italic>M</italic> to another promoter (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3A</xref>). The kinetic reactions describing the dynamics of the expression of <italic>R</italic> appear in <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in the Supporting Information, and their deterministic approximation is given by:<disp-formula id="pcbi.1003179.e060"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e060" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e061" xlink:type="simple"/></inline-formula> is the degradation rate of <italic>R</italic> and the functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e062" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e063" xlink:type="simple"/></inline-formula> describe the dependence of the expression of <italic>R</italic> on <italic>U</italic>, <italic>C</italic> and <italic>M</italic> (see <xref ref-type="disp-formula" rid="pcbi.1003179.e136">Eq. (5)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). A high level of <italic>U</italic> in <xref ref-type="disp-formula" rid="pcbi.1003179.e060">Eq. (3)</xref> results in a high value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e064" xlink:type="simple"/></inline-formula>. This elicits the expression of <italic>R</italic>, independently of the values of <italic>M</italic> and <italic>C</italic>, corresponding to the UR. By contrast, a high level of <italic>C</italic> results in a high level of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e065" xlink:type="simple"/></inline-formula> only when <italic>M</italic> is in its high expression level. Thus, in the absence of the US, the stimulus substantially increases <italic>R</italic> only when <italic>M</italic> is in its high expression level, corresponding to the CR.</p>
<fig id="pcbi-1003179-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g003</object-id><label>Figure 3</label><caption>
<title>A model for a Genetic Associative Memory module (GAM).</title>
<p>(A) A logic circuit representing the GRN's regulatory dynamics. The external signals CS (blue) and US (orange) induce the expression of the proteins <italic>C</italic> (blue) and <italic>U</italic> (orange), respectively. The expression of <italic>U</italic> elicits a response <italic>R</italic> (green) independently of <italic>C</italic>. In contrast, <italic>C</italic> elicits a response <italic>R</italic> only if the expression level of <italic>M</italic> (red) is high. The expression of <italic>M</italic> is induced by a high concentration of <italic>M</italic> (the positive feedback, <xref ref-type="disp-formula" rid="pcbi.1003179.e031">Eq. (2)</xref>) or by the co-expression of <italic>C</italic> and <italic>U</italic>, and is inhibited by the expression of <italic>U</italic> in the absence of <italic>C</italic>. (B) Associative learning in a simulation of the GAM. Initially, the GAM is in the naïve state, in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e066" xlink:type="simple"/></inline-formula>. In this state the GAM responds to the US (orange) but not to the CS (blue rectangles). Repeated pairing of the CS and US (<italic>t</italic> = 3, 4 and 5 h) changes the state of <italic>M</italic> (color coded in brightness) to the high state (immediately after <italic>t</italic> = 5 h). As a result, the GAM is responsive to the CS in isolation (<italic>t</italic> = 6 and 7 h). In response to repeated presentation of the US in the absence of the CS (<italic>t</italic> = 8, 9, 10 and 11 h), the expression level of <italic>M</italic> reverts to the low state (immediately after <italic>t</italic> = 11 h) resulting in a loss of response to the learned CS (<italic>t</italic> = 12 and 13 h). Note that the response at <italic>t</italic> = 5 h is slightly higher than the responses at previous times. This results from the transition of <italic>M</italic> to its high state.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g003" position="float" xlink:type="simple"/></fig>
<p>The dynamics of <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eqs. (1</xref>–<xref ref-type="disp-formula" rid="pcbi.1003179.e060">3)</xref> describe a GAM that can learn the association between a CS and a US. This is demonstrated in <xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3B</xref>. Initially, at time <italic>t</italic> = 0, <italic>M</italic> is in the low expression level state, corresponding to the ‘naïve’ state of the network prior to learning. In this state, a US (orange rectangle, <italic>t</italic> = 1 h) elicits a response (UR), but a CS (open blue rectangle, <italic>t</italic> = 2 h) does not elicit any response. Following two pairings of the CS and US (<italic>t</italic> = 3 and 4 h), the state of <italic>M</italic> does not change but in response to the third pairing (<italic>t</italic> = 5 h) the state of <italic>M</italic> changes to the high state level. In this state, the GAM is responsive to both a CS (<italic>t</italic> = 6 and 7 h) and a US (<italic>t</italic> = 8 h). Three presentations of the US in the absence of a CS (<italic>t</italic> = 8–10 h) do not elicit any change in the state of <italic>M</italic> but in response to another presentation of the US in the absence of a CS (<italic>t</italic> = 11 h), the state of <italic>M</italic> reverts to its low value, and the GAM is no longer responsive to CS (at <italic>t</italic> = 12 and 13 h).</p>
</sec></sec><sec id="s2b">
<title>Learning multiple associations</title>
<p>In the previous section, we demonstrated that a GRN can learn to associate a CS with a US (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3</xref>). However, this learning is limited, as it is specific to a single, predefined CS. This GAM can be trivially generalized to enable the learning of several different associations by postulating that the GAM is characterized by a number of memory elements, each associated with a single CS. However, this generalized GAM is still limited in its ability to learn associations because only those predefined CS can be learned. This limitation contrasts sharply with neural network models, which are capable of learning general associations. In this section we generalize the model presented in <xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3A</xref> and show that similar to neural network models, GRNs are also endowed with the capacity to learn a large number of arbitrary, overlapping CS.</p>
<p>Consider the network described <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4A</xref>. In contrast to the single-pathway model (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3A</xref>), in which a CS induces the expression of a single protein <italic>C</italic>, in the generalized model we assume that the CS are complex stimuli that activate <italic>N</italic> different receptors, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e067" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e068" xlink:type="simple"/></inline-formula>. Each receptor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e069" xlink:type="simple"/></inline-formula> is associated with a single pseudo-synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e070" xlink:type="simple"/></inline-formula>. The dynamics of each of the pseudo-synapses follow the same equations as in the single-pathway model (not shown in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4A</xref>, see <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p>
<fig id="pcbi-1003179-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g004</object-id><label>Figure 4</label><caption>
<title>A model for learning multiple overlapping associations.</title>
<p>(A) A schematic description of the dependence of the expression of <italic>R</italic> (green) on the activation of the receptors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e071" xlink:type="simple"/></inline-formula> (blue), the pseudo-synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e072" xlink:type="simple"/></inline-formula> (red) and the US (orange), see <xref ref-type="disp-formula" rid="pcbi.1003179.e136">Eq. (5)</xref>. Note that for reasons of clarity, the encoding process, which follows the same dynamics as in <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> (see <xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3A</xref>) is not shown. (B) Simulation of the model (<xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eqs. (4)</xref> and <xref ref-type="disp-formula" rid="pcbi.1003179.e136">(5)</xref>). Bottom, the expression level of 5 representative pseudo-synapses over time is depicted using a color code (color coded in brightness); green, the response <italic>R</italic>; orange rectangles, the timing of a US; open blue rectangles, the timing of activations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e073" xlink:type="simple"/></inline-formula> by a stimulus. Initially, the GAM is in a naïve state. In that state, its response to CS (<italic>t</italic> = 0, 1, 2, 3 and 4 h) is below some threshold (dashed horizontal line). In response to the pairing of three of the CS (C, B and A) with the US (<italic>t</italic> = 5, 6 and 7 h, respectively), a fraction of the pseudo-synapses which correspond to an active <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e074" xlink:type="simple"/></inline-formula> undergo a transition to the high expression state (e.g., <italic>i</italic> = 2 at <italic>t</italic> = 6 h) and a fraction of the pseudo-synapses which correspond to an inactive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e075" xlink:type="simple"/></inline-formula> undergo a transition to the low expression state (e.g., <italic>i</italic> = 4 at <italic>t</italic> = 7 h). As a result, the response of the GAM to A, B and C (<italic>t</italic> = 8, 9 and 10 h) is larger than the response to the unlearned stimuli, D and E (<italic>t</italic> = 11 and 12 h, respectively). As a result of repeated association of pattern E with the US (at times <italic>t</italic> = 13, 14 and 15 h), the GAM vigorously responds to the presentation of pattern E (at time <italic>t</italic> = 17 h) but not to pattern D (at time <italic>t</italic> = 16 h).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g004" position="float" xlink:type="simple"/></fig>
<p>The last component of our generalized GAM is the readout scheme. We assume that similar to the single-pathway model, the UR and the CR manifest in the generalized model as the production of a response protein <italic>R</italic>. We assume two independent promoters that regulate the expression of <italic>R</italic>. The response to the presentation of the US is described by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e076" xlink:type="simple"/></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1003179.e060">Eq. (3)</xref>) and the response to the presentation of the CS is regulated by the cooperative binding of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e077" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e078" xlink:type="simple"/></inline-formula>, where different pairs of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e079" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e080" xlink:type="simple"/></inline-formula> independently regulate <italic>R</italic> (<xref ref-type="disp-formula" rid="pcbi.1003179.e136">Eq. (5)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in Supplementary Information).</p>
<p>For simplicity, we assume in our analysis that the patterns of expression of the proteins <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e081" xlink:type="simple"/></inline-formula> that define the stimuli are random and independent. In this case, the statistics of the stimuli are fully determined by the sparseness of the stimuli, the probability that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e082" xlink:type="simple"/></inline-formula> is in its high expression level, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e083" xlink:type="simple"/></inline-formula>.</p>
<p>To gain insights into the ability of the generalized GAM to learn multiple associations, we consider a naïve GAM, in which the values of the pseudo-synapses are random (<xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>, bottom, <italic>t</italic> = 0). The responses of the GAM to five different stimuli, denoted by A, B, C, D and E, presented to the GAM at times <italic>t</italic> = 0, 1, 2, 3 and 4 h, respectively, are relatively small. This is due to the random, and hence relatively small overlap between the pattern of activation of pseudo-synapses (color coded) and the pattern of activation of the receptors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e084" xlink:type="simple"/></inline-formula> of the five stimuli (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e085" xlink:type="simple"/></inline-formula> is denoted by an open blue rectangle in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>).</p>
<p>In response to the pairing of C, B and A with the US (at times <italic>t</italic> = 5, 6 and 7 h, respectively), the expression levels of some of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e086" xlink:type="simple"/></inline-formula> become more similar to that of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e087" xlink:type="simple"/></inline-formula> in A, B and C, respectively. As a result, the GAM responds more vigorously to the presentation of A, B and C (at times <italic>t</italic> = 8, 9 and 10 h, respectively) but not to the presentation of D or E (at times <italic>t</italic> = 11 and 12 h, respectively). However, as a result of a repeated association of pattern E with the US (at times <italic>t</italic> = 13, 14 and 15 h), the GAM vigorously responds to the presentation of pattern E (at time <italic>t</italic> = 17 h) but not to pattern D (at time <italic>t</italic> = 16 h). This example demonstrates that a GAM can selectively learn to associate several arbitrary CS patterns with a US.</p>
</sec><sec id="s2c">
<title>Order effect</title>
<p>A careful analysis of <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref> reveals that after learning, the magnitude of the responses to the three learned CS is not equal. The response to stimulus C (<italic>t</italic> = 10 h) is smaller than the response to stimulus B (<italic>t</italic> = 9 h) and the response to B is smaller than the response to A (<italic>t</italic> = 8 h). This difference reflects the fact that the order of association affects the magnitude of the response to a CS. This is because learning a new pattern may change the expression level of a pseudo-synapse that participates in the encoding of an older pattern. For example, consider pseudo-synapse 4 in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>. In response to the presentation of stimulus C (at time <italic>t</italic> = 5 h), the state of the pseudo-synapse has changed to the high expression level, in line with the expression level of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e088" xlink:type="simple"/></inline-formula> in CS C. However, the association of the US with A (at time <italic>t</italic> = 7 h) has reverted the state of the pseudo-synapse to the low expression level, decreasing the overall response to the CS C. In other words, the association with the CS A has overwritten the information stored in pseudo-synapse 4 concerning the CS C. More generally, because of the overwriting of memories by more recent memories, the magnitude of response to a CS is expected to decrease with the number of subsequent CSs. After the encoding of a large number of patterns, the response to an ‘old’ CS is expected to diminish to an extent where it is no longer distinguishable from the response to non-learned stimuli. In this case the CS is said to have been extinguished (a more precise definition of “distinguishable” appears below). By contrast to the diminishing of the response to a pattern following the overwriting by other patterns, the repeated co-occurrence of the same pattern with the US (at times <italic>t</italic> = 13, 14 and 15 h) augments the strength of association of that pattern with the US, as demonstrated by the response to pattern E at time <italic>t</italic> = 17 h.</p>
<p>The magnitude of the order effect depends on two probabilities: the probability <italic>p</italic> that the co-occurrence of <italic>U</italic> and a high level of expression of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e089" xlink:type="simple"/></inline-formula> would induce a transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e090" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e091" xlink:type="simple"/></inline-formula> in the corresponding pseudo-synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e092" xlink:type="simple"/></inline-formula> and the probability <italic>q</italic> that the co-occurrence of <italic>U</italic> and a low level of expression of the corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e093" xlink:type="simple"/></inline-formula> would induce a transition from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e094" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e095" xlink:type="simple"/></inline-formula> in the corresponding pseudo-synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e096" xlink:type="simple"/></inline-formula>. The probabilities <italic>p</italic> and <italic>q</italic> are determined by the two rates of the US-induced transitions and the duration of co-occurrence of the US and CS, <italic>T</italic> (assuming that the rates of all other transitions are negligible, see above) such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e097" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e098" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e099" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e100" xlink:type="simple"/></inline-formula> are the low-to-high and high-to-low transition rates, respectively. The larger the transition rates and the longer the duration, the larger the transition probabilities are.</p>
<p>If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e101" xlink:type="simple"/></inline-formula> all pseudo-synapses are determined by the most recent CS and the pattern of expression level of the different pseudo-synapses corresponds to the pattern of activation of the receptors in that CS. As a result, the response to the most recent CS is substantially larger than the response to a non-learned stimulus. However, this comes at a price. The most recent CS overwrites the memory trace of all previously encoded CS and therefore the responses to all these ‘older’ CS are indistinguishable from the responses to the non-learned stimuli. Thus, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e102" xlink:type="simple"/></inline-formula>, the GAM cannot store more than a single association. The smaller the values of <italic>p</italic> and <italic>q</italic> (e.g., due to smaller US-induced transition rates), the fewer pseudo-synapses change in the process of learning a CS, allowing the GAM to maintain information about previously-learned CSs.</p>
<p>However, the transition probabilities should not be too small because the smaller these probabilities are, the weaker is the encoding. If these probabilities are too small, the response of the GAM even to the most recently stored GAM is too small to be distinguishable from non-learned stimuli. Therefore, in order for the GAM to be able store a large number of CS, the values of the US-induced transition rates should be sufficiently large to allow for a sufficiently large response to the learned-CS but sufficiently small to minimize the overwriting of old memories by new memories.</p>
<p>To better understand the requirement that the response to a CS needs to be distinguishable from the response to non-learned stimuli, consider again <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>. The responses of the GAM to the presentations of the non-learned stimuli A-E at times 0–5 h, respectively, are not identical. These differences are due to the fact that there is stochasticity in the response, resulting from stochasticity in the dynamics of the pseudo-synapses and in the realization of the different CS. Therefore, a memory of a CS is said to be maintained if the <italic>distribution</italic> of the responses of the GAM to the CS is distinguishable from the <italic>distribution</italic> of responses to the non-learned stimuli. This notion becomes exact in the next section.</p>
</sec><sec id="s2d">
<title>The capacity of the GAM</title>
<p>How many CS can be stored in a GAM? Addressing this question using the full dynamical equations (<xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4</xref>) requires extensive simulations that are beyond the scope of this paper. Therefore, we use a binary approximation (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). The quality of the binary approximation is demonstrated in <xref ref-type="supplementary-material" rid="pcbi.1003179.s001">Figure S1</xref> in the Supporting Information.</p>
<p>As described in the previous section, responses to non-learned stimuli depend on the overlap of the pattern of activation of the stimuli with the pattern of activation of the pseudo-synapses. Because both the stimuli and the dynamics of the pseudo-synapses are stochastic, this response is a stochastic variable. The distribution of the responses to non-learned stimuli (see <xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>) is depicted in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5A</xref> (blue). The response of the GAM to learned CS is also a stochastic variable. The distribution of responses to the most recently learned CS is depicted in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5A</xref> (black; <xref ref-type="disp-formula" rid="pcbi.1003179.e176">Eq. (13)</xref> and in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). This distribution is well-separated from the distribution of responses to the non-learned stimuli. Therefore, recently-learned stimuli are distinguished from non-learned stimuli using a simple threshold mechanism (e.g., the dashed line in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>). The probability of an error depends on the overlap between the two distributions. If the overlap is small, the GAM almost always responds to the most recently learned CS and almost never responds to non-learned stimuli. On the other hand, a large overlap would result in a large number of errors, false positives or misses, depending on the choice of threshold. The difference between the means of the two distributions (black and blue) depends on the transition probabilities. The higher the probabilities, the larger the difference is. Therefore, the higher the transition rates are, the easier it is to distinguish between the most recently learned CS and the non-learned stimuli.</p>
<fig id="pcbi-1003179-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g005</object-id><label>Figure 5</label><caption>
<title>The capacity of a single GAM to maintain associations.</title>
<p>(A) a distribution plot of the normalized response, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e103" xlink:type="simple"/></inline-formula>, as a function of the age of the CS. (B) the SNR as a function of the age of the CS. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e104" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e105" xlink:type="simple"/></inline-formula>. (C) The capacity of the GAM to store memories as a function of <italic>N</italic>. Blue, exact Markov model; Red, approximated model (<xref ref-type="disp-formula" rid="pcbi.1003179.e223">Eq. 20</xref>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g005" position="float" xlink:type="simple"/></fig>
<p>The distribution of responses to the presentation of the second-most recently learned CS (darkest gray) is also to the right of the distribution of responses to non-learned stimuli (blue). Nevertheless, it is shifted to the left relative to the distribution of responses to the most recently learned CS (black). As a result, the overlap of this distribution with the distribution of responses to the non-learned stimuli is larger. The reason for this shift is that as noted in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>, the newer CS ‘overwrites’ the memory of the older CS, resulting in a decreased overlap between the CS and the pseudo-synapses. The degree of overwriting, manifested as a shift to the left of the distribution of responses to the second-most recently learned CS relative to the most recently learned CS, depends on the US-induced transition rates. The smaller the transition rates, the smaller the overwriting is and therefore the smaller the shift to the left of the distribution.</p>
<p>More generally, the distributions of responses to a CS shift to the left with the ‘age’ of the CS. This is depicted in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5A</xref> using grayscale. While the distribution of the several most-recently learned CS is well-separated from the distribution of responses to non-learned stimuli (blue in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5A</xref>), the distributions of responses to ‘older’ CS and non-learned stimuli largely overlap, indicating that ‘older’ CS are ‘forgotten’.</p>
<p>More formally, the ability of the GAM to distinguish between a learned CS and a non-learned stimulus depends on the signal to noise ratio (SNR), which is defined as the ratio of the difference in mean responses to the two classes of stimuli, divided by the square root of the sum of variances of the two distributions (<xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In general, the larger the SNR, the fewer errors when distinguishing between learned and non-learned stimuli. The SNR, as a function of the ‘age’ of the CS is depicted in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5B:</xref> the newer the CS, the larger the SNR. The SNR of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e106" xlink:type="simple"/></inline-formula> CS (where the numbering of patterns is reversed such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e107" xlink:type="simple"/></inline-formula> corresponds to the most recent stimulus) is given by <xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section. The capacity of the GAM can thus be defined as the ‘oldest’ CS such that the corresponding SNR is larger than 1. In other words, the capacity of the GAM <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e108" xlink:type="simple"/></inline-formula> is defined as the largest value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e109" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e110" xlink:type="simple"/></inline-formula>.</p>
<p>The capacity of the GAM depends on the US-induced transition rates, which determine the transition probabilities. As discussed above, if these rates are high, forgetting is fast. On the other hand, if these rates are too low the GAM cannot reliably retrieve even the most recent CS. The capacity of the GAM is maximal when the US-induced transition rates are intermediate, balancing between these two requirements. The capacity of the GAM as a function of the number of pseudo-synapses (<italic>N</italic>) is depicted in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5C</xref> (blue). The larger <italic>N</italic>, the larger is the capacity of the GAM. In the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section we show that in the limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e111" xlink:type="simple"/></inline-formula>, if the US-induced transition probabilities are optimal, the capacity of the GAM is proportional to the square root of the number of pseudo-synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e112" xlink:type="simple"/></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1003179.e223">Eq. (20)</xref>; red line in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5C</xref>). This result is similar to the memory capacity of models of neural networks with binary synapses <xref ref-type="bibr" rid="pcbi.1003179-Tsodyks1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Amit1">[48]</xref>. However, the learning rule proposed here, even in the binary approximation, differs from the Hebbian synaptic plasticity rule used in neural network models <xref ref-type="bibr" rid="pcbi.1003179-Tsodyks1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Amit1">[48]</xref>.</p>
</sec><sec id="s2e">
<title>The wisdom of crowds</title>
<p>In the previous sections we studied the ability of a single GRN to learn associations. However in nature, GRNs often do not reside in isolation but in populations comprising of a large number of individual cells of the same type, e.g., as in a colony of bacteria or in a tissue, all exposed to the same external conditions. This raises an interesting question: is the capacity of a population of GAMs to store associations larger than that of a single GAM? The answer is trivially positive if we allow the different GAMs to communicate and form a recurrent network with specialized connections between individual GAMs, similar to neurons in neuronal networks. However, here we ask a different question: is the capacity of a population of non-interacting GAMs to store and retrieve memories different from that of the single GAM?</p>
<p>We consider a population of generalized GAMs as in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4A</xref>. All GAMs are identical, exposed to the same sequence of stimuli but differ in their internal stochasticity. In other words, the noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e113" xlink:type="simple"/></inline-formula> associated with the dynamics of the pseudo-synapses (<xref ref-type="disp-formula" rid="pcbi.1003179.e031">Eq. (2)</xref>) in the different GAMs is assumed to be independent. The population response in our model is assumed to be simply the accumulated response of all individual GAMs.</p>
<p>In order to understand why the capacity of a population of identical GAMs to store memories may be larger than the capacity of a single GAM, we note that a CS of a particular ‘age’ can be retrieved if the overlap between the distributions of responses to the learned and non-learned stimuli is sufficiently small. This overlap is sensitive to the variances of the two distributions (width of the curves in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5A</xref>). The larger the variance, the larger is the overlap. Two sources contribute to this variance in the responses. First, there is stochasticity in the realization of CS and non-learned stimuli. Second, there is stochasticity in the encoding process. While the first type of stochasticity is external and thus shared by all GAMs in the population, the second type of stochasticity is independent for each GAM. As a result, when considering the cumulative response of a large population of GAMs, all other parameters being equal, the variance in the distribution of responses is considerably smaller (<xref ref-type="disp-formula" rid="pcbi.1003179.e238">Eq. (23)</xref> in the <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In <xref ref-type="fig" rid="pcbi-1003179-g006">Figure 6A</xref> we plot the distributions of responses to CS of different ‘ages’ (gray, color-coded) and non-learned stimuli (blue).</p>
<fig id="pcbi-1003179-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003179.g006</object-id><label>Figure 6</label><caption>
<title>The capacity of a large population of GAMs to maintain associations.</title>
<p>(A) a distribution plot of the normalized response, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e114" xlink:type="simple"/></inline-formula> , as a function of the age of the CS. (B) Solid blue line, the SNR of a population of GAMs as a function of the age of the CS. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e115" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e116" xlink:type="simple"/></inline-formula>. Dashed blue line, the single GAM, same as in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5B</xref>. (C) The capacity of a population of GAMs as a function of <italic>N</italic>. Blue line, exact Markov model; Red line, approximated model (<xref ref-type="disp-formula" rid="pcbi.1003179.e223">Eq. 20</xref>). Note that the blue and red lines almost overlap. Dashed blue line, the single GAM, same as in <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5C</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003179.g006" position="float" xlink:type="simple"/></fig>
<p>Similar to the case of a single GAM, the capacity of a population of GAMs depends on the US-induced transition rates. However, because the variance in the responses in the case of the population is considerably smaller than the variance in the case of a single GAM, the US-induced transition probabilities that maximize the capacity of the population are considerably smaller than those that maximize the capacity of a single GAM. In <xref ref-type="fig" rid="pcbi-1003179-g006">Figure 6B</xref> we plot the SNR as a function of the ‘age’ of the CS (solid blue line). Compared to the SNR of a single GAM (dashed blue line, identical to <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5B</xref>), the SNR of the response of the population of GAMs is larger than 1 for much ‘older’ CS.</p>
<p>The capacity of the population of GAMs as a function of the number of pseudo-synapses (<italic>N</italic>) is depicted in <xref ref-type="fig" rid="pcbi-1003179-g006">Figure 6C</xref> (solid blue line). The larger <italic>N</italic> is, the larger is the capacity of the GAMs. More quantitative analysis reveals that for an appropriate choice of parameters, the number of different CS that a large population of GAMs can store is proportional to the number of pseudo-synapses (<xref ref-type="disp-formula" rid="pcbi.1003179.e291">Eq. (31)</xref>; solid red line), compared to a capacity that is only proportional to the square root of the number of pseudo-synapses in the case of a single GAM (dashed blue line, identical to <xref ref-type="fig" rid="pcbi-1003179-g005">Figure 5C</xref>).</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>In this paper, we explored the ability of a general GRN to encode associations. We showed that a GRN that is endowed with bistable elements and stochastic dynamics is capable of storing and retrieving multiple arbitrary and overlapping associations. The capacity of a single GRN in our model, defined as the number of stored associations, is proportional to the square root of the number of bistable elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e117" xlink:type="simple"/></inline-formula>. This result is reminiscent of Hopfield-like models with bounded synapses, in which the capacity is proportional to the square root of the number of synapses <xref ref-type="bibr" rid="pcbi.1003179-Tsodyks1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Amit1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Fusi1">[49]</xref>. Remarkably, in a large population of GRNs, as is in a colony of bacteria or in a tissue, this capacity is substantially higher and is proportional to the number of bistable elements.</p>
<p>Despite the similarities between the GAM and the Hopfield model, there are two important differences that are noteworthy. First, the capacity of a single GAM may be limited by the presence of readout noise (e.g., in the dynamics of <italic>R</italic>). However, this readout noise is not expected to substantially affect the capacity of a population of GAMs because of averaging. Second, the number of neurons available in neuronal networks is much larger than the number of bistable elements in GRNs. Altogether, our model predicts that if the number of bistable elements in the GRN does not exceed several tens, it will be difficult to store more than one or two memories in a single GAM. Therefore, the storage of multiple memories is likely to require a population of GAMs.</p>
<p>The key elements in our model are the bistability and the stochasticity of the dynamics of the GRN. Importantly, bistability and stochasticity are not restricted to the transcriptional machinery. Rather, they are found in various cellular processes, including post-transcriptional regulation (e.g., by non-coding RNA <xref ref-type="bibr" rid="pcbi.1003179-Yoon1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Storz1">[51]</xref>) or post-translational regulation (e.g. phosphorylation and degradation regulation <xref ref-type="bibr" rid="pcbi.1003179-Pomerening1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Markevich1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Yao1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Kapuy1">[54]</xref>). We modeled associative memory that is based on the interaction of proteins through the transcriptional machinery because these dynamics are better characterized and are more accessible experimentally than other cellular alternatives.</p>
<p>Moreover, the GAM is not restricted to a particular organism. The parameters used in the simulations presented in this paper are biologically plausible for bacteria. However, because the basic elements of the GAM, namely, bistability and stochasticity, are widespread in GRNs of all cells, the potential for associative learning without a nervous system exists for virtually all cell types, including single-celled eukaryotes and plants. Furthermore, this work suggests that even in animals that possess a nervous system, learning that is independent of this nervous system is also possible. In particular, it could be interesting to consider GAM in the immune system, which has evolved to learn to respond to novel pathogens.</p>
<p>Bearing this in mind, we believe that in view of the recent developments of experimental methods that quantitatively measure the expression level of proteins, bacteria, in particular the well characterized <italic>E. coli</italic>, are the ideal substrate to study the associative learning in GRNs. Each of the components of the GAM module (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3A</xref>), namely inducible elements, bistable switches and AND gates, have been established in the <italic>E. coli</italic> transcription network and therefore a synthetic implementation is achievable <xref ref-type="bibr" rid="pcbi.1003179-Chin1">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Hasty2">[56]</xref>.</p>
<p>Beyond synthetic implementation, the complexity of the genetic networks suggests that GAM-like modules may exist. A first step in searching for GAMs in known networks should be the identification of plausible candidates for the US, UR and CS. In animals, the US is a stimulus that causes an overt response prior to learning, the UR. Typically the US is a stimulus of biological significance, such as food or a noxious stimulus and the UR is an ecologically-relevant overt response, often in the form of muscle activation. For example, in the eye-blink conditioning experiment (<xref ref-type="fig" rid="pcbi-1003179-g001">Figure 1</xref>) the US is an air puff and the UR is an eye blink that protects the eye from the puff. An important point to consider when searching for associative learning in bacteria is ecological significance. Our model for associative learning, similar to models of associative learning in neuronal networks, does not incorporate any ecological information about the stimuli. However in animals, it is known that the ability to form an association depends on the ecological relevance of the CS to the US. For example, the association of the taste of a certain food (CS) with the symptoms caused by a toxic or spoiled food (US), known as taste aversion, is easily-formed after a small number of repetitions. By contrast, it is substantially more difficult to form an association of a tone with the same US <xref ref-type="bibr" rid="pcbi.1003179-Lionel1">[57]</xref>. It is generally believed that this difference results from the fact that typically, taste is more informative about the chemical composition of substances than auditory signals. Therefore, taste-aversion but not tone-aversion has evolved as a specific learning mechanism aimed at preventing the consumption of poisonous substances. Drawing an analogy to associative learning in bacteria, we propose to utilize ecologically-relevant CS rather than arbitrary CS when searching for associative learning in bacteria. In our model, the strength of association increases with the number of repetitions due to the stochasticity in the encoding process. Such dependence of the strength of association on the number of repetitions is also observed in classical conditioning experiments in animals <xref ref-type="bibr" rid="pcbi.1003179-Gallistel1">[58]</xref>. Therefore, experiments involving a large number of co-occurrences of the CS and US are more likely to reveal associative learning in GRNs or populations of GRNs. Note that standard experiments studying responses of bacteria are typically short and do not involve repetitions in the presentation of stimuli to the same population of bacteria. Therefore, associative learning in such experiments may have been overlooked. Moreover, we have shown that the learning capacity of the population of bacteria is higher than that of a single GRN. Therefore, the experimental search for associative learning in bacteria should be done at the population level.</p>
<p>More specifically in bacteria, the presence of foreign bacteria is a signal of potential stress. For example, many bacteria produce antibiotics that are harmful to other strains <xref ref-type="bibr" rid="pcbi.1003179-Garmendia1">[59]</xref>. Other bacteria are sensitive to these damaging antibiotics and respond to their presence by activating a pre-wired stress response, such as the multiple antibiotics response (MAR) <xref ref-type="bibr" rid="pcbi.1003179-Alekshun1">[60]</xref>. We thus suggest that the <italic>R</italic> gene in our scheme corresponds to one of the outputs of MAR response, e.g. the micF gene <xref ref-type="bibr" rid="pcbi.1003179-Delihas1">[61]</xref>. Note that similar to the blink in the classic eye-blink conditioning that protects the eye from the air puff (<xref ref-type="fig" rid="pcbi-1003179-g001">Figure 1</xref>), the activation of micF prevents the entry of the antibiotics into the cell. Thus, the antibiotics can be considered as a US whereas the stress response can be considered as a UR. However, the production of harmful antibiotics is not present in all bacteria species. Therefore, learning to distinguish between harmful and benign strains of bacteria is of potential great ecological significance because it may allow the bacteria to respond faster. Thus, the presence of foreign bacteria could correspond to the CS in our framework. Indeed, bacteria are able to detect secondary metabolites that are produced by other strains <xref ref-type="bibr" rid="pcbi.1003179-Whitehead1">[62]</xref>. In that line, we suggest as a candidate for the <italic>M</italic> protein in the model the MarA gene. MarA is known to positively autoregulate itself, and thus has the potential to be bistable. In addition, the promoter of that gene contains multiple binding sites for transcription factors, allowing for complex regulation of the gene expression including the realization of AND gates.</p>
<p>Experimentally, the UR can be measured using a fluorescent-based reporter that is regulated by a promoter of a stress response gene. The CS in this framework should be stimuli that can be sensed by the bacteria but do not elicit the stress response. These include a change in the concentration of different molecules that does not activate the stress response. Repeated exposure to such conditions can be controlled using a chemostat <xref ref-type="bibr" rid="pcbi.1003179-Novick2">[63]</xref>, which can maintain selected growth conditions at a constant level while changing others.</p>
<p>Finally, the benefit of the stress response at the population level can also be found in the induction of the MAR response, as it triggers the activation of genes that inactivate toxic compounds. The benefit of this “pooled response” for the population comes from the decrease in the concentration of the toxic compound <xref ref-type="bibr" rid="pcbi.1003179-Bailey1">[64]</xref>.</p>
<p>Whether or not associative learning exists in GRNs on a time-scale much shorter than required for evolution is an open question. However, whether considering bacteria that can predict a stress condition or human digestive cells that can predict food intake, associative learning in single and populations of cells seems to have an evolutionary advantage. In view of the computational capabilities of GRNs demonstrated in this paper, we believe that future careful investigations will reveal the existence of associative learning in single and populations of cells.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>The dynamical equations of the generalized model</title>
<p>In this section we provide the rate equations that describe the dynamics of the generalized model (<xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4A</xref>). The kinetic reactions that underlie these dynamics and the derivation of the rate equations from the kinetic reactions are described in <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in the Supporting Information. The single pathway equations correspond to <italic>the</italic> generalized model with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e118" xlink:type="simple"/></inline-formula>.</p>
<p>The equations that describe the dynamics of the pseudo-synapses are given by:<disp-formula id="pcbi.1003179.e119"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e119" xlink:type="simple"/><label>(4)</label></disp-formula><italic>where</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e120" xlink:type="simple"/></inline-formula>. The nonlinear positive feedback term, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e121" xlink:type="simple"/></inline-formula>, is described by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e122" xlink:type="simple"/></inline-formula> where the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e123" xlink:type="simple"/></inline-formula> are kinetic parameters, and <italic>n</italic> is the Hill coefficient, corresponding to the cooperativity of binding. The second term in <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> denotes the protein degradation, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e124" xlink:type="simple"/></inline-formula> is a parameter. The third term in <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> describe the effect of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e125" xlink:type="simple"/></inline-formula> and <italic>U</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e126" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e127" xlink:type="simple"/></inline-formula> are kinetic parameters. The last term in <xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eq. (4)</xref> models the stochasticity of the dynamics, and we assume that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e128" xlink:type="simple"/></inline-formula> are independent white noise such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e129" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e130" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e131" xlink:type="simple"/></inline-formula> is Kronecker's delta function such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e132" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e133" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e134" xlink:type="simple"/></inline-formula> otherwise and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e135" xlink:type="simple"/></inline-formula> is a parameter.</p>
<p>The reactive equation that describes the dynamics of <italic>R</italic> is given by:<disp-formula id="pcbi.1003179.e136"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e136" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e137" xlink:type="simple"/></inline-formula> is the degradation rate of <italic>R</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e138" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e139" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e140" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e141" xlink:type="simple"/></inline-formula> are kinetic parameters.</p>
</sec><sec id="s4b">
<title>The capacity of the GAM</title>
<p>In this section we compute the capacity of the GAM to learn associations. To that goal, we consider a binary approximation of the dynamics of the pseudo-synapses. Because the dynamics of <italic>M</italic> spend most of the time near the attractors of the deterministic dynamics, <xref ref-type="disp-formula" rid="pcbi.1003179.e002">Eq. (1)</xref>, it can be approximated using a two-state Markov chain, where each state corresponds to one attractor of the deterministic dynamics. We further assume that the US and CS are presented in discrete “trials” composed of a fixed period of time. Therefore, the response of <italic>M</italic> to the presentation of the CS and US can be approximated by:<disp-formula id="pcbi.1003179.e142"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e142" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e143" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e144" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e145" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e146" xlink:type="simple"/></inline-formula> denote epochs in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e147" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e148" xlink:type="simple"/></inline-formula>, respectively and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e149" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e150" xlink:type="simple"/></inline-formula> denote epochs in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e151" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e152" xlink:type="simple"/></inline-formula>, respectively. The variables <italic>m</italic> and <italic>m′</italic> denote the states of the pseudo-synapse before and after the presentation of the external cues and their values; 0 or 1 denote epochs in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e153" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e154" xlink:type="simple"/></inline-formula>, respectively. The steady state response to the presentation of a pattern is:<disp-formula id="pcbi.1003179.e155"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e155" xlink:type="simple"/><label>(7)</label></disp-formula>The selectivity of the response in <xref ref-type="disp-formula" rid="pcbi.1003179.e155">Eq. (7)</xref> depends on the value of the sum of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e156" xlink:type="simple"/></inline-formula>. In response to the presentation of a CS that was learned <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e157" xlink:type="simple"/></inline-formula> CSs ago,<disp-formula id="pcbi.1003179.e158"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e158" xlink:type="simple"/><label>(8)</label></disp-formula>where<disp-formula id="pcbi.1003179.e159"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e159" xlink:type="simple"/><label>(9)</label></disp-formula><disp-formula id="pcbi.1003179.e160"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e160" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1003179.e161"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e161" xlink:type="simple"/></disp-formula>and<disp-formula id="pcbi.1003179.e162"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e162" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1003179.e163"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e163" xlink:type="simple"/></disp-formula>(see <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in Supplementary Information for a more detailed derivation).</p>
<p>Dissociating a learned pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e164" xlink:type="simple"/></inline-formula> from non-learned patterns (which we denote as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e165" xlink:type="simple"/></inline-formula>) is possible only if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e166" xlink:type="simple"/></inline-formula> is significantly different from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e167" xlink:type="simple"/></inline-formula>. The difficulty in dissociating learned and non-learned patterns lies in the fact that the responses to the two types of patterns are stochastic variables that depend on the stochasticity in the realization of the learned and non-learned stimuli as well as the stochasticity in the learning. Therefore, we consider the distribution of responses to the learned and non-learned stimuli.</p>
<p>To compute the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e168" xlink:type="simple"/></inline-formula>, note that in response to the presentation of a sequence of CS, changes in the state of the pseudo-synapses follow a Markov chain such that<disp-formula id="pcbi.1003179.e169"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e169" xlink:type="simple"/><label>(10)</label></disp-formula>From <xref ref-type="disp-formula" rid="pcbi.1003179.e169">Eq. (10)</xref> it follows that at the stationary distribution,<disp-formula id="pcbi.1003179.e170"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e170" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e171" xlink:type="simple"/></inline-formula>.</p>
<p>Using <xref ref-type="disp-formula" rid="pcbi.1003179.e170">Eq. (11)</xref>, and the fact that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e172" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e173" xlink:type="simple"/></inline-formula>, a straightforward calculation yields that the mean and variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e174" xlink:type="simple"/></inline-formula> are given by:<disp-formula id="pcbi.1003179.e175"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e175" xlink:type="simple"/><label>(12)</label></disp-formula>where<disp-formula id="pcbi.1003179.e176"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e176" xlink:type="simple"/><label>(13)</label></disp-formula>Note that for large <italic>N</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e177" xlink:type="simple"/></inline-formula> is the sum of a large number of independent and identically distributed random variables and therefore according to the central limit theorem <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e178" xlink:type="simple"/></inline-formula> is normally distributed.</p>
<p>In order to compute the capacity of the GAM, we define the difference between the mean responses to learned and non-learned stimuli as the signal and the square root of the sum of the variances of the responses to the learned and non-learned stimuli as the noise. In the limit of large <italic>N</italic>, the ability of a binary classifier to discriminate between the learned and non-learned stimuli depends on the SNR. If the SNR is large, it is possible to achieve a high detection rate while maintaining a low level of false positives. A low SNR implies that the two stimuli are indistinguishable. Therefore, we define the capacity of the GAM to be the oldest memory such that the SNR is larger than 1 (see also <xref ref-type="bibr" rid="pcbi.1003179-Tsodyks1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003179-Amit1">[48]</xref> for a similar approach in models of neural networks). Formally, the signal-to-noise-ratio for a pattern presented <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e179" xlink:type="simple"/></inline-formula> patterns ago is given by:<disp-formula id="pcbi.1003179.e180"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e180" xlink:type="simple"/><label>(14)</label></disp-formula>where<disp-formula id="pcbi.1003179.e181"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e181" xlink:type="simple"/><label>(15)</label></disp-formula>We compute the capacity in the limit of large <italic>N</italic> and consider the effect of the scaling of <italic>p</italic> and <italic>q</italic> with <italic>N</italic> on the capacity of the GAM. If the values of <italic>p</italic> and <italic>q</italic> are very different then the pseudo-synapses will saturate. Therefore, we consider the same scaling of <italic>p</italic> and <italic>q</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e182" xlink:type="simple"/></inline-formula>. The signal in <xref ref-type="disp-formula" rid="pcbi.1003179.e176">Eq. (13)</xref> depends on the product of two terms, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e183" xlink:type="simple"/></inline-formula> that depends on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e184" xlink:type="simple"/></inline-formula> and a prefactor, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e185" xlink:type="simple"/></inline-formula> that is independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e186" xlink:type="simple"/></inline-formula>. It is easy to see that the prefactor, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e187" xlink:type="simple"/></inline-formula>. Similarly, it is easy to see that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e188" xlink:type="simple"/></inline-formula>. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e189" xlink:type="simple"/></inline-formula>. Because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e190" xlink:type="simple"/></inline-formula>, a necessary condition for the SNR to be larger than 1 is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e191" xlink:type="simple"/></inline-formula>. The term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e192" xlink:type="simple"/></inline-formula> decays exponentially fast with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e193" xlink:type="simple"/></inline-formula>. However, because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e194" xlink:type="simple"/></inline-formula>, as long as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e195" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e196" xlink:type="simple"/></inline-formula>. Therefore, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e197" xlink:type="simple"/></inline-formula>, as long as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e198" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e199" xlink:type="simple"/></inline-formula>. Thus, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e200" xlink:type="simple"/></inline-formula>, the capacity of the GAM is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e201" xlink:type="simple"/></inline-formula>, which is maximal for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e202" xlink:type="simple"/></inline-formula>. In other words, assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e203" xlink:type="simple"/></inline-formula>, the capacity of the GAM is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e204" xlink:type="simple"/></inline-formula>.</p>
<p>To gain insights into this result, we consider the optimal choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e205" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e206" xlink:type="simple"/></inline-formula> (which minimizes the variance), in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e207" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e208" xlink:type="simple"/></inline-formula>. In this case, in the limit of large <italic>N</italic>,<disp-formula id="pcbi.1003179.e209"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e209" xlink:type="simple"/><label>(16)</label></disp-formula>and <xref ref-type="disp-formula" rid="pcbi.1003179.e181">Eq. (15)</xref> becomes<disp-formula id="pcbi.1003179.e210"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e210" xlink:type="simple"/><label>(17)</label></disp-formula>Thus, <xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> becomes:<disp-formula id="pcbi.1003179.e211"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e211" xlink:type="simple"/><label>(18)</label></disp-formula>The requirement that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e212" xlink:type="simple"/></inline-formula> yields:<disp-formula id="pcbi.1003179.e213"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e213" xlink:type="simple"/><label>(19)</label></disp-formula>where we used the fact that for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e214" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e215" xlink:type="simple"/></inline-formula> and therefore <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e216" xlink:type="simple"/></inline-formula>.</p>
<p>In order to find the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e217" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e218" xlink:type="simple"/></inline-formula> that maximize the capacity of the GAM, we compute the zeros of the partial derivatives of <xref ref-type="disp-formula" rid="pcbi.1003179.e213">Eq. (19)</xref> with respect to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e219" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e220" xlink:type="simple"/></inline-formula>, resulting in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e221" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e222" xlink:type="simple"/></inline-formula>. Thus, the capacity of the GAM is<disp-formula id="pcbi.1003179.e223"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e223" xlink:type="simple"/><label>(20)</label></disp-formula>For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e224" xlink:type="simple"/></inline-formula>, the capacity is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e225" xlink:type="simple"/></inline-formula>. Note that the capacity increases as the value of <italic>f</italic> deviates from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e226" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4c">
<title>The capacity of a population of GAMs</title>
<p>In this section we compute the capacity of a large population composed of <italic>Z</italic> identical GAMs. The population response to the presentation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e227" xlink:type="simple"/></inline-formula> is given by (up to constant shift and scaling):<disp-formula id="pcbi.1003179.e228"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e228" xlink:type="simple"/><label>(21)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e229" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e230" xlink:type="simple"/></inline-formula> pseudo synapse (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e231" xlink:type="simple"/></inline-formula>) in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e232" xlink:type="simple"/></inline-formula> GAM (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e233" xlink:type="simple"/></inline-formula>) (compare to <xref ref-type="disp-formula" rid="pcbi.1003179.e159">Eq. (9)</xref>).</p>
<p>Similar to the analysis of the capacity of a single GAM, we compute the mean and variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e234" xlink:type="simple"/></inline-formula>. The computation of mean of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e235" xlink:type="simple"/></inline-formula> in the case of the population is similar to that computation for the case of a single GAM, yielding<disp-formula id="pcbi.1003179.e236"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e236" xlink:type="simple"/><label>(22)</label></disp-formula>Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e237" xlink:type="simple"/></inline-formula> is independent of the size of the population: since all GAMs are identical, their contribution, on average, is equal. Computing the variance of <xref ref-type="disp-formula" rid="pcbi.1003179.e228">Eq. (21)</xref> results yields:<disp-formula id="pcbi.1003179.e238"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e238" xlink:type="simple"/><label>(23)</label></disp-formula>In order to evaluate <xref ref-type="disp-formula" rid="pcbi.1003179.e238">Eq. (23)</xref>, we consider the dynamics of a single pseudo-synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e239" xlink:type="simple"/></inline-formula>. Similar to <xref ref-type="disp-formula" rid="pcbi.1003179.e060">Eq. (3)</xref>,<disp-formula id="pcbi.1003179.e240"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e240" xlink:type="simple"/><label>(24)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e241" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e242" xlink:type="simple"/></inline-formula> are Bernoulli variables with parameters <italic>p</italic> and <italic>q</italic>, respectively.</p>
<p>Using induction, it is easy to prove that the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e243" xlink:type="simple"/></inline-formula> in response to the learning of an infinite sequence of CS is given by:<disp-formula id="pcbi.1003179.e244"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e244" xlink:type="simple"/><label>(25)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e245" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e246" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e247" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e248" xlink:type="simple"/></inline-formula> denote the values of the Bernoulli variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e249" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e250" xlink:type="simple"/></inline-formula>, respectively, during the encoding of the CS <italic>x</italic> patterns ago.</p>
<p>Using <xref ref-type="disp-formula" rid="pcbi.1003179.e240">Eq. (24)</xref>, it can be shown that:<disp-formula id="pcbi.1003179.e251"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e251" xlink:type="simple"/><label>(26)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e252" xlink:type="simple"/></inline-formula>.</p>
<p>Substituting <xref ref-type="disp-formula" rid="pcbi.1003179.e251">Eq. (26)</xref> in <xref ref-type="disp-formula" rid="pcbi.1003179.e238">Eq. (23)</xref> and assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e253" xlink:type="simple"/></inline-formula> yields:<disp-formula id="pcbi.1003179.e254"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e254" xlink:type="simple"/><label>(27)</label></disp-formula>Note that in the case of a single network, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e255" xlink:type="simple"/></inline-formula>, only the first term contributes, yielding <xref ref-type="disp-formula" rid="pcbi.1003179.e209">Eq. (16)</xref>.</p>
<p>The capacity of the population of GAMs is defined as the oldest memory such that the SNR is larger than 1, where the signal and noise terms in <xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> are given by<disp-formula id="pcbi.1003179.e256"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e256" xlink:type="simple"/><label>(28)</label></disp-formula>And<disp-formula id="pcbi.1003179.e257"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e257" xlink:type="simple"/><label>(29)</label></disp-formula>In the limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e258" xlink:type="simple"/></inline-formula> (large number of GAMs) the contribution of the first term in <xref ref-type="disp-formula" rid="pcbi.1003179.e251">Eq. (26)</xref> to the variance vanishes and the capacity depends on the second term. For a general value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e259" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e260" xlink:type="simple"/></inline-formula> and this term dominates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e261" xlink:type="simple"/></inline-formula>, resulting in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e262" xlink:type="simple"/></inline-formula>. Therefore, the population capacity in this case is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e263" xlink:type="simple"/></inline-formula>, similar to that of a single GAM. However, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e264" xlink:type="simple"/></inline-formula> this <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e265" xlink:type="simple"/></inline-formula> term vanishes and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e266" xlink:type="simple"/></inline-formula> is dominated by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e267" xlink:type="simple"/></inline-formula>, resulting in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e268" xlink:type="simple"/></inline-formula>. Similar to the case of a single GAM, we compute the capacity in the limit of large <italic>N</italic> and consider the effect of the scaling of <italic>p</italic> and <italic>q</italic> with <italic>N</italic> on the capacity of the population of GAMs. If the values of p and q are very different then the pseudo-synapses will saturate. Therefore, we consider the same scaling of <italic>p</italic> and <italic>q</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e269" xlink:type="simple"/></inline-formula>. The signal in <xref ref-type="disp-formula" rid="pcbi.1003179.e254">Eq. (27)</xref> is the same as that of a single GAM (<xref ref-type="disp-formula" rid="pcbi.1003179.e176">Eq. (13)</xref>), therefore the prefactor in <xref ref-type="disp-formula" rid="pcbi.1003179.e176">Eq. (13)</xref> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e270" xlink:type="simple"/></inline-formula>. Similarly, it is easy to see that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e271" xlink:type="simple"/></inline-formula>. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e272" xlink:type="simple"/></inline-formula>. Because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e273" xlink:type="simple"/></inline-formula>, a necessary condition for the SNR to be larger than 1 is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e274" xlink:type="simple"/></inline-formula>. The term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e275" xlink:type="simple"/></inline-formula> decays exponentially fast with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e276" xlink:type="simple"/></inline-formula>. However, because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e277" xlink:type="simple"/></inline-formula>, as long as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e278" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e279" xlink:type="simple"/></inline-formula>. Therefore, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e280" xlink:type="simple"/></inline-formula>, as long as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e281" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e282" xlink:type="simple"/></inline-formula>. Thus, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e283" xlink:type="simple"/></inline-formula>, the capacity of the GAM is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e284" xlink:type="simple"/></inline-formula>, which is maximal for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e285" xlink:type="simple"/></inline-formula>. In other words, assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e286" xlink:type="simple"/></inline-formula>, the capacity of the GAM is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e287" xlink:type="simple"/></inline-formula>. In particular, assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e288" xlink:type="simple"/></inline-formula>, substituting <xref ref-type="disp-formula" rid="pcbi.1003179.e256">Eqs. (28)</xref> and <xref ref-type="disp-formula" rid="pcbi.1003179.e257">Eq. (29)</xref> in <xref ref-type="disp-formula" rid="pcbi.1003179.e180">Eq. (14)</xref> yields<disp-formula id="pcbi.1003179.e289"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e289" xlink:type="simple"/><label>(30)</label></disp-formula>A straightforward calculation reveals that the capacity is maximal when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e290" xlink:type="simple"/></inline-formula>, resulting in capacity:<disp-formula id="pcbi.1003179.e291"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e291" xlink:type="simple"/><label>(31)</label></disp-formula></p>
</sec><sec id="s4d">
<title>Numerical procedures</title>
<p>In our simulations, we used the following parameters: <disp-formula id="pcbi.1003179.e292"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e292" xlink:type="simple"/></disp-formula>For the generalized model (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3</xref>) we used: <disp-formula id="pcbi.1003179.e293"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003179.e293" xlink:type="simple"/></disp-formula>All other parameters were the same as the single pathway model (<xref ref-type="fig" rid="pcbi-1003179-g003">Figure 3</xref>). The derivation of the parameters from the reaction kinetic constants is provided in the <xref ref-type="supplementary-material" rid="pcbi.1003179.s003">Text S1</xref> in the Supporting Information. The reaction kinetic constants that were used are provided in <xref ref-type="supplementary-material" rid="pcbi.1003179.s002">Table S1</xref> in the Supporting Information. Simulations in <xref ref-type="fig" rid="pcbi-1003179-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1003179-g004">4</xref> were carried out using Euler method for numerical integration with step sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003179.e294" xlink:type="simple"/></inline-formula>and 0.5 min, respectively.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003179.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003179.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Comparing the dynamics equations and the Markov approximation.</bold> (A) Green line, the response <italic>R</italic> in a simulation of the model (<xref ref-type="disp-formula" rid="pcbi.1003179.e119">Eqs. (4)</xref> and <xref ref-type="disp-formula" rid="pcbi.1003179.e136">(5)</xref>) in the same paradigm as in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref>. Orange rectangles, the timing of a US; Letters A–E denote the timing as identities of CS. (B) The responses <italic>R</italic> to patterns A–E prior to learning (blue, green, black, magenta and yellow lines, respectively) and to pattern A after learning (red line), at the times corresponding to the corresponding colored horizontal lines in A, aligned to the time of presentation of the stimuli. Circles, mean response in the second half of stimulus presentation (last 15min) for each pattern. . (C) Histograms of mean responses (circles in B) to the most recently learned patterns (black) and random patterns (blue). (D) The SNR as a function of the age of the pattern. Red circles, the dynamics equations, blue line, the predicted SNR from the Markov model. Green line, the predicted SNR assuming optimal parameters. Note that the green and blue lines almost overlap, and that they both agree well with the simulation red circles. The parameters that were used in the simulation are the same as those used in <xref ref-type="fig" rid="pcbi-1003179-g004">Figure 4B</xref> and the SNR and histograms are based on 1,000 repetitions.</p>
<p>(TIF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003179.s002" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003179.s002" position="float" xlink:type="simple"><label>Table S1</label><caption>
<p><bold>Kinetic parameters used in simulations.</bold> A table of all the kinetic parameters used to derive the parameters of the numerical simulations of the approximate dynamics.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003179.s003" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003179.s003" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>Derivations of the approximate dynamic equations </bold><xref ref-type="disp-formula" rid="pcbi.1003179.e002"><bold>(Eqs. 1</bold></xref><bold>–</bold><xref ref-type="disp-formula" rid="pcbi.1003179.e159"><bold>9)</bold></xref><bold> from the kinetic reaction equations</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Ohad Sorek for drawing <xref ref-type="fig" rid="pcbi-1003179-g001">Figure 1</xref> and Mor Nitzan for her helpful comments on the manuscript</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003179-Pavlov1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Pavlov IP (1927) Conditioned Reflexes. Anrep GV, translator. London: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Kitazawa1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kitazawa</surname><given-names>S</given-names></name> (<year>2002</year>) <article-title>Neurobiology: ready to unlearn</article-title>. <source>Nature</source> <volume>416</volume>: <fpage>270</fpage>–<lpage>273</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Medina1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Medina</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Repa</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Mauk</surname><given-names>MD</given-names></name>, <name name-style="western"><surname>LeDoux</surname><given-names>JE</given-names></name> (<year>2002</year>) <article-title>Parallels between cerebellum- and amygdala-dependent conditioning</article-title>. <source>Nat Rev Neurosci</source> <volume>3</volume>: <fpage>122</fpage>–<lpage>131</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Rumpel1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rumpel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>LeDoux</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zador</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Malinow</surname><given-names>R</given-names></name> (<year>2005</year>) <article-title>Postsynaptic receptor trafficking underlying a form of associative learning</article-title>. <source>Science</source> <volume>308</volume>: <fpage>83</fpage>–<lpage>88</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Nakazawa1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakazawa</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Quirk</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Chitwood</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Watanabe</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Yeckel</surname><given-names>MF</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Requirement for hippocampal CA3 NMDA receptors in associative memory recall</article-title>. <source>Science</source> <volume>297</volume>: <fpage>211</fpage>–<lpage>218</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Smolen1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smolen</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Baxter</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Byrne</surname><given-names>JH</given-names></name> (<year>2000</year>) <article-title>Mathematical modeling of gene networks</article-title>. <source>Neuron</source> <volume>26</volume>: <fpage>567</fpage>–<lpage>580</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-GarciaOjalvo1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Garcia-Ojalvo</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Physical approaches to the dynamics of genetic circuits: a tutorial</article-title>. <source>Contemporary Physics</source> <volume>52</volume>: <fpage>439</fpage>–<lpage>464</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Alon1"><label>8</label>
<mixed-citation publication-type="other" xlink:type="simple">Alon U (2007) An Introduction to systems biology: design principles of biological circuits. Chapman &amp; Hall/CRC</mixed-citation>
</ref>
<ref id="pcbi.1003179-Bray1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bray</surname><given-names>D</given-names></name> (<year>1995</year>) <article-title>Protein molecules as computational elements in living cells</article-title>. <source>Nature</source> <volume>376</volume>: <fpage>307</fpage>–<lpage>312</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Buchler1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buchler</surname><given-names>NE</given-names></name>, <name name-style="western"><surname>Gerland</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Hwa</surname><given-names>T</given-names></name> (<year>2003</year>) <article-title>On schemes of combinatorial transcription logic</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>100</volume>: <fpage>5136</fpage>–<lpage>5141</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Wang1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kitney</surname><given-names>RI</given-names></name>, <name name-style="western"><surname>Joly</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Buck</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Engineering modular and orthogonal genetic logic gates for robust digital-like synthetic biology</article-title>. <source>Nat Commun</source> <volume>2</volume>: <fpage>508</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Anderson1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Voigt</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Arkin</surname><given-names>AP</given-names></name> (<year>2007</year>) <article-title>Environmental signal integration by a modular AND gate</article-title>. <source>Mol Syst Biol</source> <volume>3</volume>: <fpage>133</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-HenggeAronis1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hengge-Aronis</surname><given-names>R</given-names></name> (<year>2002</year>) <article-title>Recent insights into the general stress response regulatory network in Escherichia coli</article-title>. <source>J Mol Microbiol Biotechnol</source> <volume>4</volume>: <fpage>341</fpage>–<lpage>346</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Mitchell1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mitchell</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Romano</surname><given-names>GH</given-names></name>, <name name-style="western"><surname>Groisman</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Yona</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Dekel</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Adaptive prediction of environmental changes by microorganisms</article-title>. <source>Nature</source> <volume>460</volume>: <fpage>220</fpage>–<lpage>U280</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Tagkopoulos1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tagkopoulos</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>YC</given-names></name>, <name name-style="western"><surname>Tavazoie</surname><given-names>S</given-names></name> (<year>2008</year>) <article-title>Predictive behavior within microbial genetic networks</article-title>. <source>Science</source> <volume>320</volume>: <fpage>1313</fpage>–<lpage>1317</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Hennessey1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hennessey</surname><given-names>TM</given-names></name>, <name name-style="western"><surname>Rucker</surname><given-names>WB</given-names></name>, <name name-style="western"><surname>Mcdiarmid</surname><given-names>CG</given-names></name> (<year>1979</year>) <article-title>Classical-Conditioning in Paramecia</article-title>. <source>Animal Learning &amp; Behavior</source> <volume>7</volume>: <fpage>417</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Armus1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Armus</surname><given-names>HL</given-names></name>, <name name-style="western"><surname>Montgomery</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Gurney</surname><given-names>RL</given-names></name> (<year>2006</year>) <article-title>Discrimination learning and extinction in paramecia (P. caudatum)</article-title>. <source>Psychol Rep</source> <volume>98</volume>: <fpage>705</fpage>–<lpage>711</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Fritz1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fritz</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Buchler</surname><given-names>NE</given-names></name>, <name name-style="western"><surname>Hwa</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Gerland</surname><given-names>U</given-names></name> (<year>2007</year>) <article-title>Designing sequential transcription logic: a simple genetic circuit for conditional memory</article-title>. <source>Syst Synth Biol</source> <volume>1</volume>: <fpage>89</fpage>–<lpage>98</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Fernando1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fernando</surname><given-names>CT</given-names></name>, <name name-style="western"><surname>Liekens</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Bingle</surname><given-names>LE</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lenser</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Molecular circuits for associative learning in single-celled organisms</article-title>. <source>J R Soc Interface</source> <volume>6</volume>: <fpage>463</fpage>–<lpage>469</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Gandhi1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gandhi</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Ashkenasy</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Tannenbaum</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Associative learning in biochemical networks</article-title>. <source>J Theor Biol</source> <volume>249</volume>: <fpage>58</fpage>–<lpage>66</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Ginsburg1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ginsburg</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Jablonka</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>Epigenetic learning in non-neural organisms</article-title>. <source>J Biosci</source> <volume>34</volume>: <fpage>633</fpage>–<lpage>646</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Loewenstein1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loewenstein</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name> (<year>2003</year>) <article-title>Temporal integration by calcium dynamics in a model neuron</article-title>. <source>Nat Neurosci</source> <volume>6</volume>: <fpage>961</fpage>–<lpage>967</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Loewenstein2"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loewenstein</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Mahon</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Chadderton</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Kitamura</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Bistability of cerebellar Purkinje cells modulated by sensory stimulation</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>202</fpage>–<lpage>211</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Ferrell1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrell</surname><given-names>JE</given-names><suffix>Jr</suffix></name> (<year>2002</year>) <article-title>Self-perpetuating states in signal transduction: positive feedback, double-negative feedback and bistability</article-title>. <source>Curr Opin Cell Biol</source> <volume>14</volume>: <fpage>140</fpage>–<lpage>148</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Wilhelm1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilhelm</surname><given-names>T</given-names></name> (<year>2009</year>) <article-title>The smallest chemical reaction system with bistability</article-title>. <source>BMC Syst Biol</source> <volume>3</volume>: <fpage>90</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Koulakov1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koulakov</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Raghavachari</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kepecs</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lisman</surname><given-names>JE</given-names></name> (<year>2002</year>) <article-title>Model for a robust neural integrator</article-title>. <source>Nat Neurosci</source> <volume>5</volume>: <fpage>775</fpage>–<lpage>782</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Gardner1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>TS</given-names></name>, <name name-style="western"><surname>Cantor</surname><given-names>CR</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2000</year>) <article-title>Construction of a genetic toggle switch in Escherichia coli</article-title>. <source>Nature</source> <volume>403</volume>: <fpage>339</fpage>–<lpage>342</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-AjoFranklin1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ajo-Franklin</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Drubin</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Eskin</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Gee</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Landgraf</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Rational design of memory in eukaryotic cells</article-title>. <source>Genes Dev</source> <volume>21</volume>: <fpage>2271</fpage>–<lpage>2276</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Kramer1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kramer</surname><given-names>BP</given-names></name>, <name name-style="western"><surname>Viretta</surname><given-names>AU</given-names></name>, <name name-style="western"><surname>Daoud-El-Baba</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Aubel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Weber</surname><given-names>W</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>An engineered epigenetic transgene switch in mammalian cells</article-title>. <source>Nat Biotechnol</source> <volume>22</volume>: <fpage>867</fpage>–<lpage>870</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Isaacs1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Isaacs</surname><given-names>FJ</given-names></name>, <name name-style="western"><surname>Hasty</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Cantor</surname><given-names>CR</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2003</year>) <article-title>Prediction and measurement of an autoregulatory genetic module</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>100</volume>: <fpage>7714</fpage>–<lpage>7719</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Novick1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Novick</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Weiner</surname><given-names>M</given-names></name> (<year>1957</year>) <article-title>Enzyme Induction as an All-or-None Phenomenon</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>43</volume>: <fpage>553</fpage>–<lpage>566</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Ferrell2"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrell</surname><given-names>JE</given-names><suffix>Jr</suffix></name> (<year>2008</year>) <article-title>Feedback regulation of opposing enzymes generates robust, all-or-none bistable responses</article-title>. <source>Curr Biol</source> <volume>18</volume>: <fpage>R244</fpage>–<lpage>245</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Xiong1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xiong</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Ferrell</surname><given-names>JE</given-names><suffix>Jr</suffix></name> (<year>2003</year>) <article-title>A positive-feedback-based bistable ‘memory module’ that governs a cell fate decision</article-title>. <source>Nature</source> <volume>426</volume>: <fpage>460</fpage>–<lpage>465</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Bagowski1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bagowski</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>Ferrell</surname><given-names>JE</given-names><suffix>Jr</suffix></name> (<year>2001</year>) <article-title>Bistability in the JNK cascade</article-title>. <source>Curr Biol</source> <volume>11</volume>: <fpage>1176</fpage>–<lpage>1182</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Hasty1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasty</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pradines</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dolnik</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2000</year>) <article-title>Noise-based switches and amplifiers for gene expression</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>97</volume>: <fpage>2075</fpage>–<lpage>2080</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Pomerening1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pomerening</surname><given-names>JR</given-names></name> (<year>2008</year>) <article-title>Uncovering mechanisms of bistability in biological systems</article-title>. <source>Curr Opin Biotechnol</source> <volume>19</volume>: <fpage>381</fpage>–<lpage>388</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Ozbudak1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozbudak</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Thattai</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lim</surname><given-names>HN</given-names></name>, <name name-style="western"><surname>Shraiman</surname><given-names>BI</given-names></name>, <name name-style="western"><surname>Van Oudenaarden</surname><given-names>A</given-names></name> (<year>2004</year>) <article-title>Multistability in the lactose utilization network of Escherichia coli</article-title>. <source>Nature</source> <volume>427</volume>: <fpage>737</fpage>–<lpage>740</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Mahaffy1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mahaffy</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Savev</surname><given-names>ES</given-names></name> (<year>1999</year>) <article-title>Stability Analysis for a mathematical model of the lac operon</article-title>. <source>Q Appl Math</source> <volume>57</volume>: <fpage>37</fpage>–<lpage>53</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Yildirim1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yildirim</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Santillan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Horike</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Mackey</surname><given-names>MC</given-names></name> (<year>2004</year>) <article-title>Dynamics and bistability in a reduced model of the lac operon</article-title>. <source>Chaos</source> <volume>14</volume>: <fpage>279</fpage>–<lpage>292</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Raj1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raj</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Peskin</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Tranchina</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Vargas</surname><given-names>DY</given-names></name>, <name name-style="western"><surname>Tyagi</surname><given-names>S</given-names></name> (<year>2006</year>) <article-title>Stochastic mRNA synthesis in mammalian cells</article-title>. <source>PLoS Biol</source> <volume>4</volume>: <fpage>e309</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Raj2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raj</surname><given-names>A</given-names></name>, <name name-style="western"><surname>van Oudenaarden</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Nature, nurture, or chance: stochastic gene expression and its consequences</article-title>. <source>Cell</source> <volume>135</volume>: <fpage>216</fpage>–<lpage>226</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Golding1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Golding</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Paulsson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zawilski</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Cox</surname><given-names>EC</given-names></name> (<year>2005</year>) <article-title>Real-time kinetics of gene activity in individual bacteria</article-title>. <source>Cell</source> <volume>123</volume>: <fpage>1025</fpage>–<lpage>1036</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Bialek1"><label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Bialek W. (2000) Stability and Noise in Biochemical Switches. pp. 103–109.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Neiman1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neiman</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Loewenstein</surname><given-names>Y</given-names></name> (<year>2013</year>) <article-title>Covariance-based synaptic plasticity in an attractor network model accounts for fast adaptation in free operant learning</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>1521</fpage>–<lpage>1534</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-VanKampen1"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Van Kampen NG (1992) Stochastic Processes in Physics and Chemistry. Amsterdam: North-Holland.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Proft1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Proft</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Struhl</surname><given-names>K</given-names></name> (<year>2002</year>) <article-title>Hog1 kinase converts the Sko1-Cyc8-Tup1 repressor complex into an activator that recruits SAGA and SWI/SNF in response to osmotic stress</article-title>. <source>Mol Cell</source> <volume>9</volume>: <fpage>1307</fpage>–<lpage>1317</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Tsodyks1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name> (<year>1990</year>) <article-title>Associative Memory in Neural Networks with Binary Synapses Modern Physics Letters B</article-title>. <volume>4</volume>: <fpage>713</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Amit1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amit</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name> (<year>1994</year>) <article-title>Learning in Neural Networks with Material Synapses</article-title>. <source>Neural Comput</source> <volume>6</volume>: <fpage>957</fpage>–<lpage>982</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Fusi1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name> (<year>2007</year>) <article-title>Limits on the memory storage capacity of bounded synapses</article-title>. <source>Nat Neurosci</source> <volume>10</volume>: <fpage>485</fpage>–<lpage>493</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Yoon1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yoon</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>Abdelmohsen</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Gorospe</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Post-transcriptional gene regulation by long noncoding RNA</article-title>. <source>J Mol Biol</source></mixed-citation>
</ref>
<ref id="pcbi.1003179-Storz1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Storz</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Altuvia</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wassarman</surname><given-names>KM</given-names></name> (<year>2005</year>) <article-title>An abundance of RNA regulators</article-title>. <source>Annu Rev Biochem</source> <volume>74</volume>: <fpage>199</fpage>–<lpage>217</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Markevich1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markevich</surname><given-names>NI</given-names></name>, <name name-style="western"><surname>Hoek</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Kholodenko</surname><given-names>BN</given-names></name> (<year>2004</year>) <article-title>Signaling switches and bistability arising from multisite phosphorylation in protein kinase cascades</article-title>. <source>J Cell Biol</source> <volume>164</volume>: <fpage>353</fpage>–<lpage>359</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Yao1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yao</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ndoja</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Regulation of gene expression by the ubiquitin-proteasome system</article-title>. <source>Semin Cell Dev Biol</source> <volume>23</volume>: <fpage>523</fpage>–<lpage>529</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Kapuy1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kapuy</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Barik</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sananes</surname><given-names>MRD</given-names></name>, <name name-style="western"><surname>Tyson</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Novak</surname><given-names>B</given-names></name> (<year>2009</year>) <article-title>Bistability by multiple phosphorylation of regulatory proteins</article-title>. <source>Progress in Biophysics &amp; Molecular Biology</source> <volume>100</volume>: <fpage>47</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Chin1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chin</surname><given-names>JW</given-names></name> (<year>2006</year>) <article-title>Modular approaches to expanding the functions of living matter</article-title>. <source>Nat Chem Biol</source> <volume>2</volume>: <fpage>304</fpage>–<lpage>311</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Hasty2"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasty</surname><given-names>J</given-names></name>, <name name-style="western"><surname>McMillen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2002</year>) <article-title>Engineered gene circuits</article-title>. <source>Nature</source> <volume>420</volume>: <fpage>224</fpage>–<lpage>230</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Lionel1"><label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">Lionel N (2009) Introduction To Psychology. Juta and Company Ltd.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Gallistel1"><label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Gallistel CR (1990) The organization of learning. Cambridge, MA: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Garmendia1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Garmendia</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Hernandez</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sanchez</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Martinez</surname><given-names>JL</given-names></name> (<year>2012</year>) <article-title>Metagenomics and antibiotics</article-title>. <source>Clin Microbiol Infect</source> <volume>18 Suppl 4</volume>: <fpage>27</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Alekshun1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alekshun</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>Levy</surname><given-names>SB</given-names></name> (<year>1999</year>) <article-title>The mar regulon: multiple resistance to antibiotics and other toxic chemicals</article-title>. <source>Trends Microbiol</source> <volume>7</volume>: <fpage>410</fpage>–<lpage>413</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Delihas1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Delihas</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Forst</surname><given-names>S</given-names></name> (<year>2001</year>) <article-title>MicF: an antisense RNA gene involved in response of Escherichia coli to global stress factors</article-title>. <source>J Mol Biol</source> <volume>313</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Whitehead1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Whitehead</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Barnard</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Slater</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Simpson</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Salmond</surname><given-names>GP</given-names></name> (<year>2001</year>) <article-title>Quorum-sensing in Gram-negative bacteria</article-title>. <source>FEMS Microbiol Rev</source> <volume>25</volume>: <fpage>365</fpage>–<lpage>404</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Novick2"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Novick</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Szilard</surname><given-names>L</given-names></name> (<year>1950</year>) <article-title>Description of the chemostat</article-title>. <source>Science</source> <volume>112</volume>: <fpage>715</fpage>–<lpage>716</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003179-Bailey1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bailey</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Constantinidou</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Ivens</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Garvey</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Webber</surname><given-names>MA</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Exposure of Escherichia coli and Salmonella enterica serovar Typhimurium to triclosan induces a species-specific response, including drug detoxification</article-title>. <source>J Antimicrob Chemother</source> <volume>64</volume>: <fpage>973</fpage>–<lpage>985</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>