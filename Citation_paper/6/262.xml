<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-46274</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0096732</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Biochemical simulations</subject></subj-group></subj-group><subj-group><subject>Biotechnology</subject><subj-group><subject>Bioengineering</subject><subj-group><subject>Biological systems engineering</subject><subject>Biomedical engineering</subject></subj-group></subj-group></subj-group><subj-group><subject>Computational biology</subject><subj-group><subject>Genome analysis</subject><subj-group><subject>Genetic networks</subject></subj-group></subj-group></subj-group><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject></subj-group></subj-group><subj-group><subject>Systems biology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Information technology</subject><subj-group><subject>Databases</subject></subj-group></subj-group><subj-group><subject>Information theory</subject></subj-group><subj-group><subject>Network analysis</subject><subj-group><subject>Metabolic networks</subject><subject>Regulatory networks</subject><subject>Signaling networks</subject></subj-group></subj-group><subj-group><subject>Software engineering</subject><subj-group><subject>Software tools</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Engineering and technology</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Social sciences</subject></subj-group></article-categories>
<title-group>
<article-title>MIDER: Network Inference with Mutual Information Distance and Entropy Reduction</article-title>
<alt-title alt-title-type="running-head">Network Inference with MIDER</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Villaverde</surname><given-names>Alejandro F.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>John</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Morán</surname><given-names>Federico</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Banga</surname><given-names>Julio R.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Bioprocess Engineering Group, IIM-CSIC, Vigo, Spain</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Chemistry, Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Department of Biochemistry and Molecular Biology, Complutense University, Madrid, Spain</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Rattray</surname><given-names>Magnus</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Manchester, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">afvillaverde@iim.csic.es</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: AFV JR FM JRB. Performed the experiments: AFV. Analyzed the data: AFV JRB. Contributed reagents/materials/analysis tools: JR FM. Wrote the paper: AFV JRB.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>7</day><month>5</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>5</issue>
<elocation-id>e96732</elocation-id>
<history>
<date date-type="received"><day>5</day><month>11</month><year>2013</year></date>
<date date-type="accepted"><day>9</day><month>4</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Villaverde et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>The prediction of links among variables from a given dataset is a task referred to as network inference or reverse engineering. It is an open problem in bioinformatics and systems biology, as well as in other areas of science. Information theory, which uses concepts such as mutual information, provides a rigorous framework for addressing it. While a number of information-theoretic methods are already available, most of them focus on a particular type of problem, introducing assumptions that limit their generality. Furthermore, many of these methods lack a publicly available implementation. Here we present MIDER, a method for inferring network structures with information theoretic concepts. It consists of two steps: first, it provides a representation of the network in which the distance among nodes indicates their statistical closeness. Second, it refines the prediction of the existing links to distinguish between direct and indirect interactions and to assign directionality. The method accepts as input time-series data related to some quantitative features of the network nodes (such as e.g. concentrations, if the nodes are chemical species). It takes into account time delays between variables, and allows choosing among several definitions and normalizations of mutual information. It is general purpose: it may be applied to any type of network, cellular or otherwise. A Matlab implementation including source code and data is freely available (<ext-link ext-link-type="uri" xlink:href="http://www.iim.csic.es/~gingproc/mider.html" xlink:type="simple">http://www.iim.csic.es/~gingproc/mider.html</ext-link>). The performance of MIDER has been evaluated on seven different benchmark problems that cover the main types of cellular networks, including metabolic, gene regulatory, and signaling. Comparisons with state of the art information–theoretic methods have demonstrated the competitive performance of MIDER, as well as its versatility. Its use does not demand any a priori knowledge from the user; the default settings and the adaptive nature of the method provide good results for a wide range of problems without requiring tuning.</p>
</abstract>
<funding-group><funding-statement>This work was supported by the EU project “BioPreDyn” (European Commission grant FP7-KBBE-2011-5/289434); the Spanish Ministerio de Economia y Competitividad (MINECO) projects DPI2011-28112-C04-03, BFU2009-12895-C02-02, and BFU2012-39816-C02-02; the CSIC intramural project “BioREDES” (PIE-201170E018); and the National Science Foundation grant CHE 0847073. Work in UCM is supported by grant BFU2012-39816-C02-02 from Spanish Ministry of Economy and Competitiveness (MINECO) and Consolider/Ingenio2010 CSD2007-00002 from Spanish MICINN. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="15"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Reverse engineering a network consists of inferring the structure of interactions between its components from a set of data. This problem appears in many different contexts, such as chemistry (construction of chemical reaction mechanisms), biology (inferring gene regulatory networks), engineering (system identification), or social sciences <xref ref-type="bibr" rid="pone.0096732-Villaverde1">[1]</xref>. In bioinformatics, the network inference problem consists of reconstructing the structure of a cellular network from data. Cellular networks can be classified as gene regulatory, metabolic, or protein signaling, depending on the type of entities and interactions. <xref ref-type="sec" rid="s2">Methods</xref> developed specifically for a particular type of network usually try to exploit previously available knowledge, and make assumptions about the underlying structure; a typical example is inference of gene regulatory networks (GRN) <xref ref-type="bibr" rid="pone.0096732-Markowetz1">[2]</xref>–<xref ref-type="bibr" rid="pone.0096732-Wang1">[11]</xref>. However, there is also a number of methods that are not tailored to a particular type of network, and are applicable to chemical reaction networks of any kind <xref ref-type="bibr" rid="pone.0096732-Crampin1">[12]</xref>, <xref ref-type="bibr" rid="pone.0096732-Ross1">[13]</xref>.</p>
<p>Reviews of network inference methods typically find large discrepancies among the predictions of different algorithms, and usually conclude that there is no single best method for all problems <xref ref-type="bibr" rid="pone.0096732-DeSmet1">[5]</xref>, <xref ref-type="bibr" rid="pone.0096732-Marbach1">[14]</xref>. Different methods highlight different interaction types and can be therefore considered complementary <xref ref-type="bibr" rid="pone.0096732-Prill1">[15]</xref>–<xref ref-type="bibr" rid="pone.0096732-Lecca1">[17]</xref>. Furthermore, even the best methods achieve low prediction accuracies, and manage to recover only small networks of simple topology <xref ref-type="bibr" rid="pone.0096732-Maetschke1">[10]</xref>. Hence it has been argued that accurate reconstruction of large-scale regulatory network from expression data alone is currently not feasible, and unsupervised inference methods should focus instead on smaller-scale networks for which higher-quality data is available <xref ref-type="bibr" rid="pone.0096732-Maetschke1">[10]</xref>.</p>
<p>The present work addresses the problem of recovering the structure of a network from the available data in its most general form. This entails that no assumptions about the underlying structure are made, and previous knowledge is not taken into account. Interactions should be deduced only from the statistical features of the data, without resorting to biological intuition. To reach this goal, many methods have exploited the analytical tools provided by information theory. The fundamental concept of information theory is entropy, which was introduced by Shannon <xref ref-type="bibr" rid="pone.0096732-Shannon1">[18]</xref> as a way of measuring the uncertainty of a random variable. Let X be a discrete random vector with alphabet <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e001" xlink:type="simple"/></inline-formula> and probability mass function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e002" xlink:type="simple"/></inline-formula>. The entropy is<disp-formula id="pone.0096732.e003"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e003" xlink:type="simple"/><label>(1)</label></disp-formula>where log is usually the logarithm to the base 2. In the case of continuous variables the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e004" xlink:type="simple"/></inline-formula> are replaced by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e005" xlink:type="simple"/></inline-formula>. The joint entropy of a pair of variables (X,Y) is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e006" xlink:type="simple"/></inline-formula>. Conditional entropy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e007" xlink:type="simple"/></inline-formula> is the entropy of a random variable conditional on the knowledge of another one:</p>
<p><disp-formula id="pone.0096732.e008"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e008" xlink:type="simple"/><label>(2)</label></disp-formula>The joint entropy and the conditional entropy are related so that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e009" xlink:type="simple"/></inline-formula>.</p>
<p>The relative entropy, which is also known as Kullback–Leibler divergence or information gain, is a measure of the distance between two distributions. It is defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e010" xlink:type="simple"/></inline-formula>; it is always non-negative, and it is zero if and only if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e011" xlink:type="simple"/></inline-formula>. The relative entropy between the joint distribution, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e012" xlink:type="simple"/></inline-formula>, and the product distribution, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e013" xlink:type="simple"/></inline-formula>, is called mutual information, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e014" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096732-Cover1">[19]</xref>, that is,<disp-formula id="pone.0096732.e015"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e015" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>The mutual information measures the amount of information that one random variable contains about another. In other words, it is the reduction in the uncertainty of one variable due to the knowledge of another. Since it does not assume any property of the dependence between variables–such as linearity or continuity–it is more general than linear measures such as the correlation coefficient, and is able to detect more interactions <xref ref-type="bibr" rid="pone.0096732-Faith1">[20]</xref>. The concept of mutual information suggests its application for inferring interaction networks of any kind (chemical, biological, social): if two components of a network interact closely, their mutual information will be large; if they are not related, their mutual information will be theoretically zero.</p>
<p>In the next section (Methods) we present a methodology and software toolbox called MIDER (Mutual Information Distance and Entropy Reduction). MIDER seeks to achieve high precision on small and medium-scale networks of any kind, cellular or otherwise, although it can also be applied to large-scale problems. It is designed with the aim of accurately distinguishing between direct and indirect interactions, thus minimizing the number of false positives. In the <xref ref-type="sec" rid="s3">Results</xref> section the performance of MIDER is compared with that of four other methods reviewed in this Introduction, using seven benchmark problems. Final remarks are given in the Conclusions section.</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<p>The MIDER workflow is shown in <xref ref-type="fig" rid="pone-0096732-g001">Figure 1</xref>. It begins by estimating time-lagged multi-dimensional entropies and mutual information from data. These estimates are then used for constructing a distance matrix between variables, based on estimates of the mutual information from data. This matrix is converted for visualization into a two-dimensional map of the variables (species), with the distances among them being a first guess for their connections (reactions, interactions). Then an entropy reduction step based on conditional entropies is applied to further refine the map, helping in discriminating between direct and indirect connections. Finally, the direction of the inferred links is assigned using transfer entropies. The next subsection (Background) gives an overview of the information-theoretic methods already available, and the subsequent subsections present the details of the MIDER methodology.</p>
<fig id="pone-0096732-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g001</object-id><label>Figure 1</label><caption>
<title>MIDER workflow.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g001" position="float" xlink:type="simple"/></fig><sec id="s2a">
<title>Background: information-theoretic methods for network inference</title>
<p>A recent review on information-theoretic network inference methods can be found in <xref ref-type="bibr" rid="pone.0096732-Villaverde2">[21]</xref>. Early examples of biological applications, which relied basically on the definition of mutual information, <xref ref-type="disp-formula" rid="pone.0096732.e015">Equation (3</xref>), can be found in <xref ref-type="bibr" rid="pone.0096732-Farber1">[22]</xref>–<xref ref-type="bibr" rid="pone.0096732-Butte1">[26]</xref>. More refined techniques appeared soon afterwards, such as the Entropy Metric Construction (EMC) presented in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>, which is oriented towards reverse engineering chemical reaction mechanisms. It estimates mutual information from time series data of concentrations of the species, and defines the distance between two species X and Y as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e016" xlink:type="simple"/></inline-formula>. Since it takes into account possible time delays (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e017" xlink:type="simple"/></inline-formula>) between species, the EMC distance is actually the minimum regardless of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e018" xlink:type="simple"/></inline-formula>:<disp-formula id="pone.0096732.e019"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e019" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>Thus it defines a matrix of distances between species, and by applying Multidimensional Scaling (MDS) it obtains a two-dimensional map that serves as an indication of species connectivity. EMC was designed as a generalization of a previous method called CMC, Correlation Metric Construction <xref ref-type="bibr" rid="pone.0096732-Arkin1">[29]</xref>, <xref ref-type="bibr" rid="pone.0096732-Arkin2">[30]</xref>, which used correlations instead of mutual information and extracted indications of the causality of reactions from the temporal ordering of the correlation maxima. This network inference approach based on time–lagged correlations was combined in <xref ref-type="bibr" rid="pone.0096732-Lecca2">[31]</xref> with an additional parameter estimation step, where the kinetic rate constants resulting from the guessed interactions were also deduced. Samoilov et al proposed to extend EMC with the Entropy Reduction Technique, ERT <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>. This never tested method was designed to return the ordered list of species <bold>X</bold>* with which a given species Y reacts, exploiting the property that, if a variable Y is completely independent of a set of variables <bold>X</bold>, then theoretically <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e020" xlink:type="simple"/></inline-formula>; otherwise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e021" xlink:type="simple"/></inline-formula>. The ERT algorithm starts with an empty set of reacting species, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e022" xlink:type="simple"/></inline-formula>, for every species Y. Then it finds the species that causes the largest entropy reduction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e023" xlink:type="simple"/></inline-formula>, and adds it to the set, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e024" xlink:type="simple"/></inline-formula>. This is repeated until <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e025" xlink:type="simple"/></inline-formula>, or when all species except Y are already in <bold>X</bold>*. In other words, ERT determines whether the nonlinear variation in a variable Y is explainable by the variations of a subset of the other variables in the system, <bold>X</bold>*. This is carried out by iterating through cycles of adding a variable X* to <bold>X</bold>* that minimizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e026" xlink:type="simple"/></inline-formula> until further additions do not decrease the entropy.</p>
<p>A different way of distinguishing direct from indirect interactions is carried out by the ARACNE method <xref ref-type="bibr" rid="pone.0096732-Margolin1">[32]</xref>, <xref ref-type="bibr" rid="pone.0096732-Margolin2">[33]</xref>, which builds on <xref ref-type="bibr" rid="pone.0096732-Butte1">[26]</xref> and includes an additional step. It was designed for identifying transcriptional interactions between gene products, using microarray expression profile data. It applies the Data Processing Inequality (DPI) to discard indirect interactions. The DPI is a property of mutual information <xref ref-type="bibr" rid="pone.0096732-Cover1">[19]</xref> that states that, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e027" xlink:type="simple"/></inline-formula> forms a Markov chain, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e028" xlink:type="simple"/></inline-formula>. The ARACNE algorithm examines each gene triplet for which all three mutual informations are greater than a threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e029" xlink:type="simple"/></inline-formula> and removes the edge with the smallest value. An extension called hARACNe, which considers indirect interactions of higher-order (that is, mediated by more than one extra regulator), has recently been published <xref ref-type="bibr" rid="pone.0096732-Jang1">[34]</xref>. Additionally, a time-delay version of ARACNE, TD-ARACNE <xref ref-type="bibr" rid="pone.0096732-Zoppoli1">[35]</xref>, can be used when time-series data is available.</p>
<p>Context Likelihood of Relatedness, CLR <xref ref-type="bibr" rid="pone.0096732-Faith1">[20]</xref>, is another technique designed for inferring transcriptional interactions. It estimates the mutual information between a transcription factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e030" xlink:type="simple"/></inline-formula> and a gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e031" xlink:type="simple"/></inline-formula>, and corrects its value by comparing it with the background distribution of mutual information for all possible interactions involving <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e032" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e033" xlink:type="simple"/></inline-formula>. CLR takes into account the network context, assuming that the most probable interactions are not those with the highest MI scores, but those whose scores are significantly above the background distribution. The main purpose of this correction step is to remove false correlations. CLR was tested using <italic>E. coli</italic> data and known regulatory interactions from RegulonDB; for that data set it was reported <xref ref-type="bibr" rid="pone.0096732-Faith1">[20]</xref> that it outperformed other methods, including ARACNE.</p>
<p>The Minimum Redundancy Maximum Relevance method (MRMR) introduced in <xref ref-type="bibr" rid="pone.0096732-Peng1">[36]</xref> combines two criteria. On the one hand, it aims at selecting the subset of genes that have the maximum relevance for a given target, while on the other hand it aims at selecting genes that are mutually maximally dissimilar (minimum redundancy). MRNET <xref ref-type="bibr" rid="pone.0096732-Meyer1">[37]</xref> is a method for inferring transcriptional networks that applies the MRMR idea. It seeks to maximize, for every target variable Y, a score <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e034" xlink:type="simple"/></inline-formula> which consists of a relevance term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e035" xlink:type="simple"/></inline-formula> and a redundancy term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e036" xlink:type="simple"/></inline-formula>, which are defined as<disp-formula id="pone.0096732.e037"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e037" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>The rationale is to rank direct interactions better than indirect interactions. MRNET was implemented in the R package MINET <xref ref-type="bibr" rid="pone.0096732-Meyer2">[38]</xref>, which also includes implementations of ARACNE and CLR.</p>
<p>Another way of discriminating between direct and indirect interactions is given by MI3, three-way mutual information <xref ref-type="bibr" rid="pone.0096732-Luo1">[39]</xref>. It is a statistical learning strategy specifically designed to detect cooperative activity between two regulators in transcriptional regulatory networks. It aims at detecting higher order interactions, a purpose for which it uses scores calculated from multiple-variable joint entropies. Given three variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e038" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e039" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e040" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e041" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e042" xlink:type="simple"/></inline-formula> are possible regulators of the target variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e043" xlink:type="simple"/></inline-formula>, the MI3 metric is defined as<disp-formula id="pone.0096732.e044"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e044" xlink:type="simple"/><label>(6)</label></disp-formula></p>
<p>Finally, some authors have proposed to redefine the concept of entropy in order to make it more suited for inferring networks where long-range interactions exist. <xref ref-type="disp-formula" rid="pone.0096732.e003">Equation (1</xref>) is the classical definition of entropy, also known as Boltzmann-Gibbs entropy (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e045" xlink:type="simple"/></inline-formula>) or Shannon entropy. This concept is the basis of standard statistical mechanics, which applies to physical systems that satisfy ergodicity at the microscopic dynamical level. Standard statistical mechanics is extensive: it assumes that, for a system <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e046" xlink:type="simple"/></inline-formula> consisting of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e047" xlink:type="simple"/></inline-formula> independent subsystems <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e048" xlink:type="simple"/></inline-formula>, it holds that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e049" xlink:type="simple"/></inline-formula>. Tsallis <xref ref-type="bibr" rid="pone.0096732-Tsallis1">[40]</xref> argued that systems with long-range interactions violate this hypothesis, and proposed to overcome this limitation by generalizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e050" xlink:type="simple"/></inline-formula> as:<disp-formula id="pone.0096732.e051"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e051" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e052" xlink:type="simple"/></inline-formula> is a positive constant that sets the dimension and scale, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e053" xlink:type="simple"/></inline-formula> are the probabilities associated with the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e054" xlink:type="simple"/></inline-formula> distinct configurations of the system, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e055" xlink:type="simple"/></inline-formula> is the entropic parameter. The entropic parameter characterizes the degree of nonextensivity, which in the limit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e056" xlink:type="simple"/></inline-formula> recovers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e057" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e058" xlink:type="simple"/></inline-formula>, the Boltzmann constant. The generalized entropy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e059" xlink:type="simple"/></inline-formula> is non-extensive for systems without correlations; however, for complex systems with long-range correlations the reverse is true: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e060" xlink:type="simple"/></inline-formula> is non-extensive and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e061" xlink:type="simple"/></inline-formula> becomes extensive <xref ref-type="bibr" rid="pone.0096732-Tsallis2">[41]</xref>. By defining the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e062" xlink:type="simple"/></inline-formula>-logarithm function as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e063" xlink:type="simple"/></inline-formula>, the generalized entropy can be expressed in a similar form as the Boltzmann-Gibbs entropy of <xref ref-type="disp-formula" rid="pone.0096732.e003">Equation (1</xref>), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e064" xlink:type="simple"/></inline-formula>, and, as in <xref ref-type="disp-formula" rid="pone.0096732.e015">Equation (3</xref>), a generalized mutual information can be defined <xref ref-type="bibr" rid="pone.0096732-Borland1">[42]</xref>,<disp-formula id="pone.0096732.e065"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e065" xlink:type="simple"/><label>(8)</label></disp-formula>which has the necessary properties to be used as a criterion measure for consistent testing <xref ref-type="bibr" rid="pone.0096732-Tsallis3">[43]</xref>. The generalized conditional entropy is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e066" xlink:type="simple"/></inline-formula>. It is possible to look for dependencies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e067" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e068" xlink:type="simple"/></inline-formula> by minimizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e069" xlink:type="simple"/></inline-formula>, as done by Lopes et al <xref ref-type="bibr" rid="pone.0096732-Lopes1">[44]</xref> in the context of reverse-engineering gene networks. They reported an improvement on the inference accuracy by the adoption of subextensive entropies, which reduced the number of false connections.</p>
</sec><sec id="s2b">
<title>Calculating mutual information</title>
<p>This subsection explains how MIDER (1) estimates mutual information from data using an adaptive partitioning algorithm, (2) provides several normalizations of the mutual information, and (3) plots three-dimensional landscapes of the mutual information pairs as a function of the time lag between variables.</p>
<sec id="s2b1">
<title>Estimation of mutual information from data</title>
<p>Mutual information can be either analytically calculated or estimated from experimental data. For reverse engineering purposes, knowledge of the underlying system equations cannot be assumed; therefore it is necessary to estimate mutual information from the available datasets. This is far from trivial, and several algorithms have been proposed for this task. The simplest one is a naive estimation, where the data is binned into equally sized intervals and an indicator function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e070" xlink:type="simple"/></inline-formula> counts the number of datapoints within each bin. Then the probabilities are estimated from the relative frequencies of occurrence,<disp-formula id="pone.0096732.e071"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e071" xlink:type="simple"/><label>(9)</label></disp-formula></p>
<p>This simple approach gives good results if the number of data points is large; otherwise the finite-size effects lead to overestimation of the mutual information <xref ref-type="bibr" rid="pone.0096732-Steuer1">[45]</xref>. A more sophisticated approach is adaptive partitioning, where the size of the bins is not uniform; instead, it is chosen so that each bin contains approximately the same number of points. One such algorithm is the Fraser-Swinney algorithm <xref ref-type="bibr" rid="pone.0096732-Fraser1">[46]</xref> chosen in <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>; for a review of this and other possibilities, including kernel density estimation, see <xref ref-type="bibr" rid="pone.0096732-Steuer1">[45]</xref>. In <xref ref-type="bibr" rid="pone.0096732-Cellucci1">[47]</xref> an alternative to the Fraser-Swinney algorithm was presented, which was reported to achieve comparable performance as the original method while requiring just <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e072" xlink:type="simple"/></inline-formula> of the computational time. Further, it has the additional advantage of providing an explicit calculation of the probability of the null hypothesis that X and Y are independent.</p>
<p>These reasons support the choice of the aforementioned adaptive algorithm <xref ref-type="bibr" rid="pone.0096732-Cellucci1">[47]</xref>, which has been re-implemented and adapted in MIDER. Specifically, it has been augmented so that it calculates not only the mutual information between a pair of variables but also the joint entropies of pairs, triplets, and 4-tuples of variables, that is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e073" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e074" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e075" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e076" xlink:type="simple"/></inline-formula>, which may be required at the entropy reduction step.</p>
</sec><sec id="s2b2">
<title>Normalized mutual information</title>
<p>A characteristic of mutual information is that its range of values is in principle unknown. A number of normalizations have been proposed in the literature. An early one was the definition by Linfoot <xref ref-type="bibr" rid="pone.0096732-Linfoot1">[48]</xref>, with values ranging from 0 to 1:<disp-formula id="pone.0096732.e077"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e077" xlink:type="simple"/><label>(10)</label></disp-formula></p>
<p>In <xref ref-type="bibr" rid="pone.0096732-Michaels1">[25]</xref> a normalization was introduced in the context of analyzing large-scale gene expression data:<disp-formula id="pone.0096732.e078"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e078" xlink:type="simple"/><label>(11)</label></disp-formula></p>
<p>The distance measure is then defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e079" xlink:type="simple"/></inline-formula>. This normalization has two advantages: (1) the distance is between 0 and 1, and (2) it guarantees that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e080" xlink:type="simple"/></inline-formula>.</p>
<p>Studholme et al <xref ref-type="bibr" rid="pone.0096732-Studholme1">[49]</xref> proposed an overlap invariant entropy measure in the context of 3D medical image alignment. It was defined as<disp-formula id="pone.0096732.e081"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e081" xlink:type="simple"/><label>(12)</label></disp-formula>which can have values between 1 and 2.</p>
<p>MIDER lets the user choose between any of these normalizations or the standard definition of mutual information. While normalization changes the numerical range of the distance matrix, in practice its effects on the reconstructed network are very small.</p>
<p>Furthermore, the user can choose between the classic definition of mutual information (<xref ref-type="disp-formula" rid="pone.0096732.e015">Equation (3</xref>)) and the nonextensive version (<xref ref-type="disp-formula" rid="pone.0096732.e065">Equation (8</xref>)). The default choice is the classic one; the nonextensive definition can be used if there are reasons to believe that the underlying system is more suited to it.</p>
</sec><sec id="s2b3">
<title>Plots of the time-lagged mutual information</title>
<p>MIDER generates 3D plots of the mutual information between every variable and all the others, for every time lag considered. They are a graphical representation of the time-varying dependency between variables. To make visualization easier, the mutual information is normalized to the range [0,1] according to <xref ref-type="disp-formula" rid="pone.0096732.e077">Equation (10</xref>). An example is shown in <xref ref-type="fig" rid="pone-0096732-g002">Figure 2</xref>.</p>
<fig id="pone-0096732-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g002</object-id><label>Figure 2</label><caption>
<title>MI plot.</title>
<p>One of the MIDER outputs, shown for Benchmark B2: a 3D plot of the mutual information between a variable (X3) and the rest, for different time lags between variables.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g002" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s2c">
<title>Defining the distance between variables</title>
<p>MIDER uses mutual information <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e082" xlink:type="simple"/></inline-formula> as a measure of statistical dependence to define a distance between the variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e083" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e084" xlink:type="simple"/></inline-formula>. The measure of statistical closeness between two variables is the number of states jointly available to the two variables – the size of the support set – compared to the number of states available to them individually. The support set of a distribution is the smallest closed set whose complement has probability zero; it may be understood as the points or elements that are actual members of the distribution. We denote the support set of a continuous variable by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e085" xlink:type="simple"/></inline-formula>. Following <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>, we define the distance between two variables as the support set of the two variables divided by the product of the support sets of each variable:<disp-formula id="pone.0096732.e086"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e086" xlink:type="simple"/><label>(13)</label></disp-formula></p>
<p>If time series data is available, the mutual information between two variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e087" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e088" xlink:type="simple"/></inline-formula> can be calculated for different delays <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e089" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e090" xlink:type="simple"/></inline-formula>. The distance used in MIDER is the minimum of <xref ref-type="disp-formula" rid="pone.0096732.e086">Equation (13</xref>) regardless of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e091" xlink:type="simple"/></inline-formula>:<disp-formula id="pone.0096732.e092"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e092" xlink:type="simple"/><label>(14)</label></disp-formula>which is the same distance that was defined in eq. (4). Multidimensional Scaling (MDS), a tool for representing high-dimensional data in a reduced number of coordinates, is then applied to the distance matrix for visualization purposes. MIDER uses MDS to generate a two-dimensional configuration of points representing each of the species. This 2D plot gives an indication of the likelihood of connections: the closer two species appear in the map, the more likely it is that there exists a link between them. However, in the presence of indirect relations the closeness can be misleading. To help in distinguishing direct and indirect relations, MIDER carries out entropy reduction as detailed in the next subsection.</p>
</sec><sec id="s2d">
<title>Detecting indirect interactions with entropy reduction</title>
<p>MIDER implements an entropy reduction procedure that is inspired by the one proposed in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>, which was described in the Background subsection as part of the ERT method. As has been already explained, ERT seeks to determine if the variation in a variable Y can be explained by the variations in other variables in the system. The outcome of ERT would be the list of species <bold>X</bold> with which a given species Y reacts, in order of the reaction strength. Note that neither the EMC nor the ERT methods are publicly available. Indeed, to the best of the authors' knowledge the ERT method is a just a theoretical proposal, which has never been implemented or tested. Hence the use of the conditional tense to refer to its results. The mathematical formulation stems from the observation that, if a variable Y is completely independent of a set of variables <bold>X</bold>, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e093" xlink:type="simple"/></inline-formula>; otherwise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e094" xlink:type="simple"/></inline-formula>. By iterating through cycles of adding a variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e095" xlink:type="simple"/></inline-formula> that reduces <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e096" xlink:type="simple"/></inline-formula>, ERT would yield an ordered set of variables that control the variation in Y. Theoretically, ERT stops iterating when it stops explaining any more of Y with new X's. In practice, entropy values are estimated from data, and are therefore an approximation. Since their precision is limited, this theoretical condition is not appropriate as a termination criterion in real applications. MIDER carries out several entropy reduction rounds, and in each one follows this practical guideline to consider a connection as true and not as an artifact: for hypothesizing that a species <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e097" xlink:type="simple"/></inline-formula> is connected with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e098" xlink:type="simple"/></inline-formula> (which has already been predicted to be connected with a subset <bold>X</bold>*), its inclusion must reduce the entropy by a proportion at least equal to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e099" xlink:type="simple"/></inline-formula>. That is, a link between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e100" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e101" xlink:type="simple"/></inline-formula> is predicted if and only if<disp-formula id="pone.0096732.e102"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e102" xlink:type="simple"/><label>(15)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e103" xlink:type="simple"/></inline-formula> is the reduction in the entropy of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e104" xlink:type="simple"/></inline-formula> due to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e105" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e106" xlink:type="simple"/></inline-formula> is a threshold that may be fixed by the user or (by default) calculated automatically as a function of the entropy values. By default <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e107" xlink:type="simple"/></inline-formula> is set to a value which is obtained from the maximum reduction in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e108" xlink:type="simple"/></inline-formula> achieved by any variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e109" xlink:type="simple"/></inline-formula>, as follows:</p>
<p><disp-formula id="pone.0096732.e110"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e110" xlink:type="simple"/></disp-formula></p>
<p>The numerical values, such as the upper limit of 0.2, were empirically chosen; this tuning was carried out with the datasets used in the <xref ref-type="sec" rid="s3">Results</xref> section, for which the above rule provided good results.</p>
<p>Note that other measures of entropic reduction have been proposed elsewhere for similar tasks, and could also be used at this step. For example, in the area of machine learning the concept of variable relevance, defined as the relative reduction of uncertainty of one variable due to the knowledge of another, was formalized <xref ref-type="bibr" rid="pone.0096732-Bell1">[50]</xref> in the context of feature subset selection as<disp-formula id="pone.0096732.e111"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e111" xlink:type="simple"/><label>(16)</label></disp-formula></p>
<p>MIDER implements the entropy reduction step according to <xref ref-type="disp-formula" rid="pone.0096732.e102">Equation (15</xref>), which was proposed in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>. A limitation of entropy reduction is that a large amount of data is required to obtain reliable estimations of joint entropies of many variables. This was acknowledged for ERT in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>, where it was noted that for multivariate Gaussian distributions the amount of data needed increases exponentially with the number of variables. Hence, when reconstructing large systems one can generally not aspire to inspect all of the possible combinations of reactants for a given species. However, this is generally not necessary, since in practice a species reacts only with a reduced number of other species. Thus it is feasible to do a limited reconstruction where the <italic>m</italic> most important reactants are found. MIDER is programmed to detect up to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e112" xlink:type="simple"/></inline-formula> connections, which entailes estimating joint entropies of up to 4-tuples of variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e113" xlink:type="simple"/></inline-formula> for different time lags. Since this is the most computationally expensive part of the method, it may be useful to limit the calculations to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e114" xlink:type="simple"/></inline-formula> (default setting).</p>
</sec><sec id="s2e">
<title>Strength and causality of interactions</title>
<p>There are several ways of estimating the strength of an interaction between two variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e115" xlink:type="simple"/></inline-formula> and Y. To begin with, the distance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e116" xlink:type="simple"/></inline-formula> defined in <xref ref-type="disp-formula" rid="pone.0096732.e092">Equation (14</xref>) may serve as a first indication: the smaller the distance, the stronger the interaction. To consider connections involving more than two variables, it is useful to resort to the two-dimensional map provided by MDS. For example, if three variables appear very close to each other in the map as opposed to the remaining variables in the system, this may indicate that they participate in the same reaction (for the case of chemical species). This criterion, albeit reasonable, does not take into account the possibility of indirect interactions. Hence, if three variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e117" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e118" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e119" xlink:type="simple"/></inline-formula> are very close, this criterion would predict links between the three variable pairs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e120" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e121" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e122" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e123" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e124" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e125" xlink:type="simple"/></inline-formula>. However, it may be the case that only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e126" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e127" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e128" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e129" xlink:type="simple"/></inline-formula> are connected, and that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e130" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e131" xlink:type="simple"/></inline-formula> are only linked indirectly through <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e132" xlink:type="simple"/></inline-formula>. This is the motivation behind the entropy reduction step presented in the previous subsection. To help in visualizing this, MIDER gives further indications of the interaction strength by drawing links of different width between variables. The width is proportional to the entropy reduction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e133" xlink:type="simple"/></inline-formula>. As has been already mentioned, the entropy reduction step requires large amounts of data, which can limit its accuracy in some cases. Therefore it is wise to treat its output as a complement of the distance map and not as the only criterion.</p>
<p>Links between variables are plotted as arrows, which represent directional (causal) relationships. Inferring causality is a subtle matter, with deep theoretical implications, and currently an open problem in biological applications <xref ref-type="bibr" rid="pone.0096732-Maathuis1">[51]</xref>-<xref ref-type="bibr" rid="pone.0096732-Snijder1">[55]</xref>. Mutual information is undirected, and most information theoretic methods do not assign causality to the inferred interactions. An exception is TD-ARACNE <xref ref-type="bibr" rid="pone.0096732-Zoppoli1">[35]</xref>, which exploits time series data to establish causality of interactions from the order in concentration changes. This idea was already present in the CMC method <xref ref-type="bibr" rid="pone.0096732-Arkin1">[29]</xref>, <xref ref-type="bibr" rid="pone.0096732-Arkin2">[30]</xref>, which ordered the species according to the temporal ordering of their correlation maxima. It is also possible to retrieve this information from MIDER, which, as has been already mentioned, generates plots of the mutual information (instead of correlation) between variables for different time lags. The time lags that yield the maximum mutual information between variables are reported and stored in the Output structure, in the field “Output.taumin”. MIDER assigns causality to the inferred links by calculating the transfer entropy between variables. The transfer entropy, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e134" xlink:type="simple"/></inline-formula>, is a non-symmetric measure of causality introduced by Schreiber <xref ref-type="bibr" rid="pone.0096732-Schreiber1">[56]</xref>, which quantifies the reduction in the uncertainty in future values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e135" xlink:type="simple"/></inline-formula> obtained by knowing the past values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e136" xlink:type="simple"/></inline-formula>, given past values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e137" xlink:type="simple"/></inline-formula>. Similarly to the aforementioned entropy reduction used by MIDER, the transfer entropy is also based on time-lagged conditional entropies, and it may be expressed as a function of them as follows <xref ref-type="bibr" rid="pone.0096732-Amblard1">[57]</xref>:<disp-formula id="pone.0096732.e138"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e138" xlink:type="simple"/><label>(17)</label></disp-formula></p>
<p>For every pair of variables (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e139" xlink:type="simple"/></inline-formula>) for which a link is predicted, MIDER calculates the two transfer entropies (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e140" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e141" xlink:type="simple"/></inline-formula>), and assigns causality in the direction corresponding to the maximum of the two.</p>
</sec></sec><sec id="s3">
<title>Results and Discussion</title>
<p>The performance of MIDER has been evaluated with the seven benchmark problems listed in <xref ref-type="table" rid="pone-0096732-t001">Table 1</xref>. They include examples of the three main types of cellular networks: metabolic, protein signaling, and gene regulatory networks. For two of them experimental data was available; in the remaining cases pseudo-experimental data was generated and used as the input of the reverse-engineering procedure. The results were compared to those obtained with four state of the art methods based on mutual information. We chose methods capable of detecting indirect interactions, and for which an implementation was publicly available. Based on these criteria, we selected CLR <xref ref-type="bibr" rid="pone.0096732-Faith1">[20]</xref>, ARACNE <xref ref-type="bibr" rid="pone.0096732-Margolin1">[32]</xref>, <xref ref-type="bibr" rid="pone.0096732-Margolin2">[33]</xref> – which are arguably the two most widely used information theoretic methods –, and MRNET <xref ref-type="bibr" rid="pone.0096732-Meyer1">[37]</xref>, all of which are implemented in the R package MINET <xref ref-type="bibr" rid="pone.0096732-Meyer2">[38]</xref>. We also tested the time-delay version of ARACNE, TD-ARACNE <xref ref-type="bibr" rid="pone.0096732-Zoppoli1">[35]</xref>. In those cases in which other comparisons were of interest, we also discussed other methods, namely CMC <xref ref-type="bibr" rid="pone.0096732-Arkin1">[29]</xref>, <xref ref-type="bibr" rid="pone.0096732-Arkin2">[30]</xref> and MI3 <xref ref-type="bibr" rid="pone.0096732-Luo1">[39]</xref>.</p>
<table-wrap id="pone-0096732-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.t001</object-id><label>Table 1</label><caption>
<title>Benchmarks.</title>
</caption><alternatives><graphic id="pone-0096732-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Number</td>
<td align="left" rowspan="1" colspan="1">Description</td>
<td align="left" rowspan="1" colspan="1">Publication</td>
<td align="left" rowspan="1" colspan="1">Type</td>
<td align="left" rowspan="1" colspan="1">Data</td>
<td align="left" rowspan="1" colspan="1">Data points</td>
<td align="left" rowspan="1" colspan="1">Variables</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">B1</td>
<td align="left" rowspan="1" colspan="1">Glycolytic pathway</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Arkin2">[30]</xref></td>
<td align="left" rowspan="1" colspan="1">Metabolic</td>
<td align="left" rowspan="1" colspan="1">Real</td>
<td align="left" rowspan="1" colspan="1">57</td>
<td align="left" rowspan="1" colspan="1">10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B2</td>
<td align="left" rowspan="1" colspan="1">8 species mechanism</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref></td>
<td align="left" rowspan="1" colspan="1">Metabolic</td>
<td align="left" rowspan="1" colspan="1">Simulated</td>
<td align="left" rowspan="1" colspan="1">250</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B3</td>
<td align="left" rowspan="1" colspan="1">4 species mechanism</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref></td>
<td align="left" rowspan="1" colspan="1">Metabolic</td>
<td align="left" rowspan="1" colspan="1">Simulated</td>
<td align="left" rowspan="1" colspan="1">100</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B4</td>
<td align="left" rowspan="1" colspan="1">IRMA benchmark</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Cantone1">[59]</xref></td>
<td align="left" rowspan="1" colspan="1">Genetic regulatory</td>
<td align="left" rowspan="1" colspan="1">Real</td>
<td align="left" rowspan="1" colspan="1">125</td>
<td align="left" rowspan="1" colspan="1">5</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B5</td>
<td align="left" rowspan="1" colspan="1">MAPK cascade</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Huang1">[60]</xref></td>
<td align="left" rowspan="1" colspan="1">Protein signaling</td>
<td align="left" rowspan="1" colspan="1">Simulated</td>
<td align="left" rowspan="1" colspan="1">210</td>
<td align="left" rowspan="1" colspan="1">12</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B6</td>
<td align="left" rowspan="1" colspan="1">DREAM4 10 genes–1</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Marbach3">[61]</xref></td>
<td align="left" rowspan="1" colspan="1">Genetic regulatory</td>
<td align="left" rowspan="1" colspan="1">Simulated</td>
<td align="left" rowspan="1" colspan="1">105</td>
<td align="left" rowspan="1" colspan="1">10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">B7</td>
<td align="left" rowspan="1" colspan="1">DREAM4 100 genes–1</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0096732-Marbach3">[61]</xref></td>
<td align="left" rowspan="1" colspan="1">Genetic regulatory</td>
<td align="left" rowspan="1" colspan="1">Simulated</td>
<td align="left" rowspan="1" colspan="1">210</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>List of the benchmark problems used in the comparisons.</p></fn></table-wrap-foot></table-wrap>
<p>To carry out objective comparisons between inference methods it is necessary to have quantitative measures of their performance. Two common measures are precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e142" xlink:type="simple"/></inline-formula>) and recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e143" xlink:type="simple"/></inline-formula>), which are defined as follows. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e144" xlink:type="simple"/></inline-formula> denote a true positive prediction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e145" xlink:type="simple"/></inline-formula> a false positive, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e146" xlink:type="simple"/></inline-formula> a true negative, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e147" xlink:type="simple"/></inline-formula> a false negative. Then precision and recall are<disp-formula id="pone.0096732.e148"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e148" xlink:type="simple"/><label>(18)</label></disp-formula></p>
<p>Other common measures are the true positive rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e149" xlink:type="simple"/></inline-formula>) and the false positive rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e150" xlink:type="simple"/></inline-formula>),<disp-formula id="pone.0096732.e151"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e151" xlink:type="simple"/><label>(19)</label></disp-formula></p>
<p>Most inference methods have some tunable parameter that represents the minimum strength that an interaction must have in order to be considered real, and not an artifact of the data. By changing this threshold and recording the different outcomes of a method, one can plot either Precision-Recall curves (PR), which show how <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e152" xlink:type="simple"/></inline-formula> changes as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e153" xlink:type="simple"/></inline-formula>, or Receiver Operator Characteristic curves (ROC), which plot <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e154" xlink:type="simple"/></inline-formula> as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e155" xlink:type="simple"/></inline-formula>. The area under precision-recall curves (AUPR) and area under ROC (AUROC) condense the information captured by the curves in a single scalar measure. It has been argued <xref ref-type="bibr" rid="pone.0096732-Davis1">[58]</xref> that PR curves are more informative than ROC curves, which can give an excessively optimistic picture of an algorithm's performance. The reason is that a method with a seemingly good ROC curve can have a very large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e156" xlink:type="simple"/></inline-formula> ratio, and therefore low precision. Hence in this paper we use precision, recall, and AUPR as performance measures.</p>
<p>Precision-Recall curves provide quantitative measures of a method's performance for a variety of settings. However, they do not give information about which performance is to be expected with the method's <italic>default</italic> settings, the ones that will be typically used in absence of further knowledge about the problem. Since not all methods apply the threshold in the same way, it may happen that a method with an apparently good PR curve gives a poor result (e.g. very good recall, but with low precision, or vice versa) when used with “out-of-the-box” settings. To take this into account, with the aim of avoiding unfair comparisons, we reported not only the PR curves and the AUPR value but also the (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e157" xlink:type="simple"/></inline-formula>) values obtained with default, out-of-the-box settings.</p>
<p>While MIDER and TD-ARACNE infer interaction direction, ARACNE, MRNET, and CLR do not. To enable direct comparison of these methods, we do not take direction into account when classifying a link as true or false.</p>
<p>Previous evaluations of network inference methods, such as the ones carried out in the DREAM initiative, have stressed the importance of the “wisdom of crowds” <xref ref-type="bibr" rid="pone.0096732-Marbach1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096732-Marbach2">[16]</xref>. While no single method was found to be optimal for every problem, the integration of the outcomes of all methods in a “community prediction” provided a consistent performance across all datasets. This observation prompted us to investigate whether this would also be the case for the set of problems and methods compared here. With this aim we created a community prediction for every benchmark by averaging the connection strengths yielded by each method and applying a threshold (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e158" xlink:type="simple"/></inline-formula>) to the result.</p>
<p><xref ref-type="fig" rid="pone-0096732-g003">Figure 3</xref> shows Precision-Recall curves of the five algorithms (and the community prediction) for the seven benchmark problems, including default (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e159" xlink:type="simple"/></inline-formula>) values. The same information is provided using two-dimensional color maps in <xref ref-type="fig" rid="pone-0096732-g004">Figure 4</xref>. In accordance with previous comparisons reported in the literature, no algorithm was the best performer for all problems. MIDER was the best performer –best precision and recall– for benchmarks B3 and B4, and provided the result with highest precision for B1, B2, and B5. For the genetic networks of B6 and B7 it did not provide the best precision nor the best recall, but ranked in intermediate positions among other methods. On average, we found the performance of MIDER to be at least comparable to that of the other methods.</p>
<fig id="pone-0096732-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g003</object-id><label>Figure 3</label><caption>
<title>Precision-Recall curves.</title>
<p>PR curves (recall in horizontal axis, precision in vertical axis) of all the benchmarks (B1–B7) for five network inference methods (ARACNE, CLR, MRNET, TDARACNE, and MIDER) and for the community prediction. Solid lines and small dots correspond to the (P,R) values obtained by changing the threshold for detecting interactions. Large square points correspond to the (P,R) values obtained with the default (out of the box) settings of each method.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g003" position="float" xlink:type="simple"/></fig><fig id="pone-0096732-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g004</object-id><label>Figure 4</label><caption>
<title>P, R, and AUPR.</title>
<p>The color maps show precision (left panel) and recall (central panel) achieved by each method and for each benchmark with its default settings, as well as the area under precision-recall curve (AUPR, right panel). Numerical values are in the range [0–1], and are represented in colors according to the scale in the right (green  =  good, blue  =  bad).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g004" position="float" xlink:type="simple"/></fig>
<p>It should be noted that the community prediction turned out to be comparable to the best result obtained by any method in six of the seven benchmarks. In other words, the community prediction is in the Pareto front of non-dominated solutions for those cases: no method has simultaneously better precision and better recall than the community. Thus, the community prediction is the optimal trade-off between precision and recall for a given weight of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e160" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e161" xlink:type="simple"/></inline-formula> (although not for every possible weight). The only exception is benchmark B3, for which, exceptionally, two methods (MIDER and ARACNE) provided perfect reconstructions, so the addition of less accurate results made the community a worse solution than the one provided by those methods.</p>
<p>These results show, on the one hand, that MIDER is a good option for network inference in a variety of settings, and on the other hand, that it is advantageous to take into account the outcomes of several algorithms. The following subsections describe the benchmark problems and analyze the results in more detail.</p>
<sec id="s3a">
<title>Benchmark B1: glycolytic pathway</title>
<p>As a first example we considered the first steps of the glycolytic pathway, which are depicted in the upper left panel of <xref ref-type="fig" rid="pone-0096732-g005">Figure 5</xref>. The problem of reverse-engineering this system – a chemical reaction network of realistic size – was chosen in <xref ref-type="bibr" rid="pone.0096732-Arkin2">[30]</xref> as a way of demonstrating the feasibility of the CMC method. With that aim, an experiment was carried out in a continuous-flow, stirred-tank reactor (CSTR). Experimental time-series data was obtained for the concentrations of ten species: Pi, G6P, F6P, F16BP, F26BP, and DHAP, as well as the input and reactor concentrations of citrate and AMP. The sampling period was 13 minutes, and the overall number of sampling instants was 57. The data is publicly available at <ext-link ext-link-type="uri" xlink:href="http://genomics.lbl.gov/?page_id=44" xlink:type="simple">http://genomics.lbl.gov/?page_id=44</ext-link> as part of the Deduce software package. We remark that, although the MIDER method is theoretically capable of detecting more complicated relationships between variables than CMC, it also requires more data points to carry out this task reliably. Thus, it is useful to demonstrate that it produced similar results to CMC (shown in <xref ref-type="fig" rid="pone-0096732-g005">Figure 5</xref>) in cases such as this one, when the available data was limited (in the next example we show a situation where the MIDER method improved the CMC prediction for a system for which more data was available). Among the benchmarked methods, MIDER (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e162" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e163" xlink:type="simple"/></inline-formula>) yielded the highest precision with out-of-the-box settings, outperforming ARACNE, TD-ARACNE (both of which achieved <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e164" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e165" xlink:type="simple"/></inline-formula>), and CLR (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e166" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e167" xlink:type="simple"/></inline-formula>). MRNET (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e168" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e169" xlink:type="simple"/></inline-formula>) yielded the highest recall, although with low precision.</p>
<fig id="pone-0096732-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g005</object-id><label>Figure 5</label><caption>
<title>Benchmark B1.</title>
<p>First reaction steps of glycolysis.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g005" position="float" xlink:type="simple"/></fig></sec><sec id="s3b">
<title>Benchmark B2: enzyme-catalyzed reaction pathway</title>
<p>As a second example we chose a simulated metabolic pathway, the chemical reaction network represented by<disp-formula id="pone.0096732.e170"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e170" xlink:type="simple"/><label>(20)</label></disp-formula>where species A and B are kept at constant concentrations, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e171" xlink:type="simple"/></inline-formula>. The step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e172" xlink:type="simple"/></inline-formula> is enzyme catalyzed with a rate coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e173" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e174" xlink:type="simple"/></inline-formula> is the input species; its concentration is varied randomly. The remaining steps are first order reactions, with forward rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e175" xlink:type="simple"/></inline-formula> and backward rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e176" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e177" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e178" xlink:type="simple"/></inline-formula> otherwise. This example was introduced in <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref> to illustrate the difficulties that arise from the self-inhibition of the enzyme catalysis by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e179" xlink:type="simple"/></inline-formula>. The quadratic dependence of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e180" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e181" xlink:type="simple"/></inline-formula> creates a strong nonlinearity that complicates the reverse engineering of this model with a correlation-based method such as CMC, which was designed to quantify linear interdependence. However, CMC still recovered correctly the mechanism (see <xref ref-type="fig" rid="pone-0096732-g006">Figure 6</xref>), although it predicted a very weak link between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e182" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e183" xlink:type="simple"/></inline-formula>, and showed a wrap around in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e184" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e185" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e186" xlink:type="simple"/></inline-formula> part of the chain. The automatic reconstruction yielded by MIDER, in contrast, did not present those issues, although it did not predict the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e187" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e188" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e189" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e190" xlink:type="simple"/></inline-formula> links directly, since their interaction strength was slightly lower than the default threshold. However, these links can be clearly inferred by visual inspection from the 2D entropic distance map. Without adding these links, MIDER yielded a perfect precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e191" xlink:type="simple"/></inline-formula>) and a recall of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e192" xlink:type="simple"/></inline-formula>. ARACNE yielded higher recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e193" xlink:type="simple"/></inline-formula>) but lower precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e194" xlink:type="simple"/></inline-formula>), due to the false prediction of a link between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e195" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e196" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e197" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e198" xlink:type="simple"/></inline-formula>. TD-ARACNE, CLR, and MRNET yielded several false positives, leading to a good recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e199" xlink:type="simple"/></inline-formula>) but also to low precisions (in the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e200" xlink:type="simple"/></inline-formula>). It should be noted that this benchmark uses artificial data. We generated data corresponding to 250 time points, instead of the 2000 used in <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref>, a restriction that makes this problem more realistic and more complicated than the one originally published.</p>
<fig id="pone-0096732-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g006</object-id><label>Figure 6</label><caption>
<title>Benchmark B2.</title>
<p>Reaction chain with 8 species.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g006" position="float" xlink:type="simple"/></fig></sec><sec id="s3c">
<title>Benchmark B3: small reaction pathway</title>
<p>Next we considered the following small linear chain of reactions,<disp-formula id="pone.0096732.e201"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096732.e201" xlink:type="simple"/><label>(21)</label></disp-formula>where reaction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e202" xlink:type="simple"/></inline-formula> is much weaker than the rest: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e203" xlink:type="simple"/></inline-formula>, while <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e204" xlink:type="simple"/></inline-formula>. The use of this system was proposed in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref> as a target application for the Entropy Reduction Technique (ERT). The difficulty posed by this system is caused by the different values in the kinetic constants. Due to them, both correlational and entropic distances between variables are small for the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e205" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e206" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e207" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e208" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e209" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e210" xlink:type="simple"/></inline-formula> pairs, while the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e211" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e212" xlink:type="simple"/></inline-formula> distance is large. The resulting configuration of points obtained with MIDER is shown in <xref ref-type="fig" rid="pone-0096732-g007">Figure 7</xref>. Note that, if the method took into account only the distances between points, it would predict links between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e213" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e214" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e215" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e216" xlink:type="simple"/></inline-formula>, and (incorrectly) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e217" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e218" xlink:type="simple"/></inline-formula>; since the distance between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e219" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e220" xlink:type="simple"/></inline-formula> is large, only a weak link between them – or no link at all – would be predicted. The ERT method was proposed in <xref ref-type="bibr" rid="pone.0096732-Samoilov1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096732-Samoilov2">[28]</xref> to improve the predictions in this situation: it was hypothesized that by calculating conditional entropies ERT would establish that, though <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e221" xlink:type="simple"/></inline-formula> is strongly dependent on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e222" xlink:type="simple"/></inline-formula>, all of the dependence (or, due to lack of precision, most of it) is due to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e223" xlink:type="simple"/></inline-formula>. Despite being proposed, however, ERT was never tested. The implementation of an entropy reduction procedure included in MIDER confirmed the aforementioned hypothesis: not only did it predict a link between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e224" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e225" xlink:type="simple"/></inline-formula> and another one between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e226" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e227" xlink:type="simple"/></inline-formula>, it also estimated that the link between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e228" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e229" xlink:type="simple"/></inline-formula> was stronger than the one between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e230" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e231" xlink:type="simple"/></inline-formula>. If the variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e232" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e233" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e234" xlink:type="simple"/></inline-formula> are chemical species, as in this case, this may be taken as an indication that the kinetics between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e235" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e236" xlink:type="simple"/></inline-formula> are faster than between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e237" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e238" xlink:type="simple"/></inline-formula>. For this benchmark both ARACNE and MIDER achieved perfect precision and recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e239" xlink:type="simple"/></inline-formula>). It must be noted that the data was generated by changing the concentration of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e240" xlink:type="simple"/></inline-formula> randomly; thus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e241" xlink:type="simple"/></inline-formula> acted as an input species whose variation was propagated to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e242" xlink:type="simple"/></inline-formula>, then to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e243" xlink:type="simple"/></inline-formula>, and finally to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e244" xlink:type="simple"/></inline-formula>. Therefore, although the reactions are reversible (and hence the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e245" xlink:type="simple"/></inline-formula> symbol in <xref ref-type="disp-formula" rid="pone.0096732.e201">Equation 21</xref>) there is a directionality in the interactions that should be ideally inferred by the methods. MIDER predicted correctly the direction of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e246" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e247" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e248" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e249" xlink:type="simple"/></inline-formula> links, and incorrectly predicted a bidirectional interaction between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e250" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e251" xlink:type="simple"/></inline-formula>. ARACNE, however, does not infer directionality of the interactions. CLR, TD-ARACNE, and MRNET provided incorrect reconstructions. Some network inference methods make other assumptions about the connectivity of the network, often based on considerations about the architectures that are common in gene regulatory networks. This choice may limit their generality. For example, the MI3 method mentioned in the Introduction uses a metric (<xref ref-type="disp-formula" rid="pone.0096732.e044">Equation (6</xref>)) designed for detecting cooperative activity between regulators. It assumes that every species (target) is linked with two regulators, which causes false positives in cases such as this.</p>
<fig id="pone-0096732-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g007</object-id><label>Figure 7</label><caption>
<title>Benchmark B3.</title>
<p>Reaction chain with 4 species.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g007" position="float" xlink:type="simple"/></fig></sec><sec id="s3d">
<title>Benchmark B4: IRMA</title>
<p>IRMA (In vivo Reverse-engineering and Modeling Assessment) <xref ref-type="bibr" rid="pone.0096732-Cantone1">[59]</xref> is a yeast synthetic network for benchmarking reverse-engineering approaches. It consists of five genes that regulate each other through several interactions. It is particularly interesting as a benchmark because it is an engineered system, which means that the true network is known, and at the same time the system outputs can be measured in vivo, instead of just simulated in silico. A dataset consisting of time series and steady-state expression data after multiple perturbations is available; for the network inference purposes the time-series data was used. <xref ref-type="fig" rid="pone-0096732-g008">Figure 8</xref> shows the results of the different methods. The outcome of TD-ARACNE had already been reported in the original publication <xref ref-type="bibr" rid="pone.0096732-Zoppoli1">[35]</xref>, since IRMA was one of the benchmark problems selected to demonstrate the performance of that method; we repeated the calculations and obtained the same result (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e252" xlink:type="simple"/></inline-formula>). MIDER achieved the same recall as TD-ARACNE with slightly higher precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e253" xlink:type="simple"/></inline-formula>). According to the precision-recall metrics the worst result was the one obtained by CLR (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e254" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e255" xlink:type="simple"/></inline-formula>); ARACNE and MRNET outperformed CLR but fared worse than MIDER and TD-ARACNE.</p>
<fig id="pone-0096732-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g008</object-id><label>Figure 8</label><caption>
<title>Benchmark B4.</title>
<p>IRMA.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g008" position="float" xlink:type="simple"/></fig>
<p>It must be noted that the five methods predict a link between SWI5 and GAL4, which does not exist in reality (SWI5 is linked to GAL4 only indirectly, through GAL80). GAL4 and GAL80 form a complex, and it was already acknowledged in the original publication <xref ref-type="bibr" rid="pone.0096732-Cantone1">[59]</xref> that these two proteins may indeed be considered as a single component for reverse engineering purposes: since no protein data is available, network inference is carried out with mRNA concentration data, and it is unlikely that the real protein–protein interactions are correctly recovered.</p>
</sec><sec id="s3e">
<title>Benchmark B5: MAPK cascade</title>
<p>The classic Mitogen-Activated Protein Kinase model presented by Huang &amp; Ferrell <xref ref-type="bibr" rid="pone.0096732-Huang1">[60]</xref> is a highly conserved series of three protein kinases implicated in diverse biological processes. It exhibits a highly nonlinear (“ultrasensitive”) behavior <xref ref-type="bibr" rid="pone.0096732-Huang1">[60]</xref>, converting graded inputs into switch-like outputs. The cascade as a whole behaves like a highly cooperative enzyme, even though none of the enzymes in the cascade are regulated cooperatively. This benchmark was more difficult to recover than the previous ones, due to a larger number of network nodes and more complex interactions. The reconstructions, shown in <xref ref-type="fig" rid="pone-0096732-g009">Figure 9</xref>, differ largely from one method to another, with clear trade-offs between precision and recall: MIDER yielded the highest precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e256" xlink:type="simple"/></inline-formula>) but with the lowest recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e257" xlink:type="simple"/></inline-formula>); MRNET, on the other hand, yielded a high recall (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e258" xlink:type="simple"/></inline-formula>) with low precision (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e259" xlink:type="simple"/></inline-formula>), and so did CLR (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e260" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e261" xlink:type="simple"/></inline-formula>). The P-R metrics of the results provided by ARACNE and TDARACNE were intermediate between those of MIDER and MRNET. Although none of the benchmarked methods generated a really good approximation of the complex network, all of them succeeded in predicting the linking between the MAPKKK activator, MAPKKK, and P-MAPKKK (and, with the exception of TD-ARACNE, also with the MAPKKK inactivator); that is, the most upstream part of the network. Reconstructions of the rest of the network, however, are much less accurate. Interestingly, the three levels of the cascade can be distinguished in the spatial configuration yielded by MIDER, which consisted of three distinct groups of species (although it confused P-MAPK and PP-MAPKK).</p>
<fig id="pone-0096732-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096732.g009</object-id><label>Figure 9</label><caption>
<title>Benchmark B5.</title>
<p>MAPK cascade.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096732.g009" position="float" xlink:type="simple"/></fig></sec><sec id="s3f">
<title>Benchmarks B6 and B7: DREAM4 in silico gene networks</title>
<p>Finally, we tested the methods using benchmark problems generated for the DREAM4 in silico network challenge (<ext-link ext-link-type="uri" xlink:href="http://wiki.c2b2.columbia.edu/dream/index.php/D4c2" xlink:type="simple">http://wiki.c2b2.columbia.edu/dream/index.php/D4c2</ext-link>). This network inference challenge consisted of different subchallenges, which aimed at reverse engineering genetic networks of sizes 10 and 100. The artificial networks were generated as reported in <xref ref-type="bibr" rid="pone.0096732-Marbach3">[61]</xref>, <xref ref-type="bibr" rid="pone.0096732-Schaffter1">[62]</xref>. We picked one network of each size: network 1 from the DREAM4_InSilico_Size10 dataset, and network 1 from the DREAM4_InSilico_Size100 dataset. Since these are artificial networks their representations have no biological meaning, and hence are not pictured here.</p>
<p>The performance of all the five methods compared in this section was relatively modest for the network of size 10. Precision values ranged from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e262" xlink:type="simple"/></inline-formula> (MRNET) to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e263" xlink:type="simple"/></inline-formula> (TD-ARACNE), and recall from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e264" xlink:type="simple"/></inline-formula> (ARACNE) to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e265" xlink:type="simple"/></inline-formula> (MRNET). The reconstruction obtained with MIDER yielded intermediate values (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e266" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e267" xlink:type="simple"/></inline-formula>).</p>
<p>For the network of size 100 all methods obtained poor results. We found a clear distinction between methods that focused on precision (ARACNE, TD-ARACNE, MIDER) and methods that focused on recall (CLR,MRNET). <xref ref-type="sec" rid="s2">Methods</xref> from the first group achieved precisions in the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e268" xlink:type="simple"/></inline-formula> and recalls in the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e269" xlink:type="simple"/></inline-formula>, while methods in the second group yielded even lower precision values (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e270" xlink:type="simple"/></inline-formula>), but with recalls in the range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096732.e271" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4">
<title>Conclusions</title>
<p>The present work has introduced a methodology for network inference called MIDER. It is based on information theoretic concepts, and combines the use of mutual information-based distances and entropy reduction. It outputs a visual representation of the inferred system, as well as estimates of the strength and directionality of the interactions, and time-lagged plots of the mutual information between variables. Among other options, it offers the possibility of choosing from different normalizations of the mutual information, and even a nonextensive version.</p>
<p>One of the strengths of MIDER is its generality: it makes no assumptions about the characteristics of the network, which makes it suitable for inferring connections in systems where little is known. Indeed, the only necessary input is the experimental data. Another advantage of the method is that, although it has some tunable parameters that can be modified if desired, it requires no expertise from the user. Due to the adaptive nature of its subroutines, its default settings provide good results for a variety of problems. It has been tested on seven different benchmarks including metabolic, gene regulatory, and protein signaling networks, and has performed well when compared to other state of the art techniques.</p>
<p>Regarding its theoretical foundations, a strength of MIDER is its ability to detect multiple interactions and avoiding false positives. It ranked first in precision among the tested methods in five of the seven benchmark problems considered, and achieved precision scores close to the best performer in the other two. Since in every reverse engineering method there is a trade-off between precision and recall, this emphasis in precision entails that MIDER can yield low recall for large-scale problems. However, for smaller-scale networks (up to ten nodes in our tests) it manages to obtain simultaneously high precision and high recall.</p>
<p>The main hurdle to surmount in order to accurately discard false positives is the need of large amounts of data, which are required if it is desired to carry out more than three entropy reduction rounds. This limitation is due to the difficulty in estimating reliably joint entropies of high dimensions (i.e., of four or more species), and is hence shared by all information-theoretic methods. For networks with a large number of components, performing more than three entropy reduction rounds may also involve high computational costs, particularly if many possible time lags are taken into account. To alleviate this burden, MIDER estimates the mutual information using an algorithm that is much faster than the one used by some of the precedent methods. Furthermore, since the related calculations are carried out in arrays and are amenable for parallelization, this limitation can be easily overcome. As a future development we plan to implement a parallel version of MIDER.</p>
<p>We hope that MIDER will be a valuable addition to the existing methodologies for network inference, either by itself or in combination with other algorithms to create a community prediction. To facilitate its use, we provide the source code along with the datasets required to reproduce the results reported in this paper. We envision that it will be particularly useful for the community of Matlab users; to the best of the authors' knowledge, this is the first time that a Matlab implementation of a comparable method is made available.</p>
</sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0096732.s001" xlink:href="info:doi/10.1371/journal.pone.0096732.s001" mimetype="application/x-rar-compressed" position="float" xlink:type="simple"><label>File S1</label><caption>
<p><bold>MIDER toolbox.</bold> This compressed file contains the MIDER toolbox, which is implemented in Matlab. It includes all the datasets used in this article, the source code of the MIDER functions, and a user manual.</p>
<p>(RAR)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors thank Alfonso Albano for kindly providing an implementation of the algorithm in <xref ref-type="bibr" rid="pone.0096732-Cellucci1">[47]</xref> and for suggesting the use of transfer entropy, Michael Samoilov for helpful comments on the EMC and ERT methods, Erik A Johnson for permission to redistribute his arrow function with the MIDER software, and an anonymous reviewer for his/her helpful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0096732-Villaverde1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Villaverde</surname><given-names>AF</given-names></name>, <name name-style="western"><surname>Banga</surname><given-names>JR</given-names></name> (<year>2014</year>) <article-title>Reverse engineering and identification in systems biology: strategies, perspectives and challenges</article-title>. <source>J R Soc Interface</source> <volume>11</volume>: <fpage>20130505</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Markowetz1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markowetz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Spang</surname><given-names>R</given-names></name> (<year>2007</year>) <article-title>Inferring cellular networks–a review</article-title>. <source>BMC Bioinform</source> <volume>8</volume>: <fpage>S5</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Bansal1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bansal</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Belcastro</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Ambesi-Impiombato</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Di Bernardo</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>How to infer gene networks from expression profiles</article-title>. <source>Mol Syst Biol</source> <volume>3</volume>: <fpage>78</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Hecker1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hecker</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lambeck</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Toepfer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>van Someren</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Guthke</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>Gene regulatory network inference: Data integration in dynamic models - a review</article-title>. <source>Biosystems</source> <volume>96</volume>: <fpage>86</fpage>–<lpage>103</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-DeSmet1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Smet</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Marchal</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>Advantages and limitations of current network inference methods</article-title>. <source>Nat Rev Microbiol</source> <volume>8</volume>: <fpage>717</fpage>–<lpage>729</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Altay1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Altay</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Emmert-Streib</surname><given-names>F</given-names></name> (<year>2010</year>) <article-title>Revealing differences in gene network inference algorithms on the network level by ensemble methods</article-title>. <source>Bioinformatics</source> <volume>26</volume>: <fpage>1738</fpage>–<lpage>1744</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Hurley1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hurley</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Araki</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Tamada</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dunmore</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Sanders</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Gene network inference and visualization tools for biologists: application to new human transcriptome datasets</article-title>. <source>Nucleic Acids Res</source> <volume>40</volume>: <fpage>2377</fpage>–<lpage>2398</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Schulz1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schulz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Devanny</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Gitter</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Zhong</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ernst</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Drem 2.0: Improved reconstruction of dynamic regulatory networks from time-series expression data</article-title>. <source>BMC Syst Biol</source> <volume>6</volume>: <fpage>104</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-LpezKleine1"><label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">López-Kleine L, Leal L, López C (2013) Biostatistical approaches for the reconstruction of gene co-expression networks based on transcriptomic data. Brief Funct Genomics.</mixed-citation>
</ref>
<ref id="pone.0096732-Maetschke1"><label>10</label>
<mixed-citation publication-type="other" xlink:type="simple">Maetschke SR, Madhamshettiwar PB, Davis MJ, Ragan MA (2013) Supervised, semi-supervised and unsupervised inference of gene regulatory networks. Brief Bioinform First published online: May 21, 2013.</mixed-citation>
</ref>
<ref id="pone.0096732-Wang1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Arkin</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Samoilov</surname><given-names>MS</given-names></name> (<year>2013</year>) <article-title>Inference of gene regulatory networks from genome-wide knockout fitness data</article-title>. <source>Bioinformatics</source> <volume>29</volume>: <fpage>338</fpage>–<lpage>346</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Crampin1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crampin</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Schnell</surname><given-names>S</given-names></name>, <name name-style="western"><surname>McSharry</surname><given-names>P</given-names></name> (<year>2004</year>) <article-title>Mathematical and computational techniques to deduce complex biochemical reaction mechanisms</article-title>. <source>Prog Biophys Mol Biol</source> <volume>86</volume>: <fpage>77</fpage>–<lpage>112</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Ross1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>J</given-names></name> (<year>2008</year>) <article-title>Determination of complex reaction mechanisms. analysis of chemical, biological and genetic networks</article-title>. <source>J Phys Chem A</source> <volume>112</volume>: <fpage>2134</fpage>–<lpage>2143</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Marbach1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marbach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Prill</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Schaffter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Mattiussi</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Revealing strengths and weaknesses of methods for gene network inference</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>107</volume>: <fpage>6286</fpage>–<lpage>6291</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Prill1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prill</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Saez-Rodriguez</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Alexopoulos</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Sorger</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Stolovitzky</surname><given-names>G</given-names></name> (<year>2011</year>) <article-title>Crowdsourcing network inference: the dream predictive signaling network challenge</article-title>. <source>Sci Signal</source> <volume>4</volume>: <fpage>mr7</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Marbach2"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marbach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Costello</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Küffner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Vega</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Prill</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Wisdom of crowds for robust gene network inference</article-title>. <source>Nat Methods</source> <volume>9</volume>: <fpage>79604</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Lecca1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lecca</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Priami</surname><given-names>C</given-names></name> (<year>2012</year>) <article-title>Biological network inference for drug discovery</article-title>. <source>Drug Discov Today</source> <volume>18</volume>: <fpage>256</fpage>–<lpage>264</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Shannon1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shannon</surname><given-names>C</given-names></name> (<year>1948</year>) <article-title>A mathematical theory of communication</article-title>. <source>Bell Syst Tech J</source> <volume>27</volume>: <fpage>379</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Cover1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Cover T, Thomas J (1991) Elements of information theory. New York, NY, USA: Wiley.</mixed-citation>
</ref>
<ref id="pone.0096732-Faith1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Faith</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hayete</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Thaden</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mogno</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Wierzbowski</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Large-scale mapping and validation of escherichia coli transcriptional regulation from a compendium of expression profiles</article-title>. <source>PLoS Biol</source> <volume>5</volume>: <fpage>e8</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Villaverde2"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Villaverde</surname><given-names>AF</given-names></name>, <name name-style="western"><surname>Ross</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Banga</surname><given-names>JR</given-names></name> (<year>2013</year>) <article-title>Reverse engineering cellular networks with information theoretic methods</article-title>. <source>Cells</source> <volume>2</volume>: <fpage>306</fpage>–<lpage>329</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Farber1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Farber</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Lapedes</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sirotkin</surname><given-names>K</given-names></name> (<year>1992</year>) <article-title>Determination of eukaryotic protein coding regions using neural networks and information theory</article-title>. <source>J Mol Biol</source> <volume>226</volume>: <fpage>471</fpage>–<lpage>479</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Korber1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Korber</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Farber</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wolpert</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Lapedes</surname><given-names>A</given-names></name> (<year>1993</year>) <article-title>Covariation of mutations in the v3 loop of human immunodeficiency virus type 1 envelope protein: an information theoretic analysis</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>90</volume>: <fpage>7176</fpage>–<lpage>7180</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Liang1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Liang S, Fuhrman S, Somogyi R (1998) Reveal, a general reverse engineering algorithm for inference of genetic network architectures. In: Pac. Symp. Biocomput. volume <volume>3</volume> , pp. 18–29.</mixed-citation>
</ref>
<ref id="pone.0096732-Michaels1"><label>25</label>
<mixed-citation publication-type="other" xlink:type="simple">Michaels G, Carr D, Askenazi M, Fuhrman S, Wen X, <etal>et al</etal>.. (1998) Cluster analysis and data visualization of large scale gene expression data. In: Pac. Symp. Biocomp. volume <volume>3</volume> , pp. 42–53.</mixed-citation>
</ref>
<ref id="pone.0096732-Butte1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Butte A, Kohane I (2000) Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements. In: Pac. Symp. Biocomput. volume <volume>5</volume> , pp. 418–429.</mixed-citation>
</ref>
<ref id="pone.0096732-Samoilov1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Samoilov M (1997) Reconstruction and functional analysis of general chemical reactions and reaction networks. Ph.D. thesis, Stanford University.</mixed-citation>
</ref>
<ref id="pone.0096732-Samoilov2"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Samoilov</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Arkin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Ross</surname><given-names>J</given-names></name> (<year>2001</year>) <article-title>On the deduction of chemical reaction pathways from measurements of time series of concentrations</article-title>. <source>Chaos</source> <volume>11</volume>: <fpage>108</fpage>–<lpage>114</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Arkin1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arkin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Ross</surname><given-names>J</given-names></name> (<year>1995</year>) <article-title>Statistical construction of chemical reaction mechanisms from measured time-series</article-title>. <source>J Phys Chem</source> <volume>99</volume>: <fpage>970</fpage>–<lpage>979</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Arkin2"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arkin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shen</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Ross</surname><given-names>J</given-names></name> (<year>1997</year>) <article-title>A test case of correlation metric construction of a reaction pathway from measurements</article-title>. <source>Science</source> <volume>277</volume>: <fpage>1275</fpage>–<lpage>1279</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Lecca2"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lecca</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Morpurgo</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Fantaccini</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Casagrande</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Priami</surname><given-names>C</given-names></name> (<year>2012</year>) <article-title>Inferring biochemical reaction pathways: the case of the gemcitabine pharmacokinetics</article-title>. <source>BMC Syst Biol</source> <volume>6</volume>: <fpage>51</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Margolin1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Margolin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lim</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kustagi</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nemenman</surname><given-names>I</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Reverse engineering cellular networks</article-title>. <source>Nat Protoc</source> <volume>1</volume>: <fpage>662</fpage>–<lpage>671</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Margolin2"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Margolin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Nemenman</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Basso</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Wiggins</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Stolovitzky</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</article-title>. <source>BMC Bioinform</source> <volume>7</volume>: <fpage>S7</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Jang1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jang</surname><given-names>IS</given-names></name>, <name name-style="western"><surname>Margolin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Califano</surname><given-names>A</given-names></name> (<year>2013</year>) <article-title>haracne: improving the accuracy of regulatory model reverse engineering via higher-order data processing inequality tests</article-title>. <source>Interface Focus</source> <volume>3</volume>: <fpage>20130011</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Zoppoli1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zoppoli</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Morganella</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ceccarelli</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Timedelay-aracne: Reverse engineering of gene networks from time-course data by an information theoretic approach</article-title>. <source>BMC Bioinform</source> <volume>11</volume>: <fpage>154</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Peng1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peng</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Long</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Ding</surname><given-names>C</given-names></name> (<year>2005</year>) <article-title>Feature selection based on mutual information: criteria of maxdependency, max-relevance, and min-redundancy</article-title>. <source>IEEE T Pattern Anal Mach Intell</source> <volume>27</volume>: <fpage>1226</fpage>–<lpage>1238</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Meyer1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyer</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Kontos</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lafitte</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bontempi</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Information-theoretic inference of large transcriptional regulatory networks</article-title>. <source>EURASIP J Bioinform Syst Biol</source> <volume>2007</volume>: <fpage>79879</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Meyer2"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyer</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Lafitte</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bontempi</surname><given-names>G</given-names></name> (<year>2008</year>) <article-title>minet: A r/bioconductor package for inferring large transcriptional networks using mutual information</article-title>. <source>BMC Bioinform</source> <volume>9</volume>: <fpage>461</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Luo1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luo</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Hankenson</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Woolf</surname><given-names>P</given-names></name> (<year>2008</year>) <article-title>Learning transcriptional regulatory networks from high throughput gene expression data using continuous three-way mutual information</article-title>. <source>BMC Bioinform</source> <volume>9</volume>: <fpage>467</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Tsallis1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsallis</surname><given-names>C</given-names></name> (<year>1988</year>) <article-title>Possible generalization of boltzmann-gibbs statistics</article-title>. <source>J Stat Phys</source> <volume>52</volume>: <fpage>479</fpage>–<lpage>487</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Tsallis2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsallis</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Gell-Mann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>Y</given-names></name> (<year>2005</year>) <article-title>Asymptotically scale-invariant occupancy of phase space makes the entropy sq extensive</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>102</volume>: <fpage>15377</fpage>–<lpage>15382</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Borland1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borland</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Plastino</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Tsallis</surname><given-names>C</given-names></name> (<year>1998</year>) <article-title>Information gain within nonextensive thermostatistics</article-title>. <source>J Math Phys</source> <volume>39</volume>: <fpage>6490</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Tsallis3"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsallis</surname><given-names>C</given-names></name> (<year>1998</year>) <article-title>Generalized entropy-based criterion for consistent testing</article-title>. <source>Phys Rev E</source> <volume>58</volume>: <fpage>1442</fpage>–<lpage>1445</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Lopes1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lopes</surname><given-names>F</given-names></name>, <name name-style="western"><surname>de Oliveira</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Cesar</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Inference of gene regulatory networks from time series by tsallis entropy</article-title>. <source>BMC Syst Biol</source> <volume>5</volume>: <fpage>61</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Steuer1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steuer</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kurths</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Daub</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Weise</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Selbig</surname><given-names>J</given-names></name> (<year>2002</year>) <article-title>The mutual information: detecting and evaluating dependencies between variables</article-title>. <source>Bioinformatics</source> <volume>18</volume>: <fpage>S231</fpage>–<lpage>S240</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Fraser1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fraser</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Swinney</surname><given-names>H</given-names></name> (<year>1986</year>) <article-title>Independent coordinates for strange attractors from mutual information</article-title>. <source>Phys Rev A</source> <volume>33</volume>: <fpage>1134</fpage>–<lpage>1140</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Cellucci1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cellucci</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Albano</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rapp</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Statistical validation of mutual information calculations: Comparison of alternative numerical algorithms</article-title>. <source>Phys Rev E</source> <volume>71</volume>: <fpage>066208</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Linfoot1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linfoot</surname><given-names>E</given-names></name> (<year>1957</year>) <article-title>An informational measure of correlation</article-title>. <source>Inf Control</source> <volume>1</volume>: <fpage>85</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Studholme1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Studholme</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Hill</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hawkes</surname><given-names>D</given-names></name> (<year>1999</year>) <article-title>An overlap invariant entropy measure of 3d medical image alignment</article-title>. <source>Pattern Recogn</source> <volume>32</volume>: <fpage>71</fpage>–<lpage>86</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Bell1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>H</given-names></name> (<year>2000</year>) <article-title>A formalism for relevance and its application in feature subset selection</article-title>. <source>Mach Learn</source> <volume>41</volume>: <fpage>175</fpage>–<lpage>195</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Maathuis1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maathuis</surname><given-names>MH</given-names></name>, <name name-style="western"><surname>Colombo</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kalisch</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bühlmann</surname><given-names>P</given-names></name> (<year>2010</year>) <article-title>Predicting causal effects in large-scale systems from observational data</article-title>. <source>Nat Methods</source> <volume>7</volume>: <fpage>247</fpage>–<lpage>248</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Alipanahi1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alipanahi</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Frey</surname><given-names>BJ</given-names></name> (<year>2013</year>) <article-title>Network cleanup</article-title>. <source>Nat Biotechnol</source> <volume>31</volume>: <fpage>714</fpage>–<lpage>715</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Barzel1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barzel</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Barabási</surname><given-names>AL</given-names></name> (<year>2013</year>) <article-title>Network link prediction by global silencing of indirect correlations</article-title>. <source>Nat Biotechnol</source> <volume>31</volume>: <fpage>720</fpage>–<lpage>725</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Feizi1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Feizi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Marbach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Médard</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kellis</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Network deconvolution as a general method to distinguish direct dependencies in networks</article-title>. <source>Nat Biotechnol</source> <volume>31</volume>: <fpage>726</fpage>–<lpage>733</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Snijder1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Snijder</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Liberali</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Frechin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Stoeger</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Pelkmans</surname><given-names>L</given-names></name> (<year>2013</year>) <article-title>Predicting functional gene interactions with the hierarchical interaction score</article-title>. <source>Nat Methods</source> <volume>10</volume>: <fpage>1089</fpage>–<lpage>1092</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Schreiber1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schreiber</surname><given-names>T</given-names></name> (<year>2000</year>) <article-title>Measuring information transfer</article-title>. <source>Phys Rev Lett</source> <volume>85</volume>: <fpage>461</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Amblard1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amblard</surname><given-names>PO</given-names></name>, <name name-style="western"><surname>Michel</surname><given-names>OJ</given-names></name> (<year>2012</year>) <article-title>The relation between granger causality and directed information theory: a review</article-title>. <source>Entropy</source> <volume>15</volume>: <fpage>113</fpage>–<lpage>143</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Davis1"><label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Davis J, Goadrich M (2006) The relationship between precision-recall and roc curves.In: Proceedings of the 23rd international conference on machine learning. ACM, pp. 233–240.</mixed-citation>
</ref>
<ref id="pone.0096732-Cantone1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cantone</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Marucci</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Iorio</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Ricci</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Belcastro</surname><given-names>V</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>A yeast synthetic network for in vivo assessment of reverse-engineering and modeling approaches</article-title>. <source>Cell</source> <volume>137</volume>: <fpage>172</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Huang1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huang</surname><given-names>CY</given-names></name>, <name name-style="western"><surname>Ferrell</surname><given-names>JE</given-names></name> (<year>1996</year>) <article-title>Ultrasensitivity in the mitogen-activated protein kinase cascade</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>93</volume>: <fpage>10078</fpage>–<lpage>10083</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Marbach3"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marbach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schaffter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Mattiussi</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>Generating realistic in silico gene networks for performance assessment of reverse engineering methods</article-title>. <source>J Comput Biol</source> <volume>16</volume>: <fpage>229</fpage>–<lpage>239</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096732-Schaffter1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schaffter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Marbach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name> (<year>2011</year>) <article-title>Genenetweaver: in silico benchmark generation and performance profiling of network inference methods</article-title>. <source>Bioinformatics</source> <volume>27</volume>: <fpage>2263</fpage>–<lpage>2270</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>