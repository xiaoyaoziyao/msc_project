<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">10-PONE-RA-21070R2</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0014465</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computer Science/Applications</subject><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Experimental Psychology</subject></subj-group></article-categories><title-group><article-title>Identifying Object Categories from Event-Related EEG: Toward Decoding of Conceptual Representations</article-title><alt-title alt-title-type="running-head">Concepts Decoding from EEG</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Simanova</surname><given-names>Irina</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>van Gerven</surname><given-names>Marcel</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Oostenveld</surname><given-names>Robert</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Hagoort</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Nijmegen, The Netherlands</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Institute for Computing and Information Sciences, Radboud University Nijmegen, Nijmegen, The Netherlands</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>de Beeck</surname><given-names>Hans P. Op.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University of Leuven, Belgium</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">irina.simanova@mpi.nl</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: IS MvG RO PH. Performed the experiments: IS. Analyzed the data: IS. Contributed reagents/materials/analysis tools: IS MvG RO. Wrote the paper: IS MvG.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2010</year></pub-date><pub-date pub-type="epub"><day>30</day><month>12</month><year>2010</year></pub-date><volume>5</volume><issue>12</issue><elocation-id>e14465</elocation-id><history>
<date date-type="received"><day>14</day><month>7</month><year>2010</year></date>
<date date-type="accepted"><day>6</day><month>12</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Simanova et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Multivariate pattern analysis is a technique that allows the decoding of conceptual information such as the semantic category of a perceived object from neuroimaging data. Impressive single-trial classification results have been reported in studies that used fMRI. Here, we investigate the possibility to identify conceptual representations from event-related EEG based on the presentation of an object in different modalities: its spoken name, its visual representation and its written name. We used Bayesian logistic regression with a multivariate Laplace prior for classification. Marked differences in classification performance were observed for the tested modalities. Highest accuracies (89% correctly classified trials) were attained when classifying object drawings. In auditory and orthographical modalities, results were lower though still significant for some subjects. The employed classification method allowed for a precise temporal localization of the features that contributed to the performance of the classifier for three modalities. These findings could help to further understand the mechanisms underlying conceptual representations. The study also provides a first step towards the use of concept decoding in the context of real-time brain-computer interface applications.</p>
</abstract><funding-group><funding-statement>The authors gratefully acknowledge the support of the BrainGain Smart Mix Programme of the Netherlands Ministry of Economic Affairs and the Netherlands Ministry of Education, Culture and Science (<ext-link ext-link-type="uri" xlink:href="http://www.nici.ru.nl/cgi-brain/index.cgi" xlink:type="simple">http://www.nici.ru.nl/cgi-brain/index.cgi</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="12"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Identification of the neural processes underlying semantic representations is a key challenge in cognitive neuroscience. Different hypotheses have been proposed on how representations of particular concepts establish a system of conceptual knowledge. The general consensus is that shared object properties are reflected in the organization of the semantic system and that the system generalizes across concepts that belong to a particular category (such a <italic>animals</italic>, <italic>tools</italic>, or <italic>buildings</italic>). The notion of category specificity in the organization of object knowledge emerged in the 1980s, when Warrington and colleagues first reported on patients with selective impairment for one semantic category compared to other semantic categories <xref ref-type="bibr" rid="pone.0014465-Warrington1">[1]</xref>–<xref ref-type="bibr" rid="pone.0014465-Warrington3">[3]</xref>. Since those initial investigations, a large number of studies have confirmed the phenomenon of category–specific semantic deficits. Patients have been reported with impairments for all types of knowledge about a particular category such as, for instance, living things. Such patients are severely impaired for both perceptual (“Does a cow have a mane?”) and functional (“Does a whale fly?”) knowledge of living things, but are within normal range for both types of knowledge for non-animals <xref ref-type="bibr" rid="pone.0014465-Caramazza1">[4]</xref>–<xref ref-type="bibr" rid="pone.0014465-Mahon1">[6]</xref>.</p>
<p>Differences in category-related brain activity have been demonstrated with various neuroimaging methods in healthy subjects, for living things versus manmade objects, and for several specific object categories such as faces, body parts, animals, fruits/vegetables, buildings, tools and furniture (for a recent review see <xref ref-type="bibr" rid="pone.0014465-Gerlach1">[7]</xref>–<xref ref-type="bibr" rid="pone.0014465-Binder1">[9]</xref>). Differential activation, suggesting a specific functional organization, has been shown in processing both visual and verbal stimulus modalities. For some types of objects, the functional organization by semantic category has been demonstrated within a given modality, e.g. category–specificity in the visual pathway for faces <xref ref-type="bibr" rid="pone.0014465-Kanwisher1">[10]</xref>, <xref ref-type="bibr" rid="pone.0014465-Kanwisher2">[11]</xref> or for living versus nonliving entities <xref ref-type="bibr" rid="pone.0014465-Perani1">[12]</xref>–<xref ref-type="bibr" rid="pone.0014465-Noppeney1">[15]</xref>. It has also been shown that objects and their sensory or functional attributes (such as tool-associated actions) activate the same neural regions <xref ref-type="bibr" rid="pone.0014465-Tyler1">[16]</xref>–<xref ref-type="bibr" rid="pone.0014465-Hoenig1">[19]</xref>, suggesting that these regions are implicitly involved in concept representation.</p>
<p>Modern theories about conceptual representation share the view that the semantic system relates to perceptual and functional attributes of objects that are coded in respective sensory or motor areas. However, there are two broad groups of theories. Theories within the first group assume that each concept is represented as a set of attributes in a distributed system <xref ref-type="bibr" rid="pone.0014465-Tyler2">[20]</xref>, <xref ref-type="bibr" rid="pone.0014465-Moss1">[21]</xref>. Concepts from one semantic domain have highly correlated attributes, resulting in category-specific effects. However the semantic system is undifferentiated in the sense that there are no explicit boundaries according to object category, and there is no categorical structure at the level of functional anatomy. Alternatively, theories within the second group assume that a dissociable neural substrate is involved in representing different semantic categories. One such theory, the sensory/functional, initially proposed by Warrington and McCarthy <xref ref-type="bibr" rid="pone.0014465-Warrington1">[1]</xref>, <xref ref-type="bibr" rid="pone.0014465-Warrington3">[3]</xref> and later modified by others <xref ref-type="bibr" rid="pone.0014465-Humphreys1">[22]</xref>, <xref ref-type="bibr" rid="pone.0014465-McRae1">[23]</xref>, suggests that concepts are essentially grounded in sensory and functional semantic subsystems, and conceptual categories with different sensory or functional emphasis are represented in different subsystems. A second theory within this group, the distributed domain-specific hypothesis <xref ref-type="bibr" rid="pone.0014465-Caramazza1">[4]</xref>, <xref ref-type="bibr" rid="pone.0014465-Mahon1">[6]</xref>, <xref ref-type="bibr" rid="pone.0014465-Caramazza2">[24]</xref>, suggests that, beyond the sensory and motor properties, there also exist semantic constraints. According to this theory, semantic domains, such as living animals, for which fast and efficient recognition could have had a survival advantage in evolutionary history, have different neuronal substrates. It is suggested that semantic domain is a constraint on the functional organization at both a conceptual level and at the level of visual perception <xref ref-type="bibr" rid="pone.0014465-Mahon1">[6]</xref>.</p>
<p>In recent years, a number of studies have demonstrated the possibility to discriminate retrieval of conceptual categories in functional MRI data, using multivariate analysis methods <xref ref-type="bibr" rid="pone.0014465-Hanson1">[25]</xref>–<xref ref-type="bibr" rid="pone.0014465-Shinkareva1">[28]</xref>. In contrast to conventional univariate methods, multivariate analysis takes into account the full spatial pattern of brain activity. This has been shown to increase sensitivity when analyzing human neuroimaging data <xref ref-type="bibr" rid="pone.0014465-Haynes1">[29]</xref> and may help to elucidate the nature of semantic representations. The goal of multivariate analysis is to learn a model that best explains the observed data, often quantified in terms of predictive performance (how well does the model predict experimental condition from measured data). Once the model is learned, the obtained parameter estimates can be mapped back to native space, yielding so-called importance maps. These importance maps inform about the relative importance of data features in space and/or time with respect to predicting the experimental condition in single trials. Recently, van Gerven and colleagues introduced a Bayesian approach to multivariate analysis for the interpretation of neuroimaging data <xref ref-type="bibr" rid="pone.0014465-vanGerven1">[30]</xref>. The approach makes it possible to 1) quantify uncertainty about the relative importance of data features and 2) impose constraints on the obtained models based on prior neuroscientific knowledge.</p>
<p>In the current study we applied the Bayesian approach to identify concept-related neuronal activity from event-related brain potentials (ERPs). We presented stimuli of two semantic categories: <italic>animals</italic> and <italic>tools</italic>, and trained a classifier to discriminate these categories. We estimated classification performance and interpret the obtained importance maps at a single-subject level for three stimulus modalities: auditory (an object's spoken name), visual (a drawing of an object), and orthographic (an object's written name). The use of ERPs as the basis for classification was guided by a number of considerations. First, electroencephalography (EEG) has a well-documented ability to characterize certain brain states, in particular the processing of different semantic categories <xref ref-type="bibr" rid="pone.0014465-Hoenig1">[19]</xref>, <xref ref-type="bibr" rid="pone.0014465-Pulvermller1">[31]</xref>–<xref ref-type="bibr" rid="pone.0014465-Adorni1">[36]</xref>. Second, the high temporal resolution of EEG allows a fine-grained characterization of concept retrieval in terms of the electrophysiological patterns that make decoding possible. Third, the development of EEG-based semantic-decoding algorithms is interesting from an applications perspective since the temporal resolution of EEG allows decoding in real-time <xref ref-type="bibr" rid="pone.0014465-Mller1">[37]</xref>. When it becomes possible to decode conceptual information from EEG, a brain-computer interface system that transforms lexical concepts into a written or spoken output could become a reality.</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<sec id="s2a">
<title>Participants</title>
<p>Twenty-four native Dutch speakers (10 males and 14 females, 18–28 years of age) participated in the study; four of them were selected as a pilot group (see “Optimization of the analysis”). All participants were right-handed, and reported that they did not suffer from any psychological or neurological disorders. The experiments were approved by the local ethics committee (Commissie Mensgebonden Onderzoek Regio Arnhem-Nijmegen), and all the subjects gave written informed consent prior to the experiment. Subjects received either monetary compensation or course credits for their participation.</p>
</sec><sec id="s2b">
<title>Stimuli</title>
<p>Concepts from three semantic categories were used: two relevant categories (<italic>animals</italic>, <italic>tools</italic>) and a task category that varied across subjects, either <italic>clothing</italic> or <italic>vegetables</italic>. There were four exemplars per category, see <xref ref-type="table" rid="pone-0014465-t001">Table 1</xref>. All exemplars were monosyllabic and were matched for frequency per million (mean±SD = 18.25±9.55) based on CELEX (Max Planck Institute for Psycholinguistics, The Netherlands, 2001).</p>
<table-wrap id="pone-0014465-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.t001</object-id><label>Table 1</label><caption>
<title>Relevant items used in the experiment.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0014465-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Orthography</td>
<td align="left" colspan="1" rowspan="1">Phonetics</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">“animals”</td>
<td align="left" colspan="1" rowspan="1">koe <italic>(cow)</italic></td>
<td align="left" colspan="1" rowspan="1">ku</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">beer <italic>(bear)</italic></td>
<td align="left" colspan="1" rowspan="1">be:r</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">leeuw <italic>(lion)</italic></td>
<td align="left" colspan="1" rowspan="1">lew</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">aap <italic>(ape)</italic></td>
<td align="left" colspan="1" rowspan="1">a:p</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“tools”</td>
<td align="left" colspan="1" rowspan="1">bijl <italic>(axe)</italic></td>
<td align="left" colspan="1" rowspan="1">bεil</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">schaar <italic>(scissors)</italic></td>
<td align="left" colspan="1" rowspan="1">s÷a:r</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">kam <italic>(comb)</italic></td>
<td align="left" colspan="1" rowspan="1">kαm</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">pen <italic>(pen)</italic></td>
<td align="left" colspan="1" rowspan="1">pεn</td>
</tr>
</tbody>
</table></alternatives></table-wrap>
<p>All exemplars were presented in three modalities: auditory (spoken Dutch words recorded digitally at 16 bits with a sampling rate of 44.100 Hz), visual (black line drawings on white background) <xref ref-type="bibr" rid="pone.0014465-Szekely1">[38]</xref> and orthographical (written Dutch words, black letters on white background). Pictures were matched for familiarity and complexity. Each of the relevant items was repeated eighty times in each modality. Task items were repeated sixteen times and shown approximately once per ten relevant items. The text or picture stimuli were presented for 300 ms and were followed by a blank screen with a random duration between 1000–1200 ms. Subsequently, the next item was presented. The interval between auditory stimuli was also between 1000–1200 ms and a fixation cross was shown on the screen during the auditory presentation.</p>
</sec><sec id="s2c">
<title>Experimental design</title>
<p>All stimuli were presented in twelve blocks with audio, picture and text stimuli in separate blocks. The order of blocks was alternated across subjects. In each run, the same full set of concepts was used and their order was randomized. The experiment lasted about eighty minutes, with a short break between blocks. Participants were instructed to respond upon appearance of items from the classification irrelevant task category (clothing or vegetables). With this procedure participants were forced to categorize the presented items without overtly discriminating between relevant classes. Responses were made by pressing a button with the right hand index finger.</p>
</sec><sec id="s2d">
<title>EEG recording and processing</title>
<p>Continuous EEG was registered using a 64 channel ActiCap system (Brain Products GmbH) filtered at 0.2–200 Hz and sampled at 500 Hz with the BrainVision Recorder Professional software (Brain Products GmbH). An equidistant electrode cap was used to position 60 electrodes on the scalp (<xref ref-type="fig" rid="pone-0014465-g001">Figure 1</xref>). EEG data were recorded against the reference at the right mastoid; an additional electrode measured the voltage on the left mastoid, and the data were offline converted to a linked-mastoids reference. Bipolar EOG was computed using electrodes that were placed horizontally and vertically around the eyes. The continuously recorded data were divided into epochs of one second starting 300 ms before stimulus onset. Trials containing eye artifacts or voltage variations at any electrode above 150 µV were rejected. The signal was filtered with a pass band of 1–30 Hz. Only relevant stimuli – of semantic categories <italic>animals</italic> and <italic>tools</italic> - were selected for subsequent analysis. Differences in the number of trials between the two classes after artifact rejection did not exceed 1.5%. All offline data processing was performed using MATLAB R2008 (The MathWorks, Inc., Natic, MA) and FieldTrip, an open source Matlab toolbox for the analysis of EEG and MEG data that has been developed at our centre (<ext-link ext-link-type="uri" xlink:href="http://www.ru.nl/neuroimaging/fieldtrip/" xlink:type="simple">http://www.ru.nl/neuroimaging/fieldtrip/</ext-link>).</p>
<fig id="pone-0014465-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g001</object-id><label>Figure 1</label><caption>
<title>The equidistant electrode montage.</title>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g001" xlink:type="simple"/></fig></sec><sec id="s2e">
<title>Optimization of the analysis</title>
<p>To optimize the analysis procedure, we experimented with several analysis methods. However, to ensure that tuning the procedure to a specific set of subjects did not bias our results, we used data from four subjects (the pilot group) to optimize the procedure. The pilot data was used to examine the effect of artifact removal and to set the optimal filtering parameters, as described above. Furthermore, the pilot data was used to select the optimal feature selection and classification procedure. The pilot subjects were excluded from the reported analysis.</p>
<p>As input to the classifier we used the time-domain representation of the event-related potentials, the voltage measurements in sixty channels over the samples at each two milliseconds, at the 0–700 ms interval after stimulus onset. The signal over all trials was standardized to have zero mean and a standard deviation of one. Bayesian logistic regression with a multivariate Laplace prior was chosen as the classifier for subsequent analysis since it has been shown to give rise to interpretable importance maps <xref ref-type="bibr" rid="pone.0014465-vanGerven1">[30]</xref>. The Supporting Information (<xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref>, <xref ref-type="supplementary-material" rid="pone.0014465.s002">Figure S2</xref> and <xref ref-type="supplementary-material" rid="pone.0014465.s003">Figure S3</xref>) may be consulted for details of the employed computational method. Once this optimal analysis scheme had been developed, the remaining group of subjects (N = 20) was analyzed blindly.</p>
</sec><sec id="s2f">
<title>Classification procedure</title>
<p>Classifiers were trained to identify in single trials which of the two semantic categories (<italic>animal</italic> or <italic>tool</italic>) were presented to the subject. We imposed constraints on the obtained models that coupled parameters located closely together in time through the use of a multivariate Laplace prior (details are mentioned in <xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref>). This effectively induces an adaptive temporal smoothing of the variance of estimated regression coefficients, which facilitates interpretation of the results <xref ref-type="bibr" rid="pone.0014465-vanGerven1">[30]</xref>. Classification accuracy (proportion of correctly classified trials) was used to evaluate classifier performance. Since we presented equal fractions of the two categories, chance level performance was at 50%. Significance of the classification outcome was computed using a binomial test, which compares the performance of the trained classifier with that of a baseline classifier that assigns all trials to the most prevalent class <xref ref-type="bibr" rid="pone.0014465-Burges1">[39]</xref>. The significance level was Bonferroni corrected for the number of used subjects.</p>
<p>The classification approach was used to conduct three different analyses. In the first analysis, only those trials corresponding to the presentation of a particular modality were used as input to the classifier and the task was to predict semantic category from EEG data. For each subject, a stratified five-fold cross-validation was performed in which the dataset was partitioned into five random subsets. Each subset was retained as the validation data for testing the model and the remaining four subsets were used as training data for that run. This process was repeated five times. The results from all the five runs, or so-called folds, were averaged to produce a single estimate of classification accuracy.</p>
<p>This procedure was applied a) to the entire interval of 0–700 ms post stimulus onset, and b) repeated again for small intervals of 40 ms (16 intervals from 0 up to 640 ms), in order to identify independent important data features for each time interval.</p>
<p>In the experimental design, we used a small set of exemplars, which were presented repeatedly throughout a session. This allowed us to match them for the linguistic characteristics (e.g. frequency of use, syllabic structure). At the same time this approach leads to interpretation problems, since the same exemplars presented in different trials appear both in training and test datasets in cross-validation. Therefore, the classifier might use exemplar-specific rather than category-specific data features to identify class-membership, effectively predicting exemplars instead of semantic categories within a modality. A proof that the classifier generalizes over the items from one semantic category would be the ability to correctly identify the category of a previously unseen exemplar. To this end, we conducted as a second analysis, an “unseen exemplar” test. We trained a classifier on all exemplars except one. The semantic category of the left-out exemplar was then predicted using the trained classifier. This procedure was repeated for each of the eight concepts in the set for each subject.</p>
<p>Finally, in order to study the generalization between instead of within modalities, we used a so-called transfer learning approach <xref ref-type="bibr" rid="pone.0014465-Thrun1">[40]</xref>. In previous analyses, the trials for each of the three modalities (visual, auditory and orthographical) were assumed to be independent. In the transfer learning setting, in contrast, parameters are estimated simultaneously for each of the datasets by introducing a coupling between datasets through the use of the multivariate Laplace prior. In this way, data features are identified which should allow trials to be classified correctly for each of the three modalities (see <xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref> for details). This analysis was conducted a) for the whole trial length of 700 ms, and b) for subsequent intervals of 40 ms from 0 to 640 ms post stimulus onset.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>ERP results</title>
<p><xref ref-type="fig" rid="pone-0014465-g002">Figure 2</xref> shows the grand averages obtained from the entire group of twenty subjects (variability in the experimental data is illustrated in <xref ref-type="supplementary-material" rid="pone.0014465.s001">Figure S1</xref>). Inspection of the figure shows that picture presentations elicited a P1 ERP component at about 110 ms post stimulus onset followed by a visual N1 at about 160 ms post stimulus onset. These early components were largest over the posterior part of the head at infero-temporal and occipital electrodes. There were differences in the morphologies of the early components between the two categories. The P1 component in occipital electrodes peaked earlier on a response to animals and the N1 component for animals had larger amplitude at the right occipital electrodes. The early components were followed by a broad negativity that lasted from about 280 to 550 ms in fronto-central sites and occipito-temporal sites. In frontal electrodes the deflection was less negative for animals than for tools.</p>
<fig id="pone-0014465-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g002</object-id><label>Figure 2</label><caption>
<title>Grand average ERP results, 0–600 ms after stimulus onset.</title>
<p>Grand average (N = 20) waveforms are shown for presentation of pictures (A), spoken words (B), and written words (C). The EEG channels are labeled according to the used electrode montage, see <xref ref-type="fig" rid="pone-0014465-g001">Figure 1</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g002" xlink:type="simple"/></fig>
<p>The spoken words elicited N1 component at centro-posterior sites peaking at 130 ms followed by P2-N2 wave at 220–310 ms. Following the N2, there was a broad negative deflection in central sites peaking between 450 and 550 ms (N400). The grand average ERP responses show that there were differences in the morphology of the P2-N2 complex in central electrodes between word categories. The N2 had larger amplitude for tools over central electrodes.</p>
<p>The written words elicited visual P1-N1 pattern over posterior electrodes, with larger amplitude of the N1 component over left hemisphere. At anterior sites the P1 was not clearly visible and was overlapping with a negative wave that peaked at 100 ms. In the subsequent part of the recording a broad positivity was observed in central and frontal regions, followed by frontal negativity peaking at about 300 ms <xref ref-type="bibr" rid="pone.0014465-Grainger1">[41]</xref> and subsequently by the N400 at 400–550 ms. Over parietal and centro-parietal sites there was an additional negative deflection peaking at 200 ms (N2) <xref ref-type="bibr" rid="pone.0014465-Dien1">[42]</xref>. The N300 component at fronto-central electrodes and the subsequent N400 were less negative for animals than for tools.</p>
</sec><sec id="s3b">
<title>Within modalities classification results</title>
<p>In the first analysis we trained and tested the classifiers within each of the individual modalities separately. We found strong differences in accuracies obtained for pictures in comparison with the auditory and orthographic modalities (<xref ref-type="fig" rid="pone-0014465-g003">Figure 3</xref>). For pictures, the highest classification accuracy reached over all subjects was 0.89, and classification was significant (p&lt;0.05, Bonferroni corrected) for all twenty subjects with a mean value of 0.79 (SD = 0.07). The classifier for the auditory modality performed significantly better than chance in eight out of twenty subjects, the mean value over twenty subjects was 0.61 (SD = 0.04). The classifier for the orthographic modality performed significantly better than chance in two out of twenty subjects, with a mean group value of 0.56 (SD = 0.04).</p>
<fig id="pone-0014465-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g003</object-id><label>Figure 3</label><caption>
<title>Classification performance for the three modalities.</title>
<p>Dark bars indicate significant outcomes.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g003" xlink:type="simple"/></fig>
<p>Decoding performance did not correlate with subjects' age or task performance. Every subject performed well on the experimental task. On average they responded to 99% (SD = 1.7%) of the target stimuli.</p>
</sec><sec id="s3c">
<title>Important data features</title>
<p>In this study we demonstrated that Bayesian logistic regression allows identification of task relevant time-channel locations from the ERPs at the single trial level in single subjects. An example of the classification model obtained for a representative subject for the entire trial duration of 700 ms is shown in <xref ref-type="fig" rid="pone-0014465-g004">Figure 4</xref>. The figure suggests that only a few channels contribute to the decoding performance. Note, however, that this sparseness is not only induced by the data but also by the employed multivariate Laplace prior. This phenomenon is described in greater detail in <xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref>, see also <xref ref-type="supplementary-material" rid="pone.0014465.s003">Figure S3</xref>.</p>
<fig id="pone-0014465-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g004</object-id><label>Figure 4</label><caption>
<title>An example of the importance values for the time-channel pairs in one representative subject.</title>
<p>Importance maps are shown for presentation of pictures (upper left panel), spoken words (bottom left panel), written words (upper right panel), and for the transfer learning (bottom right panel). The relative importance of the data features is expressed in terms of the variance of the auxiliary variables (see <xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref>). Importance values are shown over time (<italic>x</italic>-axis, sampled each 2 ms) for 60 EEG channels (<italic>y</italic>-axis).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g004" xlink:type="simple"/></fig>
<p>In order to further investigate the discriminative characteristics of ERPs on different post-stimulus latencies, we divided the trial into short time segments and conducted the classification on these segments independently. Here we present the importance maps for animal/tool classification in all three modalities (pictures, spoken and written words), averaged over five subjects that showed highest classification performance in each modality (<xref ref-type="fig" rid="pone-0014465-g005">Figure 5</xref>). Supporting material for this article includes the time course of importance maps for the twenty subjects for the three modalities (see <xref ref-type="supplementary-material" rid="pone.0014465.s005">Videos S1</xref>, <xref ref-type="supplementary-material" rid="pone.0014465.s006">S2</xref>, and <xref ref-type="supplementary-material" rid="pone.0014465.s007">S3</xref>).</p>
<fig id="pone-0014465-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g005</object-id><label>Figure 5</label><caption>
<title>Data features important for the classification in three modalities.</title>
<p>Upper panel – pictures, middle panel – spoken words, bottom panel – written words. A) Classification performance at 40 ms time intervals from 0–640 ms after stimulus onset. Chance level performance is at 0.50. B) The ERP waveforms from the channels that contributed most to the classification. C) The locations of the important data features in the different time intervals, starting at stimulus onset.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g005" xlink:type="simple"/></fig><sec id="s3c1">
<title>Pictures</title>
<p>The classifier could reliably distinguish the category 100 ms after stimulus onset. The important data features were localized in central parieto-occipital sites 43 and 44 (POz, PO3). These results are in line with the increasing number of studies that report on early effects of visual object category in posterior locations <xref ref-type="bibr" rid="pone.0014465-PazCaballero1">[33]</xref>, <xref ref-type="bibr" rid="pone.0014465-Fuggetta1">[35]</xref>, <xref ref-type="bibr" rid="pone.0014465-Mazerolle1">[43]</xref>, <xref ref-type="bibr" rid="pone.0014465-Liu1">[44]</xref>. Later in the time interval, from 100–200 ms after stimulus onset, the focus spreads more laterally. The data features of highest importance in posterior sites correspond to the N1-P2 waveform complex of the respective ERP. In previous studies that have used univariate analysis, the time window of the N1 component has indeed been shown to be sensitive to object category. Particularly, the N1 amplitude is consistently larger for natural than for artifactual categories <xref ref-type="bibr" rid="pone.0014465-Proverbio1">[34]</xref>, <xref ref-type="bibr" rid="pone.0014465-Kiefer3">[45]</xref>, as is confirmed by our results. The N1 is traditionally thought to reflect perceptual processing. However its amplitude and latency are modulated by the experimental task, i.e. attendance to the target stimulus and categorization demand <xref ref-type="bibr" rid="pone.0014465-Mangun1">[46]</xref>–<xref ref-type="bibr" rid="pone.0014465-Large1">[49]</xref>. This indicates that the N1 reflects stimulus discrimination and is influenced by top-down mechanisms <xref ref-type="bibr" rid="pone.0014465-Vogel1">[50]</xref>, <xref ref-type="bibr" rid="pone.0014465-Arnott1">[51]</xref>. At later latencies that are usually assumed to include semantic and associative processing, data features in the right occipital site PO4 were important for distinguishing the semantic categories.</p>
</sec><sec id="s3c2">
<title>Spoken words</title>
<p>The category of spoken words could be identified starting at 150 ms after stimulus onset, with the relevant data features located at central and fronto-central electrodes sites 9, 10, 17, and 18 (C1, C3, FC3, FC4, C4). Early important data features are left-lateralized and correspond to the N1 component, which is known to reflect the conscious detection of discrete changes in the auditory environment <xref ref-type="bibr" rid="pone.0014465-Hyde1">[52]</xref> and is also modulated by attention <xref ref-type="bibr" rid="pone.0014465-Ntnen1">[53]</xref>, <xref ref-type="bibr" rid="pone.0014465-Alcaini1">[54]</xref>. Categories could be distinguished most easily at around 200–240 ms after stimulus onset, the interval that corresponds to the N2-P2 complex in the centro-parietal site 26 (CP4-P5), which has previously been shown to be sensitive to detection of semantic manipulations in single word listening <xref ref-type="bibr" rid="pone.0014465-Pulvermller1">[31]</xref>, <xref ref-type="bibr" rid="pone.0014465-Pulvermller2">[55]</xref>, <xref ref-type="bibr" rid="pone.0014465-Assadollahi1">[56]</xref>. Semantic categories could also be identified in late (&gt;400 ms) ERP components, but the data features are more spread out across the scalp.</p>
</sec><sec id="s3c3">
<title>Written words</title>
<p>For written words the important data features arise around 250–400 ms after stimulus onset, focused at the left parietal electrodes 29–45 (P3–P5), with a main peak around 240–280 ms after stimulus onset. According to recent findings, recognition of written words occurs as early as 200–250 ms after stimulus onset <xref ref-type="bibr" rid="pone.0014465-Sereno1">[57]</xref>–<xref ref-type="bibr" rid="pone.0014465-Sahin1">[61]</xref>. Some previous studies also showed a strong effect of the semantic category of nouns in this time window <xref ref-type="bibr" rid="pone.0014465-Adorni1">[36]</xref>. The left occipito-temporal localization of the data features might point towards a source in left fusiform gyrus, an area that is consistently engaged in reading and particularly in written word recognition <xref ref-type="bibr" rid="pone.0014465-Dien1">[42]</xref>, <xref ref-type="bibr" rid="pone.0014465-Sereno1">[57]</xref>, <xref ref-type="bibr" rid="pone.0014465-McCandliss1">[62]</xref>, <xref ref-type="bibr" rid="pone.0014465-Devlin1">[63]</xref>. In later latencies the classification focus spreads to the right central and centro-frontal locations 9, 10, and 12 (C4-FC4). The electrophysiological activity in these sites allowed classification at around 500 ms after stimulus onset. Late ERP waves such as the N400 and the Late Positive Component have been shown to be sensitive to semantic category in visual word presentation <xref ref-type="bibr" rid="pone.0014465-Kiefer2">[32]</xref>, <xref ref-type="bibr" rid="pone.0014465-Adorni1">[36]</xref>.</p>
</sec></sec><sec id="s3d">
<title>Unseen exemplar analysis</title>
<p>In the unseen exemplar analysis, our aim was to determine whether the semantic category could be predicted for previously unseen exemplars. The classifier could only solve this task reliably in the visual modality (mean accuracy 0.77, SD = 0.08, p&lt;0.05, Bonferroni corrected, for all subjects). The classification results were non-significant for the other modalities (<xref ref-type="fig" rid="pone-0014465-g006">Figure 6</xref>).</p>
<fig id="pone-0014465-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g006</object-id><label>Figure 6</label><caption>
<title>Classification performance for unseen exemplars.</title>
<p>Chance level performance is at 0.50. English translations of Dutch stimuli are given in italics.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g006" xlink:type="simple"/></fig></sec><sec id="s3e">
<title>Classification between modalities</title>
<p>To reveal the common category-related patterns across modalities we used a transfer learning approach that identified the data features that are relevant to all modalities. For this analysis we selected a subset of four subjects that showed high classification accuracies in all the modalities (subjects nr 4, 5, 7, 14). The classifier can be thought of as building a common model for the three datasets (the data from all three modalities) in each subject. The mean classification accuracy on the entire trial up to 700 ms after stimulus onset was 0.83 (SD = 0.06) for pictures, 0.66 (SD = 0.02) for audio and 0.62 (SD = 0.03) for text, see <xref ref-type="table" rid="pone-0014465-t002">Table 2</xref>. The important data features were located in posterior sites 43 and 44 (POz, PO3); see <xref ref-type="fig" rid="pone-0014465-g007">Figure 7</xref>. The classification on short time segments revealed similar results.</p>
<fig id="pone-0014465-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.g007</object-id><label>Figure 7</label><caption>
<title>Results of the transfer learning test.</title>
<p>A) Classification performance at 40 ms time intervals, from 0–640 ms after stimulus onset, for all three modalities. B) The locations of the important data features in the different time intervals, starting at stimulus onset. Note the strong preference for occipital areas.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.g007" xlink:type="simple"/></fig><table-wrap id="pone-0014465-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0014465.t002</object-id><label>Table 2</label><caption>
<title>The results of transfer learning.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0014465-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.t002" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Pictures</td>
<td align="left" colspan="1" rowspan="1">Spoken words</td>
<td align="left" colspan="1" rowspan="1">Written words</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Performance</td>
<td align="left" colspan="1" rowspan="1">0.83</td>
<td align="left" colspan="1" rowspan="1">0.66</td>
<td align="left" colspan="1" rowspan="1">0.61</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SD</td>
<td align="left" colspan="1" rowspan="1">0.05</td>
<td align="left" colspan="1" rowspan="1">0.04</td>
<td align="left" colspan="1" rowspan="1">0.03</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Significance<xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">1.7×10<sup>−5</sup> (0.001)</td>
<td align="left" colspan="1" rowspan="1">0.02 (0.32)</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>*p-values, and Bonferroni corrected p-values.</p></fn></table-wrap-foot></table-wrap></sec></sec><sec id="s4">
<title>Discussion</title>
<p>In this study we set out to decode the semantic category of objects from event-related EEG. We repeatedly presented a set of eight instances from two different semantic categories (<italic>animals</italic> and <italic>tools</italic>) where each instance appeared in three modalities: as a picture, as a spoken word or as a written word. Since Bayesian logistic regression is well suited for quantifying the relative importance of the data features and therefore facilitated interpretation of the obtained importance maps <xref ref-type="bibr" rid="pone.0014465-vanGerven1">[30]</xref>, it was the method of choice for the analysis. The distribution of electrophysiological features that contribute to the animal/tool classification in the three modalities agrees with a number of existing studies on the temporal and spatial organization of the neuronal activity underlying lexical access. In all the modalities the classifier mostly relies on early electrophysiological patterns. In addition there is a contribution from late activity in the N400 time window that is traditionally associated with semantic processes <xref ref-type="bibr" rid="pone.0014465-Kutas1">[64]</xref>. The results are highly consistent over subjects and reveal distinct brain regions and temporal structure for task-related activation.</p>
<sec id="s4a">
<title>Classification in the visual modality</title>
<p>The visual modality demonstrated a clear differential response to the semantic categories. Classification performance was highly significant for all subjects. Moreover, the classifier that had been trained to discriminate <italic>animals</italic> and <italic>tools</italic> could accurately identify the category of a previously unseen exemplar from one of these categories.</p>
<p>The topographical distribution of the data features important for classification indicates that differential activity first takes place at centro-occipital sites and then moves laterally towards occipito-temporal locations. A large number of neuroimaging studies have reported on consistent topographical biases in the visual processing stream for pictures of animals compared with non-living objects resulting in category-specific patterns in occipito-temporal cortex (for recent reviews see <xref ref-type="bibr" rid="pone.0014465-Gerlach1">[7]</xref>, <xref ref-type="bibr" rid="pone.0014465-Martin1">[8]</xref>, <xref ref-type="bibr" rid="pone.0014465-Martin2">[65]</xref>). For instance, in an fMRI study by Chao, Haxby and Martin <xref ref-type="bibr" rid="pone.0014465-Chao1">[13]</xref>, the lateral fusiform gyrus showed differential neural response to living things, whereas nonliving things elicited differential responses in the medial fusiform gyrus. Our results seem to indicate differential activation at similar locations. These findings sit naturally with the distributed domain-specific hypothesis by Caramazza <xref ref-type="bibr" rid="pone.0014465-Caramazza1">[4]</xref>, <xref ref-type="bibr" rid="pone.0014465-Mahon1">[6]</xref>, <xref ref-type="bibr" rid="pone.0014465-Caramazza2">[24]</xref>, which claims that visual response is topographically segregated by semantic category. In line with this suggestion, a number of recent behavioural studies showed that category can be accessed rapidly when objects are visually presented <xref ref-type="bibr" rid="pone.0014465-Large1">[49]</xref>, <xref ref-type="bibr" rid="pone.0014465-Thorpe1">[66]</xref>–<xref ref-type="bibr" rid="pone.0014465-Mace1">[69]</xref>. For example, in processing visual scenes, human participants can reliably make saccades to the side containing an animal in as little as 120 ms <xref ref-type="bibr" rid="pone.0014465-Kirchner1">[70]</xref>, and in a visual monitoring task, humans tend to detect changes concerning animals both faster and more accurately than vehicles, buildings, plants and tools <xref ref-type="bibr" rid="pone.0014465-New1">[71]</xref>. These functional advantages in visual identification of animals compared to other categories could result from a segregated recognition mechanism, which evolved due to the high biological relevance of this category.</p>
<p>Obviously, the current results might also be explained without invoking the notion of semantic categorization on the level of visual processing. The differential activity in occipital and occipito-temporal sites could result from selectivity to certain visual attributes that happen to be more characteristic of one category than another <xref ref-type="bibr" rid="pone.0014465-Humphreys1">[22]</xref>, <xref ref-type="bibr" rid="pone.0014465-LloydJones1">[72]</xref>. Depicted animals tend to have rounded shapes and curved lines as opposed to elongated shapes and straight lines for tools. It was recently demonstrated that if two classes of visual stimuli have a low amount of within-class variation, it is possible to get reliable classification performance using just the outputs of primary visual areas <xref ref-type="bibr" rid="pone.0014465-Pinto1">[73]</xref>.</p>
<p>Even though the present study remains inconclusive about whether category membership or visual properties drive the classification, the present data shows that object category can be successfully decoded from the early visual components of scalp EEG. This finding is of relevance to brain-computer interface (BCI) research <xref ref-type="bibr" rid="pone.0014465-vanGerven2">[74]</xref>. For instance, many studies have shown that similar patterns of brain activity arise when perceiving and imagining objects <xref ref-type="bibr" rid="pone.0014465-Roland1">[75]</xref>–<xref ref-type="bibr" rid="pone.0014465-Reddy1">[79]</xref>. If the semantic category can be predicted for imagined concepts using EEG then this could be used for communication and control in BCI applications.</p>
</sec><sec id="s4b">
<title>Classification of written and spoken words</title>
<p>In contrast to pictures, classification of spoken and written words turned out to be more difficult. There were two main complexities. First, classification performance across subjects was lower for audio trials than for pictures, and considerably lower for text, where it was significant only for two out of twenty subjects. Second, for these modalities, the classifier failed to predict the semantic category of a previously unseen item, suggesting that the classifier could not distinguish the semantic classes, but only the exemplars, possibly through the use of perceptual differences between the exemplars. Note further that, in contrast to pictures, for spoken or written words there are no perceptual differences that are characteristic of one or the other semantic class.</p>
<p>According to recent psycholinguistic studies, verbal input is processed at different levels of analysis, where situation and task demands modulate the depth of semantic processing <xref ref-type="bibr" rid="pone.0014465-Ferreira1">[80]</xref>, <xref ref-type="bibr" rid="pone.0014465-Sturt1">[81]</xref>. This implies that the words might not necessarily have been processed at the required level. We assume this could happen in our experiment, as the experimental task did not demand the retrieval of associative-semantic knowledge. These considerations might explain poor performance for the verbal presentations of concepts. Moreover, in our experiment the stimuli were repeated many times, and it has been shown previously that category-related effects reduce with repeated stimuli <xref ref-type="bibr" rid="pone.0014465-Kiefer3">[45]</xref>, <xref ref-type="bibr" rid="pone.0014465-Chao2">[82]</xref>. These issues should be taken into account in the design of future semantic encoding experiments.</p>
</sec><sec id="s4c">
<title>In search for amodal semantic representations</title>
<p>An interesting prospect when studying the semantic system is the identification of common activity patterns across different input modalities. During the initial stages of processing, the percepts of different modalities are analyzed in their respective sensory systems. Subsequently, perceptual processing, structural encoding and identification are followed by semantic-associative integration <xref ref-type="bibr" rid="pone.0014465-Price1">[83]</xref>. The same semantic knowledge can be accessed by various written or spoken symbols, or real world cues, so the integration stage is assumed to be modality-independent.</p>
<p>The transfer learning approach allowed us to obtain reasonable classification accuracies for all three modalities. A number of previous neuroimaging studies investigating amodal semantic processing found overlapping activation for pictures and words, implicating a distributed, left-lateralized neural network in frontal, peri-sylvian temporal and parietal areas <xref ref-type="bibr" rid="pone.0014465-Vandenberghe1">[84]</xref>–<xref ref-type="bibr" rid="pone.0014465-VanDoren1">[87]</xref> (for a review see <xref ref-type="bibr" rid="pone.0014465-Price1">[83]</xref>). However, in our study, the important electrophysiological patterns for the cross-modal classification were largely located in occipital cortical sites. It is likely that picture trials biased the classification algorithm such that mostly data features in occipital sites were selected, allowing a reliable performance for pictures and a moderate performance for the other modalities.</p>
<p>One possible explanation for the inability to reveal amodal semantics-related patterns with the employed procedure is due to timing differences. Auditory stimuli are spread out in time, whereas the others are presented instantaneously. Besides the differences in timing, there might be a mismatch between the electrophysiological correlates of semantic retrieval from different modalities due to the flexibility of conceptual representations. It has been recently suggested that concepts are flexibly tailored to the current contextual constraints and the access to conceptual knowledge can be modulated by focusing on certain conceptual attributes <xref ref-type="bibr" rid="pone.0014465-Hoenig1">[19]</xref>, <xref ref-type="bibr" rid="pone.0014465-Kiefer3">[45]</xref>, <xref ref-type="bibr" rid="pone.0014465-Barsalou1">[88]</xref>. For example, visually related attributes are predominantly recruited in contexts that focus on the visual appearance of objects <xref ref-type="bibr" rid="pone.0014465-Hoenig1">[19]</xref>. Hence, the electrophysiological signals of interest might vary too much across modalities in order to be generalizable.</p>
</sec><sec id="s4d">
<title>Concluding remarks</title>
<p>Summarizing, in this study we employed a novel multivariate approach for the analysis of semantic category-related electrophysiological brain activity. The method allows identification of the data features that are important for classification, thereby tracking down task-related activations at the single trial level in individual subjects. We showed an ability to decode the category of presented objects from the single-trial ERP waveforms. At present, the conducted experiments do not allow us to differentiate between the perceptual versus semantic origin of the obtained classification performance, so this issue remains inconclusive. Further research on the nature of semantic representations is warranted in order to be able to characterize the interactions between perceptual and conceptual processes, and how and when perceptual input transforms into conceptual representation.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0014465.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s001" xlink:type="simple"><label>Figure S1</label><caption>
<p>An illustration of variability in the ERP dataset. Left panel: pictures, middle panel: spoken words, right panel: written words. A) Between-subjects variability as shown by the ERPs from 20 subjects in response to stimuli of the different modalities. This variability is quite typical for ERP experiments and is caused, amongst others, by the large variability in cortical folding between zsubjects. The single-trial analysis is challenged by the low signal-to-noise ratio of ERPs in relation to the ongoing EEG and artifacts (line noise, muscle and ocular artifacts), so it can be extremely sensitive to the individual voltage distributions. This might explain the differences in classification performance across subjects. B) An example of within-subjects trial-to-trial variability for one representative subject. The black line and blue area represent the mean and standard deviation of the electrical potentials elicited by animals over the course of the experimental session. The number of trials used for averaging: for pictures N = 285, for spoken names N = 297, for written names N = 273. The red line and aquamarine area represent the mean and standard deviation of the electrical potentials elicited by tools: pictures (N = 305), spoken names (N = 298), written names (N = 281).</p>
<p>(1.33 MB TIF)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s002" xlink:type="simple"><label>Figure S2</label><caption>
<p>An example of a precision matrix. The multivariate Laplace prior employed during classification is specified in terms of a precision matrix. In this example, we show the (scaled) precision matrix for five channels and ten time points where consecutive time points are coupled with a coupling strength of one hundred. The regularization parameter was set to one.</p>
<p>(0.31 MB TIF)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s003" xlink:type="simple"><label>Figure S3</label><caption>
<p>Tradeoff between sparseness and smoothness of the importance map. A) Correlations of the event-related responses among sixty EEG channels in one representative subject. The matrix shows correlation coefficients among the channels, for the averaged ERP in response to spoken words, 0–700 ms after stimulus onset. The electrode positions are according to the equidistant montage; see <xref ref-type="fig" rid="pone-0014465-g001">Figure 1</xref>. B) Relative importance of the data features for time-channels pairs. The importance maps demonstrate effect of no coupling (upper-left map), coupling between neighbouring channels (bottom-left map), coupling between neighbouring time-points (upper right), and coupling between both time-points and channels (bottom right); see <xref ref-type="supplementary-material" rid="pone.0014465.s004">Text S1</xref> for details. Results from one representative subject (same as on the Panel A), for presentation of spoken words are shown. Importance values are shown over time (x-axis, sampled each 2 ms) for 60 EEG channels (y-axis).</p>
<p>(3.10 MB TIF)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s004" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s004" xlink:type="simple"><label>Text S1</label><caption>
<p>Details of the computational method.</p>
<p>(0.09 MB DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s005" mimetype="video/mpeg" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s005" xlink:type="simple"><label>Video S1</label><caption>
<p>Features importance maps over 0–640 ms after the stimulus onset, 20 subjects, pictures presentations.</p>
<p>(7.84 MB MPG)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s006" mimetype="video/mpeg" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s006" xlink:type="simple"><label>Video S2</label><caption>
<p>Features importance maps over 0–640 ms after the stimulus onset, 20 subjects, spoken-word presentations.</p>
<p>(7.88 MB MPG)</p>
</caption></supplementary-material><supplementary-material id="pone.0014465.s007" mimetype="video/mpeg" position="float" xlink:href="info:doi/10.1371/journal.pone.0014465.s007" xlink:type="simple"><label>Video S3</label><caption>
<p>Features importance maps over 0–640 ms after the stimulus onset, 20 subjects, written-word presentations.</p>
<p>(7.91 MB MPG)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors thank Ole Jensen for valuable comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0014465-Warrington1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Warrington</surname><given-names>EK</given-names></name>
<name name-style="western"><surname>McCarthy</surname><given-names>R</given-names></name>
</person-group>             <year>1983</year>             <article-title>Category specific access dysphasia.</article-title>             <source>Brain</source>             <volume>106</volume>             <issue>Pt 4</issue>             <fpage>859</fpage>             <lpage>878</lpage>          </element-citation></ref>
<ref id="pone.0014465-Warrington2"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Warrington</surname><given-names>EK</given-names></name>
<name name-style="western"><surname>Shallice</surname><given-names>T</given-names></name>
</person-group>             <year>1984</year>             <article-title>Category specific semantic impairments.</article-title>             <source>Brain</source>             <volume>107</volume>             <issue>Pt 3</issue>             <fpage>829</fpage>             <lpage>854</lpage>          </element-citation></ref>
<ref id="pone.0014465-Warrington3"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Warrington</surname><given-names>EK</given-names></name>
<name name-style="western"><surname>McCarthy</surname><given-names>RA</given-names></name>
</person-group>             <year>1987</year>             <article-title>Categories of knowledge. Further fractionations and an attempted integration.</article-title>             <source>Brain</source>             <volume>110</volume>             <issue>Pt 5</issue>             <fpage>1273</fpage>             <lpage>1296</lpage>          </element-citation></ref>
<ref id="pone.0014465-Caramazza1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Caramazza</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Mahon</surname><given-names>BZ</given-names></name>
</person-group>             <year>2003</year>             <article-title>The organization of conceptual knowledge: the evidence from category-specific semantic deficits.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>354</fpage>             <lpage>361</lpage>          </element-citation></ref>
<ref id="pone.0014465-Patterson1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Patterson</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Nestor</surname><given-names>PJ</given-names></name>
<name name-style="western"><surname>Rogers</surname><given-names>TT</given-names></name>
</person-group>             <year>2007</year>             <article-title>Where do you know what you know? The representation of semantic knowledge in the human brain.</article-title>             <source>Nat Rev Neurosci</source>             <volume>8</volume>             <fpage>976</fpage>             <lpage>987</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mahon1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mahon</surname><given-names>BZ</given-names></name>
<name name-style="western"><surname>Caramazza</surname><given-names>A</given-names></name>
</person-group>             <year>2009</year>             <article-title>Concepts and categories: a cognitive neuropsychological perspective.</article-title>             <source>Annu Rev Psychol</source>             <volume>60</volume>             <fpage>27</fpage>             <lpage>51</lpage>          </element-citation></ref>
<ref id="pone.0014465-Gerlach1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gerlach</surname><given-names>C</given-names></name>
</person-group>             <year>2007</year>             <article-title>A review of functional imaging studies on category specificity.</article-title>             <source>J Cogn Neurosci</source>             <volume>19</volume>             <fpage>296</fpage>             <lpage>314</lpage>          </element-citation></ref>
<ref id="pone.0014465-Martin1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Martin</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>The representation of object concepts in the brain.</article-title>             <source>Annu Rev Psychol</source>             <volume>58</volume>             <fpage>25</fpage>             <lpage>45</lpage>          </element-citation></ref>
<ref id="pone.0014465-Binder1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Binder</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Desai</surname><given-names>RH</given-names></name>
<name name-style="western"><surname>Graves</surname><given-names>WW</given-names></name>
<name name-style="western"><surname>Conant</surname><given-names>LL</given-names></name>
</person-group>             <year>2009</year>             <article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies.</article-title>             <source>Cereb Cortex</source>             <volume>19</volume>             <fpage>2767</fpage>             <lpage>2796</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kanwisher1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>
<name name-style="western"><surname>McDermott</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Chun</surname><given-names>MM</given-names></name>
</person-group>             <year>1997</year>             <article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>4302</fpage>             <lpage>4311</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kanwisher2"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name>
</person-group>             <year>2006</year>             <article-title>The fusiform face area: a cortical region specialized for the perception of faces.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>361</volume>             <fpage>2109</fpage>             <lpage>2128</lpage>          </element-citation></ref>
<ref id="pone.0014465-Perani1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Perani</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Cappa</surname><given-names>SF</given-names></name>
<name name-style="western"><surname>Bettinardi</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Bressi</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Gorno-Tempini</surname><given-names>M</given-names></name>
<etal/></person-group>             <year>1995</year>             <article-title>Different neural systems for the recognition of animals and man-made tools.</article-title>             <source>Neuroreport</source>             <volume>6</volume>             <fpage>1637</fpage>             <lpage>1641</lpage>          </element-citation></ref>
<ref id="pone.0014465-Chao1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chao</surname><given-names>LL</given-names></name>
<name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>
<name name-style="western"><surname>Martin</surname><given-names>A</given-names></name>
</person-group>             <year>1999</year>             <article-title>Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects.</article-title>             <source>Nat Neurosci</source>             <volume>2</volume>             <fpage>913</fpage>             <lpage>919</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mahon2"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mahon</surname><given-names>BZ</given-names></name>
<name name-style="western"><surname>Milleville</surname><given-names>SC</given-names></name>
<name name-style="western"><surname>Negri</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Rumiati</surname><given-names>RI</given-names></name>
<name name-style="western"><surname>Caramazza</surname><given-names>A</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Action-related properties shape object representations in the ventral stream.</article-title>             <source>Neuron</source>             <volume>55</volume>             <fpage>507</fpage>             <lpage>520</lpage>          </element-citation></ref>
<ref id="pone.0014465-Noppeney1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Noppeney</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Price</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name>
<name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>
</person-group>             <year>2006</year>             <article-title>Two distinct neural mechanisms for category-selective responses.</article-title>             <source>Cereb Cortex</source>             <volume>16</volume>             <fpage>437</fpage>             <lpage>445</lpage>          </element-citation></ref>
<ref id="pone.0014465-Tyler1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tyler</surname><given-names>LK</given-names></name>
<name name-style="western"><surname>Stamatakis</surname><given-names>EA</given-names></name>
<name name-style="western"><surname>Dick</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Bright</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Fletcher</surname><given-names>P</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Objects and their actions: evidence for a neurally distributed semantic system.</article-title>             <source>Neuroimage</source>             <volume>18</volume>             <fpage>542</fpage>             <lpage>557</lpage>          </element-citation></ref>
<ref id="pone.0014465-Gerlach2"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gerlach</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Law</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Paulson</surname><given-names>OB</given-names></name>
</person-group>             <year>2002</year>             <article-title>When action turns into words. Activation of motor-based knowledge during categorization of manipulable objects.</article-title>             <source>J Cogn Neurosci</source>             <volume>14</volume>             <fpage>1230</fpage>             <lpage>1239</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kiefer1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kiefer</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sim</surname><given-names>EJ</given-names></name>
<name name-style="western"><surname>Herrnberger</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Grothe</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Hoenig</surname><given-names>K</given-names></name>
</person-group>             <year>2008</year>             <article-title>The sound of concepts: four markers for a link between auditory and conceptual brain systems.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>12224</fpage>             <lpage>12230</lpage>          </element-citation></ref>
<ref id="pone.0014465-Hoenig1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hoenig</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Sim</surname><given-names>EJ</given-names></name>
<name name-style="western"><surname>Bochev</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Herrnberger</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Kiefer</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Conceptual flexibility in the human brain: dynamic recruitment of semantic maps from visual, motor, and motion-related areas.</article-title>             <source>J Cogn Neurosci</source>             <volume>20</volume>             <fpage>1799</fpage>             <lpage>1814</lpage>          </element-citation></ref>
<ref id="pone.0014465-Tyler2"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tyler</surname><given-names>LK</given-names></name>
<name name-style="western"><surname>Moss</surname><given-names>HE</given-names></name>
</person-group>             <year>2001</year>             <article-title>Towards a distributed account of conceptual knowledge.</article-title>             <source>Trends Cogn Sci</source>             <volume>5</volume>             <fpage>244</fpage>             <lpage>252</lpage>          </element-citation></ref>
<ref id="pone.0014465-Moss1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Moss</surname><given-names>HE</given-names></name>
<name name-style="western"><surname>Tyler</surname><given-names>LK</given-names></name>
</person-group>             <year>2003</year>             <article-title>Weighing up the facts of category-specific semantic deficits.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>480–1; author reply 481–2</fpage>          </element-citation></ref>
<ref id="pone.0014465-Humphreys1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Humphreys</surname><given-names>GW</given-names></name>
<name name-style="western"><surname>Forde</surname><given-names>EM</given-names></name>
</person-group>             <year>2001</year>             <article-title>Hierarchies, similarity, and interactivity in object recognition: “category-specific” neuropsychological deficits.</article-title>             <source>Behav Brain Sci</source>             <volume>24</volume>             <fpage>453–76; discussion 476</fpage>             <lpage>509</lpage>          </element-citation></ref>
<ref id="pone.0014465-McRae1"><label>23</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McRae</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Cree</surname><given-names>GS</given-names></name>
</person-group>             <year>2002</year>             <article-title>Factors underlying category-specific semantic deficits.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Forde</surname><given-names>EME</given-names></name>
</person-group>             <source>Category specificity in brain and mind</source>             <publisher-loc>Hove, East Sussex</publisher-loc>             <publisher-name>Psychology Press and New York: Taylor &amp; Francis</publisher-name>             <fpage>211</fpage>             <lpage>249</lpage>          </element-citation></ref>
<ref id="pone.0014465-Caramazza2"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Caramazza</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Shelton</surname><given-names>JR</given-names></name>
</person-group>             <year>1998</year>             <article-title>Domain-specific knowledge systems in the brain: The animate-inanimate distinction.</article-title>             <source>J Cogn Neurosci</source>             <volume>10</volume>             <fpage>1</fpage>             <lpage>34</lpage>          </element-citation></ref>
<ref id="pone.0014465-Hanson1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hanson</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Halchenko</surname><given-names>YO</given-names></name>
</person-group>             <year>2008</year>             <article-title>Brain reading using full brain support vector machines for object recognition: there is no “face” identification area.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>486</fpage>             <lpage>503</lpage>          </element-citation></ref>
<ref id="pone.0014465-Haxby1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>
<name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name>
<name name-style="western"><surname>Furey</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Ishai</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Schouten</surname><given-names>JL</given-names></name>
<etal/></person-group>             <year>2001</year>             <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex.</article-title>             <source>Science</source>             <volume>293</volume>             <fpage>2425</fpage>             <lpage>2430</lpage>          </element-citation></ref>
<ref id="pone.0014465-Norman1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name>
<name name-style="western"><surname>Polyn</surname><given-names>SM</given-names></name>
<name name-style="western"><surname>Detre</surname><given-names>GJ</given-names></name>
<name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>
</person-group>             <year>2006</year>             <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data.</article-title>             <source>Trends Cogn Sci</source>             <volume>10</volume>             <fpage>424</fpage>             <lpage>430</lpage>          </element-citation></ref>
<ref id="pone.0014465-Shinkareva1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shinkareva</surname><given-names>SV</given-names></name>
<name name-style="western"><surname>Mason</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Malave</surname><given-names>VL</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Mitchell</surname><given-names>TM</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Using FMRI brain activation to identify cognitive states associated with perception of tools and dwellings.</article-title>             <source>PLoS One</source>             <volume>3</volume>             <fpage>e1394</fpage>          </element-citation></ref>
<ref id="pone.0014465-Haynes1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haynes</surname><given-names>JD</given-names></name>
<name name-style="western"><surname>Rees</surname><given-names>G</given-names></name>
</person-group>             <year>2006</year>             <article-title>Decoding mental states from brain activity in humans.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>523</fpage>             <lpage>534</lpage>          </element-citation></ref>
<ref id="pone.0014465-vanGerven1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Gerven</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Cseke</surname><given-names>B</given-names></name>
<name name-style="western"><surname>de Lange</surname><given-names>FP</given-names></name>
<name name-style="western"><surname>Heskes</surname><given-names>T</given-names></name>
</person-group>             <year>2010</year>             <article-title>Efficient Bayesian multivariate fMRI analysis using a sparsifying spatio-temporal prior.</article-title>             <source>Neuroimage</source>             <volume>50</volume>             <fpage>150</fpage>             <lpage>161</lpage>          </element-citation></ref>
<ref id="pone.0014465-Pulvermller1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pulvermüller</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Lutzenberger</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Preissl</surname><given-names>H</given-names></name>
</person-group>             <year>1999</year>             <article-title>Nouns and verbs in the intact brain: evidence from event-related potentials and high-frequency cortical responses.</article-title>             <source>Cereb Cortex</source>             <volume>9</volume>             <fpage>497</fpage>             <lpage>506</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kiefer2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kiefer</surname><given-names>M</given-names></name>
</person-group>             <year>2001</year>             <article-title>Perceptual and semantic sources of category-specific effects: event-related potentials during picture and word categorization.</article-title>             <source>Mem Cognit</source>             <volume>29</volume>             <fpage>100</fpage>             <lpage>116</lpage>          </element-citation></ref>
<ref id="pone.0014465-PazCaballero1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Paz-Caballero</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Cuetos</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Dobarro</surname><given-names>A</given-names></name>
</person-group>             <year>2006</year>             <article-title>Electrophysiological evidence for a natural/artifactual dissociation.</article-title>             <source>Brain Res</source>             <volume>1067</volume>             <fpage>189</fpage>             <lpage>200</lpage>          </element-citation></ref>
<ref id="pone.0014465-Proverbio1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>Del Zotto</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Zani</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>The emergence of semantic categorization in early visual processing: ERP indices of animal vs. artifact recognition.</article-title>             <source>BMC Neurosci</source>             <volume>8</volume>             <fpage>24</fpage>          </element-citation></ref>
<ref id="pone.0014465-Fuggetta1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fuggetta</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Rizzo</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Pobric</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Lavidor</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Walsh</surname><given-names>V</given-names></name>
</person-group>             <year>2009</year>             <article-title>Functional representation of living and nonliving domains across the cerebral hemispheres: a combined event-related potential/transcranial magnetic stimulation study.</article-title>             <source>J Cogn Neurosci</source>             <volume>21</volume>             <fpage>403</fpage>             <lpage>414</lpage>          </element-citation></ref>
<ref id="pone.0014465-Adorni1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adorni</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name>
</person-group>             <year>2009</year>             <article-title>New insights into name category-related effects: is the Age of Acquisition a possible factor?</article-title>             <source>Behav Brain Funct</source>             <volume>5</volume>             <fpage>33</fpage>          </element-citation></ref>
<ref id="pone.0014465-Mller1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Müller</surname><given-names>KR</given-names></name>
<name name-style="western"><surname>Tangermann</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Dornhege</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Krauledat</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Curio</surname><given-names>G</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Machine learning for real-time single-trial EEG-analysis: from brain-computer interfacing to mental state monitoring.</article-title>             <source>J Neurosci Methods</source>             <volume>167</volume>             <fpage>82</fpage>             <lpage>90</lpage>          </element-citation></ref>
<ref id="pone.0014465-Szekely1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Szekely</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Jacobsen</surname><given-names>T</given-names></name>
<name name-style="western"><surname>D'Amico</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Devescovi</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Andonova</surname><given-names>E</given-names></name>
<etal/></person-group>             <year>2004</year>             <article-title>A new on-line resource for psycholinguistic studies.</article-title>             <source>J Mem Lang</source>             <volume>51</volume>             <fpage>247</fpage>             <lpage>250</lpage>          </element-citation></ref>
<ref id="pone.0014465-Burges1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Burges</surname><given-names>CJC</given-names></name>
</person-group>             <year>1998</year>             <article-title>A tutorial on support vector machines for pattern recognition.</article-title>             <source>Data mining and knowledge discovery</source>             <volume>2</volume>             <fpage>121</fpage>             <lpage>167</lpage>          </element-citation></ref>
<ref id="pone.0014465-Thrun1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Thrun</surname><given-names>S</given-names></name>
</person-group>             <year>1996</year>             <article-title>Is learning the n-th thing any easier than learning the first?</article-title>             <source>Processing Systems</source>             <publisher-name>The MIT Press</publisher-name>             <fpage>640</fpage>             <lpage>646</lpage>          </element-citation></ref>
<ref id="pone.0014465-Grainger1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Grainger</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Holcomb</surname><given-names>PJ</given-names></name>
</person-group>             <year>2009</year>             <article-title>Watching the Word Go by: On the Time-course of Component Processes in Visual Word Recognition.</article-title>             <source>Lang Linguist Compass</source>             <volume>3</volume>             <fpage>128</fpage>             <lpage>156</lpage>          </element-citation></ref>
<ref id="pone.0014465-Dien1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dien</surname><given-names>J</given-names></name>
</person-group>             <year>2009</year>             <article-title>The neurocognitive basis of reading single words as seen through early latency ERPs: a model of converging pathways.</article-title>             <source>Biol Psychol</source>             <volume>80</volume>             <fpage>10</fpage>             <lpage>22</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mazerolle1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mazerolle</surname><given-names>EL</given-names></name>
<name name-style="western"><surname>D'Arcy</surname><given-names>RC</given-names></name>
<name name-style="western"><surname>Marchand</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Bolster</surname><given-names>RB</given-names></name>
</person-group>             <year>2007</year>             <article-title>ERP assessment of functional status in the temporal lobe: examining spatiotemporal correlates of object recognition.</article-title>             <source>Int J Psychophysiol</source>             <volume>66</volume>             <fpage>81</fpage>             <lpage>92</lpage>          </element-citation></ref>
<ref id="pone.0014465-Liu1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Liu</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Agam</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Madsen</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Kreiman</surname><given-names>G</given-names></name>
</person-group>             <year>2009</year>             <article-title>Timing, timing, timing: fast decoding of object information from intracranial field potentials in human visual cortex.</article-title>             <source>Neuron</source>             <volume>62</volume>             <fpage>281</fpage>             <lpage>290</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kiefer3"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kiefer</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>Repetition-priming modulates category-related effects on event-related potentials: further evidence for multiple cortical semantic systems.</article-title>             <source>J Cogn Neurosci</source>             <volume>17</volume>             <fpage>199</fpage>             <lpage>211</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mangun1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mangun</surname><given-names>GR</given-names></name>
<name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name>
</person-group>             <year>1991</year>             <article-title>Modulations of sensory-evoked brain potentials indicate changes in perceptual processing during visual-spatial priming.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>17</volume>             <fpage>1057</fpage>             <lpage>1074</lpage>          </element-citation></ref>
<ref id="pone.0014465-Tanaka1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tanaka</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Luu</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Weisbrod</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kiefer</surname><given-names>M</given-names></name>
</person-group>             <year>1999</year>             <article-title>Tracking the time course of object categorization using event-related potentials.</article-title>             <source>Neuroreport</source>             <volume>10</volume>             <fpage>829</fpage>             <lpage>835</lpage>          </element-citation></ref>
<ref id="pone.0014465-Pernet1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pernet</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Basan</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Doyon</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Cardebat</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Démonet</surname><given-names>JF</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Neural timing of visual implicit categorization.</article-title>             <source>Brain Res Cogn Brain Res</source>             <volume>17</volume>             <fpage>327</fpage>             <lpage>338</lpage>          </element-citation></ref>
<ref id="pone.0014465-Large1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Large</surname><given-names>ME</given-names></name>
<name name-style="western"><surname>Kiss</surname><given-names>I</given-names></name>
<name name-style="western"><surname>McMullen</surname><given-names>PA</given-names></name>
</person-group>             <year>2004</year>             <article-title>Electrophysiological correlates of object categorization: back to basics.</article-title>             <source>Brain Res Cogn Brain Res</source>             <volume>20</volume>             <fpage>415</fpage>             <lpage>426</lpage>          </element-citation></ref>
<ref id="pone.0014465-Vogel1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vogel</surname><given-names>EK</given-names></name>
<name name-style="western"><surname>Luck</surname><given-names>SJ</given-names></name>
</person-group>             <year>2000</year>             <article-title>The visual N1 component as an index of a discrimination process.</article-title>             <source>Psychophysiology</source>             <volume>37</volume>             <fpage>190</fpage>             <lpage>203</lpage>          </element-citation></ref>
<ref id="pone.0014465-Arnott1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Arnott</surname><given-names>SR</given-names></name>
<name name-style="western"><surname>Pratt</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Shore</surname><given-names>DI</given-names></name>
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
</person-group>             <year>2001</year>             <article-title>Attentional set modulates visual areas: an event-related potential study of attentional capture.</article-title>             <source>Brain Res Cogn Brain Res</source>             <volume>12</volume>             <fpage>383</fpage>             <lpage>395</lpage>          </element-citation></ref>
<ref id="pone.0014465-Hyde1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hyde</surname><given-names>M</given-names></name>
</person-group>             <year>1997</year>             <article-title>The N1 response and its applications.</article-title>             <source>Audiol Neurootol</source>             <volume>2</volume>             <fpage>281</fpage>             <lpage>307</lpage>          </element-citation></ref>
<ref id="pone.0014465-Ntnen1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Näätänen</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Picton</surname><given-names>T</given-names></name>
</person-group>             <year>1987</year>             <article-title>The N1 wave of the human electric and magnetic response to sound: a review and an analysis of the component structure.</article-title>             <source>Psychophysiology</source>             <volume>24</volume>             <fpage>375</fpage>             <lpage>425</lpage>          </element-citation></ref>
<ref id="pone.0014465-Alcaini1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alcaini</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Giard</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Thévenet</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Pernier</surname><given-names>J</given-names></name>
</person-group>             <year>1994</year>             <article-title>Two separate frontal components in the N1 wave of the human auditory evoked response.</article-title>             <source>Psychophysiology</source>             <volume>31</volume>             <fpage>611</fpage>             <lpage>615</lpage>          </element-citation></ref>
<ref id="pone.0014465-Pulvermller2"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pulvermüller</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Härle</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Hummel</surname><given-names>F</given-names></name>
</person-group>             <year>2001</year>             <article-title>Walking or talking? Behavioral and neurophysiological correlates of action verb processing.</article-title>             <source>Brain Lang</source>             <volume>78</volume>             <fpage>143</fpage>             <lpage>168</lpage>          </element-citation></ref>
<ref id="pone.0014465-Assadollahi1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Assadollahi</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Pulvermüller</surname><given-names>F</given-names></name>
</person-group>             <year>2001</year>             <article-title>Neuromagnetic evidence for early access to cognitive representations.</article-title>             <source>Neuroreport</source>             <volume>12</volume>             <fpage>207</fpage>             <lpage>213</lpage>          </element-citation></ref>
<ref id="pone.0014465-Sereno1"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sereno</surname><given-names>SC</given-names></name>
<name name-style="western"><surname>Rayner</surname><given-names>K</given-names></name>
</person-group>             <year>2003</year>             <article-title>Measuring word recognition in reading: eye movements and event-related potentials.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>489</fpage>             <lpage>493</lpage>          </element-citation></ref>
<ref id="pone.0014465-Hauk1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hauk</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Davis</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Ford</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Pulvermüller</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Marslen-Wilson</surname><given-names>WD</given-names></name>
</person-group>             <year>2006</year>             <article-title>The time course of visual word recognition as revealed by linear regression analysis of ERP data.</article-title>             <source>Neuroimage</source>             <volume>30</volume>             <fpage>1383</fpage>             <lpage>1400</lpage>          </element-citation></ref>
<ref id="pone.0014465-Barber1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barber</surname><given-names>HA</given-names></name>
<name name-style="western"><surname>Kutas</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Interplay between computational models and cognitive electrophysiology in visual word recognition.</article-title>             <source>Brain Res Rev</source>             <volume>53</volume>             <fpage>98</fpage>             <lpage>123</lpage>          </element-citation></ref>
<ref id="pone.0014465-Hauk2"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hauk</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Shtyrov</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Pulvermüller</surname><given-names>F</given-names></name>
</person-group>             <year>2008</year>             <article-title>The time course of action and action-word comprehension in the human brain as revealed by neurophysiology.</article-title>             <source>J Physiol Paris</source>             <volume>102</volume>             <fpage>50</fpage>             <lpage>58</lpage>          </element-citation></ref>
<ref id="pone.0014465-Sahin1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sahin</surname><given-names>NT</given-names></name>
<name name-style="western"><surname>Pinker</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Cash</surname><given-names>SS</given-names></name>
<name name-style="western"><surname>Schomer</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Halgren</surname><given-names>E</given-names></name>
</person-group>             <year>2009</year>             <article-title>Sequential processing of lexical, grammatical, and phonological information within Broca's area.</article-title>             <source>Science</source>             <volume>326</volume>             <fpage>445</fpage>             <lpage>449</lpage>          </element-citation></ref>
<ref id="pone.0014465-McCandliss1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McCandliss</surname><given-names>BD</given-names></name>
<name name-style="western"><surname>Cohen</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Dehaene</surname><given-names>S</given-names></name>
</person-group>             <year>2003</year>             <article-title>The visual word form area: expertise for reading in the fusiform gyrus.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>293</fpage>             <lpage>299</lpage>          </element-citation></ref>
<ref id="pone.0014465-Devlin1"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Devlin</surname><given-names>JT</given-names></name>
<name name-style="western"><surname>Jamison</surname><given-names>HL</given-names></name>
<name name-style="western"><surname>Gonnerman</surname><given-names>LM</given-names></name>
<name name-style="western"><surname>Matthews</surname><given-names>PM</given-names></name>
</person-group>             <year>2006</year>             <article-title>The role of the posterior fusiform gyrus in reading.</article-title>             <source>J Cogn Neurosci</source>             <volume>18</volume>             <fpage>911</fpage>             <lpage>922</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kutas1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kutas</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name>
</person-group>             <year>1980</year>             <article-title>Reading senseless sentences: brain potentials reflect semantic incongruity.</article-title>             <source>Science</source>             <volume>207</volume>             <fpage>203</fpage>             <lpage>205</lpage>          </element-citation></ref>
<ref id="pone.0014465-Martin2"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Martin</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Chao</surname><given-names>LL</given-names></name>
</person-group>             <year>2001</year>             <article-title>Semantic memory and the brain: structure and processes.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>11</volume>             <fpage>194</fpage>             <lpage>201</lpage>          </element-citation></ref>
<ref id="pone.0014465-Thorpe1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Thorpe</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Fize</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Marlot</surname><given-names>C</given-names></name>
</person-group>             <year>1996</year>             <article-title>Speed of processing in the human visual system.</article-title>             <source>Nature</source>             <volume>381</volume>             <fpage>520</fpage>             <lpage>522</lpage>          </element-citation></ref>
<ref id="pone.0014465-VanRullen1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>VanRullen</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name>
</person-group>             <year>2001</year>             <article-title>The time course of visual processing: from early perception to decision-making.</article-title>             <source>J Cogn Neurosci</source>             <volume>13</volume>             <fpage>454</fpage>             <lpage>461</lpage>          </element-citation></ref>
<ref id="pone.0014465-Tarr1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tarr</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Cheng</surname><given-names>YD</given-names></name>
</person-group>             <year>2003</year>             <article-title>Learning to see faces and objects.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>23</fpage>             <lpage>30</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mace1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mace</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Joubert</surname><given-names>OR</given-names></name>
<name name-style="western"><surname>Nespoulous</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Fabre-Thorpe</surname><given-names>M</given-names></name>
</person-group>             <year>2009</year>             <article-title>The time-course of visual categorizations: you spot the animal faster than the bird.</article-title>             <source>PLoS One</source>             <volume>4</volume>             <fpage>e5927</fpage>          </element-citation></ref>
<ref id="pone.0014465-Kirchner1"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kirchner</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name>
</person-group>             <year>2006</year>             <article-title>Ultra-rapid object detection with saccadic eye movements: visual processing speed revisited.</article-title>             <source>Vision Res</source>             <volume>46</volume>             <fpage>1762</fpage>             <lpage>1776</lpage>          </element-citation></ref>
<ref id="pone.0014465-New1"><label>71</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>New</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Cosmides</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Tooby</surname><given-names>J</given-names></name>
</person-group>             <year>2007</year>             <article-title>Category-specific attention for animals reflects ancestral priorities, not expertise.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>16598</fpage>             <lpage>16603</lpage>          </element-citation></ref>
<ref id="pone.0014465-LloydJones1"><label>72</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lloyd-Jones</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Humphreys</surname><given-names>GW</given-names></name>
</person-group>             <year>1997</year>             <article-title>Perceptual differentiation as a source of category effects in object processing: evidence from naming and object decision.</article-title>             <source>Mem Cognit</source>             <volume>25</volume>             <fpage>18</fpage>             <lpage>35</lpage>          </element-citation></ref>
<ref id="pone.0014465-Pinto1"><label>73</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pinto</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Cox</surname><given-names>DD</given-names></name>
<name name-style="western"><surname>DiCarlo</surname><given-names>JJ</given-names></name>
</person-group>             <year>2008</year>             <article-title>Why is real-world visual object recognition hard?</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>e27</fpage>          </element-citation></ref>
<ref id="pone.0014465-vanGerven2"><label>74</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Gerven</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Farquhar</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Schaefer</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Vlek</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Geuze</surname><given-names>J</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>The brain-computer interface cycle.</article-title>             <source>J Neural Eng</source>             <volume>6</volume>             <fpage>041001</fpage>          </element-citation></ref>
<ref id="pone.0014465-Roland1"><label>75</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roland</surname><given-names>PE</given-names></name>
<name name-style="western"><surname>Gulyás</surname><given-names>B</given-names></name>
</person-group>             <year>1995</year>             <article-title>Visual memory, visual imagery, and visual recognition of large field patterns by the human brain: functional anatomy by positron emission tomography.</article-title>             <source>Cereb Cortex</source>             <volume>5</volume>             <fpage>79</fpage>             <lpage>93</lpage>          </element-citation></ref>
<ref id="pone.0014465-Mellet1"><label>76</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mellet</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Petit</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Mazoyer</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Denis</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Tzourio</surname><given-names>N</given-names></name>
</person-group>             <year>1998</year>             <article-title>Reopening the mental imagery debate: lessons from functional anatomy.</article-title>             <source>Neuroimage</source>             <volume>8</volume>             <fpage>129</fpage>             <lpage>139</lpage>          </element-citation></ref>
<ref id="pone.0014465-Thirion1"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Thirion</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Duchesnay</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Hubbard</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Dubois</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Poline</surname><given-names>JB</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>Inverse retinotopy: inferring the visual content of images from brain activation patterns.</article-title>             <source>Neuroimage</source>             <volume>33</volume>             <fpage>1104</fpage>             <lpage>1116</lpage>          </element-citation></ref>
<ref id="pone.0014465-Stokes1"><label>78</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stokes</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Thompson</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Cusack</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Duncan</surname><given-names>J</given-names></name>
</person-group>             <year>2009</year>             <article-title>Top-down activation of shape-specific population codes in visual cortex during mental imagery.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>1565</fpage>             <lpage>1572</lpage>          </element-citation></ref>
<ref id="pone.0014465-Reddy1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reddy</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Tsuchiya</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Serre</surname><given-names>T</given-names></name>
</person-group>             <year>2010</year>             <article-title>Reading the mind's eye: decoding category information during mental imagery.</article-title>             <source>Neuroimage</source>             <volume>50</volume>             <fpage>818</fpage>             <lpage>825</lpage>          </element-citation></ref>
<ref id="pone.0014465-Ferreira1"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ferreira</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Bailey</surname><given-names>KGD</given-names></name>
<name name-style="western"><surname>Ferraro</surname><given-names>V</given-names></name>
</person-group>             <year>2002</year>             <article-title>Good-Enough Representations in Language Comprehension.</article-title>             <source>Current Directions in Psychological Science</source>             <volume>11</volume>             <fpage>11</fpage>             <lpage>15</lpage>          </element-citation></ref>
<ref id="pone.0014465-Sturt1"><label>81</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sturt</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Sanford</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>Stewart</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Dawydiak</surname><given-names>E</given-names></name>
</person-group>             <year>2004</year>             <article-title>Linguistic focus and good-enough representations: an application of the change-detection paradigm.</article-title>             <source>Psychon Bull Rev</source>             <volume>11</volume>             <fpage>882</fpage>             <lpage>888</lpage>          </element-citation></ref>
<ref id="pone.0014465-Chao2"><label>82</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chao</surname><given-names>LL</given-names></name>
<name name-style="western"><surname>Weisberg</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Martin</surname><given-names>A</given-names></name>
</person-group>             <year>2002</year>             <article-title>Experience-dependent modulation of category-related cortical activity.</article-title>             <source>Cereb Cortex</source>             <volume>12</volume>             <fpage>545</fpage>             <lpage>551</lpage>          </element-citation></ref>
<ref id="pone.0014465-Price1"><label>83</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Price</surname><given-names>CJ</given-names></name>
</person-group>             <year>2004</year>             <article-title>An Overview of Speech Comprehension and Production.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Frackowiak</surname><given-names>RSJ</given-names></name>
<name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>
</person-group>             <source>Human brain function</source>             <publisher-loc>Amsterdam; Boston</publisher-loc>             <publisher-name>Elsevier Academic Press</publisher-name>             <fpage>517</fpage>             <lpage>533</lpage>          </element-citation></ref>
<ref id="pone.0014465-Vandenberghe1"><label>84</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vandenberghe</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Price</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Wise</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Frackowiak</surname><given-names>RS</given-names></name>
</person-group>             <year>1996</year>             <article-title>Functional anatomy of a common semantic system for words and pictures.</article-title>             <source>Nature</source>             <volume>383</volume>             <fpage>254</fpage>             <lpage>256</lpage>          </element-citation></ref>
<ref id="pone.0014465-Bright1"><label>85</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bright</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Moss</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Tyler</surname><given-names>LK</given-names></name>
</person-group>             <year>2004</year>             <article-title>Unitary vs multiple semantics: PET studies of word and picture processing.</article-title>             <source>Brain Lang</source>             <volume>89</volume>             <fpage>417</fpage>             <lpage>432</lpage>          </element-citation></ref>
<ref id="pone.0014465-Kircher1"><label>86</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kircher</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Sass</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Sachs</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Krach</surname><given-names>S</given-names></name>
</person-group>             <year>2009</year>             <article-title>Priming words with pictures: neural correlates of semantic associations in a cross-modal priming task using fMRI.</article-title>             <source>Hum Brain Mapp</source>             <volume>30</volume>             <fpage>4116</fpage>             <lpage>4128</lpage>          </element-citation></ref>
<ref id="pone.0014465-VanDoren1"><label>87</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Van Doren</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Dupont</surname><given-names>P</given-names></name>
<name name-style="western"><surname>De Grauwe</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Peeters</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Vandenberghe</surname><given-names>R</given-names></name>
</person-group>             <year>2010</year>             <article-title>The amodal system for conscious word and picture identification in the absence of a semantic task.</article-title>             <source>Neuroimage</source>             <volume>49</volume>             <fpage>3295</fpage>             <lpage>3307</lpage>          </element-citation></ref>
<ref id="pone.0014465-Barsalou1"><label>88</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barsalou</surname><given-names>LW</given-names></name>
<name name-style="western"><surname>Kyle Simmons</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Barbey</surname><given-names>AK</given-names></name>
<name name-style="western"><surname>Wilson</surname><given-names>CD</given-names></name>
</person-group>             <year>2003</year>             <article-title>Grounding conceptual knowledge in modality-specific systems.</article-title>             <source>Trends Cogn Sci</source>             <volume>7</volume>             <fpage>84</fpage>             <lpage>91</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>