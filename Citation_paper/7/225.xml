<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">08-PONE-RA-05866R1</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0003536</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience</subject><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Experimental Psychology</subject></subj-group></article-categories><title-group><article-title>Neural Correlates of Enhanced Visual Short-Term Memory for Angry Faces: An fMRI Study</article-title><alt-title alt-title-type="running-head">Enhanced VSTM for Angry Faces</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Jackson</surname><given-names>Margaret C.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Wolf</surname><given-names>Claudia</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Johnston</surname><given-names>Stephen J.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Raymond</surname><given-names>Jane E.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Linden</surname><given-names>David E. J.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group><aff id="aff1">          <addr-line>School of Psychology, Bangor University, Bangor, Gwynedd, United Kingdom</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Whitney</surname><given-names>David</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University of California Davis, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">m.jackson@bangor.ac.uk</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: MCJ SJJ JR DEJL. Performed the experiments: MCJ CW SJJ. Analyzed the data: MCJ CW DEJL. Wrote the paper: MCJ JR DEJL.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2008</year></pub-date><pub-date pub-type="epub"><day>29</day><month>10</month><year>2008</year></pub-date><volume>3</volume><issue>10</issue><elocation-id>e3536</elocation-id><history>
<date date-type="received"><day>7</day><month>8</month><year>2008</year></date>
<date date-type="accepted"><day>1</day><month>10</month><year>2008</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder>Jackson et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><sec>
<title>Background</title>
<p>Fluid and effective social communication requires that both face identity and emotional expression information are encoded and maintained in visual short-term memory (VSTM) to enable a coherent, ongoing picture of the world and its players. This appears to be of particular evolutionary importance when confronted with potentially threatening displays of emotion - previous research has shown better VSTM for angry versus happy or neutral face identities.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>Using functional magnetic resonance imaging, here we investigated the neural correlates of this angry face benefit in VSTM. Participants were shown between one and four to-be-remembered angry, happy, or neutral faces, and after a short retention delay they stated whether a single probe face had been present or not in the previous display. All faces in any one display expressed the same emotion, and the task required memory for face identity. We find enhanced VSTM for angry face identities and describe the right hemisphere brain network underpinning this effect, which involves the globus pallidus, superior temporal sulcus, and frontal lobe. Increased activity in the globus pallidus was significantly correlated with the angry benefit in VSTM. Areas modulated by emotion were distinct from those modulated by memory load.</p>
</sec><sec>
<title>Conclusions/Significance</title>
<p>Our results provide evidence for a key role of the basal ganglia as an interface between emotion and cognition, supported by a frontal, temporal, and occipital network.</p>
</sec></abstract><funding-group><funding-statement>MCJ and DEJL were supported by a Wellcome Trust grant to DEJL (grant number 077185/Z/05/Z). Aspects of this research were also supported by BBSRC (UK) grant BBS/B/16178 to JER and the Wales Institute of Cognitive Neuroscience (WICN).</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Visual short-term memory (VSTM) is an active system that temporarily stores and updates information over a period of a few seconds. It is particularly useful for maintaining a constant and coherent percept of the world in the face of eye, head, and object motion. In contrast, long-term memory (LTM) is a system dedicated to storing information over hours, days, and even decades; it is essential for learning and developing knowledge and skills.</p>
<p>Although it is well established that LTM is enhanced for images with an emotional, particularly negative, content <xref ref-type="bibr" rid="pone.0003536-Dolan1">[1]</xref>–<xref ref-type="bibr" rid="pone.0003536-LaBar1">[3]</xref>, an effect thought to be driven by neural communication between LTM and limbic systems <xref ref-type="bibr" rid="pone.0003536-LaBar2">[4]</xref>, the question of whether information to be retained in VSTM is influenced by its emotional content, and which brain mechanisms might be involved, has received little attention and results are varied. One study found no effect of valence on STM for fearful versus neutral faces, nor for taboo versus neutral words <xref ref-type="bibr" rid="pone.0003536-Kensinger2">[5]</xref>. Two studies using emotive images from the International Affective Picture System (IAPS) found an influence of valence on STM. In one, participants judged the relative emotional intensity (“higher” or “lower”) of two successively presented images that were matched for valence (positive or negative) and were separated by a 3 second retention interval <xref ref-type="bibr" rid="pone.0003536-Mikels1">[6]</xref>. Young participants were more likely to make accurate relativity judgments for negative compared to positive images (accuracy was based on whether judgments matched previously established ratings obtained from an independent group of young participants). The authors interpreted this to reflect enhanced STM for negative images, and report the opposite effect with older participants. However, their task was not a direct test of the effect of valence on STM for visual content per se. In a functional magnetic resonance imaging (fMRI) study, participants were required to state whether a positive, negative, or neutral image seen 11.5 seconds earlier was present or not in an array of nine valence-matched images <xref ref-type="bibr" rid="pone.0003536-Perlstein1">[7]</xref>. Increased activity in dorsolateral prefrontal cortex (DLPFC) and decreased orbitofrontal cortex (OFC) activity was found for positive versus negative images, but these data are difficult to interpret because task accuracy during scanning did not show a difference in STM for positive (65%) versus negative (65%) images. The above studies, while interesting in measuring responses to emotional stimuli, provide little clear insight into whether visual information with an emotional content can influence VSTM and, if so, what brain mechanisms might be involved. [Note that because our aim is to measure the neural correlates of information retained in VSTM with an emotional versus neutral content, we do not review here studies of the effect of emotional distraction or induced mood state on VSTM for neutral stimuli.]</p>
<p>Previous behavioural research of ours <xref ref-type="bibr" rid="pone.0003536-Jackson1">[8]</xref> has shown that VSTM for face identities is significantly enhanced when faces display an angry compared to a happy or neutral expression. We replicated this result a number of times and were able to eliminate several possible accounts of the effect. We showed that that the anger benefit for faces in VSTM was not due to low-level feature recognition: inverting the faces abolished the effect; a perceptual discrimination task in which participants stated whether two faces matched identity or not showed no difference in accuracy or reaction time between angry, happy, or neutral face conditions. We also showed that heightened physiological arousal is unlikely to underpin the effect: the presence of calming or energizing background music during the task did not differentially influence VSTM nor interact with emotional expression conditions, suggesting that enhanced VSTM for angry faces is valence-driven. Perceptual encoding limitations were excluded as an account because the angry benefit remained present when the original study time of 2000 ms was doubled. Finally, the effect was replicated using a different set of faces from another database that were also equated for expression intensity, providing evidence that enhanced VSTM for angry faces is not specific to the faces used, nor due to the potential for angry faces to be more intense in expression than happy or neutral faces.</p>
<p>In the current study, we again used angry, happy, and neutral faces to investigate the neural correlates of VSTM for information with an emotional versus neutral content. Faces are well suited for this purpose because not only are they ecologically valid, they also allow the presentation of differently valenced emotional information in the same individual exemplars. This reduces variability of low-level featural information among different emotion conditions, a factor that may have confounded results of previous studies using IAPS pictures <xref ref-type="bibr" rid="pone.0003536-Davidson1">[9]</xref>. Another person's emotional facial expression can convey critical information about his/her internal mood state and, in turn, affect one's own behavioral decisions, e.g., whether to approach or avoid, or what manner of speech to adopt. Successful and appropriate face-to-face interactions depend not only on recognition of emotional expression, but often also require accurate face identification. Critically, our ability to select an appropriate social response in a timely and effective manner depends on our ability to identify who is expressing what emotion, and this information must be retained in memory for a period sufficient to develop an action plan. Thus, storage of face identity information in VSTM forms a crucial bridge between immediate encoding of emotionally charged information and execution of appropriate behavior.</p>
<p>Here, during fMRI participants were required to memorize between one and four angry, happy, or neutral faces for 2,000 ms (the number of faces to be remembered is termed <italic>face load</italic>), and one second later they were asked to report whether a single face probe matched in identity to one of the previous to-be-remembered faces or not (<xref ref-type="fig" rid="pone-0003536-g001">Fig. 1</xref>). All faces (at both encoding and retrieval) in any one trial displayed the same emotion, thus emotional expression of the to-be-remembered faces was task-irrelevant. Our aim was to specifically examine the neural correlates of the angry benefit for faces in VSTM and determine how emotion and memory systems in the brain might interact to produce this effect. By manipulating face load, we were also able to examine any interactions between load and expression conditions. We predicted that the angry face benefit in VSTM is likely to recruit an interplay of brain regions involved in emotion processing, such as the amygdala, basal ganglia, and insula <xref ref-type="bibr" rid="pone.0003536-Davidson1">[9]</xref>–<xref ref-type="bibr" rid="pone.0003536-Stein1">[11]</xref>, short-term memory, such as the prefrontal cortex <xref ref-type="bibr" rid="pone.0003536-Linden1">[12]</xref>, and face processing, such as the fusiform gyrus <xref ref-type="bibr" rid="pone.0003536-KeslerWest1">[13]</xref> and superior temporal sulcus <xref ref-type="bibr" rid="pone.0003536-Narumoto1">[14]</xref>.</p>
<fig id="pone-0003536-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g001</object-id><label>Figure 1</label><caption>
<title>Here is an example trial procedure (load 3 shown as illustration).</title>
<p>Between one and four faces (all expressing either angry, happy, or neutral emotion) were shown for encoding for 2000 ms, followed by a 1000 ms blank retention/maintenance phase, and a 2000 ms retrieval phase in which participants stated whether a single probe face had been present or not in the previous display. All faces in any one trial (i.e., at encoding and retrieval) displayed the same emotion. A jittered inter-trial interval (ITI) of between 4000 ms and 6500 ms separated each trial.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g001" xlink:type="simple"/></fig></sec><sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Participants</title>
<p>Thirty five right-handed healthy volunteers (mean age 29 years; 15females) from the student and community panels in Bangor participated in return for £20. Subjects reported no history of neurological or psychiatric disorder, had normal or corrected to normal vision, and provided informed written consent prior to participation. The study was approved by the School's ethics committee in Bangor.</p>
</sec><sec id="s2b">
<title>Stimuli</title>
<p>Greyscale face images of six adult males each expressing three emotions (angry, happy, and neutral) were used <xref ref-type="bibr" rid="pone.0003536-Ekman1">[15]</xref>. Each image subtended approximately 1.43°×1.36°. Scrambled greyscale face images, selected at random from a set of eight different scrambled images, were used to fill memory display locations on trials in which fewer than four faces were presented.</p>
</sec><sec id="s2c">
<title>Experimental Procedure</title>
<p>Participants were oriented to the centre of the computer screen by a small fixation cross presented for 1,000 ms and instructed to maintain fixation throughout each session in order to minimize eye movement artefacts in the functional data. To signal the start of a trial, the fixation cross increased in size for 1,000 ms, after which it returned to its original size for another 1,000 ms. On each trial, between one and four faces, each expressing the same emotion (angry, happy, or neutral) were presented for 2,000 ms in a 2×2 memory matrix with fixation at the centre. The centre of each image within the matrix was positioned at a visual angle of approximately 1.27° from fixation to ensure that the faces display was foveal, and thus minimize eye movements. Previous research has established that 2,000 ms is sufficient time to encode four faces <xref ref-type="bibr" rid="pone.0003536-Jackson1">[8]</xref>, <xref ref-type="bibr" rid="pone.0003536-Jackson2">[16]</xref>. On trials in which fewer than four faces were presented, all other matrix locations were occupied by a scrambled face. Face locations were randomised within the matrix. After a 1,000 ms blank retention interval during which only the fixation cross was present, a single face probe (expressing the same emotion as the preceding matrix) was displayed in the centre of the screen for 2,000 ms. Participants were required to state, within the 2,000 ms single probe presentation duration, whether the probe person had been present or not in the immediately preceding display (50% probe present). The task involved an identity decision, thus emotional expression was irrelevant to the task. Participants used their right hand to respond “yes” or “no” using a simple button press. Feedback was not provided. A jittered fixation inter-trial interval (ITI) of between 4,000 and 6,500 ms separated each trial (<xref ref-type="fig" rid="pone-0003536-g001">Figure 1</xref>).</p>
<p>Sixteen experimental trials were presented for each load (1,2,3,4) in each emotion condition (angry, happy, neutral) in a pseudo-random order, resulting in 192 trials in total (event-related design). In order to minimize subject fatigue, the experiment was separated into four separate scanning blocks of 48 trials each, within a single scanning session. Each block lasted approximately 11 minutes. Before the main experiment began, participants were given a short practice session outside the scanner.</p>
</sec><sec id="s2d">
<title>Data Acquisition</title>
<p>Behavioural data were acquired with a 14-inch Dell Latitude D610 laptop (32-bit true colour; resolution 1280×1024 pixels). The tasks were generated by E-Prime software <xref ref-type="bibr" rid="pone.0003536-Schneider1">[17]</xref>. fMRI data were acquired with a Philips 1.5T MRI scanner with a SENSE parallel head coil. We used a gradient echo echoplanar sequence sensitive to the blood oxygen dependent (BOLD) signal (TR = 2,000 ms; TE = 40 ms; matrix size = 96×96; FOV = 256×256 mm<sup>2</sup>; voxel size = 3×3×3 mm<sup>3</sup>; 90° flip angle; 20 axial slices). Two dummy volumes were acquired before each scan block to reduce possible T1 saturation effects. During the VSTM faces task, the fMRI sequence was synchronized with the fixation cross at the start of each trial (see <xref ref-type="fig" rid="pone-0003536-g001">Fig. 1</xref>). Anatomical data was acquired with a high resolution T1-weighted three-dimensional (3D) volume (1×1×1 mm<sup>3</sup>), and used for coregistration of functional data.</p>
</sec><sec id="s2e">
<title>Data Analysis</title>
<sec id="s2e1">
<title>Behavioural Data Analysis</title>
<p>False alarm rates in all emotional expression conditions varied significantly as a function of face load, so we converted hits and false alarms into dprime (d') scores in order to provide a more sensitive measure of signal detection. d' is the z-normalised hit rate (probability of ‘yes’ responses when the probe was present) minus the z-normalised false alarm rate (probability of ‘yes’ responses when the probe was absent) [d' = <sub>z</sub>Hit Rate – <sub>z</sub>False Alarm Rate].</p>
</sec><sec id="s2e2">
<title>FMRI Data Analysis</title>
<p>Functional data were preprocessed and analysed using the BrainVoyager 1.79 software. We applied slice scan time correction using sinc interpolation and ascending slice scanning order, 3D motion correction using trilinear interpolation, spatial smoothing (8 mm Gaussian kernel), and a temporal high pass filter (3 cycles per time course). Three-D anatomical scans were transformed into Talairach space <xref ref-type="bibr" rid="pone.0003536-Talairach1">[18]</xref>, the parameters of which were applied to the coregistered functional data.</p>
<p>All but one subject completed all four VSTM task runs (one subject completed only three runs due to technical scanning problems), and runs that were unsuitable for analysis were excluded from analysis (two runs in each of two subjects revealed head movements greater than 5 mm). In total, 135 z-normalised volume time courses were entered into a whole brain, random effects analysis of covariance (ANCOVA). Motion-corrected covariates were included in the model in order to optimize the elimination of task-correlated motion artifacts and maximize sensitivity to true activations <xref ref-type="bibr" rid="pone.0003536-Johnstone1">[19]</xref>, and to reduce inter- and intra-subject variability <xref ref-type="bibr" rid="pone.0003536-Lund1">[20]</xref>. Functional data from all phases of the VSTM task (excluding the ITI) were entered into the analysis model: no distinctions were made between encoding, maintenance, or retrieval phases. In all analyses, regions of activation were determined using the False Discovery Rate (FDR) significance threshold of &lt;.05. To examine emotional expression effects, we computed a repeated-measures ANCOVA (three within-factor levels: angry, happy, neutral) to assess the main effect of emotion, and we also computed specific emotion contrasts (angry - neutral, angry - happy, happy - neutral). In each identified emotion cluster, we conducted random effects GLM region of interest (ROI) analyses to extract beta values that were subsequently applied to statistical comparisons between emotional expression conditions, and correlated with VSTM task performance values. VSTM load effects were examined by contrasting loads 4, 3, and 2 with load 1. A repeated-measures ANCOVA with emotion and load as within factors assessed whether an emotion by load interaction was present at the whole brain level.</p>
</sec><sec id="s2e3">
<title>Correlation with behavioural data</title>
<p>To examine whether there were any correlations between the magnitude of the angry face effect and brain activity levels, we used the mean behavioural dprime score across all face loads for each emotional expression condition to calculate difference scores for angry minus happy and angry minus neutral face contrasts (based on the angry face advantage observed in the behavioural results). These performance difference scores were correlated with related beta difference scores extracted from emotion-sensitive brain areas. To examine whether there were any correlations between STM capacity and brain activity levels, we calculated Cowan's K capacity estimates at each load [load*(hits – false alarms)] <xref ref-type="bibr" rid="pone.0003536-Cowan1">[21]</xref>, averaged across emotion conditions, with related beta values extracted from load-sensitive brain areas. K and beta values were concatenated across all loads for this statistical comparison. Pearson's correlation coefficient (r<sup>2</sup>) was used in all cases.</p>
</sec></sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Behavioural Results</title>
<p>We conducted an emotion (angry, happy, neutral) by load (1, 2, 3, 4) repeated-measures ANOVA on the behavioural data, expressed in d' values. Consistent with our previous findings <xref ref-type="bibr" rid="pone.0003536-Jackson1">[8]</xref>, we found that VSTM performance was significantly modulated by emotional expression, <italic>F</italic>(2, 68) = 3.17, <italic>p</italic> = .048, and that angry faces were significantly better remembered than happy faces (<italic>p</italic>&lt;.05) (<xref ref-type="fig" rid="pone-0003536-g002">Fig. 2</xref>). It is clear from <xref ref-type="fig" rid="pone-0003536-g002">Figure 2</xref> that the effect of emotional expression appears most pronounced at face loads 2 and 3, likely due to the fact that we can only store about two face identities in VSTM at any one time <xref ref-type="bibr" rid="pone.0003536-Jackson2">[16]</xref>. When only face loads 2 and 3 are analysed, the main effect of emotion becomes more significant (<italic>F</italic>(2, 16) = 4.01, <italic>p</italic> = .02) and the difference between angry and neutral faces also reaches significance (<italic>p</italic>&lt;.05). A significant main effect of face load was observed, <italic>F</italic>(3,102) = 120.38, <italic>p</italic>&lt;.001, but its interaction with emotional expression was not significant, <italic>F</italic>(6, 204)&lt;1.0.</p>
<fig id="pone-0003536-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g002</object-id><label>Figure 2</label><caption>
<title>Behavioural performance on angry, happy, and neutral trials for all four face loads are displayed as d' (dprime) values.</title>
<p>A maximum d' value of 4.66 indicates 100% performance, while a d' value of zero indicates performance at chance (50%). Participants performed significantly better on the VSTM task when the identities of angry faces were to be remembered, compared to happy or neutral faces. VSTM performance declined as face load increased for all emotional expression conditions. Bars represent±1 standard error.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g002" xlink:type="simple"/></fig></sec><sec id="s3b">
<title>Functional Imaging Results</title>
<sec id="s3b1">
<title>Emotion Effects</title>
<p>Using whole-brain analysis of variance (ANOVA), and an FDR significance threshold of <italic>p</italic>&lt;.05, we found a significant main effect of emotion in three areas of the right hemisphere: superior temporal sulcus (STS), prefrontal cortex (PFC) along the anterior inferior frontal sulcus (IFS), and globus pallidus internus (GPi) (<xref ref-type="fig" rid="pone-0003536-g003">Fig. 3a</xref>). Talairach coordinates are provided in <xref ref-type="table" rid="pone-0003536-t001">Table 1</xref>. There was no main effect of emotion in the left hemisphere. ROI analyses revealed that the main effect of emotion in the STS, PFC, and GPi was driven by significantly enhanced blood oxygen level dependent (BOLD) responses to angry faces (in all regions: angry vs. happy, <italic>p</italic>&lt;.001; angry vs. neutral, <italic>p</italic>&lt;.001) (<xref ref-type="fig" rid="pone-0003536-g003">Fig. 3b</xref>). There were no significant differences between happy and neutral face activations in any of these regions (<italic>p</italic>&gt;.54 in all cases).</p>
<fig id="pone-0003536-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g003</object-id><label>Figure 3</label><caption>
<p>(A) Three coronal brain slices show modulation of brain activity by emotional expression of faces in the VSTM task in the superior temporal sulcus (STS), prefrontal cortex (PFC) along the inferior frontal sulcus (IFS), and globus pallidus internus (GPi), all in the right hemisphere. (B) Beta values for each emotion and face load condition are plotted for the STS, PFC, and GPi. Activity is greater for angry vs. happy and neutral face expression conditions in all three brain regions. Bars represent±1 standard error.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g003" xlink:type="simple"/></fig><table-wrap id="pone-0003536-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.t001</object-id><label>Table 1</label><caption>
<title>Talairach coordinates and voxel cluster size values for the main effect of emotion (FDR&lt;.05).</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0003536-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Region of activation</td>
<td align="left" colspan="1" rowspan="1">R/L</td>
<td align="left" colspan="1" rowspan="1">x</td>
<td align="left" colspan="1" rowspan="1">y</td>
<td align="left" colspan="1" rowspan="1">z</td>
<td align="left" colspan="1" rowspan="1">Cluster size (mm<sup>3</sup>)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">STS</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">56</td>
<td align="left" colspan="1" rowspan="1">−52</td>
<td align="left" colspan="1" rowspan="1">7</td>
<td align="left" colspan="1" rowspan="1">1448</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">PFC (IFS)</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">54</td>
<td align="left" colspan="1" rowspan="1">29</td>
<td align="left" colspan="1" rowspan="1">20</td>
<td align="left" colspan="1" rowspan="1">320</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPi</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">16</td>
<td align="left" colspan="1" rowspan="1">−4</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">123</td>
</tr>
</tbody>
</table></alternatives></table-wrap>
<p>The angry minus neutral functional contrast showed the same pattern of activation as the main effect of emotion (higher activity for angry than neutral faces in rSTS, rPFC, and rGPi), but in addition this contrast revealed significantly greater angry vs. neutral activity in bilateral fusiform gyrus (<italic>p</italic>&lt;.001 in both cases) (<xref ref-type="fig" rid="pone-0003536-g004">Fig. 4</xref>). In the right fusiform, analysis of extracted beta values also revealed significantly greater activation for angry vs. happy faces, <italic>p</italic> = .02. There were no load effects in these regions. At whole-brain level, the angry minus happy functional contrast similarly revealed rSTS activity (higher for angry) but did not show any additional regions of activation. No regions showed greater activation for happy vs. neutral faces. Talairach coordinates for the specific emotion contrasts are provided in <xref ref-type="table" rid="pone-0003536-t002">Table 2</xref>.</p>
<fig id="pone-0003536-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g004</object-id><label>Figure 4</label><caption>
<title>Coronal view shows bilateral fusiform activity obtained from the angry minus neutral contrast (regions outlined by black squares).</title>
<p>Activity is greater for angry compared to neutral faces. Bars represent±1 standard error.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g004" xlink:type="simple"/></fig><table-wrap id="pone-0003536-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.t002</object-id><label>Table 2</label><caption>
<title>Talairach coordinates and voxel cluster size values for specific emotion contrasts (FDR&lt;.05).</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0003536-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.t002" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Contrast</td>
<td align="left" colspan="1" rowspan="1">Region of activation</td>
<td align="left" colspan="1" rowspan="1">R/L</td>
<td align="left" colspan="1" rowspan="1">x</td>
<td align="left" colspan="1" rowspan="1">y</td>
<td align="left" colspan="1" rowspan="1">z</td>
<td align="left" colspan="1" rowspan="1">Cluster size (mm<sup>3</sup>)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Angry-Neutral</td>
<td align="left" colspan="1" rowspan="1">STS</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">54</td>
<td align="left" colspan="1" rowspan="1">−54</td>
<td align="left" colspan="1" rowspan="1">6</td>
<td align="left" colspan="1" rowspan="1">2241</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">PFC (IFS)</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">55</td>
<td align="left" colspan="1" rowspan="1">28</td>
<td align="left" colspan="1" rowspan="1">23</td>
<td align="left" colspan="1" rowspan="1">1353</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">GPi</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">16</td>
<td align="left" colspan="1" rowspan="1">−2</td>
<td align="left" colspan="1" rowspan="1">3</td>
<td align="left" colspan="1" rowspan="1">16</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">43</td>
<td align="left" colspan="1" rowspan="1">−43</td>
<td align="left" colspan="1" rowspan="1">−16</td>
<td align="left" colspan="1" rowspan="1">140</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−32</td>
<td align="left" colspan="1" rowspan="1">−42</td>
<td align="left" colspan="1" rowspan="1">−12</td>
<td align="left" colspan="1" rowspan="1">21</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Angry-Happy</td>
<td align="left" colspan="1" rowspan="1">STS</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">57</td>
<td align="left" colspan="1" rowspan="1">−53</td>
<td align="left" colspan="1" rowspan="1">7</td>
<td align="left" colspan="1" rowspan="1">1282</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>The happy minus neutral contrast did not yield any regions of activation at this threshold.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3b2">
<title>Correlation Between Behavioral and Functional data for Emotion Effects</title>
<p>To test whether higher activation for angry faces reflected a generalized increase in response to angry faces or associated arousal levels, or whether it might represent the very brain mechanism that brings about the angry face benefit in VSTM, we investigated the relationship between brain activity and behavioral data. We correlated the behavioral scores (difference in d') for the angry minus happy and angry minus neutral differences with the corresponding beta value differences in each emotion-sensitive region. In GPi, behavioural difference scores significantly correlated with related beta difference scores in the angry-happy contrast, <italic>r</italic><sup>2</sup> = .44, <italic>p</italic> = .01 (<xref ref-type="fig" rid="pone-0003536-g005">Fig. 5a</xref>), and marginally correlated with related beta difference scores in the angry-neutral contrast, <italic>r</italic><sup>2</sup> = .32, <italic>p</italic> = .06 (<xref ref-type="fig" rid="pone-0003536-g005">Fig. 5b</xref>). Superior VSTM for angry faces was thus correlated with enhanced activity in the GPi, suggesting a key role for this region in the angry face benefit. There were no significant correlations between behavioural scores and beta values in STS, PFC, or fusiform regions. Because the behavioural angry vs. neutral benefit was driven by the differences at loads 2 and 3, we re-ran these correlations using just loads 2 and 3. We replicated the angry-neutral contrast marginal correlation between behavioural and brain data in the GPi (<italic>r</italic><sup>2</sup> = .33, <italic>p</italic> = .06), and additionally found a marginally significant angry-neutral contrast correlation in the right FFA (<italic>r</italic><sup>2</sup> = .29, <italic>p</italic> = .09) suggesting perhaps some role of this face processing region in the angry vs. neutral benefit. Correlations in all other emotion-sensitive regions yielded a <italic>p</italic>-value greater than .10. We also correlated these behavioural data with related activity in load-sensitive areas and found no significant results.</p>
<fig id="pone-0003536-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g005</object-id><label>Figure 5</label><caption>
<title>Better performance on the VSTM task for angry versus happy faces (A), and for angry versus neutral faces (B), was correlated with greater activity in the GPi.</title>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g005" xlink:type="simple"/></fig></sec><sec id="s3b3">
<title>Load Effects</title>
<p>We examined load effects by contrasting loads 4, 3, and 2 with load 1, with the view that higher activity at loads greater than 1 indicates a greater draw on resources used to encode and retain multiple face identities in VSTM. Several areas in bilateral dorsolateral, ventrolateral, and medial prefrontal cortex (DLPFC, VLPFC, MPFC), frontal eye field (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex showed significantly higher activation when multiple faces were to be remembered compared to one face in both the right and left hemispheres (<xref ref-type="fig" rid="pone-0003536-g006">Fig. 6a</xref>). These results conform to previous studies of face load in STM <xref ref-type="bibr" rid="pone.0003536-Druzgal1">[22]</xref>. Interestingly, we replicated the dissociation of load effects between parietal and prefrontal areas described previously <xref ref-type="bibr" rid="pone.0003536-Linden2">[23]</xref>, with activity in parietal areas peaking at load 3 and prefrontal activity rising further towards load 4 in a monotonic fashion (<xref ref-type="fig" rid="pone-0003536-g006">Fig. 6b</xref>). This dissociation was supported by a significant load by region interaction between beta values in right parietal cortex and right PFC, <italic>F</italic>(3, 102) = 16.05, <italic>p</italic>&lt;.001. Talairach coordinates for the load contrasts are provided in <xref ref-type="table" rid="pone-0003536-t003">Table 3</xref>.</p>
<fig id="pone-0003536-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.g006</object-id><label>Figure 6</label><caption>
<p>(A) Face loads 4 (blue), 3 (green), and 2 (red) were contrasted with face load 1. Several regions of the PFC, the frontal eye fields (FEF), inferior parietal sulcus (IPS), fusiform gyrus, and occipital cortex, in both left and right hemispheres, showed greater activity when multiple faces were to be remembered compared to just one face. Brain regions modulated by emotion in the right hemisphere (pink = emotion main effect; white = angry minus neutral contrast; brown = angry minus happy contrast) are overlain to illustrate the anatomical distinction between emotional expression and face load effects. Some anatomical landmarks are provided to aid navigation: superior frontal sulcus (SFS); inferior frontal sulcus (IFS); silvian fissure (SF); inferior parietal sulcus (IPS); occipito-temporal sulcus (OTS). (B) Beta values from each load condition (averaged across emotions) illustrate the contrast between a monotonic increase of activity with load in right PFC (x = 41, y = 29, z = 26) and peaked activation at load 3 in right parietal cortex (x = 18, y = −69, z = 43). Bars represent±1 standard error.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.g006" xlink:type="simple"/></fig><table-wrap id="pone-0003536-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.t003</object-id><label>Table 3</label><caption>
<title>Talairach coordinates and voxel cluster size values for face loads 4 minus 1, 3 minus 1, and 2 minus 1 contrasts (FDR&lt;.05).</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0003536-t003-3" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.t003" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Contrast</td>
<td align="left" colspan="1" rowspan="1">Region of activation</td>
<td align="left" colspan="1" rowspan="1">R/L</td>
<td align="left" colspan="1" rowspan="1">x</td>
<td align="left" colspan="1" rowspan="1">y</td>
<td align="left" colspan="1" rowspan="1">z</td>
<td align="left" colspan="1" rowspan="1">Cluster size (mm<sup>3</sup>)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Load 4-1</td>
<td align="left" colspan="1" rowspan="1">Medial PFC</td>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">2</td>
<td align="left" colspan="1" rowspan="1">16</td>
<td align="left" colspan="1" rowspan="1">48</td>
<td align="left" colspan="1" rowspan="1">13929</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Dorso-ventral PFC</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">41</td>
<td align="left" colspan="1" rowspan="1">29</td>
<td align="left" colspan="1" rowspan="1">26</td>
<td align="left" colspan="1" rowspan="1">14874</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">DLPFC</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−43</td>
<td align="left" colspan="1" rowspan="1">7</td>
<td align="left" colspan="1" rowspan="1">43</td>
<td align="left" colspan="1" rowspan="1">10217</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">VLPFC</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−37</td>
<td align="left" colspan="1" rowspan="1">16</td>
<td align="left" colspan="1" rowspan="1">7</td>
<td align="left" colspan="1" rowspan="1">751</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Anterior frontal</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−34</td>
<td align="left" colspan="1" rowspan="1">53</td>
<td align="left" colspan="1" rowspan="1">24</td>
<td align="left" colspan="1" rowspan="1">1732</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">FEF</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">35</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">60</td>
<td align="left" colspan="1" rowspan="1">5028</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">FEF</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−43</td>
<td align="left" colspan="1" rowspan="1">6</td>
<td align="left" colspan="1" rowspan="1">44</td>
<td align="left" colspan="1" rowspan="1">10619</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">IPS</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">29</td>
<td align="left" colspan="1" rowspan="1">−59</td>
<td align="left" colspan="1" rowspan="1">37</td>
<td align="left" colspan="1" rowspan="1">1583</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">IPS</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−25</td>
<td align="left" colspan="1" rowspan="1">−65</td>
<td align="left" colspan="1" rowspan="1">52</td>
<td align="left" colspan="1" rowspan="1">5806</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">36</td>
<td align="left" colspan="1" rowspan="1">−66</td>
<td align="left" colspan="1" rowspan="1">−19</td>
<td align="left" colspan="1" rowspan="1">4533</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−36</td>
<td align="left" colspan="1" rowspan="1">−66</td>
<td align="left" colspan="1" rowspan="1">−19</td>
<td align="left" colspan="1" rowspan="1">6598</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Occipital cortex</td>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">7</td>
<td align="left" colspan="1" rowspan="1">−73</td>
<td align="left" colspan="1" rowspan="1">−10</td>
<td align="left" colspan="1" rowspan="1">24252</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Load 3-1</td>
<td align="left" colspan="1" rowspan="1">Medial PFC</td>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">1</td>
<td align="left" colspan="1" rowspan="1">17</td>
<td align="left" colspan="1" rowspan="1">44</td>
<td align="left" colspan="1" rowspan="1">6937</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">DLPFC</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−50</td>
<td align="left" colspan="1" rowspan="1">16</td>
<td align="left" colspan="1" rowspan="1">31</td>
<td align="left" colspan="1" rowspan="1">2602</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">VLPFC</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">34</td>
<td align="left" colspan="1" rowspan="1">21</td>
<td align="left" colspan="1" rowspan="1">8</td>
<td align="left" colspan="1" rowspan="1">1590</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">FEF</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">30</td>
<td align="left" colspan="1" rowspan="1">−8</td>
<td align="left" colspan="1" rowspan="1">51</td>
<td align="left" colspan="1" rowspan="1">217</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">FEF</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−30</td>
<td align="left" colspan="1" rowspan="1">−10</td>
<td align="left" colspan="1" rowspan="1">58</td>
<td align="left" colspan="1" rowspan="1">1116</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">IPS</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">18</td>
<td align="left" colspan="1" rowspan="1">−69</td>
<td align="left" colspan="1" rowspan="1">43</td>
<td align="left" colspan="1" rowspan="1">7477</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">IPS</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−21</td>
<td align="left" colspan="1" rowspan="1">−68</td>
<td align="left" colspan="1" rowspan="1">50</td>
<td align="left" colspan="1" rowspan="1">3162</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">R</td>
<td align="left" colspan="1" rowspan="1">38</td>
<td align="left" colspan="1" rowspan="1">−67</td>
<td align="left" colspan="1" rowspan="1">−15</td>
<td align="left" colspan="1" rowspan="1">4903</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−30</td>
<td align="left" colspan="1" rowspan="1">−71</td>
<td align="left" colspan="1" rowspan="1">−12</td>
<td align="left" colspan="1" rowspan="1">10557</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Occipital cortex</td>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">−2</td>
<td align="left" colspan="1" rowspan="1">−75</td>
<td align="left" colspan="1" rowspan="1">−4</td>
<td align="left" colspan="1" rowspan="1">36825</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Load 2-1</td>
<td align="left" colspan="1" rowspan="1">Medial PFC</td>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">1</td>
<td align="left" colspan="1" rowspan="1">11</td>
<td align="left" colspan="1" rowspan="1">51</td>
<td align="left" colspan="1" rowspan="1">441</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">FEF</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−30</td>
<td align="left" colspan="1" rowspan="1">−9</td>
<td align="left" colspan="1" rowspan="1">59</td>
<td align="left" colspan="1" rowspan="1">85</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"/>
<td align="left" colspan="1" rowspan="1">Fusiform</td>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">−38</td>
<td align="left" colspan="1" rowspan="1">−67</td>
<td align="left" colspan="1" rowspan="1">−13</td>
<td align="left" colspan="1" rowspan="1">142</td>
</tr>
</tbody>
</table></alternatives></table-wrap>
<p>The spatial dissociation of emotion and face load effects on brain activation is particularly striking. Although both emotion and load effects were observed in parts of the right PFC, these areas did not anatomically overlap (<xref ref-type="fig" rid="pone-0003536-g006">Fig. 6a</xref>). Similarly, the load effect in bilateral fusiform gyrus was anatomically different to fusiform activity modulated by the angry minus neutral contrast (the emotion region lies more anterior to the load region). Furthermore, a whole brain statistical analysis did not reveal any areas that showed an interaction between emotion and load.</p>
</sec><sec id="s3b4">
<title>Correlation Between Behavioral and Functional data for Load Effects</title>
<p>We also examined correlations between STM capacity estimates, as indexed by Cowan's K, and brain activation levels in load-sensitive areas. K capacity estimates (collapsed across emotion conditions) were: load 1 = 0.93 (<italic>SE</italic> = .02<italic>)</italic>; load 2 = 1.48 (<italic>SE</italic> = .07); load 3 = 1.70 (<italic>SE</italic> = .11); load 4 = 1.71 (<italic>SE</italic> = .13). Significant or marginally significant positive correlations were found in all regions except left VLPFC and right fusiform (<xref ref-type="table" rid="pone-0003536-t004">Table 4</xref>): as the number of faces stored in STM (K) increased, activity also increased. We correlated these K data with load activity in emotion-sensitive areas and found no significant results, confirming the spatial dissociation between emotion and load effects.</p>
<table-wrap id="pone-0003536-t004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0003536.t004</object-id><label>Table 4</label><caption>
<title>Correlation between STM capacity estimates (K) and related beta values in load-sensitive regions. r<sup>2</sup> values are provided with <italic>p</italic> values in brackets.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0003536-t004-4" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0003536.t004" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Region of activation</td>
<td align="left" colspan="1" rowspan="1">Correlation coefficient r<sup>2</sup></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Medial PFC</td>
<td align="left" colspan="1" rowspan="1"><bold>.32 </bold><bold><italic>(&lt;.001)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">r Dorso-ventral PFC</td>
<td align="left" colspan="1" rowspan="1"><bold>.32 </bold><bold><italic>(&lt;.001)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">l DLPFC</td>
<td align="left" colspan="1" rowspan="1"><bold>.16 </bold><bold><italic>(.06)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">l VLPFC</td>
<td align="left" colspan="1" rowspan="1">.12 <italic>(.17)</italic></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Anterior frontal</td>
<td align="left" colspan="1" rowspan="1"><bold>.18 </bold><bold><italic>(.04)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">r FEF</td>
<td align="left" colspan="1" rowspan="1"><bold>.25 </bold><bold><italic>(&lt;.01)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">l FEF</td>
<td align="left" colspan="1" rowspan="1"><bold>.16 </bold><bold><italic>(.06)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">r IPS</td>
<td align="left" colspan="1" rowspan="1"><bold>.21 </bold><bold><italic>(.01)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">l IPS</td>
<td align="left" colspan="1" rowspan="1"><bold>.23 </bold><bold><italic>(&lt;.01)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">r Fusiform</td>
<td align="left" colspan="1" rowspan="1">.14 <italic>(.10)</italic></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">l Fusiform</td>
<td align="left" colspan="1" rowspan="1"><bold>.27 </bold><bold><italic>(&lt;.01)</italic></bold></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Occipital cortex</td>
<td align="left" colspan="1" rowspan="1"><bold>.33 </bold><bold><italic>(&lt;.001)</italic></bold></td>
</tr>
</tbody>
</table></alternatives></table-wrap></sec></sec></sec><sec id="s4">
<title>Discussion</title>
<p>Our behavioral results show that VSTM is significantly enhanced for face identities when faces display an angry compared to a happy or neutral expression, replicating previous findings <xref ref-type="bibr" rid="pone.0003536-Jackson1">[8]</xref>. It has been suggested that effects of emotion on memory require time to emerge, allowing effective consolidation of such memories <xref ref-type="bibr" rid="pone.0003536-LaBar2">[4]</xref>. Yet here, as in our previous study, we show that the effects of emotion on memory can be more immediate – emotional expression can influence visual short-term memory for faces.</p>
<p>In the present study, a network of emotion-sensitive areas comprised STS, PFC, and GPi, all in the right hemisphere, in keeping with the view that the right hemisphere is more involved in the processing and generation of emotions and affect than the left <xref ref-type="bibr" rid="pone.0003536-Borod1">[24]</xref>, <xref ref-type="bibr" rid="pone.0003536-Davidson2">[25]</xref>. The specific areas all fit into current models of emotion processing. The STS has been identified as a key area for the extraction of emotional information from faces <xref ref-type="bibr" rid="pone.0003536-Narumoto1">[14]</xref>, <xref ref-type="bibr" rid="pone.0003536-Haxby1">[26]</xref>, <xref ref-type="bibr" rid="pone.0003536-Winston1">[27]</xref> and more generally for the evaluation of others' intentions <xref ref-type="bibr" rid="pone.0003536-Allison1">[28]</xref>. The STS has also been specifically implicated in processing various forms of anger <xref ref-type="bibr" rid="pone.0003536-Grosbras1">[29]</xref>. Regions of the PFC have been implicated in experience <xref ref-type="bibr" rid="pone.0003536-Habel1">[30]</xref> and observation <xref ref-type="bibr" rid="pone.0003536-Stip1">[31]</xref> of negative mood, and higher activity in response to negative than positive images has been evidenced in regions of the right ventrolateral PFC specifically <xref ref-type="bibr" rid="pone.0003536-Dolcos1">[32]</xref>. Integration of emotional state and STM processes in regions of bilateral PFC has also been reported <xref ref-type="bibr" rid="pone.0003536-Gray1">[33]</xref>. The GPi, a subcortical structure, is a major part of the basal ganglia which, beyond their function in the extrapyramidal motor circuit, are involved in a variety of cognitive functions including emotion processing <xref ref-type="bibr" rid="pone.0003536-Utter1">[34]</xref>.</p>
<p>What is striking about the present findings is that the right STS, PFC, and GPi were specifically recruited in the service of VSTM for angry faces. The GPi seems to be the main region responsible for enhanced VSTM for angry faces, and this finding concurs with a recent study that showed a positive correlation between increased globus pallidus activity and increased STM capacity for simple objects <xref ref-type="bibr" rid="pone.0003536-McNab1">[35]</xref>. This study also outlined the role of the globus pallidus as an attentional filter that allows only relevant information access to VSTM. It is possible in our study that enhanced GPi activity to angry faces in VSTM might reflect heightened attention to angry faces, driven by the saliency of potential threat. Threat (anger and fear) expressions have frequently been reported as especially good at capturing attention <xref ref-type="bibr" rid="pone.0003536-Fox1">[36]</xref>–<xref ref-type="bibr" rid="pone.0003536-Mogg1">[38]</xref>, even when task-irrelevant <xref ref-type="bibr" rid="pone.0003536-Eastwood1">[39]</xref>. However, these studies involve the capture of attention of a single angry face in a display of differently valenced faces, while in our study all faces in any one VSTM trial displayed the same emotion, thus removing any such competition for attention between different expressions. Furthermore, there is also evidence of rapid attentional orienting to happy faces <xref ref-type="bibr" rid="pone.0003536-Juth1">[40]</xref> and more generally to stimuli with high emotional relevance <xref ref-type="bibr" rid="pone.0003536-Brosch1">[41]</xref>. Perhaps attention was heightened in general during angry face trials, in order to facilitate encoding and maintenance of person identity information in VSTM in the context of potential threat.</p>
<p>The prominent role of the GPi, which was the key area where neural activity was significantly correlated with behavioural performance, is in keeping with recent findings on the role of dopamine in recognition of angry expression. Selective impairment of angry face perception has been linked to: lack of dopamine in Parkinson's disease, which affects the information processing capacity of the GP <xref ref-type="bibr" rid="pone.0003536-Heimer1">[42]</xref>, <xref ref-type="bibr" rid="pone.0003536-Lawrence1">[43]</xref>; treatment with antidopaminergic drugs <xref ref-type="bibr" rid="pone.0003536-Lawrence2">[44]</xref>; and deep brain stimulation of the subthalamic nucleus <xref ref-type="bibr" rid="pone.0003536-Schroeder1">[45]</xref>, which is directly connected with the limbic part of the GP <xref ref-type="bibr" rid="pone.0003536-Karachi1">[10]</xref>. The present study shows that the GPi, one of the main relay stations of the basal ganglia, is not only responsive to emotional stimuli but aids their processing in a way that allows the effective handling of evolutionarily salient information.</p>
<p>A specific angry vs. neutral contrast also revealed a role for the fusiform gyrus - a face-selective area <xref ref-type="bibr" rid="pone.0003536-Kanwisher1">[46]</xref> - in the angry benefit, wherein BOLD activity was higher for angry than neutral faces bilaterally and for angry than happy faces in the right hemisphere. Modulation of activity in the fusiform region by facial expression has been reported previously during passive viewing, identity matching, and emotion recognition tasks. For example, there is evidence that fearful <xref ref-type="bibr" rid="pone.0003536-Breiter1">[47]</xref>–<xref ref-type="bibr" rid="pone.0003536-Vuilleumier1">[49]</xref>, happy <xref ref-type="bibr" rid="pone.0003536-Breiter1">[47]</xref>, <xref ref-type="bibr" rid="pone.0003536-Lewis1">[50]</xref>, and angry faces <xref ref-type="bibr" rid="pone.0003536-KeslerWest1">[13]</xref> elicit greater fusiform activity than neutral faces. However, our study is the first to report modulation of the fusiform gyrus by facial expression during a VSTM task.</p>
<p>Traditionally, the amygdala has been implicated in the processing of emotional stimuli and in the long-term retention of emotional events or images wherein activity is often suggested to reflect heightened physiological arousal, which is thought to mediate emotional learning via direct and indirect neural pathways subserving short and long-term memory <xref ref-type="bibr" rid="pone.0003536-LaBar2">[4]</xref>. In our study, however, we did not find significant influence of the amygdala on the enhancement of VSTM for angry faces. There are a couple of explanations for this. First, the amygdala does not respond selectively to negative emotion: studies have shown activation in response to images of happy and neutral faces <xref ref-type="bibr" rid="pone.0003536-Wright1">[51]</xref>. Thus, it is possible that the emotion contrasts computed here did not reveal modulation of the amygdala if all three emotions recruited this region to the same degree. Second, the angry face effect in VSTM is likely driven by image valence (i.e., negativity) rather than physiological arousal (i.e., excitability). In our previous behavioural study <xref ref-type="bibr" rid="pone.0003536-Jackson1">[8]</xref> we showed that music-induced arousal states did not modulate VSTM performance in general nor interact with expression conditions. We also found that arousal ratings, as measured by the Self-Assessment Manikin (SAM) rating scale <xref ref-type="bibr" rid="pone.0003536-Bradley1">[52]</xref>, did not differ between angry and happy faces. Our behavioural data thus make a general arousal account of enhanced VSTM for angry versus happy faces less likely.</p>
<p>With regard to load modulated brain regions, higher activity in the fusiform gyrus can be explained by the larger number of faces in the memory encoding display, and may also reflect the involvement of this area in VSTM processes <xref ref-type="bibr" rid="pone.0003536-Druzgal1">[22]</xref>. The activation increase in parietal and prefrontal areas reflects their role in supporting the attentional, encoding, and storage requirements of higher memory loads <xref ref-type="bibr" rid="pone.0003536-Linden2">[23]</xref>, <xref ref-type="bibr" rid="pone.0003536-Mayer1">[53]</xref>. Importantly, the bilateral fusiform regions that displayed load effects (e.g., load 4 – load 1; LH: x = −36, y = −66, z = −19; RH: x = 36, y = −66, z = −19) were anatomically distinct from the more anterior fusiform regions that displayed an angry face benefit (LH: x = −32, y = −42, z = −12; RH: x = 43, y = −43, z = −16). Face processing regions in the occipito-temporal cortex have been segregated previously into two distinct regions, the fusiform face area (FFA) and the occipital face area (OFA), the former located more anterior to the latter <xref ref-type="bibr" rid="pone.0003536-Peelen1">[54]</xref>. Our Talairach coordinates for the emotion- and load-affected fusiform regions correspond nicely with reported right hemisphere FFA and OFA coordinates respectively (FFA: x = 39, y = −44, z = −18; OFA: x = 39, y = −64, z = −20). None of the other load-related areas showed an additional modulation of their activity by emotional expression. This suggests that the enhancement of VSTM capacity by the angry expression operates mainly through the recruitment of emotion and face processing networks rather than through recruitment of additional neurons in the classical fronto-parietal STM network. The positive correlation between capacity estimates (K) and brain activation levels in most load-sensitive regions in the occipital, temporal, parietal, and frontal cortices, reflecting increased activity as the number of stored faces increased, suggests that activity in both low-level perceptual and higher-level cognitive areas is modulated by the amount of facial information stored in STM.</p>
<p>We propose a new neural mechanism that supports the angry face benefit in VSTM by facilitating processing and extending memory capabilities. Studies have reported several areas of the fronto-parietal STM network that pose a bottleneck for memory storage at high loads because they cannot respond by further increasing their levels of activity <xref ref-type="bibr" rid="pone.0003536-Linden2">[23]</xref>, <xref ref-type="bibr" rid="pone.0003536-Mayer1">[53]</xref>, <xref ref-type="bibr" rid="pone.0003536-Todd1">[55]</xref>. Our study suggests that VSTM for faces is not only supported by the recruitment of areas that are modulated by load, but also by areas that respond categorically and automatically to the presence of a certain type of stimulus content, in this case, emotion. In the present study, enhanced VSTM capacity for angry faces would thus have been supported by communication between emotion-sensitive areas (STS, IFS, GPi, and FFA) and face identification and VSTM areas (PFC, IPS, OFA).</p>
<p>Our findings also provide further perspective to the debate on whether or not there is independence between face identification and emotional expression decoding processes. While some studies have indicated dissociable neural representations for identity processing in the fusiform gyrus and facial expression processing in the anterior STS <xref ref-type="bibr" rid="pone.0003536-Haxby1">[26]</xref>, <xref ref-type="bibr" rid="pone.0003536-Winston1">[27]</xref>, others suggest that neural circuits underpinning identity and expression processes overlap <xref ref-type="bibr" rid="pone.0003536-Ganel1">[56]</xref>, <xref ref-type="bibr" rid="pone.0003536-Vuilleumier2">[57]</xref>. We show that, in VSTM at least, the impact of (angry) emotional expression on face identification tends not to be achieved by multi-functionality of one region but by communication between different process-specific regions responsive to face expression or load. The dissociation between anger and load effects in anterior (FFA) and posterior (OFA) regions of the fusiform gyrus respectively is a novel finding, and perhaps suggests a more complex, fine-grained functional organisation of this region in supporting both expression and face identification processes.</p>
<p>Finally, our discovery of the pivotal role of the GPi at the interface between emotion and cognition may have profound implications for clinical neuropsychiatry. Deficits of social cognition, such as extraction of meaning from facial expressions, may be core elements of the psychopathology of schizophrenia and mood disorders. Whether these are linked to changes in the basal ganglia will have to be explored in future research. The basal ganglia also are the main target of deep brain stimulation for movement disorders and increasingly also for behavioural disorders, and a better understanding of their non-motor functions would be of great clinical importance.</p>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0003536-Dolan1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Emotion, cognition, and behaviour.</article-title>             <source>Science</source>             <volume>298(5596)</volume>             <fpage>1191</fpage>             <lpage>1194</lpage>          </element-citation></ref>
<ref id="pone.0003536-Kensinger1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kensinger</surname><given-names>EA</given-names></name>
</person-group>             <year>2007</year>             <article-title>Negative emotion enhances memory accuracy: Behavioural and neuroimaging evidence.</article-title>             <source>Curr Dir Psychol Sci</source>             <volume>16(4)</volume>             <fpage>213</fpage>             <lpage>218</lpage>          </element-citation></ref>
<ref id="pone.0003536-LaBar1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>La Bar</surname><given-names>KS</given-names></name>
</person-group>             <year>2007</year>             <article-title>Beyond fear: Emotional memory mechanisms in the human brain.</article-title>             <source>Curr Dir Psychol Sci</source>             <volume>16(4)</volume>             <fpage>173</fpage>             <lpage>177</lpage>          </element-citation></ref>
<ref id="pone.0003536-LaBar2"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>LaBar</surname><given-names>KS</given-names></name>
<name name-style="western"><surname>Cabeza</surname><given-names>R</given-names></name>
</person-group>             <year>2006</year>             <article-title>Cognitive neuroscience of emotional memory.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>54</fpage>             <lpage>64</lpage>          </element-citation></ref>
<ref id="pone.0003536-Kensinger2"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kensinger</surname><given-names>EA</given-names></name>
<name name-style="western"><surname>Corkin</surname><given-names>S</given-names></name>
</person-group>             <year>2003</year>             <article-title>Effect of negative emotional content on working memory and long-term memory.</article-title>             <source>Emotion</source>             <volume>3(4)</volume>             <fpage>378</fpage>             <lpage>393</lpage>          </element-citation></ref>
<ref id="pone.0003536-Mikels1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mikels</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Larkin</surname><given-names>GR</given-names></name>
<name name-style="western"><surname>Reuter-Lorenz</surname><given-names>PA</given-names></name>
<name name-style="western"><surname>Carstenen</surname><given-names>LL</given-names></name>
</person-group>             <year>2005</year>             <article-title>Divergent trajectories in the ageing mind: Changes in working memory for affective versus visual information with age.</article-title>             <source>Psychol Ageing</source>             <volume>20(4)</volume>             <fpage>542</fpage>             <lpage>553</lpage>          </element-citation></ref>
<ref id="pone.0003536-Perlstein1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Perlstein</surname><given-names>WM</given-names></name>
<name name-style="western"><surname>Elbert</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Stenger</surname><given-names>VA</given-names></name>
</person-group>             <year>2002</year>             <article-title>Dissociations in human prefrontal cortex of affective influences on working memory-related activity.</article-title>             <source>P Natl Acad Sci. USA.</source>             <volume>99(3)</volume>             <fpage>1736</fpage>             <lpage>1741</lpage>          </element-citation></ref>
<ref id="pone.0003536-Jackson1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jackson</surname><given-names>MC</given-names></name>
<name name-style="western"><surname>Wu</surname><given-names>C-Y</given-names></name>
<name name-style="western"><surname>Linden</surname><given-names>DEJ</given-names></name>
<name name-style="western"><surname>Raymond</surname><given-names>JE</given-names></name>
</person-group>             <year>In Press</year>             <article-title>Enhanced visual short-term memory for angry faces.</article-title>             <source>J Exp Psychol Human</source>          </element-citation></ref>
<ref id="pone.0003536-Davidson1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Davidson</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Irwin</surname><given-names>W</given-names></name>
</person-group>             <year>1999</year>             <article-title>The functional neuroanatomy of emotion and affective style.</article-title>             <source>Trends Cogn Sci</source>             <volume>3(1)</volume>             <fpage>11</fpage>             <lpage>21</lpage>          </element-citation></ref>
<ref id="pone.0003536-Karachi1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karachi</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Yelnik</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Tande</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Tremblay</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Hirsch</surname><given-names>EC</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>The pallidosubthalamic projection: An anatomical substrate for nonmotor functions of the subthalamic nucleus in primates.</article-title>             <source>Movement Disord</source>             <volume>20(2)</volume>             <fpage>172</fpage>             <lpage>80</lpage>          </element-citation></ref>
<ref id="pone.0003536-Stein1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stein</surname><given-names>MB</given-names></name>
<name name-style="western"><surname>Simmons</surname><given-names>AN</given-names></name>
<name name-style="western"><surname>Feinstein</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Paulus</surname><given-names>MP</given-names></name>
</person-group>             <year>2007</year>             <article-title>Increased amygdala and insula activation during emotion processing in anxiety-prone subjects.</article-title>             <source>Am J Psychiat</source>             <volume>164(2)</volume>             <fpage>318</fpage>             <lpage>327</lpage>          </element-citation></ref>
<ref id="pone.0003536-Linden1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Linden</surname><given-names>DEJ</given-names></name>
</person-group>             <year>2007</year>             <article-title>The working memory networks of the human brain.</article-title>             <source>Neuroscientist</source>             <volume>13(3)</volume>             <fpage>257</fpage>             <lpage>267 (2007)</lpage>          </element-citation></ref>
<ref id="pone.0003536-KeslerWest1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kesler/West</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Andersen</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>Smith</surname><given-names>CD</given-names></name>
<name name-style="western"><surname>Avison</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Davis</surname><given-names>CE</given-names></name>
<etal/></person-group>             <year>2001</year>             <article-title>Neural substrates of facial emotion processing using fMRI.</article-title>             <source>Cognitive Brain Res</source>             <volume>11</volume>             <fpage>213</fpage>             <lpage>226</lpage>          </element-citation></ref>
<ref id="pone.0003536-Narumoto1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Narumoto</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Okada</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Sadato</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Fukui</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Yonekura</surname><given-names>Y</given-names></name>
</person-group>             <year>2001</year>             <article-title>Attention to emotion modulates fMRI activity in human right superior temporal sulcus.</article-title>             <source>Cognitive Brain Res</source>             <volume>12(2)</volume>             <fpage>225</fpage>             <lpage>231</lpage>          </element-citation></ref>
<ref id="pone.0003536-Ekman1"><label>15</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Friesen</surname><given-names>WV</given-names></name>
</person-group>             <year>1976</year>             <article-title>Pictures of facial affect.</article-title>             <publisher-loc>Palo Alto, CA</publisher-loc>             <publisher-name>Consulting Psychologists Press</publisher-name>          </element-citation></ref>
<ref id="pone.0003536-Jackson2"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jackson</surname><given-names>MC</given-names></name>
<name name-style="western"><surname>Raymond</surname><given-names>JE</given-names></name>
</person-group>             <year>2008</year>             <article-title>Familiarity enhances visual working memory for faces.</article-title>             <source>J Exp Psychol Human</source>             <volume>34(3)</volume>             <fpage>556</fpage>             <lpage>568</lpage>          </element-citation></ref>
<ref id="pone.0003536-Schneider1"><label>17</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Eschman</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Zuccolotto</surname><given-names>A</given-names></name>
</person-group>             <year>2002</year>             <article-title>E-Prime User's Guide.</article-title>             <publisher-loc>Pittsburgh</publisher-loc>             <publisher-name>Psychology Software Tools Inc</publisher-name>          </element-citation></ref>
<ref id="pone.0003536-Talairach1"><label>18</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Talairach</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Tournoux</surname><given-names>P</given-names></name>
</person-group>             <year>1988</year>             <article-title>Co-planar stereotaxic atlas of the human brain.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Thieme</publisher-name>          </element-citation></ref>
<ref id="pone.0003536-Johnstone1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Johnstone</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Walsh</surname><given-names>KSO</given-names></name>
<name name-style="western"><surname>Greischar</surname><given-names>LL</given-names></name>
<name name-style="western"><surname>Alexander</surname><given-names>AL</given-names></name>
<name name-style="western"><surname>Fox</surname><given-names>AS</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>Motion correction and the use of motion covariates in multiple-subject fMRI analysis.</article-title>             <source>Hum Brain Mapp</source>             <volume>27</volume>             <fpage>779</fpage>             <lpage>788</lpage>          </element-citation></ref>
<ref id="pone.0003536-Lund1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lund</surname><given-names>TE</given-names></name>
<name name-style="western"><surname>Nørgaard</surname><given-names>MD</given-names></name>
<name name-style="western"><surname>Rostrup</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Rowe</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Paulson</surname><given-names>OB</given-names></name>
</person-group>             <year>2005</year>             <article-title>Motion or activity: Their role in intra- and inter-subject variation in fMRI.</article-title>             <source>Neuroimage</source>             <volume>26</volume>             <fpage>960</fpage>             <lpage>964</lpage>          </element-citation></ref>
<ref id="pone.0003536-Cowan1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cowan</surname><given-names>N</given-names></name>
</person-group>             <year>2001</year>             <article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity.</article-title>             <source>Behav Brain Sci</source>             <volume>24</volume>             <fpage>87</fpage>             <lpage>185</lpage>          </element-citation></ref>
<ref id="pone.0003536-Druzgal1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Druzgal</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>D'Esposito</surname><given-names>M</given-names></name>
</person-group>             <year>2003</year>             <article-title>Dissecting contributions of prefrontal cortex and fusiform face area to face working memory.</article-title>             <source>J Cognitive Neurosci</source>             <volume>15(6)</volume>             <fpage>771</fpage>             <lpage>784</lpage>          </element-citation></ref>
<ref id="pone.0003536-Linden2"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Linden</surname><given-names>DEJ</given-names></name>
<name name-style="western"><surname>Bittner</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Muckli</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Waltz</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Cortical capacity constraints for visual working memory: Dissociation of fMRI load effects in a fronto-parietal network.</article-title>             <source>Neuroimage</source>             <volume>20(3)</volume>             <fpage>1518</fpage>             <lpage>1530</lpage>          </element-citation></ref>
<ref id="pone.0003536-Borod1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Borod</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Cicero</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Obler</surname><given-names>LK</given-names></name>
<name name-style="western"><surname>Welkowitz</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Erhan</surname><given-names>HM</given-names></name>
<etal/></person-group>             <year>1998</year>             <article-title>Right hemisphere emotional perception: Evidence across multiple channels.</article-title>             <source>Neuropsychology</source>             <volume>12</volume>             <fpage>446</fpage>             <lpage>458</lpage>          </element-citation></ref>
<ref id="pone.0003536-Davidson2"><label>25</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Davidson</surname><given-names>RJ</given-names></name>
</person-group>             <year>1984</year>             <article-title>Affect, cognition, and hemispheric specialization.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Izard</surname><given-names>CE</given-names></name>
<name name-style="western"><surname>Kagan</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Zajonc</surname><given-names>R</given-names></name>
</person-group>             <source>Emotion, Cognition and Behavior</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Cambridge Univ. Press</publisher-name>             <fpage>320</fpage>             <lpage>365</lpage>          </element-citation></ref>
<ref id="pone.0003536-Haxby1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>
<name name-style="western"><surname>Hoffman</surname><given-names>EA</given-names></name>
<name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name>
</person-group>             <year>2000</year>             <article-title>The distributed human neural system for face perception.</article-title>             <source>Trends Cogn Sci</source>             <volume>4(6)</volume>             <fpage>223</fpage>             <lpage>233</lpage>          </element-citation></ref>
<ref id="pone.0003536-Winston1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Winston</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Henson</surname><given-names>RNA</given-names></name>
<name name-style="western"><surname>Fine-Goulden</surname><given-names>MR</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
</person-group>             <year>2004</year>             <article-title>fMRI-adaptation reveals dissociable neural representations of identity and expression in face perception.</article-title>             <source>J Neurophysiol</source>             <volume>92(3)</volume>             <fpage>1830</fpage>             <lpage>1839</lpage>          </element-citation></ref>
<ref id="pone.0003536-Allison1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Allison</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Puce</surname><given-names>A</given-names></name>
<name name-style="western"><surname>McCarthy</surname><given-names>G</given-names></name>
</person-group>             <year>2000</year>             <article-title>Social perception from visual cues: Role of the STS region.</article-title>             <source>Trends Cogn Sci</source>             <volume>4(7)</volume>             <fpage>267</fpage>             <lpage>278</lpage>          </element-citation></ref>
<ref id="pone.0003536-Grosbras1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Grosbras</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Paus</surname><given-names>T</given-names></name>
</person-group>             <year>2006</year>             <article-title>Brain networks involved in viewing angry hands or faces.</article-title>             <source>Cereb Cortex</source>             <volume>16</volume>             <fpage>1087</fpage>             <lpage>1096</lpage>          </element-citation></ref>
<ref id="pone.0003536-Habel1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Habel</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Klein</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kellermann</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Shah</surname><given-names>NJ</given-names></name>
<name name-style="western"><surname>Schneider</surname><given-names>F</given-names></name>
</person-group>             <year>2005</year>             <article-title>Same or different? Neural correlated of happy and sad mood in healthy males.</article-title>             <source>Neuroimage</source>             <volume>26(1)</volume>             <fpage>206</fpage>             <lpage>214</lpage>          </element-citation></ref>
<ref id="pone.0003536-Stip1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stip</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Fahim</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Liddle</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Mancini-Marie</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Mensour</surname><given-names>B</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Neural correlates of sad feelings in schizophrenia with and without blunted affect.</article-title>             <source>Can J Psychiat</source>             <volume>50(14)</volume>             <fpage>909</fpage>             <lpage>917</lpage>          </element-citation></ref>
<ref id="pone.0003536-Dolcos1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dolcos</surname><given-names>F</given-names></name>
<name name-style="western"><surname>LaBar</surname><given-names>KS</given-names></name>
<name name-style="western"><surname>Cabeza</surname><given-names>R</given-names></name>
</person-group>             <year>2004</year>             <article-title>Dissociable effects of arousal and valence on prefrontal activity indexing emotional evaluation and subsequent memory: An event-related fMRI study.</article-title>             <source>Neuroimage</source>             <volume>23</volume>             <fpage>64</fpage>             <lpage>74</lpage>          </element-citation></ref>
<ref id="pone.0003536-Gray1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gray</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Braver</surname><given-names>TS</given-names></name>
<name name-style="western"><surname>Raichle</surname><given-names>ME</given-names></name>
</person-group>             <year>2002</year>             <article-title>Integration of emotion and cognition in the lateral prefrontal cortex.</article-title>             <source>P Natl Acad Sci USA</source>             <volume>99(6)</volume>             <fpage>4115</fpage>             <lpage>4120</lpage>          </element-citation></ref>
<ref id="pone.0003536-Utter1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Utter</surname><given-names>AA</given-names></name>
<name name-style="western"><surname>Basso</surname><given-names>MA</given-names></name>
</person-group>             <year>2008</year>             <article-title>The basal ganglia: An overview of circuits and function.</article-title>             <source>Neurosci Biobehav R</source>             <volume>32(3)</volume>             <fpage>333</fpage>             <lpage>342</lpage>          </element-citation></ref>
<ref id="pone.0003536-McNab1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McNab</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Klingberg</surname><given-names>T</given-names></name>
</person-group>             <year>2007</year>             <article-title>Prefrontal cortex and basal ganglia control access to working memory.</article-title>             <source>Nat Neurosci</source>             <volume>11(1)</volume>             <fpage>103</fpage>             <lpage>107</lpage>          </element-citation></ref>
<ref id="pone.0003536-Fox1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fox</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Lester</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Russo</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Bowles</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Pichler</surname><given-names>A</given-names></name>
<etal/></person-group>             <year>2000</year>             <article-title>Facial expressions of emotion: Are angry faces detected more efficiently?</article-title>             <source>Cognition Emotion</source>             <volume>14(1)</volume>             <fpage>61</fpage>             <lpage>92</lpage>          </element-citation></ref>
<ref id="pone.0003536-Hansen1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hansen</surname><given-names>CH</given-names></name>
<name name-style="western"><surname>Hansen</surname><given-names>RD</given-names></name>
</person-group>             <year>1988</year>             <article-title>Finding the face in the crowd: An anger superiority effect.</article-title>             <source>J Pers Soc Psychol</source>             <volume>54(6)</volume>             <fpage>917</fpage>             <lpage>924</lpage>          </element-citation></ref>
<ref id="pone.0003536-Mogg1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mogg</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Bradley</surname><given-names>BP</given-names></name>
</person-group>             <year>1999</year>             <article-title>Orienting of attention to threatening facial expressions presented under conditions of restricted awareness.</article-title>             <source>Cognition Emotion</source>             <volume>13(6)</volume>             <fpage>713</fpage>             <lpage>740</lpage>          </element-citation></ref>
<ref id="pone.0003536-Eastwood1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Eastwood</surname><given-names>JD</given-names></name>
<name name-style="western"><surname>Smilek</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Merikle</surname><given-names>PM</given-names></name>
</person-group>             <year>2003</year>             <article-title>Negative facial expression captures attention and disrupts performance.</article-title>             <source>Percept Psychophys</source>             <volume>65(3)</volume>             <fpage>352</fpage>             <lpage>358</lpage>          </element-citation></ref>
<ref id="pone.0003536-Juth1"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Juth</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Lundqvist</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Karlsson</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Ohman</surname><given-names>A</given-names></name>
</person-group>             <year>2005</year>             <article-title>Looking for foes and friends: perceptual and emotional factors when finding a face in the crowd.</article-title>             <source>Emotion</source>             <volume>5(4)</volume>             <fpage>379</fpage>             <lpage>95</lpage>          </element-citation></ref>
<ref id="pone.0003536-Brosch1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brosch</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Sander</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Pourtois</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Scherer</surname><given-names>KR</given-names></name>
</person-group>             <year>2008</year>             <article-title>Beyond fear: Rapid spatial orienting toward positive emotional stimuli.</article-title>             <source>Psychol Sci</source>             <volume>19(4)</volume>             <fpage>362</fpage>             <lpage>370</lpage>          </element-citation></ref>
<ref id="pone.0003536-Heimer1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Heimer</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Rivlin</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Israel</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Bergman</surname><given-names>H</given-names></name>
</person-group>             <year>2006</year>             <article-title>Synchronizing activity of basal ganglia and pathophysiology of Parkinson's disease.</article-title>             <source>J Neural Transm-Supp</source>             <volume>70</volume>             <fpage>17</fpage>             <lpage>20</lpage>          </element-citation></ref>
<ref id="pone.0003536-Lawrence1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lawrence</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Goerendt</surname><given-names>IK</given-names></name>
<name name-style="western"><surname>Brooks</surname><given-names>DJ</given-names></name>
</person-group>             <year>2007</year>             <article-title>Impaired recognition of facial expressions of anger in Parkinson's disease patients acutely withdrawn from dopamine replacement therapy.</article-title>             <source>Neuropsychologia</source>             <volume>45(1)</volume>             <fpage>65</fpage>             <lpage>74</lpage>          </element-citation></ref>
<ref id="pone.0003536-Lawrence2"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lawrence</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Calder</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>McGowan</surname><given-names>SW</given-names></name>
<name name-style="western"><surname>Grasby</surname><given-names>PM</given-names></name>
</person-group>             <year>2002</year>             <article-title>Selective disruption of the recognition of facial expressions of anger.</article-title>             <source>Neuroreport</source>             <volume>13(6)</volume>             <fpage>881</fpage>             <lpage>884</lpage>          </element-citation></ref>
<ref id="pone.0003536-Schroeder1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schroeder</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Kuehler</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hennenlotter</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Haslinger</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Tronnier</surname><given-names>VM</given-names></name>
<etal/></person-group>             <year>2004</year>             <article-title>Facial expression recognition and subthalamic nucleus stimulation.</article-title>             <source>J Neurol Neurosur Ps</source>             <volume>75(4)</volume>             <fpage>648</fpage>             <lpage>650</lpage>          </element-citation></ref>
<ref id="pone.0003536-Kanwisher1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name>
</person-group>             <year>2006</year>             <article-title>The fusiform face area: A cortical region specialized for the perception of faces.</article-title>             <source>Philos T Roy Soc B</source>             <volume>361(1476)</volume>             <fpage>2109</fpage>             <lpage>2128</lpage>          </element-citation></ref>
<ref id="pone.0003536-Breiter1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Breiter</surname><given-names>HC</given-names></name>
<name name-style="western"><surname>Etcoff</surname><given-names>NL</given-names></name>
<name name-style="western"><surname>Whalen</surname><given-names>PJ</given-names></name>
<name name-style="western"><surname>Kennedy</surname><given-names>WA</given-names></name>
<name name-style="western"><surname>Rauch</surname><given-names>SL</given-names></name>
<etal/></person-group>             <year>1996</year>             <article-title>Response and habituation of the human amygdala during visual processing of facial expression.</article-title>             <source>Neuron</source>             <volume>17(5)</volume>             <fpage>875</fpage>             <lpage>887</lpage>          </element-citation></ref>
<ref id="pone.0003536-Pessoa1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pessoa</surname><given-names>L</given-names></name>
<name name-style="western"><surname>McKenna</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Guitierrez</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Ungerleider</surname><given-names>LG</given-names></name>
</person-group>             <year>2002</year>             <article-title>Neural processing of emotional faces requires attention.</article-title>             <source>P Natl Acad Sci USA</source>             <volume>99(17)</volume>             <fpage>11458</fpage>             <lpage>11463</lpage>          </element-citation></ref>
<ref id="pone.0003536-Vuilleumier1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vuilleumier</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Armony</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Driver</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
</person-group>             <year>2001</year>             <article-title>Effects of attention and emotion on face processing in the human brain: An event-related fMRI study.</article-title>             <source>Neuron</source>             <volume>30(3)</volume>             <fpage>829</fpage>             <lpage>841</lpage>          </element-citation></ref>
<ref id="pone.0003536-Lewis1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lewis</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Thoma</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Lanoue</surname><given-names>MD</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Heller</surname><given-names>W</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Visual processing of facial affect.</article-title>             <source>Neuroreport</source>             <volume>14(14)</volume>             <fpage>1841</fpage>             <lpage>1845</lpage>          </element-citation></ref>
<ref id="pone.0003536-Wright1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wright</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Liu</surname><given-names>YJ</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neutral faces activate the amygdala during identity matching.</article-title>             <source>Neuroimage</source>             <volume>29(2)</volume>             <fpage>628</fpage>             <lpage>636</lpage>          </element-citation></ref>
<ref id="pone.0003536-Bradley1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bradley</surname><given-names>MM</given-names></name>
<name name-style="western"><surname>Lang</surname><given-names>PJ</given-names></name>
</person-group>             <year>1994</year>             <article-title>Measuring emotion: The self-assessment manikin and the semantic differential.</article-title>             <source>J Behav Ther Exp Psy</source>             <volume>25(1)</volume>             <fpage>49</fpage>             <lpage>59</lpage>          </element-citation></ref>
<ref id="pone.0003536-Mayer1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mayer</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Bittner</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Nicolić</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Bledowski</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Common neural substrates for visual working memory and attention.</article-title>             <source>Neuroimage</source>             <volume>36(2)</volume>             <fpage>441</fpage>             <lpage>453</lpage>          </element-citation></ref>
<ref id="pone.0003536-Peelen1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Peelen</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Downing</surname><given-names>PE</given-names></name>
</person-group>             <year>2005</year>             <article-title>Selectivity for the human body in the fusiform gyrus.</article-title>             <source>J Neurophysiol</source>             <volume>93</volume>             <fpage>603</fpage>             <lpage>608</lpage>          </element-citation></ref>
<ref id="pone.0003536-Todd1"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Todd</surname><given-names>JJ</given-names></name>
<name name-style="western"><surname>Marois</surname><given-names>R</given-names></name>
</person-group>             <year>2004</year>             <article-title>Capacity limit of visual short-term memory in human posterior parietal cortex.</article-title>             <source>Nature</source>             <volume>428</volume>             <fpage>751</fpage>             <lpage>754</lpage>          </element-citation></ref>
<ref id="pone.0003536-Ganel1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ganel</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Valyear</surname><given-names>KF</given-names></name>
<name name-style="western"><surname>Goshen-Gottstein</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Goodale</surname><given-names>MA</given-names></name>
</person-group>             <year>2005</year>             <article-title>The involvement of the “fusiform face area” in processing facial expression.</article-title>             <source>Neuropsychologia</source>             <volume>43(11)</volume>             <fpage>1645</fpage>             <lpage>1654</lpage>          </element-citation></ref>
<ref id="pone.0003536-Vuilleumier2"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vuilleumier</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Pourtois</surname><given-names>G</given-names></name>
</person-group>             <year>2007</year>             <article-title>Distributed and interactive brain mechanisms during emotion face perception: Evidence from functional neuroimaging.</article-title>             <source>Neuropsychologia</source>             <volume>45(1)</volume>             <fpage>174</fpage>             <lpage>194</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>