<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0149431</article-id>
<article-id pub-id-type="publisher-id">PONE-D-15-30969</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Mammals</subject><subj-group><subject>Dogs</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Frontal lobe</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Frontal lobe</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Our Faces in the Dog's Brain: Functional Imaging Reveals Temporal Cortex Activation during Perception of Human Faces</article-title>
<alt-title alt-title-type="running-head">FMRI of Dog's Perception of Human Faces</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Cuaya</surname>
<given-names>Laura V.</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hernández-Pérez</surname>
<given-names>Raúl</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Concha</surname>
<given-names>Luis</given-names>
</name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Instituto de Neurobiología, Universidad Nacional Autónoma de México, Querétaro, México</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Stamatakis</surname>
<given-names>Emmanuel Andreas</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University Of Cambridge, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: LVC RHP LC. Performed the experiments: LVC RHP LC. Analyzed the data: LVC LC. Contributed reagents/materials/analysis tools: RHP LC. Wrote the paper: LVC RHP LC.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">lconcha@unam.mx</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>2</day>
<month>3</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<year>2016</year>
</pub-date>
<volume>11</volume>
<issue>3</issue>
<elocation-id>e0149431</elocation-id>
<history>
<date date-type="received">
<day>15</day>
<month>7</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>1</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Cuaya et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0149431"/>
<abstract>
<p>Dogs have a rich social relationship with humans. One fundamental aspect of it is how dogs pay close attention to human faces in order to guide their behavior, for example, by recognizing their owner and his/her emotional state using visual cues. It is well known that humans have specific brain regions for the processing of other human faces, yet it is unclear how dogs’ brains process human faces. For this reason, our study focuses on describing the brain correlates of perception of human faces in dogs using functional magnetic resonance imaging (fMRI). We trained seven domestic dogs to remain awake, still and unrestrained inside an MRI scanner. We used a visual stimulation paradigm with block design to compare activity elicited by human faces against everyday objects. Brain activity related to the perception of faces changed significantly in several brain regions, but mainly in the bilateral temporal cortex. The opposite contrast (i.e., everyday objects against human faces) showed no significant brain activity change. The temporal cortex is part of the ventral visual pathway, and our results are consistent with reports in other species like primates and sheep, that suggest a high degree of evolutionary conservation of this pathway for face processing. This study introduces the temporal cortex as candidate to process human faces, a pillar of social cognition in dogs.</p>
</abstract>
<funding-group>
<funding-statement>LVC and RHP are doctoral students from Programa de Doctorado en Ciencias Biomédicas at the Universidad Nacional Autónoma de México (UNAM), and received fellowships 260381 and 260395 from the National Council of Science and Technology in Mexico (CONACyT). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="13"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are available via Figshare (<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.6084/m9.figshare.2070007" xlink:type="simple">https://dx.doi.org/10.6084/m9.figshare.2070007</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Faces provide us with valuable information about others, e.g., species, age, gender, motivational and attentional state. There is evidence from behavioral, neuropsychological and neurophysiological studies to suggest the existence of a specialized mechanism to process the perception of faces [<xref ref-type="bibr" rid="pone.0149431.ref001">1</xref>]. In humans, this mechanism is located in the temporal cortex, specifically in the fusiform face area [<xref ref-type="bibr" rid="pone.0149431.ref002">2</xref>], and fMRI studies have shown that this cerebral region responds at least twice as strongly when the participant observes faces in comparison to other classes of visual stimuli [<xref ref-type="bibr" rid="pone.0149431.ref003">3</xref>]. Electrophysiological studies have found that non-human primates have an anatomically and functionally equivalent region required for face perception called the inferotemporal region [<xref ref-type="bibr" rid="pone.0149431.ref004">4</xref>]. However, the processes involved in face perception and discrimination are not the same in all species. For example, Japanese monkeys (<italic>Macaca fuscata</italic>) are incapable of naturally discriminating between two human faces [<xref ref-type="bibr" rid="pone.0149431.ref005">5</xref>], even though they are able to discriminate between two Japanese monkey faces. Dogs (<italic>Canis familiaris</italic>), on the other hand, are perfectly adept at an equivalent task.</p>
<p>Unlike non-human primates, dogs are an excellent model to study the social cognition in a comparative approach, as they possess unique cognitive skills that make them more similar to a human infant than other species [<xref ref-type="bibr" rid="pone.0149431.ref006">6</xref>–<xref ref-type="bibr" rid="pone.0149431.ref010">10</xref>]. Although the ability to discriminate between two human faces is not exclusive to dogs (it has been observed in other species that are in close contact with humans, such as sheep), the detail of the information that a dog can acquire from a mere glimpse towards a human face, even without training [<xref ref-type="bibr" rid="pone.0149431.ref011">11</xref>], is extraordinary. Dogs are especially good at discriminating between two humans, even if they are both familiar to them [<xref ref-type="bibr" rid="pone.0149431.ref012">12</xref>], but also, they have a remarkable ability to pick up small but important signals in a human face, like the attentional state [<xref ref-type="bibr" rid="pone.0149431.ref013">13</xref>] (e.g., they prefer to ask for food from a human with whom they can establish eye contact), and the emotional state [<xref ref-type="bibr" rid="pone.0149431.ref014">14</xref>] (they can discriminate between smiling and neutral faces). Similarly, dogs spend more time looking at a new human face in an image than at a familiar one, which suggests that they can discriminate between individuals using only visual cues [<xref ref-type="bibr" rid="pone.0149431.ref015">15</xref>]. Also, dogs pay significantly less attention to their owner, if the owner has his or her head covered [<xref ref-type="bibr" rid="pone.0149431.ref016">16</xref>]. This tendency to look at a human face during interaction has not been found in other canids, not even in extremely socialized wolves [<xref ref-type="bibr" rid="pone.0149431.ref011">11</xref>]. Altogether, these findings show that dogs are capable of perceiving subtle traits in human faces and that they use this information to modulate their behavior.</p>
<p>Nevertheless, the canine cerebral correlates of face perception have not been addressed. Functional magnetic resonance imaging (fMRI) is a valuable tool to assess regional cortical activity, and has recently been successfully applied in dogs to study auditory [<xref ref-type="bibr" rid="pone.0149431.ref017">17</xref>], visual [<xref ref-type="bibr" rid="pone.0149431.ref018">18</xref>,<xref ref-type="bibr" rid="pone.0149431.ref019">19</xref>] and olfactory [<xref ref-type="bibr" rid="pone.0149431.ref020">20</xref>] processes. In this work we use fMRI to describe the cerebral correlates of human face perception in dogs. This will lead us closer to understanding the underlying cerebral activity of one of the foundations of the dog's social cognition. Our results show several brain regions involved in the processing of faces by dogs, including the bilateral temporal cortex, right frontal cortex, medial frontal cortex, thalamus and caudate nucleus.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Participants</title>
<p>Seven healthy dogs participated in the study (four neutered males and three females; ages 15 to 50 months). The sample included five Border Collies, one Labrador Retriever and one Golden Retriever, all recruited through local families. The main caretaker of each dog gave informed consent and the dogs lived with their human families throughout the study. All procedures were performed in compliance with international ethics and animal care guidelines, and the study was approved by the Bioethics Committee of the Institute of Neurobiology, Universidad Nacional Autónoma de México (File 26RM).</p>
</sec>
<sec id="sec004">
<title>Training</title>
<p>All the dogs completed training prior to the imaging sessions, with the goal being that the dogs remain still inside the scanner while watching images projected during the acquisition of fMRI (<xref ref-type="fig" rid="pone.0149431.g001">Fig 1</xref>). To accomplish this, we first trained the dogs to remain still in sphinx position, with their head supported in a chin rest similar to the one reported in other studies [<xref ref-type="bibr" rid="pone.0149431.ref018">18</xref>]. The chin rest used is adjustable to different dog head sizes, and it helped the dogs maintain the sphinx position. The first part of the training was performed in the dog owner’s house until the dog was able to stay still for five minutes. The next step consisted of training the same behavior in a mock scanner. This part of the training included sounds similar to those produced by the real scanner, the use of noise protectors for dogs and staying still without seeing humans (to prepare for the projection of images). Finally, the last training step was inside the real scanner, adding the positioning of the MRI coil and projection of visual stimuli.</p>
<fig id="pone.0149431.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0149431.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Training procedure for awake dog fMRI.</title>
<p>During a period of approximately four months, dogs learned to stay still and attend to a visual stimulation paradigm within the MRI scanner. First, dogs learned to rest their chin and avoid movement (<bold>A</bold>), followed by habituation to the scanning environment, including scanner sounds and the use of protective headphones, in a mock MRI scanner (<bold>B</bold>). Next, dogs were further trained within the real MRI scanner (<bold>C</bold>) and habituated to the imaging coils (<bold>D</bold>). Upon completion of training, all dogs were able to lie still and awake for periods of up to 15 minutes.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.g001" xlink:type="simple"/>
</fig>
<p>The three training stages were conducted under the same basic principles: at the beginning the dogs habituated to the situation and its new elements; all training sessions lasted a maximum of 15 minutes—if there were multiple sessions in a day, they were interspersed with periods of rest and play. The frequency of training sessions was, on average, once per week. We used shaping, chaining and positive reinforcement to train the behavior, and the dogs could leave the session at any time.</p>
</sec>
<sec id="sec005">
<title>Stimuli</title>
<p>As stimuli, we used photographs of 50 human faces of both genders with a neutral expression extracted from the AR Face Database [<xref ref-type="bibr" rid="pone.0149431.ref021">21</xref>] (with the author's permission), and 50 everyday objects. All face images were presented in a frontal view. In order to have more natural stimuli, all photographs were in color. The images of everyday objects were original photographs. All photographs were taken under the same lighting conditions, were edited to maintain a similar size, and were adjusted to the same brightness and contrast conditions as the AR Face Database photographs. Images were back-projected to a screen in front of the dogs, at a distance of 1.5 m (the maximum distance for a dog to be able to discriminate details on a face is close to six meters [<xref ref-type="bibr" rid="pone.0149431.ref012">12</xref>]). In order to preserve a natural appearance for the stimulus, the size of the projected images was similar to that of a real face (15 cm × 20 cm), as this size has been found to be adequate in other studies [<xref ref-type="bibr" rid="pone.0149431.ref012">12</xref>,<xref ref-type="bibr" rid="pone.0149431.ref014">14</xref>]. Each stimulus was presented only once in each run to avoid habituation to the images.</p>
<p>The visual stimulation paradigm had a block design, with each block lasting 7 s and including 4 images (<xref ref-type="fig" rid="pone.0149431.g002">Fig 2</xref>). There were two types of blocks: unfamiliar <italic>faces</italic> and everyday <italic>objects</italic>; blocks were separated by 12.25 s. The order of the blocks in each run was pseudo randomized. Each fMRI run had duration of 190 s and included 10 blocks (5 of human faces and 5 of everyday objects). Each participant observed 5 runs; in each run the types of block were presented in a different order. Visual stimulus presentation was controlled by PsychoPy2 [<xref ref-type="bibr" rid="pone.0149431.ref022">22</xref>]. The lights in the MRI suite were turned off during paradigm presentation. An experimenter was present in the MRI suite (out of the dog’s sight) during image acquisition to ensure the dog’s compliance with the task. To maximize compliance, only 1–3 runs were acquired per imaging session, with the dogs returning on subsequent days, until 5 runs were acquired successfully.</p>
<fig id="pone.0149431.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0149431.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Visual stimulation paradigm.</title>
<p>We used a block paradigm constituted by two types of blocks: Human faces and Objects. Each block was presented for 7 s, and it was composed of 4 different images (i.e., each image was visible for 1.75 s). At the beginning of each run and after each block, a fixation screen was presented for 12.25 s. The total duration of each run was 190 s, and each dog experienced 5 runs in total. Photographs of faces are reprinted from the AR face database [<xref ref-type="bibr" rid="pone.0149431.ref021">21</xref>] under a CC BY license, with permission from the author.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Data acquisition</title>
<p>All images were acquired at the Institute of Neurobiology at the Universidad Nacional Autónoma de México. We used a 3 T Philips Achieva TX scanner equipped with a SENSE Flex Small coil which consists of two circular elements of 11 cm in diameter, one placed above the cranium and the second underneath the muzzle, both secured with velcro. This kind of coil was successfully used in a previous study, and it has the advantage of being able to fit any dog’s head size [<xref ref-type="bibr" rid="pone.0149431.ref017">17</xref>]. The blood oxygen level dependent (BOLD) images covered the whole brain with 28 contiguous coronal slices acquired with a gradient-echo echo-planar imaging (EPI) sequence (TR/TE = 1750/30 ms; flip angle = 90°; FOV = 224×240 mm<sup>2</sup>, acquisition matrix 112×120, resulting in 2×2×3 mm<sup>3</sup> spatial resolution). Each run included 110 volumes and five dummy scans. Also, a standard T1-weighted structural image with a turbo spin echo sequence with 75 slices covering the whole brain (with 1×1×1 mm<sup>3</sup> spatial resolution) was acquired for anatomical reference and registration.</p>
</sec>
<sec id="sec007">
<title>Image Analysis</title>
<p>All functional images were preprocessed for temporal and motion correction using FSL [<xref ref-type="bibr" rid="pone.0149431.ref023">23</xref>] version 4.19. The brain was extracted using manual segmentation. Spatial smoothing was performed using a Gaussian kernel with FWHM = 7 mm. Motion correction was performed separately on each run. We discarded runs that showed motion throughout the scan, as defined by head rotation greater than 1° or translation greater than 3 mm [<xref ref-type="bibr" rid="pone.0149431.ref017">17</xref>]. Considering all sessions, less than 20% of functional images were discarded. Functional images were spatially normalized to a digital atlas of the dog's brain [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>].</p>
<p>Statistical analyses of fMRI data were performed using the General Linear Model as implemented in FSL. The regressors in this model included stimuli vectors of human faces and everyday objects. Regressors were convolved with the canonical hemodynamic response function modeled as a Gamma function. First, each run was analyzed individually in a first level. Next, for each participant, we made a single subject fixed effect analysis with five runs. At the group level we made a random effects analysis with the seven participants. In order to describe the cerebral regions involved in the perception of human faces, we analyzed the contrasts faces vs. objects in a whole-brain, voxel-wise analysis. The resulting statistical parametric maps were threshold using random field theory [<xref ref-type="bibr" rid="pone.0149431.ref025">25</xref>] (thresholded at z &gt; 2.2 and p<sub>cluster</sub> &lt; 0.05). To localize and label the cerebral structures, we used two atlases: the digital atlas of Datta et al. [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>] that is derived from fifteen mesocephalic dogs (this category includes breeds similar to the ones used herein) and the Beagle Brain in Stereotaxic Coordinates of Palazzi [<xref ref-type="bibr" rid="pone.0149431.ref026">26</xref>]. Coordinates reported refer to the Datta atlas.</p>
<p>We created a sphere of 5 mm radius around the voxel with the maximum <italic>z</italic> value to extract the BOLD signal change. The BOLD responses for faces and objects derived from this spherical region of interest were compared using a two tailed paired t-test and differences were deemed significant if p &lt; 0.05.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<p>The time to complete the training varied among participants because the frequency of the sessions differed and ranged from 1 to 4 months. The experimenter inside the scanner room visually monitored the dogs to make sure they were awake and attentive. As maintenance of the sphinx position requires muscle tone, loss of which would result in major head movement, the criteria used for motion correction of imaging data further guarantee that the dogs remained awake.</p>
<p>To describe the brain correlates of human face perception in dogs, we contrasted the activity of human faces and everyday objects (human faces &gt; objects), which revealed two clusters (<xref ref-type="fig" rid="pone.0149431.g003">Fig 3</xref>). The first cluster (37,420 mm<sup>3</sup>) was located in the left temporal cortex and extended to the frontal cortex, the caudate nucleus and the thalamus. The second cluster (30,404 mm<sup>3</sup>) was located in the right frontal cortex and extended to the right temporal cortex (see <xref ref-type="supplementary-material" rid="pone.0149431.s001">S1 Fig</xref> and <xref ref-type="supplementary-material" rid="pone.0149431.s004">S1 Table</xref> for information about the location and BOLD signal change within local maxima of these clusters). All dogs showed a clearly different BOLD response to each stimulus category, which is evident from the data extracted from a sphere centered at the peak <italic>z</italic> value in each resulting cluster (<xref ref-type="fig" rid="pone.0149431.g003">Fig 3C and 3F</xref>).</p>
<fig id="pone.0149431.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0149431.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Human faces &gt; Objects (n = 7).</title>
<p>The two largest resulting clusters are shown overlaid on the Datta atlas [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>]. <bold>A.</bold> Sagittal slice of the temporal cluster, which shows activity within the left temporal and frontal cortices. <bold>B.</bold> Coronal slice shows the left temporal cluster, which extends to the thalamus. <bold>C.</bold> BOLD signal change in a 5 mm of radius sphere around the voxel with maximum <italic>z</italic> value for the left temporal cluster (blue sphere in A and B). <bold>D.</bold> Sagittal slice of the frontal cluster, which is located in the right frontal temporal and cortices. <bold>E.</bold> Coronal slice of the frontal cluster. <bold>F.</bold> BOLD signal change in a 5 mm of radius sphere around the voxel with maximum <italic>z</italic> value for the right frontal cluster (blue sphere in D and E). <bold>G-I.</bold> Volume renderings of the same results, seen in left lateral, basal and right lateral views, respectively. S = Superior, I = Inferior, L = Left, R = Right, P = Posterior and, A = Anterior. 1 = Temporal Cortex, 2 = Thalamus, 3 = Lateral Frontal Cortex, 4 = Temporal Cortex, 5 = Medial Frontal Cortex. The oblique lines in C and F represent data of each participant, while vertical lines denote the standard error (*** &lt; 0.001, **&lt;0.01).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.g003" xlink:type="simple"/>
</fig>
<p>The temporal cortex showed bilateral activation in the contrast human face &gt; objects, as shown in <xref ref-type="fig" rid="pone.0149431.g004">Fig 4</xref>. The left temporal lobe showed a greater extent of activation than the right temporal lobe. However, an analysis of BOLD signal of a spherical region (5 mm radius) in two homologous regions inside the temporal activations showed no inter-hemispheric asymmetry of the differential responses to faces and objects (p = 0.95). The opposite contrast (objects &gt; human faces) showed no significant differences, even when the <italic>z</italic> value threshold was decreased to 1.6.</p>
<fig id="pone.0149431.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0149431.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Bilateral temporal cortex in the contrast Human faces &gt; Objects (n = 7).</title>
<p>The cerebral activity focused in the temporal cortex is shown overlaid on the Datta atlas [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>]. <bold>A.</bold> Left hemisphere in a sagittal slice. <bold>B.</bold> Bilateral temporal cortex in a coronal slice. <bold>C.</bold> Right hemisphere in a sagittal slice. Dashed lines in B show the location of the sagittal slices shown in A and C. <bold>D.</bold> BOLD signal change in a sphere of 5 mm radius sphere centered at the voxel with maximum <italic>z</italic> value for the both hemispheres (blue spheres show in A, B and C). Oblique lines represent the data of each participant and vertical lines represent standard error. * &lt; 0.05; ** &lt; 0.01.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.g004" xlink:type="simple"/>
</fig>
<p>The peri-stimulus time course of the BOLD signal was extracted from a sphere (5 mm radius) centered at the voxel with the maximum <italic>z</italic> value for the contrast face &gt; objects within the temporal cluster in each participant (blue sphere in <xref ref-type="fig" rid="pone.0149431.g003">Fig 3A and 3B</xref>). The average of all blocks for all participants showed significant differences between human faces and objects, 3.5 seconds after the start of the block; this difference was maintained for 7 seconds (<xref ref-type="supplementary-material" rid="pone.0149431.s002">S2 Fig</xref>). Interestingly, the hemodynamic response was modulated by human faces and objects in opposite directions, with an increase in response to human faces as large as the decrease in signal in response to objects. The hemodynamic response to human faces is consistent with a previous study in dogs, with a peak in the response 3–5 seconds after the stimuli [<xref ref-type="bibr" rid="pone.0149431.ref027">27</xref>].</p>
<p>At the subject level, there was variability in the location of regions most sensitive to faces (<xref ref-type="fig" rid="pone.0149431.g005">Fig 5</xref>). We specifically searched for these regions within the Sylvian gyrus bilaterally [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>], and extracted BOLD signal change from spheres of 5 mm radius (see <xref ref-type="supplementary-material" rid="pone.0149431.s005">S2 Table</xref> for coordinates of each sphere). Despite slight anatomical variability, all dogs showed a very similar pattern of differential BOLD activity in response to each type of stimulus (<xref ref-type="fig" rid="pone.0149431.g005">Fig 5D</xref>).</p>
<fig id="pone.0149431.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0149431.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Location of the most sensitive region for faces in each participant in the temporal cortex.</title>
<p><bold>A-C:</bold> Left lateral, anterior and right lateral views showing spheres of 5 mm radius in each hemisphere, colored differently for each dog. <bold>D:</bold> BOLD signal change in both hemispheres in response to faces and objects within the sphere of each participant. Lines represent the data of each dog, colors according to spheres in A-C. Vertical lines represent the standard error (*** &lt; 0.001).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.g005" xlink:type="simple"/>
</fig>
<p>In a separate analysis, we contrasted human faces &gt; objects, but only within those voxels that had already shown a significant activity in response to any of the two types of visual stimuli, with respect to baseline. The cluster showing activity to any type of visual stimulus was large and, as expected, restricted to the occipital lobes (164,443 mm<sup>3</sup>). There were several regions within this large cluster that showed a differential activation favoring faces over objects (<xref ref-type="supplementary-material" rid="pone.0149431.s003">S3 Fig</xref>), but these were only seen on uncorrected statistical maps (thresholded at p<sub>uncorr</sub> &lt; 0.05), and these regions were not significant after correction for multiple comparisons.</p>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>The present study reveals fMRI evidence of cortical and subcortical activity related to visual processing of human faces in the dog brain, particularly within ventral-posterior regions of the temporal lobes (Figs <xref ref-type="fig" rid="pone.0149431.g003">3</xref> and <xref ref-type="fig" rid="pone.0149431.g004">4</xref>). We suggest that this portion of the temporal cortex in dogs could be anatomically and functionally similar to regions found in other species, like humans [<xref ref-type="bibr" rid="pone.0149431.ref001">1</xref>], non-human primates [<xref ref-type="bibr" rid="pone.0149431.ref028">28</xref>] and sheep [<xref ref-type="bibr" rid="pone.0149431.ref029">29</xref>], which suggests a high degree of evolutionary conservation of the ventral visual pathway for face processing. The most consistent and robust face-selective activation in humans is located on the lateral side of the mid-fusiform gyrus [<xref ref-type="bibr" rid="pone.0149431.ref002">2</xref>] within the temporal lobe, which is in line with a recent report using similar methodology [<xref ref-type="bibr" rid="pone.0149431.ref019">19</xref>]. There are remarkable similarities in face processing in macaques and sheep, which suggest that they have a similar specialized mechanism for face perception localized in the temporal cortex [<xref ref-type="bibr" rid="pone.0149431.ref030">30</xref>]. Using fMRI, face-selective regions have been found in the inferior temporal lobe in macaques [<xref ref-type="bibr" rid="pone.0149431.ref028">28</xref>]. Similarly, electrophysiological studies have demonstrated that sheep have neuronal populations in the temporal cortex that respond preferentially to faces [<xref ref-type="bibr" rid="pone.0149431.ref030">30</xref>]. In the case of dogs, the Sylvian gyrus (ventral temporal cortex) displays robust activity to faces in comparison to objects. However, in comparison to studies performed on humans and non-human primates, the anatomical location of face sensitive regions we show in awake dogs is more variable amongst individuals (<xref ref-type="fig" rid="pone.0149431.g005">Fig 5</xref>); this variability could be due to anatomical or functional differences between subjects, but may also be due to the fact that primate studies have much higher signal-to-noise ratio than one achieved in this study. Humans, too, show some anatomic variability of FFA [<xref ref-type="bibr" rid="pone.0149431.ref031">31</xref>], albeit to a lesser degree than what we show in dogs. This variability was also noted in dogs in a recent study of face processing in dogs; in that study, similarly to our results, face processing regions were located within the temporal cortices in all participants [<xref ref-type="bibr" rid="pone.0149431.ref019">19</xref>]. It is interesting that in humans [<xref ref-type="bibr" rid="pone.0149431.ref001">1</xref>], non-human primates [<xref ref-type="bibr" rid="pone.0149431.ref028">28</xref>,<xref ref-type="bibr" rid="pone.0149431.ref032">32</xref>], sheep [<xref ref-type="bibr" rid="pone.0149431.ref029">29</xref>] and dogs, the processing of faces involves the temporal cortex, albeit not in the exact same location. Even across the primates, humans and macaques differ in terms of the location and number of regions sensitive to faces, suggesting a shift of the location of the face area throughout primate evolution [<xref ref-type="bibr" rid="pone.0149431.ref033">33</xref>]. While precise function of each patch sensitive to faces in the macaque brain is still unclear [<xref ref-type="bibr" rid="pone.0149431.ref033">33</xref>], the anterior medial patch is the only region that shows clear activity in response to faces shown in any angle [<xref ref-type="bibr" rid="pone.0149431.ref034">34</xref>] making it a likely homologue to FFA in humans. Future studies are needed to test whether an analogue of these regions exists in dogs.</p>
<p>As has been seen in humans [<xref ref-type="bibr" rid="pone.0149431.ref001">1</xref>], face processing in dogs revealed activity in several brain areas beyond the temporal lobe, including the medial and lateral frontal cortex. A previous fMRI study with dogs reported activity in the medial frontal cortex related to familiar scents, especially to a familiar dog scent [<xref ref-type="bibr" rid="pone.0149431.ref020">20</xref>]. It is possible that the activity in the medial frontal cortex reflects familiarity with, or salience of, the kind of stimulus presented. In our case, it may be that dogs were more familiar with a human face than with objects and thus, showed enhanced activity in the medial frontal cortex. Alternatively, activation of the medial frontal cortex may be due to a greater salience of faces as compared with objects. The activity in the lateral frontal region was found mainly, but not exclusively, in the right hemisphere. There are behavioral traits that are suggestive of right hemispheric preference related to novel [<xref ref-type="bibr" rid="pone.0149431.ref035">35</xref>] or emotionally charged stimuli, such as listening to a thunderstorm [<xref ref-type="bibr" rid="pone.0149431.ref036">36</xref>] or to human commands with intonational salience [<xref ref-type="bibr" rid="pone.0149431.ref037">37</xref>]. The faces we used in our paradigm were not familiar to the dogs and qualified as emotionally neutral, yet it is known that these faces can often be interpreted as negative by humans [<xref ref-type="bibr" rid="pone.0149431.ref038">38</xref>]; the right hemispheric preference seen in our results could be the due to the salience or valence assigned by dogs' perception of human faces. Nonetheless, we cannot rule out that, as with other species, the activity seen in the frontal cortex is related to other functional processes [<xref ref-type="bibr" rid="pone.0149431.ref039">39</xref>].</p>
<p>We also found activity in subcortical structures, namely in the caudate and the thalamus. The caudate activations are especially interesting, because this cerebral structure has been reported in several studies in dogs using fMRI. In the first study, the authors suggested that the caudate activation is associated with reward [<xref ref-type="bibr" rid="pone.0149431.ref027">27</xref>]. In a later study [<xref ref-type="bibr" rid="pone.0149431.ref018">18</xref>], the authors replicated the caudate activation and found that the activation was greater in service dogs when a human was showing them a sign related to a reward. In a different study, the caudate activation was related to a scent of familiar humans and dogs, but the maximum response was to the scent of a familiar human [<xref ref-type="bibr" rid="pone.0149431.ref020">20</xref>]. In this light, our data suggest that the caudate region is involved in reward processes, but not necessarily related to familiar stimuli. It is possible that, for a dog, observing a human face is intrinsically more rewarding than the sight of an object, in line with behavioral studies that have proven that dogs find human faces to be a salient stimulus [<xref ref-type="bibr" rid="pone.0149431.ref010">10</xref>]. The thalamus has been related in humans to an emotional response towards faces [<xref ref-type="bibr" rid="pone.0149431.ref040">40</xref>–<xref ref-type="bibr" rid="pone.0149431.ref042">42</xref>]. The face stimuli used in our study were neutral, although we don't have a way of knowing how dogs interpret faces and, given our current data, it is difficult to link the thalamic activity to a specific cognitive process.</p>
<p>There are other regions related to processing of faces in humans, such as the occipital face area and the posterior region of the superior temporal sulcus [<xref ref-type="bibr" rid="pone.0149431.ref001">1</xref>]. These regions are thought to be a set of stages in the hierarchical processing for face perception [<xref ref-type="bibr" rid="pone.0149431.ref043">43</xref>]. When we restricted our statistical analyses to regions active in response to visual stimuli (regardless their category) with respect to baseline, we found face-selective regions within the occipital lobes, (<xref ref-type="supplementary-material" rid="pone.0149431.s003">S3 Fig</xref>). However, these results were not corrected for multiple comparisons and we cannot conclude that this activity is similar to occipital face area seen in humans.</p>
<p>One limitation in our study is that the dogs passively viewed the stimuli; we minimized the potential of habituation by presenting each stimulus only twice throughout the experiment, but we cannot be certain if the dog has stopped paying attention. An open challenge is to receive an active behavioral response from the dogs without promoting movement. Also, we did not determine the spatial viewing pattern of images in our participants. There is evidence using eye tracking that dogs show significant differences in the number of fixations and total fixation duration between a blank screen and images, and dogs show a higher total duration time when observing a human in comparison to an object [<xref ref-type="bibr" rid="pone.0149431.ref044">44</xref>].</p>
<p>Given the importance of the faces for social behavior, we see this study as the beginning of new efforts to find the cerebral correlates of the perception and processing of faces in dogs. An important unclear issue is how dogs represent faces. In this study we focused only in human faces, mainly for the mutual attachment between dogs and humans [<xref ref-type="bibr" rid="pone.0149431.ref045">45</xref>,<xref ref-type="bibr" rid="pone.0149431.ref046">46</xref>] and because there is plenty of evidence that dogs can extract valuable information from human faces, like emotional state or identity [<xref ref-type="bibr" rid="pone.0149431.ref012">12</xref>,<xref ref-type="bibr" rid="pone.0149431.ref014">14</xref>]. The recognition of human faces in dogs may have been a crucial factor for their adaptation, given their natural anthropogenic niche, as some dogs can have more contact with human faces than with other dogs’ faces [<xref ref-type="bibr" rid="pone.0149431.ref012">12</xref>]. The recognition of human faces by dogs could be an essential factor for establishing attachment with humans. This is supported by the evidence found so far, that dogs, and no other canids, are able to recognize and attend to human faces without training [<xref ref-type="bibr" rid="pone.0149431.ref011">11</xref>]. Nonetheless, it is important to recognize that, given our data, we cannot determine if the temporal cortex is involved in the representations of faces in general, as we did not include faces of other species, including dogs. A recent study [<xref ref-type="bibr" rid="pone.0149431.ref019">19</xref>], however, suggests that the temporal cortex is involved in processing of faces of humans, as well as dogs; our results confirm and expand these findings showing that the temporal cortex, in conjunction with frontal cortex, thalamus and caudate, is involved in the perception of human faces. Moreover, our experimental design allowed for comparison of visual stimulation to baseline activity, allowing the identification of occipital regions suggestive of face processing.</p>
<p>Given that face recognition is present in all major vertebrate taxa, it is possible that visual species recognition emerged early in the evolution of mammals [<xref ref-type="bibr" rid="pone.0149431.ref047">47</xref>]. Besides, many species exhibit a conspecific advantage (the recognition and discrimination of members of their own species more readily than other species) [<xref ref-type="bibr" rid="pone.0149431.ref047">47</xref>], and it is therefore possible that face recognition of humans in dogs occurs in the same specialized neural and cognitive mechanisms used to process faces of its own species. We suggest that a general face processing system is localized in the temporal cortex, while categorization between species occurs in other cerebral regions, although (given the stimulation paradigm used) our present data cannot test this.</p>
<p>The comparison of the cognitive processes across different species will allow us to broaden our understanding of cognition and will help us construct a bottom-up perspective focused on the underlying cerebral mechanisms [<xref ref-type="bibr" rid="pone.0149431.ref048">48</xref>]. The use of dogs as a model allows us to explore fascinating topics of comparative social cognition, like the refinements produced by adaptations to an anthropogenic niche. Dogs have a predisposition to cooperate with humans [<xref ref-type="bibr" rid="pone.0149431.ref006">6</xref>] that, combined with non-invasive methodologies, make a perfect marriage for their use as a model. More than ten years ago Miklósi, Topál &amp; Csányi wrote about "The beginning of an adventure" [<xref ref-type="bibr" rid="pone.0149431.ref007">7</xref>], and thanks to them and other groups, we know more today about our best friend. This adventure now includes information derived from functional imaging studies with awake and unrestrained dogs, as pioneered by Berns, Brooks &amp; Spivak [<xref ref-type="bibr" rid="pone.0149431.ref027">27</xref>]. We hope that our study contributes to a better understanding of one of the foundations of social cognition in dogs: the perception of human faces.</p>
</sec>
<sec id="sec010">
<title>Supporting Information</title>
<supplementary-material id="pone.0149431.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>BOLD signal change in the local maxima of each of the two clusters resulting from the contrast faces &gt; objects.</title>
<p>The BOLD signal change was extracted from a sphere of 5 mm of radius around each local maxima (see <xref ref-type="supplementary-material" rid="pone.0149431.s004">S1 Table</xref> for corresponding spatial information). <bold>A.</bold> Local maxima within the Temporal cluster. <bold>B.</bold> Local maxima within the Frontal cluster. The vertical lines represent the standard error (* &lt; 0.05, ** &lt; 0.01; *** &lt; 0.001).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0149431.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Peri-stimulus BOLD time course for faces and objects in temporal cortex (n = 7).</title>
<p>The responses of all blocks for all participants were averaged. Dotted lines mark the start and end of the stimulation block. There are significant differences in the response between human faces and objects between 3.5 and 10.5 seconds after the presentation of the stimuli. * &lt; 0.05, ** &lt; 0.01; *** &lt; 0.001.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0149431.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Human faces &gt; Objects in visual areas (n = 7).</title>
<p>Volume renderings of the Datta atlas (grayscale) and statistical parametric maps. Hot colors indicate the regions showing increased BOLD activity in response to visual stimuli (regardless of category), with respect to baseline. Cool colors show regions within the already identified visual areas that showed a differential activation favoring faces over objects, thresholded at p<sub>uncorr</sub> &lt; 0.05. <bold>A.</bold> Posterior view. <bold>B.</bold> Superior view. <bold>C.</bold> Lateral view of the left hemisphere. <bold>D.</bold> Lateral view of the right hemisphere.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0149431.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.s004" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Local Maxima of the temporal and frontal clusters resulting from the Contrast Faces &gt; Objects.</title>
<p>Coordinates are given according to the Datta atlas [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>].</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0149431.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0149431.s005" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Localization of the center of individual spheres in the Sylvian gyrus.</title>
<p>Coordinates are given in mm, according to Datta atlas [<xref ref-type="bibr" rid="pone.0149431.ref024">24</xref>].</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>Our thanks to our participants and their caregivers for their cooperation, patience and friendship: Andrea Dávila and Lourdes Guajardo (Zilla), Ariadna Ríos and Ariel Mendoza (Hera), Daniel Ramírez (Kora), Lenin Ochoa and Jessica Moreno (Morris), Luis Nájera and Liza Guerrero (Morante), and of course to Odín and Kun-kun. We also thank Javier García, Ángeles Zavala, Humberto Jackson, Juan Ortiz and Erick Pasaye for their support during image acquisition, and Víctor de Lafuente, Juan Fernández Ruiz, Sarael Alcauter, Daniel Ríos, Azalea Reyes and Eduardo Rojas for their helpful comments and support during the different stages of this project. We are grateful to Dorothy Pless for proofreading and editing, and V. Garciadiego Cano for the photographs shown in <xref ref-type="fig" rid="pone.0149431.g001">Fig 1C and 1D</xref>. LVC and RHP are doctoral students from Programa de Doctorado en Ciencias Biomédicas, Universidad Nacional Autónoma de México (UNAM). Finally, we thank the reviewers for their valuable suggestions and comments that improved this study.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0149431.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>. <article-title>The fusiform face area: a cortical region specialized for the perception of faces</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2006</year>;<volume>361</volume>: <fpage>2109</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2006.1934" xlink:type="simple">10.1098/rstb.2006.1934</ext-link></comment> <object-id pub-id-type="pmid">17118927</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name>. <article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title>. <source>J Neurosci</source>. <year>1997</year>;<volume>17</volume>: <fpage>4302</fpage>–<lpage>4311</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/Rstb.2006.1934" xlink:type="simple">10.1098/Rstb.2006.1934</ext-link></comment> <object-id pub-id-type="pmid">9151747</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>Functional specificity in the human brain: A window into the functional architecture of the mind</article-title>. <source>Proc Natl Acad Sci</source>. <year>2010</year>;<volume>107</volume>: <fpage>11163</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1005062107" xlink:type="simple">10.1073/pnas.1005062107</ext-link></comment> <object-id pub-id-type="pmid">20484679</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parr</surname> <given-names>LA</given-names></name>. <article-title>The evolution of face processing in primates</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2011</year>;<volume>366</volume>: <fpage>1764</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2010.0358" xlink:type="simple">10.1098/rstb.2010.0358</ext-link></comment> <object-id pub-id-type="pmid">21536559</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sugita</surname> <given-names>Y</given-names></name>. <article-title>Face perception in monkeys reared with no exposure to faces</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year>;<volume>105</volume>: <fpage>394</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0706079105" xlink:type="simple">10.1073/pnas.0706079105</ext-link></comment> <object-id pub-id-type="pmid">18172214</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hare</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tomasello</surname> <given-names>M</given-names></name>. <article-title>Human-like social skills in dogs?</article-title> <source>Trends Cogn Sci</source>. <year>2005</year>;<volume>9</volume>: <fpage>439</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2005.07.003" xlink:type="simple">10.1016/j.tics.2005.07.003</ext-link></comment> <object-id pub-id-type="pmid">16061417</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miklósi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Topál</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Csányi</surname> <given-names>V</given-names></name>. <article-title>Comparative social cognition: what can dogs teach us?</article-title> <source>Anim Behav</source>. <year>2004</year>;<volume>67</volume>: <fpage>995</fpage>–<lpage>1004</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2003.10.008" xlink:type="simple">10.1016/j.anbehav.2003.10.008</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Topál</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gergely</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Erdohegyi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Csibra</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Miklósi</surname> <given-names>A</given-names></name>. <article-title>Differential sensitivity to human communication in dogs, wolves, and human infants</article-title>. <source>Science (80-)</source>. <year>2009</year>;<volume>325</volume>: <fpage>1269</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1176960" xlink:type="simple">10.1126/science.1176960</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bräuer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kaminski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Riedel</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Call</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tomasello</surname> <given-names>M</given-names></name>. <article-title>Making Inferences about the location of hidden food: Social dog, causal ape</article-title>. <source>J Comp Psychol</source>. <year>2006</year>;<volume>120</volume>: <fpage>38</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0735-7036.120.1.38" xlink:type="simple">10.1037/0735-7036.120.1.38</ext-link></comment> <object-id pub-id-type="pmid">16551163</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref010"><label>10</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Miklósi</surname> <given-names>Á</given-names></name>. <source>Dog behavior, evolution and cognition</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="pone.0149431.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miklósi</surname> <given-names>Á</given-names></name>, <name name-style="western"><surname>Kubinyi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Topál</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gácsi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Virányi</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Csányi</surname> <given-names>V</given-names></name>. <article-title>A simple reason for a big difference: wolves do not look back at humans, but dogs do</article-title>. <source>Curr Biol</source>. <year>2003</year>;<volume>13</volume>: <fpage>763</fpage>–<lpage>766</lpage>. <object-id pub-id-type="pmid">12725735</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huber</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Racca</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Scaf</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Virányi</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Range</surname> <given-names>F</given-names></name>. <article-title>Discrimination of familiar human faces in dogs (Canis familiaris)</article-title>. <source>Learn Motiv. Elsevier Ltd</source>; <year>2013</year>;<volume>44</volume>: <fpage>258</fpage>–<lpage>269</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.lmot.2013.04.005" xlink:type="simple">10.1016/j.lmot.2013.04.005</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gácsi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Miklód</surname> <given-names>Á</given-names></name>, <name name-style="western"><surname>Varga</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Topál</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Csányi</surname> <given-names>V</given-names></name>. <article-title>Are readers of our face readers of our minds? Dogs (Canis familiaris) show situation-dependent recognition of human’s attention</article-title>. <source>Anim Cogn</source>. <year>2004</year>;<volume>7</volume>: <fpage>144</fpage>–<lpage>153</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-003-0205-8" xlink:type="simple">10.1007/s10071-003-0205-8</ext-link></comment> <object-id pub-id-type="pmid">14669075</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nagasawa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Murai</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mogi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kikusui</surname> <given-names>T</given-names></name>. <article-title>Dogs can discriminate human smiling faces from blank expressions</article-title>. <source>Anim Cogn</source>. <year>2011</year>;<volume>14</volume>: <fpage>525</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-011-0386-5" xlink:type="simple">10.1007/s10071-011-0386-5</ext-link></comment> <object-id pub-id-type="pmid">21359654</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Racca</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Amadei</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ligout</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Guo</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Meints</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mills</surname> <given-names>D</given-names></name>. <article-title>Discrimination of human and dog faces and inversion responses in domestic dogs (Canis familiaris)</article-title>. <source>Anim Cogn</source>. <year>2010</year>;<volume>13</volume>: <fpage>525</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-009-0303-3" xlink:type="simple">10.1007/s10071-009-0303-3</ext-link></comment> <object-id pub-id-type="pmid">20020168</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mongillo</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Bono</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Regolin</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Marinelli</surname> <given-names>L</given-names></name>. <article-title>Selective attention to humans in companion dogs, Canis familiaris</article-title>. <source>Anim Behav. Elsevier Ltd</source>; <year>2010</year>;<volume>80</volume>: <fpage>1057</fpage>–<lpage>1063</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2010.09.014" xlink:type="simple">10.1016/j.anbehav.2010.09.014</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andics</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gácsi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Faragó</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kiz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Miklósi</surname> <given-names>Á</given-names></name>. <article-title>Report Voice-Sensitive Regions in the Dog and Human Brain Are Revealed by Comparative fMRI</article-title>. <source>Curr Biol</source>. <year>2014</year>;<volume>24</volume>: <fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="pone.0149431.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berns</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Brooks</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Spivak</surname> <given-names>M</given-names></name>. <article-title>Replicability and heterogeneity of awake unrestrained canine FMRI responses</article-title>. <source>PLOS One</source>. <year>2013</year>;<volume>8</volume>: <fpage>e81698</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0081698" xlink:type="simple">10.1371/journal.pone.0081698</ext-link></comment> <object-id pub-id-type="pmid">24324719</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dilks</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Cook</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Weiller</surname> <given-names>SK</given-names></name>, <name name-style="western"><surname>Berns</surname> <given-names>HP</given-names></name>, <name name-style="western"><surname>Spivak</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Berns</surname> <given-names>GS</given-names></name>. <article-title>Awake fMRI reveals a specialized region in dog temporal cortex for face processing</article-title>. <source>PeerJ</source>. <year>2015</year>;<volume>3</volume>: <fpage>e1115</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7717/peerj.1115" xlink:type="simple">10.7717/peerj.1115</ext-link></comment> <object-id pub-id-type="pmid">26290784</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berns</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Brooks</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Spivak</surname> <given-names>M</given-names></name>. <article-title>Scent of the familiar: An fMRI study of canine brain responses to familiar and unfamiliar human and dog odors</article-title>. <source>Behav Processes. Elsevier B.V.</source>; <year>2014</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.beproc.2014.02.011" xlink:type="simple">10.1016/j.beproc.2014.02.011</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Martinez</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Benavente</surname> <given-names>R</given-names></name>. <article-title>The AR face database</article-title>. <source>CVC Tech Rep</source>. <year>1998</year>;<volume>24</volume>.</mixed-citation></ref>
<ref id="pone.0149431.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peirce</surname> <given-names>JW</given-names></name>. <article-title>PsychoPy-Psychophysics software in Python</article-title>. <source>J Neurosci Methods</source>. <year>2007</year>;<volume>162</volume>: <fpage>8</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2006.11.017" xlink:type="simple">10.1016/j.jneumeth.2006.11.017</ext-link></comment> <object-id pub-id-type="pmid">17254636</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jenkinson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Beckmann</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>. <article-title>Fsl</article-title>. <source>Neuroimage</source>. <year>2012</year>;<volume>62</volume>: <fpage>782</fpage>–<lpage>790</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2011.09.015" xlink:type="simple">10.1016/j.neuroimage.2011.09.015</ext-link></comment> <object-id pub-id-type="pmid">21979382</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Datta</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Duda</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Avants</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Vite</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Tseng</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>A Digital Atlas of the Dog Brain</article-title>. <source>PLOS One</source>. <year>2012</year>;<volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0052140" xlink:type="simple">10.1371/journal.pone.0052140</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref025"><label>25</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Worsley</surname> <given-names>KJ</given-names></name>. <chapter-title>Statistical analysis of activation images</chapter-title>. In: <name name-style="western"><surname>Jezzard</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Matthews</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, editors. <source>Functional MRI: an introduction to methods</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>2001</year>. pp. <fpage>251</fpage>–<lpage>270</lpage>.</mixed-citation></ref>
<ref id="pone.0149431.ref026"><label>26</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Palazzi</surname> <given-names>X</given-names></name>. <source>The Beagle Brain in Stereotaxic Coordinates</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2011</year>.</mixed-citation></ref>
<ref id="pone.0149431.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berns</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Brooks</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Spivak</surname> <given-names>M</given-names></name>. <article-title>Functional MRI in awake unrestrained dogs</article-title>. <source>PLOS One</source>. <year>2012</year>;<volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0038027" xlink:type="simple">10.1371/journal.pone.0038027</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>, <name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Knutsen</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Mandeville</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name>. <article-title>Faces and objects in macaque cerebral cortex</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>989</fpage>–<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1111" xlink:type="simple">10.1038/nn1111</ext-link></comment> <object-id pub-id-type="pmid">12925854</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kendrick</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>da Costa</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Leigh</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Peirce</surname> <given-names>JW</given-names></name>. <article-title>Sheep don’t forget a face</article-title>. <source>Nature</source>. <year>2001</year>;<volume>414</volume>: <fpage>165</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35102669" xlink:type="simple">10.1038/35102669</ext-link></comment> <object-id pub-id-type="pmid">11700543</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tate</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Leigh</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Kendrick</surname> <given-names>KM</given-names></name>. <article-title>Behavioural and neurophysiological evidence for face identity and face emotion processing in animals</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2006</year>;<volume>361</volume>: <fpage>2155</fpage>–<lpage>2172</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2006.1937" xlink:type="simple">10.1098/rstb.2006.1937</ext-link></comment> <object-id pub-id-type="pmid">17118930</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saxe</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brett</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>Divide and conquer: A defense of functional localizers</article-title>. <source>Neuroimage</source>. <year>2006</year>;<volume>30</volume>: <fpage>1088</fpage>–<lpage>1096</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2005.12.062" xlink:type="simple">10.1016/j.neuroimage.2005.12.062</ext-link></comment> <object-id pub-id-type="pmid">16635578</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parr</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Hecht</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Barks</surname> <given-names>SK</given-names></name>, <name name-style="western"><surname>Preuss</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Votaw</surname> <given-names>JR</given-names></name>. <article-title>Face processing in the chimpanzee brain</article-title>. <source>Curr Biol. Elsevier Ltd</source>; <year>2009</year>;<volume>19</volume>: <fpage>50</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2008.11.048" xlink:type="simple">10.1016/j.cub.2008.11.048</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>, <name name-style="western"><surname>Moeller</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name>. <article-title>Comparing face patch systems in macaques and humans</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year>;<volume>105</volume>: <fpage>19514</fpage>–<lpage>19519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0809662105" xlink:type="simple">10.1073/pnas.0809662105</ext-link></comment> <object-id pub-id-type="pmid">19033466</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>. <article-title>Functional Compartmentalization and Viewpoint Generalization Within the Macaque Face-Prcessing System</article-title>. <source>Science (80-)</source>. <year>2010</year>;<volume>330</volume>: <fpage>845</fpage>–<lpage>852</lpage>.</mixed-citation></ref>
<ref id="pone.0149431.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Siniscalchi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sasso</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pepe</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Dimatteo</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vallortigara</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Quaranta</surname> <given-names>A</given-names></name>. <article-title>Sniffing with the right nostril: Lateralization of response to odour stimuli by dogs</article-title>. <source>Anim Behav</source>. <year>2011</year>;<volume>82</volume>: <fpage>399</fpage>–<lpage>404</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2011.05.020" xlink:type="simple">10.1016/j.anbehav.2011.05.020</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Siniscalchi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Quaranta</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rogers</surname> <given-names>LJ</given-names></name>. <article-title>Hemispheric specialization in dogs for processing different acoustic stimuli</article-title>. <source>PLOS One</source>. <year>2008</year>;<volume>3</volume>: <fpage>1</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0003349" xlink:type="simple">10.1371/journal.pone.0003349</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliffe</surname> <given-names>VF</given-names></name>, <name name-style="western"><surname>Reby</surname> <given-names>D</given-names></name>. <article-title>Orienting Asymmetries in Dogs’ Responses to Different Communicatory Components of Human Speech</article-title>. <source>Curr Biol. Elsevier Ltd</source>; <year>2014</year>; <fpage>1</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2014.10.030" xlink:type="simple">10.1016/j.cub.2014.10.030</ext-link></comment></mixed-citation></ref>
<ref id="pone.0149431.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kang</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>IH</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>An</surname> <given-names>SK</given-names></name>. <article-title>Is a neutral face really evaluated as being emotionally neutral?</article-title> <source>Psychiatry Res</source>. <year>2008</year>;<volume>157</volume>: <fpage>77</fpage>–<lpage>85</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.psychres.2007.02.005" xlink:type="simple">10.1016/j.psychres.2007.02.005</ext-link></comment> <object-id pub-id-type="pmid">17804083</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref039"><label>39</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Fuster</surname> <given-names>J</given-names></name>. <source>The prefrontal cortex</source>. <edition>Fourth</edition>. <publisher-loc>Londres</publisher-loc>: <publisher-name>Elsevier</publisher-name>; <year>2008</year>.</mixed-citation></ref>
<ref id="pone.0149431.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Armony</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Distinct spatial frequency sensitivities for processing faces and emotional expressions</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>624</fpage>–<lpage>631</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1057" xlink:type="simple">10.1038/nn1057</ext-link></comment> <object-id pub-id-type="pmid">12740580</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fusar-Poli</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Placentino</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Carletti</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Landi</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Allen</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Surguladze</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Functional atlas of emotional faces processing: A voxel-based meta-analysis of 105 functional magnetic resonance imaging studies</article-title>. <source>J Psychiatry Neurosci</source>. <year>2009</year>;<volume>34</volume>: <fpage>418</fpage>–<lpage>432</lpage>. <object-id pub-id-type="pmid">19949718</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>. <article-title>Neural systems for recognizing emotion</article-title>. <source>Curr Opin Neurobiol</source>. <year>2002</year>;<volume>12</volume>: <fpage>169</fpage>–<lpage>177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0959-4388(02)00301-X" xlink:type="simple">10.1016/S0959-4388(02)00301-X</ext-link></comment> <object-id pub-id-type="pmid">12015233</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hoffman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gobbini</surname> <given-names>M</given-names></name>. <article-title>The distributed human neural system for face perception</article-title>. <source>Trends Cogn Sci</source>. <year>2000</year>;<volume>4</volume>: <fpage>223</fpage>–<lpage>233</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10827445" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10827445</ext-link> <object-id pub-id-type="pmid">10827445</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Somppi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Törnqvist</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hänninen</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Krause</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Vainio</surname> <given-names>O</given-names></name>. <article-title>Dogs do look at images: eye tracking in canine cognition research</article-title>. <source>Anim Cogn</source>. <year>2012</year>;<volume>15</volume>: <fpage>163</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-011-0442-1" xlink:type="simple">10.1007/s10071-011-0442-1</ext-link></comment> <object-id pub-id-type="pmid">21861109</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Topál</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Miklósi</surname> <given-names>Á</given-names></name>, <name name-style="western"><surname>Csányi</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Dóka</surname> <given-names>A</given-names></name>. <source>Attachment Behavior in Dogs (Canis familiaris): A New Application of Ainsworth ‘ s (1969) Strange Situation Test</source>. <year>1998</year>;<volume>112</volume>: <fpage>219</fpage>–<lpage>229</lpage>.</mixed-citation></ref>
<ref id="pone.0149431.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nagasawa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kikusui</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Onaka</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ohta</surname> <given-names>M</given-names></name>. <article-title>Dog’s gaze at its owner increases owner's urinary oxytocin during social interaction</article-title>. <source>Horm Behav</source>. <year>2009</year>;<volume>55</volume>: <fpage>434</fpage>–<lpage>441</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.yhbeh.2008.12.002" xlink:type="simple">10.1016/j.yhbeh.2008.12.002</ext-link></comment> <object-id pub-id-type="pmid">19124024</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leopold</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Rhodes</surname> <given-names>G</given-names></name>. <article-title>A comparative view of face perception</article-title>. <source>J Comp Psychol</source>. <year>2010</year>;<volume>124</volume>: <fpage>233</fpage>–<lpage>251</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0019460" xlink:type="simple">10.1037/a0019460</ext-link></comment> <object-id pub-id-type="pmid">20695655</object-id></mixed-citation></ref>
<ref id="pone.0149431.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Waal</surname> <given-names>FBM</given-names></name>, <name name-style="western"><surname>Ferrari</surname> <given-names>PF</given-names></name>. <article-title>Towards a bottom-up perspective on animal and human cognition</article-title>. <source>Trends Cogn Sci. Elsevier Ltd</source>; <year>2010</year>;<volume>14</volume>: <fpage>201</fpage>–<lpage>207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2010.03.003" xlink:type="simple">10.1016/j.tics.2010.03.003</ext-link></comment></mixed-citation></ref>
</ref-list>
</back>
</article>