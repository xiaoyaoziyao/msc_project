<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-11-03677</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0022026</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Sensory perception</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Neural Coding of Cooperative vs. Affective Human Interactions: 150 ms to Code the Action's Purpose</article-title><alt-title alt-title-type="running-head">Understanding Intentions</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Proverbio</surname>
            <given-names>Alice Mado</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Riva</surname>
            <given-names>Federica</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Paganelli</surname>
            <given-names>Laura</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Cappa</surname>
            <given-names>Stefano F.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Canessa</surname>
            <given-names>Nicola</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Perani</surname>
            <given-names>Daniela</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Zani</surname>
            <given-names>Alberto</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Psychology, University of Milano-Bicocca, Milan, Italy</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Institute of Molecular Bioimaging and Physiology, CNR, Milano-Segrate, Italy</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Vita-Salute University and Division of Neuroscience, San Raffaele Scientific Insitute, Milan, Italy</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Greenlee</surname>
            <given-names>Mark W.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">University of Regensburg, Germany</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">mado.proverbio@unimib.it</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: AMP. Performed the experiments: FR LP. Analyzed the data: AMP FR LP. Contributed reagents/materials/analysis tools: AMP AZ. Wrote the paper: AMP. Contributed to study design and data discussion: AZ SC NC DP .</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>7</day>
        <month>7</month>
        <year>2011</year>
      </pub-date><volume>6</volume><issue>7</issue><elocation-id>e22026</elocation-id><history>
        <date date-type="received">
          <day>22</day>
          <month>2</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>13</day>
          <month>6</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Proverbio et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>The timing and neural processing of the understanding of social interactions was investigated by presenting scenes in which 2 people performed cooperative or affective actions. While the role of the human mirror neuron system (MNS) in understanding actions and intentions is widely accepted, little is known about the time course within which these aspects of visual information are automatically extracted. Event-Related Potentials were recorded in 35 university students perceiving 260 pictures of cooperative (e.g., 2 people dragging a box) or affective (e.g., 2 people smiling and holding hands) interactions. The action's goal was automatically discriminated at about 150–170 ms, as reflected by occipito/temporal N170 response. The swLORETA inverse solution revealed the strongest sources in the right posterior cingulate cortex (CC) for affective actions and in the right pSTS for cooperative actions. It was found a right hemispheric asymmetry that involved the fusiform gyrus (BA37), the posterior CC, and the medial frontal gyrus (BA10/11) for the processing of affective interactions, particularly in the 155–175 ms time window. In a later time window (200–250 ms) the processing of cooperative interactions activated the left post-central gyrus (BA3), the left parahippocampal gyrus, the left superior frontal gyrus (BA10), as well as the right premotor cortex (BA6). Women showed a greater response discriminative of the action's goal compared to men at P300 and anterior negativity level (220–500 ms). These findings might be related to a greater responsiveness of the female vs. male MNS. In addition, the discriminative effect was bilateral in women and was smaller and left-sided in men. Evidence was provided that perceptually similar social interactions are discriminated on the basis of the agents' intentions quite early in neural processing, differentially activating regions devoted to face/body/action coding, the limbic system and the MNS.</p>
      </abstract><funding-group><funding-statement>This work was funded by FAR 2008 grants from the University of Milano-Bicocca to AMP and CNR grants to AZ. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="12"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Understanding another person's behavior requires the ability to automatically understand actions and intentions on the mere basis of bodily language. Action processing must also be fast, in order to provide quick reactions to potentially aversive agents, such as recognizing a threat from another person (“is this man trying to hit me?”). An increasingly large amount of neuroimaging data point to the human mirror neuron system (MNS), including the inferior frontal gyrus (IFG), the inferior parietal lobule (IPL), and the posterior part of superior temporal sulcus (pSTS), as the primary neural circuit engaged in action intention understanding <xref ref-type="bibr" rid="pone.0022026-Rizzolatti1">[1]</xref>–<xref ref-type="bibr" rid="pone.0022026-NewmanNorlund1">[3]</xref>. The principle is that viewing another person's actions activates sensory-motor neurons in the MNS, which is assumed to provide a link between action execution and observation, thus also enabling intention understanding. EEG data have consistently demonstrated a mirror activity in the somatosensory cortex, in terms of a mu rhythm desynchronization or suppression, during the recognition of point-light biological motion <xref ref-type="bibr" rid="pone.0022026-Ulloa1">[4]</xref> as well as reaching and grasping hand movements <xref ref-type="bibr" rid="pone.0022026-Perry1">[5]</xref>.</p>
      <p>Yet, data concerning the relationship between the time course of brain activation and the understanding of the intentions of others based on their behavior are scarce and fragmentary. For example, MEG studies have shown that manipulative hand actions and their observation modulate the somatosensory cortex (SI and SII) with an overall latency of 35-ms for SI responses and of 80–90 ms for the SII response, with no difference between manipulating and observing <xref ref-type="bibr" rid="pone.0022026-Avikainen1">[6]</xref>. Similarly, it has been shown that viewing another person's articulatory gestures (mouth movements) activates the left SI cortex by as early as 55 ms <xref ref-type="bibr" rid="pone.0022026-Mttnen1">[7]</xref>. As for the very early effect, it must be considered that these actions are quite basic and not elaborated, and the somatosensory cortex merely recognizes the biologically relevant gestures “resonating” in the person's view. Studies on more complex learned or symbolic behaviors hint to a much later stage for the processing of the action's purpose. For example, event-related potential (ERP) data have shown that meaningless vs. meaningful hand postures (e.g., the sign for “victory,” or the sign for “OK”) are discriminated at about 400 ms post-stimulus, as indexed by an increase in the right anterior frontal N400 response to meaningless gestures <xref ref-type="bibr" rid="pone.0022026-Gunter1">[8]</xref>. Similarly, Shibata and co-workers <xref ref-type="bibr" rid="pone.0022026-Shibata1">[9]</xref> recorded ERPs to appropriate or inappropriate passive/received hand actions. They found a parietal N400 (later spreading at the anterior sites) that was greater in response to inappropriate gestures. Again, Bach et al. <xref ref-type="bibr" rid="pone.0022026-Bach1">[10]</xref> investigated ERPs during the evaluation of the appropriateness of tool use actions performed by one person and found that spatially inappropriate tool use actions (e.g., the presentation of a picture showing a hand holding a coin vertically after the presentation of a picture showing a slot for a coin that was horizontal) elicited left lateralized N400s. Although these studies used stimuli depicting actions more complex than the ones used for MEG recording, they only involved a single body part (hand or arm), and the pictures lacked the representation of the whole body of the agent, their social or environmental context, as well as any affective information (i.e., body language and facial expressions). Similarly, in a recent electrophysiological study <xref ref-type="bibr" rid="pone.0022026-Ortigue1">[11]</xref>, VEPs were recorded to visual frames showing either an object or a hand interacting with it while viewers were verbally asked to try to understand the intention of the agent. The results showed a strong activation of the left IPL between 200–220 ms, which was interpreted as the stage of intention understanding. This result was also discussed in the context of the role of the IPL, which is often damaged in apraxia patients, in action representation.</p>
      <p>Aiming to study the neural circuits underpinning the comprehension of complex human behavior, we recently performed an ERP study <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref> in which we compared the perception of congruent and recognizable behavior (e.g., a young woman trying shoes on in a shop) with an incongruent action lacking a comprehensible goal (e.g., a businesswoman balancing on one foot in the desert). The data provided evidence of an early coding of the action's purpose (∼250 ms), especially in females, who also exhibited larger responses. The data also provided evidence of the specific involvement of the IPL, left IFG, left and right premotor areas, right cingulate cortex, right STG and extra-striate cortex according to swLORETA inverse solutions. These data are consistent with those from similar studies in the literature <xref ref-type="bibr" rid="pone.0022026-NewmanNorlund2">[13]</xref>.</p>
      <p>In the present study, rather than using meaningless actions, we sought to investigate the neural processing of two types of actions characterized by a clearly distinguishable, but radically different goal: pursuing a common goal requiring cooperation between conspecifics (such as lifting a heavy item), or establishing emotional contact without a further goal (not necessarily involving physical contact), which is an essential behavior for social animals.</p>
      <p>Few studies have specifically investigated the neural basis of action comprehension during the perception of human scenes in which 2 agents were engaged in a cooperative or affective interaction. Hider and Simmel <xref ref-type="bibr" rid="pone.0022026-Heider1">[14]</xref> were the first to show short clips in which geometrical entities (2 triangles and a circle) moved outside and inside a rectangle. These investigators found that children were inclined to describe the figure movements in terms of the cooperative or affective intentions of the agents. More recently, various imaging studies recorded brain activity during the perception of similar configurations: geometrical items displaying social or affective interactions <xref ref-type="bibr" rid="pone.0022026-Abell1">[15]</xref>–<xref ref-type="bibr" rid="pone.0022026-Pavlova1">[17]</xref>. Functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) studies point to several brain regions that are active during visual tasks that make use of Heider-and-Simmel animations. These areas include, among others, the posterior part of the right superior temporal sulcus, the parieto–temporal junction, the fusiform face area, and the medial prefrontal cortex. In other studies, fMRI scanning was performed while participants played a cooperation game with a human agent (e.g., cooperate with the experimenter to shape the two sticks of the box in either an angle or a straight line)<xref ref-type="bibr" rid="pone.0022026-Kokal1">[18]</xref>, played two-person “trust and reciprocity” games with both human and computer counterparts for cash rewards <xref ref-type="bibr" rid="pone.0022026-McCabe1">[19]</xref>, or played the “Prisoner's Dilemma” Game with another person <xref ref-type="bibr" rid="pone.0022026-Rilling1">[20]</xref>. In other studies, social interactions were represented by means of schematic agents depicted by point-lights <xref ref-type="bibr" rid="pone.0022026-Centelles1">[21]</xref>, which were interacting with each other (showing something on the ground) or moving by themselves (jumping, raising a leg). The first type of interaction was named “social” and the second type was named “non-social.” fMRI recording showed a stronger activation of the left temporo/parietal junction, the right anterior superior temporal sulcus (STS) and the dorsal part of the medial prefrontal cortex (MFPC) when viewing the social vs. the non-social interactions.</p>
      <p>Although insightful, these studies are based on non-realistic agents that are quite schematic and barely resemble real individuals. These studies also do not provide visual stimulation to neural structures devoted to processing the human figure (body and face), such as the face fusiform area <xref ref-type="bibr" rid="pone.0022026-Haxby1">[22]</xref> and the extra-striate body area, which are also responsive to action processing, including the action's goal ( <xref ref-type="bibr" rid="pone.0022026-Downing1">[23]</xref> and <xref ref-type="bibr" rid="pone.0022026-Takahashi1">[24]</xref>).</p>
      <p>The aim of the present study was therefore to investigate the time course and the cerebral mechanisms involved in the neural coding of ecologic and realistic human scenes depicting cooperative interactions (in which two persons are pursuing a common goal), as opposed to perceptually similar interactions where the only goal is to enter into affective contact with each other (affective interaction). Both behaviors are typical of the human repertoire, are spontaneously performed both by adults and young individuals of both sexes, and are universally recognizable on the basis of silent body language. Importantly, actions showing a complex human behavior were presented rather than simple reaching/grasping/hitting arm-based movements <xref ref-type="bibr" rid="pone.0022026-Ortigue1">[11]</xref> or geometrical agents <xref ref-type="bibr" rid="pone.0022026-Pavlova2">[25]</xref>. We aimed to establish how early during neural processing the action's goal is coded.</p>
      <p>Since the 2 types of affective vs. cooperative interactions only differed for the diverse agents' intentions (and not for perceptual characteristics) we assumed that they will be associated with a substantially similar ERP morphology (i.e., series of positive and negative peaks) except for those components reflecting the activity of neural structures subserving intention understanding. In the same line of thought, the temporal latency corresponding to the first significant difference in the amplitude of the bioelectric responses to the 2 types of actions would correspond to the processing time required to discriminate the action's purpose. Other studies have shown, for example, that the parietal N2 response (150–280 ms), whose neural generators includes regions of the so-called “human mirror-neuron system (MNS)” (inferior/parietal, left inferior/frontal, left and right premotor areas, right cingulate cortex, right superior/temporal and extra-striate cortex) is strongly modulated by the action's purpose. In the present study, we wished to determine whether an earlier ERP response, namely the occipito/temporal N170, known to reflect the processing of configurational <xref ref-type="bibr" rid="pone.0022026-Bentin1">[26]</xref>, <xref ref-type="bibr" rid="pone.0022026-Kanwisher1">[27]</xref>, affective <xref ref-type="bibr" rid="pone.0022026-Proverbio2">[28]</xref> and even social <xref ref-type="bibr" rid="pone.0022026-Freeman1">[29]</xref> face and body properties was affected by stimulus content. Indeed, there are compelling evidence that extra-striate area is involved in the action processing, including the action's goal ( <xref ref-type="bibr" rid="pone.0022026-Downing1">[23]</xref> and <xref ref-type="bibr" rid="pone.0022026-Takahashi1">[24]</xref>).</p>
      <p>We also determined whether there are sex differences in the time course and neuroanatomical substrates of functional circuits involved because previous studies have suggested a gender difference in the processing of social interactions <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref>, <xref ref-type="bibr" rid="pone.0022026-Pavlova2">[25]</xref>, <xref ref-type="bibr" rid="pone.0022026-Domes1">[30]</xref>–<xref ref-type="bibr" rid="pone.0022026-Yang1">[32]</xref>. More specifically, a sex difference has been shown in the ability to understand the others' intentions <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref> or to comprehend the others' emotional state. This difference has also been related to a neuro-anatomical dimorphism, with females having a significantly larger gray matter volume in the pars opercularis and inferior parietal lobule than males, and therefore a possibly more responding mirror neuron system <xref ref-type="bibr" rid="pone.0022026-Cheng1">[33]</xref>. In this line of research, Cheng and coworkers <xref ref-type="bibr" rid="pone.0022026-Cheng2">[34]</xref> measured the electroencephalographic mu rhythm at central sites (C3, Cz, and C4) as a reliable indicator of human mirror-neuron system activity when female and male participants watched either hand actions or a moving dot. The results showed significantly stronger mu suppression in females than males when watching hand actions compared to moving dots. Because mu rhythm results from the spontaneous firing of the sensorimotor neurons in synchrony when individuals execute an action or observe an action performed by another individual, the authors interpreted their data in terms of a gender difference in the mirror activity during action observation. The hypothesis of a sex difference in MNS responsivity was therefore tested (although not being it one of the primary research goal of this study) by comparing the brain's ability to automatically discriminate perceptually similar scenes on the basis of the agents' intentions.</p>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>Participants</title>
        <p>Thirty-five university students (17 males and 18 females) ranging in age from 20 to 35 years (mean age  = 21.81 years, SD = 2.1) volunteered in this experiment. All participants had a normal or corrected-to-normal vision with right eye dominance. They were strictly right-handed as assessed by the Edinburgh Inventory, and none of them had any left-handed relatives. Experiments were conducted with the understanding and written consent of each participant according to the Declaration of Helsinki (BMJ 1991; 302: 1194), with approval from the Ethical Committee of the Italian National Research Council (CNR) and in compliance with APA ethical standards for the treatment of human volunteers (1992, American Psychological Association). Subjects gained academic credits for their participation. Data from 4 men and 4 women were subsequently discarded because of excessive eye-movements or EEG artifacts. The ovarian cycle of female participants was ascertained and matched across subjects (see <xref ref-type="table" rid="pone-0022026-t001">Table 1</xref>). The 60-item Empathy Quotient (EQ) <xref ref-type="bibr" rid="pone.0022026-BaronCohen1">[35]</xref> was administered to assess empathic capacity in men and women. No significant sex differences were found (Men = 52, women  = 51.7).</p>
        <table-wrap id="pone-0022026-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0022026.t001</object-id><label>Table 1</label><caption>
            <title>Matching of female participant characteristics related to their ovarian cycle.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0022026-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.t001" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1">Hormonal contraceptive</td>
                <td align="left" colspan="1" rowspan="1">Yes</td>
                <td align="left" colspan="1" rowspan="1">No</td>
                <td align="left" colspan="1" rowspan="1">Total</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1"># Ss</td>
                <td align="left" colspan="1" rowspan="1">8</td>
                <td align="left" colspan="1" rowspan="1">7</td>
                <td align="left" colspan="1" rowspan="1">15</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Ovarian phase</td>
                <td align="left" colspan="1" rowspan="1">Follicular(1<sup>st</sup>–14<sup>th</sup> day)</td>
                <td align="left" colspan="1" rowspan="1">Luteal(15<sup>th</sup>–28<sup>th</sup> day)</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"># Ss</td>
                <td align="left" colspan="1" rowspan="1">7</td>
                <td align="left" colspan="1" rowspan="1">8</td>
                <td align="left" colspan="1" rowspan="1">15</td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt101">
              <label/>
              <p>Number or female subjects that assumed hormonal contraceptives and that were in their pre-ovulatory or post-ovulatory phase of their menstrual cycle at the time of EEG recording. As visible, women were matched across classes so that it can be excluded that higher levels of either estrogen or progesteron (whose concentration changes in the 2 phases) might modulate neural responses to social stimuli similarly in all female participants.</p>
            </fn>
          </table-wrap-foot></table-wrap>
      </sec>
      <sec id="s2b">
        <title>Stimuli</title>
        <p>The stimulus set was comprised of 260 color pictures depicting males and females of various ages and numbers engaged in goal-directed actions belonging to the typical human repertoire. The pictures were downloaded from Google Images. The action's goal might consist of reaching a common aim (such as lifting a box or dragging heavy furniture), in which case the actions were of the “cooperative” type. In alternative, the goal might be of social nature, to establish an affective contact, or just to relate to someone else (e.g., shaking hands or holding each other), in which case the actions were of the “social” type (see examples in <xref ref-type="fig" rid="pone-0022026-g001">Fig. 1</xref>). A total of 130 cooperative and 130 social actions were presented randomly mixed with 44 neutral infrequent targets (landscapes without any visible people). The pictures were 15×15 cm (7° 32′ 33″) in size and their average luminance was 15.48 Foot-lamberts. An ANOVA showed no difference in stimulus luminance as a function of stimulus type. Each slide was presented for 1300 ms at the center of a PC screen with an ISI ranging from 1750 to 1900 ms. The outer background was dark grey.</p>
        <fig id="pone-0022026-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Examples of pictures depicting cooperative vs. affective interactions in young and older agents of both sexes.</title>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g001" xlink:type="simple"/>
        </fig>
        <p>Stimuli were selected from a wider sample of 310 photos, including 155 items for each category. They were randomly ordered in a PowerPoint file, one per page, and presented to a group of 52 different judges of similar age and educational level as the experimental subjects. Half of the examiners judged the pictures for their cooperative content, while the other half judged them for their social content. The experimenter briefly showed them the pictures (one by one) for a few seconds and asked them to evaluate whether the action presented seemed cooperative (or social) to them by means of a 3-point scale [3 =  very much cooperative (or social); 2 =  vaguely cooperative (or social) 1 =  not at all cooperative (or affective)]. As the judge gave his or her opinion on the photographs, the person administering the test recorded the results for each photograph. The risk of a bias in the responses was minimized by randomly changing the order in which the photographs were presented to each judge. Cooperative pictures were judged as very much cooperative by the 26 judges administering the cooperative survey and not at all social by the 26 judges administering the social survey, and vice versa. Therefore, 50 cooperative and social pictures were discarded because of an insufficient average score (&lt;1.3).</p>
        <p>At the end of this process, we were able to select 260 pictures (130 for each category) that were balanced for gender, age, number of persons (see <xref ref-type="table" rid="pone-0022026-t002">Table 2</xref>) and the body part depicted (full-length bodies vs. half-length bodies). In order to have subjects performing a secondary task, 44 further photos depicting common natural or urban landscapes without visible persons (including streets, offices, shops, a public library, the countryside, a seascape, a mountain landscape, etc.) were also included. These pictures were equal to the human pictures in terms of average luminance and size.</p>
        <table-wrap id="pone-0022026-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0022026.t002</object-id><label>Table 2</label><caption>
            <title>Inter-categorical balancing of sex, number and age of agents depicted in human scenes.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0022026-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.t002" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1">Age</td>
                <td align="left" colspan="2" rowspan="1">Adults</td>
                <td align="left" colspan="2" rowspan="1">Children</td>
                <td align="left" colspan="2" rowspan="1">Both</td>
                <td align="left" colspan="1" rowspan="1">Total</td>
                <td align="left" colspan="1" rowspan="1">Total</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Scene Content</td>
                <td align="left" colspan="1" rowspan="1">Aff.</td>
                <td align="left" colspan="1" rowspan="1">Coop.</td>
                <td align="left" colspan="1" rowspan="1">Aff.</td>
                <td align="left" colspan="1" rowspan="1">Coop.</td>
                <td align="left" colspan="1" rowspan="1">Aff.</td>
                <td align="left" colspan="1" rowspan="1">Coop.</td>
                <td align="left" colspan="1" rowspan="1">Aff.</td>
                <td align="left" colspan="1" rowspan="1">Coop.</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">Men</td>
                <td align="left" colspan="1" rowspan="1">8</td>
                <td align="left" colspan="1" rowspan="1">10</td>
                <td align="left" colspan="1" rowspan="1">5</td>
                <td align="left" colspan="1" rowspan="1">6</td>
                <td align="left" colspan="1" rowspan="1">10</td>
                <td align="left" colspan="1" rowspan="1">11</td>
                <td align="left" colspan="1" rowspan="1">23</td>
                <td align="left" colspan="1" rowspan="1">27</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Women</td>
                <td align="left" colspan="1" rowspan="1">10</td>
                <td align="left" colspan="1" rowspan="1">10</td>
                <td align="left" colspan="1" rowspan="1">6</td>
                <td align="left" colspan="1" rowspan="1">5</td>
                <td align="left" colspan="1" rowspan="1">15</td>
                <td align="left" colspan="1" rowspan="1">15</td>
                <td align="left" colspan="1" rowspan="1">31</td>
                <td align="left" colspan="1" rowspan="1">30</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Both</td>
                <td align="left" colspan="1" rowspan="1">52</td>
                <td align="left" colspan="1" rowspan="1">50</td>
                <td align="left" colspan="1" rowspan="1">6</td>
                <td align="left" colspan="1" rowspan="1">7</td>
                <td align="left" colspan="1" rowspan="1">18</td>
                <td align="left" colspan="1" rowspan="1">16</td>
                <td align="left" colspan="1" rowspan="1">76</td>
                <td align="left" colspan="1" rowspan="1">73</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Total</td>
                <td align="left" colspan="1" rowspan="1">70</td>
                <td align="left" colspan="1" rowspan="1">70</td>
                <td align="left" colspan="1" rowspan="1">17</td>
                <td align="left" colspan="1" rowspan="1">18</td>
                <td align="left" colspan="1" rowspan="1">43</td>
                <td align="left" colspan="1" rowspan="1">42</td>
                <td align="left" colspan="1" rowspan="1">130</td>
                <td align="left" colspan="1" rowspan="1">130</td>
              </tr>
            </tbody>
          </table></alternatives></table-wrap>
      </sec>
      <sec id="s2c">
        <title>Task and procedure</title>
        <p>The task consisted of responding as accurately and quickly as possible to the presence of landscapes (scenarios without visible persons) by pressing a response key with the index finger of the left or right hand while ignoring all other pictures. The two hands were used alternately during the recording session. The order of the hand and task conditions was counterbalanced across subjects.</p>
        <p>Participants were comfortably seated in a darkened, acoustically and electrically shielded test area. They faced a high-resolution VGA computer screen located 114 cm from their eyes. They were instructed to gaze at the center of the screen, where a small circle served as the fixation point, and to avoid any eye or body movements during the recording session. Stimuli were presented at the center of the screen and were randomly mixed in 8 different short runs of 32–36 trials that lasted about 2 minutes each. For each experimental run, the target stimuli varied between 2 and 8 runs. The sequence presentation order differed across the subjects.</p>
      </sec>
      <sec id="s2d">
        <title>EEG recording and analysis</title>
        <p>The EEG was continuously recorded from 128 scalp sites at a sampling rate of 512 Hz by means of an ANT-EEprobe 3.1. system. Horizontal and vertical eye movements were also recorded. Linked ears served as the reference lead. The EEG and electro-oculogram (EOG) were amplified with a half-amplitude band pass of 0.016–100 Hz. Electrode impedance was kept below 5 kΩ. EEG epochs were synchronized with the onset of stimuli presentation. Computerized artifact rejection was performed before averaging to discard epochs in which eye movements, blinks, excessive muscle potentials or amplifier blocking occurred. The artifact rejection criterion was peak-to-peak amplitude exceeding 50 µV, and the rejection rate was ∼5%. ERPs were averaged off-line from −100 ms before to 1000 ms after stimulus onset. ERP components were identified and measured, with reference to the average baseline voltage over the interval from −100 ms to 0 ms, at sites and latency where they reached their maximum amplitude.</p>
        <p>The mean amplitude of the occipito/temporal N170 was measured at the PO9, PO10, PPO10h, and PPO9h sites during the 150–190 ms time window. The parietal N2 response was measured at the Pz, P3, and P4 sites during the 160–280 ms time window. Posterior P300 was measured at the same sites (PO9, PO10, PPO10h, and PPO9h) between 250–350 ms post-stimulus. Anterior negativity (N2/N3 deflections) was quantified at the F1, F2, F5, F6, C1, and C2 electrode sites in the 220–500 ms post-stimulus time window.</p>
        <p>ERP data were subjected to a multifactorial repeated-measures ANOVA with one factor between (sex: males, females) and 3 factors within groups. The within factors were as follows: scene content (cooperative, affective), electrode (dependent on the ERP component of interest) and hemisphere (left, right) for the ERP data. Multiple comparisons of means were performed by the post-hoc Tukey tests.</p>
        <p><italic>Low Resolution Electromagnetic Tomography</italic> (LORETA) <xref ref-type="bibr" rid="pone.0022026-PasqualMarqui1">[36]</xref> was performed on ERP difference waves at various time latencies. LORETA, which is a discrete linear solution to the inverse EEG problem, corresponds to the 3D distribution of neuronal electric activity that has maximum similarity (i.e., maximum synchronization) in terms of orientation and strength between neighboring neuronal populations (represented by adjacent voxels). In this study, an improved version of the weighted low-resolution brain electromagnetic tomography (sLORETA) was used, which incorporates a singular value decomposition-based lead field weighting: swLORETA <xref ref-type="bibr" rid="pone.0022026-PalmeroSoler1">[37]</xref>. The source space properties were as follows: grid spacing (the distance between two calculation points)  = 5 points; estimated signal to noise ratio (SNR, which defines the regularization; and a higher value for SNR means less regularization and less blurred results)  = 3 points. LORETA was performed on group data and it identified statistically significant electromagnetic dipoles (p&lt;0.05). The larger the magnitude, the more significant the difference in activation between the two compared conditions was.</p>
        <p>A realistic boundary element model (BEM) was derived from a T1 weighted 3D MRI data set by segmentation of the brain tissue. The BEM model consisted of one homogenic compartment made up of 3446 vertices and 6888 triangles. The head model was used for intra-cranial localization of surface potentials. Segmentation and head model generation were performed using the ASA (A.N.T. Software B.V., Enschede, The Netherlands) package <xref ref-type="bibr" rid="pone.0022026-Zanow1">[38]</xref>.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>Occipito/temporal N170 (150–190 ms)</title>
        <p>The ANOVA performed on the N170 mean amplitude values yielded the significance of scene content (F(1,25)  = 36.41; p&lt;0.000003; ε = 1), which showed greater N170 amplitudes to affective scenes compared to cooperative scenes (AFF. = 1.45 µV, COOP. = 2.55 µV). This result is displayed in <xref ref-type="fig" rid="pone-0022026-g002">Fig. 2</xref>. The N170 was greater at the occipito/temporal site than the lateral occipital electrode sites (F(1,25) = 29.29; p&lt;0.00001; ε = 1), as indicated by post-hoc comparisons (PPO9/10h 1.42 µV vs. PO9/10 e PO09 2.58 µV). The further interaction of scene content x hemisphere (F(1,25)  = 23.49; p&lt;0.00005; ε = 1) and relative post-hoc comparisons among means demonstrate that the N170 was larger over the left hemisphere in response to cooperative scenes (LH = 2.24, SE = 0.72; RH = 2.87, SE = 0.6; diff = p&lt;0.0017), while it was bilateral in response to social scenes (LH = 1.44, SE = 0.76; RH = 1.46, SE = 0.61).</p>
        <fig id="pone-0022026-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Grand-average ERP waveforms recorded at the left and right occipito/temporal sites in response to affective vs. cooperative actions, independent of the viewer's sex.</title>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g002" xlink:type="simple"/>
        </fig>
        <p>To investigate the effect of scene content on the visual processing of human interactions, two swLORETA inverse solutions <xref ref-type="bibr" rid="pone.0022026-PasqualMarqui1">[36]</xref> were performed on the negative voltage related to affective vs. cooperative processing during the N170 time window (155–175 ms). LORETA analysis (see <xref ref-type="table" rid="pone-0022026-t003">Table 3</xref> for a list of significant electromagnetic dipoles) showed that the processing of affective gestures was associated with significant activity in the posterior cingulate cortex of the right hemisphere (BA30) and in the right (BA37) and left (BA19) medial occipital gyrus, as visible in the axial section of <xref ref-type="fig" rid="pone-0022026-g003">Fig. 3</xref>. On the other hand, LORETA analysis performed on brain activity elicited by cooperative actions was associated with the activation of the right middle temporal/posterior STG, the right parahippocampal gyrus and the right medial frontal gyrus.</p>
        <fig id="pone-0022026-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Axial view of N170 active sources for the processing of affective (left) and cooperative (right) human interactions according to the swLORETA analysis during the 155–175 ms time window.</title>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g003" xlink:type="simple"/>
        </fig>
        <table-wrap id="pone-0022026-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0022026.t003</object-id><label>Table 3</label><caption>
            <title>Talairach coordinates corresponding to the intracranial generators, which explain the surface voltage related to the processing of affective and cooperative actions during the 155–175 ms time window.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0022026-t003-3" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.t003" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1">Magnitude</td>
                <td align="left" colspan="1" rowspan="1">T-x [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-y [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-z [mm]</td>
                <td align="left" colspan="1" rowspan="1">Hem.</td>
                <td align="left" colspan="1" rowspan="1">Lobe</td>
                <td align="left" colspan="1" rowspan="1">Area</td>
                <td align="left" colspan="1" rowspan="1">BA</td>
              </tr>
              <tr>
                <td align="left" colspan="8" rowspan="1">AFFECTIVE</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">27.8</td>
                <td align="left" colspan="1" rowspan="1">21.2</td>
                <td align="left" colspan="1" rowspan="1">−57.9</td>
                <td align="left" colspan="1" rowspan="1">5.6</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">Limbic</td>
                <td align="left" colspan="1" rowspan="1">Posterior Cingulate</td>
                <td align="left" colspan="1" rowspan="1">30</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">25.5</td>
                <td align="left" colspan="1" rowspan="1">50.8</td>
                <td align="left" colspan="1" rowspan="1">−68</td>
                <td align="left" colspan="1" rowspan="1">4.7</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">O</td>
                <td align="left" colspan="1" rowspan="1">Medial occipital gyrus</td>
                <td align="left" colspan="1" rowspan="1">37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">23.9</td>
                <td align="left" colspan="1" rowspan="1">−38.5</td>
                <td align="left" colspan="1" rowspan="1">−78.2</td>
                <td align="left" colspan="1" rowspan="1">3.8</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">O</td>
                <td align="left" colspan="1" rowspan="1">Medial occipital gyrus</td>
                <td align="left" colspan="1" rowspan="1">19</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">5.38</td>
                <td align="left" colspan="1" rowspan="1">1.5</td>
                <td align="left" colspan="1" rowspan="1">48.2</td>
                <td align="left" colspan="1" rowspan="1">−17.2</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Medial frontal gyrus</td>
                <td align="left" colspan="1" rowspan="1">11</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">2.32</td>
                <td align="left" colspan="1" rowspan="1">1.5</td>
                <td align="left" colspan="1" rowspan="1">64.4</td>
                <td align="left" colspan="1" rowspan="1">16.8</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Medial frontal gyrus</td>
                <td align="left" colspan="1" rowspan="1">10</td>
              </tr>
            </tbody>
          </table><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="8" rowspan="1">COOPERATIVE</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">12.90</td>
                <td align="left" colspan="1" rowspan="1">50.8</td>
                <td align="left" colspan="1" rowspan="1">−57.9</td>
                <td align="left" colspan="1" rowspan="1">5.6</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">T</td>
                <td align="left" colspan="1" rowspan="1">Middle temporal Gyrus, pSTG</td>
                <td align="left" colspan="1" rowspan="1">21/37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">13.01</td>
                <td align="left" colspan="1" rowspan="1">21.2</td>
                <td align="left" colspan="1" rowspan="1">−46.8</td>
                <td align="left" colspan="1" rowspan="1">−2.1</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">Limbic</td>
                <td align="left" colspan="1" rowspan="1">Parahippocampal Gyrus</td>
                <td align="left" colspan="1" rowspan="1">19/20</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">2.85</td>
                <td align="left" colspan="1" rowspan="1">1.5</td>
                <td align="left" colspan="1" rowspan="1">64.4</td>
                <td align="left" colspan="1" rowspan="1">16.8</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Medial Frontal Gyrus</td>
                <td align="left" colspan="1" rowspan="1">10</td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt102">
              <label/>
              <p>According to the swLORETA (ASA) analysis <xref ref-type="bibr" rid="pone.0022026-PalmeroSoler1">[37]</xref>; grid spacing  = 5 mm; estimated SNR  = 3.</p>
            </fn>
          </table-wrap-foot></table-wrap>
      </sec>
      <sec id="s3b">
        <title>Parietal N2 (160–280 ms)</title>
        <p>N2 reached its maximum amplitude at parietal sites (Pz, P3, and P4) between 160–280 ms. Statistical analysis shows the significance of scene content (F(1,25)  = 5.04; p&lt;0.03; ε = 1), with greater N2 amplitudes in response to cooperative actions vs. affective actions (COOP. = −1.18 µV; AFF. = −0.75 µV). The electrode factor (F(1.68, 42)  = 22.24; p&lt;0.00001, ε = 0.84) showed that N2 was larger at the midline site (Pz), but with a strong left hemispheric asymmetry (PZ = −1.87; P3 = −1.11 µV; P4 = 0.08 µV), as demonstrated by significant post-hoc comparisons. The further interaction of scene content with the electrode (F(1.4, 35)  = 18.23; p&lt;0.000018; ε = 0.70) showed a non-significant difference in the N2 response between scene types over the right hemisphere, and a significantly larger N2 (p = 0.00014) in response to cooperative (−1.34 µV) vs. affective interactions (−0.88 µV) over the left parietal site. This result is clearly visible in <xref ref-type="fig" rid="pone-0022026-g004">Fig. 4</xref>.</p>
        <fig id="pone-0022026-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Grand-average ERP waveforms recorded at the left, mesial and right parietal sites in response to affective and cooperative actions, independent of the viewer's sex.</title>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g004" xlink:type="simple"/>
        </fig>
        <p>To locate the possible neural source of the action content effect, two different swLORETA source reconstructions were performed separately for cooperative and affective actions during the 200–250 ms time window, which corresponds to the peak of the parietal N2. The inverse solution showed that the processing of affective actions was associated with electromagnetic activity in a number of left and right hemispheric regions, which are listed in <xref ref-type="table" rid="pone-0022026-t004">Table 4</xref>. These regions include the right fusiform gyrus (BA 37), the left parahippocampal gyrus (BA37), the left post-central gyrus (BA 3), the left and right premotor area (BA6) and the left orbitofrontal cortex (BA10, 11). On the other hand, the processing of cooperative scenes resulted in the activation of partially similar regions (see <xref ref-type="table" rid="pone-0022026-t004">Table 4</xref>), except for a stronger activation of the left fusiform gyrus (BA3), the left post-central gyrus (BA3), the left parahippocampal gyrus, and the left superior frontal gyrus (BA10). The activation was stronger over the right hemisphere over the premotor cortex (BA6). These differences were confirmed by a further comparison performed by subtracting the brain activity (ERPs) evoked by affective actions from that evoked by cooperative actions, and computing a LORETA inverse solution on the difference wave so obtained. The significant electromagnetic dipoles explaining the difference voltage are marked by an asterisk in <xref ref-type="table" rid="pone-0022026-t004">Table 4</xref> and are visible in <xref ref-type="fig" rid="pone-0022026-g005">Fig. 5</xref>.</p>
        <fig id="pone-0022026-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Axial view of N2 active sources for the processing of cooperative minus affective human interactions according to the swLORETA analysis during the 200–250 ms time window.</title>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g005" xlink:type="simple"/>
        </fig>
        <table-wrap id="pone-0022026-t004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0022026.t004</object-id><label>Table 4</label><caption>
            <title>Talairach coordinates corresponding to the intracortical generators, which explain the surface voltage recorded during the 200–250 ms time window in response to affective and cooperative actions.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0022026-t004-4" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.t004" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="8" rowspan="1">AFFECTIVE (200–250 ms)</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Magnitude</td>
                <td align="left" colspan="1" rowspan="1">T-x [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-y [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-z [mm]</td>
                <td align="left" colspan="1" rowspan="1">Hem.</td>
                <td align="left" colspan="1" rowspan="1">Lobe</td>
                <td align="left" colspan="1" rowspan="1">Area</td>
                <td align="left" colspan="1" rowspan="1">BA</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">8.68</td>
                <td align="left" colspan="1" rowspan="1">40.9</td>
                <td align="left" colspan="1" rowspan="1">−55.9</td>
                <td align="left" colspan="1" rowspan="1">−10.2</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">T</td>
                <td align="left" colspan="1" rowspan="1">Fusiform gyrus</td>
                <td align="left" colspan="1" rowspan="1">37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">6.58</td>
                <td align="left" colspan="1" rowspan="1">−28.5</td>
                <td align="left" colspan="1" rowspan="1">−45.8</td>
                <td align="left" colspan="1" rowspan="1">−9.5</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">Limbic</td>
                <td align="left" colspan="1" rowspan="1">Parahippocampal gyrus</td>
                <td align="left" colspan="1" rowspan="1">7</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.88</td>
                <td align="left" colspan="1" rowspan="1">−38.5</td>
                <td align="left" colspan="1" rowspan="1">−21</td>
                <td align="left" colspan="1" rowspan="1">35.7</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">P</td>
                <td align="left" colspan="1" rowspan="1">Post-central gyrus</td>
                <td align="left" colspan="1" rowspan="1">3</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.50</td>
                <td align="left" colspan="1" rowspan="1">−8.5</td>
                <td align="left" colspan="1" rowspan="1">57.3</td>
                <td align="left" colspan="1" rowspan="1">−9</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Superior Frontal gyrus</td>
                <td align="left" colspan="1" rowspan="1">10</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.46</td>
                <td align="left" colspan="1" rowspan="1">−85</td>
                <td align="left" colspan="1" rowspan="1">38.2</td>
                <td align="left" colspan="1" rowspan="1">−17.9</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Rectus</td>
                <td align="left" colspan="1" rowspan="1">11</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.03</td>
                <td align="left" colspan="1" rowspan="1">−38.5</td>
                <td align="left" colspan="1" rowspan="1">2.4</td>
                <td align="left" colspan="1" rowspan="1">29.4</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Pre-central gyrus</td>
                <td align="left" colspan="1" rowspan="1">6</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">0.99</td>
                <td align="left" colspan="1" rowspan="1">40.9</td>
                <td align="left" colspan="1" rowspan="1">2.4</td>
                <td align="left" colspan="1" rowspan="1">29.4</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Pre-central gyrus</td>
                <td align="left" colspan="1" rowspan="1">6</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">0.91</td>
                <td align="left" colspan="1" rowspan="1">−28.5</td>
                <td align="left" colspan="1" rowspan="1">56.3</td>
                <td align="left" colspan="1" rowspan="1">−1.6</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Superior Frontal Gyrus</td>
                <td align="left" colspan="1" rowspan="1">11</td>
              </tr>
            </tbody>
          </table><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="8" rowspan="1">COOPERATIVE (200–250 ms)</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">Magnitude</td>
                <td align="left" colspan="1" rowspan="1">T-x [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-y [mm]</td>
                <td align="left" colspan="1" rowspan="1">T-z [mm]</td>
                <td align="left" colspan="1" rowspan="1">Hem.</td>
                <td align="left" colspan="1" rowspan="1">Lobe</td>
                <td align="left" colspan="1" rowspan="1">Area</td>
                <td align="left" colspan="1" rowspan="1">BA</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">9.62<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">40.9</td>
                <td align="left" colspan="1" rowspan="1">−55.9</td>
                <td align="left" colspan="1" rowspan="1">−10.2</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">T</td>
                <td align="left" colspan="1" rowspan="1">Fusiform gyrus</td>
                <td align="left" colspan="1" rowspan="1">37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">7.33<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">−28.5</td>
                <td align="left" colspan="1" rowspan="1">−45.8</td>
                <td align="left" colspan="1" rowspan="1">−9.5</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">Limbic</td>
                <td align="left" colspan="1" rowspan="1">Parahippocampal gyrus</td>
                <td align="left" colspan="1" rowspan="1">37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">7.23<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">−48.5</td>
                <td align="left" colspan="1" rowspan="1">−55.9</td>
                <td align="left" colspan="1" rowspan="1">−10.2</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">T</td>
                <td align="left" colspan="1" rowspan="1">Fusiform gyrus</td>
                <td align="left" colspan="1" rowspan="1">37</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">2.17<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">−38.5</td>
                <td align="left" colspan="1" rowspan="1">−21</td>
                <td align="left" colspan="1" rowspan="1">35.7</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">P</td>
                <td align="left" colspan="1" rowspan="1">Postcentral gyrus</td>
                <td align="left" colspan="1" rowspan="1">3</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.84<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">−8.5</td>
                <td align="left" colspan="1" rowspan="1">57.3</td>
                <td align="left" colspan="1" rowspan="1">−9</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Superior frontal gyrus</td>
                <td align="left" colspan="1" rowspan="1">10</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.62</td>
                <td align="left" colspan="1" rowspan="1">−8.5</td>
                <td align="left" colspan="1" rowspan="1">38.2</td>
                <td align="left" colspan="1" rowspan="1">−17.9</td>
                <td align="left" colspan="1" rowspan="1">L</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Rectus</td>
                <td align="left" colspan="1" rowspan="1">11</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.29<bold>*</bold></td>
                <td align="left" colspan="1" rowspan="1">40.9</td>
                <td align="left" colspan="1" rowspan="1">2.4</td>
                <td align="left" colspan="1" rowspan="1">29.4</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Premotor cortex</td>
                <td align="left" colspan="1" rowspan="1">6</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">1.15</td>
                <td align="left" colspan="1" rowspan="1">11.3</td>
                <td align="left" colspan="1" rowspan="1">57.3</td>
                <td align="left" colspan="1" rowspan="1">−9</td>
                <td align="left" colspan="1" rowspan="1">R</td>
                <td align="left" colspan="1" rowspan="1">F</td>
                <td align="left" colspan="1" rowspan="1">Superior frontal gyrus</td>
                <td align="left" colspan="1" rowspan="1">10</td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt103">
              <label/>
              <p>Power RMS  = 276.2 µV. Asterisks indicate the brain structures that were significantly more active during perception of cooperative than affective interactions, as provided by a LORETA inverse solution (displayed in <xref ref-type="fig" rid="pone-0022026-g005">Fig. 5</xref>) applied to the difference-waves obtained by subtracting ERPs to affective from cooperative interactions.</p>
            </fn>
          </table-wrap-foot></table-wrap>
      </sec>
      <sec id="s3c">
        <title>Posterior P300 component (250–350 ms)</title>
        <p>This positive deflection was measured at the lateral occipito/temporal sites during the 250–350 ms time window. The ANOVA analysis showed a lateralization effect (F(1,25)  = 11.84; p&lt;0.002; ε = 1), with a larger P300 recorded over the right (RH = 8.75 µV) than the left hemispheric sites (6.72 µV). The P300 was strongly modulated by scene content (F(1,25)  = 18.06; p&lt;0.0002; ε = 1) and was much more positive in response to cooperative actions compared to affective actions in both genders (COOP. = 8.17 µV; AFF. = 7.30 µV). However, a simple affect analysis showed that, while scene content was strongly significant in women (F(1,13)  = 13.07; p&lt;0.003; ε = 1) with a P300 to cooperative actions exceeding 1.21 µV P300 compared to affective actions (Women: COOP. = 8.80, SE = 1.21; AFF. = 7.59 µV, SD = 1.02), the effect was less significant in men (F(1,12)  = 5.56; p&lt;0.03; ε = 1), with a content-related difference of only 0.53 µV (Men. COOP.: 7.54, SD = 0.73; AFF. = 7.01, SD = 0.64). This sex difference is highlighted in <xref ref-type="fig" rid="pone-0022026-g006">Fig. 6</xref>.</p>
        <fig id="pone-0022026-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0022026.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Grand-average ERP waveforms recorded at the left and right dorsal prefrontal, inferior frontal, central, occipito-temporal and lateral occipital sites in response to affective and cooperative actions.</title>
            <p>The results are analyzed separately for women and men.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0022026.g006" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3d">
        <title>Anterior Negativity (220–500 ms)</title>
        <p>The anterior negativity was recorded at anterior sites (F1, F2, F5, F6, C1, and C2) during the 220–500 ms time window. The anterior negativity was of greater amplitude at medial frontal sites (medial frontal = −4.93 µV; inferior frontal F5–F6 = −4.3 µV; central C1–C2 = −3.59 µV), as demonstrated by the significance of the electrode (F(1.31, 32.82)  = 16.27; p&lt;0.00001; ε = 0.65). ANOVA analysis showed a significant effect of scene content (F(1,25)  = 62.28; p&lt;0.000001; ε = 1), with a wider anterior negativity in response to cooperative scenes compared to affective scenes (COOP. = −5.06 µV; AFF. = −3.48 µV). The interaction of hemisphere with sex (F (1,25)  = 5.28; p&lt;0.03; ε = 1) and the relative post-hoc comparisons showed a bilateral (and greater) anterior negativity in women (−5.32 µV) and a much smaller and left-sided (p&lt;0.014) negativity in men (−3.15 µV).</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>In this study, we aimed to investigate the brain correlates of the processing of an action's goal by directly comparing the neural correlates of cooperative vs. affective action processing. To do so, we presented hundreds of realistic scenes depicting 2 persons of different ages and sexes engaged in a behavior belonging to the typical human repertoire in the context of an urban or natural environment. Viewers were male and female university students attentively perceiving these pictures but engaged in a secondary perceptual task. The secondary task (detecting an inanimate landscape) was introduced to avoid a conscious awareness of two types of behavior. Indeed, no subject revealed knowledge about the two-fold nature of the behavior observed at the end of EEG recording; this finding is quite understandable as the two types of interactions did not differ at the perceptual level because people could be spatially very close or far from each other, smiling or neutral, and gesticulating/moving or resting/quiet. Because the cooperative and affective actions were matched for a number of perceptual characteristics, except for the real goal of the human interaction (“are you trying to help me to lift this sofa or are you just entering into contact with me?”), the contrast between neural processing of the two types of actions allowed us to shed some light on the neural mechanisms promoting the comprehension of the other intentions and the exact time course by which this information is automatically extracted from visual inputs and made available for further processing. Thus, time-locked ERP responses were identified and measured over occipito-temporal sites along the ventral stream (N170 and P300 components), over the parietal area (160–280 ms), and at frontal sites (late anterior negativity).</p>
      <p>The N170 data provided evidence of an early processing of affective scene content. Indeed, the brain response was of greater amplitude in response to affective stimuli compared to cooperative stimuli between 150–190 ms. This finding agrees with many studies in the literature supporting an early coding of stimulus affective valence for both faces <xref ref-type="bibr" rid="pone.0022026-Pizzagalli1">[39]</xref>, <xref ref-type="bibr" rid="pone.0022026-Proverbio3">[40]</xref> and complex human scenes <xref ref-type="bibr" rid="pone.0022026-Proverbio4">[41]</xref>, <xref ref-type="bibr" rid="pone.0022026-Junghfer1">[42]</xref>.</p>
      <p>Overall, the N170 was of greater amplitude over the right hemisphere and in response to affective pictures. In agreement with the surface ERP data, the swLORETA inverse solution displayed a strong activation of the limbic system and especially the right posterior cingulate cortex in response to affective pictures compared to cooperative pictures. It is known that both anterior and posterior cingulate cortices are involved in emotion processing <xref ref-type="bibr" rid="pone.0022026-Phillips1">[43]</xref>, <xref ref-type="bibr" rid="pone.0022026-Adolphs1">[44]</xref>, in the subjective evaluation of events, and in their emotional significance. Specifically, the ventral posterior cingulate cortex is involved in the coding of visual stimulus emotional content <xref ref-type="bibr" rid="pone.0022026-Vogt1">[45]</xref>, thus supporting our finding of a greater activation of the posterior cingulate (BA30) in response to affective vs. cooperative actions. In our study, the swLORETA source reconstruction identified other generators (besides the cingulate cortex), which included the medial occipital gyrus (BA19 and BA37) and the right medial frontal cortex (BA10/11), which are possibly involved in the processing of both faces and bodies, thus explaining the N170 surface voltage. The involvement of prefrontal neurons in the early coding of social information is supported by available literature. In a combined ERP/fMRI study <xref ref-type="bibr" rid="pone.0022026-Henson1">[46]</xref> face recognition was associated with haemodynamic increases in fusiform, medial frontal and orbitofrontal cortices. Again, in a very recent MEG study <xref ref-type="bibr" rid="pone.0022026-Taylor1">[47]</xref> it was found an activation of the right prefrontal cortex that was maximum at 240 ms for inverted faces but was very pronounced also at 170 ms of latency. Quite consistently, face responsive neurons have been identified in the prefrontal cortex of rhesus monkeys <xref ref-type="bibr" rid="pone.0022026-Scalaidhe1">[48]</xref>.</p>
      <p>It should be noted that the right hemispheric generator in the visual cortex (Middle Occipital gyrus, MOG) had a stronger magnitude (in nA) compared to the left hemispheric generator. This finding agrees with studies showing a strong hemispheric asymmetry in the face-related <xref ref-type="bibr" rid="pone.0022026-Pizzagalli1">[39]</xref>, <xref ref-type="bibr" rid="pone.0022026-George1">[49]</xref>–<xref ref-type="bibr" rid="pone.0022026-Rossion1">[51]</xref> and body-related <xref ref-type="bibr" rid="pone.0022026-Gliga1">[52]</xref> N170 electromagnetic response. However, such an asymmetry may reflect the numerous presence of male individuals in the experimental sample, since sex differences in the lateralization of face-related visual processing exist, with more bilateral processing in women and right-sided lateralization in men <xref ref-type="bibr" rid="pone.0022026-Proverbio5">[53]</xref>, <xref ref-type="bibr" rid="pone.0022026-Bourne1">[54]</xref>.</p>
      <p>The early coding of cooperative pictures was instead associated with the activation of the right MTG/pSTG (BA21), which was the strongest generator. The early coding of cooperative pictures was also associated with the right parahippocampal area possibly involved in the processing of scenes and places (PPA), which were more relevant for comprehending the action's goal than for affective interactions, that are more centred to the human body and facial expressions). The early coding of cooperative pictures was also associated with the medial frontal cortex. Both this region <xref ref-type="bibr" rid="pone.0022026-Iacoboni1">[55]</xref> and especially the rSTG have been repeatedly described as described as being primarily involved in perceiving biological motion <xref ref-type="bibr" rid="pone.0022026-Pelphrey1">[56]</xref>, <xref ref-type="bibr" rid="pone.0022026-Puce1">[57]</xref> and understanding of others' goals and intentions <xref ref-type="bibr" rid="pone.0022026-Carter1">[58]</xref>, <xref ref-type="bibr" rid="pone.0022026-Pelphrey2">[59]</xref>.</p>
      <p>The analysis of the time course of brain processing indicates that the coding of scene content and possibly of the action's goal was faster for affective scenes than cooperative scenes. Indeed, the subsequent centro-parietal response (N160–280) was the first component that displayed a larger potential to cooperative actions compared to affective actions, particularly over the left hemisphere. The swLORETA inverse solution provided evidence of a strong parietal involvement of the left post-central gyrus along with the right pre-central gyrus (BA6). The left hemispheric symmetry in IPL activation strongly agrees with the LORETA inverse solution from Ortigue et al. <xref ref-type="bibr" rid="pone.0022026-Ortigue1">[11]</xref>, which measured VEPs to hand-objects interactions. According to Grezes and Decety <xref ref-type="bibr" rid="pone.0022026-Grzes1">[60]</xref>, the precentral gyrus is involved in the mental simulation of human actions. The <italic>embodied theory</italic> of action <xref ref-type="bibr" rid="pone.0022026-Pineda1">[61]</xref> predicts that simulation is based on the activation of the somatosensory cortex. Furthermore, several MEG <xref ref-type="bibr" rid="pone.0022026-Avikainen1">[6]</xref>, <xref ref-type="bibr" rid="pone.0022026-Mttnen1">[7]</xref> and fMRI studies <xref ref-type="bibr" rid="pone.0022026-Schubotz1">[62]</xref> suggest that the somatosensory cortex is particularly active during the observation of actions. Some studies <xref ref-type="bibr" rid="pone.0022026-Hamilton1">[63]</xref>–<xref ref-type="bibr" rid="pone.0022026-Fecteau1">[65]</xref>, indeed, have explicitly included the somatosensory cortex in the fronto-parietal human mirror system devoted to the comprehension of human actions. As for the precentral gyrus (BA6) activation found in response to cooperative actions, many studies have demonstrated the role of the premotor cortex in action comprehension <xref ref-type="bibr" rid="pone.0022026-Rizzolatti2">[66]</xref>, <xref ref-type="bibr" rid="pone.0022026-Buccino1">[67]</xref>, in the coding of action motor schema <xref ref-type="bibr" rid="pone.0022026-MolnarSzakacs1">[68]</xref> and in mental simulation of actions<xref ref-type="bibr" rid="pone.0022026-Decety1">[69]</xref>. On the other hand, the activation of more anterior brain regions (left and right superior frontal gyri) may be linked to their role in the automatic comprehension of the action purpose for both affective and cooperative interactions <xref ref-type="bibr" rid="pone.0022026-Iacoboni1">[55]</xref>, <xref ref-type="bibr" rid="pone.0022026-Iacoboni2">[70]</xref>.</p>
      <p>Going further with the time course of information processing within the 250–350 ms time window, a positive occipito/temporal P300 was of greater amplitude in response to cooperative actions compared to affective actions. A simple effect analysis revealed a greater discriminative effect in women than men. It is interesting to note that a recent fMRI study <xref ref-type="bibr" rid="pone.0022026-Cappa1">[71]</xref> performed with the same experimental paradigm, but on different subjects, provided evidence of a sex difference in neural activation as a function of the type of action. Cooperation-specific activity engaged mostly limbic and reward-related areas (right ventral striatum and caudal orbitofrontal cortex) in males, while areas associated with bilateral fronto-parietal mirror-activity (EBA, pSTS, rostral portion of the inferior parietal lobule and premotor cortex) were more strongly activated by the same condition in females than males. It is possible to hypothesize that the specific pattern of activation in the female brain reflects, to a greater extent, a resonating system supporting the comprehension of the action's intentions. Indeed, the superior temporal sulcus and the ventral premotor cortex are part of the so-called human mirror neuron system (MNS) <xref ref-type="bibr" rid="pone.0022026-Rizzolatti2">[66]</xref>, <xref ref-type="bibr" rid="pone.0022026-Buccino1">[67]</xref>, <xref ref-type="bibr" rid="pone.0022026-Buccino2">[72]</xref>. It is likely that the MNS mirrors the actions and experiences of others with one's own actions and experiences, thus providing a key to understanding the intentions of others <xref ref-type="bibr" rid="pone.0022026-Iacoboni2">[70]</xref>, <xref ref-type="bibr" rid="pone.0022026-Hamilton2">[73]</xref>.</p>
      <p>The gender difference in the comprehension of the actions' purpose also fits with previous evidence of a greater empathic attitude in females <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref>, <xref ref-type="bibr" rid="pone.0022026-Proverbio4">[41]</xref>, <xref ref-type="bibr" rid="pone.0022026-BaronCohen2">[74]</xref>–<xref ref-type="bibr" rid="pone.0022026-SchulteRuther1">[76]</xref>. Kaplan and Iacoboni <xref ref-type="bibr" rid="pone.0022026-Kaplan1">[77]</xref> suggest that the MNS supports a simulation system devoted to the understanding of the intentions of others and that this system is linked to other social competence functions, such as empathy. In the literature, some neuroscientific evidence of a sex difference in the responsiveness of the MNS to human actions was recently demonstrated. In particular, Cheng and collaborators <xref ref-type="bibr" rid="pone.0022026-Cheng1">[33]</xref> used a voxel-based morphometry analysis to show that young adult females had significantly larger gray matter volume in the pars opercularis and inferior parietal lobule than matched male participants. The authors interpreted their data as an index of neuroanatomical sex differences in the human MNS. They also suggested that the network of the human mirror-neuron system is strongly linked to empathy competence.</p>
      <p>In the present study, Anterior Negativity modulated the amplitude of fronto-central N2 and N400 deflections that were much greater during the processing of cooperative actions. This higher order and later involvement of prefrontal brain regions in the processing of socially-relevant information has been previously reported, for example in the processing of social relations by medial prefrontal cortex in <xref ref-type="bibr" rid="pone.0022026-Iacoboni1">[55]</xref>. Again, the roles of the frontal areas (the prefrontal and orbitofrontal cortex) in higher order cognitive functions, such as social reasoning and decision making, have been determined <xref ref-type="bibr" rid="pone.0022026-Adolphs1">[44]</xref>. The LORETA inverse solution performed on ERP data showed that the medial and superior frontal gyri (BA10/11) were indeed active as early as 170 ms post-stimulus during action processing. However there was a difference in their activation as a function of the type of interaction and along the time course of neural processing. At N170 level the medial frontal cortex was activated over the right hemisphere, and more strongly to affective than cooperative interactions, whereas at N2 level the superior frontal gyrus was activated over the left hemisphere, more strongly to cooperative than affective interactions.</p>
      <p>The sex difference in hemispheric lateralization relative to the scalp distribution of anterior negativity is also interesting. While the anterior negativity was bilateral in women, it was strongly left-sided in men. This sex difference in lateral preference and hemispheric lateralization is well documented for a variety of stimuli in the literature. For example, in an ERP study on the emotional processing of facial expressions, Proverbio et al. <xref ref-type="bibr" rid="pone.0022026-Proverbio5">[53]</xref> found a smaller degree of lateralization of face-devoted ERP responses (P1 and N170) in women compared to men. Several studies have found a bilateral vs. right-sided bias in structural brain asymmetry (e.g., <xref ref-type="bibr" rid="pone.0022026-Kovalev1">[78]</xref>) and in the emotional coding of visual information <xref ref-type="bibr" rid="pone.0022026-Kemp1">[79]</xref>, <xref ref-type="bibr" rid="pone.0022026-Schneider1">[80]</xref>. Overall, our results agree with many studies that show differences between men and women in the degree of lateralization of cognitive and affective processes. Substantial data support greater hemispheric lateralization in men than women for linguistic tasks <xref ref-type="bibr" rid="pone.0022026-Shaywitz1">[81]</xref> and for spatial tasks <xref ref-type="bibr" rid="pone.0022026-Rilea1">[82]</xref>. Gender differences have also been found in the lateralization of visual-spatial processes, such as object construction and mental rotation tasks <xref ref-type="bibr" rid="pone.0022026-Johnson1">[83]</xref>, in which males are typically right hemisphere (RH)-dominant while females are bilaterally distributed.</p>
      <sec id="s4a">
        <title>Conclusions</title>
        <p>The present ERP data suggest the existence of a neural circuit that strongly responds to visual scenes depicting human interactions and is capable of discriminating goal-directed cooperative vs. affective actions. In particular, affective scenes were processed earlier than cooperative scenes, as indicated by the latency of early N170 modulation. The LORETA analysis identified a strong focus of activation in the cingulate cortex (which is known to provide the affective connotation to visual coding), the medial occipital cortex and the face fusiform gyrus (possibly devoted to face and body processing) during the perception of affective scenes, and the right medial frontal cortex.</p>
        <p>The specific processing of a cooperative purpose did not emerge before 200 ms and progressed until 500 ms post-stimulus, as indexed by the modulation of parietal N200, P300 and anterior negativity, which were of greater amplitude in response to cooperative pictures compared to affective pictures. Cooperative scenes seemed to initially activate the pSTG and the medial frontal cortex, and neural populations belonging to the fronto-parietal neuron-mirror system were activated thereafter (<xref ref-type="bibr" rid="pone.0022026-Rizzolatti1">[1]</xref>, <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref>, <xref ref-type="bibr" rid="pone.0022026-Proverbio6">[84]</xref>). The LORETA analysis identified the sources of activation for the processing of cooperative actions over the left parietal cortex and the left and right premotor areas (BA6)<xref ref-type="bibr" rid="pone.0022026-Cappa1">[71]</xref>, thus indicating that the mirror neuron system (MNS) is more strongly activated by cooperative, than affective, actions. This result is consistent with the MNS being involved in the visuo-motor transformation of actions and action representation (parietal N2). Later on, the premotor and prefrontal areas are involved in more complex social processing (P300 and Anterior Negativity).</p>
        <p>The analysis of posterior P300 responses also suggests a sex difference in the processing of the two scene types. Indeed, a larger inter-category difference was found in women compared to men, suggesting improved comprehension of unattended social scenes. This finding is possibly related to women's supposed increased interest in conspecifics <xref ref-type="bibr" rid="pone.0022026-Proverbio7">[85]</xref>.</p>
        <p>Finally, our results highlighted a different pattern of hemispheric lateralization as a function of scene content and viewers' gender. The N170 response was greater over the left hemisphere, compared with the right one, only in response to cooperative scenes, while the response was bilateral in response to social scenes. Again, the N2 amplitude showed a lack of scene content coding over the right hemisphere and a significantly larger N2 in response to cooperative vs. socially-aimed interactions over the left parietal site. Consistently, the LORETA inverse solution provided evidence of a stronger activation of left-sided regions during the processing of cooperative actions between 200–250 ms (left fusiform gyrus, BA37, left parietal cortex (BA3), and left para-hippocampal gyrus), along with a stronger activation of the right premotor cortex (BA6). These results are in agreement with previous investigations <xref ref-type="bibr" rid="pone.0022026-Ortigue1">[11]</xref>. Women showed a larger response that was discriminative of action intentions compared to men at the posterior P300 level (250–350 ms) and at the anterior negativity level (220–500 ms). In addition, the discriminative effect was bilateral in women, and much smaller and left-sided in men suggesting that this finding may be related to the supposed greater responsiveness of the female vs. male MNS <xref ref-type="bibr" rid="pone.0022026-Proverbio1">[12]</xref>, <xref ref-type="bibr" rid="pone.0022026-Pavlova2">[25]</xref>, <xref ref-type="bibr" rid="pone.0022026-Cheng1">[33]</xref>, <xref ref-type="bibr" rid="pone.0022026-Cheng2">[34]</xref>, <xref ref-type="bibr" rid="pone.0022026-BaronCohen2">[74]</xref>. One potential limitation of this study, however, is the sample size, which was not so conspicuous for analyzing sex-related differences. As a consequence, it should be at least considered that some null findings might be due to lack of power.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We are grateful to Roberta Adorni, Nicola Crotti, Mirella Manfredi and Federica Alemanno for their kind support.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0022026-Rizzolatti1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name><name name-style="western"><surname>Sinigaglia</surname><given-names>C</given-names></name></person-group>             <year>2010</year>             <article-title>The functional role of the parieto-frontal mirror circuit: interpretations and misinterpretations.</article-title>             <source>Nat Rev Neurosci</source>             <volume>11</volume>             <fpage>264</fpage>             <lpage>274</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Shmuelof1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shmuelof</surname><given-names>L</given-names></name><name name-style="western"><surname>Zohary</surname><given-names>E</given-names></name></person-group>             <year>2007</year>             <article-title>Watching Others' Actions: Mirror Representations in the Parietal Cortex.</article-title>             <source>The Neuroscientist</source>             <volume>13</volume>             <fpage>667</fpage>             <lpage>672</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-NewmanNorlund1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Newman-Norlund</surname><given-names>R</given-names></name><name name-style="western"><surname>van Schie</surname><given-names>HT</given-names></name><name name-style="western"><surname>van Hoek</surname><given-names>MEC</given-names></name><name name-style="western"><surname>Cuijpers</surname><given-names>RH</given-names></name><name name-style="western"><surname>Bekkering</surname><given-names>H</given-names></name></person-group>             <year>2010</year>             <article-title>The role of inferior frontal and parietal areas in differentiating meaningful and meaningless object-directed actions.</article-title>             <source>Brain Research</source>             <volume>1315</volume>             <fpage>63</fpage>             <lpage>74</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Ulloa1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ulloa</surname><given-names>ER</given-names></name><name name-style="western"><surname>Pineda</surname><given-names>JA</given-names></name></person-group>             <year>2007</year>             <article-title>Recognition of point-light biological motion: Mu rhythms and mirror neuron activity.</article-title>             <source>Behavioural Brain Research</source>             <volume>183</volume>             <fpage>188</fpage>             <lpage>194</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Perry1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perry</surname><given-names>A</given-names></name><name name-style="western"><surname>Bentin</surname><given-names>S</given-names></name></person-group>             <year>2009</year>             <article-title>Mirror activity in the human brain while observing hand movements: A comparison between EEG desynchronization in the [mu]-range and previous fMRI results.</article-title>             <source>Brain Research</source>             <volume>1282</volume>             <fpage>126</fpage>             <lpage>132</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Avikainen1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Avikainen</surname><given-names>S</given-names></name><name name-style="western"><surname>Forss</surname><given-names>N</given-names></name><name name-style="western"><surname>Hari</surname><given-names>R</given-names></name></person-group>             <year>2002</year>             <article-title>Modulated Activation of the Human SI and SII Cortices during Observation of Hand Actions.</article-title>             <source>NeuroImage</source>             <volume>15</volume>             <fpage>640</fpage>             <lpage>646</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Mttnen1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Möttönen</surname><given-names>R</given-names></name><name name-style="western"><surname>Järveläinen</surname><given-names>J</given-names></name><name name-style="western"><surname>Sams</surname><given-names>M</given-names></name><name name-style="western"><surname>Hari</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Viewing speech modulates activity in the left SI mouth cortex.</article-title>             <source>NeuroImage</source>             <volume>24</volume>             <fpage>731</fpage>             <lpage>737</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Gunter1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gunter</surname><given-names>TC</given-names></name><name name-style="western"><surname>Bach</surname><given-names>P</given-names></name></person-group>             <year>2004</year>             <article-title>Communicating hands: ERPs elicited by meaningful symbolic hand postures.</article-title>             <source>Neuroscience Letters</source>             <volume>372</volume>             <fpage>52</fpage>             <lpage>56</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Shibata1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shibata</surname><given-names>H</given-names></name><name name-style="western"><surname>Gyoba</surname><given-names>J</given-names></name><name name-style="western"><surname>Suzuki</surname><given-names>Y</given-names></name></person-group>             <year>2009</year>             <article-title>Event-related potentials during the evaluation of the appropriateness of cooperative actions.</article-title>             <source>Neuroscience Letters</source>             <volume>452</volume>             <fpage>189</fpage>             <lpage>193</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Bach1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bach</surname><given-names>P</given-names></name><name name-style="western"><surname>Gunter</surname><given-names>T</given-names></name><name name-style="western"><surname>Knoblich</surname><given-names>G</given-names></name><name name-style="western"><surname>Prinz</surname><given-names>W</given-names></name><name name-style="western"><surname>Friederici</surname><given-names>AD</given-names></name></person-group>             <year>2009</year>             <article-title>N400-like negativities in action perception reflect the activation of two components of an action representation.</article-title>             <source>Social Neuroscience</source>             <volume>4</volume>             <fpage>212</fpage>             <lpage>232</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Ortigue1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ortigue</surname><given-names>S</given-names></name><name name-style="western"><surname>Sinigaglia</surname><given-names>C</given-names></name><name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name><name name-style="western"><surname>Grafton</surname><given-names>ST</given-names></name></person-group>             <year>2010</year>             <article-title>Understanding Actions of Others: The Electrodynamics of the Left and Right Hemispheres. A High-Density EEG Neuroimaging Study.</article-title>             <source>PLoS ONE</source>             <volume>5</volume>             <fpage>e12160</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Riva</surname><given-names>F</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name></person-group>             <year>2010</year>             <article-title>When neurons do not mirror the agent's intentions: Sex differences in neural coding of goal-directed actions.</article-title>             <source>Neuropsychologia</source>             <volume>48</volume>             <fpage>1454</fpage>             <lpage>1463</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-NewmanNorlund2">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Newman-Norlund</surname><given-names>R</given-names></name><name name-style="western"><surname>van Schie</surname><given-names>HT</given-names></name><name name-style="western"><surname>van Hoek</surname><given-names>MEC</given-names></name><name name-style="western"><surname>Cuijpers</surname><given-names>RH</given-names></name><name name-style="western"><surname>Bekkering</surname><given-names>H</given-names></name></person-group>             <year>2009</year>             <article-title>The role of inferior frontal and parietal areas in differentiating meaningful and meaningless object-directed actions.</article-title>             <source>Brain Research</source>             <volume>1315</volume>             <fpage>63</fpage>             <lpage>74</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Heider1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Heider</surname><given-names>F</given-names></name><name name-style="western"><surname>Simmel</surname><given-names>M</given-names></name></person-group>             <year>1944</year>             <article-title>An experimental study of apparent behavior.</article-title>             <source>American Journal of Psychology</source>             <volume>57</volume>             <fpage>243</fpage>             <lpage>259</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Abell1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Abell</surname><given-names>F</given-names></name><name name-style="western"><surname>Happé</surname><given-names>F</given-names></name><name name-style="western"><surname>Frith</surname><given-names>U</given-names></name></person-group>             <year>2000</year>             <article-title>Do triangles play tricks? Attribution of mental states to animated shapes in normal and abnormal development.</article-title>             <source>Journal of Cognitive Development,</source>             <volume>15</volume>             <fpage>1</fpage>             <lpage>20</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Tremoulet1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tremoulet</surname><given-names>PD</given-names></name><name name-style="western"><surname>Feldman</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>The influence of spatial context and the role of intentionality in the interpretation of animacy from motion.</article-title>             <source>Perception &amp; Psychophysics</source>             <volume>68</volume>             <issue>6</issue>             <fpage>1047</fpage>             <lpage>1058</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pavlova1">
        <label>17</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pavlova</surname><given-names>M</given-names></name><name name-style="western"><surname>Guerreschi</surname><given-names>M</given-names></name><name name-style="western"><surname>Lutzenberger</surname><given-names>W</given-names></name><name name-style="western"><surname>Krageloh-Mann</surname><given-names>I</given-names></name></person-group>             <year>2010</year>             <article-title>Social Interaction Revealed by Motion: Dynamics of Neuromagnetic Gamma Activity.</article-title>             <source>Cereb Cortex</source> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">bhp304</size>           </element-citation>
      </ref>
      <ref id="pone.0022026-Kokal1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kokal</surname><given-names>I</given-names></name><name name-style="western"><surname>Gazzola</surname><given-names>V</given-names></name><name name-style="western"><surname>Keysers</surname><given-names>C</given-names></name></person-group>             <year>2009</year>             <article-title>Acting together in and beyond the mirror neuron system.</article-title>             <source>NeuroImage</source>             <volume>47</volume>             <fpage>2046</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-McCabe1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McCabe</surname><given-names>K</given-names></name><name name-style="western"><surname>Houser</surname><given-names>D</given-names></name><name name-style="western"><surname>Ryan</surname><given-names>L</given-names></name><name name-style="western"><surname>Smith</surname><given-names>V</given-names></name><name name-style="western"><surname>Trouard</surname><given-names>T</given-names></name></person-group>             <year>2001</year>             <article-title>A functional imaging study of cooperation in two-person reciprocal exchange.</article-title>             <source>Proceedings of the National Academy of Sciences of the United States of America</source>             <volume>98</volume>             <fpage>11832</fpage>             <lpage>11835</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Rilling1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rilling</surname><given-names>JK</given-names></name><name name-style="western"><surname>Gutman</surname><given-names>DA</given-names></name><name name-style="western"><surname>Zeh</surname><given-names>TR</given-names></name><name name-style="western"><surname>Pagnoni</surname><given-names>G</given-names></name><name name-style="western"><surname>Berns</surname><given-names>GS</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>A Neural Basis for Social Cooperation.</article-title>             <source>Neuron</source>             <volume>35</volume>             <fpage>395</fpage>             <lpage>405</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Centelles1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Centelles</surname><given-names>L</given-names></name><name name-style="western"><surname>Assaiante</surname><given-names>C</given-names></name><name name-style="western"><surname>Nazarian</surname><given-names>B</given-names></name><name name-style="western"><surname>Anton</surname><given-names>J-L</given-names></name><name name-style="western"><surname>Schmitz</surname><given-names>C</given-names></name></person-group>             <year>2011</year>             <article-title>Recruitment of Both the Mirror and the Mentalizing Networks When Observing Social Interactions Depicted by Point-Lights: A Neuroimaging Study.</article-title>             <source>PLoS ONE</source>             <volume>6</volume>             <fpage>e15749</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Haxby1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name><name name-style="western"><surname>Hoffman</surname><given-names>EA</given-names></name><name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name></person-group>             <year>2000</year>             <article-title>The distributed human neural system for face perception.</article-title>             <source>Trends Cogn Sci</source>             <volume>4</volume>             <fpage>223</fpage>             <lpage>233</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Downing1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Downing</surname><given-names>P</given-names></name><name name-style="western"><surname>Peelen</surname><given-names>M</given-names></name><name name-style="western"><surname>Wiggett</surname><given-names>A</given-names></name><name name-style="western"><surname>Tew</surname><given-names>B</given-names></name></person-group>             <year>2006</year>             <article-title>The role of the extrastriate body area in action perception.</article-title>             <source>Soc Neurosci</source>             <volume>1</volume>             <issue>1</issue>             <fpage>52</fpage>             <lpage>62</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Takahashi1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Takahashi</surname><given-names>H</given-names></name><name name-style="western"><surname>Shibuya</surname><given-names>T</given-names></name><name name-style="western"><surname>Kato</surname><given-names>M</given-names></name><name name-style="western"><surname>Sassa</surname><given-names>T</given-names></name><name name-style="western"><surname>Koeda</surname><given-names>M</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Enhanced activation in the extrastriate body area by goal-directed actions.</article-title>             <source>Psychiatry and Clinical Neurosciences</source>             <volume>62</volume>             <fpage>214</fpage>             <lpage>219</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pavlova2">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pavlova</surname><given-names>M</given-names></name><name name-style="western"><surname>Guerreschi</surname><given-names>M</given-names></name><name name-style="western"><surname>Lutzenberger</surname><given-names>W</given-names></name><name name-style="western"><surname>Sokolov</surname><given-names>AN</given-names></name><name name-style="western"><surname>Krägeloh-Mann</surname><given-names>I</given-names></name></person-group>             <year>2010</year>             <article-title>Cortical response to social interaction is affected by gender.</article-title>             <source>NeuroImage</source>             <volume>50</volume>             <fpage>1327</fpage>             <lpage>1332</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Bentin1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bentin</surname><given-names>S</given-names></name><name name-style="western"><surname>Allison</surname><given-names>T</given-names></name><name name-style="western"><surname>Puce</surname><given-names>A</given-names></name><name name-style="western"><surname>Perez</surname><given-names>E</given-names></name><name name-style="western"><surname>McCarthy</surname><given-names>G</given-names></name></person-group>             <year>1996</year>             <article-title>Electrophysiological studies of face perception in humans.</article-title>             <source>Journal Of Cognitive Neuroscience</source>             <volume>8</volume>             <fpage>551</fpage>             <lpage>565</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Kanwisher1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name><name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name></person-group>             <year>2006</year>             <article-title>The fusiform face area: a cortical region specialized for the perception of faces.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>361</volume>             <fpage>2109</fpage>             <lpage>2128</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio2">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Matarazzo</surname><given-names>S</given-names></name><name name-style="western"><surname>Brignone</surname><given-names>V</given-names></name><name name-style="western"><surname>Zotto</surname><given-names>MD</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Processing valence and intensity of infant expressions: The roles of expertise and gender.</article-title>             <source>Scandinavian Journal of Psychology</source>             <volume>48</volume>             <fpage>477</fpage>             <lpage>485</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Freeman1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Freeman</surname><given-names>JB</given-names></name><name name-style="western"><surname>Ambady</surname><given-names>N</given-names></name><name name-style="western"><surname>Holcomb</surname><given-names>PJ</given-names></name></person-group>             <year>2010</year>             <article-title>The face-sensitive N170 encodes social category information.</article-title>             <source>Neuroreport</source>             <volume>6</volume>             <issue>21</issue>             <fpage>24</fpage>             <lpage>28</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Domes1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Domes</surname><given-names>G</given-names></name><name name-style="western"><surname>Heinrichs</surname><given-names>M</given-names></name><name name-style="western"><surname>Michel</surname><given-names>A</given-names></name><name name-style="western"><surname>Berger</surname><given-names>C</given-names></name><name name-style="western"><surname>Herpertz</surname><given-names>SC</given-names></name></person-group>             <year>2007</year>             <article-title>Oxytocin Improves “Mind-Reading” in Humans.</article-title>             <source>Biological Psychiatry</source>             <volume>61</volume>             <fpage>731</fpage>             <lpage>733</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-SchulteRther1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schulte-Rüther</surname><given-names>M</given-names></name><name name-style="western"><surname>Markowitsch</surname><given-names>HJ</given-names></name><name name-style="western"><surname>Shah</surname><given-names>NJ</given-names></name><name name-style="western"><surname>Fink</surname><given-names>GR</given-names></name><name name-style="western"><surname>Piefke</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Gender differences in brain networks supporting empathy.</article-title>             <source>NeuroImage</source>             <volume>42</volume>             <fpage>393</fpage>             <lpage>403</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Yang1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>C-Y</given-names></name><name name-style="western"><surname>Decety</surname><given-names>J</given-names></name><name name-style="western"><surname>Lee</surname><given-names>S</given-names></name><name name-style="western"><surname>Chen</surname><given-names>C</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>Y</given-names></name></person-group>             <year>2009</year>             <article-title>Gender differences in the mu rhythm during empathy for pain: An electroencephalographic study.</article-title>             <source>Brain Research</source>             <volume>1251</volume>             <fpage>176</fpage>             <lpage>184</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Cheng1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cheng</surname><given-names>Y</given-names></name><name name-style="western"><surname>Chou</surname><given-names>KH</given-names></name><name name-style="western"><surname>Decety</surname><given-names>J</given-names></name><name name-style="western"><surname>Chen</surname><given-names>IY</given-names></name><name name-style="western"><surname>Hung</surname><given-names>D</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Sex differences in the neuroanatomy of human mirror-neuron system: A voxel-based morphometric investigation.</article-title>             <source>Neuroscience</source>             <volume>158</volume>             <fpage>713</fpage>             <lpage>720</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Cheng2">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cheng</surname><given-names>Y</given-names></name><name name-style="western"><surname>Lee</surname><given-names>P-L</given-names></name><name name-style="western"><surname>Yang</surname><given-names>C-Y</given-names></name><name name-style="western"><surname>Lin</surname><given-names>C-P</given-names></name><name name-style="western"><surname>Hung</surname><given-names>D</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Gender Differences in the Mu Rhythm of the Human Mirror-Neuron System.</article-title>             <source>PLoS ONE</source>             <volume>3</volume>             <fpage>e2113</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-BaronCohen1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baron-Cohen</surname><given-names>S</given-names></name><name name-style="western"><surname>Wheelwright</surname><given-names>S</given-names></name></person-group>             <year>2004</year>             <article-title>The empathy quotient: an investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences.</article-title>             <source>Journal of Autism and Developmental Disorders</source>             <volume>33</volume>             <issue>5</issue>             <fpage>509</fpage>             <lpage>17</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-PasqualMarqui1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pasqual-Marqui</surname><given-names>RD</given-names></name><name name-style="western"><surname>Michel</surname><given-names>CM</given-names></name><name name-style="western"><surname>Lehmann</surname><given-names>D</given-names></name></person-group>             <year>1994</year>             <article-title>Low resolution electromagnetic tomography: a new method for localizing electrical activity in the brain.</article-title>             <source>In J Psychophysiol</source>             <volume>18</volume>             <fpage>49</fpage>             <lpage>65</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-PalmeroSoler1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Palmero-Soler</surname><given-names>E</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>K</given-names></name><name name-style="western"><surname>Hadamschek</surname><given-names>V</given-names></name><name name-style="western"><surname>Tass</surname><given-names>PA</given-names></name></person-group>             <year>2007</year>             <article-title>swLORETA: a novel approach to robust source localization and synchronization tomography.</article-title>             <source>Physics in medicine and biology</source>             <volume>52</volume>             <fpage>1783</fpage>             <lpage>1800</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Zanow1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zanow</surname><given-names>F</given-names></name><name name-style="western"><surname>Knösche</surname><given-names>TR</given-names></name></person-group>             <year>2004</year>             <article-title>ASA-Advanced Source Analysis of Continuous and Event-Related EEG/MEG Signals.</article-title>             <source>Brain Topography</source>             <volume>16</volume>             <fpage>287</fpage>             <lpage>290</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pizzagalli1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pizzagalli</surname><given-names>DA</given-names></name><name name-style="western"><surname>Lehmann</surname><given-names>D</given-names></name><name name-style="western"><surname>Hendrick</surname><given-names>AM</given-names></name><name name-style="western"><surname>Regard</surname><given-names>M</given-names></name><name name-style="western"><surname>Pascual-Marqui</surname><given-names>RD</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>Affective Judgments of Faces Modulate Early Activity (∼160 ms) within the Fusiform Gyri.</article-title>             <source>NeuroImage</source>             <volume>16</volume>             <fpage>663</fpage>             <lpage>677</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio3">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Brignone</surname><given-names>V</given-names></name><name name-style="western"><surname>Matarazzo</surname><given-names>S</given-names></name><name name-style="western"><surname>Del Zotto</surname><given-names>M</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Gender and parental status affect the visual cortical response to infant facial expression.</article-title>             <source>Neuropsychologia</source>             <volume>44</volume>             <fpage>2987</fpage>             <lpage>2999</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio4">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Adorni</surname><given-names>R</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name><name name-style="western"><surname>Trestianu</surname><given-names>L</given-names></name></person-group>             <year>2009</year>             <article-title>Sex differences in the brain response to affective scenes with or without humans.</article-title>             <source>Neuropsychologia</source>             <volume>47</volume>             <issue>12</issue>             <fpage>2374</fpage>             <lpage>88</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Junghfer1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Junghöfer</surname><given-names>M</given-names></name><name name-style="western"><surname>Bradley</surname><given-names>MM</given-names></name><name name-style="western"><surname>Elbert</surname><given-names>TR</given-names></name><name name-style="western"><surname>Lang</surname><given-names>PJ</given-names></name></person-group>             <year>2001</year>             <article-title>Fleeting images: A new look at early emotion discrimination.</article-title>             <source>Psychophysiology</source>             <volume>38</volume>             <fpage>175</fpage>             <lpage>178</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Phillips1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Phillips</surname><given-names>ML</given-names></name><name name-style="western"><surname>Bullmore</surname><given-names>ET</given-names></name><name name-style="western"><surname>Howard</surname><given-names>R</given-names></name><name name-style="western"><surname>Woodruff</surname><given-names>PWR</given-names></name><name name-style="western"><surname>Wright</surname><given-names>IC</given-names></name><etal/></person-group>             <year>1998</year>             <article-title>Investigation of facial recognition memory and happy and sad facial expression perception: an fMRI study.</article-title>             <source>Psychiatry Res</source>             <volume>83</volume>             <fpage>127</fpage>             <lpage>138</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Adolphs1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Adolphs</surname><given-names>R</given-names></name></person-group>             <year>2003</year>             <article-title>Cognitive neuroscience of human social behaviour.</article-title>             <source>Nat Rev, Neurosci</source>             <volume>4</volume>             <fpage>165</fpage>             <lpage>178</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Vogt1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vogt</surname><given-names>BA</given-names></name><name name-style="western"><surname>Vogt</surname><given-names>L</given-names></name><name name-style="western"><surname>Laureys</surname><given-names>S</given-names></name></person-group>             <year>2006</year>             <article-title>Cytology and functionally correlated circuits of human posterior cingulate areas.</article-title>             <source>NeuroImage</source>             <volume>29</volume>             <fpage>452</fpage>             <lpage>466</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Henson1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Henson</surname><given-names>RN</given-names></name><name name-style="western"><surname>Goshen-Gottstein</surname><given-names>Y</given-names></name><name name-style="western"><surname>Ganel</surname><given-names>T</given-names></name><name name-style="western"><surname>Otten</surname><given-names>LJ</given-names></name><name name-style="western"><surname>Quayle</surname><given-names>A</given-names></name><etal/></person-group>             <year>2003</year>             <article-title>Electrophysiological and Haemodynamic Correlates of Face Perception, Recognition and Priming.</article-title>             <source>Cerebral Cortex</source>             <volume>13</volume>             <fpage>793</fpage>             <lpage>805</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Taylor1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Taylor</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Bayless</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Mills</surname><given-names>T</given-names></name><name name-style="western"><surname>Pang</surname><given-names>EW</given-names></name></person-group>             <year>2011</year>             <article-title>Recognising upright and inverted faces: MEG source localisation.</article-title>             <source>Brain Research</source>             <volume>1381</volume>             <fpage>167</fpage>             <lpage>174</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Scalaidhe1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Scalaidhe</surname><given-names>SPO</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>FAW</given-names></name><name name-style="western"><surname>Goldman-Rakic</surname><given-names>SP</given-names></name></person-group>             <year>1999</year>             <article-title>Face-selective Neurons During Passive Viewing and Working Memory Performance of Rhesus Monkeys: Evidence for Intrinsic Specialization of Neuronal Coding.</article-title>             <source>Cerebral Cortex</source>             <volume>9</volume>             <fpage>459</fpage>             <lpage>475</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-George1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>George</surname><given-names>N</given-names></name><name name-style="western"><surname>Jemel</surname><given-names>B</given-names></name><name name-style="western"><surname>Fiori</surname><given-names>N</given-names></name><name name-style="western"><surname>Chaby</surname><given-names>L</given-names></name><name name-style="western"><surname>Renault</surname><given-names>B</given-names></name></person-group>             <year>2005</year>             <article-title>Electrophysiological correlates of facial decision: Insights from upright and upside-down Mooney-face perception.</article-title>             <source>Cogn Brain Res</source>             <volume>310</volume>             <fpage>663</fpage>             <lpage>673</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Caldara1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Caldara</surname><given-names>R</given-names></name><name name-style="western"><surname>Rossion</surname><given-names>B</given-names></name><name name-style="western"><surname>Bovet</surname><given-names>P</given-names></name><name name-style="western"><surname>Hauert</surname><given-names>CA</given-names></name></person-group>             <year>2004</year>             <article-title>Event-related potentials and time course of the “other-race” face classification advantage.</article-title>             <source>Neuroreport</source>             <volume>9</volume>             <fpage>905</fpage>             <lpage>910</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Rossion1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rossion</surname><given-names>B</given-names></name><name name-style="western"><surname>Joyce</surname><given-names>CA</given-names></name><name name-style="western"><surname>Cottrell</surname><given-names>GW</given-names></name><name name-style="western"><surname>Tarr</surname><given-names>MJ</given-names></name></person-group>             <year>2003</year>             <article-title>Early lateralization and orientation tuning for face, word, and object processing in the visual cortex.</article-title>             <source>Neuroimage</source>             <volume>20</volume>             <fpage>1609</fpage>             <lpage>1624</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Gliga1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gliga</surname><given-names>T</given-names></name><name name-style="western"><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Structural Encoding of Body and Face in Human Infants and Adults.</article-title>             <source>Journal of Cognitive Neuroscience</source>             <volume>17</volume>             <fpage>1328</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio5">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Brignone</surname><given-names>V</given-names></name><name name-style="western"><surname>Matarazzo</surname><given-names>S</given-names></name><name name-style="western"><surname>Del Zotto</surname><given-names>M</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Gender differences in hemispheric asymmetry for face processing.</article-title>             <source>BMC Neuroscience</source>             <volume>8</volume>             <issue>7</issue>             <fpage>44</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Bourne1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bourne</surname><given-names>VJ</given-names></name></person-group>             <year>2005</year>             <article-title>Lateralized processing of positive facial emotion: sex differences in strength of hemispheric dominance.</article-title>             <source>Neuropsychologia</source>             <volume>43</volume>             <fpage>953</fpage>             <lpage>956</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Iacoboni1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name><name name-style="western"><surname>Lieberman</surname><given-names>MD</given-names></name><name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name><name name-style="western"><surname>Moritz</surname><given-names>M</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Watching social interactions produces dorsomedial prefrontal and medial parietal BOLD fMRI signal increases compared to a resting baseline.</article-title>             <source>NeuroImage</source>             <volume>21</volume>             <fpage>1167</fpage>             <lpage>1173</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pelphrey1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pelphrey</surname><given-names>KA</given-names></name><name name-style="western"><surname>Mitchell</surname><given-names>TV</given-names></name><name name-style="western"><surname>McKeown</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Goldstein</surname><given-names>J</given-names></name><name name-style="western"><surname>Allison</surname><given-names>T</given-names></name><etal/></person-group>             <year>2003</year>             <article-title>Brain Activity Evoked by the Perception of Human Walking: Controlling for Meaningful Coherent Motion.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>6819</fpage>             <lpage>6825</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Puce1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Puce</surname><given-names>A</given-names></name><name name-style="western"><surname>Allison</surname><given-names>T</given-names></name><name name-style="western"><surname>Bentin</surname><given-names>S</given-names></name><name name-style="western"><surname>Gore</surname><given-names>JC</given-names></name><name name-style="western"><surname>McCarthy</surname><given-names>G</given-names></name></person-group>             <year>1998</year>             <article-title>Temporal Cortex Activation in Humans Viewing Eye and Mouth Movements.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>2188</fpage>             <lpage>2199</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Carter1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Carter</surname><given-names>EJ</given-names></name><name name-style="western"><surname>Hodgins</surname><given-names>JK</given-names></name><name name-style="western"><surname>Rakison</surname><given-names>DH</given-names></name></person-group>             <year>2011</year>             <article-title>Exploring the neural correlates of goal-directed action and intention understanding.</article-title>             <source>Neuroimage</source>             <volume>15; 54</volume>             <issue>2</issue>             <fpage>1634</fpage>             <lpage>1642</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pelphrey2">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pelphrey</surname><given-names>KA</given-names></name><name name-style="western"><surname>Morris</surname><given-names>JP</given-names></name><name name-style="western"><surname>e</surname><given-names>al</given-names></name></person-group>             <year>2004</year>             <article-title>Grasping the Intentions of Others: The Perceived Intentionality of an Action Influences Activity in the Superior Temporal Sulcus during Social Perception.</article-title>             <source>Journal of Cognitive Neuroscience</source>             <volume>16</volume>             <fpage>1706</fpage>             <lpage>1716</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Grzes1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grèzes</surname><given-names>J</given-names></name><name name-style="western"><surname>Decety</surname><given-names>J</given-names></name></person-group>             <year>2001</year>             <article-title>Functional anatomy of execution, mental simulation, observation, and verb generation of actions: A meta-analysis.</article-title>             <source>Human Brain Mapping</source>             <volume>12</volume>             <fpage>1</fpage>             <lpage>19</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Pineda1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pineda</surname><given-names>JA</given-names></name></person-group>             <year>2008</year>             <article-title>Sensorimotor cortex as a critical component of an 'extended' mirror neuron system: Does it solve the development, correspondence, and control problems in mirroring?</article-title>             <source>Behav Brain Funct </source>             <volume>18</volume>             <fpage>4:47</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Schubotz1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schubotz</surname><given-names>RI</given-names></name><name name-style="western"><surname>von Cramon</surname><given-names>DY</given-names></name></person-group>             <year>2004</year>             <article-title>Sequences of Abstract Nonbiological Stimuli Share Ventral Premotor Cortex with Action Observation and Imagery.</article-title>             <source>J Neurosci</source>             <volume>24</volume>             <fpage>5467</fpage>             <lpage>5474</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Hamilton1">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hamilton</surname><given-names>AFdC</given-names></name><name name-style="western"><surname>Grafton</surname><given-names>ST</given-names></name></person-group>             <year>2006</year>             <article-title>Goal Representation in Human Anterior Intraparietal Sulcus.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>1133</fpage>             <lpage>1137</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Hari1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hari</surname><given-names>R</given-names></name><name name-style="western"><surname>Hänninen</surname><given-names>R</given-names></name><name name-style="western"><surname>Mäkinen</surname><given-names>T</given-names></name><name name-style="western"><surname>Jousmäki</surname><given-names>V</given-names></name><name name-style="western"><surname>Forss</surname><given-names>N</given-names></name><etal/></person-group>             <year>1998</year>             <article-title>Three hands: fragmentation of human bodily awareness.</article-title>             <source>Neuroscience Letters</source>             <volume>240</volume>             <fpage>131</fpage>             <lpage>134</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Fecteau1">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fecteau</surname><given-names>S</given-names></name><name name-style="western"><surname>Carmant</surname><given-names>L</given-names></name><name name-style="western"><surname>Tremblay</surname><given-names>C</given-names></name><name name-style="western"><surname>Robert</surname><given-names>M</given-names></name><name name-style="western"><surname>Bouthillier</surname><given-names>A</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>A motor resonance mechanism in children? Evidence from subdural electrodes in a 36-month-old child.</article-title>             <source>Neuroreport</source>             <volume>15</volume>             <issue>17</issue>             <fpage>2625</fpage>             <lpage>2627</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Rizzolatti2">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name><name name-style="western"><surname>Craighero</surname><given-names>L</given-names></name></person-group>             <year>2004</year>             <article-title>The mirror-neuron system.</article-title>             <source>Annual Review of Neuroscience</source>             <volume>27</volume>             <fpage>169</fpage>             <lpage>192</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Buccino1">
        <label>67</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Buccino</surname><given-names>G</given-names></name><name name-style="western"><surname>Binkofski</surname><given-names>F</given-names></name><name name-style="western"><surname>Fink</surname><given-names>G</given-names></name><name name-style="western"><surname>Fadiga</surname><given-names>L</given-names></name><name name-style="western"><surname>Fogassi</surname><given-names>L</given-names></name><etal/></person-group>             <year>2001</year>             <article-title>Action observation activates premotor and parietal areas in a somatotopic manner: An fMRI study.</article-title>             <source>Eur J Neurosci</source>             <volume>13</volume>             <issue>2</issue>             <fpage>400</fpage>             <lpage>404</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-MolnarSzakacs1">
        <label>68</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name><name name-style="western"><surname>Kaplan</surname><given-names>J</given-names></name><name name-style="western"><surname>Greenfield</surname><given-names>PM</given-names></name><name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name></person-group>             <year>2006</year>             <article-title>Observing complex action sequences: The role of the fronto-parietal mirror neuron system.</article-title>             <source>NeuroImage</source>             <volume>33</volume>             <fpage>923</fpage>             <lpage>935</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Decety1">
        <label>69</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Decety</surname><given-names>J</given-names></name><name name-style="western"><surname>Perani</surname><given-names>D</given-names></name><name name-style="western"><surname>Jeannerod</surname><given-names>M</given-names></name><name name-style="western"><surname>Bettinardi</surname><given-names>V</given-names></name><name name-style="western"><surname>Tadary</surname><given-names>B</given-names></name><etal/></person-group>             <year>1994</year>             <article-title>Mapping motor representations with positron emission tomography.</article-title>             <source>Nature</source>             <volume>371</volume>             <fpage>600</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Iacoboni2">
        <label>70</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name><name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name><name name-style="western"><surname>Gallese</surname><given-names>V</given-names></name><name name-style="western"><surname>Buccino</surname><given-names>G</given-names></name><name name-style="western"><surname>Mazziotta</surname><given-names>JC</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Grasping the intentions of others with one's own mirror neuron system.</article-title>             <source>PLOS Biology</source>             <volume>3</volume>             <fpage>1</fpage>             <lpage>7</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Cappa1">
        <label>71</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cappa</surname><given-names>S</given-names></name><name name-style="western"><surname>Canessa</surname><given-names>N</given-names></name><name name-style="western"><surname>Alemanno</surname><given-names>F</given-names></name><name name-style="western"><surname>Riva</surname><given-names>F</given-names></name><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><etal/></person-group>             <article-title>(submitted) I see what you people are doing: neural correlates of the automatic visual encoding of social interactions</article-title>          </element-citation>
      </ref>
      <ref id="pone.0022026-Buccino2">
        <label>72</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Buccino</surname><given-names>G</given-names></name><name name-style="western"><surname>Vogt</surname><given-names>S</given-names></name><name name-style="western"><surname>Ritzl</surname><given-names>A</given-names></name><name name-style="western"><surname>Fink</surname><given-names>GR</given-names></name><name name-style="western"><surname>Zilles</surname><given-names>K</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Neural Circuits Underlying Imitation Learning of Hand Actions: An Event-Related fMRI Study.</article-title>             <source>Neuron</source>             <volume>42</volume>             <fpage>323</fpage>             <lpage>334</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Hamilton2">
        <label>73</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hamilton</surname><given-names>AF</given-names></name><name name-style="western"><surname>Grafton</surname><given-names>ST</given-names></name></person-group>             <year>2008</year>             <article-title>Action Outcomes Are Represented in Human Inferior Frontoparietal Cortex.</article-title>             <source>Cereb Cortex</source>             <volume>18</volume>             <fpage>160</fpage>             <lpage>1168</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-BaronCohen2">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baron-Cohen</surname><given-names>S</given-names></name><name name-style="western"><surname>Knickmeyer</surname><given-names>RC</given-names></name><name name-style="western"><surname>Belmonte</surname><given-names>MK</given-names></name></person-group>             <year>2005</year>             <article-title>Sex Differences in the Brain: Implications for Explaining Autism.</article-title>             <source>Science</source>             <volume>310</volume>             <fpage>819</fpage>             <lpage>823</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Singer1">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Singer</surname><given-names>T</given-names></name><name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name><name name-style="western"><surname>Klaas</surname><given-names>E</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>S</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Empathic neural responses are modulated by the perceived fairness of others.</article-title>             <source>Nature</source>             <volume>439</volume>             <fpage>466</fpage>             <lpage>4469</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-SchulteRuther1">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schulte-Ruther</surname><given-names>M</given-names></name><name name-style="western"><surname>Markowitsch</surname><given-names>HJ</given-names></name><name name-style="western"><surname>Fink</surname><given-names>GR</given-names></name><name name-style="western"><surname>Piefke</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>Mirror neuron and theory of mind mechanisms involved in face-to-face interactions: a functional magnetic resonance imaging approach to empathy.</article-title>             <source>J Cogn Neurosci</source>             <volume>19</volume>             <fpage>1354</fpage>             <lpage>1372</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Kaplan1">
        <label>77</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaplan</surname><given-names>JT</given-names></name><name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name></person-group>             <year>2006</year>             <article-title>Getting a grip on other minds: Mirror neurons, intention understanding, and cognitive empathy.</article-title>             <source>Social Neuroscience</source>             <volume>1</volume>             <fpage>175</fpage>             <lpage>183</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Kovalev1">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kovalev</surname><given-names>VA</given-names></name><name name-style="western"><surname>Kruggel</surname><given-names>F</given-names></name><name name-style="western"><surname>von Cramon</surname><given-names>DY</given-names></name></person-group>             <year>2003</year>             <article-title>Gender and age effects in structural brain asymmetry as measured by MRI texture analysis.</article-title>             <source>NeuroImage</source>             <volume>19</volume>             <fpage>895</fpage>             <lpage>905</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Kemp1">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kemp</surname><given-names>AH</given-names></name><name name-style="western"><surname>Silberstein</surname><given-names>RB</given-names></name><name name-style="western"><surname>Armstrong</surname><given-names>SM</given-names></name><name name-style="western"><surname>Nathan</surname><given-names>PJ</given-names></name></person-group>             <year>2004</year>             <article-title>Gender differences in the cortical electrophysiological processing of visual emotional stimuli.</article-title>             <source>NeuroImag </source>             <volume>21</volume>             <fpage>632</fpage>             <lpage>646</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Schneider1">
        <label>80</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schneider</surname><given-names>F</given-names></name><name name-style="western"><surname>Habel</surname><given-names>U</given-names></name><name name-style="western"><surname>Kessler</surname><given-names>C</given-names></name><name name-style="western"><surname>Salloum</surname><given-names>JB</given-names></name><name name-style="western"><surname>Posse</surname><given-names>S</given-names></name></person-group>             <year>2000</year>             <article-title>Gender differences in regional cerebral activity during sadness.</article-title>             <source>Human Brain Mapping</source>             <volume>9</volume>             <fpage>226</fpage>             <lpage>238</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Shaywitz1">
        <label>81</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shaywitz</surname><given-names>BA</given-names></name><name name-style="western"><surname>Shaywltz</surname><given-names>SE</given-names></name><name name-style="western"><surname>Pugh</surname><given-names>KR</given-names></name><name name-style="western"><surname>Constable</surname><given-names>RT</given-names></name><name name-style="western"><surname>Skudlarski</surname><given-names>P</given-names></name><etal/></person-group>             <year>1995</year>             <article-title>Sex differences in the functional organization of the brain for language.</article-title>             <source>Nature</source>             <volume>373</volume>             <issue>6515</issue>             <fpage>607</fpage>             <lpage>609</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Rilea1">
        <label>82</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rilea</surname><given-names>SL</given-names></name><name name-style="western"><surname>Roskos-Ewoldsen</surname><given-names>B</given-names></name><name name-style="western"><surname>Boles</surname><given-names>D</given-names></name></person-group>             <year>2004</year>             <article-title>Sex differences in spatial ability: A lateralization of function approach.</article-title>             <source>Brain and Cognition</source>             <volume>56</volume>             <fpage>332</fpage>             <lpage>343</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Johnson1">
        <label>83</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>BWCA</given-names></name><name name-style="western"><surname>McKenzie</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Hamm</surname><given-names>JP</given-names></name></person-group>             <year>2002</year>             <article-title>Cerebral asymmetry for mental rotation: effects of response hand, handedness and gender.</article-title>             <source>Neuroreport</source>             <volume>13</volume>             <fpage>1929</fpage>             <lpage>1932</lpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio6">
        <label>84</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Riva</surname><given-names>F</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name></person-group>             <year>2009</year>             <article-title>Observation of Static Pictures of Dynamic Actions Enhances the Activity of Movement-Related Brain Areas.</article-title>             <source>PLoS ONE</source>             <volume>4</volume>             <fpage>e5389</fpage>          </element-citation>
      </ref>
      <ref id="pone.0022026-Proverbio7">
        <label>85</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name><name name-style="western"><surname>Zani</surname><given-names>A</given-names></name><name name-style="western"><surname>Adorni</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>Neural markers of a greater female responsiveness to social stimuli.</article-title>             <source>BMC Neurosci</source>             <volume>30</volume>             <issue>9</issue>             <fpage>56</fpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>