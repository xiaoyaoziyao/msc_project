<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="pmc">plosone</journal-id>
      <journal-title-group>
        <journal-title>PLoS ONE</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1932-6203</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PONE-D-12-25693</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pone.0049451</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
              <subj-group>
                <subject>Cognition</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Neuroimaging</subject>
              <subj-group>
                <subject>fMRI</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Visual system</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Neuroanatomy</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Medicine</subject>
          <subj-group>
            <subject>Neurology</subject>
            <subj-group>
              <subject>Neuroimaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
          <subject>Neurological Disorders</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A Brain Network Processing the Age of Faces</article-title>
        <alt-title alt-title-type="running-head">A Brain Network Processing the Age of Faces</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Homola</surname>
            <given-names>György A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Jbabdi</surname>
            <given-names>Saad</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Beckmann</surname>
            <given-names>Christian F.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bartsch</surname>
            <given-names>Andreas J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Department of Neuroradiology, University of Würzburg, Würzburg, Germany</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Centre for Functional MRI of the Brain, University of Oxford, Oxford, United Kingdom</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Donders Institute for Brain, Cognition and Behaviour, Radboud University of Nijmegen and MIRA Institute, University of Twente, Nijmegen, The Netherlands</addr-line>
      </aff>
      <aff id="aff4">
        <label>4</label>
        <addr-line>Department of Neuroradiology, University of Heidelberg, Heidelberg, Germany</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Zuo</surname>
            <given-names>Xi-Nian</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>Institute of Psychology, Chinese Academy of Sciences, China</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">homola@neuroradiologie.uni-wuerzburg.de</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: GAH AJB. Performed the experiments: GAH AJB. Analyzed the data: GAH AJB SJ CFB. Contributed reagents/materials/analysis tools: SJ. Wrote the paper: GAH AJB SJ CFB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <year>2012</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>20</day>
        <month>11</month>
        <year>2012</year>
      </pub-date>
      <volume>7</volume>
      <issue>11</issue>
      <elocation-id>e49451</elocation-id>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>8</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>8</day>
          <month>10</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2012</copyright-year>
        <copyright-holder>Homola et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Age is one of the most salient aspects in faces and of fundamental cognitive and social relevance. Although face processing has been studied extensively, brain regions responsive to age have yet to be localized. Using evocative face morphs and fMRI, we segregate two areas extending beyond the previously established face-sensitive core network, centered on the inferior temporal sulci and angular gyri bilaterally, both of which process changes of facial age. By means of probabilistic tractography, we compare their patterns of functional activation and structural connectivity. The ventral portion of Wernicke's understudied perpendicular association fasciculus is shown to interconnect the two areas, and activation within these clusters is related to the probability of fiber connectivity between them. In addition, post-hoc age-rating competence is found to be associated with high response magnitudes in the left angular gyrus. Our results provide the first evidence that facial age has a distinct representation pattern in the posterior human brain. We propose that particular face-sensitive nodes interact with additional object-unselective quantification modules to obtain individual estimates of facial age. This brain network processing the age of faces differs from the cortical areas that have previously been linked to less developmental but instantly changeable face aspects. Our probabilistic method of associating activations with connectivity patterns reveals an exemplary link that can be used to further study, assess and quantify structure-function relationships.</p>
      </abstract>
      <funding-group>
        <funding-statement>This work was supported by the UK Medical Research Council (G0800578) and the German Doppelfeld Foundation (2008–2011), with its publishing being funded by the German Research Foundation (DFG) and the University of Würzburg (Open Access Publishing funding program). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="14"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Processing the age of faces is a crucial cognitive skill. Facial age varies but not in a volatile manner like eye gaze, lip movements or facial expressions. Contrary to other fixed and variant cues <xref ref-type="bibr" rid="pone.0049451-Haxby1">[1]</xref>, the cognitive basis of facial age processing has not yet been investigated by any dedicated neuroimaging experiment. Facial age is depicted by complex features and configurations such as skin texture and distance from average head shape <xref ref-type="bibr" rid="pone.0049451-OToole1">[2]</xref>. Localizing a brain network involved with age processing will allow us to determine whether it is primarily up to face-sensitive areas to combine low-level cues into a coherent age percept, whether this is formed by a different system altogether, or whether two or more systems interact with each other. Additionally, facial age processing may also be relevant and applicable to other networks that compute effects of magnitude and passage of time.</p>
      <p>Developmentally, age is less salient in faces than gender and ethnicity <xref ref-type="bibr" rid="pone.0049451-McGraw1">[3]</xref>. In order to augment its processing, we utilize face morphs which provide useful modulations of the age parameter: Attracting visual attention to the optical flow of such changes can be expected to enhance neural responses to every attribute of the morphed object <xref ref-type="bibr" rid="pone.0049451-OCraven1">[4]</xref>, and average response levels measured in virtually all face-selective regions tend to be higher for moving than for static face stimuli <xref ref-type="bibr" rid="pone.0049451-Fox1">[5]</xref>–<xref ref-type="bibr" rid="pone.0049451-Pitcher1">[7]</xref>. Morphing is also suited to minimize adaptation while animations facilitate implicit processing without particular cognitive efforts, and video probes in general are increasingly adopted for stimulation in neuroimaging experiments <xref ref-type="bibr" rid="pone.0049451-Fox1">[5]</xref>, <xref ref-type="bibr" rid="pone.0049451-Pitcher1">[7]</xref>–<xref ref-type="bibr" rid="pone.0049451-Saygin1">[16]</xref>. Static images from graded morph transitions have already been used as a powerful tool to investigate visual processing of faces and non-face objects <xref ref-type="bibr" rid="pone.0049451-Kircher1">[17]</xref>–<xref ref-type="bibr" rid="pone.0049451-Jiang2">[27]</xref> but age has either not been varied or controlled.</p>
      <p>Here, we generate continuous morphs that introduce independent age and gender changes of face stimuli. These changes are virtual but based on a fully morphable 3D model, similar to <xref ref-type="bibr" rid="pone.0049451-Leopold1">[18]</xref>, <xref ref-type="bibr" rid="pone.0049451-Blanz1">[28]</xref>, and therefore constrained to appear smooth and realistic (<xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref>, Movie S1). Processing of facial age is compared with gender - instead of identity, attractiveness, or other changeable face aspects - for the following reasons: Gender differentiation normally changes with age and involves changes of similar complexity like aging <xref ref-type="bibr" rid="pone.0049451-Ramanathan1">[29]</xref>. By contrast, identity recognition is, within limits, age-invariant <xref ref-type="bibr" rid="pone.0049451-George1">[30]</xref>. Furthermore, judgments of age and gender need not be affected in prosopagnosia <xref ref-type="bibr" rid="pone.0049451-Tranel1">[31]</xref>–<xref ref-type="bibr" rid="pone.0049451-DeRenzi1">[33]</xref> but cases selectively agnostic for age while preserving gender recognition have not yet been reported. Given that categorical gender varies across androgyny levels <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, both gender as well as age of a face are quantifiable but not instantly changeable. Based on the cognitive models of face processing proposed by Bruce and Young <xref ref-type="bibr" rid="pone.0049451-Bruce1">[34]</xref> and Ellis <xref ref-type="bibr" rid="pone.0049451-Ellis1">[35]</xref>–<xref ref-type="bibr" rid="pone.0049451-Ellis3">[37]</xref>, face gender and age have both been conceptualized as ‘visually-directed semantic codes’ <xref ref-type="bibr" rid="pone.0049451-Bruyer1">[38]</xref> and their processing is here compared to each other.</p>
      <fig id="pone-0049451-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Continuous face morphing, optical flow and associated functional activations.</title>
          <p>(A) Exemplary keyframes of a video sequence (see Movie S1) morphing a 20 year-old female into a 60 year-old male. Both gradual age and gender changes are illustrated at intervals of 1 second. (B) Line magnitude images of optical flow velocities computed by the Horn-Schunck algorithm. Differential motion/optical flow was quantified as an overall parameter by the sum of flow magnitudes between successive keyframes. (C) Motion-/flow-related activations of hMT+ derived from the group-level analyses (n = 24 subjects, FWER-corrected p&lt;0.05, [−log10 (p)] colorbar) on posterior cortical flat maps of both hemispheres. Additionally, ventral (v) and dorsal (d) visuotopic labels (V1–8, Vp, LO, hMT+) of the SuMS database, transformed from Caret's PALS atlas into FreeSurfer's average surface space, are displayed. Note that according to recent data <xref ref-type="bibr" rid="pone.0049451-Wandell1">[112]</xref>, V4v and V8 are labeled together as hV4 while VP has been labeled V3v.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>We use functional (fMRI) and diffusion-weighted (DWI) magnetic resonance imaging to investigate the following: <italic>(</italic><bold><italic>i)</italic></bold> Do facial age and gender transitions engage distinct functional networks? <italic>(</italic><bold><italic>ii)</italic></bold> Which of the age-responsive areas are associated with high age-rating competence? <bold><italic>(iii)</italic></bold> Is the pattern of functional activation within age-responsive areas related to their connectivity? Using spatial cross-correlations between probability profiles of activation and fiber connectivity, we assess the impact of structural connections on activation patterns. Thereby, we seek to substantiate which fiber pathways transmit age-relevant information of faces. According to our results facial age processing involves distinct brain areas, connected by vertical association pathways. We suggest that face-sensitive regions may interact with quantification modules when age (but not androgyny) is varied across faces.</p>
    </sec>
    <sec id="s2" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s2a">
        <title>Participants</title>
        <p>We obtained blood oxygenation level dependent (BOLD) fMRI and DWI scans of 24 healthy, right-handed, white Caucasian volunteers (age range 23 to 34, mean age 26, standard deviation 3 years; 12 females), who all gave written informed consent. The Ethics Committee of the University of Würzburg (Faculty of Medicine) approved the study. Handedness was assessed by a variant of the Edinburgh Handedness Inventory <xref ref-type="bibr" rid="pone.0049451-Oldfield1">[39]</xref>, expanded by one eye and foot preference item <xref ref-type="bibr" rid="pone.0049451-Teng1">[40]</xref>. Females were scanned between days 5 to 15 of the menstrual cycle, not taking oral contraceptives.</p>
        <p>For validation of the tractography results, diffusion-weighted imaging (DWI) data of additional 46 right-handed healthy volunteers (age range 19 to 63, mean age 30, standard deviation 9 years; 25 females) from the database of the Oxford Centre for Functional MRI of the Brain (FMRIB) were analyzed.</p>
      </sec>
      <sec id="s2b">
        <title>Experimental paradigm</title>
        <p>Full-front photographs of 121 unfamiliar, unambiguously gendered faces of white Caucasians (age range 2 to 81, mean age 33, standard deviation 15 years; 60 females age-matched to the males; all free of any make-up and beardless, with eye gaze directed at the viewer, wearing no jewellery or piercings, without tattoos; rated as neutral in their expression on a 6-point visual analogue scale by all participants) were matched by a computerized algorithm <xref ref-type="bibr" rid="pone.0049451-Leopold1">[18]</xref>, <xref ref-type="bibr" rid="pone.0049451-Blanz1">[28]</xref> to a morphable 3D model consisting of a surface mesh of editable polygons and texture materials using FaceGen Modeller v3.1 (2004, Singular Inversions Inc., Toronto, <ext-link ext-link-type="uri" xlink:href="http://www.facegen.com/" xlink:type="simple">http://www.facegen.com/</ext-link>) and 3 ds Max 8 (2005, Autodesk Inc., San Rafael, <ext-link ext-link-type="uri" xlink:href="http://www.autodesk.com/" xlink:type="simple">http://www.autodesk.com/</ext-link>). From these models, 120 face morphs were rendered. Half of them contained gender transitions. The mean age difference between start and target face of the 120 morphs was 14.8±11.7 years, ranging from 0 to 46.7 years. Since all face stimuli were generated from a fully morphable 3D model <xref ref-type="bibr" rid="pone.0049451-Leopold1">[18]</xref>, <xref ref-type="bibr" rid="pone.0049451-Blanz1">[28]</xref>, virtual faces between the start and target images appear realistic (see <xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref>, Movie S1), avoiding grotesque or bizarre distortions for intermediate morphing steps. Face stimuli were presented as shown in <xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref>. The two subjects selected have given written informed consent (as outlined in the PLoS consent form) to publication of the portrayals derived from their photographs.</p>
        <p>Morphing transitions between two faces lasted 6 seconds (see Movie S1), with an additional 1-second still in-between. Face morphs with and without gender transitions (n = 60 each) were arranged in random order, with all morphs across gender proceeding from full-male/-female to the opposite.</p>
        <p>Facial age of start and target stimuli was continuously modulated, except for the one-second stills, with varying degrees and age changes being pseudo-randomized according to 10-year intervals. Age changes during morphing were independent of (i.e. orthogonal to) the transitions of gender (Pearson's normalized correlation between the modelled regressors: r = 0.046, p = 0.39) and the psychometric ratings of attractiveness/likeability, which was not significantly modulated (i.e. did not exceed one rating-point difference for all start/target image pairs on a 6-point visual analogue scale). Thereby, morphing eliminates the need for an explicit baseline but nevertheless allows us to separate the effects of age and gender.</p>
        <p>Psychophysical changes of age and gender were parametrically modeled according to Steven's power law (cf. <xref ref-type="fig" rid="pone-0049451-g002">Figures 2</xref> and <xref ref-type="fig" rid="pone-0049451-g003">3</xref>). Differential motion/optical flow <xref ref-type="bibr" rid="pone.0049451-Bartels1">[9]</xref> was controlled for and integrated as a global nuisance variable (<xref ref-type="fig" rid="pone-0049451-g001">Figure 1B,C</xref>). Our experimental paradigm simultaneously engaged configural and textural processing, both known to be involved in categorical face processing <xref ref-type="bibr" rid="pone.0049451-Yovel1">[41]</xref>.</p>
        <fig id="pone-0049451-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Psychometrics of facial age and gender changes.</title>
            <p>(A) Facial age difference ratings (magnitude of age-gradients spanned by morphing rated on a 6-point visual analogue scale, maximum scaled to 3.0 arbitrary units [a.u.]) followed Stevens' (∧0.3) better than Weber-Fechner's law (log10) or a natural logarithmic transformation (ln) of start and target age. All face stimuli (n = 121) were morphed to an average-aged male face of 33 years, the morphing sequence was randomly played forwards or backwards for the rating (circles with error bars; n = 24 subjects). (B) Facial aging (x-axis; objective age in [years]) increased the variability of subjective age ratings (y-axis; SD, standard deviation of estimated age in [years] across n = 24 subjects). Rating accuracy of factual (n = 121 stimuli of real faces) and interpolated age (n = 80 intermediate face stimuli from the morphing algorithm; one randomly selected for each annual increment between 2 and 81 years of age) did not differ significantly (p = 0.97). (C) Face gender ratings (on a 6-point visual analogue scale, maximum scaled to 1.0 arbitrary units [a.u.]) along temporal morph continua (n = 60) across faces of clearly different sex. Subjective ratings by (n = 24) subjects (boxes with error bars, blue line) were augmented above linear transition values (dashed line with black dots), reflecting the tendency to apperceptive gender categorization.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g002" position="float" xlink:type="simple"/>
        </fig>
        <fig id="pone-0049451-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Modeling changes of age and gender during face morphing.</title>
            <p>Both were time-binned at the video frame rate (24 fps) and scaled to maxima of 1.0 arbitrary units [a.u.]. (A) Differential age change encoded according to Stevens' law of psychophysics (using a power exponent of 0.3; <xref ref-type="fig" rid="pone-0049451-g002">Figure 2A</xref>). Note that relative facial aging was up-weighted to initial periods of the example morph (also see <xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref>; here: solid red line) and, for identical age differences, to younger absolute ages, i.e. aging from 10 to 26 was assumed to provide a stronger stimulus with more visual cues than aging from 64 to 80 years (dashed vs. double-dotted/dashed line). (B) Differential gender change expressed by the first derivative of the function plotted in <xref ref-type="fig" rid="pone-0049451-g002">Figure 2C</xref>. Note that peak androgyny was defined as the effective stimulus-of-interest, i.e. the transition of facial gender was emphasized at the center of the morph (see also <xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref> and Movie S1). Half of the morphs contained no gender transitions, retaining a flat line at zero level to indicate the lack of gender change (dashed line).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g003" position="float" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2c">
        <title>Paradigm presentation</title>
        <p>The morphing video was presented at 24 frames per second (fps) using a fMRI-compatible LCD screen, scaled to the maximum resolution of the presentation equipment (640×480 pixels VGA). The paradigm contained the entire set of 120 face morphs between different pairs of start and target faces, separated by 1-second stills, and was presented to the subjects in a single run lasting 14 minutes. Thus, the inter-stimulus interval (ISI) between the offset of a 6-seconds morph and the onset of the next was 1 second, resulting in a stimulus onset asynchrony (SOA) or inter-trial interval (ITI) of 7 seconds with no stimulus repetitions. In order to sustain attention and to monitor compliance, subjects were instructed to press a key with their right index finger whenever the target face appearance of the morphing sequence was anticipated. Speed and accuracy were not emphasized. The explicit task was of no particular interest and only ensured that the participants attended to the paradigm. The associated activations are not reported because they are contaminated by co-activations of executive and motor functioning from key pressing. While watching the face morph of Movie S1, for example, the subject realizes that a young female is changed into an older male, and the characteristics of the target face can be anticipated before it finally appears. This may coincide with the detection of a subjective identity transition although identity virtually changes continuously in a slow but permanent manner during all morphing episodes. Note that age and gender changes were continuously modeled over the entire morphing period while subjects generally pressed the key once in anticipation of the target face, i.e. explicit task performance was sufficiently independent of implicit age and gender processing as we have modeled it. Key-press responses were recorded by a fMRI-compatible keyboard and logged by Cogent 2000 v125 (2003, Wellcome Laboratory of Neurobiology, London, <ext-link ext-link-type="uri" xlink:href="http://www.vislab.ucl.ac.uk/" xlink:type="simple">http://www.vislab.ucl.ac.uk/</ext-link>)., Global display luminance was controlled, and constant color channel ratios were maintained. Temporal synchronization between video presentation and scanning was achieved by triggering the start of each fMRI volume externally at a minimum precision of 50 µs using MATLAB R2007a (2007, The MathWorks Inc., Natick, <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/" xlink:type="simple">http://www.mathworks.com/</ext-link>).</p>
      </sec>
      <sec id="s2d">
        <title>MRI and behavioral data acquisition</title>
        <p>We acquired fMRI time-series and T1-weighted anatomical images of the (n = 24) healthy volunteers in one session, and whole-brain DWI data and explicit behavioral post-hoc ratings of the same set of subjects in a second session within two weeks. In order to assess the relation between fMRI activations and age rating competence at the second level, age-rating performance was used to discriminate most accurate (n = 5) from average (n = 14) age-raters.</p>
        <p>Functional and T1-weighted structural MRI data were acquired on a 3 Tesla TimTrio scanner (Siemens, Erlangen, Germany) using a 12-channel head coil. Whole-brain T2*-weighted BOLD images were recorded by a single-shot 2D gradient-echo EPI sequence with interleaved slice acquisition (TR = 2400 ms, TE = 30 ms, resolution 3×3×4 mm<sup>3</sup>, including 25% interslice gap, 30 sagittal slices of 3.2 mm thickness). After discarding the four initial scans, 350 volumes acquired during visual paradigm presentation were analyzed. In order to unwarp geometric distortions of BOLD EPIs, we used gradient-echo fieldmaps (TR = 500 ms, TE1 = 4.30 ms, ΔTE1/2 = 2.46 ms). In addition, a T1-weighted 3D anatomical image using a MPRAGE sequence (TR = 1560 ms, TE = 2.26 ms, resolution 1×1×1 mm<sup>3</sup>) optimized for segmentation and surface reconstructions and, for basic screening, a T2-weighted 2D axial FLAIR sequence were acquired.</p>
        <p>In order to avoid potential DWI signal-loss artefacts <xref ref-type="bibr" rid="pone.0049451-Gallichan1">[42]</xref>, we recorded whole-brain diffusion-weighted EPI volumes (60 diffusion directions isotropically distributed on a sphere at b = 1000 s/mm<sup>2</sup>, TR = 9000 ms, TE = 97 ms, resolution 2×2×2.5 mm<sup>3</sup>, including 20% interslice gap, 60 axial slices) and five volumes without diffusion weighting on a 1.5 Tesla Quantum Vision scanner (Siemens, Erlangen, Germany). For unwarping their geometric distortions, gradient-echo fieldmaps matching the DWI protocol were used (TR = 325 ms, TE1 = 4.30 ms, ΔTE1/2 = 4.76 ms).</p>
        <p>DWI data of the independent database were acquired on a 1.5 Tesla Sonata scanner (Siemens, Erlangen, Germany) with similar sequence parameters at slightly lower slice thickness (resolution2×2×2 mm<sup>3</sup>, 72 axial slices). Three sets of DWI data were recorded for subsequent averaging to improve the signal-to-noise ratio (total scan time 45 minutes).</p>
      </sec>
      <sec id="s2e">
        <title>Preprocessing and statistical analysis</title>
        <p>All MRI data were processed using FSL 4.1 (<ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl/" xlink:type="simple">http://www.fmrib.ox.ac.uk/fsl/</ext-link>; <xref ref-type="bibr" rid="pone.0049451-Smith1">[43]</xref>, <xref ref-type="bibr" rid="pone.0049451-Woolrich1">[44]</xref>) and FreeSurfer v4.5.0 (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/" xlink:type="simple">http://surfer.nmr.mgh.harvard.edu/</ext-link> <xref ref-type="bibr" rid="pone.0049451-Dale1">[45]</xref>, <xref ref-type="bibr" rid="pone.0049451-Fischl1">[46]</xref>). First-level fMRI and DWI data were motion- and eddy current-corrected (using MCFLIRT <xref ref-type="bibr" rid="pone.0049451-Jenkinson1">[47]</xref> and eddy_correct, respectively), unwarped (using PRELUDE/FUGUE) and brain-extracted (using BET <xref ref-type="bibr" rid="pone.0049451-Smith2">[48]</xref>; all part of FSL). First-level fMRI analysis was carried out by applying the General Linear Model (GLM) within FEAT using FILM prewhitening <xref ref-type="bibr" rid="pone.0049451-Woolrich2">[49]</xref>, with motion outliers (detected by fsl_motion_outliers) being added as confound regressors. High-pass temporal filtering of the data and the model was set to 100 secs based on the power spectra of the design matrices (estimated by cutoffcalc; all part of FSL). Three main explanatory variables were modeled and controlled: Optical flow, age and gender change. Parametric intensity modulation of their graded stimulus strength is described below, linear modeling of age and gender changes did not explain a significant amount of variance on top of this. Button press responses to anticipated target face appearance were also modeled but of no further interest. In order to capture slight deviations from the model, temporal derivatives of all explanatory variables convolved with FEAT's gamma hemodynamic response function (HRF) were included.</p>
        <p>In order to take advantage of surface-based registrations and statistical analyses, FreeSurfer was used for segmentation and surface reconstructions of the structural T1-weighted MRIs. Employing boundary-based registration (using bbregister, part of FreeSurfer, <xref ref-type="bibr" rid="pone.0049451-Greve1">[50]</xref>), robust and accurate within-subject cross-modal alignment of functional and anatomical space was achieved. Concatenating this transformation with the surface-based registration to FreeSurfer's spherical average <xref ref-type="bibr" rid="pone.0049451-Fischl2">[51]</xref>, FEAT's first-level contrast-of-parameter estimates (COPEs) and their variance estimates (VARCOPEs) were resampled to the common fsaverage surface. Surface-based spatial smoothing of 5 mm FWHM was applied. At the group level, a mixed-effects (ME) GLM analysis <xref ref-type="bibr" rid="pone.0049451-Beckmann1">[52]</xref> was performed (using mri_glmfit, part of FreeSurfer) identifying vertices in which brain activity was correlated with age, gender and optical flow processing. Second-level thresholding was performed by non-parametric permutation-based cluster mass inference <xref ref-type="bibr" rid="pone.0049451-Nichols1">[53]</xref>–<xref ref-type="bibr" rid="pone.0049451-Hagler1">[57]</xref> and included within-contrast correction for multiple comparisons across all vertices of the fsaverage surface. Across the contrasts tested, Bonferroni's correction was applied which further enforced rigorous protection from false-positive detections. Interactions between the main explanatory variables of interest (age and gender change, optical flow) were modeled at the first and assessed at the second level. The volunteers' gender was explicitly modeled at the second level to test for differences between the sexes. Only results with family-wise error rate (FWER) corrected p-values&lt;0.05 are reported, coordinates are given in MNI standard space.</p>
        <p>Relative response magnitudes were quantified based on individual mean within-cluster contrast-of-parameter estimates (COPEs) normalized to the respective minimum, see <xref ref-type="fig" rid="pone-0049451-g004">Figure 4B,D</xref>. Scaled to the peak-to-peak height of the effective regressor and divided by the mean-over-time of the preprocessed (i.e. filtered) EPI time-series from lower-level GLM analyses, mean COPE values are equivalent to mean percentage BOLD signal changes and characterize the observed effect sizes. Given constant scaling for a particular contrast fitted, normalized COPE values translate directly into estimated ratios of the associated signal changes within (but not across) specific contrasts. First-level COPEs from each cluster were tested for hemisphere and sex effects (n = 24; ANOVA, factorial within-/across-subjects design).</p>
        <fig id="pone-0049451-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Functional activations associated with changes of facial age and gender.</title>
            <p>(A) Group-level (n = 24) functional activations<sup>1</sup> related to age and gender change, respectively. (B) Quantification and between-cluster/-hemisphere comparisons of observed effect sizes evoked by facial age and gender changes across (n = 24) subjects. Individual values of each cluster's mean activation (± error bars across subjects) were normalized to the lowest average of corresponding response magnitudes (as extracted from the first-level analyses). (C) Increased age-related activations<sup>1</sup> of the most accurate (n = 5) above average age-raters (n = 14). The corresponding cortical flat map is outlined by the borders of the left age-responsive pANG cluster. (D) Relative to average post-hoc raters (avg, n = 14), high explicit age-rating accuracy (upper quintile P80, n = 5) was accompanied by almost five times the response magnitude during implicit age-change processing within left pANG (p&lt;0.001, based on mean individual activation levels of the sub-cluster shown in <xref ref-type="fig" rid="pone-0049451-g004">Figure 4C</xref>, as back-projected to native subject space). Activations of lower quintile raters (P20, n = 5) were more variable but not statistically different from the average (P20–80). <sup>1</sup>Significant activations (FWER-corrected p&lt;0.05) displayed on FreeSurfer's average inflated surface (color bars depict uncorrected activation probabilities [−log10 (p)]). pANG, posterior angular gyrus area; pITS, posterior inferior temporal sulcus; DLPFC, dorsolateral prefrontal cortex; LOT, lateral occipito-temporal area; FFG, fusiform gyrus; orientation labels: L, left; R, right.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g004" position="float" xlink:type="simple"/>
        </fig>
        <p>DWI data were processed using FMRIB's Diffusion Toolbox (FDT, part of FSL). Up to two fiber orientations were modeled and the corresponding probabilistic distributions of diffusion parameters were built up at each voxel (using bedpostx, part of FDT). Probabilistic modeling of multiple fiber orientations <xref ref-type="bibr" rid="pone.0049451-Behrens1">[58]</xref> was essential because of crossing fibers in the areas under examination. Subsequently, probabilistic tractography was performed by probtrackx (part of FDT) on the same (n = 24) as well as independent (n = 46) subjects included for replication, to investigate structural connectivity between cortical regions related to either age or gender processing. After transforming functional clusters obtained at the second level back to the individual surface space of the anatomical scans, each cluster mask was defined as a seed with all the others serving as potential targets. Probabilistic streamlines were seeded directly from surface vertices. A total of 10∧4 samples was sent out from each tracking point. Stop and waypoint masking was used to exclude indirect routes. Upon slight spatial smoothing (2 mm FWHM), probabilistic seed-to-target connectivities were then averaged on FreeSurfer's common fsaverage surface. Probabilistic pathways were transformed to MNI space, added and thresholded for visualization (using FSL's non-linear 1 mm MNI template as target space; see 3D-tract volume rendering, thresholded at ≥100 connecting samples passing through each voxel, displayed on sagittal [x = −36 mm] and coronal [y = −54 mm] projection view planes in <xref ref-type="fig" rid="pone-0049451-g005">Figure 5</xref>).</p>
        <fig id="pone-0049451-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Association pathways subserving facial age processing.</title>
            <p>Ventral portion of Wernicke's perpendicular fasciculus (WpF) connecting pANG and pITS (average probabilistic path distributions connecting the functional clusters; n = 24, 3D-tract volume rendering thresholded at ≥100 connecting samples passing through each voxel, displayed on sagittal [x = −36 mm] and coronal [y = −54 mm] projection view planes in MNI standard space). pANG, posterior angular gyrus area; pITS, posterior inferior temporal sulcus; orientation labels: L, left; R, right.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g005" position="float" xlink:type="simple"/>
        </fig>
        <p>Utilizing spatial cross-correlations between functional activation probability values and tractography-based connectivity scores, we examine if the activation pattern of one area that processes facial age is predicted by its intrinsic structural connectivity with another, i.e. evidence for two selected areas directly interacting with each other as connections to the latter determine activations of the former and vice versa. The rationale behind this analysis was that if the spatial profile of a connection between A and B predicts the activation profile in A, then this suggests that the connection between A and B is indeed involved in brain processes producing the activation in A. Because fiber pathways, even when connecting A and B, do not have to participate in the processing, and because functional activations of A and B can be associated with each other in the absence of direct structural connectivity, we don't expect perfect spatial correspondence of functional and connectional probability profiles. But if detectable, significant correspondence of functional and connectivity profiles should emphasize the functional importance of a tract between A and B. Gender processing is again used for within- and across-condition comparison.</p>
        <p>Vertex-wise spatial cross-correlations between functional and structural profiles provide a quantitative measure for the association of the two (cf. <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>) and were calculated non-parametrically using Spearman's rank correlation coefficient (ρ). All p-values were Bonferroni-corrected for the total number of tests performed. Since lower false-positive activation error probabilities reflect higher activation likelihoods, i.e. higher positive t-values and z-scores, absolute log10 (p)-values were used for correlation.</p>
        <fig id="pone-0049451-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Surface-based cross-correlation of fMRI activation probabilities and structural connectivities.</title>
            <p>Spatial cross-correlation plots (± SEM)<sup>1</sup> between activation probabilities ([−log10(p)]) and structural connectivity scores ([log10(cs/ns)], with [(cs/ns)] reflecting ratios of connecting samples to the number of samples sent out from each vertex) for pANG, pITS and FFG (cf. <xref ref-type="fig" rid="pone-0049451-g004">Figure 4A</xref>), based on two samples: (n = 24) paired with functional data [red] and (n = 46) independent subjects [blue]. Connectivity ratios tend to get bound earlier at maximum values than corresponding activation probabilities. Positive correlations were slightly stronger for the sample with paired fMRI and DWI data (n = 24) compared to the independent sample from the FMRIB DWI database (n = 46; with Spearman's ρ displayed for the paired/independent sample when significant). However, the latter largely replicate and confirm generalizability of the results. <sup>1</sup>SEM, standard error of the mean; */**/***: FWER-corrected p&lt;0.05/0.01/0.001. pANG, posterior angular gyrus area; pITS, posterior inferior temporal sulcus; FFG, fusiform gyrus.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g006" position="float" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2f">
        <title>Modeling changes of age, gender and optical flow</title>
        <p>Since face stimuli underwent continuous temporal changes during the morphing, the explanatory variables of interest were modeled according to their change over time. Age and gender change were time-binned at the video frame-rate (24 fps). Scaling of each regressor was set to a relative maximum of 1. In order to determine accurate stimulus response functions, especially for age and gender, we extensively evaluated our paradigm and the stimuli employed by various psychometric ratings (see Behavioral Results). Thereby, we empirically identified unbiased stimulus response functions for age and gender, later used for modeling in the fMRI analysis.</p>
        <p>As illustrated in <xref ref-type="fig" rid="pone-0049451-g002">Figures 2A</xref> and <xref ref-type="fig" rid="pone-0049451-g003">3A</xref>, we modeled the age-related changes between start and target faces dependent on their psychophysical age difference. By transforming absolute age using an empirically derived power exponent of 0.3 according to Steven's law, our psychophysical response function accounted for the fact that aging during the first 20 years of life involves more visible changes than from 60 to 80, for example. The power exponent of 0.3 was empirically derived from our psychometric data (see below). According to these psychometric results, absolute facial age is best converted according to Steven's law using 0.3 for exponential transformation to estimate the psychophysical age gradient between start and target face (cf. <xref ref-type="fig" rid="pone-0049451-g002">Figure 2A</xref>). For the 6-seconds morphs and based on the psychometric results, the unsigned first derivative is used (cf. <xref ref-type="fig" rid="pone-0049451-g003">Figure 3A</xref>). Using the unsigned first derivative is based on the psychometrically tested assumption that the interpolated age of intermediate virtual frames between the start and target face morphed into each other is not differently perceived than the age of real faces (cf. <xref ref-type="fig" rid="pone-0049451-g002">Figure 2B</xref>). Thus, our stimulus response function models stronger the age-related activations the higher the psychophysical age gradient between two faces morphed into each other. Based on our psychometric results and in good accordance with previously published data <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, gender was modeled similarly by the unsigned first derivative of linear androgyny levels encoded by Steven's law using 3 for exponential transformation (see below).</p>
        <p>Optical flow <xref ref-type="bibr" rid="pone.0049451-Barron1">[59]</xref>, representing the total amount of motion between successive keyframes of the paradigm, was separately modeled to reduce the amount of unexplained variance which would confound the analysis if all morphing transitions were treated the same. On top of age and gender, optical flow during morphing differs between different pairs of start and target faces. Therefore, the full set of visual stimuli containing the (n = 120) continuous morph sequences displayed in the fMRI paradigm was fed into a customized Simulink V6.6 (2007, The MathWorks Inc., Natick, <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/products/simulink/" xlink:type="simple">http://www.mathworks.com/products/simulink/</ext-link>) model estimating optical flow between successive video keyframes by a Horn-Schunck algorithm <xref ref-type="bibr" rid="pone.0049451-Horn1">[60]</xref> based on flow velocities using MATLAB's video and image processing blockset with 30 iterations per pair. First, a vector field representing the inter-keyframe motion was extracted, as illustrated by flow magnitude lines in <xref ref-type="fig" rid="pone-0049451-g001">Figure 1B</xref>. Then, the vector field was converted to a binary mask. The sum of absolute flow values within that mask described the total amount of motion between successive keyframes of the paradigm and was robustly estimated as a surrogate parameter of overall flow intensity at one-second intervals. Note that optical flow detection on a frame-by-frame basis becomes less robust, i.e. time-binning above 1 fps does not improve the results. Given that all pixels exhibiting optical flow cannot be entered as separate explanatory variables to preserve sufficient degrees-of-freedom for the analysis, and considering that expansions and contractions involved in our face morphing were quite smooth, i.e. cross-correlated, optical flow was estimated at 1 fps and integrated as a nuisance regressor into our paradigm.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <p>This section is divided into two parts. The first part focuses on the psychometric behavioral data and, based upon these, on modeling the psychophysical changes of the main explanatory variables.</p>
      <p>The second part covers the related functional activations, as derived from the same set of (n = 24) subjects, and the structural connectivity between them, i.e. the neuroimaging results of the study.</p>
      <sec id="s3a">
        <title>Psychometric Results</title>
        <sec id="s3a1">
          <title>Age rating and the age regressor</title>
          <p>For the psychometric assessment, we instructed our volunteers to rate their subjective impression of how much facial age actually changed across morph sequences spanning an age spectrum similar to the original fMRI paradigm. In order to minimize the potential rating bias, the (n = 121) face stimuli were morphed to another average-aged male face of 33 years not contained in the original stimulus set. Therefore, the subjects were familiar with the set of faces used as start and targets in the fMRI video paradigm but not with the particular morphs displayed in the psychometric rating. Single start-to-target morphs were randomly played forwards or backwards for the rating, and the corresponding results are plotted in <xref ref-type="fig" rid="pone-0049451-g002">Figure 2A</xref>.</p>
          <p>On a 6-point visual analogue scale, subjective age-gradient ratings for the (n = 121) separate face morphs were best encoded according to Stevens' law of psychophysics <xref ref-type="bibr" rid="pone.0049451-Stevens1">[61]</xref>. Here, the perceived magnitude of age gradients spanned by the morphs was related to the difference between start and target age, both best transformed by a power exponent of 0.3 (cf. <xref ref-type="fig" rid="pone-0049451-g002">Figure 2A</xref>). For infinitesimal small bins during continuous morphing, psychophysical age change then corresponds to the unsigned first derivative of absolute facial ages (range: 2 to 81 years) encoded by Steven's law using 0.3 for exponential transformation. Given that it remains unclear to what extent facial age estimates are based on local feature, internal configuration, texture and global shape processing <xref ref-type="bibr" rid="pone.0049451-Ramanathan1">[29]</xref>, <xref ref-type="bibr" rid="pone.0049451-George2">[62]</xref>–<xref ref-type="bibr" rid="pone.0049451-Park1">[64]</xref>, this was considered the optimal approach to implement and model continuous changes of facial age. Deviations from linear transition values reflect the fact that the subjective perception of facial aging is relatively up-weighted to initial morphing periods and younger absolute ages (<xref ref-type="fig" rid="pone-0049451-g003">Figure 3A</xref>). Applied to age changes within individuals, for which only very limited data of unstandardized and scarcely suitable images are available <xref ref-type="bibr" rid="pone.0049451-Ramanathan1">[29]</xref>, this would reflect a modeling bias towards the earlier development of face shape that prevails over textural changes such as wrinkle formation during later aging <xref ref-type="bibr" rid="pone.0049451-Ramanathan1">[29]</xref>, or their removal by cosmetic rejuvenation. Across individuals and their shape differences, however, configural processing was not forced into any overt advantage over featural processing (see also the flow magnitude lines in <xref ref-type="fig" rid="pone-0049451-g001">Figure 1B</xref>). Both are difficult to completely separate and parameterize for facial age and aging.</p>
          <p>In a second rating, the task was to estimate the age of (n = 201) face stills in years. For this purpose, stills of all (n = 121) real faces and of (n = 80) interpolated age models were displayed randomly. In both of these stimulus samples, i.e. the real and interpolated age models, facial aging increased subjective age rating variability across our (n = 24) subjects similar to the group-ratings of young and old faces reported by Ebner <xref ref-type="bibr" rid="pone.0049451-Ebner1">[65]</xref>, see <xref ref-type="fig" rid="pone-0049451-g002">Figure 2B</xref>. No significant difference between real and interpolated faces was detected and exponential fitting revealed congruent curves.</p>
        </sec>
        <sec id="s3a2">
          <title>Age rating competence</title>
          <p>Based on the actual distribution of rating errors accumulated over all stills, we trichotomized according to upper and lower quintile cutoffs in order to relate age rating performance to fMRI activations (see below). Because implicit age-change processing (during the fMRI experiment) is rather unlikely to strongly correlate with explicit age-rating accuracy in post-hoc assessments of a limited sample size, this was not more rigorously modeled. The upper quintile of most accurate age-raters (n = 5) was compared to average performers (n = 14). The lower quintile of below-average raters (P20, n = 5) was excluded. Confirmed by their own verbal report, their compliance and motivation was limited at the second session so that age-rating performance of these subjects did not correspond to their actual capacities. This was reflected in disproportionally higher post-hoc rating errors and an increased rating variability (low accuracy ≤P20: 9.1±0.8, average accuracy &gt;P20/&lt;P80: 7.1±0.5 and high accuracy ≥P80: 5.7±0.5 years, as averaged over trials).</p>
        </sec>
        <sec id="s3a3">
          <title>Gender rating and the gender regressor</title>
          <p>In order to investigate the psychophysical processing of gender, especially at intermediate ambiguous levels, (n = 119) sample faces along temporal morph continua across gender from the (n = 60) transsexual morphing sequences were rated by the volunteers on a 6-point visual analogue scale according to their subjective impression of facial gender/androgyny levels. In accordance with previous reports <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, subjective gender levels were augmented above linear transition values reflecting the tendency to apperceptive categorization (<xref ref-type="fig" rid="pone-0049451-g002">Figure 2C</xref>). Gender-level ratings of the faces followed Stevens' power law just as age but were best fitted by a power exponent of 3 along the temporal morph continuum which is also in good agreement with the published data <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>. Perceived gender change while morphing thus simply depends on the difference of androgyny levels between time-points. For infinitesimal small bins during continuous morphing towards mid-androgyny between two clearly gendered faces, psychophysical gender change is then described by the unsigned first derivative of absolute androgyny levels (range: 0 to 1), encoded by Steven's law using 3 for exponential transformation (cf. <xref ref-type="fig" rid="pone-0049451-g003">Figure 3B</xref>). Note that contrary to previous modeling <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, peak androgyny was defined as the effective stimulus-of-interest because recognition of face gender transitions is particularly emphasized at the center of such morphs, see <xref ref-type="fig" rid="pone-0049451-g001">Figures 1</xref> and <xref ref-type="fig" rid="pone-0049451-g003">3B</xref>. Slight deviations from the center peak were captured by including the temporal derivative (see Material and Methods). Since pre-pubertal faces tend to appear less gendered the younger they are, androgyny peaks while morphing can be shifted to very young faces. Similarly, very old faces, especially when seen without hairstyle, may be liable to a male classification bias. Modeling a temporal derivative accounted for these effects and avoided a bias in testing age-by-gender interactions.</p>
        </sec>
      </sec>
      <sec id="s3b">
        <title>Neuroimaging Results</title>
        <sec id="s3b1">
          <title>Functional activations associated with optical flow</title>
          <p>Inclusion of optical flow as a nuisance variable enabled us to account for low-level configural and featural changes during face morphing which would otherwise have confounded the analysis. Optical flow was associated with functional activations in the motion-sensitive cortex (hMT+), see <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref> and <xref ref-type="fig" rid="pone-0049451-g001">Figure 1C</xref>, that is known to respond stronger than any other area to radial motion, 2D expansions and contractions of objects <xref ref-type="bibr" rid="pone.0049451-Bartels1">[9]</xref>, <xref ref-type="bibr" rid="pone.0049451-Zeki1">[66]</xref>–<xref ref-type="bibr" rid="pone.0049451-Vanduffel1">[70]</xref>. Functional (hMT+) activations related to optical flow are shown on bilateral flat maps in <xref ref-type="fig" rid="pone-0049451-g001">Figure 1C</xref> with additional visuotopic labels <xref ref-type="bibr" rid="pone.0049451-Tootell4">[71]</xref>, <xref ref-type="bibr" rid="pone.0049451-Tootell5">[72]</xref> of the SuMS <xref ref-type="bibr" rid="pone.0049451-VanEssen1">[73]</xref> database (<ext-link ext-link-type="uri" xlink:href="http://sumsdb.wustl.edu/" xlink:type="simple">http://sumsdb.wustl.edu/</ext-link>) to facilitate orientation and to illustrate the spatial correspondence of our clusters with the hMT+ atlas labels.</p>
          <table-wrap id="pone-0049451-t001" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049451.t001</object-id>
            <label>Table 1</label>
            <caption>
              <title>Synopsis of functional activations related to age, gender and motion/optical flow.</title>
            </caption>
            <alternatives>
              <graphic id="pone-0049451-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.t001" xlink:type="simple"/>
              <table>
                <colgroup span="1">
                  <col align="left" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                </colgroup>
                <thead>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">hemi</td>
                    <td align="left" rowspan="1" colspan="1">cluster</td>
                    <td align="left" rowspan="1" colspan="1">size</td>
                    <td align="left" rowspan="1" colspan="1">CWP</td>
                    <td align="left" rowspan="1" colspan="1">Max</td>
                    <td align="left" rowspan="1" colspan="1">VtxMax</td>
                    <td colspan="3" align="left" rowspan="1">MNI X, Y, Z</td>
                    <td align="left" rowspan="1" colspan="1">vE/BA</td>
                    <td align="left" rowspan="1" colspan="1">annotation</td>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td align="left" rowspan="1" colspan="1">
                      <bold>age</bold>
                    </td>
                    <td align="left" rowspan="1" colspan="1">left</td>
                    <td align="left" rowspan="1" colspan="1">pANG</td>
                    <td align="left" rowspan="1" colspan="1">2309</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">8.739</td>
                    <td align="left" rowspan="1" colspan="1">142332</td>
                    <td align="left" rowspan="1" colspan="1">−41.0</td>
                    <td align="left" rowspan="1" colspan="1">−74.5</td>
                    <td align="left" rowspan="1" colspan="1">27.0</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>G</italic>/39</td>
                    <td align="left" rowspan="1" colspan="1">inferior parietal</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">pITS</td>
                    <td align="left" rowspan="1" colspan="1">526</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">7.307</td>
                    <td align="left" rowspan="1" colspan="1">40331</td>
                    <td align="left" rowspan="1" colspan="1">−54.1</td>
                    <td align="left" rowspan="1" colspan="1">−55.8</td>
                    <td align="left" rowspan="1" colspan="1">−8.5</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>H</italic>/37</td>
                    <td align="left" rowspan="1" colspan="1">inferior temporal</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">right</td>
                    <td align="left" rowspan="1" colspan="1">pANG</td>
                    <td align="left" rowspan="1" colspan="1">1177</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">8.465</td>
                    <td align="left" rowspan="1" colspan="1">117820</td>
                    <td align="left" rowspan="1" colspan="1">46.7</td>
                    <td align="left" rowspan="1" colspan="1">−59.3</td>
                    <td align="left" rowspan="1" colspan="1">19.5</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>G</italic>/39</td>
                    <td align="left" rowspan="1" colspan="1">inferior parietal</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">pITS</td>
                    <td align="left" rowspan="1" colspan="1">367</td>
                    <td align="left" rowspan="1" colspan="1">0.0004</td>
                    <td align="left" rowspan="1" colspan="1">6.025</td>
                    <td align="left" rowspan="1" colspan="1">5665</td>
                    <td align="left" rowspan="1" colspan="1">54.2</td>
                    <td align="left" rowspan="1" colspan="1">−53.5</td>
                    <td align="left" rowspan="1" colspan="1">−9.4</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>H</italic>/37</td>
                    <td align="left" rowspan="1" colspan="1">inferior temporal</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1">
                      <bold>rating*</bold>
                    </td>
                    <td align="left" rowspan="1" colspan="1">left</td>
                    <td align="left" rowspan="1" colspan="1">pANG*</td>
                    <td align="left" rowspan="1" colspan="1">32</td>
                    <td align="left" rowspan="1" colspan="1">0.0133</td>
                    <td align="left" rowspan="1" colspan="1">5.045</td>
                    <td align="left" rowspan="1" colspan="1">146872</td>
                    <td align="left" rowspan="1" colspan="1">−42.4</td>
                    <td align="left" rowspan="1" colspan="1">−56.6</td>
                    <td align="left" rowspan="1" colspan="1">25.5</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>G</italic>/39</td>
                    <td align="left" rowspan="1" colspan="1">inferior parietal</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1">
                      <bold>gender</bold>
                    </td>
                    <td align="left" rowspan="1" colspan="1">left</td>
                    <td align="left" rowspan="1" colspan="1">DLPFC</td>
                    <td align="left" rowspan="1" colspan="1">370</td>
                    <td align="left" rowspan="1" colspan="1">0.0005</td>
                    <td align="left" rowspan="1" colspan="1">5.948</td>
                    <td align="left" rowspan="1" colspan="1">29235</td>
                    <td align="left" rowspan="1" colspan="1">−36.9</td>
                    <td align="left" rowspan="1" colspan="1">19.5</td>
                    <td align="left" rowspan="1" colspan="1">22.1</td>
                    <td align="left" rowspan="1" colspan="1">F<italic>D</italic>/46</td>
                    <td align="left" rowspan="1" colspan="1">inf. front. sulcus</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">FFG</td>
                    <td align="left" rowspan="1" colspan="1">228</td>
                    <td align="left" rowspan="1" colspan="1">0.0020</td>
                    <td align="left" rowspan="1" colspan="1">5.437</td>
                    <td align="left" rowspan="1" colspan="1">92500</td>
                    <td align="left" rowspan="1" colspan="1">−39.1</td>
                    <td align="left" rowspan="1" colspan="1">−67.9</td>
                    <td align="left" rowspan="1" colspan="1">−17.2</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>H</italic>/37</td>
                    <td align="left" rowspan="1" colspan="1">fusiform</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">right</td>
                    <td align="left" rowspan="1" colspan="1">LOT</td>
                    <td align="left" rowspan="1" colspan="1">862</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">5.988</td>
                    <td align="left" rowspan="1" colspan="1">35952</td>
                    <td align="left" rowspan="1" colspan="1">42.4</td>
                    <td align="left" rowspan="1" colspan="1">−77.3</td>
                    <td align="left" rowspan="1" colspan="1">−5.4</td>
                    <td align="left" rowspan="1" colspan="1">O<italic>A</italic>/19</td>
                    <td align="left" rowspan="1" colspan="1">lateral occipital</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">FFG</td>
                    <td align="left" rowspan="1" colspan="1">202</td>
                    <td align="left" rowspan="1" colspan="1">0.0021</td>
                    <td align="left" rowspan="1" colspan="1">5.107</td>
                    <td align="left" rowspan="1" colspan="1">28527</td>
                    <td align="left" rowspan="1" colspan="1">36.4</td>
                    <td align="left" rowspan="1" colspan="1">−56.0</td>
                    <td align="left" rowspan="1" colspan="1">−16.4</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>H</italic>/37</td>
                    <td align="left" rowspan="1" colspan="1">fusiform</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1">
                      <bold>motion</bold>
                    </td>
                    <td align="left" rowspan="1" colspan="1">left</td>
                    <td align="left" rowspan="1" colspan="1">hMT+</td>
                    <td align="left" rowspan="1" colspan="1">605</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">8.816</td>
                    <td align="left" rowspan="1" colspan="1">551</td>
                    <td align="left" rowspan="1" colspan="1">−42.6</td>
                    <td align="left" rowspan="1" colspan="1">−79.6</td>
                    <td align="left" rowspan="1" colspan="1">0.1</td>
                    <td align="left" rowspan="1" colspan="1">O<italic>A</italic>/19</td>
                    <td align="left" rowspan="1" colspan="1">middle occipital</td>
                  </tr>
                  <tr>
                    <td align="left" rowspan="1" colspan="1"/>
                    <td align="left" rowspan="1" colspan="1">right</td>
                    <td align="left" rowspan="1" colspan="1">hMT+</td>
                    <td align="left" rowspan="1" colspan="1">1204</td>
                    <td align="left" rowspan="1" colspan="1">0.0001</td>
                    <td align="left" rowspan="1" colspan="1">8.554</td>
                    <td align="left" rowspan="1" colspan="1">91197</td>
                    <td align="left" rowspan="1" colspan="1">46.7</td>
                    <td align="left" rowspan="1" colspan="1">−58.9</td>
                    <td align="left" rowspan="1" colspan="1">0.4</td>
                    <td align="left" rowspan="1" colspan="1">P<italic>HO</italic>/19</td>
                    <td align="left" rowspan="1" colspan="1">middle temporal</td>
                  </tr>
                </tbody>
              </table>
            </alternatives>
            <table-wrap-foot>
              <fn id="nt101">
                <label/>
                <p>Clusters significantly activated by changes of facial age, gender and motion/optical flow (FWER-corrected p&lt;0.05 for n = 24 subjects)<xref ref-type="table-fn" rid="nt102">1</xref>.</p>
              </fn>
              <fn id="nt102">
                <label>1</label>
                <p>hemi, hemisphere; size in [mm<sup>2</sup>], CWP, cluster-wise probability (non-parametric cluster mass inference over the entire surface; [ ]); Max, peak activation probability (absolute log10-maximum of uncorrected p-values: −log10(p); [ ]); VtxMax, vertex of Max on Freesurfer's average surface; MNI, coordinates in MNI standard space [mm]; vE/BA, <xref ref-type="bibr" rid="pone.0049451-vonEconomo1">[113]</xref>/<xref ref-type="bibr" rid="pone.0049451-Brodmann1">[114]</xref> area; annotation, anatomical labels; pANG, posterior angular gyrus area (*sub-cluster related to high age-rating competence); pITS, posterior inferior temporal sulcus; DLPFC, dorsolateral prefrontal cortex; LOT, lateral occipitotemporal area; FFG, fusiform gyrus; hMT+, human motion-sensitive MT+ (V5 or MT/MST) area.</p>
              </fn>
            </table-wrap-foot>
          </table-wrap>
        </sec>
        <sec id="s3b2">
          <title>Functional activations associated with facial age and interactions</title>
          <p>Age change-related activations were centered on the posterior inferior temporal sulcus (pITS), lateral to the fusiform gyrus (FFG), and on the posterior angular gyrus area (pANG) of both hemispheres; see <xref ref-type="fig" rid="pone-0049451-g004">Figure 4A</xref> and <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref>. Age change, but not the gender condition, was found to be associated with higher mean left-hemispheric activations (p = 0.04, ANOVA, condition-by-hemisphere interaction; <xref ref-type="fig" rid="pone-0049451-g004">Figure 4B</xref>). Apart from that, no other significant condition-by-hemisphere interactions, no significant differences between male and female volunteers and no significant positive or negative interactions between the variables-of-interest age, gender and optical flow or their relative response magnitudes, i.e. normalized effect size values, were detected. Note that the fact that we did not detect a gender-by-age interaction may be related to our specific modeling approach and our stimulus set of clearly gendered faces. The latter limited high androgyny levels to morphs with gender transitions and thereby the power to detect such interaction.</p>
        </sec>
        <sec id="s3b3">
          <title>Age-responsive areas associated with high age-rating competence</title>
          <p>Within left pANG, a sub-cluster above the superior temporal sulcus (STS) discriminated the upper quintile (P80, n = 5) of best explicit age raters from average performers (P20–80, n = 14) by higher activations, see <xref ref-type="fig" rid="pone-0049451-g004">Figure 4C</xref> and <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref>. Here, superior explicit age-rating competence of upper quintile performers corresponded to an enhanced mean response magnitude in their activation level associated with facial age, which was augmented by more than fourfold relative to average raters (as illustrated in <xref ref-type="fig" rid="pone-0049451-g004">Figure 4D</xref>). The lower quintile (P20, n = 5), which was not included in this specific second-level assessment based on the behavioral data, exhibited the highest variability of corresponding relative fMRI response magnitudes (shown by increased error bars in <xref ref-type="fig" rid="pone-0049451-g004">Figure 4D</xref>). The more pronounced fMRI response variability of these below-average age raters emphasizes their heterogeneity and presumed underperformance with respect to their actual capacities, which had prompted their exclusion from this part of the analysis (see Behavioral Results above).</p>
        </sec>
        <sec id="s3b4">
          <title>Functional activations associated with facial gender</title>
          <p>Gender change-related activations were detected within FFG bilaterally, see <xref ref-type="fig" rid="pone-0049451-g004">Figure 4A</xref> and <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref>, amplifying previous evidence for graded gender responses of the FFG and fusiform face area (FFA) <xref ref-type="bibr" rid="pone.0049451-Ng1">[21]</xref>, <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>. Notably, increased face androgyny during across-sex morph transitions activated above the more differentiated gender levels (cf. <xref ref-type="fig" rid="pone-0049451-g003">Figure 3B</xref>), and not vice versa as for static stimuli <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, illustrating the context dependency of the functional activations. In addition, the right lateral occipitotemporal area (LOT), already implicated by an early PET study <xref ref-type="bibr" rid="pone.0049451-Sergent1">[74]</xref>, and the left dorsolateral prefrontal cortex (DLPFC) were involved (<xref ref-type="fig" rid="pone-0049451-g004">Figure 4A,B</xref> and <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref>).</p>
        </sec>
        <sec id="s3b5">
          <title>Structural connections between age- and gender-related clusters</title>
          <p>For each subject, probabilistic tractography was run between all age and gender change-related clusters on individual brain surface reconstructions. An association tract, the ventral portion of Wernicke's perpendicular fasciculus <xref ref-type="bibr" rid="pone.0049451-Dejerine1">[75]</xref>, was found to interconnect pANG and pITS (<xref ref-type="fig" rid="pone-0049451-g005">Figure 5</xref>). Its almost vertically running fibers connect the posterior inferior parietal lobule, namely the angular gyrus (‘pli courbe’), and the parieto-occipital transition, namely the second parieto-occipital ‘pli de passage’ of Gratiolet <xref ref-type="bibr" rid="pone.0049451-Duvernoy1">[76]</xref>, with the inferior temporal area <xref ref-type="bibr" rid="pone.0049451-Noback1">[77]</xref>. Other cortico-cortical pathways, such as fibers of the superior longitudinal and fronto-occipital fasciculi connecting FFG, pANG and DLPFC (schematically displayed in <xref ref-type="fig" rid="pone-0049451-g007">Figure 7</xref>), are not rendered for display and revealed lower connectivities (see log-transformed connectivity scores in <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>), except for clusters located very close to each other (e.g., FFG and LOT). Commissure connectivities between clusters related to age or gender processing remained negligible, i.e. less than 0.1‰ of the total number of samples sent out from seed vertices reached the targets (n = 32 pathways of homo-, e.g. right↔left pITS, and heterotopic, e.g. right pANG↔left pITS, commissures extracted).</p>
          <fig id="pone-0049451-g007" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049451.g007</object-id>
            <label>Figure 7</label>
            <caption>
              <title>Left-hemispheric nodes of the presumed brain network processing the age of faces.</title>
              <p>3D model illustrating how the ventral stream, pITS in particular, may interact via Wernicke's perpendicular fasciculus (WpF) with the posterior magnitude-encoding and approximate number system <xref ref-type="bibr" rid="pone.0049451-Walsh1">[98]</xref>, <xref ref-type="bibr" rid="pone.0049451-Cantlon1">[99]</xref>, pANG in particular, to quantify the varying age of faces. FFG exhibits some connectivity to pANG (cf. <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>) but is primarily engaged in processing fixed face attributes such as categorical gender (even if continuously changed over variable androgyny levels like in <xref ref-type="fig" rid="pone-0049451-g001">Figure 1A</xref>; see also <xref ref-type="fig" rid="pone-0049451-g002">Figures 2C</xref>, <xref ref-type="fig" rid="pone-0049451-g003">3B</xref> and <xref ref-type="fig" rid="pone-0049451-g004">4A</xref>). pANG, posterior angular gyrus area; pITS, posterior inferior temporal sulcus; DLPFC, dorsolateral prefrontal cortex; LOT, lateral occipitotemporal area; FFG, fusiform gyrus; 17–19, Brodmann's areas forming three visual tiers; hMT+, human motion-sensitive temporal cortex; ITG/MTG/STG, inferior/middle/superior temporal gyrus; ITS/STS, inferior/superior temporal sulcus.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049451.g007" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s3b6">
          <title>Linking connectivity and activation patterns</title>
          <p>The connectivity between functionally defined seed- and target-clusters was quantified by counting how many connecting samples arrived at every vertex of the target (from any vertex of the steed), yielding an index for every target vertex. In order to characterize the extent to which different structural seed-to-target connectivities relate to activation patterns, we then examined the vertex-wise spatial cross-correlations between surface connectivity scores and activation probabilities, i.e. the above connectivity index was correlated (plotted) against the activation probability of the target vertices in <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref> (see Materials and Methods). This is based on the hypothesis that if there is a direct structural connection between a pair of functional regions, where this connection itself is involved in the cerebral processing, then locations of highest fMRI activation probability within the regions should be close to the highest probability of structural connectivity between them, i.e. the patterns of functional activations and anatomical connectivity should be positively correlated. We tested this hypothesis on all clusters responsive to age and gender change.</p>
          <p>At the group level, by far most consistent spatial cross-correlations between activation probabilities and average connectivity scores were detected for pANG and pITS (cf. <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>; results exclusively shown for association pathways of Wernicke's perpendicular fasciculus between pANG, pITS and FFG). Thus, for pANG, lowest type I activation error probabilities were in proximity to high pITS connectivity, indicating pITS' ability to directly recruit pANG for age processing and vice versa. In addition to pANG and pITS <italic>within</italic> the age-change condition of both hemispheres (<xref ref-type="fig" rid="pone-0049451-g004">Figures 4</xref> and <xref ref-type="fig" rid="pone-0049451-g006">6</xref>), significant but lower positive vertex-wise spatial cross-correlations of activation probabilities and connectivity values were only found in the right hemisphere for the pANG and LOT cluster (0.10≤ρ≤0.18 for pANG↔LOT; not shown). Furthermore, activations of the pANG cluster revealed potentially relevant associations with connections to FFG, especially on the left, but just on this tractography seeding end (i.e. FFG activations were <italic>not</italic> consistently related to their pANG connectivity; see spatial cross-correlation plots in <xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>), and pANG's overall connectivity to the FFG cluster remained comparatively low. These connections, which were originally discovered by Wernicke <xref ref-type="bibr" rid="pone.0049451-Ross1">[78]</xref> based on anatomical examination of monkey brains <xref ref-type="bibr" rid="pone.0049451-Wernicke1">[79]</xref> and later demonstrated to form part of the stratum verticale convexitatis in men <xref ref-type="bibr" rid="pone.0049451-Sachs1">[80]</xref>, correspond to fibers of Wernicke's perpendicular fasciculus between the angular and fusiform gyri <xref ref-type="bibr" rid="pone.0049451-Quain1">[81]</xref>. Commissure connectivities (n = 32 homo- and heterotopic pathways; see above) were also tested but revealed no significant vertex-wise spatial cross-correlations with corresponding activation probabilities. Because cluster size and distance effects are hard to disentangle from meaningful inter-hemispheric differences, we did not test for differences between surface-based spatial cross-correlations of fMRI activation probabilities and structural connectivities across the two hemispheres.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>Our investigation provides the first description of a distinct brain network associated with processing the age of faces and its underlying structural connectivity. Although facial age is of high social relevance and has been shown to influence medial prefrontal activations when presumed personality characteristics are rated <xref ref-type="bibr" rid="pone.0049451-Ebner2">[82]</xref>, the neural basis of facial age processing itself has not previously been identified. According to our data, its primary cortical components – the areas around pITS and pANG – are separate from those processing categorical gender while face-selective FFA activations have recently been shown to be primarily predicted by inferotemporal connectivity of the FFG <xref ref-type="bibr" rid="pone.0049451-Saygin1">[16]</xref>. Notably, the age-processing network, i.e. pITS <italic>together with</italic> pANG, also expands the proposed core system representing other variable face aspects (such as eye gaze; unvaried and directed at the viewer in our fMRI study) which are ready to change instantly under attentional, emotional or volitional instead of ontogenetic control <xref ref-type="bibr" rid="pone.0049451-Haxby1">[1]</xref>, <xref ref-type="bibr" rid="pone.0049451-Calder1">[83]</xref>. It may also augment the extended system, as previously conceptualized, which has been suggested to mediate spatially directed attention and recognition of emotions in faces, for example <xref ref-type="bibr" rid="pone.0049451-Haxby1">[1]</xref>.</p>
      <sec id="s4a">
        <title>Structural within-network connectivity</title>
        <p>Wernicke's perpendicular fasciculus (WpF) has been recognized as a separate cerebral association tract but so far largely escaped further description and attention <xref ref-type="bibr" rid="pone.0049451-Oishi1">[84]</xref>. Only its more posterior occipital portion has been implied as part of a disconnection syndrome potentially underlying cases of pure alexia <xref ref-type="bibr" rid="pone.0049451-Greenblatt1">[85]</xref>. Compared to other association tracts, it runs in a peculiar vertical instead of horizontal trajectory which enables it to interconnect ventral and dorsal parallel pathways <xref ref-type="bibr" rid="pone.0049451-ffytche1">[86]</xref>, see <xref ref-type="fig" rid="pone-0049451-g005">Figures 5</xref> and <xref ref-type="fig" rid="pone-0049451-g007">7</xref>. Despite the known limitations and inaccuracies of DWI-based tractography <xref ref-type="bibr" rid="pone.0049451-Jbabdi1">[87]</xref>, our main finding that brain activity spatially correlates with connectivity between pITS and pANG substantiates our claim that the structural connection of these two cortical areas by WpF's ventral portion is of real functional importance <italic>in vivo</italic>. Specifically, our results suggest that this association pathway may be linked to facial age processing (see below).</p>
      </sec>
      <sec id="s4b">
        <title>Methodological Limitations</title>
        <p>Given that tractography cannot reveal directions of information processing, our data do not ensure that it is pITS that recruits pANG and not vice versa. Continuous morphing, despite its strength of presumably augmenting change-sensitive neural responses and supporting our explicit psychophysiological model, precludes reliable detection of temporal delay differences between pITS and pANG. Thus, we acknowledge that these clusters may influence each other reciprocally, as schematically indicated in <xref ref-type="fig" rid="pone-0049451-g007">Figure 7</xref>, a fact that is generally assumed for most cortical areas connected by association tracts.</p>
        <p>Due to the inherent smoothness of fMRI data, which is further pronounced on the average surface, and because connectivity probabilities tend to increase the closer seed and target are located, association of probabilistic connectivity and activation probabilities for extremely short association fibers and cortical regions located very near to each other (e.g., right LOT and pITS <italic>across</italic> the age and gender condition) may be inflated. In fact, at a liberal threshold (p = 0.05, uncorrected for multiple comparisons) the right age-related pITS activation extends into the ipsilateral gender-related LOT cluster, and nearby parts of these two clusters are also vigorously interconnected. This suggests that right LOT, to some extent, may participate in age processing. Similarly, connectivity of gender-responsive FFG to nearby pITS (not shown) and pANG (<xref ref-type="fig" rid="pone-0049451-g006">Figure 6</xref>) may be relevant for facial age processing. In having identified potential key components of these circuitries, our study may serve as a precursor for future studies of effective functional connectivity between such sets of areas, e.g. by using dynamic causal modeling (DCM). Interestingly, apparent face gender is normally fixed for a given individual (except in early developmental stages and transsexuals): Changes of face gender are virtually always and inevitably associated with changes of personal identity. Consistent with it and the presented results, both gender and identity processing have been strongly associated to FFG/FFA <xref ref-type="bibr" rid="pone.0049451-Rotshtein1">[19]</xref>, <xref ref-type="bibr" rid="pone.0049451-Ng1">[21]</xref>, <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, <xref ref-type="bibr" rid="pone.0049451-Hoffman1">[88]</xref>–<xref ref-type="bibr" rid="pone.0049451-Haist1">[93]</xref>. The fact that our data on the processing of face gender (which also changed continuously in our experiment) largely replicates previous results obtained by static stimuli <xref ref-type="bibr" rid="pone.0049451-Ng1">[21]</xref>, <xref ref-type="bibr" rid="pone.0049451-Freeman1">[25]</xref>, <xref ref-type="bibr" rid="pone.0049451-Sergent1">[74]</xref>, <xref ref-type="bibr" rid="pone.0049451-Kaul1">[94]</xref> and that neither our age nor gender condition involved the right anterior STS (which has been shown to exclusively respond to moving faces) <xref ref-type="bibr" rid="pone.0049451-Pitcher1">[7]</xref>, <xref ref-type="bibr" rid="pone.0049451-Lee1">[11]</xref> further strengthens the conclusion that we have indeed detected a brain network processing the age of faces and not other unstable features (such as the movement within the faces) or subliminal changes of identity. This corroboration is important, since people do not normally age in front of our eyes, and adaptation experiments have indicated the potential recruitment of more widely distributed brain regions <xref ref-type="bibr" rid="pone.0049451-Ng1">[21]</xref> and the area around the STS even in identity processing <xref ref-type="bibr" rid="pone.0049451-Winston1">[95]</xref>. However, the latter finding is not supported by other data <xref ref-type="bibr" rid="pone.0049451-CohenKadosh1">[96]</xref> and would, contrary to our findings, also be expected to affect our gender condition.</p>
      </sec>
      <sec id="s4c">
        <title>Interpretation</title>
        <p>A unique combination of fMRI and diffusion tractography measurements enabled us not only to track anatomical connections between peak activations but also to uncover significant spatial cross-correlations between functional activations on the one hand and structural connectivity probabilities on the other. The demonstration of such associations between functional and probabilistic connectivity measures, which has only recently been highlighted by a different hypothesis and approach <xref ref-type="bibr" rid="pone.0049451-Saygin1">[16]</xref>, <xref ref-type="bibr" rid="pone.0049451-Jbabdi2">[97]</xref>, may further assist the understanding of relations between fMRI activations and cerebral connectivity. For example, this type of association in the localization of function and structure can substantiate evidence for fiber tracts being directly involved in transmitting condition-relevant information which has not previously been proposed or analyzed. Our data suggest that age-relevant information may be transmitted between pITS and pANG by the anterior division of Wernicke's perpendicular fasciculus to which no unambiguous function has yet been attributed.</p>
        <p>Our results allow us to propose the first coherent model (illustrated in <xref ref-type="fig" rid="pone-0049451-g007">Figure 7</xref>) for how the ventral visual stream may interact with the angular gyrus area to process different facial ages. Changing within as well as across individuals, age is automatically quantified and attributed particularly to faces, i.e. more precisely than for any other object. We propose that facial age is represented in terms of growing quantities and contrastable numerical magnitudes. By utilizing the ventral part of Wernicke's perpendicular fasciculus, a largely understudied association tract, age-responsive pITS gains access to pANG, posterior processing core of a common quantification network outlined in a theory of magnitude (ATOM) <xref ref-type="bibr" rid="pone.0049451-Walsh1">[98]</xref> and part of an approximate number system (ANS) <xref ref-type="bibr" rid="pone.0049451-Cantlon1">[99]</xref>. Neither pITS nor pANG are likely to process facial age exclusively, and both areas are certainly not only devoted to decode the age of faces, yet our findings indicate their spatially coherent involvement in its implicit processing across subjects. Sparse data from brain-lesioned patients <xref ref-type="bibr" rid="pone.0049451-DeRenzi2">[100]</xref> indicate that the posterior right brain may be crucial for (ap-)perceptive component of age processing. Increased left-hemispheric responses (shown in <xref ref-type="fig" rid="pone-0049451-g004">Figure 4A,B</xref>) and higher activation levels of most accurate raters above the superior temporal sulcus within left pANG only (cf. <xref ref-type="fig" rid="pone-0049451-g004">Figure 4C,D</xref>), on the other hand, correspond to a known importance of the left angular gyrus for abstract number representations, quantized discrete decoding, numerical comparisons and operations <xref ref-type="bibr" rid="pone.0049451-Gbel1">[101]</xref>, <xref ref-type="bibr" rid="pone.0049451-Gbel2">[102]</xref>, as well as high mental calculation abilities <xref ref-type="bibr" rid="pone.0049451-Grabner1">[103]</xref>. These findings do not disambiguate which lower-level brain regions and face features (e.g., wrinkle quantity, skin texture, or head cast with different developmental face-to-skull proportions) contribute to the encoding of facial age. Nevertheless, they may suggest that the age-responsive network assembles and eventually integrates these inputs into comparable and estimable magnitudes particularly within pANG, by different contributions from the right and left hemisphere. Contrary to the static and dynamic processing of other face object categorizations and discriminations <xref ref-type="bibr" rid="pone.0049451-Pitcher1">[7]</xref>, <xref ref-type="bibr" rid="pone.0049451-Barton1">[104]</xref>, average responses related to facial age were more pronounced and robust in the left hemisphere, and age-rating performance was also associated with left brain functioning of pANG.</p>
        <p>Considering the extraordinary relevance of age judgements for the interpersonal domain, e.g. to establish peer communication, attractiveness and even empathy, the cognitive processing of facial age and aging reflects an intrinsic core capacity of the human “social brain”. Its functions have also been related to the temporo-parietal junction. Attractiveness, which has not been modulated in our study, is influenced by facial age <xref ref-type="bibr" rid="pone.0049451-OToole1">[2]</xref>, <xref ref-type="bibr" rid="pone.0049451-Perrett1">[105]</xref>. It has been, among other brain areas, associated with the STS. However, activation peaks reported for attractiveness judgements <xref ref-type="bibr" rid="pone.0049451-Winston2">[106]</xref> were located superior to those of pITS and more anterior to those of pANG (see <xref ref-type="table" rid="pone-0049451-t001">Table 1</xref>). Obviously, faces of the same age are differently attractive, and attractiveness per se has not been shown to evoke unequivocal activations <xref ref-type="bibr" rid="pone.0049451-Kampe1">[107]</xref>. Furthermore, the brain network proposed by us to process facial age clearly differs from the largely reward-related systems that have been implied in association with beauty <xref ref-type="bibr" rid="pone.0049451-Kampe1">[107]</xref>–<xref ref-type="bibr" rid="pone.0049451-Tsukiura1">[110]</xref>.</p>
      </sec>
      <sec id="s4d">
        <title>Outlook and Conclusions</title>
        <p>Future investigations and lesion studies are required to further elucidate cognitive age processing. Our analysis may be broadened by other approaches examining distributed patterns of neural age-encoding in their selectiveness and specificity but this would have been beyond the scope of this study. More elaborate insights can be anticipated investigating age discrimination upon face inversion, processing the age of non-face objects, adaptation to age, own- vs. other-age effects including associated visual processing strategies and their potential center-periphery bias, cross-modal integration of age information, age processing in the blind, dissociation of non-abstract and numerical age representations, and the development of age-recognition expertise. Even though our study highlights pANG as one key component for age processing, its precise role in this context is still speculative and needs further investigation. Our model, illustrated in <xref ref-type="fig" rid="pone-0049451-g007">Figure 7</xref>, gives rise to interesting hypotheses: One testable prediction would be that disruption of left pANG activity using transcranial magnetic stimulation (TMS), for example, should impair numerical age but not gender judgements, and that brain lesion-symptom mapping can eventually dissociate the two. On the other hand, our model of separate brain networks processing age and gender (cf. <xref ref-type="fig" rid="pone-0049451-g007">Figure 7</xref>) would be falsified if dissociations of age from gender agnosia cannot be confirmed. Consistent with our proposed model of segregated neural systems for gender and age processing, Bruyer &amp; Schweich describe a patient with prosopagnosia secondary to a right temporo-occipital brain haemorrhage (most likely affecting right LOFA +/− FFG according to their description) who exhibited deficient gender categorization but in whom age classification was preserved <xref ref-type="bibr" rid="pone.0049451-Bruyer1">[38]</xref>. Another assumption would be that activity of at least parts of the network processing the age of faces is incremental with low-level cues, such as wrinkle formation and head proportions, with more cues giving rise to higher activation levels in these areas. Such low-level cues determining facial age perception may be modulated con- and divergently. Finally, pANG (but not pITS?) may be involved in the processing of age and aging for non-face stimuli, like other body parts or inanimated objects.</p>
        <p>The notion of a distributed neural core system processing fixed attributes vs. changeable aspects of faces <xref ref-type="bibr" rid="pone.0049451-Haxby1">[1]</xref> parallels the traditional logic of distinguishing essential from non-essential object properties. In this regard, facial age may be considered an auxiliary appearance, conveying non-symbolic, abstract and social information. As is the case with gender and identity, age does not need to be constantly ascertained in another's face and is not reproduced or “mirrored“ by the perceiver. Therefore, its regular processing presumably relies less on permanent monitoring required to follow eye gaze, lip-speech or facial expressions <xref ref-type="bibr" rid="pone.0049451-Calder1">[83]</xref> for which predictable motion trajectories may be anticipated <xref ref-type="bibr" rid="pone.0049451-Furl2">[111]</xref>. Our results can be interpreted to discover a genuine set of the face-processing ensemble: the posterior inferior sulcus within the extrastriate system of visual face analysis that interacts via Wernicke's perpendicular fasciculus with extended modules of the angular gyrus area to represent the age of faces.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pone.0049451.s001" mimetype="video/quicktime" xlink:href="info:doi/10.1371/journal.pone.0049451.s001" position="float" xlink:type="simple">
        <label>Movie S1</label>
        <caption>
          <p><bold>Exemplary video sequence morphing a 20 year-old female into a 60 year-old male.</bold> The exemplary morph video (Movie 1) is also available in Windows AVI and Apple QuickTime format for download here: <ext-link ext-link-type="uri" xlink:href="http://www.neuroradiologie.uk-wuerzburg.de/facemorph/" xlink:type="simple">http://www.neuroradiologie.uk-wuerzburg.de/facemorph/</ext-link>.</p>
          <p>(MOV)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We would like to thank E.K. Warrington for her inspiration and helpful notes, as well as T.E. Behrens, A. Biller, B. Fischl, D. Greve, M. Hanke, T. Höll, M. Jenkinson, D. Dierker, F. Oltmanns, and S.M. Smith for their substantial advice. M. Bendszus and L. Solymosi provided continuous support.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0049451-Haxby1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>, <name name-style="western"><surname>Hoffman</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name> (<year>2000</year>) <article-title>The distributed human neural system for face perception</article-title>. <source>Trends Cogn Sci</source> <volume>4</volume>: <fpage>223</fpage>–<lpage>233</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-OToole1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Toole</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Price</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Vetter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Bartlett</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Blanz</surname><given-names>V</given-names></name> (<year>1999</year>) <article-title>3D shape and 2D surface textures of human faces: the role of “averages” in attractiveness and age</article-title>. <source>Image and Vision Computing</source> <volume>18</volume>: <fpage>9</fpage>–<lpage>19</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-McGraw1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McGraw</surname><given-names>KO</given-names></name>, <name name-style="western"><surname>Durm</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Durnam</surname><given-names>MR</given-names></name> (<year>1989</year>) <article-title>The relative salience of sex, race, age, and glasses in children's social perception</article-title>. <source>J Genet Psychol</source> <volume>150</volume>: <fpage>251</fpage>–<lpage>267</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-OCraven1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Craven</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Downing</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>1999</year>) <article-title>fMRI evidence for objects as the units of attentional selection</article-title>. <source>Nature</source> <volume>401</volume>: <fpage>584</fpage>–<lpage>587</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Fox1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fox</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Iaria</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Barton</surname><given-names>JJ</given-names></name> (<year>2009</year>) <article-title>Defining the face processing network: optimization of the functional localizer in fMRI</article-title>. <source>Human Brain Mapping</source> <volume>30</volume>: <fpage>1637</fpage>–<lpage>1651</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Schultz1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pilz</surname><given-names>KS</given-names></name> (<year>2009</year>) <article-title>Natural facial motion enhances cortical responses to faces</article-title>. <source>Experimental brain research Experimentelle Hirnforschung Experimentation cerebrale</source> <volume>194</volume>: <fpage>465</fpage>–<lpage>475</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Pitcher1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitcher</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Dilks</surname><given-names>DD</given-names></name>, <name name-style="western"><surname>Saxe</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Triantafyllou</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Differential selectivity for dynamic versus static information in face-selective cortical regions</article-title>. <source>Neuroimage</source> <volume>56</volume>: <fpage>2356</fpage>–<lpage>2363</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hasson1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasson</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Nir</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Levy</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Fuhrmann</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Malach</surname><given-names>R</given-names></name> (<year>2004</year>) <article-title>Intersubject Synchronization of Cortical Activity During Natural Vision</article-title>. <source>Science</source> <volume>303</volume>: <fpage>1634</fpage>–<lpage>1640</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Bartels1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartels</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Zeki</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name> (<year>2008</year>) <article-title>Natural vision reveals regional specialization to local motion and to contrast-invariant, global flow in the human brain</article-title>. <source>Cerebral Cortex</source> <volume>18</volume>: <fpage>705</fpage>–<lpage>717</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Fine1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fine</surname><given-names>JG</given-names></name>, <name name-style="western"><surname>Semrud-Clikeman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Zhu</surname><given-names>DC</given-names></name> (<year>2009</year>) <article-title>Gender differences in BOLD activation to face photographs and video vignettes</article-title>. <source>Behav Brain Res</source> <volume>201</volume>: <fpage>137</fpage>–<lpage>146</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Lee1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>Andrews</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Woods</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Gouws</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Neural responses to rigidly moving faces displaying shifts in social attention investigated with fMRI and MEG</article-title>. <source>Neuropsychologia</source> <volume>48</volume>: <fpage>477</fpage>–<lpage>490</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Scherf1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scherf</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Luna</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Minshew</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Behrmann</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Location, location, location: alterations in the functional topography of face- but not object- or place-related cortex in adolescents with autism</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>4</volume>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Kauppi1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kauppi</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Jaaskelainen</surname><given-names>IP</given-names></name>, <name name-style="western"><surname>Sams</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Tohka</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Inter-subject correlation of brain hemodynamic responses during watching a movie: localization in space and frequency</article-title>. <source>Front Neuroinformatics</source> <volume>4</volume>: <fpage>5</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hasson2">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasson</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Malach</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2010</year>) <article-title>Reliability of cortical activity during natural stimulation</article-title>. <source>Trends in Cognitive Sciences</source> <volume>14</volume>: <fpage>40</fpage>–<lpage>48</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Raz1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raz</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Winetraub</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Jacob</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kinreich</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Maron-Katz</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Portraying emotions at their unfolding: A multilayered approach for probing dynamics of neural networks</article-title>. <source>Neuroimage</source> <volume>60</volume>: <fpage>1448</fpage>–<lpage>1461</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Saygin1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saygin</surname><given-names>ZM</given-names></name>, <name name-style="western"><surname>Osher</surname><given-names>DE</given-names></name>, <name name-style="western"><surname>Koldewyn</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Reynolds</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gabrieli</surname><given-names>JD</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Anatomical connectivity patterns predict face selectivity in the fusiform gyrus</article-title>. <source>Nature neuroscience</source> <volume>15</volume>: <fpage>321</fpage>–<lpage>327</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Kircher1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kircher</surname><given-names>TT</given-names></name>, <name name-style="western"><surname>Senior</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Phillips</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Rabe-Hesketh</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Benson</surname><given-names>PJ</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Recognizing one's own face</article-title>. <source>Cognition</source> <volume>78</volume>: <fpage>B1</fpage>–<lpage>B15</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Leopold1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leopold</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>O'Toole</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Vetter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Blanz</surname><given-names>V</given-names></name> (<year>2001</year>) <article-title>Prototype-referenced shape encoding revealed by high-level aftereffects</article-title>. <source>Nat Neurosci</source> <volume>4</volume>: <fpage>89</fpage>–<lpage>94</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Rotshtein1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rotshtein</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Henson</surname><given-names>RN</given-names></name>, <name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Driver</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2005</year>) <article-title>Morphing Marilyn into Maggie dissociates physical and identity face representations in the brain</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>107</fpage>–<lpage>113</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Uddin1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uddin</surname><given-names>LQ</given-names></name>, <name name-style="western"><surname>Kaplan</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zaidel</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Self-face recognition activates a frontoparietal “mirror” network in the right hemisphere: an event-related fMRI study</article-title>. <source>Neuroimage</source> <volume>25</volume>: <fpage>926</fpage>–<lpage>935</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ng1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ng</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ciaramitaro</surname><given-names>VM</given-names></name>, <name name-style="western"><surname>Anstis</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Boynton</surname><given-names>GM</given-names></name>, <name name-style="western"><surname>Fine</surname><given-names>I</given-names></name> (<year>2006</year>) <article-title>Selectivity for the configural cues that identify the gender, ethnicity, and identity of faces in human cortex</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>103</volume>: <fpage>19552</fpage>–<lpage>19557</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Jiang1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Bradley</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Rini</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Zeffiro</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Vanmeter</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Categorization training results in shape- and category-selective human neural plasticity</article-title>. <source>Neuron</source> <volume>53</volume>: <fpage>891</fpage>–<lpage>903</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Furl1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furl</surname><given-names>N</given-names></name>, <name name-style="western"><surname>van Rijsbergen</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2007</year>) <article-title>Experience-dependent coding of facial expression in superior temporal sulcus</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>: <fpage>13485</fpage>–<lpage>13489</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tootell1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Devaney</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Postelnicu</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Rajimehr</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>fMRI mapping of a morphed continuum of 3D shapes within inferior temporal cortex</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>105</volume>: <fpage>3605</fpage>–<lpage>3609</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Freeman1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freeman</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Rule</surname><given-names>NO</given-names></name>, <name name-style="western"><surname>Adams</surname><given-names>RB</given-names><suffix>Jr</suffix></name>, <name name-style="western"><surname>Ambady</surname><given-names>N</given-names></name> (<year>2009</year>) <article-title>The neural basis of categorical face perception: graded representations of face gender in fusiform and orbitofrontal cortices</article-title>. <source>Cereb Cortex</source> <volume>20</volume>: <fpage>1314</fpage>–<lpage>1322</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Wallis1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallis</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Siebeck</surname><given-names>UE</given-names></name>, <name name-style="western"><surname>Swann</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Blanz</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Bulthoff</surname><given-names>HH</given-names></name> (<year>2008</year>) <article-title>The prototype effect revisited: Evidence for an abstract feature model of face recognition</article-title>. <source>J Vis</source> <volume>8</volume>: <fpage>20 21</fpage>–<lpage>15</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Jiang2">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Blanz</surname><given-names>V</given-names></name>, <name name-style="western"><surname>O'Toole</surname><given-names>AJ</given-names></name> (<year>2006</year>) <article-title>Probing the visual representation of faces with adaptation: A view from the other side of the mean</article-title>. <source>Psychol Sci</source> <volume>17</volume>: <fpage>493</fpage>–<lpage>500</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Blanz1">
        <label>28</label>
        <mixed-citation publication-type="other" xlink:type="simple">Blanz V, Vetter T (1999) A morphable model for the synthesis of 3D faces. SIGGRAPH. Los Angeles: ACM Press/Addison-Wesley Publishing Co.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ramanathan1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramanathan</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Chellappa</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Biswas</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Computational methods for modeling facial aging: A survey</article-title>. <source>Journal of Visual Languages &amp; Computing</source> <volume>20</volume>: <fpage>131</fpage>–<lpage>144</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-George1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>George</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Hole</surname><given-names>GJ</given-names></name> (<year>1998</year>) <article-title>Recognising the ageing face: the role of age in face processing</article-title>. <source>Perception</source> <volume>27</volume>: <fpage>1123</fpage>–<lpage>1134</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tranel1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tranel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>H</given-names></name> (<year>1988</year>) <article-title>Intact recognition of facial expression, gender, and age in patients with impaired recognition of face identity</article-title>. <source>Neurology</source> <volume>38</volume>: <fpage>690</fpage>–<lpage>696</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-McNeil1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNeil</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Warrington</surname><given-names>EK</given-names></name> (<year>1991</year>) <article-title>Prosopagnosia: a reclassification</article-title>. <source>Q J Exp Psychol A</source> <volume>43</volume>: <fpage>267</fpage>–<lpage>287</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-DeRenzi1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Renzi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Perani</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Carlesimo</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Silveri</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Fazio</surname><given-names>F</given-names></name> (<year>1994</year>) <article-title>Prosopagnosia can be associated with damage confined to the right hemisphere–an MRI and PET study and a review of the literature</article-title>. <source>Neuropsychologia</source> <volume>32</volume>: <fpage>893</fpage>–<lpage>902</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Bruce1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bruce</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>A</given-names></name> (<year>1986</year>) <article-title>Understanding face recognition</article-title>. <source>British journal of psychology</source> <volume>77</volume> (<issue>Pt 3</issue>) 
<fpage>305</fpage>–<lpage>327</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ellis1">
        <label>35</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ellis HD (1981) Theoretical Aspects Of Face Recognition. In: Davies G, Ellis HD, Shepherd J, editors. Perceiving and Remembering Faces. London: Academic Press. pp. 171–197.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ellis2">
        <label>36</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ellis HD (1983) The Role of the Right Hemisphere in Face Perception. In: Young AW, editor. Functions of the Right Cerebral Hemisphere. London: Academic Press. pp. 33–64.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ellis3">
        <label>37</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ellis HD (1986) Processes Underlying Face Recognition. In: Bruyer R, editor. The Neuropsychology of Face Perception and Facial Expression. Hillsdale, NJ: Lawrence Erlbaum. pp. 1–27.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Bruyer1">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bruyer</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Schweich</surname><given-names>M</given-names></name> (<year>1991</year>) <article-title>A clinical test battery of face processing</article-title>. <source>The International journal of neuroscience</source> <volume>61</volume>: <fpage>19</fpage>–<lpage>30</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Oldfield1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oldfield</surname><given-names>RC</given-names></name> (<year>1971</year>) <article-title>The assessment and analysis of handedness: The Edinburgh inventory</article-title>. <source>Neuropsychologia</source> <volume>9</volume>: <fpage>97</fpage>–<lpage>113</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Teng1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Teng</surname><given-names>EL</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>P-H</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>K-S</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>PC</given-names></name> (<year>1979</year>) <article-title>Lateral preferences for hand, foot and eye, and their lack of association with scholastic achievement, in 4143 Chinese</article-title>. <source>Neuropsychologia</source> <volume>17</volume>: <fpage>41</fpage>–<lpage>48</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Yovel1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>2004</year>) <article-title>Face perception: domain specific, not process specific</article-title>. <source>Neuron</source> <volume>44</volume>: <fpage>889</fpage>–<lpage>898</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Gallichan1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gallichan</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Scholz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bartsch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Robson</surname><given-names>MD</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Addressing a systematic vibration artifact in diffusion-weighted MRI</article-title>. <source>Human Brain Mapping</source> <volume>31</volume>: <fpage>193</fpage>–<lpage>202</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Smith1">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Jenkinson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Beckmann</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title>. <source>Neuroimage</source> <volume>23 Suppl 1</volume>: <fpage>S208</fpage>–<lpage>219</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Woolrich1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Jbabdi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Patenaude</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Chappell</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Makni</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Bayesian analysis of neuroimaging data in FSL</article-title>. <source>Neuroimage</source> <volume>45</volume>: <fpage>S173</fpage>–<lpage>186</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Dale1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dale</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Fischl</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Sereno</surname><given-names>MI</given-names></name> (<year>1999</year>) <article-title>Cortical surface-based analysis. I. Segmentation and surface reconstruction</article-title>. <source>Neuroimage</source> <volume>9</volume>: <fpage>179</fpage>–<lpage>194</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Fischl1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischl</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Sereno</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Dale</surname><given-names>AM</given-names></name> (<year>1999</year>) <article-title>Cortical surface-based analysis. II: Inflation, flattening, and a surface-based coordinate system</article-title>. <source>Neuroimage</source> <volume>9</volume>: <fpage>195</fpage>–<lpage>207</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Jenkinson1">
        <label>47</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jenkinson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bannister</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Brady</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>S</given-names></name> (<year>2002</year>) <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>. <source>Neuroimage</source> <volume>17</volume>: <fpage>825</fpage>–<lpage>841</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Smith2">
        <label>48</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>SM</given-names></name> (<year>2002</year>) <article-title>Fast robust automated brain extraction</article-title>. <source>Hum Brain Mapp</source> <volume>17</volume>: <fpage>143</fpage>–<lpage>155</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Woolrich2">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Ripley</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Brady</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>SM</given-names></name> (<year>2001</year>) <article-title>Temporal autocorrelation in univariate linear modeling of FMRI data</article-title>. <source>Neuroimage</source> <volume>14</volume>: <fpage>1370</fpage>–<lpage>1386</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Greve1">
        <label>50</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greve</surname><given-names>DN</given-names></name>, <name name-style="western"><surname>Fischl</surname><given-names>B</given-names></name> (<year>2009</year>) <article-title>Accurate and robust brain image alignment using boundary-based registration</article-title>. <source>Neuroimage</source> <volume>48</volume>: <fpage>63</fpage>–<lpage>72</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Fischl2">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischl</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Sereno</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Dale</surname><given-names>AM</given-names></name> (<year>1999</year>) <article-title>High-resolution intersubject averaging and a coordinate system for the cortical surface</article-title>. <source>Hum Brain Mapp</source> <volume>8</volume>: <fpage>272</fpage>–<lpage>284</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Beckmann1">
        <label>52</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beckmann</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Jenkinson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>SM</given-names></name> (<year>2003</year>) <article-title>General multilevel linear modeling for group analysis in FMRI</article-title>. <source>Neuroimage</source> <volume>20</volume>: <fpage>1052</fpage>–<lpage>1063</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Nichols1">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nichols</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Holmes</surname><given-names>AP</given-names></name> (<year>2002</year>) <article-title>Nonparametric permutation tests for functional neuroimaging: a primer with examples</article-title>. <source>Hum Brain Mapp</source> <volume>15</volume>: <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hayasaka1">
        <label>54</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayasaka</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Nichols</surname><given-names>TE</given-names></name> (<year>2003</year>) <article-title>Validating cluster size inference: random field and permutation methods</article-title>. <source>Neuroimage</source> <volume>20</volume>: <fpage>2343</fpage>–<lpage>2356</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hayasaka2">
        <label>55</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayasaka</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Nichols</surname><given-names>TE</given-names></name> (<year>2004</year>) <article-title>Combining voxel intensity and cluster extent with permutation test framework</article-title>. <source>Neuroimage</source> <volume>23</volume>: <fpage>54</fpage>–<lpage>63</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ernst1">
        <label>56</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname><given-names>DM</given-names></name> (<year>2004</year>) <article-title>Permutation Methods: A Basis for Exact Inference</article-title>. <source>Statistical Science</source> <volume>19</volume>: <fpage>676</fpage>–<lpage>685</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hagler1">
        <label>57</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagler</surname><given-names>DJ</given-names><suffix>Jr</suffix></name>, <name name-style="western"><surname>Saygin</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Sereno</surname><given-names>MI</given-names></name> (<year>2006</year>) <article-title>Smoothing and cluster thresholding for cortical surface-based group analysis of fMRI data</article-title>. <source>Neuroimage</source> <volume>33</volume>: <fpage>1093</fpage>–<lpage>1103</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Behrens1">
        <label>58</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Berg</surname><given-names>HJ</given-names></name>, <name name-style="western"><surname>Jbabdi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MF</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name> (<year>2007</year>) <article-title>Probabilistic diffusion tractography with multiple fibre orientations: What can we gain?</article-title> <source>Neuroimage</source> <volume>34</volume>: <fpage>144</fpage>–<lpage>155</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Barron1">
        <label>59</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barron</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Fleet</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Beauchemin</surname><given-names>SS</given-names></name> (<year>1994</year>) <article-title>Performance of optical flow techniques</article-title>. <source>International Journal of Computer Vision</source> <volume>12</volume>: <fpage>43</fpage>–<lpage>77</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Horn1">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Horn</surname><given-names>BKP</given-names></name>, <name name-style="western"><surname>Schunck</surname><given-names>BG</given-names></name> (<year>1981</year>) <article-title>Determining optical flow</article-title>. <source>Artificial Intelligence</source> <volume>17</volume>: <fpage>185</fpage>–<lpage>203</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Stevens1">
        <label>61</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stevens</surname><given-names>SS</given-names></name> (<year>1957</year>) <article-title>On the psychophysical law</article-title>. <source>Psychological Review</source> <volume>64</volume>: <fpage>153</fpage>–<lpage>181</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-George2">
        <label>62</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>George</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Hole</surname><given-names>GJ</given-names></name> (<year>1998</year>) <article-title>The influence of feature-based information in the age processing of unfamiliar faces</article-title>. <source>Perception</source> <volume>27</volume>: <fpage>295</fpage>–<lpage>312</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ramanathan2">
        <label>63</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramanathan</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Chellappa</surname><given-names>R</given-names></name> (<year>2006</year>) <article-title>Face verification across age progression</article-title>. <source>IEEE Trans Image Process</source> <volume>15</volume>: <fpage>3349</fpage>–<lpage>3361</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Park1">
        <label>64</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Park</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Tong</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Jain</surname><given-names>AK</given-names></name> (<year>2010</year>) <article-title>Age-invariant face recognition</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <volume>32</volume>: <fpage>947</fpage>–<lpage>954</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ebner1">
        <label>65</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ebner</surname><given-names>NC</given-names></name> (<year>2008</year>) <article-title>Age of face matters: age-group differences in ratings of young and old faces</article-title>. <source>Behav Res Methods</source> <volume>40</volume>: <fpage>130</fpage>–<lpage>136</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Zeki1">
        <label>66</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeki</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Watson</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Lueck</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Kennard</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>1991</year>) <article-title>A direct demonstration of functional specialization in human visual cortex</article-title>. <source>J Neurosci</source> <volume>11</volume>: <fpage>641</fpage>–<lpage>649</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tootell2">
        <label>67</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Reppas</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Kwong</surname><given-names>KK</given-names></name>, <name name-style="western"><surname>Malach</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Born</surname><given-names>RT</given-names></name>, <etal>et al</etal>. (<year>1995</year>) <article-title>Functional analysis of human MT and related visual cortical areas using magnetic resonance imaging</article-title>. <source>J Neurosci</source> <volume>15</volume>: <fpage>3215</fpage>–<lpage>3230</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tootell3">
        <label>68</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Hadjikhani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>EK</given-names></name>, <name name-style="western"><surname>Marrett</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Vanduffel</surname><given-names>W</given-names></name>, <etal>et al</etal>. (<year>1998</year>) <article-title>The retinotopy of visual spatial attention</article-title>. <source>Neuron</source> <volume>21</volume>: <fpage>1409</fpage>–<lpage>1422</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Morrone1">
        <label>69</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morrone</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Tosetti</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Montanaro</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Fiorentini</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Cioni</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>A cortical area that responds specifically to optic flow, revealed by fMRI</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>1322</fpage>–<lpage>1328</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Vanduffel1">
        <label>70</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vanduffel</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Fize</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Peuskens</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Denys</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sunaert</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Extracting 3D from motion: differences in human and monkey intraparietal cortex</article-title>. <source>Science</source> <volume>298</volume>: <fpage>413</fpage>–<lpage>415</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tootell4">
        <label>71</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Hadjikhani</surname><given-names>NK</given-names></name>, <name name-style="western"><surname>Vanduffel</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>AK</given-names></name>, <name name-style="western"><surname>Mendola</surname><given-names>JD</given-names></name>, <etal>et al</etal>. (<year>1998</year>) <article-title>Functional analysis of primary visual cortex (V1) in humans</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>95</volume>: <fpage>811</fpage>–<lpage>817</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tootell5">
        <label>72</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>RB</given-names></name>, <name name-style="western"><surname>Hadjikhani</surname><given-names>N</given-names></name> (<year>2001</year>) <article-title>Where is ‘dorsal V4’ in human visual cortex? Retinotopic, topographic and functional evidence</article-title>. <source>Cereb Cortex</source> <volume>11</volume>: <fpage>298</fpage>–<lpage>311</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-VanEssen1">
        <label>73</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Essen</surname><given-names>DC</given-names></name> (<year>2005</year>) <article-title>A Population-Average, Landmark- and Surface-based (PALS) atlas of human cerebral cortex</article-title>. <source>Neuroimage</source> <volume>28</volume>: <fpage>635</fpage>–<lpage>662</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Sergent1">
        <label>74</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sergent</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ohta</surname><given-names>S</given-names></name>, <name name-style="western"><surname>MacDonald</surname><given-names>B</given-names></name> (<year>1992</year>) <article-title>Functional neuroanatomy of face and object processing. A positron emission tomography study</article-title>. <source>Brain</source> <volume>115 Pt 1</volume>: <fpage>15</fpage>–<lpage>36</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Dejerine1">
        <label>75</label>
        <mixed-citation publication-type="other" xlink:type="simple">Dejerine J, Dejerine-Klumpke AM (1895) Anatomie des centres nerveux. Paris: Rueff &amp; Cie. pp. 757–758, 778–783.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Duvernoy1">
        <label>76</label>
        <mixed-citation publication-type="other" xlink:type="simple">Duvernoy HM (1999) The human brain. Surface, blood supply, and three-dimensional sectional anatomy. Wien: Springer. pp. 6, 13, 394–397, 463–473.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Noback1">
        <label>77</label>
        <mixed-citation publication-type="other" xlink:type="simple">Noback CR, Demarest RJ (1975) The human nervous system: basic principles of neurobiology. New York: McGraw-Hill. p. 451.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ross1">
        <label>78</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>J</given-names></name> (<year>1883</year>) <article-title>Reviews and notices of books - Lehrbuch der Gehirnkrankheiten für Aerzte und Studierende. Von Dr. C. Wernicke. 3 vols. Fischer, Kassel, 1881–1883. (see vol. 1, p. 23)</article-title>. <source>Brain</source> <volume>6</volume>: <fpage>398</fpage>–<lpage>403</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Wernicke1">
        <label>79</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wernicke</surname><given-names>C</given-names></name> (<year>1877</year>) <article-title>XX. Sitzung am 12. Januar 1877</article-title>. <source>Verhandlungen der Physiologischen Gesellschaft zu Berlin Jahrgang I und II (XX Sitzung am 12 Januar 1877) printed in: Deutsche Medizinische Wochenschrift</source> <volume>12</volume>: <fpage>2</fpage>–<lpage>4</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Sachs1">
        <label>80</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sachs H (1892) Das Hemisphärenmark des menschlichen Grosshirns. 1. Der Hinterhauptslappen. Leipzig: Thieme. pp. 6, 8–9, 15–19, 23–24, 26–27, 29, Phot.1–6.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Quain1">
        <label>81</label>
        <mixed-citation publication-type="other" xlink:type="simple">Quain J (1891) Quain's Elements of anatomy, Vol. III. Part I., The Spinal Cord And Brain; Sharpey-Schäfer EA, Sir, Thane GD, editors. London: Longmans, Green and Co. pp. 165–166.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Ebner2">
        <label>82</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ebner</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Gluth</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Raye</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Mitchell</surname><given-names>KM</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Medial prefrontal cortex activity when thinking about others depends on their age</article-title>. <source>Neurocase</source> <volume>17</volume>: <fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Calder1">
        <label>83</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calder</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>AW</given-names></name> (<year>2005</year>) <article-title>Understanding the recognition of facial identity and facial expression</article-title>. <source>Nat Rev Neurosci</source> <volume>6</volume>: <fpage>641</fpage>–<lpage>651</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Oishi1">
        <label>84</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oishi</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Zilles</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Amunts</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Faria</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Human brain white matter atlas: Identification and assignment of common anatomical structures in superficial white matter</article-title>. <source>Neuroimage</source> <volume>43</volume>: <fpage>447</fpage>–<lpage>457</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Greenblatt1">
        <label>85</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenblatt</surname><given-names>SH</given-names></name> (<year>1973</year>) <article-title>Alexia without agraphia or hemianopsia. Anatomical analysis of an autopsied case</article-title>. <source>Brain</source> <volume>96</volume>: <fpage>307</fpage>–<lpage>316</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-ffytche1">
        <label>86</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>ffytche</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Catani</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Beyond localization: from hodology to function</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>360</volume>: <fpage>767</fpage>–<lpage>779</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Jbabdi1">
        <label>87</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jbabdi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Johansen-Berg</surname><given-names>H</given-names></name> (<year>2011</year>) <article-title>Tractography: Where do we go from here?</article-title> <source>Brain Connectivity</source> (In Press).</mixed-citation>
      </ref>
      <ref id="pone.0049451-Hoffman1">
        <label>88</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hoffman</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name> (<year>2000</year>) <article-title>Distinct representations of eye gaze and identity in the distributed human neural system for face perception</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>80</fpage>–<lpage>84</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Gauthier1">
        <label>89</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gauthier</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Tarr</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Moylan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Skudlarski</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Gore</surname><given-names>JC</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>The fusiform “face area” is part of a network that processes faces at the individual level</article-title>. <source>J Cogn Neurosci</source> <volume>12</volume>: <fpage>495</fpage>–<lpage>504</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-GrillSpector1">
        <label>90</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Knouf</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>2004</year>) <article-title>The fusiform face area subserves face perception, not generic within-category identification</article-title>. <source>Nat Neurosci</source> <volume>7</volume>: <fpage>555</fpage>–<lpage>562</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Loffler1">
        <label>91</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loffler</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Yourganov</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Wilkinson</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name> (<year>2005</year>) <article-title>fMRI evidence for the neural representation of faces</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1386</fpage>–<lpage>1390</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Kanwisher1">
        <label>92</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>The fusiform face area: a cortical region specialized for the perception of faces</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>361</volume>: <fpage>2109</fpage>–<lpage>2128</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Haist1">
        <label>93</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haist</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Stiles</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Individuating Faces and Common Objects Produces Equal Responses in Putative Face Processing Areas in the Ventral Occipitotemporal Cortex</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>4</volume>: <fpage>181</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Kaul1">
        <label>94</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaul</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Ishai</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>The Gender of Face Stimuli is Represented in Multiple Regions in the Human Brain</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>4</volume>: <fpage>238</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Winston1">
        <label>95</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Winston</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Henson</surname><given-names>RN</given-names></name>, <name name-style="western"><surname>Fine-Goulden</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2004</year>) <article-title>fMRI-adaptation reveals dissociable neural representations of identity and expression in face perception</article-title>. <source>J Neurophysiol</source> <volume>92</volume>: <fpage>1830</fpage>–<lpage>1839</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-CohenKadosh1">
        <label>96</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen Kadosh</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Henson</surname><given-names>RN</given-names></name>, <name name-style="western"><surname>Cohen Kadosh</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>MH</given-names></name>, <name name-style="western"><surname>Dick</surname><given-names>F</given-names></name> (<year>2009</year>) <article-title>Task-dependent activation of face-sensitive cortex: an fMRI adaptation study</article-title>. <source>J Cogn Neurosci</source> <volume>22</volume>: <fpage>903</fpage>–<lpage>917</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Jbabdi2">
        <label>97</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jbabdi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name> (<year>2012</year>) <article-title>Specialization: the connections have it</article-title>. <source>Nature neuroscience</source> <volume>15</volume>: <fpage>171</fpage>–<lpage>172</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Walsh1">
        <label>98</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Walsh</surname><given-names>V</given-names></name> (<year>2003</year>) <article-title>A theory of magnitude: common cortical metrics of time, space and quantity</article-title>. <source>Trends Cogn Sci</source> <volume>7</volume>: <fpage>483</fpage>–<lpage>488</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Cantlon1">
        <label>99</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cantlon</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Platt</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Brannon</surname><given-names>EM</given-names></name> (<year>2009</year>) <article-title>Beyond the number domain</article-title>. <source>Trends Cogn Sci</source> <volume>13</volume>: <fpage>83</fpage>–<lpage>91</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-DeRenzi2">
        <label>100</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Renzi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Bonacini</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>Faglioni</surname><given-names>P</given-names></name> (<year>1989</year>) <article-title>Right posterior brain-damaged patients are poor at assessing the age of a face</article-title>. <source>Neuropsychologia</source> <volume>27</volume>: <fpage>839</fpage>–<lpage>848</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Gbel1">
        <label>101</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Göbel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Walsh</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name> (<year>2001</year>) <article-title>The Mental Number Line and the Human Angular Gyrus</article-title>. <source>Neuroimage</source> <volume>14</volume>: <fpage>1278</fpage>–<lpage>1289</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Gbel2">
        <label>102</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Göbel</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MF</given-names></name>, <name name-style="western"><surname>Walsh</surname><given-names>V</given-names></name> (<year>2006</year>) <article-title>Inferior parietal rTMS affects performance in an addition task</article-title>. <source>Cortex</source> <volume>42</volume>: <fpage>774</fpage>–<lpage>781</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Grabner1">
        <label>103</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grabner</surname><given-names>RH</given-names></name>, <name name-style="western"><surname>Ansari</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Reishofer</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Stern</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ebner</surname><given-names>F</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Individual differences in mathematical competence predict parietal brain activation during mental calculation</article-title>. <source>Neuroimage</source> <volume>38</volume>: <fpage>346</fpage>–<lpage>356</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Barton1">
        <label>104</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barton</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Press</surname><given-names>DZ</given-names></name>, <name name-style="western"><surname>Keenan</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>O'Connor</surname><given-names>M</given-names></name> (<year>2002</year>) <article-title>Lesions of the fusiform face area impair perception of facial configuration in prosopagnosia</article-title>. <source>Neurology</source> <volume>58</volume>: <fpage>71</fpage>–<lpage>78</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Perrett1">
        <label>105</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perrett</surname><given-names>DI</given-names></name>, <name name-style="western"><surname>Penton-Voak</surname><given-names>IS</given-names></name>, <name name-style="western"><surname>Little</surname><given-names>AC</given-names></name>, <name name-style="western"><surname>Tiddeman</surname><given-names>BP</given-names></name>, <name name-style="western"><surname>Burt</surname><given-names>DM</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Facial attractiveness judgements reflect learning of parental age characteristics</article-title>. <source>Proceedings Biological sciences/The Royal Society</source> <volume>269</volume>: <fpage>873</fpage>–<lpage>880</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Winston2">
        <label>106</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Winston</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Kilner</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Perrett</surname><given-names>DI</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2007</year>) <article-title>Brain systems for assessing facial attractiveness</article-title>. <source>Neuropsychologia</source> <volume>45</volume>: <fpage>195</fpage>–<lpage>206</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Kampe1">
        <label>107</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kampe</surname><given-names>KK</given-names></name>, <name name-style="western"><surname>Frith</surname><given-names>CD</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Frith</surname><given-names>U</given-names></name> (<year>2001</year>) <article-title>Reward value of attractiveness and gaze</article-title>. <source>Nature</source> <volume>413</volume>: <fpage>589</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Aharon1">
        <label>108</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aharon</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Etcoff</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Ariely</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Chabris</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>O'Connor</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Beautiful faces have variable reward value: fMRI and behavioral evidence</article-title>. <source>Neuron</source> <volume>32</volume>: <fpage>537</fpage>–<lpage>551</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Liang1">
        <label>109</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zebrowitz</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name> (<year>2010</year>) <article-title>Neural activation in the “reward circuit” shows a nonlinear response to facial attractiveness</article-title>. <source>Social neuroscience</source> <volume>5</volume>: <fpage>320</fpage>–<lpage>334</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Tsukiura1">
        <label>110</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsukiura</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Cabeza</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Shared brain activity for aesthetic and moral judgments: implications for the Beauty-is-Good stereotype</article-title>. <source>Social cognitive and affective neuroscience</source> <volume>6</volume>: <fpage>138</fpage>–<lpage>148</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Furl2">
        <label>111</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furl</surname><given-names>N</given-names></name>, <name name-style="western"><surname>van Rijsbergen</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Modulation of perception and brain activity by predictable trajectories of facial expressions</article-title>. <source>Cereb Cortex</source> <volume>20</volume>: <fpage>694</fpage>–<lpage>703</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Wandell1">
        <label>112</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Winawer</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Imaging retinotopic maps in the human brain</article-title>. <source>Vision research</source> <volume>51</volume>: <fpage>718</fpage>–<lpage>737</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049451-vonEconomo1">
        <label>113</label>
        <mixed-citation publication-type="other" xlink:type="simple">von Economo C (1927) Zellaufbau der Grosshirnrinde des Menschen. Berlin: Springer. pp. 2–78, 84–107.</mixed-citation>
      </ref>
      <ref id="pone.0049451-Brodmann1">
        <label>114</label>
        <mixed-citation publication-type="other" xlink:type="simple">Brodmann K (1909) Vergleichende Lokalisationslehre der Großhirnrinde in ihren Prinzipien dargestellt auf Grund des Zellenbaues. Leipzig: J. A. Barth. pp. 131–143, 230.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>