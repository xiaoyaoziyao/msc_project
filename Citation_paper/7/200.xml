<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0117126</article-id>
<article-id pub-id-type="publisher-id">PONE-D-14-09662</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Successful Decoding of Famous Faces in the Fusiform Face Area</article-title>
<alt-title alt-title-type="running-head">Successful Decoding of Famous Faces in the Fusiform Face Area</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Axelrod</surname>
<given-names>Vadim</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Yovel</surname>
<given-names>Galit</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>School of Psychological Sciences, Tel Aviv University, Tel Aviv, Israel</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>School of Neuroscience, Tel Aviv University, Tel Aviv, Israel</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Barton</surname>
<given-names>Jason Jeremy Sinclair</given-names>
</name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of British Columbia, CANADA</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: VA GY. Performed the experiments: VA. Analyzed the data: VA. Contributed reagents/materials/analysis tools: VA. Wrote the paper: VA GY.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">vadim.axelrod@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>25</day>
<month>2</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<year>2015</year>
</pub-date>
<volume>10</volume>
<issue>2</issue>
<elocation-id>e0117126</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>3</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>12</month>
<year>2014</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Axelrod, Yovel</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0117126" xlink:type="simple"/>
<abstract>
<p>What are the neural mechanisms of face recognition? It is believed that the network of face-selective areas, which spans the occipital, temporal, and frontal cortices, is important in face recognition. A number of previous studies indeed reported that face identity could be discriminated based on patterns of multivoxel activity in the fusiform face area and the anterior temporal lobe. However, given the difficulty in localizing the face-selective area in the anterior temporal lobe, its role in face recognition is still unknown. Furthermore, previous studies limited their analysis to occipito-temporal regions without testing identity decoding in more anterior face-selective regions, such as the amygdala and prefrontal cortex. In the current high-resolution functional Magnetic Resonance Imaging study, we systematically examined the decoding of the identity of famous faces in the temporo-frontal network of face-selective and adjacent non-face-selective regions. A special focus has been put on the face-area in the anterior temporal lobe, which was reliably localized using an optimized scanning protocol. We found that face-identity could be discriminated above chance level only in the fusiform face area. Our results corroborate the role of the fusiform face area in face recognition. Future studies are needed to further explore the role of the more recently discovered anterior face-selective areas in face recognition.</p>
</abstract>
<funding-group>
<funding-statement>VA was supported by PhD fellowship from the Levie -Edersheim - Gitter Institute. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="2"/>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Faces are recognized quickly and effortlessly. Over the past two decades, the underlying neural mechanisms of face processing have become gradually elucidated. In particular, a highly established finding in neuroimaging studies is the occipito-temporal network of face-selective regions: occipital face area (OFA) [<xref rid="pone.0117126.ref001" ref-type="bibr">1</xref>], the fusiform face area (FFA) [<xref rid="pone.0117126.ref002" ref-type="bibr">2</xref>] and the posterior superior temporal sulcus (pSTS)[<xref rid="pone.0117126.ref003" ref-type="bibr">3</xref>]. More recently, three more anterior regions have been reported to show face-selective responses. This includes face-selective areas in the anterior temporal lobe (ATL) [<xref rid="pone.0117126.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0117126.ref005" ref-type="bibr">5</xref>], the amygdala [<xref rid="pone.0117126.ref006" ref-type="bibr">6</xref>–<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>] and the prefrontal cortex [<xref rid="pone.0117126.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0117126.ref010" ref-type="bibr">10</xref>]. Notably, whereas all these regions clearly show a higher response to faces than non-face stimuli, their role in discriminating between different face identities is still unclear.</p>
<p>To date, although no clear picture has emerged, a number of imaging studies have suggested that the FFA [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>–<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>] (but see: [<xref rid="pone.0117126.ref016" ref-type="bibr">16</xref>–<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>]) and the ATL [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>,<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>–<xref rid="pone.0117126.ref025" ref-type="bibr">25</xref>] might play a role in face recognition. However, empirical evidence regarding the ATL is especially complex. In particular, while the face-selective ATL was implicated in face recognition [<xref rid="pone.0117126.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0117126.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0117126.ref020" ref-type="bibr">20</xref>,<xref rid="pone.0117126.ref021" ref-type="bibr">21</xref>,<xref rid="pone.0117126.ref026" ref-type="bibr">26</xref>–<xref rid="pone.0117126.ref028" ref-type="bibr">28</xref>], the face-selectivity (higher response to face than to non-faces) of the clusters in the ATL that discriminated between face identities has not been tested [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>–<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>]. This discrepancy might stem from severe magnetic susceptibility artifacts in the ATL (e.g., [<xref rid="pone.0117126.ref029" ref-type="bibr">29</xref>,<xref rid="pone.0117126.ref030" ref-type="bibr">30</xref>]) and consequently low reliability of the face-selective responses reported in this area. In contrast to the unclear findings with respect to the processing of face identity in the human face-selective ATL, studies of the monkey face-selective areas have shown clear identity selective view-invariant tuning in the most anterior face patch—AM [<xref rid="pone.0117126.ref027" ref-type="bibr">27</xref>]—which may be the human homologue of the face-selective area in the anterior temporal lobe [<xref rid="pone.0117126.ref031" ref-type="bibr">31</xref>]. Finally, previous studies have focused only on occipital and ventral temporal regions, while the role of additional anterior face-selective regions in face recognition, such as the amygdala and prefrontal cortex, has not been tested.</p>
<p>In the current high-resolution fMRI study, we systematically explored the role of temporo-frontal face-selective regions (FFA, posterior superior temporal sulcus (STS), ATL face-area, amygdala, and prefrontal cortex; <xref rid="pone.0117126.g001" ref-type="fig">Fig. 1</xref>) in recognition of famous faces. Participants were presented with 8 different images of each of two famous faces. We conducted Region of Interest (ROI) Univariate and Multivoxel Pattern Analysis (MVPA) [<xref rid="pone.0117126.ref032" ref-type="bibr">32</xref>] to determine the role of face-selective and adjacent non-face areas in discriminating between these two famous identities. A special emphasis was put on the ATL face-area, which was reliably localized using recently proposed scanning optimization [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. In addition, in contrast to previous identity decoding studies that used unfamiliar faces [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>,<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>], we used familiar (famous) identities as they 1) are better discriminated behaviorally [<xref rid="pone.0117126.ref033" ref-type="bibr">33</xref>,<xref rid="pone.0117126.ref034" ref-type="bibr">34</xref>]; 2) exhibit enhanced invariant neural face representation (e.g., view-invariance) [<xref rid="pone.0117126.ref035" ref-type="bibr">35</xref>–<xref rid="pone.0117126.ref037" ref-type="bibr">37</xref>]; and 3) are more likely to be discriminated in the ATL, given that the ATL is known to be involved in semantic processing [<xref rid="pone.0117126.ref038" ref-type="bibr">38</xref>].</p>
<fig id="pone.0117126.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Face-selective areas of one representative participant (inflated cortex, right hemisphere).</title>
<p>(A) Lateral brain view: posterior STS and prefrontal face-selective areas. (B) Ventral brain view: FFA, ATL face-area and amygdala face-selective areas.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g001" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec003">
<title>Apparatus</title>
<p>MRI data were collected using a 3T GE MRI scanner with an 8-channel head coil. Echo planar imaging sequence includes the following parameters: TR = 2 sec, TE = 30 ms, flip angle: 90, slice thickness: 2.4 mm no gap, FOV 200 mm, data was acquired using 96x96 matrix (in plane resolution 2.08x2.08 mm), reconstruct into 128x128 matrix (in plane resolution 1.56x1.56 mm). Slices orientation was coronal, parallel to brain stem [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. Number of slices was varied between participants from 23 to 25 slices (the maximal number of slices per participant according to slice orientation described above). The scanning was executed using a multislab method [<xref rid="pone.0117126.ref039" ref-type="bibr">39</xref>], where first slab comprised of 11 slices and covered anterior temporal region ventrally with parts of the frontal lobes dorsally. The remaining 12–14 slices covered mid-temporal areas ventrally and part of the parietal lobe dorsally. The coronal slice prescription has been shown to improve magnetic susceptibly in the ATL [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. Anatomical SPGR images (full brain coverage) were collected with 1x1x1 mm resolution (TE = 3.52 ms, TR = 9.104 ms). LCD projector (NEC, VT660K) was used for projecting the stimuli. Projector was positioned ahead of the participant and the stimuli were viewed through a tilted mirror mounted on the MR head coil. Fiber-optic MR-compatible response box (Current Designs, Philadelphia, PA) has been used to register behavioral responses during scanning.</p>
</sec>
<sec id="sec004">
<title>Participants</title>
<p>18 healthy volunteers (age: 18–40, 11 females, all right-handed) participated in the experiment. One participant was excluded from the analysis due to excessive movements in the scanner (&gt;1 cm). All participants gave informed consent to participate in the study. The study was approved by the ethics committee of the Tel Aviv Sourasky Medical Center. Participants provided written informed consent to participate in this study. Data from 9 participants was also used in different analysis in our recent publication [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>].</p>
</sec>
<sec id="sec005">
<title>Experimental Stimuli</title>
<p>The experiment included images of two categories: faces and cups. All the images were grey-scaled. The faces were of two Israeli highly familiar politicians: Benjamin Netanyahu (the prime minister of Israel) and Shimon Peres (the president of Israel) (<xref rid="pone.0117126.g002" ref-type="fig">Fig. 2A</xref>); the cups were of two different types (<xref rid="pone.0117126.g002" ref-type="fig">Fig. 2B</xref>). We verified with each of the participants before including them in the experiment that they are familiar with the two famous faces included in the experiment. Each face identity/cup type was represented by 8 different images. The face pictures were taken on different occasions mostly from front view (up to ∼10° of view angle rotation) with neutral expression. The cups were pictures taken from different views. Face images were collected from various Internet sources. Images of cups were from ETH80 dataset (<ext-link ext-link-type="uri" xlink:href="https://www.d2.mpi-inf.mpg.de/Datasets/ETH80" xlink:type="simple">https://www.d2.mpi-inf.mpg.de/Datasets/ETH80</ext-link>) [<xref rid="pone.0117126.ref040" ref-type="bibr">40</xref>]. The pictures of faces and cups were first cropped from the background. Then luminance and color between all images was adjusted using “match color” function of Photoshop CS2. Finally, a white monotonic background was added to all images. The size of all stimuli was 7x7 degrees of visual angle.</p>
<fig id="pone.0117126.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g002</object-id>
<label>Fig 2</label>
<caption>
<title>The face and cup stimuli used in the experiment.</title>
<p>(A) Eight images of Benjamin Netanyahu (the prime minister of Israel) and eight images of Shimon Peres (the president of Israel). (B) Eight images of two cup types.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g002" position="float" xlink:type="simple"/>
</fig>
<p>To test for low-level differences between stimuli we conducted image similarity analysis. We first examined whether there are any systematic low-level differences between the two sets of images of two face identities. To that extent, we calculated image pixel correlation (e.g., [<xref rid="pone.0117126.ref041" ref-type="bibr">41</xref>,<xref rid="pone.0117126.ref042" ref-type="bibr">42</xref>]). First, for each face identity image set, we calculated pixel correlation within the image set (28 image pairs for each set). Average pixel correlation within face identity image set 1 was 0.817 (MSE: 0.005) and within face identity image set 2 was 0.828 (MSE: 0.007). The difference between the pixel correlation of two image sets was insignificant (two-tailed t-test: t(54) = 1.23, p = 0.22). Next, we calculated pixel correlation across identity image sets (64 image pairs). The correlation was 0.813 (MSE: 0.004). Critically, there was an insignificant difference for pixel correlation between and within image sets (identity 1 vs. between identities: t(66) &lt; 1; identity 2 vs. between identities: t(47) = 1.69, p = 0.096; two-tailed t-test with unequal variance [<xref rid="pone.0117126.ref043" ref-type="bibr">43</xref>]). Taken together, we conclude that there is no evidence that two sets of identities differ in their low-level image-based properties.</p>
<p>The same analysis was conducted for two image sets of cup stimuli. Average pixel correlation within cup type 1 was 0.692 (MSE: 0.022) and within cup type 2 was 0.70 (MSE: 0.018). The difference between the pixel correlation of the two image sets was insignificant (two-tailed t-test: t(54) &lt; 1). Pixel correlation across cup image sets (64 image pairs) was 0.64 (MSE: 0.008). The pixel correlation between image sets was significantly lower than within image sets (cup 1 vs. between cup types: t(35) = 2.02, p = 0.05; cup 2 vs. between cup types: t(39) = 2.79, p = 0.008). Thus, we conclude that two types of cups differed in their low-level image-based properties. Notably, discrimination between the two types of cups was not the main focus of the present study.</p>
</sec>
<sec id="sec006" sec-type="materials|methods">
<title>Experimental Design</title>
<p>The stimuli were presented in blocks (block-design). The blocks were of 4 types: two face identities and two cup types. Each block lasted 16 seconds and comprised of 16 images. Each image was presented for 0.3 seconds and the inter-stimulus interval time was 0.7 seconds. To avoid consecutive presentation of two blocks of the same category, blocks within each session were arranged in triplets of either faces-cups-fixation or cups-faces-fixation. The duration of fixation block was 8 seconds. In each session there were 10 face blocks (5 for each identity), 10 cup blocks (5 for each cup type) and 10 fixation blocks. The order of face and cup blocks was counterbalanced. To ensure that the participants pay attention to the stimuli, they were asked to press a response key whenever the same image appeared in two consecutive trials (one-back task). The number of target trials varied from block to block (minimum: 0, maximum: 4). To prevent discrimination based on apparent motion, the location of the stimuli varied across trials with a random jitter of 20 pixels. The total session duration was 6:52 min. Fourteen participants completed 5 sessions and three participants completed 6 sessions.</p>
</sec>
<sec id="sec007">
<title>Data Analysis</title>
<p><bold>Preprocessing.</bold> SPM5 (Wellcome Trust Centre for Neuroimaging, London, UK; <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk" xlink:type="simple">http://www.fil.ion.ucl.ac.uk</ext-link>) was used for data analysis. The functional scans were realigned, motion corrected, normalized to 2x2x2 voxel resolution using MNI template and smoothed with a FWHM = 3 mm kernel. The normalization was done using unified segmentation procedure [<xref rid="pone.0117126.ref044" ref-type="bibr">44</xref>].</p>
<p><bold>Region of Interest independent localization.</bold> Regions of interest were localized using first session (10 blocks of faces and 10 blocks of cups). Face identity and cup type main discrimination analysis was done using all other sessions (see below). For Region of Interest (ROI) localization we estimated GLM model (HRF boxcar function) with two regressors: faces and cups. For defining face-selective regions the faces &gt; cups contrast was used. The face-selective FFA, pSTS, prefrontal cortex were defined using p&lt;0.001, uncorrected threshold and ATL face-area and amygdala were defined using p&lt;0.01, uncorrected threshold. Non-face selective region in the collateral sulcus was defined using cups &gt; faces contrast (p&lt;0.001, uncorrected) [<xref rid="pone.0117126.ref045" ref-type="bibr">45</xref>]. ROIs definition was done using the MarsBaR region of interest toolbox for SPM [<xref rid="pone.0117126.ref046" ref-type="bibr">46</xref>]. Cortical reconstruction of representative participant (inflated cortex map in <xref rid="pone.0117126.g001" ref-type="fig">Fig. 1</xref>) was created using Freesurfer image analysis 4.5 (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/" xlink:type="simple">http://surfer.nmr.mgh.harvard.edu/</ext-link>) [<xref rid="pone.0117126.ref047" ref-type="bibr">47</xref>].</p>
<p>The functional and anatomical ROIs, defined in the previous step had different sizes. It has been previously shown that classification rate might be influenced by the ROI size [<xref rid="pone.0117126.ref042" ref-type="bibr">42</xref>,<xref rid="pone.0117126.ref048" ref-type="bibr">48</xref>–<xref rid="pone.0117126.ref050" ref-type="bibr">50</xref>]. Therefore, it was important to use the same number of voxels for the ROIs of different regions. For the main discrimination analysis (<xref rid="pone.0117126.g003" ref-type="fig">Fig. 3</xref> and <xref rid="pone.0117126.g004" ref-type="fig">Fig. 4</xref>) the ROI comprised of 20 voxels (160 mm<sup>3</sup>), while they were selected as a contiguous cluster of most selective voxels (e.g., [<xref rid="pone.0117126.ref050" ref-type="bibr">50</xref>–<xref rid="pone.0117126.ref052" ref-type="bibr">52</xref>]). Number of participants per region, average z-score and average MNI coordinate is shown in <xref rid="pone.0117126.t001" ref-type="table">Table 1</xref>. For the discrimination analysis with different ROI size (<xref rid="pone.0117126.g005" ref-type="fig">Fig. 5</xref>) the most active voxels with the following size were selected: 10 voxels (80 mm<sup>3</sup>), 30 voxels (240 mm<sup>3</sup>), 40 voxels (320 mm<sup>3</sup>) and 50 voxels (400 mm<sup>3</sup>). For the control analysis we also conducted discrimination using ROIs of full size, before equalization procedure.</p>
<fig id="pone.0117126.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Region of Interest-based face identity discrimination analysis (Benjamin Netanyahu and Shimon Peres identities).</title>
<p>(A) Average percent signal change for two face identities in the different face-selective areas and non-face selective collateral sulcus area. Error bars denote standard error of the mean. (B) Classification rates between face identities in face and non-face selective regions. The black line indicates a chance level of 50%. The error bars denote the standard error of the mean.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g003" position="float" xlink:type="simple"/>
</fig>
<fig id="pone.0117126.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Individual classification rates of identity discrimination analysis in the right FFA.</title>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g004" position="float" xlink:type="simple"/>
</fig>
<fig id="pone.0117126.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Classification rates in face-selective (FFA, pSTS, ATL face-area, prefrontal face-area, amygdala) and non-face selective collateral sulcus area for different ROI sizes (10, 20, 30, 40 and 50 voxels).</title>
<p>The black line indicates a chance level of 50%. The error bars denote the standard error of the mean.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g005" position="float" xlink:type="simple"/>
</fig>
<table-wrap id="pone.0117126.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.t001</object-id>
<label>Table 1</label> <caption><title>Specification of face-selective and object-selective regions of interest (ROIs) used in the main analysis: number of subjects, average ROI z-score contrast value, and MNI coordinates of the localized.</title></caption>
<alternatives>
<graphic id="pone.0117126.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th rowspan="2" align="center" colspan="1">ROIs</th>
<th rowspan="2" align="center" colspan="1">number of participants</th>
<th rowspan="2" align="center" colspan="1">average z-score</th>
<th colspan="3" align="center" rowspan="1">MNI coordinates</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">X</th>
<th align="left" rowspan="1" colspan="1">Y</th>
<th align="left" rowspan="1" colspan="1">Z</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left FFA</bold></td>
<td align="left" rowspan="1" colspan="1">13</td>
<td align="left" rowspan="1" colspan="1">7.03</td>
<td align="left" rowspan="1" colspan="1">-41</td>
<td align="left" rowspan="1" colspan="1">-53</td>
<td align="left" rowspan="1" colspan="1">-18</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right FFA</bold></td>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1">8.50</td>
<td align="left" rowspan="1" colspan="1">39</td>
<td align="left" rowspan="1" colspan="1">-52</td>
<td align="left" rowspan="1" colspan="1">-16</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left pSTS face area</bold></td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">5.6</td>
<td align="left" rowspan="1" colspan="1">-51</td>
<td align="left" rowspan="1" colspan="1">-54</td>
<td align="left" rowspan="1" colspan="1">11</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right pSTS face area</bold></td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">6.5</td>
<td align="left" rowspan="1" colspan="1">52</td>
<td align="left" rowspan="1" colspan="1">-42</td>
<td align="left" rowspan="1" colspan="1">10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left ATL face area</bold></td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">3.16</td>
<td align="left" rowspan="1" colspan="1">-33</td>
<td align="left" rowspan="1" colspan="1">-16</td>
<td align="left" rowspan="1" colspan="1">-37</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right ATL face area</bold></td>
<td align="left" rowspan="1" colspan="1">11</td>
<td align="left" rowspan="1" colspan="1">3.51</td>
<td align="left" rowspan="1" colspan="1">36</td>
<td align="left" rowspan="1" colspan="1">-11</td>
<td align="left" rowspan="1" colspan="1">-40</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left prefrontal face area</bold></td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">4.18</td>
<td align="left" rowspan="1" colspan="1">-43</td>
<td align="left" rowspan="1" colspan="1">19</td>
<td align="left" rowspan="1" colspan="1">27</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right prefrontal face area</bold></td>
<td align="left" rowspan="1" colspan="1">13</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">44</td>
<td align="left" rowspan="1" colspan="1">19</td>
<td align="left" rowspan="1" colspan="1">26</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left amygdala face area</bold></td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">2.88</td>
<td align="left" rowspan="1" colspan="1">-19</td>
<td align="left" rowspan="1" colspan="1">-3</td>
<td align="left" rowspan="1" colspan="1">-16</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right amygdala face area</bold></td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">3.43</td>
<td align="left" rowspan="1" colspan="1">21</td>
<td align="left" rowspan="1" colspan="1">-3</td>
<td align="left" rowspan="1" colspan="1">-17</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left COS object area</bold></td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">-4.59</td>
<td align="left" rowspan="1" colspan="1">-29</td>
<td align="left" rowspan="1" colspan="1">-55</td>
<td align="left" rowspan="1" colspan="1">-11</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right COS object area</bold></td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">-4.39</td>
<td align="left" rowspan="1" colspan="1">29</td>
<td align="left" rowspan="1" colspan="1">-52</td>
<td align="left" rowspan="1" colspan="1">-10</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>Size of all ROIs was 20 voxels (160 mm<sup>3</sup>).</p></fn>
</table-wrap-foot>
</table-wrap>
<p><bold>Face identities discrimination analysis.</bold> The data in this analysis included all sessions except for the first session, which was used for the functional localization.</p>
</sec>
<sec id="sec008">
<title>Univariate analysis</title>
<p>For the univariate analysis, we estimated GLM model (HRF boxcar function) with four regressors: face identities 1,2 and cup types 1,2. This model was used to calculate percent signal change for each condition (for each face identity or cup type) within the predefined ROIs (<xref rid="pone.0117126.g003" ref-type="fig">Fig. 3A</xref> and <xref rid="pone.0117126.g006" ref-type="fig">Fig. 6A</xref>). Time courses were extracted for each of four regressors (identity 1,2 and cup type 1,2). Block plateau values (from TR = 4 to TR = 10 from block onset) were averaged and submitted to paired t-test analysis (SPSS 17). Time courses were extracted using the MarsBaR region of interest toolbox for SPM [<xref rid="pone.0117126.ref046" ref-type="bibr">46</xref>].</p>
<fig id="pone.0117126.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Region of Interest discrimination analysis for cups.</title>
<p>(A) Average percent signal change for two cup types in the face-selective areas and non-face selective collateral sulcus area. Error bars denote standard error of the mean. (B) Classification rates between two cup types in face and non-face selective regions. The black line indicates a chance level of 50%. The error bars denote the standard error of the mean.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g006" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec009">
<title>Multivoxel ROI pattern analysis</title>
<p>The Multivoxel Pattern Classification analysis procedure was similar to what was used in our previous studies [<xref rid="pone.0117126.ref050" ref-type="bibr">50</xref>,<xref rid="pone.0117126.ref052" ref-type="bibr">52</xref>]. Raw intensity values were used for pattern classification analysis. In the multivariate analysis we also used normalized data because 1) this allowed us to compare between univariate and multivariate results; 2) our preliminary data analyses show that there is no benefit for using non-normalized data for classification. The pattern classification data was detrended and normalized using z-score MATLAB function [<xref rid="pone.0117126.ref053" ref-type="bibr">53</xref>]. This procedure was applied for the full session voxel time course (for each session separately). In addition, the time course was shifted two TRs (4 seconds) to account for hemodynamic lag. For each of the four classes (two face identities and two cup types), the mean intensity (global signal) for the condition was subtracted from the voxel intensity value [<xref rid="pone.0117126.ref054" ref-type="bibr">54</xref>]. This procedure was performed separately for the data from each session so no information leakage occurs in a cross-validation procedure. Subtraction of the global average has been previously suggested to improve multivoxel prediction [<xref rid="pone.0117126.ref055" ref-type="bibr">55</xref>]. Each session consisted of 5 blocks per class, with 8 TRs per block. For each experimental block the preceding block could be either fixation or experimental block, which created a contamination of the beginning of the block [<xref rid="pone.0117126.ref056" ref-type="bibr">56</xref>]. Our preliminary pilots showed that first two volumes of the block were the most contaminated and therefore they were discarded. The remaining 6 TRs data points were averaged resulting in a single data point per block. The leave-one-session-out cross-validation procedure was repeated according to number of sessions completed by subject. The classification package was the LibSVM MATLAB implementation of the linear support vector machine (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/∼cjlin/libsvm/" xlink:type="simple">http://www.csie.ntu.edu.tw/∼cjlin/libsvm/</ext-link>). The pattern classification analysis was performed using a custom made MATLAB code [<xref rid="pone.0117126.ref053" ref-type="bibr">53</xref>]. Significance of the classification results was established as a group level one-tail t-test above the chance of the individual classification rates [<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0117126.ref042" ref-type="bibr">42</xref>,<xref rid="pone.0117126.ref057" ref-type="bibr">57</xref>] with Bonferroni correction for multiple comparisons according to the number of regions: p = 0.05/12 = 0.004.</p>
<p><bold>Multivoxel search-light pattern analysis in the ATL.</bold> Analysis was limited to the ATL region. The brain volume used in the analysis was defined as scanned volume that was in overlap with Brodmann Areas 20 and 38 (<ext-link ext-link-type="uri" xlink:href="http://fmri.wfubmc.edu/software/PickAtlas" xlink:type="simple">http://fmri.wfubmc.edu/software/PickAtlas</ext-link> [<xref rid="pone.0117126.ref058" ref-type="bibr">58</xref>]). Notably, anterior portion of the ATL (approximately more anterior MNI Y coordinate = 0) has not been included in the analysis as it has not been covered with our slice prescription. The search-light size was 27-voxel size (3x3x3 voxels box = 216 mm<sup>3</sup>). Classification was performed on individual subject data. The search-light was moved iteratively over the ATL with 1 voxel step each time. In each step a search-light classification rate was assigned to all the voxels, which were included in this search-light. At the end of whole process, each voxel classification result was a vector of classification rates of all the search-lights it was included in. The final voxel classification rate was the average of this vector. This search-light method is similar to "Monte Carlo sampling search-light" approach [<xref rid="pone.0117126.ref059" ref-type="bibr">59</xref>], which was shown to result in a higher discriminative power comparing to a strategy of assigning prediction rate to a central voxel of the search-light box (or sphere). The statistical significance was assessed as one-tailed t-test against chance level (0.5) for each voxel across all participants with p&lt;0.05, false discovery rate (FDR) correction [<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>]. As a control analysis, we also conducted a search-light analysis with non-overlapping search-lights (step of 3 voxels), where each voxel was classified only once.</p>
</sec>
<sec id="sec010">
<title>Replication experiment with a different set of famous faces</title>
<p>The face stimuli we used in the functional localizer and the identity discrimination experiment were the same. To find out whether the results we revealed will be replicated also when a standard face localizer and a different set of famous faces are used in the decoding task, 5 participants (3 females, average age: 27.5) returned to participate in a replication experiment. The experiment was conducted 3.5 years after the original experiment and used exactly the same methods, except for the differences specified below.</p>
<p><bold>Stimuli.</bold> The face stimuli in the identity discrimination experiment were of two highly familiar actors: Leonardo DiCaprio and Brad Pitt. Following the logic of the original experiment, the face identities of two actors were chosen because they belong to the same semantic category. All the participants were familiar with both faces. As in the original experiment, each face identity was represented by 8 different images (up to ∼10° of view angle rotation; neutral face expression). Image preprocessing steps were the same as in the original experiment. The size of all stimuli was 7x7 degrees of visual angle.</p>
<p>To test for low-level differences between stimuli of famous faces we conducted image similarity analysis. Average pixel correlation within face identity 1 was 0.834 (MSE: 0.006) and face identity 2 was 0.837 (MSE: 0.008). The difference between the pixel correlation of the two image sets was insignificant (two-tailed t-test: t(54) &lt; 1). Pixel correlation across identity image sets (64 image pairs) was 0.824 (MSE: 0.005). Critically, there was no significant difference for pixel correlation between and within image sets (identity 1 vs. between identities: t(65) = 1.21, p = 0.22; identity 2 vs. between identities: t(54) = 1.32, p = 0.19; two-tailed t-test with unequal variance [<xref rid="pone.0117126.ref043" ref-type="bibr">43</xref>]). Thus, there is no evidence that two sets of identities differ in their low-level image-based properties.</p>
<p><bold>Experimental Design.</bold> The face-selective and object-selective regions were localized using standard independent functional localizer that included various images of unfamiliar faces and objects [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0117126.ref052" ref-type="bibr">52</xref>,<xref rid="pone.0117126.ref060" ref-type="bibr">60</xref>,<xref rid="pone.0117126.ref061" ref-type="bibr">61</xref>]. The design of the functional localizer experiment was exactly the same as the original experiment (10 blocks per condition/session). The participants underwent two sessions of the functional localizer.</p>
<p>Design of the identity discrimination experimental sessions was the same as the original experiment. Three participants completed 5 sessions and two participants completed 6 sessions. Sessions of the identity discrimination experiment were interleaved with functional localizer sessions.</p>
</sec>
</sec>
<sec id="sec011" sec-type="results">
<title>Results</title>
<sec id="sec012">
<title>Behavioral Results</title>
<p>Behavioral results on the one-back task in the scanner were high under all conditions: 92% for face identity 1, 89% for face identity 2, 94% for cup type 1, 90% for cup type 2. No significant difference in performance was found between the two face identities and two cups (t(17) &lt; 1). Thus, task difficulty did not differ between face identities and cup types.</p>
</sec>
<sec id="sec013">
<title>Neuroimaging Results</title>
<p>In order to obtain a better signal in the ATL face-area we used an optimized scanning sequence proposed recently [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. In particular, we used a coronal slice orientation with two slabs that covered anterior temporal region ventrally with parts of the frontal lobes dorsally (anterior slab) and mid-temporal areas ventrally with part of the parietal lobe dorsally (posterior slab). This slice prescription permitted to cover the whole network of face-selective regions, except for the occipital face area (OFA). Face-selective regions of one representative participants are shown in <xref rid="pone.0117126.g001" ref-type="fig">Fig. 1</xref>. In <xref rid="pone.0117126.t001" ref-type="table">Table 1</xref>, we show ROI summary statistics of the face-selective regions (FFA, pSTS, ATL face-area, prefrontal and amygdala) and non-face-selective region in the collateral sulcus (COS) defined by voxels showing higher response to cups than faces. The regions were localized independently, using the first session of the experiment (see <xref rid="sec002" ref-type="sec">Methods</xref>).</p>
<p>First, we first tested whether, based on average fMRI signal, it is possible to discriminate between the two face identities. The results are shown in <xref rid="pone.0117126.g003" ref-type="fig">Fig. 3A</xref>. No significant difference in activation between the two identities was found in any of the regions (paired, two-tailed t-test: left FFA: t(12)&lt;1; right FFA: t(15) = 1.26, p = 0.22; left pSTS: t(7) = 1.47, p = 0.19; right pSTS: t(12) = 1.29, p = 0.21; left ATL face-area: t(6)&lt;1, right ATL face-area: t(10) = -1.89, p = 0.09; left prefrontal: t(7) = -1.32, p = 0.22; right prefrontal: t(12)&lt;1; left amygdala: t(7)&lt;1; right amygdala: t(7) = 1.88, p = 0.1; left COS: t(8) = -1.31, p = 0.22; right COS: t(11) = -1.48, p = 0.16).</p>
<p>Next, we examined whether using multivoxel pattern analyses (MVPA) we could correctly decode face identity. To ensure that any difference in the global level of activation between identities does not influence the MVPA results, the global signal level was subtracted prior to classification analysis separately for each condition [<xref rid="pone.0117126.ref054" ref-type="bibr">54</xref>]. The results of the MVPA are shown in <xref rid="pone.0117126.g003" ref-type="fig">Fig. 3B</xref>. Statistical significance was assessed using one-tailed t-test against the chance level of 0.5 (Bonferroni multiple comparison correction for number of regions (n = 12): p&lt;0.004). The prediction rate was significantly above chance in the right FFA (t(15) = 4.29, p&lt;0.001). In the left FFA and the left pSTS, the prediction rate was greater than chance; however, it did not reach statistical significance after multiple comparison correction: left FFA (t(12) = 2.57, p = 0.012), left pSTS (t(7) = 2.54, p = 0.019). In other regions, the prediction rate did not differ significantly from chance level: right pSTS: t(12) = 1.53, p = 0.08; left ATL face-area: t(6)&lt;1; right ATL face-area: t(10)&lt;1; left prefrontal: t(7)&lt;1; right prefrontal: t(12) = 1.16, p = 0.13; left amygdala: t(7) = 1.31, p = 0.11; right amygdala: t(7)&lt;1; left COS: t(8) = &lt;1; right COS: t(11)&lt;1. Notably, it could be claimed that the high significance achieved in the right FFA, but not in other regions, might be a consequence of the largest number of ROIs in this region (<xref rid="pone.0117126.t001" ref-type="table">Table 1</xref>). To address this point, in <xref rid="pone.0117126.g004" ref-type="fig">Fig. 4</xref>, we show individual prediction rates in the right FFA. As can be seen, for all the participants except for one, predictions were above chance level (50%). Thus, highly significant prediction result in the right FFA cannot be explained solely by large number of ROIs.</p>
<p>The results reported thus far were based on an ROI size of 20 voxels (160 mm<sup>3</sup>). To test the reliability of successful prediction in the FFA, we repeated the analysis for several ROI sizes: 10 voxels (80 mm<sup>3</sup>), 30 voxels (240 mm<sup>3</sup>), 40 voxels (320 mm<sup>3</sup>) and 50 voxels (400 mm<sup>3</sup>). The results of this analysis are shown in <xref rid="pone.0117126.g005" ref-type="fig">Fig. 5</xref> and <xref rid="pone.0117126.t002" ref-type="table">Table 2</xref>. As can be seen, for ROI larger than 10 voxels, the right FFA was the only region where two face identities could be consistently decoded above chance level (after multiple comparison correction). Finally, we conducted a control analysis where discrimination between two identities was tested using ROIs that were defined to include all the voxels that passed functional localization threshold (no ROI equalization procedure; see <xref rid="sec002" ref-type="sec">Methods</xref>). The results were qualitatively similar to what we reported for equalized size ROIs. The discrimination between two identities was significantly above chance in the right FFA (t(15) = 3.44, p = 0.0018). In the left FFA, the left pSTS and right prefrontal, the prediction rate was greater than chance; however, it did not reach statistical significance after multiple comparison correction: left FFA (t(12) = 2.44, p = 0.015], left pSTS (t(7) = 3.1, p = 0.008), right prefrontal (t(12) = 2.65, p = 0.01). In other regions, the prediction rate did not differ significantly from chance level: right pSTS: t(12) = 1.69, p = 0.058; left ATL face-area: t(6)&lt;1; right ATL face-area: t(10)&lt;1; left prefrontal: t(7)&lt;1; left amygdala: t(7) = 1.85, p = 0.053; right amygdala: t(7) = 1.67, p = 0.069; left COS: t(8) = &lt;1; right COS: t(11)&lt;1.</p>
<table-wrap id="pone.0117126.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.t002</object-id>
<label>Table 2</label> <caption><title>Results of discrimination between two face identities (MVPA analysis).</title></caption>
<alternatives>
<graphic id="pone.0117126.t002g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.t002" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Region</th>
<th align="left" rowspan="1" colspan="1">10 voxels</th>
<th align="left" rowspan="1" colspan="1">20 voxels</th>
<th align="left" rowspan="1" colspan="1">30 voxels</th>
<th align="left" rowspan="1" colspan="1">40 voxels</th>
<th align="left" rowspan="1" colspan="1">50 voxels</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left FFA</bold></td>
<td align="left" rowspan="1" colspan="1">t(12)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(12) = 2.57,p = 0.01</td>
<td align="left" rowspan="1" colspan="1">t(12) = 2.61,p = 0.011</td>
<td align="left" rowspan="1" colspan="1">t(12) = 2.4,p = 0.016</td>
<td align="left" rowspan="1" colspan="1">t(12) = 1.77,p = 0.05</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right FFA</bold></td>
<td align="left" rowspan="1" colspan="1">t(15) = 1.48,p = 0.08</td>
<td align="left" rowspan="1" colspan="1">t(15) = 4.3,p&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">t(15) = 4.74,p&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">t(15) = 7.12,p&lt;0.001</td>
<td align="left" rowspan="1" colspan="1">t(15) = 7.57,p&lt;0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left pSTS face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.44,p = 0.02</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.54,p = 0.02</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.35,p = 0.11</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.47,p = 0.023</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.41,p = 0.026</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right pSTS face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(11) = 2.03,p = 0.03</td>
<td align="left" rowspan="1" colspan="1">t(11) = 1.53,p = 0.08</td>
<td align="left" rowspan="1" colspan="1">t(11) = 2.63,p = 0.011</td>
<td align="left" rowspan="1" colspan="1">t(11) = 1.99,p = 0.035</td>
<td align="left" rowspan="1" colspan="1">t(11) = 1.31,p = 0.11</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left ATL face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(6)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(6) = 1,p = 0.17</td>
<td align="left" rowspan="1" colspan="1">t(6)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(6) = 1.62,p = 0.07</td>
<td align="left" rowspan="1" colspan="1">t(6)&lt;1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right ATL face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(10)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(10)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(10)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(10)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(10)&lt;1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left prefrontal face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right prefrontal face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(12)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(12) = 1.16,p = 0.13</td>
<td align="left" rowspan="1" colspan="1">t(12) = 1.32,p = 0.10</td>
<td align="left" rowspan="1" colspan="1">t(12) = 1.9,p = 0.04</td>
<td align="left" rowspan="1" colspan="1">t(12) = 1.38,p = 0.09</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left amygdala face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.31,p = 0.11</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.39,p = 0.02</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.07,p = 0.04</td>
<td align="left" rowspan="1" colspan="1">t(7) = 2.76,p = 0.014</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right amygdala face area</bold></td>
<td align="left" rowspan="1" colspan="1">t(7)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.02,p = 0.16</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.69,p = 0.067</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.1,p = 0.15</td>
<td align="left" rowspan="1" colspan="1">t(7) = 1.74,p = 0.06</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>left COS object area</bold></td>
<td align="left" rowspan="1" colspan="1">t(8)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(8)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(8)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(8)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(8)&lt;1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>right COS object area</bold></td>
<td align="left" rowspan="1" colspan="1">t(11)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(11)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(11)&lt;1</td>
<td align="left" rowspan="1" colspan="1">t(11) = 1.28,p = 0.11</td>
<td align="left" rowspan="1" colspan="1">t(11) = 1.26,p = 0.11</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>ROI sizes: 10 voxels (80 mm<sup>3</sup>), 20 voxels (160 mm<sup>3</sup>), 30 voxels (240 mm<sup>3</sup>), 40 voxels (320 mm<sup>3</sup>) and 50 voxels (400 mm<sup>3</sup>).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Our ROI analyses have shown that the FFA was the only region where face identities could be discriminated based on multivoxel patterns. Interestingly, face identity discrimination was at chance level in the ATL face-area—the region that was suggested to be important for face recognition [<xref rid="pone.0117126.ref020" ref-type="bibr">20</xref>,<xref rid="pone.0117126.ref027" ref-type="bibr">27</xref>,<xref rid="pone.0117126.ref028" ref-type="bibr">28</xref>]. Thus, to compliment the ROI analysis, we conducted search-light analysis [<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>] in the anterior temporal lobe. Due to limited brain coverage (coronal orientation, high-resolution), no search-light analysis was conducted for other regions. The search-light analysis was conducted using two schemes: in one scheme (the main analysis) the search-lights were overlapping, each voxel participated in many classifications and the results for each voxel were averaged; in an additional scheme (the control analysis), the search-lights were not overlapping and each voxel participated in one search-light only (see <xref rid="sec002" ref-type="sec">Methods</xref>). The results of classification in the anterior temporal using both schemes did not reveal any clusters, where the two famous identities could be discriminated above chance level (p&lt;0.05, FDR corrected). It is noteworthy that the areas in the ATL where previous studies did reveal decoding of face identity [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>] were more anterior (approximately more anterior MNI Y coordinate = 0) and were not covered in our study. We therefore do not claim that face identity is not represented in the ATL, but that it was not represented in the more limited brain regions covered by our high-resolution experiment where a face-selective area is found.</p>
<p>Finally, the analyses conducted for face identities were also performed for the two cup types. First, we tested whether, based on average fMRI signal, it is possible to discriminate between the two cups. The results are shown in <xref rid="pone.0117126.g006" ref-type="fig">Fig. 6A</xref>. No significant difference in activation between the two identities was found in any of the regions (paired, one-tailed t-test: left COS: t(8) = 2.56, p = 0.033; all other regions t&lt;1). To decode cup type, we employed MVPA. The results are shown in <xref rid="pone.0117126.g006" ref-type="fig">Fig. 6B</xref>. In the left STS and left prefrontal cortex, the prediction of cup type was above chance level but did not reach significance after correction for multiple comparison: left STS (t(7) = 2.36, p = 0.025); right prefrontal (t(12) = 1.83, p = 0.045). In other regions, the prediction rate did not differ from chance: left FFA (t(12) = 1.69, p = 0.057); right amygdala (t(7) = 1.37, p = 0.1); right FFA (t(15) = 1.25, p = 0.11); all other regions t&lt;1.</p>
<p><bold>Replication experiment with a new set of famous faces.</bold> The original experiment had two potential limitations related to generalization of the findings. First, the experiment used the same face identities for localization of the face-selective regions and for the face identity discrimination analysis; accordingly, it can be claimed that our discrimination results were specific for the face-selective voxels that were most sensitive to two specific identities. Second, the original experiment included only two face identities. To address both of these shortcomings, we ran the following experiment: a) the face-selective regions were localized using an independent functional localizer with various unfamiliar face and object stimuli (independent set of stimuli); and b) discrimination analysis was conducted for two additional famous face identities (Leonardo DiCaprio and Brad Pitt). The goal of the experiment was to test whether the successful decoding of the famous faces in the right FFA can be replicated using two novel identities. Five participants who participated in the original experiment participated in this experiment. Average fMRI signal and decoding results are shown in <xref rid="pone.0117126.g007" ref-type="fig">Fig. 7</xref>. Only ROIs localized in at least three participants are shown. The average fMRI signal for both face identities was similar. Critically, corroborating our findings of the original experiment, the average classification rate between two identities in the right FFA was the high, reaching the level of 60%. Despite the small sample size (N = 5), prediction in the right FFA was significantly beyond chance level (t(4) = 3.96, p = 0.008). In addition, in <xref rid="pone.0117126.g008" ref-type="fig">Fig. 8</xref> we show individual classification rates between face identities in the original and the replication experiment. Critically, in all participants the prediction rate was beyond chance level (50%) for both face pairs. Some prediction rate variability between experiments could be explained by the temporal difference between experiments (about 3.5 years) and potential difference in semantic information associated with two categories (i.e., politicians vs. actors). Taken together the results of the replication experiment demonstrate that the two famous face identities could be discriminated in the right FFA, which was localized using independent functional localization procedure.</p>
<fig id="pone.0117126.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Region of Interest-based face identity discrimination analysis (replication experiment; Leonardo DiCaprio and Brad Pitt identities).</title>
<p>(A) Average percent signal change for two face identities in the different face-selective areas and non-face selective collateral sulcus area. Error bars denote standard error of the mean. (B) Classification rates between face identities in face and non-face selective regions. The black line indicates a chance level of 50%. The error bars denote the standard error of the mean.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g007" position="float" xlink:type="simple"/>
</fig>
<fig id="pone.0117126.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0117126.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Comparison of individual classification rates of identity discrimination in the right FFA for the original (Benjamin Netanyahu and Shimon Peres) experiment and the replication (Leonardo DiCaprio and Brad Pitt).</title>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0117126.g008" position="float" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>The goal of the current study was to systematically explore the role of face-selective areas in recognition of famous faces. To that end, we presented several different images of two famous identities and used MVPA to discover which areas can discriminate between the two famous identities. The analysis was conducted for two different pairs of famous identities. The key finding was that famous face identity can be decoded significantly above chance level in the right fusiform face area (FFA). This result corroborates the importance of the FFA in face recognition.</p>
<p>The role of the FFA in face recognition has been advocated for a long time [<xref rid="pone.0117126.ref062" ref-type="bibr">62</xref>]. Consistent with this view, the FFA has been shown to exhibit properties essential for face recognition, including holistic face processing [<xref rid="pone.0117126.ref060" ref-type="bibr">60</xref>,<xref rid="pone.0117126.ref061" ref-type="bibr">61</xref>,<xref rid="pone.0117126.ref063" ref-type="bibr">63</xref>–<xref rid="pone.0117126.ref066" ref-type="bibr">66</xref>], partial view and mirror invariance [<xref rid="pone.0117126.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0117126.ref052" ref-type="bibr">52</xref>,<xref rid="pone.0117126.ref067" ref-type="bibr">67</xref>,<xref rid="pone.0117126.ref068" ref-type="bibr">68</xref>], and correlation with measures of face discrimination and recognition [<xref rid="pone.0117126.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0117126.ref069" ref-type="bibr">69</xref>], but see [<xref rid="pone.0117126.ref016" ref-type="bibr">16</xref>]. Notably, the most direct measure to test whether a region is responsible for face identity processing is to show that—based on the neural signal of that region—two identities can be discriminated [<xref rid="pone.0117126.ref070" ref-type="bibr">70</xref>]. Interestingly, while early pattern classification studies failed to find evidence in support of the role of the FFA in face recognition [<xref rid="pone.0117126.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>], three recent studies demonstrate that unfamiliar identities could be discriminated across changes in facial expressions [<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>], face view [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>] and features/configural changes [<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>]. Our results corroborate these findings by showing that different images of two famous face identities can be successfully discriminated in the fusiform face area (FFA) (<xref rid="pone.0117126.g003" ref-type="fig">Fig. 3B</xref>). The prediction rate in the right FFA was consistently above chance level across participants (<xref rid="pone.0117126.g004" ref-type="fig">Fig. 4</xref>) and across ROIs of different size (<xref rid="pone.0117126.g005" ref-type="fig">Fig. 5</xref>), suggesting the reliability of the effect. In addition, we replicated the result using two additional pairs of famous identities. It should be noted that since our design included only famous faces, we cannot estimate the extent to which rich semantic information that was part of famous stimuli we used contributed to the success of face discrimination. While based on results of early studies amount of semantic information in the FFA was minimal [<xref rid="pone.0117126.ref071" ref-type="bibr">71</xref>] or even absent [<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>], one recent study that used a more sensitive cluster analysis technique [<xref rid="pone.0117126.ref072" ref-type="bibr">72</xref>] was able to reveal semantic categories within the FFA. It is noteworthy that the semantic categories Çukur and colleagues have revealed were unrelated to faces. Thus, it is an open question whether semantic information about faces is also governed according to the same rules. In any case, in order to estimate the role of facial semantic information in the FFA, future studies will need to compare discrimination across both unfamiliar and famous identities within the same experiment. Finally, it should be noted that the view angle of the faces that we used was relatively small (up to ∼10° of view angle rotation). This was a deliberate decision as the FFA is known to be relatively view-selective [<xref rid="pone.0117126.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0117126.ref052" ref-type="bibr">52</xref>] and was shown not to generalize across large angle rotations [<xref rid="pone.0117126.ref017" ref-type="bibr">17</xref>]. Notably, many previous studies that explored identity discrimination used images of faces with a single view only [<xref rid="pone.0117126.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>–<xref rid="pone.0117126.ref016" ref-type="bibr">16</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>]. Now, as we established that famous faces with minimal view angle change can be discriminated, the next stage is to test discrimination across larger view angle changes.</p>
<p>A potential caveat in studies that discriminate between high-level visual categories in general and faces in particular is that neural discrimination can be based on low-level image properties [<xref rid="pone.0117126.ref065" ref-type="bibr">65</xref>,<xref rid="pone.0117126.ref073" ref-type="bibr">73</xref>]. Several steps were taken to address this point and ensure that the successful face discrimination was not based on low-level image properties [<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>,<xref rid="pone.0117126.ref074" ref-type="bibr">74</xref>] but rather involved face-processing mechanisms. First, the two face identities that were selected for the study were both males of similar age; they were grey-haired, and their faces did not differ by any distinctive markers, such as moustaches, beards or glasses [<xref rid="pone.0117126.ref060" ref-type="bibr">60</xref>,<xref rid="pone.0117126.ref061" ref-type="bibr">61</xref>] (<xref rid="pone.0117126.g002" ref-type="fig">Fig. 2A</xref>). Second, each of the two identities was represented by 8 different images, which were the pictures taken on different occasions mostly from the front view (up to ∼10° of view angle rotation). Third, luminance and contrast were adjusted between the images (see <xref rid="sec002" ref-type="sec">Materials and Methods</xref>). Fourth, to ensure that there was no low-level systematic difference between the two sets of images, we conducted image similarity analysis to show that images of the different identities were no more different than images of the same identity. Finally, there was no significant above chance discrimination between the two types of cups in the right FFA, although pixel-correlation analysis showed that the different cup types were different in terms of low-level features. Taken together, we suggest that discrimination between the two face identities is not likely to reflect discrimination based on low-level information but rather reflects face discrimination.</p>
<p>Interestingly, while the two famous face identities could be discriminated in the FFA, no discrimination was achieved in the anterior temporal lobe (ATL). The ATL is a large region that has been implicated in many functions, including social and emotional processing as well as semantic memory [<xref rid="pone.0117126.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0117126.ref075" ref-type="bibr">75</xref>]. Small subparts of the ATL exhibit a face-selective response [<xref rid="pone.0117126.ref028" ref-type="bibr">28</xref>], but localization of these clusters is usually relatively unreliable due to severe magnetic susceptibility (e.g., [<xref rid="pone.0117126.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0117126.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0117126.ref026" ref-type="bibr">26</xref>]). In addition, several studies demonstrated that BOLD activity in the ATL contains information about face identity [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>–<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>]. However, it is not clear whether these ATL clusters that showed identity decoding were face-selective [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>–<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>]. Thus, the question of whether face identity is processed in the face-selective ATL is still unresolved. These findings in humans are inconsistent with the very clear representation of individual identities in the monkey most anterior face-selective patch (AM) [<xref rid="pone.0117126.ref027" ref-type="bibr">27</xref>], which has been considered the monkey homologue of the human face-selective ATL area [<xref rid="pone.0117126.ref031" ref-type="bibr">31</xref>].</p>
<p>Our study focused explicitly on an ATL face-selective area that was reliably localized using a recently proposed coronal scanning optimization method [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. We found that face identities could not be discriminated in the ATL face-area (and also in adjacent non-face-selective voxels). To some extent, this result is even more surprising given that we used famous faces and the ATL is known to be a locus of semantic processing [<xref rid="pone.0117126.ref076" ref-type="bibr">76</xref>]. While it is possible that the ATL face-area indeed does not process face identity, it is also possible the "null result" stems from an insufficient sensitivity of the analysis or the still lower signal-to-noise ratio (SNR) in this area (relative to other face-selective areas), despite attempts to improve the signal by the coronal scanning [<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]. Thus, whether the ATL face-area is essential for face recognition will require further investigation. Notably, our results do not contradict previous studies that found identity information in the ATL. That is, while the method we used mitigated susceptibility effects, it was also limited in terms of brain coverage. In particular, the anterior part of the ATL (approximately more anterior MNI Y coordinate = 0) has not been covered by our slice orientation. Yet, identity information has been mostly found in these more anterior parts of the ATL [<xref rid="pone.0117126.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0117126.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0117126.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0117126.ref019" ref-type="bibr">19</xref>] (see also: [<xref rid="pone.0117126.ref020" ref-type="bibr">20</xref>]). One study that reported identity information in more posterior parts of the ATL [<xref rid="pone.0117126.ref013" ref-type="bibr">13</xref>] used two types of ATL clusters, including those clusters more adjacent to the FFA (MNI Y coordinate = -20/30)[<xref rid="pone.0117126.ref009" ref-type="bibr">9</xref>]—and may therefore reflect or partly reflect the FFA successful decoding rather than the ATL. Taken together, these methodological differences explain discrepancy in identity decoding.</p>
<p>The primary goal of the current study was to conduct a systematic exploration of the face-selective network with regard to discriminating face identity. Apart from a successful above chance discrimination in the right FFA, we also found a high prediction rate in the left FFA and left posterior superior temporal sulcus (pSTS), but the result did not reach significance after multiple comparison correction. Other regions that have not been explored before such as the face-selective area in the amygdala or the pre-frontal cortex did not show evidence of identity representation in our study. It is possible that the more abstract and multi-modal representation of faces in these areas could not be decoded with the current design that we used. For example, the choice of two faces from the same semantic categories (similar age, similar occupation, both famous) might have impeded our ability to reveal different neural codes to these two faces in these anterior areas. To test sensitivity to semantic-biographical information one may want to decode famous faces who at least have different occupations. In general, while the amygdala is believed to support emotional aspects of face-processing [<xref rid="pone.0117126.ref077" ref-type="bibr">77</xref>], the role of the prefrontal face-region in face processing is unclear to date[<xref rid="pone.0117126.ref078" ref-type="bibr">78</xref>]. For example, the region was more sensitive to dynamic than to static faces [<xref rid="pone.0117126.ref079" ref-type="bibr">79</xref>], was sensitive to the presence of eyes [<xref rid="pone.0117126.ref010" ref-type="bibr">10</xref>], was selective to the human body and its parts [<xref rid="pone.0117126.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0117126.ref079" ref-type="bibr">79</xref>] and was possibly sensitive to working memory load [<xref rid="pone.0117126.ref080" ref-type="bibr">80</xref>]. Thus these previous results do not permit to draw a coherent picture. An additional possibility that should be considered is that the signals elicited by two identities were too similar to be detected by an fMRI—the method that has relatively low SNR [<xref rid="pone.0117126.ref081" ref-type="bibr">81</xref>]. To this extent identity decoding using single-cell recording in macaque monkeys might provide more information [<xref rid="pone.0117126.ref082" ref-type="bibr">82</xref>]. With respect to earlier visual areas, because we used high resolution, our coronal scanning did not include the occipital cortex and we could not examine the decoding level of the more posterior face and non-face areas (OFA and Lateral Occipital). The lack of Lateral Occipital coverage may explain why we did not find regions that discriminate between the two types of cup [<xref rid="pone.0117126.ref042" ref-type="bibr">42</xref>].</p>
<p>In conclusion, in the current study, we explored face discrimination of famous identities in the face-selective network of regions and in the adjacent non-face-selective cortex. Our key finding was that famous face identity could be decoded above chance level in the FFA face-selective region but not in other regions of the face-selective network. This result corroborates the important role played by the FFA in face recognition.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Dafna Ben-Bashat, Moran Artzi and Yaniv Assaf for their help with fMRI protocol definition. We also thank Boaz Sadeh and Ido Tavor for their help with data acquisition.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0117126.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gauthier</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Skudlarski</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Gore</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>AW</given-names></name> (<year>2000</year>) <article-title>Expertise for cars and birds recruits brain areas involved in face recognition</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>191</fpage>–<lpage>197</lpage>. <object-id pub-id-type="pmid">10649576</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name> (<year>1997</year>) <article-title>The fusiform face area: A module in human extrastriate cortex specialized for face perception</article-title>. <source>Journal of Neuroscience</source> <volume>17</volume>: <fpage>4302</fpage>–<lpage>4311</lpage>. <object-id pub-id-type="pmid">9151747</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chao</surname> <given-names>LL</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name> (<year>1999</year>) <article-title>Are face-responsive regions selective only for faces?</article-title> <source>NeuroReport</source> <volume>10</volume>: <fpage>2945</fpage>–<lpage>2950</lpage>. <object-id pub-id-type="pmid">10549802</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>, <name name-style="western"><surname>Moeller</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name> (<year>2008</year>) <article-title>Comparing face patch systems in macaques and humans</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>: <fpage>19514</fpage>–<lpage>19519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0809662105" xlink:type="simple">10.1073/pnas.0809662105</ext-link></comment> <object-id pub-id-type="pmid">19033466</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pinsk</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Arcaro</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Kalkus</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Inati</surname> <given-names>SJ</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Neural Representations of Faces and Body Parts in Macaque and Human Cortex: A Comparative fMRI Study</article-title>. <source>Journal of Neurophysiology</source> <volume>101</volume>: <fpage>2581</fpage>–<lpage>2600</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.91198.2008" xlink:type="simple">10.1152/jn.91198.2008</ext-link></comment> <object-id pub-id-type="pmid">19225169</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todorov</surname> <given-names>A</given-names></name> (<year>2012</year>) <article-title>The role of the amygdala in face perception and evaluation</article-title>. <source>Motivation and Emotion</source> <volume>36</volume>: <fpage>16</fpage>–<lpage>26</lpage>. <object-id pub-id-type="pmid">22448077</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hanseeuw</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dricot</surname> <given-names>L</given-names></name> (<year>2012</year>) <article-title>Defining face perception areas in the human brain: a large-scale factorial fMRI face localizer analysis</article-title>. <source>Brain and Cognition</source> <volume>79</volume>: <fpage>138</fpage>–<lpage>157</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.bandc.2012.01.001" xlink:type="simple">10.1016/j.bandc.2012.01.001</ext-link></comment> <object-id pub-id-type="pmid">22330606</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harris</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Andrews</surname> <given-names>TJ</given-names></name> (<year>2014</year>) <article-title>Dynamic stimuli demonstrate a categorical representation of facial expression in the amygdala</article-title>. <source>Neuropsychologia</source> <volume>56</volume>: <fpage>47</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuropsychologia.2014.01.005" xlink:type="simple">10.1016/j.neuropsychologia.2014.01.005</ext-link></comment> <object-id pub-id-type="pmid">24447769</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name> (<year>2013</year>) <article-title>The challenge of localizing the anterior temporal face area: A possible solution</article-title>. <source>Neuroimage</source> <volume>81</volume>: <fpage>371</fpage>–<lpage>380</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2013.05.015" xlink:type="simple">10.1016/j.neuroimage.2013.05.015</ext-link></comment> <object-id pub-id-type="pmid">23684864</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chan</surname> <given-names>AW-Y</given-names></name>, <name name-style="western"><surname>Downing</surname> <given-names>PE</given-names></name> (<year>2011</year>) <article-title>Faces and Eyes in Human Lateral Prefrontal Cortex</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>5</volume>,<fpage>51</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2011.00051" xlink:type="simple">10.3389/fnhum.2011.00051</ext-link></comment> <object-id pub-id-type="pmid">21687796</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anzellotti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fairhall</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Caramazza</surname> <given-names>A</given-names></name> (<year>2014</year>) <article-title>Decoding Representations of Face Identity That are Tolerant to Rotation</article-title>. <source>Cerebral Cortex</source> <volume>24</volume>: <fpage>1988</fpage>–<lpage>1995</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bht046" xlink:type="simple">10.1093/cercor/bht046</ext-link></comment> <object-id pub-id-type="pmid">23463339</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilaie-Dotan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name> (<year>2007</year>) <article-title>Sub-exemplar Shape Tuning in Human Face-Related Areas</article-title>. <source>Cerebral Cortex</source> <volume>17</volume>: <fpage>325</fpage>–<lpage>338</lpage>. <object-id pub-id-type="pmid">16525131</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goesaert</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Op de Beeck</surname> <given-names>HP</given-names></name> (<year>2013</year>) <article-title>Representations of Facial Identity Information in the Ventral Visual Stream Investigated with Multivoxel Pattern Analyses</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>8549</fpage>–<lpage>8558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1829-12.2013" xlink:type="simple">10.1523/JNEUROSCI.1829-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23658192</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nestor</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Plaut</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Behrmann</surname> <given-names>M</given-names></name> (<year>2011</year>) <article-title>Unraveling the distributed neural code of facial identity through spatiotemporal pattern analysis</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>108</volume>: <fpage>9998</fpage>–<lpage>10003</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1102433108" xlink:type="simple">10.1073/pnas.1102433108</ext-link></comment> <object-id pub-id-type="pmid">21628569</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rotshtein</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Henson</surname> <given-names>RNA</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2005</year>) <article-title>Morphing Marilyn into Maggie dissociates physical and identity face representations in the brain</article-title>. <source>Nature Neuroscience</source> <volume>8</volume>: <fpage>107</fpage>–<lpage>113</lpage>. <object-id pub-id-type="pmid">15592463</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramon</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dricot</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name> (<year>2010</year>) <article-title>Personally familiar faces are perceived categorically in face-selective regions other than the fusiform face area</article-title>. <source>European Journal of Neuroscience</source> <volume>32</volume>: <fpage>1587</fpage>–<lpage>1598</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2010.07405.x" xlink:type="simple">10.1111/j.1460-9568.2010.07405.x</ext-link></comment> <object-id pub-id-type="pmid">20880360</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Natu</surname> <given-names>VS</given-names></name>, <name name-style="western"><surname>Jiang</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Narvekar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Keshvari</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Blanz</surname> <given-names>V</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Dissociable Neural Patterns of Facial Identity across Changes in Viewpoint</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>22</volume>: <fpage>1570</fpage>–<lpage>1582</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2009.21312" xlink:type="simple">10.1162/jocn.2009.21312</ext-link></comment> <object-id pub-id-type="pmid">19642884</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Yue</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Lescroart</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Biederman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>JG</given-names></name> (<year>2009</year>) <article-title>Adaptation in the fusiform face area (FFA): Image or person?</article-title> <source>Vision Research</source> <volume>49</volume>: <fpage>2800</fpage>–<lpage>2807</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2009.08.021" xlink:type="simple">10.1016/j.visres.2009.08.021</ext-link></comment> <object-id pub-id-type="pmid">19712692</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Formisano</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sorger</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name> (<year>2007</year>) <article-title>Individual faces elicit distinct response patterns in human anterior temporal cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>104</volume>: <fpage>20600</fpage>–<lpage>20605</lpage>. <object-id pub-id-type="pmid">18077383</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Avidan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Tanzer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hadj-Bouziane</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Selective Dissociation Between Core and Extended Regions of the Face Processing Network in Congenital Prosopagnosia</article-title>. <source>Cerebral Cortex</source> <volume>24</volume>: <fpage>1565</fpage>–<lpage>1578</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bht007" xlink:type="simple">10.1093/cercor/bht007</ext-link></comment> <object-id pub-id-type="pmid">23377287</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nasr</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name> (<year>2012</year>) <article-title>Role of fusiform and anterior temporal cortical areas in facial recognition</article-title>. <source>NeuroImage</source> <volume>63</volume>: <fpage>1743</fpage>–<lpage>1753</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2012.08.031" xlink:type="simple">10.1016/j.neuroimage.2012.08.031</ext-link></comment> <object-id pub-id-type="pmid">23034518</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thomas</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Avidan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Humphreys</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Jung</surname> <given-names>K-j</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>F</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Reduced structural connectivity in ventral visual cortex in congenital prosopagnosia</article-title>. <source>Nat Neurosci</source> <volume>12</volume>: <fpage>29</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2224" xlink:type="simple">10.1038/nn.2224</ext-link></comment> <object-id pub-id-type="pmid">19029889</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Avidan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hasson</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Behrmann</surname> <given-names>M</given-names></name> (<year>2005</year>) <article-title>Detailed Exploration of Face-related Processing in Congenital Prosopagnosia: 2. Functional Neuroimaging Findings</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>17</volume>: <fpage>1150</fpage>–<lpage>1167</lpage>. <object-id pub-id-type="pmid">16102242</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Olson</surname> <given-names>IR</given-names></name> (<year>2014</year>) <article-title>Beyond the FFA: The role of the ventral anterior temporal Lobes in face processing</article-title>. <source>Neuropsychologia</source> <volume>61</volume>: <fpage>65</fpage>–<lpage>79</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuropsychologia.2014.06.005" xlink:type="simple">10.1016/j.neuropsychologia.2014.06.005</ext-link></comment> <object-id pub-id-type="pmid">24937188</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref025"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Yang H, Susilo T, Duchaine B (2014) The Anterior Temporal Face Area Contains Invariant Representations of Face Identity That Can Persist Despite the Loss of Right FFA and OFA. Cerebral Cortex Published online December 19, 2014, <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhu289" xlink:type="simple">10.1093/cercor/bhu289</ext-link></comment></mixed-citation></ref>
<ref id="pone.0117126.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rajimehr</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name> (<year>2009</year>) <article-title>An anterior temporal face patch in human cortex, predicted by macaque maps</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>106</volume>: <fpage>1995</fpage>–<lpage>2000</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0807304106" xlink:type="simple">10.1073/pnas.0807304106</ext-link></comment> <object-id pub-id-type="pmid">19179278</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name> (<year>2010</year>) <article-title>Functional compartmentalization and viewpoint generalization within the macaque face-processing system</article-title>. <source>Science</source> <volume>330</volume>: <fpage>845</fpage>–<lpage>851</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1194908" xlink:type="simple">10.1126/science.1194908</ext-link></comment> <object-id pub-id-type="pmid">21051642</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Von Der Heide</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Skipper</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Olson</surname> <given-names>IR</given-names></name> (<year>2013</year>) <article-title>Anterior temporal face patches: A meta-analysis and empirical study</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>7</volume>, <fpage>17</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2013.00017" xlink:type="simple">10.3389/fnhum.2013.00017</ext-link></comment> <object-id pub-id-type="pmid">23378834</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Devlin</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Russell</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Price</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>J</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>Susceptibility-Induced Loss of Signal: Comparing PET and fMRI on a Semantic Task</article-title>. <source>Neuroimage</source> <volume>11</volume>: <fpage>589</fpage>–<lpage>600</lpage>. <object-id pub-id-type="pmid">10860788</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gorno-Tempini</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Hutton</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Josephs</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Deichmann</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Price</surname> <given-names>C</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Echo Time Dependence of BOLD Contrast and Susceptibility Artifacts</article-title>. <source>Neuroimage</source> <volume>15</volume>: <fpage>136</fpage>–<lpage>142</lpage>. <object-id pub-id-type="pmid">11771981</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Freiwald</surname> <given-names>WA</given-names></name> (<year>2013</year>) <article-title>Face recognition systems in monkey and human: are they the same thing?</article-title> <source>F1000prime reports</source> <volume>5</volume>: <fpage>10</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.12703/P5-10" xlink:type="simple">10.12703/P5-10</ext-link></comment> <object-id pub-id-type="pmid">23585928</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Polyn</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Detre</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name> (<year>2006</year>) <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends in Cognitive Sciences</source> <volume>10</volume>: <fpage>424</fpage>–<lpage>430</lpage>. <object-id pub-id-type="pmid">16899397</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Megreya</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Burton</surname> <given-names>AM</given-names></name> (<year>2006</year>) <article-title>Unfamiliar faces are not faces: Evidence from a matching task</article-title>. <source>Memory and Cognition</source> <volume>34</volume>: <fpage>865</fpage>–<lpage>876</lpage>. <object-id pub-id-type="pmid">17063917</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnston</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Edmonds</surname> <given-names>AJ</given-names></name> (<year>2009</year>) <article-title>Familiar and unfamiliar face recognition: A review</article-title>. <source>Memory</source> <volume>17</volume>: <fpage>577</fpage>–<lpage>596</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09658210902976969" xlink:type="simple">10.1080/09658210902976969</ext-link></comment> <object-id pub-id-type="pmid">19548173</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ewbank</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Andrews</surname> <given-names>TJ</given-names></name> (<year>2008</year>) <article-title>Differential sensitivity for viewpoint between familiar and unfamiliar faces in human visual cortex</article-title>. <source>Neuroimage</source> <volume>40</volume>: <fpage>1857</fpage>–<lpage>1870</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2008.01.049" xlink:type="simple">10.1016/j.neuroimage.2008.01.049</ext-link></comment> <object-id pub-id-type="pmid">18343161</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pourtois</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Seghier</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Lazeyras</surname> <given-names>FO</given-names></name>, <name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name> (<year>2005</year>) <article-title>View-independent coding of face identity in frontal and temporal cortices is modulated by familiarity: an event-related fMI study</article-title>. <source>Neuroimage</source> <volume>24</volume>: <fpage>1214</fpage>–<lpage>1224</lpage>. <object-id pub-id-type="pmid">15670699</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eger</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Schweinberger</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Henson</surname> <given-names>RN</given-names></name> (<year>2005</year>) <article-title>Familiarity enhances invariance of face representations in human ventral visual cortex: fMRI evidence</article-title>. <source>Neuroimage</source> <volume>26</volume>: <fpage>1128</fpage>–<lpage>1139</lpage>. <object-id pub-id-type="pmid">15961049</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wong</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gallate</surname> <given-names>J</given-names></name> (<year>2012</year>) <article-title>The function of the anterior temporal lobe: A review of the empirical evidence</article-title>. <source>Brain Research</source> <volume>1449</volume>: <fpage>94</fpage>–<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.brainres.2012.02.017" xlink:type="simple">10.1016/j.brainres.2012.02.017</ext-link></comment> <object-id pub-id-type="pmid">22421014</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref039"><label>39</label><mixed-citation publication-type="other" xlink:type="simple">Oshio K, Jolesz F, Melki P, Mulkern R (1991) T2-weighted thin-section imaging with the multislab three-dimensional RARE technique. Journal Magnetic Resonance Imaging Nov-Dec: 695–700.</mixed-citation></ref>
<ref id="pone.0117126.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leibe</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Schiele</surname> <given-names>B</given-names></name>. <article-title>Analyzing appearance and contour based methods for object categorization</article-title>; <year>2003</year>. <source>IEEE</source>. pp. <fpage>II-409</fpage>–<lpage>415</lpage> vol. <volume>402</volume>.</mixed-citation></ref>
<ref id="pone.0117126.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Henson</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name> (<year>2002</year>) <article-title>Multiple levels of visual object constancy revealed by event-related fMRI of repetition priming</article-title>. <source>Nature Neuroscience</source> <volume>5</volume>: <fpage>491</fpage>–<lpage>499</lpage>. <object-id pub-id-type="pmid">11967545</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eger</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ashburner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Rees</surname> <given-names>G</given-names></name> (<year>2008</year>) <article-title>fMRI activity patterns in human LOC carry information about object exemplars within category</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>20</volume>: <fpage>356</fpage>–<lpage>370</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2008.20019" xlink:type="simple">10.1162/jocn.2008.20019</ext-link></comment> <object-id pub-id-type="pmid">18275340</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruxton</surname> <given-names>GD</given-names></name> (<year>2006</year>) <article-title>The unequal variance t-test is an underused alternative to Student's t-test and the Mann–Whitney U test</article-title>. <source>Behavioral Ecology</source> <volume>17</volume>: <fpage>688</fpage>–<lpage>690</lpage>.</mixed-citation></ref>
<ref id="pone.0117126.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ashburner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2005</year>) <article-title>Unified segmentation</article-title>. <source>NeuroImage</source> <volume>26</volume>: <fpage>839</fpage>–<lpage>851</lpage>. <object-id pub-id-type="pmid">15955494</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Levy</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Hasson</surname> <given-names>U</given-names></name> (<year>2002</year>) <article-title>The topography of high-order human object areas</article-title>. <source>Trends in Cognitive Sciences</source> <volume>6</volume>: <fpage>176</fpage>–<lpage>184</lpage>. <object-id pub-id-type="pmid">11912041</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref046"><label>46</label><mixed-citation publication-type="other" xlink:type="simple">Brett M, Anton J, Valabregue R, Poline J (2002) Region of interest analysis using an SPM toolbox. Neuroimage 1140–1141.</mixed-citation></ref>
<ref id="pone.0117126.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dale</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Fischl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Sereno</surname> <given-names>MI</given-names></name> (<year>1999</year>) <article-title>Cortical surface-based analysis: I. Segmentation and surface reconstruction</article-title>. <source>Neuroimage</source> <volume>9</volume>: <fpage>179</fpage>–<lpage>194</lpage>. <object-id pub-id-type="pmid">9931268</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Walther</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Caddigan</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Fei-Fei</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>DM</given-names></name> (<year>2009</year>) <article-title>Natural Scene Categories Revealed in Distributed Patterns of Activity in the Human Brain</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>10573</fpage>–<lpage>10581</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0559-09.2009" xlink:type="simple">10.1523/JNEUROSCI.0559-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19710310</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Said</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Engell</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Todorov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name> (<year>2010</year>) <article-title>Distributed representations of dynamic facial expressions in the superior temporal sulcus</article-title>. <source>Journal of Vision</source> <volume>10</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="pone.0117126.ref050"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">Axelrod V, Bar M, Rees G, Yovel G (2014) Neural correlates of subliminal language processing. Cerebral Cortex Published online February 20, 2014, <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhu022" xlink:type="simple">10.1093/cercor/bhu022</ext-link></comment></mixed-citation></ref>
<ref id="pone.0117126.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cichy</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name> (<year>2011</year>) <article-title>Encoding the identity and location of objects in human LOC</article-title>. <source>Neuroimage</source> <volume>54</volume>: <fpage>2297</fpage>–<lpage>2307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2010.09.044" xlink:type="simple">10.1016/j.neuroimage.2010.09.044</ext-link></comment> <object-id pub-id-type="pmid">20869451</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name> (<year>2012</year>) <article-title>Hierarchical Processing of Face Viewpoint in Human Visual Cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>32</volume>: <fpage>2442</fpage>–<lpage>2452</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4770-11.2012" xlink:type="simple">10.1523/JNEUROSCI.4770-11.2012</ext-link></comment> <object-id pub-id-type="pmid">22396418</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name> (<year>2014</year>) <article-title>Minimizing bugs in cognitive neuroscience programming</article-title>. <source>Frontiers in psychology</source> <volume>5</volume>, <fpage>1435</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fpsyg.2014.01435" xlink:type="simple">10.3389/fpsyg.2014.01435</ext-link></comment> <object-id pub-id-type="pmid">25566120</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Misaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bandettini</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name> (<year>2010</year>) <article-title>Comparison of multivariate classifiers and response normalizations for pattern-information fMRI</article-title>. <source>Neuroimage</source> <volume>53</volume>: <fpage>103</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2010.05.051" xlink:type="simple">10.1016/j.neuroimage.2010.05.051</ext-link></comment> <object-id pub-id-type="pmid">20580933</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coutanche</surname> <given-names>MN</given-names></name> (<year>2013</year>) <article-title>Distinguishing multi-voxel patterns and mean activation: Why, how, and what does it tell us?</article-title> <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <volume>13</volume>: <fpage>667</fpage>–<lpage>673</lpage>.</mixed-citation></ref>
<ref id="pone.0117126.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hanson</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Halchenko</surname> <given-names>YO</given-names></name> (<year>2008</year>) <article-title>Brain Reading Using Full Brain Support Vector Machines for Object Recognition: There Is No “Face” Identification Area</article-title>. <source>Neural Computation</source> <volume>20</volume>: <fpage>486</fpage>–<lpage>503</lpage>. <object-id pub-id-type="pmid">18047411</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyer</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kaplan</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Essex</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Webber</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Damasio</surname> <given-names>H</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Predicting visual stimuli on the basis of activity in auditory cortices</article-title>. <source>Nature Neuroscience</source> <volume>13</volume>: <fpage>667</fpage>–<lpage>668</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2533" xlink:type="simple">10.1038/nn.2533</ext-link></comment> <object-id pub-id-type="pmid">20436482</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maldjian</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Laurienti</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Kraft</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Burdette</surname> <given-names>JH</given-names></name> (<year>2003</year>) <article-title>An automated method for neuroanatomic and cytoarchitectonic atlas-based interrogation of fMRI data sets</article-title>. <source>Neuroimage</source> <volume>19</volume>: <fpage>1233</fpage>–<lpage>1239</lpage>. <object-id pub-id-type="pmid">12880848</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Björnsdotter</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rylander</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wessberg</surname> <given-names>J</given-names></name> (<year>2011</year>) <article-title>A Monte Carlo method for locally multivariate brain mapping</article-title>. <source>Neuroimage</source> <volume>56</volume>: <fpage>508</fpage>–<lpage>516</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2010.07.044" xlink:type="simple">10.1016/j.neuroimage.2010.07.044</ext-link></comment> <object-id pub-id-type="pmid">20674749</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name> (<year>2011</year>) <article-title>Nonpreferred Stimuli Modify the Representation of Faces in the Fusiform Face Area</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>23</volume>: <fpage>746</fpage>–<lpage>756</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2010.21481" xlink:type="simple">10.1162/jocn.2010.21481</ext-link></comment> <object-id pub-id-type="pmid">20497032</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name> (<year>2010</year>) <article-title>External facial features modify the representation of internal facial features in the fusiform face area</article-title>. <source>Neuroimage</source> <volume>52</volume>: <fpage>720</fpage>–<lpage>725</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2010.04.027" xlink:type="simple">10.1016/j.neuroimage.2010.04.027</ext-link></comment> <object-id pub-id-type="pmid">20406694</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name> (<year>2006</year>) <article-title>The fusiform face area: a cortical region specialized for the perception of faces</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>361</volume>: <fpage>2109</fpage>–<lpage>2128</lpage>. <object-id pub-id-type="pmid">17118927</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name> (<year>2005</year>) <article-title>The neural basis of the behavioral face-inversion effect</article-title>. <source>Current Biology</source> <volume>15</volume>: <fpage>2256</fpage>–<lpage>2262</lpage>. <object-id pub-id-type="pmid">16360687</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andrews</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Davies-Thompson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kingstone</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>AW</given-names></name> (<year>2010</year>) <article-title>Internal and External Features of the Face Are Represented Holistically in Face-Selective Regions of Visual Cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>30</volume>: <fpage>3544</fpage>–<lpage>3552</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4863-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4863-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20203214</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname> <given-names>V</given-names></name> (<year>2010</year>) <article-title>The Fusiform Face Area: In Quest of Holistic Face Processing</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>: <fpage>8699</fpage>–<lpage>8701</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1921-10.2010" xlink:type="simple">10.1523/JNEUROSCI.1921-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20592190</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schiltz</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name> (<year>2006</year>) <article-title>Faces are represented holistically in the human occipito-temporal cortex</article-title>. <source>Neuroimage</source> <volume>32</volume>: <fpage>1385</fpage>–<lpage>1394</lpage>. <object-id pub-id-type="pmid">16870475</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kushnir</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Edelman</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Avidan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Itzchak</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. (<year>1999</year>) <article-title>Differential processing of objects under various viewing conditions in the human lateral occipital complex</article-title>. <source>Neuron</source> <volume>24</volume>: <fpage>187</fpage>–<lpage>203</lpage>. <object-id pub-id-type="pmid">10677037</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kietzmann</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Swisher</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>König</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name> (<year>2012</year>) <article-title>Prevalence of selectivity for mirror-symmetric views of faces in the ventral and dorsal visual pathways</article-title>. <source>The Journal of Neuroscience</source> <volume>32</volume>: <fpage>11763</fpage>–<lpage>11772</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0126-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0126-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22915118</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Knouf</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name> (<year>2004</year>) <article-title>The fusiform face area Subserves face perception, not generic within-category identification</article-title>. <source>Nat Neurosci</source> <volume>7</volume>: <fpage>555</fpage>–<lpage>562</lpage>. <object-id pub-id-type="pmid">15077112</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davidesco</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Zion-Golumbic</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Bickel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Harel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Groppe</surname> <given-names>DM</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Exemplar Selectivity Reflects Perceptual Similarities in the Human Fusiform Cortex</article-title>. <source>Cerebral Cortex</source> <volume>24</volume>: <fpage>1879</fpage>–<lpage>1893</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bht038" xlink:type="simple">10.1093/cercor/bht038</ext-link></comment> <object-id pub-id-type="pmid">23438448</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Hurk</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gentile</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Jansma</surname> <given-names>BM</given-names></name> (<year>2011</year>) <article-title>What's behind a Face: Person Context Coding in Fusiform Face Area as Revealed by Multivoxel Pattern Analysis</article-title>. <source>Cerebral Cortex</source> <volume>21</volume>: <fpage>2893</fpage>–<lpage>2899</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhr093" xlink:type="simple">10.1093/cercor/bhr093</ext-link></comment> <object-id pub-id-type="pmid">21571695</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Çukur</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Huth</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Nishimoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name> (<year>2013</year>) <article-title>Functional subdomains within human FFA</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>16748</fpage>–<lpage>16766</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1259-13.2013" xlink:type="simple">10.1523/JNEUROSCI.1259-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24133276</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mur</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ruff</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Bodurka</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bandettini</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name> (<year>2010</year>) <article-title>Face-Identity Change Activation Outside the Face System: "Release from Adaptation" May Not Always Indicate Neuronal Selectivity</article-title>. <source>Cerebral Cortex</source> <volume>20</volume>: <fpage>2027</fpage>–<lpage>2042</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhp272" xlink:type="simple">10.1093/cercor/bhp272</ext-link></comment> <object-id pub-id-type="pmid">20051364</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yue</surname> <given-names>XM</given-names></name>, <name name-style="western"><surname>Cassidy</surname> <given-names>BS</given-names></name>, <name name-style="western"><surname>Devaney</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Holt</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name> (<year>2011</year>) <article-title>Lower-Level Stimulus Features Strongly Influence Responses in the Fusiform Face Area</article-title>. <source>Cerebral Cortex</source> <volume>21</volume>: <fpage>35</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhq050" xlink:type="simple">10.1093/cercor/bhq050</ext-link></comment> <object-id pub-id-type="pmid">20375074</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olson</surname> <given-names>IR</given-names></name>, <name name-style="western"><surname>Plotzker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ezzyat</surname> <given-names>Y</given-names></name> (<year>2007</year>) <article-title>The Enigmatic temporal pole: a review of findings on social and emotional processing</article-title>. <source>Brain</source> <volume>130</volume>: <fpage>1718</fpage>–<lpage>1731</lpage>. <object-id pub-id-type="pmid">17392317</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Binder</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Desai</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Graves</surname> <given-names>WW</given-names></name>, <name name-style="western"><surname>Conant</surname> <given-names>LL</given-names></name> (<year>2009</year>) <article-title>Where Is the Semantic System? A Critical Review and Meta-Analysis of 120 Functional Neuroimaging Studies</article-title>. <source>Cerebral Cortex</source> <volume>19</volume>: <fpage>2767</fpage>–<lpage>2796</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhp055" xlink:type="simple">10.1093/cercor/bhp055</ext-link></comment> <object-id pub-id-type="pmid">19329570</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Hoffman</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Gobbini</surname> <given-names>MI</given-names></name> (<year>2000</year>) <article-title>The distributed human neural system for face perception</article-title>. <source>Trends in Cognitive Sciences</source> <volume>4</volume>: <fpage>223</fpage>–<lpage>233</lpage>. <object-id pub-id-type="pmid">10827445</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chan</surname> <given-names>AW-Y</given-names></name> (<year>2013</year>) <article-title>Functional organization and visual representations of human ventral lateral prefrontal cortex</article-title>. <source>Frontiers in psychology</source> <volume>4</volume>, <fpage>371</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fpsyg.2013.00371" xlink:type="simple">10.3389/fpsyg.2013.00371</ext-link></comment> <object-id pub-id-type="pmid">23847558</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitcher</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dilks</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Saxe</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Triantafyllou</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name> (<year>2011</year>) <article-title>Differential selectivity for dynamic versus static information in face-selective cortical regions</article-title>. <source>Neuroimage</source> <volume>56</volume>: <fpage>2356</fpage>–<lpage>2363</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2011.03.067" xlink:type="simple">10.1016/j.neuroimage.2011.03.067</ext-link></comment> <object-id pub-id-type="pmid">21473921</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ó Scalaidhe</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>FAW</given-names></name>, <name name-style="western"><surname>Goldman-Rakic</surname> <given-names>PS</given-names></name> (<year>1997</year>) <article-title>Areal Segregation of Face-Processing Neurons in Prefrontal Cortex</article-title>. <source>Science</source> <volume>278</volume>: <fpage>1135</fpage>–<lpage>1138</lpage>. <object-id pub-id-type="pmid">9353197</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Logothetis</surname> <given-names>NK</given-names></name>, <name name-style="western"><surname>Pauls</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Augath</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Trinath</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Oeltermann</surname> <given-names>A</given-names></name> (<year>2001</year>) <article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title>. <source>Nature</source> <volume>412</volume>: <fpage>150</fpage>–<lpage>157</lpage>. <object-id pub-id-type="pmid">11449264</object-id></mixed-citation></ref>
<ref id="pone.0117126.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubois</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>De Bekker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>D</given-names></name> (<year>2013</year>) <article-title>Pitching fMRI MVPA against single unit ground truth in the macaque monkey: Decoding face identity and viewpoint</article-title>. <source>Society for Neuroscience Conference Abstract</source> <volume>120</volume>:<fpage>12</fpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>