<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-29730</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0097584</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject></subj-group><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Invertebrates</subject><subj-group><subject>Nematoda</subject><subj-group><subject>Caenorhabditis</subject><subj-group><subject>Caenorhabditis elegans</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Computer modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Biostatistics</subject><subject>Statistical methods</subject></subj-group></subj-group><subj-group><subject>Discrete mathematics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Research and analysis methods</subject><subj-group><subject>Model organisms</subject><subj-group><subject>Animal models</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Stochastic Blockmodeling of the Modules and Core of the <italic>Caenorhabditis elegans</italic> Connectome</article-title>
<alt-title alt-title-type="running-head">Stochastic Blockmodeling of <italic>C. elegans</italic> Connectome</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Pavlovic</surname><given-names>Dragana M.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Vértes</surname><given-names>Petra E.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname><given-names>Edward T.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Schafer</surname><given-names>William R.</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Nichols</surname><given-names>Thomas E.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Statistics and Warwick Manufacturing Group, University of Warwick, Coventry, United Kingdom</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Brain Mapping Unit, Behavioural and Clinical Neuroscience Institute, Department of Psychiatry, University of Cambridge, Cambridge, United Kingdom</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>GlaxoSmithKline, Clinical Unit Cambridge, Addenbrooke's Hospital, Cambridge, United Kingdom</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Cambridgeshire and Peterborough NHS Foundation Trust, Cambridge, United Kingdom</addr-line></aff>
<aff id="aff5"><label>5</label><addr-line>Medical Research Council Laboratory of Molecular Biology, Cell Biology Division, Cambridge, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Cymbalyuk</surname><given-names>Gennady</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Georgia State University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">d.pavlovic@warwick.ac.uk</email></corresp>
<fn fn-type="conflict"><p>ETB is employed half-time by the University of Cambridge and half-time by GlaxoSmithKline; and holds stock in GSK. The other authors have declared that no competing interest exist. This does not alter the authors' adherence to all the PLOS ONE policies on sharing data and materials.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: DMP PEV ETB TEN. Performed the experiments: DMP. Analyzed the data: DMP TEN. Contributed reagents/materials/analysis tools: PEV ETB DMP TEN. Wrote the paper: DMP PEV ETB WRS TEN. Biological interpretations: PEV WRS.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>2</day><month>7</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>7</issue>
<elocation-id>e97584</elocation-id>
<history>
<date date-type="received"><day>18</day><month>7</month><year>2013</year></date>
<date date-type="accepted"><day>21</day><month>4</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Pavlovic et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Recently, there has been much interest in the community structure or mesoscale organization of complex networks. This structure is characterised either as a set of sparsely inter-connected modules or as a highly connected core with a sparsely connected periphery. However, it is often difficult to disambiguate these two types of mesoscale structure or, indeed, to summarise the full network in terms of the relationships between its mesoscale constituents. Here, we estimate a community structure with a stochastic blockmodel approach, the Erdős-Rényi Mixture Model, and compare it to the much more widely used deterministic methods, such as the Louvain and Spectral algorithms. We used the <italic>Caenorhabditis elegans</italic> (<italic>C. elegans</italic>) nervous system (connectome) as a model system in which biological knowledge about each node or neuron can be used to validate the functional relevance of the communities obtained. The deterministic algorithms derived communities with 4–5 modules, defined by sparse inter-connectivity between all modules. In contrast, the stochastic Erdős-Rényi Mixture Model estimated a community with 9 blocks or groups which comprised a similar set of modules but also included a clearly defined core, made of 2 small groups. We show that the “core-in-modules” decomposition of the worm brain network, estimated by the Erdős-Rényi Mixture Model, is more compatible with prior biological knowledge about the <italic>C. elegans</italic> nervous system than the purely modular decomposition defined deterministically. We also show that the blockmodel can be used both to generate stochastic realisations (simulations) of the biological connectome, and to compress network into a small number of super-nodes and their connectivity. We expect that the Erdős-Rényi Mixture Model may be useful for investigating the complex community structures in other (nervous) systems.</p>
</abstract>
<funding-group><funding-statement>DMP is supported by the MRC Industrial CASE award with GlaxoSmithKline's Clinical Unit Cambridge (UK) PhD studentship. PEV is supported by Medical Research Council (grant number MR/K020706/1). ETB is employed half-time by the University of Cambridge and half-time by GlaxoSmithKline (GSK); he holds stock in GSK. The Behavioural and Clinical Neuroscience Institute is supported by the Medical Research Council (UK) and Wellcome Trust. TEN is supported by NIH U54MH091657-03 and Wellcome Trust. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>The past thirty years have seen increasing interest in the systems-level understanding of structures as diverse as the global economy <xref ref-type="bibr" rid="pone.0097584-Dicken1">[1]</xref>, ecosystems <xref ref-type="bibr" rid="pone.0097584-Ulanowicz1">[2]</xref>, living cells <xref ref-type="bibr" rid="pone.0097584-Ravasz1">[3]</xref>, power grids <xref ref-type="bibr" rid="pone.0097584-Albert1">[4]</xref> and more. To obtain deeper insights into the operational mechanisms governing these systems, the scientific focus has gradually moved away from the analysis of their isolated components to the ways in which these components interact to perform the functions that characterise the system as a whole. In this manner, a wide range of systems can all be studied as networks, defined through their elements (vertices or nodes) and the connections (edges) that link them. A system's functional properties can then be studied in terms of the connection structure that is associated with its network.</p>
<p>In the context of the brain, the same approach can be used to study how simple elements (e.g., neurons) are organised into circuits to process information. This allows us to gain greater insights than the study of a single, isolated element would normally provide. For example, individual neurons can engage in complex physiological responses that are triggered by interactions between larger numbers of neurons locked in circuits. Thus, the knowledge of such circuits can provide a better understanding of brain activity <xref ref-type="bibr" rid="pone.0097584-Sporns1">[5]</xref>. In addition, brain and mind disorders are increasingly thought of in terms of damage to the connections between brain regions <xref ref-type="bibr" rid="pone.0097584-Bullmore1">[6]</xref>.</p>
<p>Although network analysis has great potential for addressing some of the key questions in neuroscience, its application at a cellular scale is only possible for one complete nervous system, namely that of <italic>Caenorhabditis elegans</italic>. Indeed, <italic>C. elegans</italic> is the only organism whose connectome (or pattern of neuronal connections) has been mapped extensively at the level of neurons and synapses, and it has therefore become a gold standard system for brain connectivity analyses <xref ref-type="bibr" rid="pone.0097584-Fortunato1">[7]</xref>–<xref ref-type="bibr" rid="pone.0097584-Towlson1">[9]</xref>.</p>
<p>However, even this simple model system consists of close to 300 individual neurons and more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e001" xlink:type="simple"/></inline-formula> edges, making its analysis non-trivial. Nevertheless, a tractable analysis is possible when it is considered that networks with high functional requirements tend to be organised in terms of homogeneous clusters that define different levels of functional hierarchy <xref ref-type="bibr" rid="pone.0097584-Bullmore2">[10]</xref>, <xref ref-type="bibr" rid="pone.0097584-Meunier1">[11]</xref>. Indeed, decomposing such networks into a collection of functionally coherent clusters, known as mesoscale organisation or community structure, can serve as a meaningful summary of the overall network's structure.</p>
<p>However, one of the underlying difficulties in the inference of a network's community structure is that the concept of “community” is not precisely defined. This degree of arbitrariness has generated diverse methodological solutions which can, in a broad sense, be classified into two groups: deterministic methods based on heuristic objective functions, and model-based methods that relate the observable data to unobservable parameters of interest with a statistical model <xref ref-type="bibr" rid="pone.0097584-Goldenberg1">[12]</xref>.</p>
<p>Within the framework of deterministic methods, an exhaustive search over the sample space of all possible community structures and their corresponding partitions is astronomically large <xref ref-type="bibr" rid="pone.0097584-Fortunato2">[13]</xref>. Nevertheless, various methods are available for particular definitions of community structure. One class of such methods (i.e., community detection algorithms) searches for groups of nodes, called modules, that comprise a high density of links within them and a lower density of links between them. The popularity of these algorithms stems from the fact that they are computationally feasible and, in particular, some of them can determine an optimal number of modules. We consider two such deterministic methods, namely the Fast Louvain algorithm <xref ref-type="bibr" rid="pone.0097584-Blondel1">[14]</xref> and the Spectral algorithm <xref ref-type="bibr" rid="pone.0097584-Newman1">[15]</xref>, <xref ref-type="bibr" rid="pone.0097584-Newman2">[16]</xref>, chosen because of their widespread use in the literature.</p>
<p>In contrast to this, model-based methods use statistical tools to estimate the community structure in a process which is generally known as the stochastic blockmodeling. The origins of this approach can be found in the sociometric literature, dating back to the work of Lorrain and White <xref ref-type="bibr" rid="pone.0097584-Lorrain1">[17]</xref> and others <xref ref-type="bibr" rid="pone.0097584-Goldenberg1">[12]</xref>, <xref ref-type="bibr" rid="pone.0097584-White1">[18]</xref>, <xref ref-type="bibr" rid="pone.0097584-Doreian1">[19]</xref> who formulated methods similar to those of modern day network compression, as well as other articles that developed stochastic blockmodels <xref ref-type="bibr" rid="pone.0097584-Holland1">[20]</xref>–<xref ref-type="bibr" rid="pone.0097584-Anderson1">[22]</xref>. Although there are various types of stochastic blockmodels which differ in terms of parametrisation and estimation strategies, they share a consistent view of the community structure in a network. In particular, the observed network is seen as a random realisation from a sample space of all possible networks, and community structure is seen as a collection of blocks; all nodes in a given block share the same probabilities of connection with other nodes in the network. Formally, this is known as the stochastic equivalence (see <xref ref-type="fig" rid="pone-0097584-g001">Figure 1</xref>). The distinctive feature of this approach is that it groups nodes together according to their similarity of connection patterns, in contrast to other community detection algorithms that groups nodes solely on the basis of high density of connections. With such approach, we can recognise a group of densely connected nodes as comprised of distinct groups, distinguished by their extra-block connections (see <xref ref-type="fig" rid="pone-0097584-g001">Figure 1 (b)</xref>, where Block A's connections to Block C differentiate it from Block B, despite similar connections within and between Blocks A &amp; B).</p>
<fig id="pone-0097584-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g001</object-id><label>Figure 1</label><caption>
<title>Network decomposition in terms of stochastic equivalence.</title>
<p>(<bold>A</bold>) Block decomposition of an undirected network on 15 nodes (numbered from 1 to 15), where the blue circles mark the presence of connection, the empty circles mark the absence of connection and the red lines demarcate Block A, B and C. (<bold>B</bold>) Compressed, stochastic representation of Block A in the network's block decomposition. Block A is defined as a group of stochastically equivalent nodes, each node having a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e002" xlink:type="simple"/></inline-formula> chance to form an edge with another node in Block A, a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e003" xlink:type="simple"/></inline-formula> chance to form an edge with another node in block B and a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e004" xlink:type="simple"/></inline-formula> chance to form an edge with another node in Block C.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g001" position="float" xlink:type="simple"/></fig>
<p>Identifying the best possible decomposition of a network into such blocks and identifying the associated connectivity rules is an area of active research in statistics. While the classic stochastic blockmodel proposed by Nowicki and Snijders <xref ref-type="bibr" rid="pone.0097584-Snijders1">[23]</xref> can handle small networks (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e005" xlink:type="simple"/></inline-formula> nodes), the more recent Erdős-Rényi Mixture Model (ERMM) proposed by Daudin et al. <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref> can handle networks with several thousand nodes. In the ERMM, each block is modelled as a small Erdős-Rényi network with a common probability of internal connections, and the relationship between each block pair is also modelled as a separate Erdős-Rényi network specified by a probability of inter-group connections (as in <xref ref-type="fig" rid="pone-0097584-g001">Figure 1</xref>). Fitting the ERMM requires the estimation of the total number of blocks, the connection probabilities within each block and between each block pair, as well as the assignment of nodes into blocks. The output consists of both an estimated community structure and a simple model for the connectivity between blocks.</p>
<p>In this paper, we compare the quality of the community structure identified by the ERMM to those found by more traditional community detection methods. We quantify the results of all 3 methods using prior data on the neurons (nodes) and synapses (edges) of the <italic>C. elegans</italic> connectome. We also illustrate the ability of the ERMM to capture other forms of mesoscale structure in the network beyond the presence of modules and to summarise the structure as a compressed network of super-nodes. In particular, we show that the ERMM provides a natural framework for identifying the core-periphery structure, defined as the densely connected core and sparsely connected periphery <xref ref-type="bibr" rid="pone.0097584-Borgatti1">[25]</xref>, a structure that cannot be identified by the deterministic community detection algorithms. Furthermore, we show that the ERMM can isolate biologically coherent groups of neurons and that it also provides a generative model yielding, for example, a good approximation of the network's degree distribution and means to simulate new data.</p>
</sec><sec id="s2">
<title>Data and Methods</title>
<sec id="s2a">
<title>Data</title>
<p>The neuronal network of the adult nematode <italic>C. elegans</italic> was first described in the publication by White et al. <xref ref-type="bibr" rid="pone.0097584-White2">[26]</xref> and was recently revised by Chen et al. <xref ref-type="bibr" rid="pone.0097584-Chen1">[27]</xref> and Varshney et al. <xref ref-type="bibr" rid="pone.0097584-Varshney1">[28]</xref>. It expresses the regime of connections between the animal's 282 somatic neurons and classifies them with respect to their type and direction (<ext-link ext-link-type="uri" xlink:href="http://www.wormatlas.org/neuronalwiring.html" xlink:type="simple">http://www.wormatlas.org/neuronalwiring.html</ext-link>, accessed 15th June 2013).</p>
<p>In our analysis, we consider a subset of this data where 3 disconnected neurons (VC06, CANL and CANR) are excluded from the set and we take all connections to be undirected. Furthermore, while the connections are distinguished in terms of their type (chemical synapses, gap junctions and neuromuscular junctions), we treat all connections as binary, that is, we assign value 1 if some type of connection exist and 0 otherwise. This yields a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e006" xlink:type="simple"/></inline-formula> binary and symmetric adjacency matrix with 2287 edges that defines the <italic>C. elegans</italic> network.</p>
<p>For an external evaluation of the community estimates, we use <italic>categorical</italic> and <italic>quantitative</italic> characteristics of the neurons (node-wise features) and <italic>quantitative</italic> characteristics of the edges (edge-wise features), as summarised in <xref ref-type="table" rid="pone-0097584-t001">Table 1</xref>.</p>
<table-wrap id="pone-0097584-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.t001</object-id><label>Table 1</label><caption>
<title>Prior biological features of the <italic>C. elegans</italic> connectome.</title>
</caption><alternatives><graphic id="pone-0097584-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Name</td>
<td align="left" rowspan="1" colspan="1">Type</td>
<td align="left" rowspan="1" colspan="1">Node-wise</td>
<td align="left" rowspan="1" colspan="1">Edge-wise</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Ganglion Classification (10 groups)</td>
<td align="left" rowspan="1" colspan="1">Categorical</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Neuron Type (4 groups)</td>
<td align="left" rowspan="1" colspan="1">Categorical</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Neuron Class (103 groups)</td>
<td align="left" rowspan="1" colspan="1">Categorical</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Locomotion Circuit (84 nodes)</td>
<td align="left" rowspan="1" colspan="1">Categorical</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Anatomical Location</td>
<td align="left" rowspan="1" colspan="1">Quantitative</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Anatomical Distance</td>
<td align="left" rowspan="1" colspan="1">Quantitative</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">√</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Birth Time</td>
<td align="left" rowspan="1" colspan="1">Quantitative</td>
<td align="left" rowspan="1" colspan="1">√</td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Birth Time Difference</td>
<td align="left" rowspan="1" colspan="1">Quantitative</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">√</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Lineage Distance</td>
<td align="left" rowspan="1" colspan="1">Quantitative</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">√</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>There is a large body of knowledge on the individual neurons, producing node-wise features. For example, we use the classification of neurons into ten anatomically defined ganglia (“Ganglion classification”), the classification of neurons by their circuitry (“Neuron type”) defined by four groups (sensory, motor, interneurons and polymodal neurons), as well as topological and synaptic division of neurons (“Neuron class”) defined by 103 groups <xref ref-type="bibr" rid="pone.0097584-Varshney1">[28]</xref>, <xref ref-type="bibr" rid="pone.0097584-Altun1">[29]</xref>. We also consider ventral nerve cord motor neurons involved in locomotion, egg-laying and possibly avoidance (broadly labelled as “Locomotion circuit” in <xref ref-type="table" rid="pone-0097584-t001">Table 1</xref>) which was described by Haspel et al. <xref ref-type="bibr" rid="pone.0097584-Haspel1">[30]</xref> using connection data from Chalfie and White <xref ref-type="bibr" rid="pone.0097584-Wood1">[31]</xref>, Von Stetina et al. <xref ref-type="bibr" rid="pone.0097584-VonStetina1">[32]</xref>, Altun and Hall <xref ref-type="bibr" rid="pone.0097584-Altun2">[33]</xref>, and Chen et al. <xref ref-type="bibr" rid="pone.0097584-Chen1">[27]</xref>. Explicitly, this circuit is composed of 84 neurons, of which 74 are motor neurons (excluding VC06) that comprise eight neuron classes. Four of these classes are connected to ventral muscles (VA, VD,VB and VC) while the other four classes are connected to dorsal muscles (AS, DA, DD and DB). The remaining 10 neurons are interneurons (AVA, AVD and AVE; AVB and PVC) promoting backward and forward motion. Although the connection data used in our analysis do not include neuromuscular connections, the circuit presented by Haspel et al. <xref ref-type="bibr" rid="pone.0097584-Haspel1">[30]</xref> provides some invaluable insights that are beneficial to the evaluation and comparison of the results obtained in our analysis. The remaining set of the node-wise features includes “Anatomical Location” (longitudinal and sectional positions) of the cell body (soma) and the “Birth Time” of each neuron (<ext-link ext-link-type="uri" xlink:href="http://www.biological-networks.org/?page_id=25" xlink:type="simple">http://www.biological-networks.org/?page_id=25</ext-link>, accessed 15th June 2013) <xref ref-type="bibr" rid="pone.0097584-Varier1">[34]</xref>.</p>
<p>Edge-wise features include the “Anatomical Distance” (Euclidean distance between each neuron pair), the “Birth Time Difference” (for each neuron pair, we take an absolute difference in their birth times) and the “Lineage Distance” (for each neuron pair, this is the sum of total divisions to the most recent common ancestor cell) <xref ref-type="bibr" rid="pone.0097584-Brenner1">[35]</xref>.</p>
</sec><sec id="s2b">
<title>Methods</title>
<p>Our analysis consists of two stages. In the first stage, we derive community structures of the <italic>C. elegans</italic> neural network using 3 different methods, as described next. In the second stage, we estimate how well each network decomposition explains the system's known prior biological properties. The general techniques used for this part of the analysis are summarised in Section “Evaluation Methods”.</p>
<p>We first fix our general notation, but emphasise that the terms “network” and “graph” are used interchangeably. A graph <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e007" xlink:type="simple"/></inline-formula> is defined as an object formed by a finite set of vertices (nodes) <italic>V</italic> of size <italic>n</italic> and a list of unordered pairs of vertices <italic>E</italic> (edge list) of size <italic>m</italic>. For a simple graph (i.e., graph without multiple edges or self connected vertices), the adjacency matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e008" xlink:type="simple"/></inline-formula> is symmetric and binary, that is, its elements <italic>A<sub>ij</sub></italic> take value 1 if there is an edge between vertices <italic>V<sub>i</sub></italic> and <italic>V<sub>j</sub></italic> and 0 otherwise. The degree of each vertex is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e009" xlink:type="simple"/></inline-formula>, the number of edges connected to a vertex, while the set of all degrees is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e010" xlink:type="simple"/></inline-formula>. Additionally, a graph can be characterised by a clustering coefficient that measures the tendency of its edges to form clusters. The clustering coefficient, defined by Newman <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref>, <xref ref-type="bibr" rid="pone.0097584-Newman3">[36]</xref> is<disp-formula id="pone.0097584.e011"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e011" xlink:type="simple"/><label>(1)</label></disp-formula>the prevalence of fully connected triplets of nodes among the set of triplets that have at least two connections.</p>
<sec id="s2b1">
<title>The Erdős-Rényi Mixture Model (ERMM)</title>
<p>The Erdős-Rényi (ER) model for a graph <xref ref-type="bibr" rid="pone.0097584-Erds1">[37]</xref>, <xref ref-type="bibr" rid="pone.0097584-Gilbert1">[38]</xref> specifies that edges occur independently with a common probability. Real world graphs are rarely so homogeneous, and the ER model is generally not useful. In contrast, the Erdős-Rényi Mixture Model <xref ref-type="bibr" rid="pone.0097584-Snijders1">[23]</xref>, <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref>, <xref ref-type="bibr" rid="pone.0097584-Latouche1">[39]</xref>–<xref ref-type="bibr" rid="pone.0097584-Zanghi2">[41]</xref> poses an ER model on subsets of edges within the graph.</p>
<p>In the ERMM, the adjacency matrix is treated as a random variable denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e012" xlink:type="simple"/></inline-formula> and the nodes are assumed to be allocated into <italic>Q</italic> unknown (latent) groups or blocks, indexed by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e013" xlink:type="simple"/></inline-formula>. We record the group assignment of each node <italic>V<sub>i</sub></italic> with a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e014" xlink:type="simple"/></inline-formula> dimensional random (classification) vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e015" xlink:type="simple"/></inline-formula>, whose elements <italic>Z<sub>iq</sub></italic> take value 1 if <italic>V<sub>i</sub></italic> belongs to the <italic>q</italic>-th group and 0 otherwise; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e016" xlink:type="simple"/></inline-formula> as each node belongs to exactly one group. The set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e017" xlink:type="simple"/></inline-formula> then consists of independent, identically distributed random variables, each following a single trial multinomial distribution<disp-formula id="pone.0097584.e018"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e018" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e019" xlink:type="simple"/></inline-formula> is a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e020" xlink:type="simple"/></inline-formula> dimensional vector whose elements satisfy the constraint <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e021" xlink:type="simple"/></inline-formula>. The elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e022" xlink:type="simple"/></inline-formula> describe the size or prevalence of each group, or, alternatively, can be interpreted as the probability that a randomly chosen node is contained in the <italic>q</italic>-th group. Note that different assumptions about the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e023" xlink:type="simple"/></inline-formula> are also possible (see, e.g., the recent publication of Latouche et al. <xref ref-type="bibr" rid="pone.0097584-Latouche2">[42]</xref> who proposed an overlapping stochastic blockmodel).</p>
<p>The ERMM specifies that, given the group (block) assignments of the vertices, the elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e024" xlink:type="simple"/></inline-formula> are conditionally independent Bernoulli random variables with rates given by their corresponding elements in the connectivity matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e025" xlink:type="simple"/></inline-formula>. In other words, if a vertex <italic>V<sub>i</sub></italic> belongs to group <italic>q</italic> and a vertex <italic>V<sub>j</sub></italic> belongs to group <italic>l</italic>, then<disp-formula id="pone.0097584.e026"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e026" xlink:type="simple"/><label>(3)</label></disp-formula>As is often the case with mixture models, the likelihood is stated as an incomplete data problem which is optimised for different values of <italic>Q</italic>, that is, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e027" xlink:type="simple"/></inline-formula>. In the ERMM, however, such optimisation is particularly challenging. Nevertheless, the estimating equations of the model's parameters (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e028" xlink:type="simple"/></inline-formula>) can still be obtained with an approximate <italic>variational method</italic> <xref ref-type="bibr" rid="pone.0097584-Jaakkola1">[43]</xref>, <xref ref-type="bibr" rid="pone.0097584-Jordan1">[44]</xref>. With an additional parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e029" xlink:type="simple"/></inline-formula>(i.e., the variational parameter for <italic>V<sub>i</sub></italic>), the estimating equations proposed in <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref> are<disp-formula id="pone.0097584.e030"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e030" xlink:type="simple"/><label>(4)</label></disp-formula><disp-formula id="pone.0097584.e031"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e031" xlink:type="simple"/><label>(5)</label></disp-formula>where we employ the usual statistical convention of lower Roman variables, <italic>x<sub>ij</sub></italic>, to denote the observed version of the random data, <italic>X<sub>ij</sub></italic>.</p>
<p>For each node, the largest variational parameter estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e032" xlink:type="simple"/></inline-formula> determines the classification vector estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e033" xlink:type="simple"/></inline-formula><disp-formula id="pone.0097584.e034"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e034" xlink:type="simple"/><label>(6)</label></disp-formula>The estimates just described depend on <italic>Q</italic>, the total number of partitions. To compare across different <italic>Q</italic>, the <italic>Integrated Classification Likelihood</italic> (ICL) criterion is used. For a model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e035" xlink:type="simple"/></inline-formula> with <italic>Q</italic> groups, the ICL criterion is<disp-formula id="pone.0097584.e036"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e036" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e037" xlink:type="simple"/></inline-formula> is an estimate of <italic>z</italic> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e038" xlink:type="simple"/></inline-formula>is the complete data log likelihood,<disp-formula id="pone.0097584.e039"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e039" xlink:type="simple"/><label>(8)</label></disp-formula>The details of each likelihood term as well as the derivation of the ICL criterion are presented in the Supplementary Text in File SI.</p>
<p>Intuitively, the ICL criterion considers the evidence for the clustered data (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e040" xlink:type="simple"/></inline-formula>), and, at the same time, it uses the term (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e041" xlink:type="simple"/></inline-formula>) to penalise the model's complexity and, therefore, preserve the simplicity and parsimony of the selected model. Hence, it is generally harder to select a model with a larger number of groups.</p>
<p>Using a Poisson approximation for a binomial distribution, the ERMM models the degree distribution as a mixture of Poisson distributions,<disp-formula id="pone.0097584.e042"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e042" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e043" xlink:type="simple"/></inline-formula> is the Poisson rate for the <italic>q</italic>-th group, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e044" xlink:type="simple"/></inline-formula>.</p>
<p>Finally, Daudin, Picard and Robin in <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref> proposed that the fitted ERMM can be used to estimate the Newman clustering coefficients (see <xref ref-type="disp-formula" rid="pone.0097584.e011">Eq. (1)</xref>) as<disp-formula id="pone.0097584.e045"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e045" xlink:type="simple"/><label>(10)</label></disp-formula>For further mathematical details on the ERMM, see Supplementary Text in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>.</p>
</sec><sec id="s2b2">
<title>The Spectral and Fast Louvain Algorithms</title>
<p>In contrast to the ERMM, the Spectral and Fast Louvain algorithms are deterministic methods that assess the goodness of a graph partition with an objective function known as <italic>modularity</italic> <xref ref-type="bibr" rid="pone.0097584-Newman4">[45]</xref>. Central to the definition of modularity is the difference between the observed edge (<italic>A<sub>ij</sub></italic>) and the expected number of edges (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e046" xlink:type="simple"/></inline-formula>) in an equivalent graph with <italic>m</italic> edges and with randomly connected vertices <xref ref-type="bibr" rid="pone.0097584-Luczak1">[46]</xref>–<xref ref-type="bibr" rid="pone.0097584-Pattison1">[48]</xref>. Modularity is defined as<disp-formula id="pone.0097584.e047"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e047" xlink:type="simple"/><label>(11)</label></disp-formula>where <italic>c<sub>i</sub></italic> and <italic>c<sub>j</sub></italic> represent the groups of vertices <italic>V<sub>i</sub></italic> and <italic>V<sub>j</sub></italic>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e048" xlink:type="simple"/></inline-formula> if <italic>V<sub>i</sub></italic> and <italic>V<sub>j</sub></italic> are located in the same module and 0 otherwise.</p>
</sec><sec id="s2b3">
<title>The Spectral Algorithm</title>
<p>The Spectral algorithm <xref ref-type="bibr" rid="pone.0097584-Newman1">[15]</xref>, <xref ref-type="bibr" rid="pone.0097584-Rubinov1">[49]</xref> optimises modularity (<xref ref-type="disp-formula" rid="pone.0097584.e047">Eq. (11)</xref>) by utilising the eigenvalues and eigenvectors associated with the modularity matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e049" xlink:type="simple"/></inline-formula> with elements defined as<disp-formula id="pone.0097584.e050"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e050" xlink:type="simple"/><label>(12)</label></disp-formula>The graph is split into two modules by setting an indicator vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e051" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e052" xlink:type="simple"/></inline-formula> if the vertex <italic>V<sub>i</sub></italic> is located in the module and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e053" xlink:type="simple"/></inline-formula> otherwise. Hence, the modularity can be expressed as<disp-formula id="pone.0097584.e054"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e054" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e055" xlink:type="simple"/></inline-formula> is the eigenvalue of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e056" xlink:type="simple"/></inline-formula> corresponding to the eigenvector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e057" xlink:type="simple"/></inline-formula>. Observe that, for a given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e058" xlink:type="simple"/></inline-formula> and a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e059" xlink:type="simple"/></inline-formula> consisting only of 1's or −1's, the inner product vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e060" xlink:type="simple"/></inline-formula> is maximised by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e061" xlink:type="simple"/></inline-formula>. This creates two groups, of not necessarily equal size, and each group is in turn split with the additional contribution to modularity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e062" xlink:type="simple"/></inline-formula> being defined as<disp-formula id="pone.0097584.e063"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e063" xlink:type="simple"/><label>(14)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e064" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e065" xlink:type="simple"/></inline-formula> (for a group <italic>g</italic> of size <italic>n<sub>g</sub></italic>) whose elements are: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e066" xlink:type="simple"/></inline-formula>. When no more positive eigenvalues are found, the algorithm stops. More details on the Spectral Algorithm can be found in Supplementary Text in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>.</p>
</sec><sec id="s2b4">
<title>The Fast Louvain Algorithm</title>
<p>The Fast Louvain algorithm <xref ref-type="bibr" rid="pone.0097584-Blondel1">[14]</xref> optimises modularity (<xref ref-type="disp-formula" rid="pone.0097584.e047">Eq. (11)</xref>) in two stages that are repeated iteratively. The algorithm is initialised by assigning each vertex to its own module and, hence, the initial number of groups is equal to the number of vertices. In the first stage, for each vertex <italic>V<sub>i</sub></italic>, the algorithm considers each of its neighbours and computes the gain of modularity that would have been obtained if the vertex <italic>V<sub>i</sub></italic> was placed in the same module as its neighbour <italic>V<sub>j</sub></italic>. The vertex <italic>V<sub>i</sub></italic> is assigned to the module for which this gain is the largest or, in the case of no positive gain, the vertex stays in its initial module. This process is applied sequentially, cycling through every vertex until no individual move can improve the modularity at which point the first stage stops.</p>
<p>In the second stage, the algorithm builds a new network whose vertices are identified as the modules found in the first stage. This gives a simplified community structure that is used as the initialisation for the next pass of the first stage. These two stages are repeated until the maximal modularity is attained.</p>
</sec><sec id="s2b5">
<title>Practical Aspects</title>
<p>Community estimation methods are notoriously sensitive to the initial starting conditions (see e.g., <xref ref-type="bibr" rid="pone.0097584-Mukherjee1">[50]</xref>). Each method begins with some sort of random initialisation that typically will lead to a local optimum of the objective function (i.e., ICL or modularity). Thus, for all three methods considered, we use multiple random restarts of the algorithm and take the solution that provides the greatest value of the objective function.</p>
</sec></sec><sec id="s2c">
<title>Evaluation Methods</title>
<p>To measure the similarity between a partition (i.e., complete segmentation of a graph into a set of groups) and some known biological classifications, we use the Adjusted Rand Index (ARI) <xref ref-type="bibr" rid="pone.0097584-Handl1">[51]</xref>, <xref ref-type="bibr" rid="pone.0097584-Hubert1">[52]</xref>. This measure is a modification of the Rand Index (RI) <xref ref-type="bibr" rid="pone.0097584-Rand1">[53]</xref>, that is expressed as the fraction of vertex pairs that are consistent: a vertex pair is consistent between two partitions if either (a) the vertex pair is within the same group in both partitions, or (b) the vertex pair is split between two groups in both partitions. The interpretation of the RI depends on the number of groups <xref ref-type="bibr" rid="pone.0097584-Morey1">[54]</xref>, whereas the ARI is adjusted for chance agreement and number of groups <xref ref-type="bibr" rid="pone.0097584-Hubert1">[52]</xref>. It is defined as<disp-formula id="pone.0097584.e067"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e067" xlink:type="simple"/><label>(15)</label></disp-formula>where the expectation is computed assuming a hypergeometric distribution of the counts of consistent vertex pairs. ARI scores range from 0 to 1, and indicate the proportion of overlap; for example, if two partitions have an ARI score of 0.6, this means that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e068" xlink:type="simple"/></inline-formula> of the nodes are classified in the same groups.</p>
<p>To assess the quality of a partition with respect to quantitative biological features, we use the Intra-class Correlation Coefficient (ICC). The ICC measures the variance that a partition explains in a continuous variable. As per best practice, we estimate the ICC with a mixed effects model <xref ref-type="bibr" rid="pone.0097584-Dobson1">[55]</xref>. For a node-wise measure, if we denote <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e069a" xlink:type="simple"/></inline-formula> as the measure on the <italic>i</italic>-th neuron in the <italic>q</italic>-th group, the mixed effects model is<disp-formula id="pone.0097584.e069"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e069" xlink:type="simple"/><label>(16)</label></disp-formula>where <italic>a<sub>q</sub></italic> is the random effect of the <italic>q</italic>-th group, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e070" xlink:type="simple"/></inline-formula> is the random error term and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e071" xlink:type="simple"/></inline-formula> is the population mean. The random terms <italic>a<sub>q</sub></italic> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e072" xlink:type="simple"/></inline-formula> are mutually independent and each are independently and identically distributed normal random variables: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e073" xlink:type="simple"/></inline-formula>and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e074" xlink:type="simple"/></inline-formula>. The ICC is defined as the proportion of total variance explained by the between group variance,<disp-formula id="pone.0097584.e075"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e075" xlink:type="simple"/><label>(17)</label></disp-formula>In other words, the ICC tells us how homogeneous the biological feature is within the partitions of a proposed network decomposition. Note that, here, we defined the ICC for node-wise measures (e.g., anatomical location of neuron), but it can be also defined for edge-wise measures (e.g., Euclidean distance between neurons). While edge-wise measures may violate the independence assumption of the mixed effect model, the ICC will still be a useful metric to compare biological validity of different partitions.</p>
<p>Ideally, we would conduct a hypothesis test on the difference in fit between different community estimates. However, because the implied models are not nested, a traditional hypothesis test cannot be employed. Nevertheless, we are able to use model selection metrics, such as the Akaike Information Criterion (AIC) <xref ref-type="bibr" rid="pone.0097584-Akaike1">[56]</xref>. The AIC can be viewed as a measure of distances between a fitted model (i.e., an estimated partition) and the unknown true model (i.e., the true partition). Denoting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e076" xlink:type="simple"/></inline-formula> to be the model under consideration (i.e., one of the ERMM, Spectral or Louvain methods), the AIC score is defined as<disp-formula id="pone.0097584.e077"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e077" xlink:type="simple"/><label>(18)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e078" xlink:type="simple"/></inline-formula> is the log likelihood of the corresponding mixed effect model (<xref ref-type="disp-formula" rid="pone.0097584.e069">Eq. (16)</xref>) and <italic>p</italic> is the number of parameters in the model (here, <italic>p</italic> = 3). The preferred model is the one with the smallest AIC score (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e079" xlink:type="simple"/></inline-formula>). While the AIC is not an absolute measure, the differences in the AIC scores provide a way to compute approximate probabilities. In particular, the relative likelihood of the model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e080" xlink:type="simple"/></inline-formula> compared to the model that minimises the AIC is given as<disp-formula id="pone.0097584.e081"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0097584.e081" xlink:type="simple"/><label>(19)</label></disp-formula>and represents the relative strength of evidence for this model. Equivalently, this tells us how probable it is that the model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e082" xlink:type="simple"/></inline-formula> minimises the distance from the true model. As a general rule of guidance, it has been suggested <xref ref-type="bibr" rid="pone.0097584-Burnham1">[57]</xref> that, if the likelihood value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e083" xlink:type="simple"/></inline-formula>(or, equivalently <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e084" xlink:type="simple"/></inline-formula>), there is a substantial evidence that this model is equally useful; if the value is contained in the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e085" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e086" xlink:type="simple"/></inline-formula>), then, there is considerably less evidence; and, finally, for values that are strictly smaller than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e087" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e088" xlink:type="simple"/></inline-formula>), there is essentially no evidence that this model is useful.</p>
</sec><sec id="s2d">
<title>Software</title>
<p>We fitted the ERMM with the R package “Mixer” <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref>, <xref ref-type="bibr" rid="pone.0097584-Latouche1">[39]</xref>–<xref ref-type="bibr" rid="pone.0097584-Zanghi2">[41]</xref>. The “mixer” function specifies default values for the maximum number of iterations, and we found improved performance by increasing these (<monospace>nbiter = 80</monospace> up from 10, <monospace>fpnbiter = 40</monospace> up from <monospace>5</monospace>). We found <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e089" xlink:type="simple"/></inline-formula> random restarts was sufficient to visit the optimal solution multiple times, but, to be exhaustive, we also considered up to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e090" xlink:type="simple"/></inline-formula> random restarts.</p>
<p>The Fast Louvain and Spectral algorithms were carried out using the Matlab “Brain Connectivity Toolbox” (<ext-link ext-link-type="uri" xlink:href="http://www.brain-connectivity-toolbox.net/" xlink:type="simple">http://www.brain-connectivity-toolbox.net/</ext-link>, accessed 15th June 2013) <xref ref-type="bibr" rid="pone.0097584-Rubinov1">[49]</xref>. For the Fast Louvain algorithm, we used the function “modularity_louvain_und”, using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e091" xlink:type="simple"/></inline-formula>restarts. For the Spectral algorithm, we used the function “modularity_und”. This function is initiated on a randomly permuted adjacency matrix and although, in theory, all permutations of the adjacency matrix should provide the same result, some numerical discrepancies may occur during the spectral decomposition, subsequently leading to slightly different modularity fits. Specifically, the variability in the fits is driven by numerical errors in the estimation of the elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e092" xlink:type="simple"/></inline-formula>, which can erroneously change the sign of its element. For example, if the true value of an element of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e093" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e094" xlink:type="simple"/></inline-formula> and the error is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e095" xlink:type="simple"/></inline-formula>, the estimated value would be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e096" xlink:type="simple"/></inline-formula>. Indeed, this has an immediate impact on the vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e097" xlink:type="simple"/></inline-formula> which will classify the corresponding node in the wrong group. To be exhaustive, we have therefore used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e098" xlink:type="simple"/></inline-formula> restarts.</p>
<p>To calculate the ARI scores, we used the function “adjustedRandIndex” in R software <xref ref-type="bibr" rid="pone.0097584-Fraley1">[58]</xref>, <xref ref-type="bibr" rid="pone.0097584-Fraley2">[59]</xref> and, for the ICC and AIC, we use the R function “lmer” <xref ref-type="bibr" rid="pone.0097584-Bates1">[60]</xref> that employs a Restricted Maximum Likelihood procedure <xref ref-type="bibr" rid="pone.0097584-Harville1">[61]</xref> to obtain estimates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e099" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e100" xlink:type="simple"/></inline-formula> and AIC.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<p>We first detail the estimated mesoscale structure of the <italic>C. elegans</italic> brain network found by the Erdős-Rényi Mixture Model, and then we proceed to compare these results with the ones obtained by the Fast Louvain and Spectral algorithms. The final part considers the generative properties of the Erdős-Rényi Mixture Model with respect to the network's degree distribution and clustering coefficient.</p>
<sec id="s3a">
<title>Erdős-Rényi Mixture Model estimate of mesoscale structure in <italic>C. elegans</italic> brain network</title>
<p>The optimal Erdős-Rényi Mixture Model fit of the <italic>C. elegans</italic> brain network consists of 9 blocks, each of which is listed in <xref ref-type="fig" rid="pone-0097584-g002">Figure 2</xref>. In addition, the anatomical locations of neurons in each Block are given in <xref ref-type="fig" rid="pone-0097584-g003">Figure 3</xref>. Broadly speaking, we found that approximately 70% of the neurons in Block 1 are head sensory neurons involved in chemo/thermotaxis or chemo/thermosensation which modulate body movement. In contrast, most head sensory neurons (around 25%) in Block 2 are involved in more direct, reflex like and deterministic effects on body movement such as escape or avoidance behaviour, while almost 60% of the remaining neurons are ring interneurons (ADA, AIB, AVK, RIA, RIB, RIC, RIG, RIS, RMG, URX), about half of which have unknown function. Nevertheless, we characterised this block as “escape/avoidance” even though its function or perhaps functional homogeneity is not entirely clear. Next, more than half of neurons in Block 3 (55%) consists of mid-body and posterior ventral cord motor neurons, while almost all of the remaining neurons are posteriorly located sensory neurons (PDE, PHA, PHB, PHC, PLM, PVD, PVM), known to have quite a direct effect on motor neurons (e.g., PHA and PHB control extent of reversals in chemo-repulsion). We have labeled this group “motor (posterior)”, but we will revisit the possible causes for their inclusion. Similarly, close to 90% of neurons in Block 4 are made up of anteriorly located ventral cord motor neurons (AS, DA, DB, VA, VB, VD) which is therefore labeled as “motor (anterior)” group. The next two Blocks (5 &amp; 6) are among the smallest in size, each with only 6 neurons. In particular, 4 neurons in Block 5 are command interneurons for (backward) locomotion (AVD, AVE), while the remaining 2 neurons are DVA (mechanosensory integration) and PVR (unknown function); whereas all 6 neurons in Block 6 are locomotion command interneurons. Next, Block 7 is mostly (about 65%) composed of neurons with unknown function, however, as 15% of the neurons seem to be involved in egg-laying and defecation, we have labeled it as “unknown/egg-laying/defecation” group. The largest number of neurons is found in Block 8 which appears to be predominantly (about 60%) composed of head motor neurons and nose touch mechanoreceptors (mainly located in the head), as well as, a numerous ring motor neurons. Many of these neurons are involved in both local search behaviour (RIV, SMDD, SMDV) and avoidance or aversive head withdrawal (ALN, IL1D, IL1V, OLQD, OLQV, RMD). We labeled this block “nose-touch/head motor”, but it may be interesting to further investigate whether this block could be subdivided into more specialised subunits. The remaining Block 9 is composed entirely (100%) of anterior ventral cord motor neurons of class DB, DD, VB, VC and VD - as previously discussed, Block 4 contains the remaining of anterior ventral cord motor neurons of type AS, DA, DB, VA, VB, VD.</p>
<fig id="pone-0097584-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g002</object-id><label>Figure 2</label><caption>
<title>Classification of neurons for each Block of the ERMM fit.</title>
<p>The corresponding neuron labels are colour coordinated according to their ganglion type.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g002" position="float" xlink:type="simple"/></fig><fig id="pone-0097584-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g003</object-id><label>Figure 3</label><caption>
<title>Anatomical locations of neurons (cell body) in the ERMM fit.</title>
<p>Each Block is shown on an approximate template, obtained from <ext-link ext-link-type="uri" xlink:href="http://www.wormatlas.org/" xlink:type="simple">http://www.wormatlas.org/</ext-link>, last accessed 9th October 2013.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g003" position="float" xlink:type="simple"/></fig>
<p>Overall, these observations indicate that the ERMM based partition highlights functionally meaningful features of the system's mesoscale organization.</p>
<p>In <xref ref-type="fig" rid="pone-0097584-g004">Figure 4 (a)</xref>, we show the optimal ERMM fit as a reorganised adjacency matrix. Note that the ERMM fit demonstrates the dense connections between - as well as within - certain groups. This is in stark contrast to traditional community detection methods that seek to find modules with dense intra-modular connectivity and sparse connections between modules. Instead, the ERMM classifies neurons into separate groups according to their individual connectivity profile to other groups, regardless of where connectivity happens to be dense. For example, Block 6 (AVA, AVB, PVC) comprises neurons with maximal interconnections (i.e., clique), which are, however, also fairly densely connected to the rest of the network. Note that Blocks 5 (AVE, AVD) and 6 (AVA, AVB, PVC) are separate groups because of differing internal connection rates (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e101" xlink:type="simple"/></inline-formula> vs. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e102" xlink:type="simple"/></inline-formula>) and external connection rates (e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e103" xlink:type="simple"/></inline-formula> vs. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e104" xlink:type="simple"/></inline-formula>). Also, consider Blocks 1 (chemo/thermosensation or chemo/thermotaxsis) and 2 (escape/avoidance) whose rates of internal and external block connections seem very similar, until it is noted that Block 1 has virtually no connections with Block 8 (nose touch mechanoreceptors and head motor neurons), while Block 2 is densely connected to Block 8.</p>
<fig id="pone-0097584-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g004</object-id><label>Figure 4</label><caption>
<title>Reorganised adjacency matrices for each method.</title>
<p>The groups are ordered arbitrarily; within each group, the neuron labels are sorted in alphabetical order. (<bold>A</bold>) The ERMM fit demonstrates the dense connections between - as well as within - certain blocks. This is in stark contrast to traditional community detection methods (<bold>B</bold>) and (<bold>C</bold>), that seek to find modules with dense intra-modular connectivity and sparse connections between modules. In addition, the ERMM fit defines blocks according to their internal and external connections. Thus, although Block 1 and 2 have similar within block connections, they are split because of their different connectivity with Block 8.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g004" position="float" xlink:type="simple"/></fig>
<p>A concomitant advantage of the ERMM approach to community estimation is its ability to provide a compressed view of the original <italic>C. elegans</italic> network. As shown in <xref ref-type="fig" rid="pone-0097584-g005">Figure 5</xref>, this compressed view serves as a summary of the network's mesoscopic structure and reveals diverse patterns of connectivity between the blocks. Here, some blocks, such as Blocks 1, 6 and 8, appear to fit the standard definition of a “module” with high internal connectivity and sparse external connectivity. However, other structures which are characterised by strong communications between blocks are also present in the network; for example, Blocks 5 &amp; 6 and Blocks 6 &amp; 7, which may suggest that these are involved in the same functional circuit. In particular, Block 6 (command interneurons) - previously identified as a clique - maintains relatively strong ties with the Block 3 and 4 (motor neurons) whose internal connections, however, are sparse. This structure is known as the core-periphery and has been shown to be a functionally significant organisational structure in various real-world networks such as social networks or power grids <xref ref-type="bibr" rid="pone.0097584-Borgatti1">[25]</xref>, <xref ref-type="bibr" rid="pone.0097584-Ravasz2">[62]</xref>.</p>
<fig id="pone-0097584-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g005</object-id><label>Figure 5</label><caption>
<title>Compressed view of the <italic>C. elegans</italic> network, in terms of between/within block connection probability rates of the ERMM fit.</title>
<p>The relative size of each circle indicates the number of neurons in that Block. The number inside the circle is the within-block connection probability in percent. The relative thickness of each line indicates the between-group connection strength, while the number on the edge gives the connection probability in percent (those less than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e105" xlink:type="simple"/></inline-formula> are omitted). Each Block is broadly characterised by its most representative function. Note how Blocks 1, 2 and 9 are “modules” with internal connectivity that is greater than external connectivity, while other structures are characterised by strong inter-block connectivity (e.g., Blocks 5 &amp; 6 and Blocks 6 &amp; 7). In addition, Block 6 (command interneurons) maintains relatively strong ties with the Block 3 and 4 (motor neurons) whose internal connections, however, are sparse, an example of core-periphery.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g005" position="float" xlink:type="simple"/></fig>
<p>For further qualitative evaluation of the ERMM community estimate, we use the Locomotion circuit, as described in the accompanying text of <xref ref-type="table" rid="pone-0097584-t001">Table 1</xref>. <xref ref-type="fig" rid="pone-0097584-g006">Figure 6 (a)</xref> shows a simplified diagram of this circuit (originally presented by Haspel et al. <xref ref-type="bibr" rid="pone.0097584-Haspel1">[30]</xref>) with the neuron block membership indicated by colour. The ERMM isolated the command interneurons into Blocks 5 and 6; while Blocks 4, 3 and 9 are fairly uniformly spread over all motor neurons. The distinction between these three blocks of motor neurons appears to be, at least partially, anatomically motivated, with the neurons in Block 3 being more posterior while the neurons in Blocks 4 and 9 are mainly found in the mid-section and anterior parts of the animal. Another noteworthy point is that the neurons VC04 and VC05, both implicated in egg-laying, are assigned separately to Blocks 4 and 7. The principal justification of this separation can be traced back to the network data used in this analysis where, for example, VC04 maintains connections to locomotion neurons AVB and AVH, while VC05 does not and, moreover, VC05 maintains connections to egg-laying neurons AVFL, AVFR, HSNR and PVT (Block 7), while VC04 does not. Given such differences in connection profiles between these two neurons, it is not surprising that they are separated. Relating to this, it is also worth mentioning that our network data excludes neuromuscular connections to the vulval muscles, made by both VC04 and VC05 which are the primary reason why these neurons are implicated in egg-laying behaviour.</p>
<fig id="pone-0097584-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g006</object-id><label>Figure 6</label><caption>
<title><italic>C. elegans</italic> locomotion network and estimated community structure for each method.</title>
<p>Each subfigure shows the 74 Motor neurons (shown in rectangles) that support the animal's motion, which are divided into eight distinct groups. Four of these groups are connected to the ventral muscles (neuron labels: VA, VD, VB and VC; VC06 is omitted in our analysis), while the remaining four groups are connected to the dorsal muscles (neuron labels starting AS, DA, DD and DB). The remaining neurons (command neurons; shown in circles) belong to the category of interneurons; some are primarily required for promoting forward movements (labels starting PVC and AVB), while others promote backward movements (labels starting AVA, AVD and AVE). The colour of each neuron indicates the group membership from a particular method's partition. The ERMM fit (<bold>A</bold>) isolates the command neurons in Blocks 5 &amp; 6, and distinguishes the posterior (Block 3) from the more anterior motor neurons (Blocks 4 &amp; 9).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g006" position="float" xlink:type="simple"/></fig></sec><sec id="s3b">
<title>Comparison of the Erdős-Rényi Mixture Model fit with estimates from the Fast Louvain and Spectral algorithms</title>
<p>The Spectral and Fast Louvain algorithms decompose the <italic>C. elegans</italic> network into 4 and 5 modules with the maximal modularity scores of 0.402 and 0.411, respectively (<xref ref-type="disp-formula" rid="pone.0097584.e054">Eq. (13)</xref> and <xref ref-type="disp-formula" rid="pone.0097584.e047">(11)</xref>), indicating that both algorithms detect a prominent modular structure. As shown in the adjacency matrices in <xref ref-type="fig" rid="pone-0097584-g004">Figure 4 (b) and (c)</xref>, both the Spectral and Louvain algorithms produced partitions with strong within-group connections and relatively sparse inter-group connections, as expected by definition.</p>
<p>In order to compare the community structures obtained via all three methods, we plot an alluvial diagram (see <xref ref-type="fig" rid="pone-0097584-g007">Figure 7 (a) and (b)</xref>) showing each block of the ERMM method (on the left) and how these merge and split in order to make up the modules of the Louvain and Spectral partition. Strands of the alluvial diagram are coloured according to the block decomposition of the ERMM.</p>
<fig id="pone-0097584-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g007</object-id><label>Figure 7</label><caption>
<title>Correspondence between the ERMM fit and the estimates of Louvain (A) and Spectral (B) algorithms.</title>
<p>The strands of the alluvial diagram show each block of the ERMM fit (on the left) and how these merge and split to form the modules of the Louvain and Spectral algorithms (on the right). The functional labels for the ERMM blocks are as follows. Block 1 (chemosensation/thermosensation), Block 7 (unknown/egg-laying/defecation), Block 8 (nose touch/head/motor), Block 2 (escape/avoidance), Block 3 (motor posterior), Block 9 (motor anterior), Block 4 (motor anterior), Block 5 (command) and Block 6 (command).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g007" position="float" xlink:type="simple"/></fig>
<p>The first thing to note when observing this diagram is that the blocks obtained in the ERMM often roughly correspond to modules obtained via the other methods, with the Louvain and Spectral algorithm merging progressively more blocks into fewer modules. Secondly, we note that Blocks <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e106" xlink:type="simple"/></inline-formula> and 9 (mainly ventral cord motor neurons and interneurons controlling locomotion) are fairly well separated from Blocks <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e107" xlink:type="simple"/></inline-formula> and 8 by all algorithms, so we will discuss these two subsets separately below.</p>
<p>Most nodes in Block 1 (chemo/thermo sensation) are also classed together in the other two algorithms, although they are also merged with some nodes from Blocks 2 (escape/avoidance) and 7 (mainly unknown function) in Module 1 of the Louvain algorithm. In contrast, the nodes in Block 2 are fairly dispersed in the Louvain algorithm (equally distributed between Modules <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e108" xlink:type="simple"/></inline-formula> and 3), while they are split between Module 1 and 4 (mainly amphid neurons) by the Spectral algorithm. As noted earlier, neurons in Blocks 1 (chemo/thermo sensation) and 2 (escape/avoidance) are also tightly interconnected and they only fall as separate blocks because of their differential connectivity to nodes in Block 8 (nose-touch/head motor). The functional relevance of this finding is yet unclear but this pattern is biologically plausible and is a particularly striking aspect of the ERMM result (as shown in <xref ref-type="fig" rid="pone-0097584-g004">Figure 4 (a)</xref>). We also note that, while Block 8 seems to lump together many of the non-sensory neurons in the head, these neurons are also all grouped together by both the Spectral (Module 1) and the Louvain algorithm (Module 3). Nevertheless, it may be interesting to further investigate whether this block could be subdivided into more specialised subunits. One such approach could be to include in the analysis virtual nodes for the various external cues (chemical attractants, olfactory cues, temperature, touch, osmolarity, etc) or to include virtual nodes for the various muscle groups controlled by motor neurons, as this information has recently been shown to be useful in understanding the connectivity of motor neurons in the Locomotor system <xref ref-type="bibr" rid="pone.0097584-Haspel2">[63]</xref>.</p>
<p>Looking at Block 7, we note that it corresponds quite well to Module 3 in the Spectral algorithm, but it is split between all modules (and mainly Modules 1 and 4) in the Louvain algorithm. From <xref ref-type="fig" rid="pone-0097584-g004">Figure 4 (a)</xref>, it is clear that Block 7 has a very specific connectivity pattern. We therefore predict that this is likely to correspond to a biologically relevant functional grouping. This is particularly interesting because many of the neurons in this block have unknown functions and because these neurons are not anatomically co-located. Thus, in investigating the functional relevance of this block, it will be important to consider its particularly strong relationships to Blocks 2 and 6.</p>
<p>Now, turning our attention to Blocks <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e109" xlink:type="simple"/></inline-formula> and 9, we note the following observations. Block 4 is made up almost entirely of anteriorly located ventral cord motor neurons (AS, DA, DB, VA, VB, VD), while Block 9 is composed entirely of anterior ventral cord motor neurons (DB, DD, VB, VC and VD). These two blocks are merged by both the Spectral and Louvain algorithms, and looking at <xref ref-type="fig" rid="pone-0097584-g004">Figure 4 (a)</xref>, their separation into two different blocks does not seem to be a strong feature of the ERMM method either. It seems to be based by a differential connectivity to Block 7, but the effect is not very strong.</p>
<p>As previously mentioned, Block 3 is composed mostly of mid-body and posterior ventral cord motor neurons and almost all of the remaining neurons are posteriorly located sensory neurons (PDE, PHA, PHB, PHC, PLM, PVD, PVM). Almost all neurons in this block (including the posteriorly located sensory neurons listed) are also grouped together in Module 4 of the Louvain algorithm and almost all of them are in Module 2 of the Spectral algorithm. We however note that, in the Spectral (but not Louvain) partition, these neurons are also grouped together with the anterior ventral cord motor neurons of Blocks 4 and 9. While the roughly anatomical split between ventral cord motor neurons in the ERMM and Louvain method may not lead to new biological insights, it is certainly driven by a strong lack of connectivity between Blocks 4 (anterior) and 3 (posterior) which is a true feature of the data. It is worth noting that the connectivity data for <italic>C. elegans</italic> are known to be partial or missing for 39 of 302 neurons, including 21 of the 75 locomotor motoneurons <xref ref-type="bibr" rid="pone.0097584-Haspel2">[63]</xref> and the data for the posterior parts of the nerve cords are especially sparse and uncertain. It is therefore unclear whether this split between Blocks <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e110" xlink:type="simple"/></inline-formula> and 9 contains biological information or whether a more complete mapping of connections in the posterior part of the ventral cord would alter these results. Note, for example, that the split does not correspond to a division between neurons involved in forward and backward locomotion <xref ref-type="bibr" rid="pone.0097584-Haspel1">[30]</xref>.</p>
<p>Finally, Blocks 5 and 6 are also merged with ventral cord motor neurons from Blocks 3 in both Louvain and Spectral algorithms. This is driven by the dense inter-connectivity between these nodes, however, the separation of Blocks 5 and 6 from the rest of the networks is one of the key features of the ERMM decomposition. Indeed, these blocks correspond almost exactly to the rich-club (core-periphery structure) whose functional importance has recently been confirmed <xref ref-type="bibr" rid="pone.0097584-Towlson1">[9]</xref>.</p>
<p>It is also worth noting that compressed views of the network - see the ERMM fit in <xref ref-type="fig" rid="pone-0097584-g005">Figure 5</xref> - are not available for the Fast Louvain and Spectral algorithms since these, by definition, decompose the network into modules with minimal connectivity between them.</p>
<p><xref ref-type="fig" rid="pone-0097584-g006">Figure 6 (b) and (c)</xref> show the Locomotion circuit and the partitions found by the Spectral and Fast Louvain algorithms. In contrast to the ERMM model, both of these algorithms failed to distinguish the command neurons from the motorneurons. In the case of the Spectral algorithm, some of the command neurons like AVEL and AVER are isolated but the rest are mixed with the motorneurons. This effect may be explained by the rigid definition of the notion of “community” that is common to both algorithms. As we can observe, this particular <italic>a priori</italic> assumption does not allow the network's topology to dictate the form of the community structure, resulting in functionally less meaningful decompositions. Similar observations can be made about the neurons VC04 and VC05, which are merged by both algorithms despite their different connectivity profiles, inherent to the data. As we saw previously, these neurons are split in the ERMM partition.</p>
<p>Further quantifications of the solutions in terms of the separation of of L/R (left/right symmetric) neurons of the same class are presented in Table S1 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>. Here, we note that out of 92 L/R neuron pairs, contained in this data set, the ERMM and Spectral algorithm partitions assigned 85 such neuron pairs in the same groups and misclassified 7 pairs, while the Louvain partitions misclassified 5 pairs. In general, ALM and SAAD are separated by all methods, while other misclassified neurons appear to be distinct.</p>
<p>Although the same block neurons in the ERMM partition appear to be functionally related, this overall partition does not correspond closely to the anatomical partition of neurons in 10 groups called ganglions (see <xref ref-type="fig" rid="pone-0097584-g002">Figure 2</xref> and Figures S1 &amp; S2 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>). More formal evaluations of this and other metrics, given in <xref ref-type="fig" rid="pone-0097584-g008">Figure 8 (a)</xref>, use the ARI (<xref ref-type="disp-formula" rid="pone.0097584.e067">Eq. (15)</xref>) scores to measure similarity between each of the known biological partitions (ganglion, neuron classes and neuron types) and each of the community estimate found by the methods. Collectively, the ARI scores are small and no greater than 0.26 for all 3 comparisons, with ganglion based partition being matched by the ERMM and Spectral algorithm with 0.25 ARI units, while the Louvain algorithm scored slightly lower. Compared to the 103 classes of neurons, the overall ERMM partition exhibits slightly higher ARI score than the partitions of the Louvain and Spectral algorithms, but note that these scores are still generally low. Similar observations hold for the ARI scores by neuron type, where the Spectral community estimate seems to be slightly more compatible than the other two fits, which tend to assign different neuron types to the same groups. These findings suggest that in general all 3 solutions are fairly different from the known biological partitions.</p>
<fig id="pone-0097584-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g008</object-id><label>Figure 8</label><caption>
<title>Method comparisons in terms of prior biological features.</title>
<p>(<bold>A</bold>) ARI scores computed between three known biological classifications - Ganglion, Neuron classes (103 groups) and Neuron type (sensory, motor, interneuron and polymodal) - and the fits of each method. Collectively, the ARI scores are small and no greater than 0.26 for all 3 methods, suggesting that all 3 solutions are fairly different from the known biological partitions. (<bold>B</bold>) ICC scores for the Anatomical location (longitudinal) (ALL), Anatomical location (sectional) (ALS), Anatomical distance (AD), Birth time (BT), Birth time difference (BTD) and Lineage distance (LD). The ICC results indicate that the ERMM partition explains more biological variance than either of the other two methods. Compared to each other, ICC scores of Spectral and Louvain fits are largely similar.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g008" position="float" xlink:type="simple"/></fig>
<p>However, it has to be noted that although the ARI score can quantify the level of similarity between partitions of interest, it cannot infer (i.e., assign a P-value) on whether one partition has significantly better fit than another partition. This is statistically challenging as the solutions (fits) are sourced from the 3 different methods and, therefore, simple validation strategies like the one presented in Pan et al. <xref ref-type="bibr" rid="pone.0097584-Pan1">[8]</xref> would not be appropriate. Nevertheless, using the ICC and AIC criterion, we can compare qualitatively all 3 estimates. For this, <xref ref-type="fig" rid="pone-0097584-g008">Figure 8 (b)</xref> shows the ICC (<xref ref-type="disp-formula" rid="pone.0097584.e075">Eq. (17)</xref>) performance of the estimated partitions with respect to six quantitative biological features. The hypothesis here is that neurons that are implicated in the same function or behaviour might be similar in terms of these quantitative features, so biologically meaningful community structures should be composed of groups that are relatively homogeneous in terms of these metrics. We note that the six quantitative biological features were selected based on the datasets available, but not all are expected to be equally useful or revealing. For example, although one might expect lineage distance (LD) to be relevant, in fact neurons of the same class (typically involved in the same function) develop around the same time and usually have no immediate common precursors. This is reflected in low ICC scores in all three methods for lineage distance. Birth time (or BTD) is therefore expected to be more representative of function, and this is confirmed by higher ICC across all methods, with ERMM showing particularly good performance. Similarly, anatomical location (especially in the longitudinal direction) is expected to cluster functionally related neurons close together. This is because neuronal placement tends to minimise wiring <xref ref-type="bibr" rid="pone.0097584-AlexanderBloch1">[64]</xref> and neurons involved in the same function therefore benefit by being close together both for efficient inter-connections between these neurons and because they are likely to be receiving similar (localised) external cues or controlling similar (localised) muscle groups. Again, the ERMM shows superior ICC in all distance related metrics.</p>
<p>Overall, the ERMM partition provides the best ICC scores on all six biological features. For example, the ERMM partition explains over 50% of the variance in the sectional anatomical location (ALS), while the other two methods explain only about half as much variability. Also, we note that neither the Louvain or Spectral measures dominate one another on the basis of the ICC scores.</p>
<p>Finally, we use the AIC score (<xref ref-type="disp-formula" rid="pone.0097584.e077">Eq. (18)</xref>) to assess if the differences between the partitions are significant. <xref ref-type="table" rid="pone-0097584-t002">Table 2</xref> shows the AIC score for each method and biological feature, and the minimum AIC score (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e111" xlink:type="simple"/></inline-formula>) always corresponds to the ERMM fit. Using <xref ref-type="disp-formula" rid="pone.0097584.e081">Eq. (19)</xref>, we compute the relative likelihood to assess how much more likely it is that the Louvain or Spectral partition minimises the distance from the true partition versus the ERMM partition. As we can observe in <xref ref-type="table" rid="pone-0097584-t002">Table 2</xref>, both the Louvain and Spectral fits fall far away from the bound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e112" xlink:type="simple"/></inline-formula>and, as such, they pose no evidence that these fits are more significant than the fit of the ERMM. In short, the AIC analysis unambiguously favours the ERMM fit as more compatible with the data, for all six of biological features, than the fits of the Louvain and Spectral algorithms.</p>
<table-wrap id="pone-0097584-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.t002</object-id><label>Table 2</label><caption>
<title>Individual AIC scores and relative likelihood of the ERMM, Spectral and Louvain partitions obtained on the set of biological features: Anatomical location (longitudinal) (ALL), Anatomical location (sectional) (ALS), Anatomical distance (AD), Birth time (BT), Birth time difference (BTD) and Lineage distance (LD).</title>
</caption><alternatives><graphic id="pone-0097584-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Biological Feature</td>
<td colspan="3" align="left" rowspan="1">AIC scores</td>
<td colspan="2" align="left" rowspan="1">Relative Likelihood</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">ERMM</td>
<td align="left" rowspan="1" colspan="1">Louvain</td>
<td align="left" rowspan="1" colspan="1">Spectral</td>
<td align="left" rowspan="1" colspan="1">Louvain vs. ERMM</td>
<td align="left" rowspan="1" colspan="1">Spectral vs. ERMM</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">ALL</td>
<td align="left" rowspan="1" colspan="1">57.47</td>
<td align="left" rowspan="1" colspan="1">93.77</td>
<td align="left" rowspan="1" colspan="1">163.33</td>
<td align="left" rowspan="1" colspan="1">1.31×10<sup>−8</sup></td>
<td align="left" rowspan="1" colspan="1">1.03×10<sup>−23</sup></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">ALS</td>
<td align="left" rowspan="1" colspan="1">–1478.54</td>
<td align="left" rowspan="1" colspan="1">–1408.02</td>
<td align="left" rowspan="1" colspan="1">–1410.16</td>
<td align="left" rowspan="1" colspan="1">4.84×10<sup>−16</sup></td>
<td align="left" rowspan="1" colspan="1">1.41×10<sup>−15</sup></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AD</td>
<td align="left" rowspan="1" colspan="1">12812.45</td>
<td align="left" rowspan="1" colspan="1">18913.31</td>
<td align="left" rowspan="1" colspan="1">26723.75</td>
<td align="left" rowspan="1" colspan="1">&lt;1×10<sup>−100</sup></td>
<td align="left" rowspan="1" colspan="1">&lt;1×10<sup>−100</sup></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BT</td>
<td align="left" rowspan="1" colspan="1">4271.19</td>
<td align="left" rowspan="1" colspan="1">4300.52</td>
<td align="left" rowspan="1" colspan="1">4293.29</td>
<td align="left" rowspan="1" colspan="1">4.27×10<sup>−7</sup></td>
<td align="left" rowspan="1" colspan="1">1.58×10<sup>−5</sup></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BTD</td>
<td align="left" rowspan="1" colspan="1">601475.22</td>
<td align="left" rowspan="1" colspan="1">605191.28</td>
<td align="left" rowspan="1" colspan="1">604905.85</td>
<td align="left" rowspan="1" colspan="1">&lt;1×10<sup>−100</sup></td>
<td align="left" rowspan="1" colspan="1">&lt;1×10<sup>−100</sup></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">LD</td>
<td align="left" rowspan="1" colspan="1">199676.54</td>
<td align="left" rowspan="1" colspan="1">200003.97</td>
<td align="left" rowspan="1" colspan="1">200136.19</td>
<td align="left" rowspan="1" colspan="1">7.94×10<sup>−72</sup></td>
<td align="left" rowspan="1" colspan="1">1.54×10<sup>−100</sup></td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>The strength of evidence is computed to compare the Spectral and Louvain partitions against the ERMM.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3c">
<title>Erdős-Rényi Mixture Model and generative modelling of the <italic>C. elegans</italic> brain network</title>
<p>In addition to estimating the mesoscale structure, the ERMM also provides a generative model of the <italic>C. elegans</italic> nervous system which provides estimates of other network characteristics such as the empirical clustering coefficient (<xref ref-type="disp-formula" rid="pone.0097584.e011">Eq. (1)</xref>) and degree distribution. <xref ref-type="fig" rid="pone-0097584-g009">Figure 9</xref> shows the observed and fitted degree distribution, demonstrating that the ERMM provides a faithful approximation of the empirical degree distribution. The fit is based on a Poisson mixture (<xref ref-type="disp-formula" rid="pone.0097584.e042">Eq. (9)</xref>), and <xref ref-type="table" rid="pone-0097584-t003">Table 3</xref> gives the estimated Poisson means (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e113" xlink:type="simple"/></inline-formula>'s) and weights (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e114" xlink:type="simple"/></inline-formula>'s). Notably, Block 6 (command neurons) has the greatest connectivity with an average degree of 74.23.</p>
<fig id="pone-0097584-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.g009</object-id><label>Figure 9</label><caption>
<title>Observed and ERMM-based fit of the degree distribution.</title>
<p>(<bold>A</bold>) Histogram of the empirical distribution with the ERMM fit. (<bold>B</bold>) Complementary cumulative distribution function (CDF) (i.e., 1-CDF) of the degrees and ERMM fit on the log-log scale. The ERMM-fitted distribution captures the large-scale features of the degree distribution extremely well, as well as most of the fine-scale features.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.g009" position="float" xlink:type="simple"/></fig><table-wrap id="pone-0097584-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097584.t003</object-id><label>Table 3</label><caption>
<title>Poisson mixture parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e115" xlink:type="simple"/></inline-formula> and mixture weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e116" xlink:type="simple"/></inline-formula> in the ERMM.</title>
</caption><alternatives><graphic id="pone-0097584-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0097584.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Block</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">9</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e117" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">0.15</td>
<td align="left" rowspan="1" colspan="1">0.11</td>
<td align="left" rowspan="1" colspan="1">0.17</td>
<td align="left" rowspan="1" colspan="1">0.12</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">0.09</td>
<td align="left" rowspan="1" colspan="1">0.26</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e118" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">12.69</td>
<td align="left" rowspan="1" colspan="1">25.48</td>
<td align="left" rowspan="1" colspan="1">8.46</td>
<td align="left" rowspan="1" colspan="1">10.54</td>
<td align="left" rowspan="1" colspan="1">48.53</td>
<td align="left" rowspan="1" colspan="1">74.23</td>
<td align="left" rowspan="1" colspan="1">22.16</td>
<td align="left" rowspan="1" colspan="1">13.26</td>
<td align="left" rowspan="1" colspan="1">17.59</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>The model-based clustering coefficient from the ERMM is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e119" xlink:type="simple"/></inline-formula>, which is somewhat less than the empirical clustering coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e120" xlink:type="simple"/></inline-formula>. The likely explanation for this difference is that the ERMM specifies each edge as an independent Bernoulli trial (edges are formed with a given probability, independently from one another), which may underestimate the actual rate at which the triangles occur (two neurons connected to the same neighbour are also likely to connect to each other). To assess this, we conducted a small simulation, creating 100 adjacency matrices that followed the ERMM assumptions, using the <italic>C. elegans</italic> estimated parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e121" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e122" xlink:type="simple"/></inline-formula> as truth. Based on these 100 realisations, the two clustering coefficients were quite similar, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e123" xlink:type="simple"/></inline-formula> (SD 0.005) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e124" xlink:type="simple"/></inline-formula> (SD 0.004), verifying that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e125" xlink:type="simple"/></inline-formula> is a reasonable estimate of <italic>C<sub>N</sub></italic> when the ERMM assumptions are satisfied.</p>
</sec><sec id="s3d">
<title>Practical considerations</title>
<p>Here, we report the computational times obtained on a 2.7 GHz quad-core Intel Core i7 linux host with 16 GB. The ERMM, on the default parameters setting (i.e., <monospace>nbiter = 10</monospace>, <monospace>fpnbiter = 5</monospace>) and the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e126" xlink:type="simple"/></inline-formula>, took 186 seconds, while the Louvain and Spectral algorithms took 0.07 and 0.62 seconds, respectively. Both the ERMM and Louvain methods required multiple restarts to find the optimal model, while restarts for the Spectral algorithm were needed due to numerical errors (see Section “Software” for more details). For the ERMM, on average, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e127" xlink:type="simple"/></inline-formula> restarts were needed to visit the optimal model 12 times, while for the Louvain algorithm, over the total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e128" xlink:type="simple"/></inline-formula> restarts, the optimal model was visited only once (for further details, see Figures S3 &amp; S4 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>).</p>
<p>Also, to assess the stability of the ERMM solution across multiple restarts, we computed the ARI similarity score between the global optimal solution (see Table S2 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>), as well as the number of times that a solution was obtained out of 100,000 restarts. These results are consistent with the selected model (9 blocks) being the global optimum and, moreover, this solution occurs frequently over the restarts. Also, it is noteworthy to observe a considerable gap (of about 0.1 ARI units) between the optimal solution and the other solutions, which suggests that the optimal solution is well-identified and, furthermore, nearly optimal solutions are discernibly different. In the context of the stability of solutions, we also show the variability of ARI and ICC scores of each fit obtained from different restarts (Figure S5 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>).</p>
</sec></sec><sec id="s4">
<title>Discussion</title>
<p>Our results highlight the advantages in the use of the model-based Erdős-Rényi Mixture Model over the deterministic community detection algorithms. The mixture model decomposed the network into an interpretable set of 9 blocks, comprising 2 small blocks that correspond to the command interneurons, and 7 larger blocks that approximately correspond to the modules defined by the deterministic algorithms. Considering other work which points to the command interneurons of the <italic>C. elegans</italic> nervous system as the topological rich club <xref ref-type="bibr" rid="pone.0097584-Towlson1">[9]</xref>, it seems that the ERMM decomposition has been able to capture both modular and core-periphery aspects <xref ref-type="bibr" rid="pone.0097584-Borgatti1">[25]</xref>, <xref ref-type="bibr" rid="pone.0097584-Holme1">[65]</xref> of the mesoscale organization of the network. This conceptual scope, which can reconcile modular and core-periphery views of community structure, is a clear advantage of the ERMM compared to deterministic algorithms which are limited to an exclusive selection of one form over the other.</p>
<p>The block decomposition of the ERMM was also more successful at accounting for the prior biological data than either of the deterministic algorithms. Using the ICC metric to quantify the percentage of variance in a biological variable that is explained by any community structure, we found that the ERMM decomposition accounted for more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e129" xlink:type="simple"/></inline-formula> of the variance in anatomical location of the neurons, and more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e130" xlink:type="simple"/></inline-formula> of the variance in anatomical distance of connections between neurons and neuronal birth times. Also, the ERMM explained a greater proportion of the variance in all biological variables than either of the deterministic algorithms.</p>
<p>Apart from considering the ICC scores, we subjected the fit of each method to a more rigorous procedure of model selection based on the AIC score. Computing the likelihood scores, we verified that the ERMM fit is significantly more compatible with the prior biological information than the fits of the Louvain and Spectral algorithms.</p>
<p>In addition to its advantages as an estimator, the ERMM also has technical advantages as a generative model (to simulate the network) and as a network compression basis to shrink the scale of a system. For example, we showed that the ERMM generated a good fit of the degree distribution and clustering coefficients of the <italic>C. elegans</italic> connectome. We also illustrated how the ERMM could be used to compress a graph into a set of super nodes, allowing a clearer view of the topology with fewer connections. In this sense, the ERMM provides a compression similar to power graph analysis methods <xref ref-type="bibr" rid="pone.0097584-Royer1">[66]</xref>, but it relaxes the condition for grouping nodes together, which allows for a more efficient and realistic compression.</p>
<p>We have found some shortcomings of the ERMM. For example, the mismatch between the empirical and model based clustering coefficient suggests that the stochastic model does not exactly match the data generating mechanism represented by the <italic>C. elegans</italic> nervous system. The ERMM can be extended by seeing it as a mixture Exponential Random Graph Model (ERGM) <xref ref-type="bibr" rid="pone.0097584-Vu1">[67]</xref> where, conditional on the partitioning, the ERGM summary statistics are the edge counts in each of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e131" xlink:type="simple"/></inline-formula> unique group pairs. Additional summary statistics can then be considered; for example, the triangle counts in each group pair. However, this will create a more complicated likelihood and necessitate new and yet more involved estimation procedures.</p>
<p>Nevertheless, the general practical advantage of the ERMM is that it leaves room for other distributional characterisations of edges which appear to be more in agreement with the network's specific type. Thus, for example, if this approach is used for the analysis of the weighted <italic>C. elegans</italic> network (i.e., the edge weights correspond to the total number of synaptic connections between a neuron pair), then the assumption that the edges are following a Binomial distribution is more appropriate. Furthermore, given that our study have used only a simple unweighted <italic>C. elegans</italic> network, it is interesting to compare our results to the 6 modules decomposition of the weighted <italic>C. elegans</italic> network reported by Pan et al. <xref ref-type="bibr" rid="pone.0097584-Pan1">[8]</xref>. The corresponding extended results of this comparison (Figure S6 &amp; Table S3 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>) show that the ERMM decomposition, again, explained more variance in the prior biological information, with the exception of the lineage distance where the ERMM explained <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e132" xlink:type="simple"/></inline-formula> less than the 6 modules decomposition (Figure S6 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>). However, in terms of AIC score, the ERMM decomposition is uniformly more significant across all biological features than the decomposition reported by Pan et al. <xref ref-type="bibr" rid="pone.0097584-Pan1">[8]</xref> (Table S3 in <xref ref-type="supplementary-material" rid="pone.0097584.s001">File S1</xref>).</p>
<p>Although the ERMM is classified as a stochastic blockmodel, it should not be confused with the <italic>p</italic><sub>1</sub> model that was proposed by Holland and Leinhardt <xref ref-type="bibr" rid="pone.0097584-Holland1">[20]</xref>. In particular, the original <italic>p</italic><sub>1</sub> model does not aim to infer the connectivity rates of groups, which is why some authors like Wang and Wong <xref ref-type="bibr" rid="pone.0097584-Wang1">[21]</xref> proposed different extensions. More recently, Karrer and Newman <xref ref-type="bibr" rid="pone.0097584-Karrer1">[68]</xref> considered the <italic>p</italic><sub>1</sub> model, referring to it as the standard stochastic blockmodel, in the context of undirected multi-graphs. They used heuristic arguments to derive a new model that corrects for variation in the degree distribution, named the degree corrected stochastic blockmodel. This approach treats node degree as a nuisance, to be discounted when finding groups. With our ERMM fit to <italic>C. elegans</italic>, this would not seem to be advantageous as it is the absolute differences in node degree that help define blocks. For example, consider Block 5 and 6 which have similar patterns of connections but their estimated connection rates are distinct (see <xref ref-type="fig" rid="pone-0097584-g005">Figure (5</xref>)). Furthermore, it is interesting to note that Karrer and Newman <xref ref-type="bibr" rid="pone.0097584-Karrer1">[68]</xref> found the standard stochastic blockmodel to be a poor fit to the Zachary karate club data <xref ref-type="bibr" rid="pone.0097584-Zachary1">[69]</xref>, and their degree corrected model misclassified only one node. In contrast, we found that the ERMM reliably finds the 2 known groups in that data with zero errors.</p>
<p>Lastly, we found that the ERMM computational times are reasonable and depend on the range of blocks, the values of the internal parameters (<monospace>nbiter</monospace>, <monospace>fpnbiter</monospace>) and, also, the size of the network. It has been reported <xref ref-type="bibr" rid="pone.0097584-Daudin1">[24]</xref> that this approach can handle networks with several thousands of vertices, which is particularly impressive given the challenging likelihood optimisation. However, the problem of finding the global maximum is heavily dependent on the initialisation and, hence, we require restarts in order to carefully search the state space. While we used a cautious approach of running a large number of restarts (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e133" xlink:type="simple"/></inline-formula>), we found <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0097584.e134" xlink:type="simple"/></inline-formula> was sufficient to reliably identify the optimal model.</p>
</sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0097584.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pone.0097584.s001" position="float" xlink:type="simple"><label>File S1</label><caption>
<p><bold>Contains Figures S1–S6, Tables S1–S3, and Supplementary Text.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Zeynep Altun and David Hall for supplying the worm template, Bryan Guillaume and Mikail Rubinov for valuable discussions, and the reviewers for their detailed comments and suggestions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0097584-Dicken1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dicken</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Kelly</surname><given-names>PF</given-names></name>, <name name-style="western"><surname>Olds</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Wai-Chung Yeung</surname><given-names>H</given-names></name> (<year>2002</year>) <article-title>Chains and networks, territories and scales: towards a relational framework for analysing the global economy</article-title>. <source>Global networks</source> <volume>1</volume>: <fpage>89</fpage>–<lpage>112</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Ulanowicz1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ulanowicz</surname><given-names>RE</given-names></name> (<year>2004</year>) <article-title>Quantitative methods for ecological network analysis</article-title>. <source>Computational Biology and Chemistry</source> <volume>28</volume>: <fpage>321</fpage>–<lpage>339</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Ravasz1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ravasz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Somera</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Mongru</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Oltvai</surname><given-names>ZN</given-names></name>, <name name-style="western"><surname>Barabási</surname><given-names>AL</given-names></name> (<year>2002</year>) <article-title>Hierarchical organization of modularity in metabolic networks</article-title>. <source>Science</source> <volume>297</volume>: <fpage>1551</fpage>–<lpage>1555</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Albert1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Albert</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Albert</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Nakarado</surname><given-names>GL</given-names></name> (<year>2004</year>) <article-title>Structural vulnerability of the north american power grid</article-title>. <source>Physical Review E</source> <volume>69</volume>: <fpage>025103</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Sporns1"><label>5</label>
<mixed-citation publication-type="book" xlink:type="simple">Sporns O (2010) Networks of the Brain. MIT Press.</mixed-citation>
</ref>
<ref id="pone.0097584-Bullmore1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname><given-names>ET</given-names></name>, <name name-style="western"><surname>Bassett</surname><given-names>DS</given-names></name> (<year>2011</year>) <article-title>Brain graphs: graphical models of the human brain connectome</article-title>. <source>Annual review of clinical psychology</source> <volume>7</volume>: <fpage>113</fpage>–<lpage>140</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Fortunato1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fortunato</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Barthelemy</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Resolution limit in community detection</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>104</volume>: <fpage>36</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Pan1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pan</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Chatterjee</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Sinha</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>Mesoscopic organization reveals the constraints governing <italic>Caenorhabditis elegans</italic> nervous system</article-title>. <source>PloS one</source> <volume>5</volume>: <fpage>e9240</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Towlson1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Towlson</surname><given-names>EK</given-names></name>, <name name-style="western"><surname>Vértes</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Ahnert</surname><given-names>SE</given-names></name>, <name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>ET</given-names></name> (<year>2013</year>) <article-title>The rich club of the <italic>C. elegans</italic> neuronal connectome</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>6380</fpage>–<lpage>6387</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Bullmore2"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2009</year>) <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nature Reviews Neuroscience</source> <volume>10</volume>: <fpage>186</fpage>–<lpage>198</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Meunier1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meunier</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Lambiotte</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>ET</given-names></name> (<year>2010</year>) <article-title>Modular and hierarchically modular organization of brain networks</article-title>. <source>Frontiers in neuroscience</source> <volume>4</volume>.</mixed-citation>
</ref>
<ref id="pone.0097584-Goldenberg1"><label>12</label>
<mixed-citation publication-type="book" xlink:type="simple">Goldenberg A, Zheng A, Fienberg S (2010) A survey of statistical network models. Now Publishers.</mixed-citation>
</ref>
<ref id="pone.0097584-Fortunato2"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fortunato</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>Community detection in graphs</article-title>. <source>Physics Reports</source> <volume>486</volume>: <fpage>75</fpage>–<lpage>174</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Blondel1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blondel</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Guillaume</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lambiotte</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Lefebvre</surname><given-names>E</given-names></name> (<year>2008</year>) <article-title>Fast unfolding of communities in large networks</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source> <volume>2008</volume>: <fpage>P10008</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Newman1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newman</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Modularity and community structure in networks</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>103</volume>: <fpage>8577</fpage>–<lpage>8582</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Newman2"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newman</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Detecting community structure in networks</article-title>. <source>The European Physical Journal B-Condensed Matter and Complex Systems</source> <volume>38</volume>: <fpage>321</fpage>–<lpage>330</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Lorrain1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lorrain</surname><given-names>F</given-names></name>, <name name-style="western"><surname>White</surname><given-names>HC</given-names></name> (<year>1971</year>) <article-title>Structural equivalence of individuals in social networks</article-title>. <source>The Journal of mathematical sociology</source> <volume>1</volume>: <fpage>49</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-White1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>HC</given-names></name>, <name name-style="western"><surname>Boorman</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Breiger</surname><given-names>RL</given-names></name> (<year>1976</year>) <article-title>Social structure from multiple networks. i. blockmodels of roles and positions</article-title>. <source>American journal of sociology</source> <fpage>730</fpage>–<lpage>780</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Doreian1"><label>19</label>
<mixed-citation publication-type="book" xlink:type="simple">Doreian P, Batagelj V, Ferligoj A (2005) Generalized blockmodeling, volume 25. Cambridge Univ Pr.</mixed-citation>
</ref>
<ref id="pone.0097584-Holland1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holland</surname><given-names>PW</given-names></name>, <name name-style="western"><surname>Leinhardt</surname><given-names>S</given-names></name> (<year>1981</year>) <article-title>An exponential family of probability distributions for directed graphs</article-title>. <source>Journal of the american Statistical association</source> <volume>76</volume>: <fpage>33</fpage>–<lpage>50</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Wang1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wong</surname><given-names>G</given-names></name> (<year>1987</year>) <article-title>Stochastic blockmodels for directed graphs</article-title>. <source>Journal of the American Statistical Association</source> <fpage>8</fpage>–<lpage>19</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Anderson1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Wasserman</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Faust</surname><given-names>K</given-names></name> (<year>1992</year>) <article-title>Building stochastic blockmodels</article-title>. <source>Social Networks</source> <volume>14</volume>: <fpage>137</fpage>–<lpage>161</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Snijders1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Snijders</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Nowicki</surname><given-names>K</given-names></name> (<year>1997</year>) <article-title>Estimation and prediction for stochastic blockmodels for graphs with latent block structure</article-title>. <source>Journal of Classification</source> <volume>14</volume>: <fpage>75</fpage>–<lpage>100</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Daudin1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daudin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Picard</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Robin</surname><given-names>S</given-names></name> (<year>2008</year>) <article-title>A mixture model for random graphs</article-title>. <source>Statistics and computing</source> <volume>18</volume>: <fpage>173</fpage>–<lpage>183</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Borgatti1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borgatti</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Everett</surname><given-names>MG</given-names></name> (<year>2000</year>) <article-title>Models of core/periphery structures</article-title>. <source>Social networks</source> <volume>21</volume>: <fpage>375</fpage>–<lpage>395</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-White2"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Southgate</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Thomson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Brenner</surname><given-names>S</given-names></name> (<year>1986</year>) <article-title>The structure of the nervous system of the nematode <italic>Caenorhabditis elegans</italic></article-title>. <source>Philosophical Transactions of the Royal Society of London B, Biological Sciences</source> <volume>314</volume>: <fpage>1</fpage>–<lpage>340</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Chen1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Wiring optimization can relate neuronal structure and func- tion</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>103</volume>: <fpage>4723</fpage>–<lpage>4728</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Varshney1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Varshney</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Paniagua</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2011</year>) <article-title>Structural properties of the <italic>Caenorhabditis elegans</italic> neuronal network</article-title>. <source>PLoS computational biology</source> <volume>7</volume>: <fpage>e1001066</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Altun1"><label>29</label>
<mixed-citation publication-type="other" xlink:type="simple">Altun Z, Hall D (2005) Handbook of <italic>C. elegans</italic> anatomy. WormAtlas <ext-link ext-link-type="uri" xlink:href="http://wwwwormatlasorg/handbook/contentshtm" xlink:type="simple">http://wwwwormatlasorg/handbook/contentshtm</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0097584-Haspel1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haspel</surname><given-names>G</given-names></name>, <name name-style="western"><surname>O'Donovan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hart</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Motoneurons dedicated to either forward or backward locomotion in the nematode <italic>Caenorhabditis elegans</italic></article-title>. <source>The Journal of Neuroscience</source> <volume>30</volume>: <fpage>11151</fpage>–<lpage>11156</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Wood1"><label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">Wood WB, editor(1987) The nematode Caenorhabditis elegans. Cold Spring Harbour Laboratory.</mixed-citation>
</ref>
<ref id="pone.0097584-VonStetina1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Von Stetina</surname><given-names>SE</given-names></name>, <name name-style="western"><surname>Treinin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>The motor circuit</article-title>. <source>Int Rev Neurobiol</source> <volume>69</volume>: <fpage>125</fpage>–<lpage>167</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Altun2"><label>33</label>
<mixed-citation publication-type="book" xlink:type="simple">Altun ZF HD (2009) Nervous system, general description. Worm atlas.</mixed-citation>
</ref>
<ref id="pone.0097584-Varier1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Varier</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kaiser</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Neural development features: Spatio-temporal development of the <italic>Caenorhabditis elegans</italic> neuronal network</article-title>. <source>PLoS Computational Biology</source> <volume>7</volume>: <fpage>e1001044</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Brenner1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brenner</surname><given-names>S</given-names></name> (<year>1974</year>) <article-title>The genetics of <italic>Caenorhabditis elegans</italic></article-title>. <source>Genetics</source> <volume>77</volume>: <fpage>71</fpage>–<lpage>94</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Newman3"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Watts</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Strogatz</surname><given-names>S</given-names></name> (<year>2002</year>) <article-title>Random graph models of social networks</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>99</volume>: <fpage>2566</fpage>–<lpage>2572</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Erds1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erdős</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Rényi</surname><given-names>A</given-names></name> (<year>1959</year>) <article-title>On random graphs</article-title>. <source>Publicationes Mathematicae Debrecen</source> <volume>6</volume>: <fpage>290</fpage>–<lpage>297</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Gilbert1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilbert</surname><given-names>E</given-names></name> (<year>1959</year>) <article-title>Random graphs</article-title>. <source>The Annals of Mathematical Statistics</source> <volume>30</volume>: <fpage>1141</fpage>–<lpage>1144</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Latouche1"><label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">Latouche P, Birmele E, Ambroise C (2008) Bayesian methods for graph clustering. SSB Research Report.</mixed-citation>
</ref>
<ref id="pone.0097584-Zanghi1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zanghi</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Ambroise</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Miele</surname><given-names>V</given-names></name> (<year>2008</year>) <article-title>Fast online graph clustering via erdos-renyi mixture</article-title>. <source>Pattern Recognition</source> <volume>41</volume>: <fpage>3592</fpage>–<lpage>3599</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Zanghi2"><label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">Zanghi H, Picard F, Miele V, Ambroise C (2008) Strategies for online inference of network mixture. Research publication.</mixed-citation>
</ref>
<ref id="pone.0097584-Latouche2"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Latouche</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Birmelé</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ambroise</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>Overlapping stochastic block models with application to the french political blogosphere</article-title>. <source>The Annals of Applied Statistics</source> <volume>5</volume>: <fpage>309</fpage>–<lpage>336</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Jaakkola1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jaakkola</surname><given-names>T</given-names></name> (<year>2001</year>) <article-title>10 tutorial on variational approximation methods</article-title>. <source>Advanced mean field methods: theory and practice</source> <fpage>129</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Jordan1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jordan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Jaakkola</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Saul</surname><given-names>L</given-names></name> (<year>1999</year>) <article-title>An introduction to variational methods for graphical models</article-title>. <source>Machine learning</source> <volume>37</volume>: <fpage>183</fpage>–<lpage>233</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Newman4"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Girvan</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Finding and evaluating community structure in networks</article-title>. <source>Physical review E</source> <volume>69</volume>: <fpage>026113</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Luczak1"><label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">Luczak T (1989) Sparse random graphs with a given degree sequence. In: Proceedings of the Symposium on Random Graphs, Poznan. pp. 165–182.</mixed-citation>
</ref>
<ref id="pone.0097584-Molloy1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Molloy</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Reed</surname><given-names>B</given-names></name> (<year>1995</year>) <article-title>A critical point for random graphs with a given degree sequence</article-title>. <source>Random Structures &amp; Algorithms</source> <volume>6</volume>: <fpage>161</fpage>–<lpage>180</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Pattison1"><label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Pattison P, Robins G (2007) Handbook of probability theory with applications. chapter probabilistic network theory.</mixed-citation>
</ref>
<ref id="pone.0097584-Rubinov1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubinov</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2010</year>) <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source> <volume>52</volume>: <fpage>1059</fpage>–<lpage>1069</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Mukherjee1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mukherjee</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Hill</surname><given-names>SM</given-names></name> (<year>2011</year>) <article-title>Network clustering: probing biological heterogeneity by sparse graphical models</article-title>. <source>Bioinformatics</source> <volume>27</volume>: <fpage>994</fpage>–<lpage>1000</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Handl1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Handl</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Knowles</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Kell</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Computational cluster validation in post-genomic data analysis</article-title>. <source>Bioinformatics</source> <volume>21</volume>: <fpage>3201</fpage>–<lpage>3212</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Hubert1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubert</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Arabie</surname><given-names>P</given-names></name> (<year>1985</year>) <article-title>Comparing partitions</article-title>. <source>Journal of classification</source> <volume>2</volume>: <fpage>193</fpage>–<lpage>218</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Rand1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rand</surname><given-names>W</given-names></name> (<year>1971</year>) <article-title>Objective criteria for the evaluation of clustering methods</article-title>. <source>Journal of the American Statistical association</source> <volume>66</volume>: <fpage>846</fpage>–<lpage>850</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Morey1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morey</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Agresti</surname><given-names>A</given-names></name> (<year>1984</year>) <article-title>The measurement of classification agreement: an adjustment to the rand statistic for chance agreement</article-title>. <source>Educational and Psychological Measurement</source> <volume>44</volume>: <fpage>33</fpage>–<lpage>37</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Dobson1"><label>55</label>
<mixed-citation publication-type="book" xlink:type="simple">Dobson A (2001) An introduction to generalized linear models. Chapman &amp; Hall/CRC.</mixed-citation>
</ref>
<ref id="pone.0097584-Akaike1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Akaike</surname><given-names>H</given-names></name> (<year>1974</year>) <article-title>A new look at the statistical model identification</article-title>. <source>Automatic Control, IEEE Transactions on</source> <volume>19</volume>: <fpage>716</fpage>–<lpage>723</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Burnham1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burnham</surname><given-names>KP</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>DR</given-names></name> (<year>2004</year>) <article-title>Multimodel inference understanding aic and bic in model selection</article-title>. <source>Sociological methods &amp; research</source> <volume>33</volume>: <fpage>261</fpage>–<lpage>304</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Fraley1"><label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Fraley C, Raftery AE (2006) MCLUST Version 3 for R: Normal Mixture Modeling and Model-based Clustering. (revised in 2012).</mixed-citation>
</ref>
<ref id="pone.0097584-Fraley2"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fraley</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Raftery</surname><given-names>AE</given-names></name> (<year>2002</year>) <article-title>Model-based clustering, discriminant analysis and density estimation</article-title>. <source>Journal of the American Statistical Association</source> <volume>97</volume>: <fpage>611</fpage>–<lpage>631</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Bates1"><label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Bates D, Maechler M, Bolker B (2012) lme4: Linear mixed-effects models using S4 classes. URL <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=lme4" xlink:type="simple">http://CRAN.R-project.org/package=lme4</ext-link>. R package version 0.999999-0.</mixed-citation>
</ref>
<ref id="pone.0097584-Harville1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harville</surname><given-names>D</given-names></name> (<year>1977</year>) <article-title>Maximum likelihood approaches to variance component estimation and to related problems</article-title>. <source>Journal of the American Statistical Association</source> <volume>72</volume>: <fpage>320</fpage>–<lpage>338</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Ravasz2"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ravasz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Barabási</surname><given-names>AL</given-names></name> (<year>2003</year>) <article-title>Hierarchical organization in complex networks</article-title>. <source>Physical Review E</source> <volume>67</volume>: <fpage>026112</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Haspel2"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haspel</surname><given-names>G</given-names></name>, <name name-style="western"><surname>O'Donovan</surname><given-names>MJ</given-names></name> (<year>2011</year>) <article-title>A perimotor framework reveals functional segmentation in the motoneuronal network controlling locomotion in caenorhabditis elegans</article-title>. <source>The Journal of Neuroscience</source> <volume>31</volume>: <fpage>14611</fpage>–<lpage>14623</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-AlexanderBloch1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alexander-Bloch</surname><given-names>AF</given-names></name>, <name name-style="western"><surname>Vértes</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Stidd</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Lalonde</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Clasen</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>The anatomical distance of functional connections predicts brain network topology in health and schizophrenia</article-title>. <source>Cerebral Cortex</source> <volume>23</volume>: <fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Holme1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holme</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Core-periphery organization of complex networks</article-title>. <source>Physical Review E</source> <volume>72</volume>: <fpage>046111</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Royer1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Royer</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Reimann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Andreopoulos</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Schroeder</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Unraveling protein networks with power graph analysis</article-title>. <source>PLoS Computational Biology</source> <volume>4</volume>: <fpage>e1000108</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Vu1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vu</surname><given-names>DQ</given-names></name>, <name name-style="western"><surname>Hunter</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Schweinberger</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Model-based clustering of large networks</article-title>. <source>arXiv preprint</source> <volume>arXiv</volume>: <fpage>12070188</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Karrer1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karrer</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Newman</surname><given-names>ME</given-names></name> (<year>2011</year>) <article-title>Stochastic blockmodels and community structure in networks</article-title>. <source>Physical Review E</source> <volume>83</volume>: <fpage>016107</fpage>.</mixed-citation>
</ref>
<ref id="pone.0097584-Zachary1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zachary</surname><given-names>WW</given-names></name> (<year>1977</year>) <article-title>An information ow model for conict and fission in small groups</article-title>. <source>Journal of Anthropological Research</source> <fpage>452</fpage>–<lpage>473</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>