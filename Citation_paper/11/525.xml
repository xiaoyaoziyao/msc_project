<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0161112</article-id>
<article-id pub-id-type="publisher-id">PONE-D-16-12205</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Maximum likelihood estimation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Maximum likelihood estimation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Statistical distributions</subject><subj-group><subject>Statistical dispersion</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Gene expression</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject></subj-group></article-categories>
<title-group>
<article-title>Performance Evaluation of Missing-Value Imputation Clustering Based on a Multivariate Gaussian Mixture Model</article-title>
<alt-title alt-title-type="running-head">Performance Evaluation of Missing-Value Imputation Clustering</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Xiao</surname>
<given-names>Jing</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Xu</surname>
<given-names>Qiongqiong</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Wu</surname>
<given-names>Chuanli</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Gao</surname>
<given-names>Yuexia</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hua</surname>
<given-names>Tianqi</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Xu</surname>
<given-names>Chenwu</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Epidemiology and Medical Statistics, School of Public Health, Nantong University, Nantong, 226019, China</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Jiangsu Key Laboratory of Crop Genetics and Physiology/Co-Innovation Center for Modern Production Technology of Grain Crops, Key Laboratory of Plant Functional Genomics of the Ministry of Education, Yangzhou University, Yangzhou, 225009, China</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Deng</surname>
<given-names>Yong</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Southwest University, CHINA</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple">
<list-item><p><bold>Conceptualization:</bold> JX CWX.</p></list-item>
<list-item><p><bold>Formal analysis:</bold> JX QQX CLW YXG TQH.</p></list-item>
<list-item><p><bold>Funding acquisition:</bold> JX CWX.</p></list-item>
<list-item><p><bold>Methodology:</bold> JX QQX.</p></list-item>
<list-item><p><bold>Software:</bold> JX QQX CLW.</p></list-item>
<list-item><p><bold>Validation:</bold> JX CWX.</p></list-item>
<list-item><p><bold>Writing - original draft:</bold> JX QQX CLW.</p></list-item>
<list-item><p><bold>Writing - review &amp; editing:</bold> JX CWX.</p></list-item></list></p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">qtls@yzu.edu.cn</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>23</day>
<month>8</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<year>2016</year>
</pub-date>
<volume>11</volume>
<issue>8</issue>
<elocation-id>e0161112</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>3</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>7</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Xiao et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0161112"/>
<abstract>
<sec id="sec001">
<title>Background</title>
<p>It is challenging to deal with mixture models when missing values occur in clustering datasets.</p>
</sec>
<sec id="sec002">
<title>Methods and Results</title>
<p>We propose a dynamic clustering algorithm based on a multivariate Gaussian mixture model that efficiently imputes missing values to generate a “pseudo-complete” dataset. Parameters from different clusters and missing values are estimated according to the maximum likelihood implemented with an expectation-maximization algorithm, and multivariate individuals are clustered with Bayesian posterior probability. A simulation showed that our proposed method has a fast convergence speed and it accurately estimates missing values. Our proposed algorithm was further validated with Fisher’s Iris dataset, the Yeast Cell-cycle Gene-expression dataset, and the CIFAR-10 images dataset. The results indicate that our algorithm offers highly accurate clustering, comparable to that using a complete dataset without missing values. Furthermore, our algorithm resulted in a lower misjudgment rate than both clustering algorithms with missing data deleted and with missing-value imputation by mean replacement.</p>
</sec>
<sec id="sec003">
<title>Conclusion</title>
<p>We demonstrate that our missing-value imputation clustering algorithm is feasible and superior to both of these other clustering algorithms in certain situations.</p>
</sec>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>the National Natural Science Foundation of China</institution>
</funding-source>
<award-id>31000539</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Xiao</surname>
<given-names>Jing</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>the National Natural Science Foundation of China</institution>
</funding-source>
<award-id>31391632</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Xu</surname>
<given-names>Chenwu Wu</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>the National Natural Science Foundation of China</institution>
</funding-source>
<award-id>91535103</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Xu</surname>
<given-names>Chenwu Wu</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>The research was supported by grants from the National Natural Science Foundation of China (31000539, 31391632 and 91535103), the Priority Academic Program Development of Jiangsu Higher Education Institutions, the National High-tech R&amp;D Program (863 Program, 2014AA10A601-5), the Natural Science Foundations of Jiangsu Province (BK20150010) and the Natural Science Foundation of the Jiangsu Higher Education Institutions (14KJA210005). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="0"/>
<table-count count="6"/>
<page-count count="14"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available from the websites <ext-link ext-link-type="uri" xlink:href="http://genome-www.stanford.edu/cellcycle/" xlink:type="simple">http://genome-www.stanford.edu/cellcycle/</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/datasets/Iris" xlink:type="simple">http://archive.ics.uci.edu/ml/datasets/Iris</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://www.cs.toronto.edu/~kriz/cifar.html" xlink:type="simple">http://www.cs.toronto.edu/~kriz/cifar.html</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec004" sec-type="intro">
<title>Introduction</title>
<p>Clustering analysis, as a multivariate statistical method, refers to the process of classifying a set of observations into subsets, called clusters, such that observations in the same cluster are similar in certain respects [<xref ref-type="bibr" rid="pone.0161112.ref001">1</xref>–<xref ref-type="bibr" rid="pone.0161112.ref003">3</xref>]. Clustering is widely used in medical sciences, for instance when clustering diseases or gene-expression profiles. Clustering methods usually fall into two categories: hierarchical clustering methods [<xref ref-type="bibr" rid="pone.0161112.ref004">4</xref>], which are used for clustering datasets with small size [<xref ref-type="bibr" rid="pone.0161112.ref005">5</xref>,<xref ref-type="bibr" rid="pone.0161112.ref006">6</xref>]; and dynamic clustering methods, such as K-means [<xref ref-type="bibr" rid="pone.0161112.ref007">7</xref>,<xref ref-type="bibr" rid="pone.0161112.ref008">8</xref>] and self-organizing maps [<xref ref-type="bibr" rid="pone.0161112.ref009">9</xref>], which begin with an initial partitioning of the individuals and iteratively move individuals from one cluster to another until the criterion of convergence is met. With dynamic clustering, the number of clusters must be specified in advance [<xref ref-type="bibr" rid="pone.0161112.ref010">10</xref>]. Dynamic algorithms are mostly heuristically motivated, and they do not require an underlying statistical model. Nevertheless, selection of the “correct” number of clusters and of the best clustering method remains a topic for discussion. Model-based clustering methods [<xref ref-type="bibr" rid="pone.0161112.ref011">11</xref>–<xref ref-type="bibr" rid="pone.0161112.ref013">13</xref>] are a type of dynamic clustering based on the hypothesis that the whole dataset is a finite mixture of the same type of distribution with different sets of parameters, such as a finite mixture of a multivariate Gaussian distribution. Compared with “heuristic” algorithms, one obvious advantage to model-based clustering is that objective statistical criteria—such as the Akaike information criterion (AIC) or the Bayesian information criterion (BIC) [<xref ref-type="bibr" rid="pone.0161112.ref014">14</xref>]—are used to determine the number of clusters.</p>
<p>Missing data present a problem for medical research, given that the data are often supplied retrospectively and from various sources [<xref ref-type="bibr" rid="pone.0161112.ref015">15</xref>]. In particular, missing data are a frequent occurrence in microarray experiments and in medical research. Missing values are especially common in large-scale studies involving dozens of variables and hundreds of individuals. Indeed, many clustering methods require a full set of data. Individuals with missing values are either rejected or been estimated prior to the analysis. Consequently, several missing-value imputation methods have been developed [<xref ref-type="bibr" rid="pone.0161112.ref016">16</xref>–<xref ref-type="bibr" rid="pone.0161112.ref020">20</xref>], such as mean substitution, regression imputation, fuzzy c-means (FCM) clustering of incomplete data [<xref ref-type="bibr" rid="pone.0161112.ref021">21</xref>], and Gaussian mixture model-based missing-value imputation classification [<xref ref-type="bibr" rid="pone.0161112.ref022">22</xref>]. In this study, we propose a dynamic method for a model-based missing-value imputation clustering algorithm. With our proposed method, missing values are estimated iteratively until arithmetic convergence is reached during the process of clustering individuals. We used 12 simulated datasets. Each of these datasets had two versions: a complete version and a version where 10% of the individuals had at least one variable missing. We used these datasets to evaluate the clustering accuracy and the accuracy and precision of cluster-parameter estimators. We compared our proposed algorithm based on the missing-value imputation according to the maximum likelihood estimation (a “pseudo-complete” dataset) with a model-based clustering algorithm using the complete dataset and another two model-based clustering algorithms, one using a dataset with missing values deleted and the other imputing the missing values by mean replacement. In addition, we compared our algorithm with the FCM clustering method using real datasets—viz., Fisher’s Iris dataset, the Yeast Cell-cycle Gene-expression dataset, and the CIFAR-10 images dataset.</p>
</sec>
<sec id="sec005" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec006">
<title>Multivariate Gaussian mixture model</title>
<p>The dataset is arranged as an <italic>n</italic> × <italic>k</italic> matrix denoted by Y, where <italic>n</italic> is the number of individuals and <italic>k</italic> is the number of variables. Let <italic>y</italic><sub><italic>ij</italic></sub> be the observed value of the <italic>i</italic>-th individual in the <italic>j</italic>-th variable, for <italic>i</italic> = 1,2,…, <italic>n</italic> and <italic>j</italic> = 1,2,…, <italic>k</italic>. Let Y<sub><italic>i</italic></sub> = (<italic>y</italic><sub><italic>i</italic>1</sub>,<italic>y</italic><sub><italic>i</italic>2</sub>,…,<italic>y</italic><sub><italic>ik</italic></sub>)<sup>T</sup> be the <italic>i</italic>-th column in matrix Y<sup>T</sup>—i.e., a <italic>k</italic> × 1 vector of the data for individual <italic>i</italic> under all variables. The value of <italic>y</italic><sub><italic>ij</italic></sub> across all the <italic>k</italic> variables represents the expression level of the <italic>i</italic>-th individual. Under a finite multivariate Gaussian mixture model, each Y<sub><italic>i</italic></sub> is assumed to follow a <italic>k</italic>-dimensional Gaussian mixture distribution. Mathematically, the mixture distribution for <italic>c</italic> clusters is as follows:
<disp-formula id="pone.0161112.e001">
<alternatives>
<graphic id="pone.0161112.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>f</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <inline-formula id="pone.0161112.e002"><alternatives><graphic id="pone.0161112.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi mathvariant="normal">π</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">exp</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the probability density function for the <italic>l</italic>-th <italic>k</italic>-dimensional Gaussian distribution with mean vector μ<sub><italic>l</italic></sub> = (<italic>μ</italic><sub><italic>l</italic>1</sub>, <italic>μ</italic><sub><italic>l</italic>2</sub>,…, <italic>μ</italic><sub><italic>lk</italic></sub>) and variance-covariance matrix <inline-formula id="pone.0161112.e003"><alternatives><graphic id="pone.0161112.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, for <italic>l</italic> = 1,2,…,<italic>c</italic>. Moreover, <italic>P</italic><sub><italic>l</italic></sub> with <inline-formula id="pone.0161112.e004"><alternatives><graphic id="pone.0161112.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, is the mixing proportion of cluster <italic>l</italic>. The mixing proportion <italic>p</italic><sub><italic>l</italic></sub> is defined as the proportion of individuals that belong to the <italic>l</italic>-th cluster. The joint log-likelihood function for <italic>n</italic> independent individual vectors is defined as follows:
<disp-formula id="pone.0161112.e005">
<alternatives>
<graphic id="pone.0161112.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:mi mathvariant="normal">ln</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mi mathvariant="normal">ln</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
</sec>
<sec id="sec007">
<title>Clustering algorithm for missing values</title>
<p>Most reports [<xref ref-type="bibr" rid="pone.0161112.ref023">23</xref>–<xref ref-type="bibr" rid="pone.0161112.ref025">25</xref>] consider only complete datasets (without missing values) for Gaussian mixture clustering. Indeed, it is challenging to estimate missing values accurately. An urgent problem concerns how to provide the optimal number of clusters <italic>c</italic> and how to cluster <italic>n</italic> individuals into the <italic>c</italic> clusters precisely. Therefore, we propose a missing-value imputation algorithm as follows.</p>
<p>Suppose that there are <italic>r</italic> missing values in Y<sub><italic>i</italic></sub>. Thus, <italic>y</italic><sub><italic>i</italic>1</sub>, <italic>y</italic><sub><italic>i</italic>2</sub>,…, <italic>y</italic><sub><italic>ir</italic></sub> are missing. The Y<sub><italic>i</italic></sub>, μ<sub><italic>l</italic></sub>, and S<sub><italic>l</italic></sub> are then divided into
<disp-formula id="pone.0161112.e006">
<alternatives>
<graphic id="pone.0161112.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">and</mml:mi><mml:mspace width="0.35em"/><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where
<disp-formula id="pone.0161112.e007">
<alternatives>
<graphic id="pone.0161112.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.35em"/><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pone.0161112.e008">
<alternatives>
<graphic id="pone.0161112.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.35em"/><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pone.0161112.e009">
<alternatives>
<graphic id="pone.0161112.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.35em"/><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>1</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pone.0161112.e010">
<alternatives>
<graphic id="pone.0161112.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.35em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.45em"/><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Suppose further that Y<sub><italic>i</italic></sub> is from the <italic>l</italic>-th <italic>k</italic>-dimensional Gaussian distribution and that Y<sub><italic>i</italic>(2)</sub> is known. The conditional expectation of Y<sub><italic>i</italic>(1)</sub>, which belongs to the <italic>l</italic>-th cluster, is derived as follows:
<disp-formula id="pone.0161112.e011">
<alternatives>
<graphic id="pone.0161112.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mrow><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi mathvariant="normal">S</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mn>22</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">μ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>We provide the initial value for μ<sub><italic>l</italic>(1)</sub>, S<sub><italic>l</italic>11</sub>, and S<sub><italic>l</italic>12</sub>. Then, based on the criterion of the minimum mean-square deviations from Eq (<xref ref-type="disp-formula" rid="pone.0161112.e011">3</xref>), the conditional expectation E<sub><italic>l</italic></sub>(Y<sub><italic>i</italic>(1)</sub>|Y<sub><italic>i</italic>(2)</sub>) can be calculated, representing the best predicted function for Y<sub><italic>i</italic>(1)</sub> [<xref ref-type="bibr" rid="pone.0161112.ref026">26</xref>]. Under the mixture distribution of the individual vector Y<sub><italic>i</italic></sub>, the conditional expectation for Y<sub><italic>i</italic>(1)</sub> based on Y<sub><italic>i</italic>(2)</sub> is
<disp-formula id="pone.0161112.e012">
<alternatives>
<graphic id="pone.0161112.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mspace width="0.15em"/><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where E(Y<sub><italic>i</italic>(1)</sub>|Y<sub><italic>i</italic>(2)</sub>) denotes the estimators for the missing values Y<sub><italic>i</italic>(1)</sub>. Subsequently, a “pseudo-complete” dataset can be constructed.</p>
</sec>
<sec id="sec008">
<title>Iterative clustering algorithm</title>
<p>The proposed model-based clustering algorithm for datasets with missing values assigns each individual to one of the <italic>c</italic> clusters with a certain probability. We define this probability as <italic>p</italic><sub><italic>li</italic></sub>, which is that of the <italic>i</italic>-th individual belonging to the <italic>l</italic>-th cluster. An individual is assigned to the <italic>l</italic>-th cluster if <italic>p</italic><sub><italic>li</italic></sub> is greater than a certain pre-determined threshold. The probability can be calculated using the expectation-maximization (EM) algorithm [<xref ref-type="bibr" rid="pone.0161112.ref027">27</xref>] to achieve the maximum likelihood for the objective function derived with Eq (<xref ref-type="disp-formula" rid="pone.0161112.e005">2</xref>). The EM algorithm begins with some initial parameters that are set in advance. Then, each parameter is iteratively updated in the algorithm until convergence to a minimizer is reached. An EM iteration includes the following steps:</p>
<list list-type="order">
<list-item><p>Initialize the prior probabilities of the cluster assignment and the cluster parameters:
<disp-formula id="pone.0161112.e013">
<alternatives>
<graphic id="pone.0161112.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:msup><mml:mi mathvariant="normal">q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">μ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">S</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p></list-item>
<list-item><p>Calculate the missing values <inline-formula id="pone.0161112.e014"><alternatives><graphic id="pone.0161112.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> using Eqs (<xref ref-type="disp-formula" rid="pone.0161112.e011">3</xref>) and (<xref ref-type="disp-formula" rid="pone.0161112.e012">4</xref>) to generate the “pseudo-complete” dataset for <inline-formula id="pone.0161112.e015"><alternatives><graphic id="pone.0161112.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item>
<list-item><p>Update the posterior probabilities of the cluster assignment:
<disp-formula id="pone.0161112.e016">
<alternatives>
<graphic id="pone.0161112.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>c</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p></list-item>
<list-item><p>Update the cluster proportions, mean vectors, and variance-covariance matrices:
<disp-formula id="pone.0161112.e017">
<alternatives>
<graphic id="pone.0161112.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mo stretchy="true">/</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>;</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
<disp-formula id="pone.0161112.e018">
<alternatives>
<graphic id="pone.0161112.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e018" xlink:type="simple"/>
<mml:math display="block" id="M18">
<mml:mrow><mml:msubsup><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mo stretchy="true">/</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mrow><mml:mo>;</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
<disp-formula id="pone.0161112.e019">
<alternatives>
<graphic id="pone.0161112.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:mrow><mml:msubsup><mml:mi mathvariant="normal">S</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">μ</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">/</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p></list-item>
<list-item><p>Repeat steps (1)–(4) until convergence is reached.</p></list-item>
</list>
<p>The number of clusters <italic>c</italic> can also be treated as an unknown parameter and inferred by the BIC or AIC tests. The BIC is derived as follows:
<disp-formula id="pone.0161112.e020">
<alternatives>
<graphic id="pone.0161112.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mrow><mml:mtext>BIC</mml:mtext><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="0.10em"/><mml:mi mathvariant="normal">ln</mml:mi><mml:mspace width="0.10em"/><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi mathvariant="normal">ln</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
where <italic>q</italic> = <italic>c</italic>(<italic>k</italic>+1)(<italic>k</italic>+2)/2−1 is the number of independent parameters to be estimated in the model, <inline-formula id="pone.0161112.e021"><alternatives><graphic id="pone.0161112.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mtext>L</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the likelihood of <inline-formula id="pone.0161112.e022"><alternatives><graphic id="pone.0161112.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>—i.e., the vector for the maximum likelihood estimation of the parameters—and <italic>n</italic> is the size of the dataset. The number of clusters <italic>c</italic> is determined by the maximum BIC value.</p>
</sec>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<sec id="sec010">
<title>Simulation analysis</title>
<p>A simulation was designed to evaluate the feasibility and accuracy of the proposed missing-values imputation algorithm. The individuals belonging to each cluster were known exactly and without subjective errors. Indeed, when analyzing real data, the misjudgment rate (MR) may reflect confounding errors in the experiment and the subjective errors. Without loss of generality, we simulated datasets with a two-dimensional Gaussian distribution and some missing values. All simulations were performed using statistical SAS (version 9.3; SAS/IML) software.</p>
<sec id="sec011">
<title>Design of the simulation</title>
<p>Suppose that there are 500 individuals derived from one of two (two-dimensional) Gaussian populations, denoted by <italic>MVN</italic> (<bold>μ</bold><sub>1</sub>,<bold>S</bold><sub>1</sub>) and <italic>MVN</italic> (<bold>μ</bold><sub>2</sub>,<bold>S</bold><sub>2</sub>), from which 10% of the individuals have at least one variable randomly removed. The entire dataset contains 1000 individuals. Each individual has two variables, and 100 individuals have at least one variable missing. The cluster’s mean vectors are denoted by <bold>μ</bold><sub>1</sub> and <bold>μ</bold><sub>2</sub>, which were simulated at three different levels: <italic>A</italic><sub>1</sub>: <bold>μ</bold><sub>1</sub> = (0, 0), <bold>μ</bold><sub>2</sub> = (2.5, 2.5), <italic>A</italic><sub>2</sub>: <bold>μ</bold><sub>1</sub> = (0, 0), <bold>μ</bold><sub>2</sub> = (2.0, 2.0), and <italic>A</italic><sub>3</sub>: <bold>μ</bold><sub>1</sub> = (0, 0), <bold>μ</bold><sub>2</sub> = (1.5, 1.5). The variance-covariance matrices are denoted by <bold>S</bold><sub>1</sub> and <bold>S</bold><sub>2</sub> (without loss of generality, supposing that <bold>S</bold><sub>1</sub> = <bold>S</bold><sub>2</sub> = <bold>S</bold>), and these were set at four levels: <inline-formula id="pone.0161112.e023"><alternatives><graphic id="pone.0161112.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn><mml:mspace width="0.25em"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0161112.e024"><alternatives><graphic id="pone.0161112.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mspace width="0.25em"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0161112.e025"><alternatives><graphic id="pone.0161112.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn><mml:mspace width="0.25em"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pone.0161112.e026"><alternatives><graphic id="pone.0161112.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.6</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. The total number of treatment combinations (datasets) is therefore 3 × 4 = 12, that is, A<sub>1</sub>B<sub>1</sub>, A<sub>1</sub>B<sub>2</sub>, A<sub>1</sub>B<sub>3</sub>, A<sub>1</sub>B<sub>4</sub>, A<sub>2</sub>B<sub>1</sub>, A<sub>2</sub>B<sub>2</sub>, A<sub>2</sub>B<sub>3</sub>, A<sub>2</sub>B<sub>4</sub>, A<sub>3</sub>B<sub>1</sub>, A<sub>3</sub>B<sub>2</sub>, A<sub>3</sub>B<sub>3</sub>, and A<sub>3</sub>B<sub>4.</sub> Twenty replicated simulations were conducted for each of the twelve scenarios.</p>
<p>Our missing-value imputation cluster algorithm (denoted by M-3, generating a “pseudo-complete” dataset) was compared with three other cluster algorithms: a cluster algorithm using the complete dataset (denoted by M-1, i.e., the above simulation dataset without any missing values); a cluster algorithm using a dataset from which all individuals with missing variables are deleted (denoted by M-2, i.e., a cropped dataset); and a cluster algorithm using missing-value imputation by mean replacement in which the missing values are replaced by the mean value of the whole dataset (denoted by M-4, another “pseudo-complete” dataset). Thus, we used these four algorithms to cluster simulated datasets. These algorithms are all based on the multivariate Gaussian mixture model, using the maximum likelihood estimation with the EM algorithm. As such, the clustering results could be fairly compared. We evaluated M-1, M-2, M-3, and M-4 using the following metrics: (1) the average convergence rate; (2) the accuracy and precision of their respective parameter estimates; and (3) the total misjudgment rate (MR), where MR is the ratio of all misjudged individuals to the total number of individuals in the 20 replicates and MR = 1 - accuracy. A chi-square test and multiple comparisons of Scheffé’s Confidence Interval were used to test the differences in MR among the four algorithms.</p>
</sec>
<sec id="sec012">
<title>Simulation results</title>
<p>The average parameter estimates include the mean vectors (± se), variance-covariance matrices (± se), the likelihood value of the maximum-likelihood function, and the total MR for the four clustering algorithms. The results are presented in Tables <xref ref-type="table" rid="pone.0161112.t001">1</xref>–<xref ref-type="table" rid="pone.0161112.t003">3</xref>. Our proposed missing-value imputation clustering algorithm (M-3) outperformed the other two algorithms (M-2 and M-4) in terms of the convergence rate for most of the simulation datasets. Indeed, its superiority was most obvious when the mean vectors of two clusters were near each other and the variance-covariance of each cluster was more disperse, such as with datasets A<sub>2</sub>B<sub>4</sub>, A<sub>3</sub>B<sub>3</sub>, and A<sub>3</sub>B<sub>4</sub>. Moreover, the proposed algorithm resulted in the most accurate and precise parameter estimations, closely approximating the true values.</p>
<table-wrap id="pone.0161112.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t001</object-id>
<label>Table 1</label> <caption><title>Average parameter estimates under 4 different simulation datasets <italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub>-<italic>A</italic><sub>1</sub><italic>B</italic><sub>4</sub> in 20 replicates.</title></caption>
<alternatives>
<graphic id="pone.0161112.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="2" rowspan="2">Treatment</th>
<th align="center" rowspan="2">Iterative time</th>
<th align="center" rowspan="2">Likelihood value</th>
<th align="center" colspan="2">Probability estimate</th>
<th align="center" colspan="4">Mean vector estimate</th>
<th align="center" colspan="4">Covariance matrix estimate</th>
<th align="center" rowspan="2">MR (%)</th>
</tr>
<tr>
<th align="center"><inline-formula id="pone.0161112.e027"><alternatives><graphic id="pone.0161112.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pone.0161112.e028"><alternatives><graphic id="pone.0161112.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e029"><alternatives><graphic id="pone.0161112.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e030"><alternatives><graphic id="pone.0161112.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e031"><alternatives><graphic id="pone.0161112.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e032"><alternatives><graphic id="pone.0161112.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">51</td>
<td align="center" rowspan="2">-1876.32</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.00±0.01</td>
<td align="center" rowspan="2">0.00±0.01</td>
<td align="center" rowspan="2">2.49±0.07</td>
<td align="center" rowspan="2">2.50±0.06</td>
<td align="center">0.25±0.04</td>
<td align="center">0.15±0.03</td>
<td align="center">0.25±0.04</td>
<td align="center">0.15±0.02</td>
<td align="center" rowspan="2">0.20<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.15±0.03</td>
<td align="center">0.26±0.04</td>
<td align="center">0.15±0.02</td>
<td align="center">0.25±0.04</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">58</td>
<td align="center" rowspan="2">-1864.94</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.00±0.01</td>
<td align="center" rowspan="2">-0.01±0.02</td>
<td align="center" rowspan="2">2.47±0.08</td>
<td align="center" rowspan="2">2.53±0.07</td>
<td align="center">0.24±0.05</td>
<td align="center">0.14±0.03</td>
<td align="center">0.25±0.03</td>
<td align="center">0.15±0.02</td>
<td align="center" rowspan="2">0.30<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.14±0.03</td>
<td align="center">0.26±0.04</td>
<td align="center">0.15±0.02</td>
<td align="center">0.24±0.04</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">64</td>
<td align="center" rowspan="2">-1897.05</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.00±0.02</td>
<td align="center" rowspan="2">0.00±0.01</td>
<td align="center" rowspan="2">2.49±0.07</td>
<td align="center" rowspan="2">2.50±0.06</td>
<td align="center">0.24±0.04</td>
<td align="center">0.14±0.02</td>
<td align="center">0.24±0.04</td>
<td align="center">0.14±0.04</td>
<td align="center" rowspan="2">0.20<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.14±0.02</td>
<td align="center">0.26±0.03</td>
<td align="center">0.14±0.04</td>
<td align="center">0.25±0.04</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">55</td>
<td align="center" rowspan="2">-1800.38</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">-0.01±0.03</td>
<td align="center" rowspan="2">0.00±0.02</td>
<td align="center" rowspan="2">2.46±0.08</td>
<td align="center" rowspan="2">2.46±0.09</td>
<td align="center">0.22±0.07</td>
<td align="center">0.13±0.04</td>
<td align="center">0.23±0.06</td>
<td align="center">0.14±0.05</td>
<td align="center" rowspan="2">1.50<xref ref-type="table-fn" rid="t001fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.13±0.04</td>
<td align="center">0.23±0.06</td>
<td align="center">0.14±0.05</td>
<td align="center">0.21±0.07</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>1</sub><italic>B</italic><sub>2</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">70</td>
<td align="center" rowspan="2">-2578.47</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.01±0.03</td>
<td align="center" rowspan="2">0.00±0.04</td>
<td align="center" rowspan="2">2.47±0.14</td>
<td align="center" rowspan="2">2.47±0.14</td>
<td align="center">0.48±0.06</td>
<td align="center">0.28±0.04</td>
<td align="center">0.47±0.07</td>
<td align="center">0.28±0.04</td>
<td align="center" rowspan="2">2.40<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.28±0.04</td>
<td align="center">0.53±0.08</td>
<td align="center">0.28±0.04</td>
<td align="center">0.48±0.06</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">80</td>
<td align="center" rowspan="2">-2362.69</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.01±0.04</td>
<td align="center" rowspan="2">0.01±0.04</td>
<td align="center" rowspan="2">2.52±0.15</td>
<td align="center" rowspan="2">2.48±0.16</td>
<td align="center">0.48±0.07</td>
<td align="center">0.32±0.04</td>
<td align="center">0.47±0.07</td>
<td align="center">0.26±0.06</td>
<td align="center" rowspan="2">2.80<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.32±0.04</td>
<td align="center">0.54±0.08</td>
<td align="center">0.26±0.06</td>
<td align="center">0.46±0.08</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">87</td>
<td align="center" rowspan="2">-2591.61</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.01±0.04</td>
<td align="center" rowspan="2">0.01±0.03</td>
<td align="center" rowspan="2">2.47±0.14</td>
<td align="center" rowspan="2">2.46±0.16</td>
<td align="center">0.47±0.06</td>
<td align="center">0.27±0.05</td>
<td align="center">0.46±0.07</td>
<td align="center">0.28±0.04</td>
<td align="center" rowspan="2">2.60<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.27±0.05</td>
<td align="center">0.53±0.07</td>
<td align="center">0.28±0.04</td>
<td align="center">0.48±0.06</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">93</td>
<td align="center" rowspan="2">-2653.93</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.02±0.09</td>
<td align="center" rowspan="2">0.01±0.08</td>
<td align="center" rowspan="2">2.43±0.26</td>
<td align="center" rowspan="2">2.44±0.23</td>
<td align="center">0.42±0.14</td>
<td align="center">0.25±0.11</td>
<td align="center">0.44±0.12</td>
<td align="center">0.25±0.11</td>
<td align="center" rowspan="2">5.64<xref ref-type="table-fn" rid="t001fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.25±0.11</td>
<td align="center">0.43±0.13</td>
<td align="center">0.25±0.11</td>
<td align="center">0.44±0.12</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>1</sub><italic>B</italic><sub>3</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">107</td>
<td align="center" rowspan="2">-2837.52</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">0.02±0.07</td>
<td align="center" rowspan="2">-0.01±0.08</td>
<td align="center" rowspan="2">2.47±0.21</td>
<td align="center" rowspan="2">2.47±0.21</td>
<td align="center">0.68±0.16</td>
<td align="center">0.42±0.10</td>
<td align="center">0.71±0.14</td>
<td align="center">0.43±0.09</td>
<td align="center" rowspan="2">5.90 <xref ref-type="table-fn" rid="t001fn003"><sup><italic>ab</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.42±0.10</td>
<td align="center">0.78±0.15</td>
<td align="center">0.43±0.09</td>
<td align="center">0.75±0.14</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">142</td>
<td align="center" rowspan="2">-2569.69</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.02±0.06</td>
<td align="center" rowspan="2">0.01±0.06</td>
<td align="center" rowspan="2">2.48±0.20</td>
<td align="center" rowspan="2">2.52±0.19</td>
<td align="center">0.73±0.16</td>
<td align="center">0.47±0.08</td>
<td align="center">0.69±0.16</td>
<td align="center">0.40±0.09</td>
<td align="center" rowspan="2">5.45<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.47±0.08</td>
<td align="center">0.81±0.15</td>
<td align="center">0.40±0.09</td>
<td align="center">0.67±0.17</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">134</td>
<td align="center" rowspan="2">-2822.26</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">-0.01±0.07</td>
<td align="center" rowspan="2">-0.02±0.06</td>
<td align="center" rowspan="2">2.45±0.21</td>
<td align="center" rowspan="2">2.46±0.20</td>
<td align="center">0.65±0.17</td>
<td align="center">0.39±0.08</td>
<td align="center">0.73±0.14</td>
<td align="center">0.42±0.07</td>
<td align="center" rowspan="2">6.12<xref ref-type="table-fn" rid="t001fn003"><sup><italic>ab</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.39±0.08</td>
<td align="center">0.76±0.12</td>
<td align="center">0.42±0.07</td>
<td align="center">0.68±0.15</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">138</td>
<td align="center" rowspan="2">-2859.62</td>
<td align="center" rowspan="2">0.45</td>
<td align="center" rowspan="2">0.55</td>
<td align="center" rowspan="2">-0.05±0.15</td>
<td align="center" rowspan="2">0.04±0.12</td>
<td align="center" rowspan="2">2.40±0.37</td>
<td align="center" rowspan="2">2.43±0.32</td>
<td align="center">0.63±0.21</td>
<td align="center">0.40±0.16</td>
<td align="center">0.70±0.19</td>
<td align="center">0.39±0.11</td>
<td align="center" rowspan="2">8.94<xref ref-type="table-fn" rid="t001fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.40±0.16</td>
<td align="center">0.60±0.20</td>
<td align="center">0.39±0.11</td>
<td align="center">0.71±0.19</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>1</sub><italic>B</italic><sub>4</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">180</td>
<td align="center" rowspan="2">-3211.91</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">-0.05±0.10</td>
<td align="center" rowspan="2">-0.03±0.12</td>
<td align="center" rowspan="2">2.40±0.25</td>
<td align="center" rowspan="2">2.42±0.28</td>
<td align="center">0.86±0.24</td>
<td align="center">0.51±0.17</td>
<td align="center">0.94±0.24</td>
<td align="center">0.59±0.15</td>
<td align="center" rowspan="2">8.50<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.51±0.17</td>
<td align="center">1.05±0.26</td>
<td align="center">0.59±0.15</td>
<td align="center">1.02±0.23</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">214</td>
<td align="center" rowspan="2">-2852.78</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">-0.04±0.10</td>
<td align="center" rowspan="2">-0.06±0.14</td>
<td align="center" rowspan="2">2.38±0.30</td>
<td align="center" rowspan="2">2.37±0.32</td>
<td align="center">0.84±0.25</td>
<td align="center">0.55±0.16</td>
<td align="center">0.97±0.19</td>
<td align="center">0.56±0.16</td>
<td align="center" rowspan="2">9.20<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.55±0.16</td>
<td align="center">1.05±0.26</td>
<td align="center">0.56±0.16</td>
<td align="center">0.94±0.25</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">215</td>
<td align="center" rowspan="2">-3100.00</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">-0.05±0.12</td>
<td align="center" rowspan="2">-0.06±0.13</td>
<td align="center" rowspan="2">2.39±0.26</td>
<td align="center" rowspan="2">2.38±0.30</td>
<td align="center">0.84±0.23</td>
<td align="center">0.48±0.19</td>
<td align="center">0.90±0.25</td>
<td align="center">0.57±0.14</td>
<td align="center" rowspan="2">8.70<xref ref-type="table-fn" rid="t001fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.48±0.19</td>
<td align="center">1.02±0.21</td>
<td align="center">0.57±0.14</td>
<td align="center">0.99±0.20</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">267</td>
<td align="center" rowspan="2">-3289.32</td>
<td align="center" rowspan="2">0.43</td>
<td align="center" rowspan="2">0.57</td>
<td align="center" rowspan="2">-0.07±0.20</td>
<td align="center" rowspan="2">-0.08±0.25</td>
<td align="center" rowspan="2">2.17±0.48</td>
<td align="center" rowspan="2">2.22±0.52</td>
<td align="center">0.77±0.32</td>
<td align="center">0.43±0.28</td>
<td align="center">0.82±0.27</td>
<td align="center">0.48±0.15</td>
<td align="center" rowspan="2">18.90<xref ref-type="table-fn" rid="t001fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="left">0.43±0.28</td>
<td align="left">1.09±0.23</td>
<td align="left">0.48±0.15</td>
<td align="left">1.07±0.25</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>M-1 indicates a complete data clustering algorithm; M-2 indicates a missing-data-deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm</p></fn>
<fn id="t001fn002"><p>M-4 indicates the clustering algorithm for missing-value imputation by mean replacement. These four algorithms are based on the multivariate Gaussian mixture model.</p></fn>
<fn id="t001fn003"><p><sup><italic>a</italic>,<italic>b</italic></sup> indicates the multiple comparisons of the differences in MR among the algorithms M-1, M-2, M-3, and M-4: having the different letters indicate that there is statistical significance between these two groups (P&lt;0.05), and vice versa.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pone.0161112.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t002</object-id>
<label>Table 2</label> <caption><title>Average parameter estimates under 4 different simulation datasets <italic>A</italic><sub>2</sub><italic>B</italic><sub>1</sub>-<italic>A</italic><sub>2</sub><italic>B</italic><sub>4</sub> in 20 replicates.</title></caption>
<alternatives>
<graphic id="pone.0161112.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="2" rowspan="2">Treatment</th>
<th align="center" rowspan="2">Iterative time</th>
<th align="center" rowspan="2">Likelihood value</th>
<th align="center" colspan="2">Probability estimate</th>
<th align="center" colspan="4">Mean vector estimate</th>
<th align="center" colspan="4">Covariance matrix estimate</th>
<th align="center" rowspan="2">MR (%)</th>
</tr>
<tr>
<th align="center"><inline-formula id="pone.0161112.e033"><alternatives><graphic id="pone.0161112.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pone.0161112.e034"><alternatives><graphic id="pone.0161112.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e035"><alternatives><graphic id="pone.0161112.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e036"><alternatives><graphic id="pone.0161112.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e037"><alternatives><graphic id="pone.0161112.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e038"><alternatives><graphic id="pone.0161112.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>2</sub><italic>B</italic><sub>1</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">81</td>
<td align="center" rowspan="2">-1903.64</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.01±0.04</td>
<td align="center" rowspan="2">0.00±0.03</td>
<td align="center" rowspan="2">2.00±0.12</td>
<td align="center" rowspan="2">2.00±0.13</td>
<td align="center">0.25±0.05</td>
<td align="center">0.15±0.04</td>
<td align="center">0.24±0.04</td>
<td align="center">0.14±0.04</td>
<td align="center" rowspan="2">1.64<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.15±0.04</td>
<td align="center">0.25±0.05</td>
<td align="center">0.14±0.04</td>
<td align="center">0.24±0.05</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">117</td>
<td align="center" rowspan="2">-1696.53</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.01±0.04</td>
<td align="center" rowspan="2">-0.01±0.04</td>
<td align="center" rowspan="2">2.00±0.14</td>
<td align="center" rowspan="2">1.99±0.13</td>
<td align="center">0.24±0.05</td>
<td align="center">0.15±0.03</td>
<td align="center">0.25±0.05</td>
<td align="center">0.14±0.04</td>
<td align="center" rowspan="2">1.86<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.15±0.03</td>
<td align="center">0.26±0.04</td>
<td align="center">0.14±0.04</td>
<td align="center">0.24±0.06</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">92</td>
<td align="center" rowspan="2">-1885.63</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.01±0.04</td>
<td align="center" rowspan="2">0.01±0.04</td>
<td align="center" rowspan="2">1.99±0.14</td>
<td align="center" rowspan="2">1.99±0.12</td>
<td align="center">0.23±0.05</td>
<td align="center">0.14±0.04</td>
<td align="center">0.23±0.06</td>
<td align="center">0.15±0.04</td>
<td align="center" rowspan="2">1.60<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.14±0.04</td>
<td align="center">0.26±0.04</td>
<td align="center">0.15±0.04</td>
<td align="center">0.24±0.05</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">126</td>
<td align="center" rowspan="2">-2008.47</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">-0.02±0.07</td>
<td align="center" rowspan="2">0.01±0.06</td>
<td align="center" rowspan="2">1.95±0.19</td>
<td align="center" rowspan="2">1.96±0.20</td>
<td align="center">0.22±0.10</td>
<td align="center">0.12±0.07</td>
<td align="center">0.21±0.10</td>
<td align="center">0.11±0.05</td>
<td align="center" rowspan="2">2.26<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.12±0.07</td>
<td align="center">0.27±0.12</td>
<td align="center">0.11±0.05</td>
<td align="center">0.27±0.07</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>2</sub><italic>B</italic><sub>2</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">120</td>
<td align="center" rowspan="2">-2372.14</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.02±0.07</td>
<td align="center" rowspan="2">-0.01±0.06</td>
<td align="center" rowspan="2">2.01±0.16</td>
<td align="center" rowspan="2">1.97±0.17</td>
<td align="center">0.45±0.13</td>
<td align="center">0.27±0.09</td>
<td align="center">0.46±0.14</td>
<td align="center">0.28±0.10</td>
<td align="center" rowspan="2">5.60<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.27±0.09</td>
<td align="center">0.52±0.11</td>
<td align="center">0.28±0.10</td>
<td align="center">0.50±0.14</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">179</td>
<td align="center" rowspan="2">-2128.49</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">-0.02±0.08</td>
<td align="center" rowspan="2">0.02±0.06</td>
<td align="center" rowspan="2">1.95±0.18</td>
<td align="center" rowspan="2">1.96±0.18</td>
<td align="center">0.48±0.11</td>
<td align="center">0.27±0.08</td>
<td align="center">0.47±0.14</td>
<td align="center">0.25±0.09</td>
<td align="center" rowspan="2">6.30<xref ref-type="table-fn" rid="t002fn003"><sup><italic>ab</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.27±0.08</td>
<td align="center">0.53±0.13</td>
<td align="center">0.25±0.09</td>
<td align="center">0.45±0.13</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">135</td>
<td align="center" rowspan="2">-2462.73</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.01±0.07</td>
<td align="center" rowspan="2">0.02±0.06</td>
<td align="center" rowspan="2">1.95±0.19</td>
<td align="center" rowspan="2">1.97±0.17</td>
<td align="center">0.46±0.11</td>
<td align="center">0.28±0.08</td>
<td align="center">0.44±0.09</td>
<td align="center">0.26±0.09</td>
<td align="center" rowspan="2">5.40<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.28±0.08</td>
<td align="center">0.53±0.10</td>
<td align="center">0.26±0.09</td>
<td align="center">0.46±0.08</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">266</td>
<td align="center" rowspan="2">-2410.50</td>
<td align="center" rowspan="2">0.45</td>
<td align="center" rowspan="2">0.55</td>
<td align="center" rowspan="2">-0.03±0.10</td>
<td align="center" rowspan="2">0.02±0.11</td>
<td align="center" rowspan="2">1.91±0.28</td>
<td align="center" rowspan="2">1.92±0.29</td>
<td align="center">0.44±0.17</td>
<td align="center">0.25±0.10</td>
<td align="center">0.44±0.18</td>
<td align="center">0.24±0.11</td>
<td align="center" rowspan="2">9.00 <xref ref-type="table-fn" rid="t002fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.25±0.10</td>
<td align="center">0.54±0.16</td>
<td align="center">0.24±0.11</td>
<td align="center">0.43±0.19</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>2</sub><italic>B</italic><sub>3</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">219</td>
<td align="center" rowspan="2">-2699.35</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">-0.05±0.08</td>
<td align="center" rowspan="2">-0.03±0.08</td>
<td align="center" rowspan="2">1.92±0.27</td>
<td align="center" rowspan="2">1.94±0.24</td>
<td align="center">0.67±0.20</td>
<td align="center">0.40±0.10</td>
<td align="center">0.75±0.19</td>
<td align="center">0.42±0.11</td>
<td align="center" rowspan="2">10.90<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.40±0.10</td>
<td align="center">0.78±0.21</td>
<td align="center">0.42±0.11</td>
<td align="center">0.78±0.19</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">387</td>
<td align="center" rowspan="2">-2489.38</td>
<td align="center" rowspan="2">0.47</td>
<td align="center" rowspan="2">0.53</td>
<td align="center" rowspan="2">-0.07±0.09</td>
<td align="center" rowspan="2">0.05±0.10</td>
<td align="center" rowspan="2">1.90±0.27</td>
<td align="center" rowspan="2">1.90±0.28</td>
<td align="center">0.64±0.25</td>
<td align="center">0.38±0.13</td>
<td align="center">0.72±0.22</td>
<td align="center">0.41±0.12</td>
<td align="center" rowspan="2">11.40<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.38±0.13</td>
<td align="center">0.73±0.24</td>
<td align="center">0.41±0.12</td>
<td align="center">0.79±0.21</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">242</td>
<td align="center" rowspan="2">-2709.34</td>
<td align="center" rowspan="2">0.47</td>
<td align="center" rowspan="2">0.53</td>
<td align="center" rowspan="2">-0.07±0.10</td>
<td align="center" rowspan="2">-0.05±0.10</td>
<td align="center" rowspan="2">1.90±0.28</td>
<td align="center" rowspan="2">1.90±0.30</td>
<td align="center">0.66±0.18</td>
<td align="center">0.38±0.09</td>
<td align="center">0.76±0.20</td>
<td align="center">0.47±0.11</td>
<td align="center" rowspan="2">11.00<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.42±0.09</td>
<td align="center">0.77±0.18</td>
<td align="center">0.47±0.11</td>
<td align="center">0.75±0.20</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">450</td>
<td align="center" rowspan="2">-2646.83</td>
<td align="center" rowspan="2">0.42</td>
<td align="center" rowspan="2">0.58</td>
<td align="center" rowspan="2">-0.14±0.20</td>
<td align="center" rowspan="2">0.12±0.18</td>
<td align="center" rowspan="2">1.89±0.41</td>
<td align="center" rowspan="2">1.88±0.45</td>
<td align="center">0.64±0.29</td>
<td align="center">0.38±0.17</td>
<td align="center">0.72±0.27</td>
<td align="center">0.40±0.15</td>
<td align="center" rowspan="2">16.96<xref ref-type="table-fn" rid="t002fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.38±0.17</td>
<td align="center">0.78±0.27</td>
<td align="center">0.40±0.15</td>
<td align="center">0.77±0.23</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>2</sub><italic>B</italic><sub>4</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">360</td>
<td align="center" rowspan="2">-3014.36</td>
<td align="center" rowspan="2">0.45</td>
<td align="center" rowspan="2">0.55</td>
<td align="center" rowspan="2">-0.11±0.16</td>
<td align="center" rowspan="2">0.09±0.17</td>
<td align="center" rowspan="2">1.85±0.34</td>
<td align="center" rowspan="2">1.80±0.32</td>
<td align="center">0.86±0.26</td>
<td align="center">0.52±0.18</td>
<td align="center">1.01±0.23</td>
<td align="center">0.63±0.17</td>
<td align="center" rowspan="2">12.80<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.52±0.18</td>
<td align="center">1.04±0.25</td>
<td align="center">0.63±0.17</td>
<td align="center">1.05±0.23</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">486</td>
<td align="center" rowspan="2">-2677.25</td>
<td align="center" rowspan="2">0.43</td>
<td align="center" rowspan="2">0.57</td>
<td align="center" rowspan="2">-0.15±0.25</td>
<td align="center" rowspan="2">-0.15±0.25</td>
<td align="center" rowspan="2">1.84±0.35</td>
<td align="center" rowspan="2">1.82±0.32</td>
<td align="center">0.82±0.30</td>
<td align="center">0.51±0.19</td>
<td align="center">1.04±0.29</td>
<td align="center">0.61±0.18</td>
<td align="center" rowspan="2">18.00<xref ref-type="table-fn" rid="t002fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.51±0.19</td>
<td align="center">0.94±0.25</td>
<td align="center">0.61±0.18</td>
<td align="center">1.01±0.29</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">342</td>
<td align="center" rowspan="2">-2907.18</td>
<td align="center" rowspan="2">0.44</td>
<td align="center" rowspan="2">0.56</td>
<td align="center" rowspan="2">-0.10±0.17</td>
<td align="center" rowspan="2">0.08±0.14</td>
<td align="center" rowspan="2">1.86±0.34</td>
<td align="center" rowspan="2">1.82±0.32</td>
<td align="center">0.87±0.27</td>
<td align="center">0.53±0.18</td>
<td align="center">0.92±0.28</td>
<td align="center">0.62±0.17</td>
<td align="center" rowspan="2">12.30<xref ref-type="table-fn" rid="t002fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.53±0.18</td>
<td align="center">1.03±0.25</td>
<td align="center">0.62±0.17</td>
<td align="center">1.03±0.29</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">440</td>
<td align="center" rowspan="2">-2977.46</td>
<td align="center" rowspan="2">0.40</td>
<td align="center" rowspan="2">0.60</td>
<td align="center" rowspan="2">-0.20±0.35</td>
<td align="center" rowspan="2">0.19±0.33</td>
<td align="center" rowspan="2">1.82±0.57</td>
<td align="center" rowspan="2">1.81±0.62</td>
<td align="center">0.76±0.41</td>
<td align="center">0.51±0.27</td>
<td align="center">1.05±0.33</td>
<td align="center">0.65±0.27</td>
<td align="center" rowspan="2">21.80<xref ref-type="table-fn" rid="t002fn003"><sup><italic>c</italic></sup></xref></td>
</tr>
<tr>
<td align="left">0.51±0.27</td>
<td align="left">0.90±0.39</td>
<td align="left">0.65±0.27</td>
<td align="left">1.07±0.34</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>M-1 indicates a complete data clustering algorithm; M-2 indicates a missing-data-deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm</p></fn>
<fn id="t002fn002"><p>M-4 indicates the clustering algorithm for missing-value imputation by mean replacement. These four algorithms are based on the multivariate Gaussian mixture model.</p></fn>
<fn id="t002fn003"><p><sup><italic>a</italic>,<italic>b</italic>,<italic>c</italic></sup> indicates the multiple comparisons of the differences in MR among the algorithms M-1, M-2, M-3, and M-4: having the different letters indicate that there is statistical significance between these two groups (P&lt;0.05), and vice versa.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pone.0161112.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t003</object-id>
<label>Table 3</label> <caption><title>Average parameter estimates under 12 different simulation datasets <italic>A</italic><sub>3</sub><italic>B</italic><sub>1</sub>-<italic>A</italic><sub>3</sub><italic>B</italic><sub>4</sub> in 20 replicates.</title></caption>
<alternatives>
<graphic id="pone.0161112.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="2" rowspan="2">Treatment</th>
<th align="center" rowspan="2">Iterative time</th>
<th align="center" rowspan="2">Likelihood value</th>
<th align="center" colspan="2">Probability estimate</th>
<th align="center" colspan="4">Mean vector estimate</th>
<th align="center" colspan="4">Covariance matrix estimate</th>
<th align="center" rowspan="2">MR (%)</th>
</tr>
<tr>
<th align="center"><inline-formula id="pone.0161112.e039"><alternatives><graphic id="pone.0161112.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pone.0161112.e040"><alternatives><graphic id="pone.0161112.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e041"><alternatives><graphic id="pone.0161112.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e042"><alternatives><graphic id="pone.0161112.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e043"><alternatives><graphic id="pone.0161112.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
<th align="center" colspan="2"><inline-formula id="pone.0161112.e044"><alternatives><graphic id="pone.0161112.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0161112.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> ± se</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>3</sub><italic>B</italic><sub>1</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">129</td>
<td align="center" rowspan="2">-1816.34</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.00±0.06</td>
<td align="center" rowspan="2">0.01±0.06</td>
<td align="center" rowspan="2">1.47±0.15</td>
<td align="center" rowspan="2">1.48±0.14</td>
<td align="center">0.23±0.08</td>
<td align="center">0.13±0.05</td>
<td align="center">0.23±0.09</td>
<td align="center">0.14±0.06</td>
<td align="center" rowspan="2">4.90<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.13±0.05</td>
<td align="center">0.26±0.09</td>
<td align="center">0.14±0.06</td>
<td align="center">0.25±0.10</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">337</td>
<td align="center" rowspan="2">-1637.81</td>
<td align="center" rowspan="2">0.51</td>
<td align="center" rowspan="2">0.49</td>
<td align="center" rowspan="2">0.01±0.07</td>
<td align="center" rowspan="2">0.01±0.06</td>
<td align="center" rowspan="2">1.53±0.15</td>
<td align="center" rowspan="2">1.47±0.16</td>
<td align="center">0.23±0.08</td>
<td align="center">0.14±0.06</td>
<td align="center">0.23±0.10</td>
<td align="center">0.12±0.06</td>
<td align="center" rowspan="2">5.35<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.14±0.06</td>
<td align="center">0.27±0.10</td>
<td align="center">0.12±0.06</td>
<td align="center">0.22±0.09</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">134</td>
<td align="center" rowspan="2">-1762.64</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">0.50</td>
<td align="center" rowspan="2">-0.01±0.07</td>
<td align="center" rowspan="2">0.00±0.06</td>
<td align="center" rowspan="2">1.46±0.16</td>
<td align="center" rowspan="2">1.46±0.16</td>
<td align="center">0.21±0.08</td>
<td align="center">0.13±0.05</td>
<td align="center">0.21±0.09</td>
<td align="center">0.14±0.05</td>
<td align="center" rowspan="2">5.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.13±0.05</td>
<td align="center">0.26±0.08</td>
<td align="center">0.14±0.05</td>
<td align="center">0.25±0.08</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">359</td>
<td align="center" rowspan="2">-1800.32</td>
<td align="center" rowspan="2">0.52</td>
<td align="center" rowspan="2">0.48</td>
<td align="center" rowspan="2">-0.02±0.09</td>
<td align="center" rowspan="2">0.03±0.08</td>
<td align="center" rowspan="2">1.44±0.25</td>
<td align="center" rowspan="2">1.45±0.26</td>
<td align="center">0.20±0.14</td>
<td align="center">0.13±0.07</td>
<td align="center">0.21±0.13</td>
<td align="center">0.14±0.06</td>
<td align="center" rowspan="2">9.20<xref ref-type="table-fn" rid="t003fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.13±0.07</td>
<td align="center">0.24±0.13</td>
<td align="center">0.14±0.06</td>
<td align="center">0.25±0.13</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>3</sub><italic>B</italic><sub>2</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">312</td>
<td align="center" rowspan="2">-2322.43</td>
<td align="center" rowspan="2">0.45</td>
<td align="center" rowspan="2">0.55</td>
<td align="center" rowspan="2">-0.06±0.10</td>
<td align="center" rowspan="2">-0.03±0.07</td>
<td align="center" rowspan="2">1.43±0.26</td>
<td align="center" rowspan="2">1.45±0.25</td>
<td align="center">0.45±0.23</td>
<td align="center">0.22±0.11</td>
<td align="center">0.45±0.23</td>
<td align="center">0.32±0.09</td>
<td align="center" rowspan="2">11.50<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.22±0.11</td>
<td align="center">0.55±0.23</td>
<td align="center">0.32±0.09</td>
<td align="center">0.53±0.22</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">444</td>
<td align="center" rowspan="2">-2102.31</td>
<td align="center" rowspan="2">0.45</td>
<td align="center" rowspan="2">0.55</td>
<td align="center" rowspan="2">-0.08±0.11</td>
<td align="center" rowspan="2">0.07±0.10</td>
<td align="center" rowspan="2">1.41±0.27</td>
<td align="center" rowspan="2">1.42±0.26</td>
<td align="center">0.41±0.25</td>
<td align="center">0.23±0.13</td>
<td align="center">0.45±0.24</td>
<td align="center">0.30±0.10</td>
<td align="center" rowspan="2">13.45<xref ref-type="table-fn" rid="t003fn003"><sup><italic>ab</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.23±0.13</td>
<td align="center">0.47±0.25</td>
<td align="center">0.30±0.10</td>
<td align="center">0.54±0.23</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">300</td>
<td align="center" rowspan="2">-2296.72</td>
<td align="center" rowspan="2">0.46</td>
<td align="center" rowspan="2">0.54</td>
<td align="center" rowspan="2">-0.06±0.10</td>
<td align="center" rowspan="2">-0.03±0.08</td>
<td align="center" rowspan="2">1.42±0.26</td>
<td align="center" rowspan="2">1.43±0.25</td>
<td align="center">0.44±0.23</td>
<td align="center">0.25±0.10</td>
<td align="center">0.46±0.22</td>
<td align="center">0.30±0.09</td>
<td align="center" rowspan="2">12.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.25±0.10</td>
<td align="center">0.54±0.22</td>
<td align="center">0.30±0.09</td>
<td align="center">0.54±0.21</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">489</td>
<td align="center" rowspan="2">-2358.99</td>
<td align="center" rowspan="2">0.43</td>
<td align="center" rowspan="2">0.57</td>
<td align="center" rowspan="2">-0.09±0.25</td>
<td align="center" rowspan="2">0.07±0.26</td>
<td align="center" rowspan="2">1.39±0.33</td>
<td align="center" rowspan="2">1.40±0.35</td>
<td align="center">0.41±0.28</td>
<td align="center">0.25±0.14</td>
<td align="center">0.43±0.29</td>
<td align="center">0.30±0.13</td>
<td align="center" rowspan="2">16.50 <xref ref-type="table-fn" rid="t003fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.25±0.14</td>
<td align="center">0.54±0.29</td>
<td align="center">0.30±0.13</td>
<td align="center">0.52±0.28</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>3</sub><italic>B</italic><sub>3</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">584</td>
<td align="center" rowspan="2">-2586.53</td>
<td align="center" rowspan="2">0.42</td>
<td align="center" rowspan="2">0.60</td>
<td align="center" rowspan="2">-0.15±0.28</td>
<td align="center" rowspan="2">-0.14±0.26</td>
<td align="center" rowspan="2">1.38±0.46</td>
<td align="center" rowspan="2">1.40±0.47</td>
<td align="center">0.68±0.32</td>
<td align="center">0.49±0.18</td>
<td align="center">0.80±0.31</td>
<td align="center">0.49±0.16</td>
<td align="center" rowspan="2">18.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.49±0.18</td>
<td align="center">0.72±0.31</td>
<td align="center">0.49±0.16</td>
<td align="center">0.78±0.30</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">603</td>
<td align="center" rowspan="2">-2364.52</td>
<td align="center" rowspan="2">0.39</td>
<td align="center" rowspan="2">0.63</td>
<td align="center" rowspan="2">-0.19±0.35</td>
<td align="center" rowspan="2">-0.18±0.33</td>
<td align="center" rowspan="2">1.38±0.52</td>
<td align="center" rowspan="2">1.37±0.50</td>
<td align="center">0.64±0.35</td>
<td align="center">0.48±0.17</td>
<td align="center">0.81±0.32</td>
<td align="center">0.46±0.18</td>
<td align="center" rowspan="2">23.30 <xref ref-type="table-fn" rid="t003fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.48±0.17</td>
<td align="center">0.65±0.34</td>
<td align="center">0.46±0.18</td>
<td align="center">0.75±0.32</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">310</td>
<td align="center" rowspan="2">-2578.77</td>
<td align="center" rowspan="2">0.44</td>
<td align="center" rowspan="2">0.58</td>
<td align="center" rowspan="2">-0.10±0.25</td>
<td align="center" rowspan="2">-0.10±0.26</td>
<td align="center" rowspan="2">1.40±0.45</td>
<td align="center" rowspan="2">1.39±0.45</td>
<td align="center">0.65±0.31</td>
<td align="center">0.44±0.17</td>
<td align="center">0.74±0.29</td>
<td align="center">0.47±0.15</td>
<td align="center" rowspan="2">18.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.44±0.17</td>
<td align="center">0.78±0.32</td>
<td align="center">0.47±0.15</td>
<td align="center">0.78±0.29</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">590</td>
<td align="center" rowspan="2">-2600.62</td>
<td align="center" rowspan="2">0.37</td>
<td align="center" rowspan="2">0.63</td>
<td align="center" rowspan="2">-0.18±0.38</td>
<td align="center" rowspan="2">-0.17±0.41</td>
<td align="center" rowspan="2">1.38±0.55</td>
<td align="center" rowspan="2">1.37±0.54</td>
<td align="center">0.63±0.39</td>
<td align="center">0.42±0.25</td>
<td align="center">0.82±0.39</td>
<td align="center">0.48±0.21</td>
<td align="center" rowspan="2">25.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.42±0.25</td>
<td align="center">0.68±0.40</td>
<td align="center">0.48±0.21</td>
<td align="center">0.75±0.39</td>
</tr>
<tr>
<td align="center" rowspan="8"><italic>A</italic><sub>3</sub><italic>B</italic><sub>4</sub></td>
<td align="center" rowspan="2">M-1</td>
<td align="center" rowspan="2">645</td>
<td align="center" rowspan="2">-3013.37</td>
<td align="center" rowspan="2">0.35</td>
<td align="center" rowspan="2">0.65</td>
<td align="center" rowspan="2">-0.13±0.46</td>
<td align="center" rowspan="2">-0.17±0.38</td>
<td align="center" rowspan="2">1.30±0.72</td>
<td align="center" rowspan="2">1.30±0.70</td>
<td align="center">0.92±0.38</td>
<td align="center">0.50±0.20</td>
<td align="center">1.14±0.40</td>
<td align="center">0.68±0.24</td>
<td align="center" rowspan="2">28.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>b</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.50±0.20</td>
<td align="center">1.08±0.34</td>
<td align="center">0.68±0.24</td>
<td align="center">0.97±0.39</td>
</tr>
<tr>
<td align="center" rowspan="2">M-2</td>
<td align="center" rowspan="2">690</td>
<td align="center" rowspan="2">-2633.70</td>
<td align="center" rowspan="2">0.20</td>
<td align="center" rowspan="2">0.80</td>
<td align="center" rowspan="2">-0.22±0.74</td>
<td align="center" rowspan="2">-0.15±0.62</td>
<td align="center" rowspan="2">1.00±0.99</td>
<td align="center" rowspan="2">1.20±0.98</td>
<td align="center">0.70±0.57</td>
<td align="center">0.38±0.40</td>
<td align="center">1.26±0.62</td>
<td align="center">1.01±0.38</td>
<td align="center" rowspan="2">48.32<xref ref-type="table-fn" rid="t003fn003"><sup><italic>c</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.38±0.40</td>
<td align="center">0.79±0.51</td>
<td align="center">1.01±0.38</td>
<td align="center">1.23±0.58</td>
</tr>
<tr>
<td align="center" rowspan="2">M-3</td>
<td align="center" rowspan="2">520</td>
<td align="center" rowspan="2">-2892.21</td>
<td align="center" rowspan="2">0.40</td>
<td align="center" rowspan="2">0.60</td>
<td align="center" rowspan="2">-0.11±0.34</td>
<td align="center" rowspan="2">0.15±0.31</td>
<td align="center" rowspan="2">1.34±0.66</td>
<td align="center" rowspan="2">1.37±0.63</td>
<td align="center">0.93±0.36</td>
<td align="center">0.62±0.18</td>
<td align="center">1.07±0.37</td>
<td align="center">0.69±0.20</td>
<td align="center" rowspan="2">21.30<xref ref-type="table-fn" rid="t003fn003"><sup><italic>a</italic></sup></xref></td>
</tr>
<tr>
<td align="center">0.62±0.18</td>
<td align="center">1.07±0.39</td>
<td align="center">0.69±0.20</td>
<td align="center">0.96±0.41</td>
</tr>
<tr>
<td align="center" rowspan="2">M-4</td>
<td align="center" rowspan="2">835</td>
<td align="center" rowspan="2">-2901.33</td>
<td align="center" rowspan="2">0.10</td>
<td align="center" rowspan="2">0.90</td>
<td align="center" rowspan="2">-0.58±0.74</td>
<td align="center" rowspan="2">-0.55±0.80</td>
<td align="center" rowspan="2">0.90±1.04</td>
<td align="center" rowspan="2">0.97±1.07</td>
<td align="center">0.61±0.72</td>
<td align="center">0.21±0.58</td>
<td align="center">1.26±0.77</td>
<td align="center">0.89±0.47</td>
<td align="center" rowspan="2">56.00<xref ref-type="table-fn" rid="t003fn003"><sup><italic>d</italic></sup></xref></td>
</tr>
<tr>
<td align="left">0.21±0.58</td>
<td align="left">0.62±0.74</td>
<td align="left">0.89±0.47</td>
<td align="left">1.23±0.77</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>M-1 indicates a complete data clustering algorithm; M-2 indicates a missing-data-deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm</p></fn>
<fn id="t003fn002"><p>M-4 indicates the clustering algorithm for missing-value imputation by mean replacement. These four algorithms are based on the multivariate Gaussian mixture model.</p></fn>
<fn id="t003fn003"><p><sup><italic>a</italic>,<italic>b</italic>,<italic>c</italic>,<italic>d</italic></sup> indicates the multiple comparisons of the differences in MR among the algorithms M-1, M-2, M-3, and M-4: having the different letters indicate that there is statistical significance between these two groups (P&lt;0.05), and vice versa.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Thus, our proposed missing-value imputation clustering algorithm correctly clusters individuals with missing variables. The total MR resulting from the proposed algorithm (M-3) demonstrates that its performance is superior to that of M-4 in all simulation trials, with significant statistical difference (p &lt; 0.05), and superior to that of M-2 in simulation trials A<sub>2</sub>B<sub>4</sub>, A<sub>3</sub>B<sub>3</sub>, and A<sub>3</sub>B<sub>4</sub>, with significant statistical difference (p &lt; 0.05). Moreover, the clustering accuracy of our proposed algorithm was comparable to that of the complete dataset (M-1) (p &gt; 0.05). In general, the more similar the mean vectors of two clusters or the more disperse their variance-covariance, the higher the MR of all clustering methods and the better the performance of our proposed algorithm compared to M-2 and M-4. Interestingly, however, our algorithm performed well in such cases. For example, in scenario A<sub>3</sub>B<sub>4</sub>, the speed of convergence with M-2 and M-4 was lower in both cases than for other scenarios and had a total MR of 48.32% and 56.00%, respectively, whereas the total MR with our proposed algorithm M-3 was 21.30%. In fact, this result was slightly better than M-1, which resulted in an MR of 28.00%.</p>
</sec>
</sec>
<sec id="sec013">
<title>Real data analysis</title>
<sec id="sec014">
<title>Iris dataset</title>
<p>Fisher’s Iris dataset (Fisher, 1936) [<xref ref-type="bibr" rid="pone.0161112.ref012">12</xref>] is perhaps the best-known database for comparing clustering algorithms. The dataset contains three clusters with 50 individuals each, where each cluster is a species of the genus <italic>Iris</italic>: namely, <italic>Iris setosa</italic>, <italic>Iris versicolor</italic>, and <italic>Iris virginica</italic>. These three species are thus segregated. The dataset contains four variables: sepal length, sepal width, petal length, and petal width. Fisher’s Iris dataset is available on the Internet (<ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/datasets/Iris" xlink:type="simple">http://archive.ics.uci.edu/ml/datasets/Iris</ext-link>). We randomly removed one of the four variables in 10% of the individual observations of <italic>Iris</italic> data; the resulting dataset constituted a dataset with missing values. <xref ref-type="table" rid="pone.0161112.t004">Table 4</xref> lists the clustering results from five clustering algorithms: the above four clustering algorithms [the clustering algorithm with a complete dataset (M-1), the clustering algorithm in which individuals with missing variables are deleted (M-2), our proposed missing-value imputation algorithm (M-3), and the clustering algorithm for missing-value imputation by mean replacement (M-4)] and the FCM clustering method applied to the dataset with data missing from 10% of the individuals. In the M-4 and FCM methods, the missing values are replaced by the mean of the whole dataset. The superiority of our proposed method is obvious insofar as M-3 resulted in the lowest MR of the five algorithms. Because of Gaussian mixture distribution of the dataset, our algorithm makes full use of the known data based on the Gaussian mixture model to estimate missing values, the accuracy of our method was higher than those of the FCM method and the M-2 and M-4 algorithms, and it closely approximated the accuracy obtained using the complete-dataset clustering algorithm (M-1). Moreover, the model-based algorithms (M-1, M-2, M-3, and M-4) resulted in the highest BIC values in the three clusters, validating the effectiveness of using the BIC to determine the number of clusters.</p>
<table-wrap id="pone.0161112.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t004</object-id>
<label>Table 4</label> <caption><title>The comparison among four algorithms and FCM method for Fisher’s Iris dataset.</title></caption>
<alternatives>
<graphic id="pone.0161112.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Method</th>
<th align="center">n</th>
<th align="center">Misjudgment rate (MR)</th>
<th align="center">Iterative time</th>
<th align="center">BIC value in three clusters</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">M-1</td>
<td align="center">150</td>
<td align="center">3 (2.0%)</td>
<td align="center">37</td>
<td align="center">-307.848</td>
</tr>
<tr>
<td align="center">M-2</td>
<td align="center">135</td>
<td align="center">6 (4.4%)</td>
<td align="center">43</td>
<td align="center">-273.539</td>
</tr>
<tr>
<td align="center">M-3</td>
<td align="center">150</td>
<td align="center">3 (2.0%)</td>
<td align="center">36</td>
<td align="center">-305.211</td>
</tr>
<tr>
<td align="center">M-4</td>
<td align="center">150</td>
<td align="center">7 (4.7%)</td>
<td align="center">49</td>
<td align="center">-307.382</td>
</tr>
<tr>
<td align="center">FCM</td>
<td align="center">150</td>
<td align="center">5 (3.3%)</td>
<td align="center"/>
<td align="center"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001"><p>M-1 indicates the complete data clustering algorithm; M-2 indicates missing data deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm; M-4 indicates clustering algorithm for missing-value imputation by mean replacement; FCM indicates Fuzzy C-Means clustering.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec015">
<title>Yeast Cell-cycle dataset</title>
<p>The Yeast Cell-cycle dataset [<xref ref-type="bibr" rid="pone.0161112.ref028">28</xref>] shows the fluctuation in the expression levels of the whole genome (6220 genes) over 17 time points taken at 10-minute intervals, covering nearly two cell cycles. The entire raw dataset is available at <ext-link ext-link-type="uri" xlink:href="http://genome-www.stanford.edu/cellcycle/" xlink:type="simple">http://genome-www.stanford.edu/cellcycle/</ext-link>. Among the effectively expressed genes, 416 genes were found to have consistent periodic changes in expression level. Yeung et al. picked out 384 genes over 15 time points that reached their peaks at five (<italic>C</italic> = 5) cell phases on the basis of the size of the buds, after which five non-intersecting clusters were classified [<xref ref-type="bibr" rid="pone.0161112.ref029">29</xref>]. These 384 gene expressions, a subset with a moderate sample size, are available at <ext-link ext-link-type="uri" xlink:href="http://www.cs.washington.edu/homes/kayee/model" xlink:type="simple">http://www.cs.washington.edu/homes/kayee/model</ext-link>. All 384 genes were assigned to one of the five clusters by the original researchers [<xref ref-type="bibr" rid="pone.0161112.ref028">28</xref>,<xref ref-type="bibr" rid="pone.0161112.ref029">29</xref>]. Therefore, we can use this dataset to test the performance of the clustering algorithms introduced here and compare them with the performance of existing methods. We randomly removed one of the 15 variable values in 10% of the genes to create a dataset with missing values. <xref ref-type="table" rid="pone.0161112.t005">Table 5</xref> lists the clustering results from five clustering algorithms: the above four model-based clustering algorithms (M-1, M-2, M-3, and M-4) and the FCM clustering method. Further validating the results from Fisher’s Iris dataset, we found that our missing-value imputation algorithm had the lowest MR. In addition, because our missing-value imputation based on the Gaussian mixture distribution is compatible with the Yeast Cell-cycle dataset, the accuracy of our method was significantly higher than that of the FCM method, and it closely approximated the accuracy from using the complete-dataset clustering algorithm (M-1).</p>
<table-wrap id="pone.0161112.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t005</object-id>
<label>Table 5</label> <caption><title>The comparison among four algorithms and FCM method for Yeast Cell-cycle dataset.</title></caption>
<alternatives>
<graphic id="pone.0161112.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t005" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Method</th>
<th align="center">n</th>
<th align="center">Misjudgment rate (MR)</th>
<th align="center">Iterative time</th>
<th align="center">BIC value in five clusters</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">M-1</td>
<td align="center">384</td>
<td align="center">65 (16.9%)</td>
<td align="center">1265</td>
<td align="center">-6472.448</td>
</tr>
<tr>
<td align="center">M-2</td>
<td align="center">346</td>
<td align="center">62 (17.9%)</td>
<td align="center">1340</td>
<td align="center">-5892.953</td>
</tr>
<tr>
<td align="center">M-3</td>
<td align="center">384</td>
<td align="center">62 (16.1%)</td>
<td align="center">1260</td>
<td align="center">-6316.730</td>
</tr>
<tr>
<td align="center">M-4</td>
<td align="center">384</td>
<td align="center">78 (20.3%)</td>
<td align="center">1307</td>
<td align="center">-6490.706</td>
</tr>
<tr>
<td align="center">FCM</td>
<td align="center">384</td>
<td align="center">80 (20.8%)</td>
<td align="center"/>
<td align="center"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001"><p>M-1 indicates the complete data clustering algorithm; M-2 indicates missing data deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm; M-4 indicates the clustering algorithm for missing-value imputation by mean replacement; FCM indicates Fuzzy C-Means clustering.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec016">
<title>CIFAR-10 images dataset</title>
<p>The CIFAR-10 dataset [<xref ref-type="bibr" rid="pone.0161112.ref030">30</xref>] contains 60,000 32 × 32 color images (3072 variables) divided into ten classes, which represent different kinds of pictures. The classes are designed to be completely mutually exclusive. For example, neither automobile pictures nor truck pictures contain images of pickup trucks. Having a large sample size, each class contains 5000 training images and 1000 test images. The entire dataset was used to test the performance of test images according to training images in supervised classification, and it is available at <ext-link ext-link-type="uri" xlink:href="http://www.cs.toronto.edu/~kriz/cifar.html" xlink:type="simple">http://www.cs.toronto.edu/~kriz/cifar.html</ext-link>. We used the training images to test the performance of our unsupervised clustering algorithm and compared it to existing clustering algorithms. We randomly removed 10 of the 3072 variable values in 10% of the color images to create a dataset with missing values.</p>
<p><xref ref-type="table" rid="pone.0161112.t006">Table 6</xref> lists the clustering results from five clustering algorithms: the above four model-based clustering algorithms (M-1, M-2, M-3, and M-4) and the FCM clustering method. We found that our missing-value imputation algorithm had a lower total MR than algorithms M-2 and M-4. The accuracy of our method closely approximated the accuracy obtained using the clustering algorithm with complete data (M-1) but was lower than that of the FCM method. (It should be noted that most clusters of the CIFAR-10 data have deviants from the normal distribution.) Thus, the performance of our model-based algorithm does not offer clustering that is more accurate than the FCM method. Moreover, the speed of computations was much lower in algorithms M-1, M-2, M-3, and M-4.</p>
<table-wrap id="pone.0161112.t006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0161112.t006</object-id>
<label>Table 6</label> <caption><title>The comparison among four algorithms and FCM method for CIFAR-10 dataset.</title></caption>
<alternatives>
<graphic id="pone.0161112.t006g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0161112.t006" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" rowspan="2">Method</th>
<th align="center" colspan="11">MR</th>
</tr>
<tr>
<th align="center">total</th>
<th align="center">Cluster 1</th>
<th align="center">Cluster 2</th>
<th align="center">Cluster 3</th>
<th align="center">Cluster 4</th>
<th align="center">Cluster 5</th>
<th align="center">Cluster 6</th>
<th align="center">Cluster 7</th>
<th align="center">Cluster 8</th>
<th align="center">Cluster 9</th>
<th align="center">Cluster 10</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">M-1</td>
<td align="justify">39.9%</td>
<td align="center">38.2%</td>
<td align="center">41.4%</td>
<td align="center">35.6%</td>
<td align="center">43.5%</td>
<td align="center">40.5%</td>
<td align="center">37.9%</td>
<td align="center">38.5%</td>
<td align="center">42.1%</td>
<td align="center">35.4%</td>
<td align="center">45.6%</td>
</tr>
<tr>
<td align="center">M-2</td>
<td align="justify">42.4%</td>
<td align="center">42.6%</td>
<td align="center">40.8%</td>
<td align="center">35.2%</td>
<td align="center">45.8%</td>
<td align="center">42.0%</td>
<td align="center">46.3%</td>
<td align="center">40.4%</td>
<td align="center">46.7%</td>
<td align="center">38.4%</td>
<td align="center">45.4%</td>
</tr>
<tr>
<td align="center">M-3</td>
<td align="center">39.8%</td>
<td align="center">42.0%</td>
<td align="center">41.0%</td>
<td align="center">36.2%</td>
<td align="center">39.6%</td>
<td align="center">39.7%</td>
<td align="center">38.9%</td>
<td align="center">38.0%</td>
<td align="center">43.2%</td>
<td align="center">34.2%</td>
<td align="center">45.0%</td>
</tr>
<tr>
<td align="center">M-4</td>
<td align="justify">44.0%</td>
<td align="center">45.3%</td>
<td align="center">43.6%</td>
<td align="center">37.4%</td>
<td align="center">45.9%</td>
<td align="center">43.7%</td>
<td align="center">48.5%</td>
<td align="center">42.8%</td>
<td align="center">47.9%</td>
<td align="center">41.3%</td>
<td align="center">43.9%</td>
</tr>
<tr>
<td align="center">FCM</td>
<td align="justify">35.9%</td>
<td align="center">35.8%</td>
<td align="center">35.6%</td>
<td align="center">35.5%</td>
<td align="center">36.7%</td>
<td align="center">34.1%</td>
<td align="center">37.6%</td>
<td align="center">32.6%</td>
<td align="center">37.6%</td>
<td align="center">35.7%</td>
<td align="center">37.8%</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t006fn001"><p>M-1 indicates the complete data clustering algorithm; M-2 indicates missing data deleted clustering algorithm; M-3 indicates our missing-value imputation clustering algorithm; M-4 indicates clustering algorithm for missing-value imputation by mean replacement; FCM indicates Fuzzy C-Means clustering.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="sec017" sec-type="conclusions">
<title>Discussion</title>
<p>Missing values are unavoidable in experimental data and data from field investigations [<xref ref-type="bibr" rid="pone.0161112.ref031">31</xref>]. Many imputation methods [<xref ref-type="bibr" rid="pone.0161112.ref016">16</xref>–<xref ref-type="bibr" rid="pone.0161112.ref020">20</xref>] have been proposed, such as the mean-substitution method, the regression imputation method, the EM estimation method, and the FCM method. Clustering is a widely used statistical method, especially in gene expression profiles. Most classical clustering methods, such as K-means clustering and hierarchical clustering, are unable to deal with missing values. Therefore, we developed a model-based clustering algorithm for imputing missing values. The proposed method utilizes information from existing data, and it is based on the Gaussian mixture model. With our imputation algorithm, missing values are estimated by calculating the conditional expectation, from which a “pseudo-complete” dataset can be generated and used for clustering.</p>
<p>The performance of our proposed algorithm was tested and compared with other algorithms using both real and simulated data. We found that our proposed method outperformed other algorithms. In particular, our proposed method produced clustering results comparable to an algorithm that uses a complete dataset, and it outperformed an algorithm in which samples with missing data are removed and another algorithm in which missing values are imputed by mean replacement. The results are consistent with Hunt and Jorgensen’s reports [<xref ref-type="bibr" rid="pone.0161112.ref032">32</xref>]. Even with datasets in which the boundaries of the clusters overlap, such as datasets <italic>A</italic><sub>3</sub><italic>B</italic><sub>3</sub>, <italic>A</italic><sub>2</sub><italic>B</italic><sub>4</sub>, and <italic>A</italic><sub>3</sub><italic>B</italic><sub>4</sub>, our algorithm performed well.</p>
<p>Furthermore, we found that the proposed algorithm outperformed the FCM clustering method on Fisher’s Iris dataset and on the Yeast Cell-cycle dataset. The FCM clustering method, a heuristic approach, has been verified as a successful missing-value clustering method [<xref ref-type="bibr" rid="pone.0161112.ref033">33</xref>]. FCM clusters data based on the characteristics of the samples. The criteria for FCM clustering are inconsistent, however, because the characteristics of dynamic algorithms lead to uncertainties about the samples, degrading FCM’s ability to precisely cluster data [<xref ref-type="bibr" rid="pone.0161112.ref034">34</xref>–<xref ref-type="bibr" rid="pone.0161112.ref036">36</xref>]. Our study shows that the proposed method is more likely to result in a low MR when the dataset is exactly a multivariable Gaussian mixture distribution. That is, it is more accurate than other methods with both simulated data and real data, e.g., Fisher’s Iris dataset and the Yeast Cell-cycle dataset. One possible reason for this is that our method estimates missing values with a conditional expectation based on the Gaussian mixture distribution and generates a “pseudo-complete” dataset. In addition, our method combines dynamic clustering with discriminant analysis and uses the EM algorithm to achieve a maximum-likelihood function. It can thus better utilize the information from known data to discover the intrinsic and implicit properties of a dataset. Usually, model-based methods are better than heuristic approaches, even though the former are always more time consuming. Model-based methods depend on a probability model, which is usually proposed based on the experience and feasibility of the model. The convergence and accuracy of the EM algorithm have already been established [<xref ref-type="bibr" rid="pone.0161112.ref025">25</xref>]. The Gaussian mixture model is both convenient and robust. Moreover, a model-based method provides substantial information—e.g., the posterior probabilities of individuals and the parameters of each cluster—and this information can be exploited to more accurately impute missing values with iterative updates to the algorithm until convergence to a minimizer is reach.</p>
<p>Our method uses the Bayesian posterior probability to cluster individuals; individuals are assigned to the cluster having the highest posterior probability. It is more reasonable to assign individuals to a cluster having a high posterior probability, such as 0.8 or 0.9, and this improves the clustering accuracy. Whereas traditional dynamic clustering methods cluster individuals directly to a certain category, this process is difficult when the boundaries of the clusters overlap. Another advantage to a model-based approach is that statistical criteria, such as AIC and BIC [<xref ref-type="bibr" rid="pone.0161112.ref014">14</xref>], can be used to discover the number of clusters that best suit the data. We confirmed the effectiveness of such criteria with results indicating three clusters for Fisher’s Iris dataset (a dataset with exactly three species of <italic>Iris</italic>) and five clusters for the Yeast Cell-cycle Gene-expression dataset. However, the reversible-jump Markov-chain Monte Carlo (MCMC) method was previously developed to infer the number of distributions in a mixture [<xref ref-type="bibr" rid="pone.0161112.ref037">37</xref>]. MCMC estimates the optimal number of clusters from a Bayesian perspective. Our future research shall compare MCMC with the BIC criteria used in this study. Finally, a prerequisite for raw data collected by experimenters is that they be normalized. Indeed, our method is more sensitive to data that have not been normalized. Therefore, either a log or some other form of data transformation should be applied in order to distribute the data in a normal fashion. Furthermore, because our proposal relies on the information from known individuals when imputing missing values, a large sample size is desirable for more accuracy when estimating missing values.</p>
</sec>
<sec id="sec018" sec-type="conclusions">
<title>Conclusions</title>
<p>In this paper, we have presented a model-based missing-data imputation algorithm for clustering numerical data with missing values. We achieved a high convergence rate with our algorithm when it was tested on simulated and real datasets. In addition, the statistical power of our algorithm is high, and it can accurately estimate parameters and correctly cluster individuals with missing variables. Moreover, the results of our evaluation show a low MR, even when the mean vectors of two clusters are close to each other or when their variance-covariance is disperse. The algorithm was applied successfully to datasets (both simulated and real) having missing data. Its performance is superior to that of an algorithm in which samples with missing data were removed and another algorithm in which missing values were imputed by mean replacement. A comparative evaluation demonstrated that our proposed algorithm outperforms the FCM method when the data from each cluster fit a multivariate Gaussian distribution.</p>
</sec>
</body>
<back>
<ack>
<p>The authors wish to thank all those organizations who shared the open datasets, e.g. Fisher’s Iris dataset, the Yeast Cell-cycle dataset and the CIFAR-10 dataset.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0161112.ref001"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Wylie MP, Holtizman J. The non-line of sight problem in mobile location estimation. In: Proc IEEE ICUPC. Cambridge. 1996; 2: 827–31. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/ICUPC.1996.562692" xlink:type="simple">10.1109/ICUPC.1996.562692</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref002"><label>2</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>YT</given-names></name>, <name name-style="western"><surname>Fang</surname> <given-names>KT</given-names></name>. <source>Introduction to Multivariate Statistical Analysis</source>. <publisher-loc>Beijing</publisher-loc>: <publisher-name>Science Press</publisher-name>, <year>1983</year>; <fpage>401</fpage>–<lpage>57</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref003"><label>3</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Johnoson</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wichern</surname> <given-names>DW</given-names></name>. <source>Applied Multivariate Statistical Analysis</source>. <publisher-loc>New Jersey</publisher-loc>: <publisher-name>Prentice-Hall, Inc</publisher-name> <year>1992</year>; <fpage>532</fpage>–<lpage>560</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eisen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Spellman</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Botstein</surname> <given-names>D</given-names></name>. <article-title>Cluster analysis and display of genome-wide expression patterns</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1998</year>; <volume>95</volume>(<issue>25</issue>): <fpage>14863</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quackenbush</surname> <given-names>J</given-names></name>. <article-title>Computational analysis of microarray data</article-title>. <source>Nature Reviews Genetics</source>. <year>2001</year>; <volume>2</volume>(<issue>6</issue>): <fpage>418</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35076576" xlink:type="simple">10.1038/35076576</ext-link></comment> <object-id pub-id-type="pmid">11389458</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref006"><label>6</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Speed</surname> <given-names>T</given-names></name>. <source>Statistical Analysis of Gene Expression Microarray Data</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Chapman &amp; Hall/CRC Press</publisher-name> <year>2003</year>; <fpage>45</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref007"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">MacQueen J. Some methods for classification and analysis of multivariate observations. In: Proceedings of the 5th Berkeley Symposium. 1967; 1, 281–97.</mixed-citation></ref>
<ref id="pone.0161112.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartigan</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>MA</given-names></name>. <article-title>A K-means clustering algorithm</article-title>. <source>Journal of Applied Statistics</source>. <year>1979</year>; <volume>28</volume>(<issue>1</issue>): <fpage>100</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/2346830" xlink:type="simple">10.2307/2346830</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herrero</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Valencia</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dopazo</surname> <given-names>J</given-names></name>. <article-title>A hierarchical unsupervised growing neural network for clustering gene expression patterns</article-title>. <source>Bioinformatics</source>. <year>2001</year>; <volume>17</volume>(<issue>2</issue>): <fpage>126</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/17.2.126" xlink:type="simple">10.1093/bioinformatics/17.2.126</ext-link></comment> <object-id pub-id-type="pmid">11238068</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Selim</surname> <given-names>SZ</given-names></name>, <name name-style="western"><surname>Alsultan</surname> <given-names>K</given-names></name>. <article-title>A simulated annealing algorithm for the clustering problem</article-title>. <source>Pattern Recognition</source>. <year>1991</year>; <volume>24</volume>(<issue>91</issue>): <fpage>1003</fpage>–<lpage>8</lpage>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0031-3203(91)90097-O" xlink:type="simple">10.1016/0031-3203(91)90097-O</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dasgupta</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Raftery</surname> <given-names>AE</given-names></name>. <article-title>Detecting features in spatial point processes with clutter via model-based clustering</article-title>. <source>Journal of the American Statistical Association</source>. <year>1998</year>; <volume>93</volume>: <fpage>294</fpage>–<lpage>302</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/01621459.1998.10474110" xlink:type="simple">10.1080/01621459.1998.10474110</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref012"><label>12</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>McLachlan</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Basford</surname> <given-names>KE</given-names></name>. <source>Mixture Models: Inference and Applications to Clustering</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Marcel Dekker</publisher-name>, <year>1988</year>.</mixed-citation></ref>
<ref id="pone.0161112.ref013"><label>13</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Titterington</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>AFM</given-names></name>, <name name-style="western"><surname>Makov</surname> <given-names>UE</given-names></name>. <source>Statistical Analysis of Finite Mixture Distributions</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley &amp; Sons, Inc</publisher-name>, <year>1985</year>.</mixed-citation></ref>
<ref id="pone.0161112.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwarz</surname> <given-names>G</given-names></name>. <article-title>Estimating the dimension of a model</article-title>. <source>Annals of Statistics</source>. <year>1978</year>; <volume>6</volume>(<issue>2</issue>): <fpage>461</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/aos/1176344136" xlink:type="simple">10.1214/aos/1176344136</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krzysztof</surname> <given-names>S</given-names></name>. <article-title>Clustering with missing values</article-title>. <source>Fundamenta informaticae</source>. <year>2013</year>; <volume>123</volume>(<issue>3</issue>): <fpage>331</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3233/FI-2013-814" xlink:type="simple">10.3233/FI-2013-814</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Inference and missing data</article-title>. <source>Biometrika</source>. <year>1976</year>; <volume>63</volume>(<issue>1</issue>): <fpage>581</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/63.3.581" xlink:type="simple">10.1093/biomet/63.3.581</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Multiple imputations in sample surveys-a phenomenological Bayesian approach to nonresponse</article-title>. <source>Journal of the American Statistical Association</source>. <year>1978</year>; (1): <fpage>20</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1631/jzus.C10b0359" xlink:type="simple">10.1631/jzus.C10b0359</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref018"><label>18</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Carpenter</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kenward</surname> <given-names>M</given-names></name>. <source>Multiple Imputation and its Application</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley &amp; Sons</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="pone.0161112.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shao</surname> <given-names>J</given-names></name>. <article-title>Nearest neighbor imputation for survey data</article-title>. <source>Journal of Official Statistics</source>. <year>2000</year>; <volume>16</volume>(<issue>2</issue>): <fpage>113</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ding</surname> <given-names>WX</given-names></name>. <article-title>Missing data in survey sampling interpolation method</article-title>. <source>Applica Stat Manage (Chin)</source>. <year>2008</year>; <volume>27</volume>: <fpage>821</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hathaway</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Bezdek</surname> <given-names>JC</given-names></name>. <article-title>Fuzzy c-Means Clustering of incomplete data</article-title>. <object-id pub-id-type="pmid">IEEE transactions on systems, men, and cybernetics-part B: cybernetics</object-id>. <year>2001</year>; <volume>31</volume>(<issue>5</issue>): <fpage>735</fpage>–<lpage>744</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/3477.956035" xlink:type="simple">10.1109/3477.956035</ext-link></comment> <object-id pub-id-type="pmid">18244838</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghahramani</surname> <given-names>ZB</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Supervised learning from incomplete data via an EM approach</article-title>. <source>Advances in Neural Information Processing Systems</source>, <year>1994</year>, <volume>6</volume>: <fpage>120</fpage>–<lpage>127</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Qu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>SZ</given-names></name>. <article-title>Supervised cluster analysis for microarray data based on multivariate Gaussian mixture</article-title>. <source>Bioinformatics</source>. <year>2004</year>; <volume>20</volume>: <fpage>1905</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/bth177" xlink:type="simple">10.1093/bioinformatics/bth177</ext-link></comment> <object-id pub-id-type="pmid">15044244</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Si</surname> <given-names>YQ</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Brutnell</surname> <given-names>TP</given-names></name>. <article-title>Model-based clustering for RNA-seq data</article-title>. <source>Bioinformatics</source> <year>2014</year>; <volume>30</volume>(<issue>2</issue>): <fpage>197</fpage>–<lpage>205</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btt632" xlink:type="simple">10.1093/bioinformatics/btt632</ext-link></comment> <object-id pub-id-type="pmid">24191069</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayes</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pyon</surname> <given-names>YS</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>. <article-title>A model-based clustering method for genomic structural variant prediction and genotyping using paired-end sequencing data</article-title>. <source>PLoS ONE</source>. <year>2012</year>; <volume>7</volume>(<issue>12</issue>): <fpage>e52881</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0052881" xlink:type="simple">10.1371/journal.pone.0052881</ext-link></comment> <object-id pub-id-type="pmid">23300804</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>XL</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>HY</given-names></name>. <article-title>Hybrid data clustering based on dependency structure and gibbs sampling</article-title>. <source>Lecture Notes in Computer Science</source> <year>2006</year>; <volume>4304</volume>: <fpage>1145</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/11941439_138" xlink:type="simple">10.1007/11941439_138</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dempster</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title>. <source>Journal of the Royal Statistical Society Series B-statistical Methodology</source>. <year>1977</year>; <volume>39</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation></ref>
<ref id="pone.0161112.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cho</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Campbell</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Winzeler</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Steinmetz</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Conway</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wodicka</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>A genome-wide transcriptional analysis of the mitotic cell cycle</article-title>. <source>Mol. Cell</source>. <year>1998</year>; <volume>2</volume>(<issue>1</issue>): <fpage>65</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1097-2765(00)80114-8" xlink:type="simple">10.1016/S1097-2765(00)80114-8</ext-link></comment> <object-id pub-id-type="pmid">9702192</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yeung</surname> <given-names>KY</given-names></name>, <name name-style="western"><surname>Fraley</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Murua</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Raftery</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Ruzzo</surname> <given-names>WL</given-names></name>. <article-title>Model-based clustering and data transformations for gene expression data</article-title>. <source>Bioinformatics</source>. <year>2001</year>; <volume>17</volume>: <fpage>977</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/17.10.977" xlink:type="simple">10.1093/bioinformatics/17.10.977</ext-link></comment> <object-id pub-id-type="pmid">11673243</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref030"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky A. Learning multiple layers of features from Tiny Images. Master’s thesis, Dept. of Comp. Sci., University of Toronto, 2009.</mixed-citation></ref>
<ref id="pone.0161112.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Troyanskaya</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Cantor</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sherlock</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Missing value estimation methods for DNA microarrays</article-title>. <source>Bioinformatics</source>. <year>2001</year>; <volume>17</volume>: <fpage>520</fpage>–<lpage>25</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/17.6.520" xlink:type="simple">10.1093/bioinformatics/17.6.520</ext-link></comment> <object-id pub-id-type="pmid">11395428</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hunt</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Jorgensen</surname> <given-names>M</given-names></name>. <article-title>Mixture model clustering for mixed data with missing information</article-title>. <source>Computational Statistics &amp; Data Analysis</source>. <year>2003</year>; <volume>41</volume>(<issue>s3-4</issue>): <fpage>429</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-9473(02)00190-1" xlink:type="simple">10.1016/S0167-9473(02)00190-1</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiao</surname> <given-names>YB</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>HB</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XQ</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>HB</given-names></name>. <article-title>Unsupervised performance evaluation strategy for bridge superstructure based on Fuzzy clustering and field data</article-title>. <source>The Scientific World Journal</source>. <year>2013</year>; <volume>2013</volume>(<issue>2</issue>): <fpage>544</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1155/2013/427072" xlink:type="simple">10.1155/2013/427072</ext-link></comment> <object-id pub-id-type="pmid">24288483</object-id></mixed-citation></ref>
<ref id="pone.0161112.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sebzalli</surname> <given-names>YM</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XZ</given-names></name>. <article-title>Knowledge discovery from process operational data using PCA and fuzzy clustering</article-title>. <source>Engineering Applications of Artificial Intelligence</source>. <year>2001</year>; <volume>14</volume>(<issue>5</issue>): <fpage>607</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0952-1976(01)00032-X" xlink:type="simple">10.1016/S0952-1976(01)00032-X</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Podofillini</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Zio</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Mercurio</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dang</surname> <given-names>VN</given-names></name>. <article-title>Dynamic safety assessment: scenario identification via a possibilistic clustering approach</article-title>. <source>Reliability Engineering &amp; System Safety</source>. <year>2010</year>; <volume>95</volume>(<issue>5</issue>): <fpage>534</fpage>–<lpage>49</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.ress.2010.01.004" xlink:type="simple">10.1016/j.ress.2010.01.004</ext-link></comment></mixed-citation></ref>
<ref id="pone.0161112.ref036"><label>36</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>SY</given-names></name>. <source>Engineering Fuzzy Mathematics with Application</source>, <publisher-loc>Harbin</publisher-loc>: <publisher-name>Harbin Institute of Technology Press; China</publisher-name>; <year>2004</year>.</mixed-citation></ref>
<ref id="pone.0161112.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Green</surname> <given-names>PJ</given-names></name>. <article-title>Reversible jump Markov chain Monte Carlo computation and Bayesian model determination</article-title>. <source>Biometrika</source>. <year>1995</year>; <volume>363</volume>(<issue>4</issue>): <fpage>711</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/82.4.711" xlink:type="simple">10.1093/biomet/82.4.711</ext-link></comment></mixed-citation></ref>
</ref-list>
</back>
</article>