<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">10-PONE-RA-19016</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0011631</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computer Science/Applications</subject><subject>Evolutionary Biology/Animal Behavior</subject><subject>Neuroscience/Behavioral Neuroscience</subject></subj-group></article-categories><title-group><article-title>Multi-Environment Model Estimation for Motility Analysis of <italic>Caenorhabditis elegans</italic></article-title><alt-title alt-title-type="running-head">Image Analysis of <italic>C. elegans</italic></alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sznitman</surname><given-names>Raphael</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gupta</surname><given-names>Manaswi</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Hager</surname><given-names>Gregory D.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Arratia</surname><given-names>Paulo E.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sznitman</surname><given-names>Josué</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Computer Science, Johns Hopkins University, Baltimore, Maryland, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, New Jersey, United States of America</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Brezina</surname><given-names>Vladimir</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Mount Sinai School of Medicine, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">sznitman@princeton.edu</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: RS JS. Performed the experiments: RS MG. Analyzed the data: RS MG JS. Contributed reagents/materials/analysis tools: GH PA JS. Wrote the paper: RS JS.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2010</year></pub-date><pub-date pub-type="epub"><day>22</day><month>7</month><year>2010</year></pub-date><volume>5</volume><issue>7</issue><elocation-id>e11631</elocation-id><history>
<date date-type="received"><day>18</day><month>5</month><year>2010</year></date>
<date date-type="accepted"><day>23</day><month>6</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Sznitman et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>The nematode <italic>Caenorhabditis elegans</italic> is a well-known model organism used to investigate fundamental questions in biology. Motility assays of this small roundworm are designed to study the relationships between genes and behavior. Commonly, motility analysis is used to classify nematode movements and characterize them quantitatively. Over the past years, <italic>C. elegans</italic>' motility has been studied across a wide range of environments, including crawling on substrates, swimming in fluids, and locomoting through microfluidic substrates. However, each environment often requires customized image processing tools relying on heuristic parameter tuning. In the present study, we propose a novel Multi-Environment Model Estimation (MEME) framework for automated image segmentation that is versatile across various environments. The MEME platform is constructed around the concept of Mixture of Gaussian (MOG) models, where statistical models for both the background environment and the nematode appearance are explicitly learned and used to accurately segment a target nematode. Our method is designed to simplify the burden often imposed on users; here, only a <italic>single</italic> image which includes a nematode in its environment must be provided for model learning. In addition, our platform enables the extraction of nematode ‘skeletons’ for straightforward motility quantification. We test our algorithm on various locomotive environments and compare performances with an intensity-based thresholding method. Overall, MEME outperforms the threshold-based approach for the overwhelming majority of cases examined. Ultimately, MEME provides researchers with an attractive platform for <italic>C. elegans</italic>' segmentation and ‘skeletonizing’ across a wide range of motility assays.</p>
</abstract><funding-group><funding-statement>The authors have no support or funding to report.</funding-statement></funding-group><counts><page-count count="11"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Since its introduction in the laboratory over thirty years ago <xref ref-type="bibr" rid="pone.0011631-Brenner1">[1]</xref>, the nematode <italic>Caenorhabditis elegans</italic> has become a ubiquitous model organism to study fundamental questions in biology <xref ref-type="bibr" rid="pone.0011631-Rankin1">[2]</xref>. In particular, <italic>C. elegans</italic> is now widely used as a platform for drug screening and development <xref ref-type="bibr" rid="pone.0011631-Link1">[3]</xref>, <xref ref-type="bibr" rid="pone.0011631-Jorgensen1">[4]</xref>, as well as for modeling various aspects of human diseases <xref ref-type="bibr" rid="pone.0011631-Chamberlain1">[5]</xref>, <xref ref-type="bibr" rid="pone.0011631-Silverman1">[6]</xref>. In the quest to understand the relationships between genes and behavior, this small, approximately 1 mm long roundworm offers a number of advantages for laboratory applications. These include a short life cycle, the availability of many mutants to explore gene functions, knowledge of its complete cell lineage <xref ref-type="bibr" rid="pone.0011631-Sulston1">[7]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sulston2">[8]</xref>, simplicity of the nervous system and its wiring <xref ref-type="bibr" rid="pone.0011631-White1">[9]</xref>, and a fully sequenced genome <xref ref-type="bibr" rid="pone.0011631-CES1">[10]</xref>.</p>
<p>A widespread strategy to investigate the genetic basis of behavior is to classify nematode movements and characterize them quantitatively. Traditionally, motility quantification has been based on crawling assays <xref ref-type="bibr" rid="pone.0011631-Karbowski1">[11]</xref>–<xref ref-type="bibr" rid="pone.0011631-Tavernarakis1">[14]</xref>, where <italic>C. elegans</italic> is observed to crawl on a substrate (<italic>e.g.</italic> agar plate). This is shown for example in <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1(a)</xref>. In the recent past, however, the number of environments used for nematode motility assays has vastly expanded. Studies of <italic>C. elegans</italic>' motility behavior now include various swimming assays <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>, <xref ref-type="bibr" rid="pone.0011631-Berri1">[15]</xref>–<xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref>, as shown in <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1(b)–(d) and (g)</xref>. In parallel, with the widespread availability of microfabrication techniques, nematode motility assays are increasingly conducted in microfluidic environments <xref ref-type="bibr" rid="pone.0011631-Chronis1">[20]</xref>–<xref ref-type="bibr" rid="pone.0011631-Qin1">[23]</xref>. An example of such environments is shown in <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1(e) and (f)</xref>. This latter platform has become particularly attractive for high-throughput drug screening applications <xref ref-type="bibr" rid="pone.0011631-Rhode1">[24]</xref>, <xref ref-type="bibr" rid="pone.0011631-Shi1">[25]</xref>. Overall, with the growing variations in environments used for nematode behavioral assays, users are in need of reliable image analysis tools capable of extracting quantitative data across a wide spectrum of experimental mediums.</p>
<fig id="pone-0011631-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g001</object-id><label>Figure 1</label><caption>
<title>Examples of environments used in <italic>C. elegans</italic>' motility assays.</title>
<p>(<bold>a</bold>) Nematode crawling on an agar plate (<xref ref-type="supplementary-material" rid="pone.0011631.s003">Video S2</xref>). (<bold>b</bold>) Nematode swimming in a 5 ml drop of M9 buffer solution (<xref ref-type="supplementary-material" rid="pone.0011631.s005">Video S4</xref>). (<bold>c</bold>) Nematode swimming in a solution of gelatin dissolved in M9 (source: berrigel0.0perc.mov, Supplementary Material in Berri <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Berri1">[15]</xref>). (<bold>d</bold>) Nematode swimming inside a fluid-filled chamber (source: SM2.avi, Supplementary Material in Pierce-Shimomura <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>). (<bold>e</bold>)–(<bold>f</bold>) Nematode locomotion in a microfluidic substrate (source: Supplemental Videos 2 and 4 in Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>). (<bold>g</bold>) Nematode swimming in a shallow acrylic channel filled with M9 (<xref ref-type="supplementary-material" rid="pone.0011631.s006">Video S5</xref>). Nematodes shown in (a) through (g) are wild-type (N2) <italic>C. elegans</italic> and are all approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e001" xlink:type="simple"/></inline-formula> mm long.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g001" xlink:type="simple"/></fig>
<p>The analysis of motility behavior has traditionally relied on qualitative observations to describe <italic>C. elegans</italic>' locomotion and discriminate between wild-type and mutant nematodes. In many instances, however, qualitative variations between strains are not apparent to the trained eye (as in <xref ref-type="bibr" rid="pone.0011631-Bessou1">[26]</xref>). Such limitations have sprouted the development of automated image analysis systems in an effort to deliver relevant phenotypic differences between nematode strains <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>–<xref ref-type="bibr" rid="pone.0011631-Tsibidis1">[36]</xref>. While the bulk of the research effort has been directed at analyzing locomotive traits of individual nematodes, some multi-worm tracking and feature extraction systems have also been developed <xref ref-type="bibr" rid="pone.0011631-Ramot1">[37]</xref>–<xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>. Yet, the majority of state-of-the-art image analysis systems are designed for a <italic>specific</italic> environment, most commonly crawling <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Cronin1">[30]</xref>–<xref ref-type="bibr" rid="pone.0011631-Huang2">[34]</xref>, <xref ref-type="bibr" rid="pone.0011631-Ramot1">[37]</xref> or swimming assays <xref ref-type="bibr" rid="pone.0011631-Buckingham2">[29]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>. These systems induce a tradeoff between either limiting the range of possible assays a researcher will investigate for motility analysis or customizing segmentation parameter selection across varying environments. However, an optimal system for the user is one which ideally bypasses such compromise.</p>
<p>Current image analysis systems provide users with morphological and locomotion features to quantify behavioral phenotypes of <italic>C. elegans</italic>. Such features include amongst other nematode speed <xref ref-type="bibr" rid="pone.0011631-Tsibidis1">[36]</xref>, <xref ref-type="bibr" rid="pone.0011631-Ramot1">[37]</xref>, wavelength and frequency of body undulations <xref ref-type="bibr" rid="pone.0011631-Buckingham2">[29]</xref>, <xref ref-type="bibr" rid="pone.0011631-Cronin1">[30]</xref>, body curvature <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Feng1">[31]</xref>, and omega bends <xref ref-type="bibr" rid="pone.0011631-Huang1">[33]</xref>; several of which make use of nematode centerline data, also known as ‘skeletons’. In practice, features are extracted from binary images, or <italic>segmentations</italic>, separating the nematode from its environment, or <italic>background</italic>. Several analysis systems compute binary images by applying a simple intensity-based threshold at each pixel location <xref ref-type="bibr" rid="pone.0011631-Cronin1">[30]</xref>, <xref ref-type="bibr" rid="pone.0011631-Feng1">[31]</xref>, <xref ref-type="bibr" rid="pone.0011631-Hoshi1">[35]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsibidis1">[36]</xref>, <xref ref-type="bibr" rid="pone.0011631-Geng2">[40]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang3">[41]</xref>. Most commonly, this involves having the user manually select an appropriate range of intensities which characterizes the nematode. A variation to this approach has been the use of an adaptive threshold where nematode intensities, or <italic>appearance</italic>, are assumed to significantly differ from the average background intensities <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang2">[34]</xref>. While these methods have shown promising capabilities, the range of environments for which they can be used for is in fact limited. This limitation is illustrated in <xref ref-type="fig" rid="pone-0011631-g002">Fig. 2</xref> where the pixel intensity distributions of the nematode and background are respectively plotted for the environments shown in <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1</xref>. Here, distributions are assumed to be Gaussian and parametrized with the mean and standard deviation of pixel intensities. In none of the cases shown can a single threshold separate any pair of distributions without causing significant errors (<xref ref-type="fig" rid="pone-0011631-g002">Fig. 2</xref>). While threshold-based techniques can still be used to compute accurate segmentations, this requires significant effort on the user-end to adjust appropriate threshold values along with other noise canceling schemes (<italic>e.g.</italic> median filters, morphological operators, background subtraction, etc.). Altogether, this tedious process makes thresholding ill-suited for applications in complex background environments.</p>
<fig id="pone-0011631-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g002</object-id><label>Figure 2</label><caption>
<title>Pixel intensity distributions of nematode and background environment.</title>
<p>Plots (<bold>a</bold>) through (<bold>g</bold>) correspond to distributions obtained from the images of <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1</xref>. Grayscale pixel intensities vary between 0 (black) and 255 (white). Distributions are assumed to be Gaussian and parametrized with the mean and standard deviation of pixel intensities.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g002" xlink:type="simple"/></fig>
<p>More recently, alternative approaches to thresholding techniques have been pursued. For example, the work of Stauffer and Grimson <xref ref-type="bibr" rid="pone.0011631-Stauffer1">[42]</xref> has been applied to the problem of nematode segmentation <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>. Here, the idea is to systematically learn how background pixels are individually distributed and use this information to segment the nematode. The learning process is done using a set of <italic>training</italic> images to statistically model the appearance of the background. Namely, each pixel is modeled by means of a Mixture of Gaussians (MOG), where the parameters of the model are learned from the training image set. This approach has been recently shown to provide excellent results for nematode segmentation <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref> as well as for other applications <xref ref-type="bibr" rid="pone.0011631-Stauffer1">[42]</xref>–<xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref>. A major drawback, however, of modeling pixels with MOGs is that many parameters must be learned; this requires a large set of nematode-free training images. This condition largely prohibits extracting nematode segmentations from arbitrary sequences (<italic>e.g.</italic> open-access material).</p>
<p>In the present study, we propose a novel framework for image analysis of <italic>C. elegans</italic> that is versatile across a wide range of environments. Moreover, our system is designed to greatly simplify the burden imposed on the user end; only a <italic>single</italic> image from a sequence which includes a nematode in its environment must be provided. From this input, models for <italic>both</italic> the background and the nematode appearance are individually learned using MOGs (see <xref ref-type="sec" rid="s2">Methods</xref>). These models are then applied to segment the nematode in subsequent images. Next, we provide an original algorithm for extracting nematode skeletons for applications to <italic>C. elegans</italic>' behavioral assays. Nematode segmentation and skeletonizing algorithms have been packaged together in a software for straightforward use by a broad range of researchers. We test our image analysis system on representative locomotive environments (<xref ref-type="fig" rid="pone-0011631-g001">Fig. 1</xref>) and compare performances with a state-of-the-art thresholding method (see <xref ref-type="sec" rid="s3">Results</xref>). Finally, we illustrate some examples of motility metrics (<italic>e.g.</italic> body curvature) which are commonly sought from nematode skeleton data (see <xref ref-type="sec" rid="s4">Discussion</xref>). We discuss future directions for algorithmic improvement (<italic>e.g.</italic> multi-worm tracking) as well as new directions for potential applications (<italic>e.g.</italic> cell tracking).</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<p>The <italic>Multi-Environment Model Estimation</italic> (MEME) framework consists of two sequential stages. As a first step, (i) the user provides information, allowing a model for the nematode and the background environment to be learned. In the second stage, (ii) the nematode and background models are used to segment the nematode and then extract its skeleton for a sequence of images. In stage (i), the user is required to input a hand-segmentation of the nematode and its corresponding width for a <italic>single</italic> image (see <xref ref-type="supplementary-material" rid="pone.0011631.s002">Video S1</xref>). This approach can be viewed as a form of “One Shot Learning” <xref ref-type="bibr" rid="pone.0011631-Fleuret1">[45]</xref>, <xref ref-type="bibr" rid="pone.0011631-FeiFei1">[46]</xref>, where model learning occurs only once, from a single labeled example. A flowchart of the MEME framework is schematically shown in <xref ref-type="fig" rid="pone-0011631-g003">Fig. 3</xref>.</p>
<fig id="pone-0011631-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g003</object-id><label>Figure 3</label><caption>
<title>Multi-Environment Model Estimation (MEME) framework overview.</title>
<p>The system consists of two components: (1) a user input and learning stage and (2) an image analysis stage. In stage (1), the user provides an image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e002" xlink:type="simple"/></inline-formula>) and marks the nematode boundary (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e003" xlink:type="simple"/></inline-formula>) and width (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e004" xlink:type="simple"/></inline-formula>). From this input, appearance models for the nematode (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e005" xlink:type="simple"/></inline-formula>) and background (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e006" xlink:type="simple"/></inline-formula>) are learned. In (2), for each image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e007" xlink:type="simple"/></inline-formula>) in a sequence, nematodes are then segmented (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e008" xlink:type="simple"/></inline-formula>) by using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e009" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e010" xlink:type="simple"/></inline-formula>. Nematode skeletons (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e011" xlink:type="simple"/></inline-formula>) are then extracted from these segmentations.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g003" xlink:type="simple"/></fig>
<p>We briefly introduce the notation used throughout the article. We define the sequence of images provided by the user as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e012" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e013" xlink:type="simple"/></inline-formula> discrete time steps, where at each time step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e014" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e015" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e016" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e017" xlink:type="simple"/></inline-formula> are the width and height of each image, respectively. We denote the user provided data (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e018" xlink:type="simple"/></inline-formula>) as a triple <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e019" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e020" xlink:type="simple"/></inline-formula> is an image from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e021" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e022" xlink:type="simple"/></inline-formula> is the nematode body segmentation and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e023" xlink:type="simple"/></inline-formula> is the nematode width (<xref ref-type="fig" rid="pone-0011631-g003">Fig. 3</xref>). We specify the intensity models derived from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e024" xlink:type="simple"/></inline-formula> as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e025" xlink:type="simple"/></inline-formula> for the worm and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e026" xlink:type="simple"/></inline-formula> for the background. For any given image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e027" xlink:type="simple"/></inline-formula> included in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e028" xlink:type="simple"/></inline-formula>, we define the computed segmentation of the nematode as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e029" xlink:type="simple"/></inline-formula> and the list of ordered pixel coordinates describing the nematode skeleton as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e030" xlink:type="simple"/></inline-formula>.</p>
<sec id="s2a">
<title>Nematode Segmentation</title>
<p>Our first step is to provide an automatic mechanism to compute accurate nematode segmentations for a single target using a static camera (as in <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>). To do this, we build on the idea of using Mixtures of Gaussians (MOG) <xref ref-type="bibr" rid="pone.0011631-Stauffer1">[42]</xref>–<xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref> to construct accurate and robust appearance models for the background and the nematode. As it is often the case for MOG methods, each pixel in an image is treated as a random variable which can be modeled by summing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e031" xlink:type="simple"/></inline-formula> weighted Gaussian distributions. This can be formally written as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e032" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e033" xlink:type="simple"/></inline-formula> is a pixel intensity value, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e034" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e035" xlink:type="simple"/></inline-formula> are respectively the weight, mean and covariance of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e036" xlink:type="simple"/></inline-formula>th Gaussian distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e037" xlink:type="simple"/></inline-formula>. These parameters are usually estimated by means of an Expectation-Maximization (EM) algorithm <xref ref-type="bibr" rid="pone.0011631-Laird1">[47]</xref>. The intuition behind this model is that each individual Gaussian represents the appearance a particular pixel may take. Therefore, combining each Gaussian provides a way to model complex pixel observations. Typically, doing this over all pixels in an image is an effective way to model background scenes <xref ref-type="bibr" rid="pone.0011631-Stauffer1">[42]</xref>–<xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref>.</p>
<p>A consequence of this approach is that the number of MOGs used is considerable (<italic>i.e.</italic> the total number <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e038" xlink:type="simple"/></inline-formula> of pixels in an image) and the number of parameters required is very large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e039" xlink:type="simple"/></inline-formula>. In turn, a substantial number of images is needed to estimate the MOG parameters accurately as each image only provides a single sample for each MOG (see <xref ref-type="bibr" rid="pone.0011631-Stauffer1">[42]</xref> for more details). Moreover, the entire background scene must be visible when attempting to estimate these parameters, since each image is used to model the background and not the nematode. This latter condition becomes problematic when image sequences always contain a nematode in the field of view (<italic>e.g.</italic> Supplementary Videos available in references <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>, <xref ref-type="bibr" rid="pone.0011631-Berri1">[15]</xref>, <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>).</p>
<p>To avoid such drawbacks, we choose instead to model the nematode appearance (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e040" xlink:type="simple"/></inline-formula>) in addition to the background model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e041" xlink:type="simple"/></inline-formula>) by means of MOGs. To learn the parameters of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e042" xlink:type="simple"/></inline-formula>, we use the information gathered from the user. Namely, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e043" xlink:type="simple"/></inline-formula> provides the pixel region of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e044" xlink:type="simple"/></inline-formula> containing the nematode as delineated by the user (<xref ref-type="fig" rid="pone-0011631-g004">Fig. 4a</xref>). From this region, we randomly select pixel locations and extract <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e045" xlink:type="simple"/></inline-formula> image patches from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e046" xlink:type="simple"/></inline-formula> around each location. These patches are then vectorized and treated as independent samples. We denote this feature extract process as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e047" xlink:type="simple"/></inline-formula>, where we select a patch around pixels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e048" xlink:type="simple"/></inline-formula> for any given image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e049" xlink:type="simple"/></inline-formula>. Notice that when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e050" xlink:type="simple"/></inline-formula>, this reduces to sampling the selected pixels only; <xref ref-type="fig" rid="pone-0011631-g004">Fig. 4(b)</xref> shows the histogram of intensities for the case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e051" xlink:type="simple"/></inline-formula>. In general, applying this transformation allows for modeling intensities with respect to image patches, as this approach carries more information than individual and independent pixels. Computing an appropriate value for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e052" xlink:type="simple"/></inline-formula> is done by using a linear model (<italic>i.e.</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e053" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e054" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e055" xlink:type="simple"/></inline-formula> are constants). The samples extracted are then used to estimate the parameters of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e056" xlink:type="simple"/></inline-formula> by using the EM algorithm. <xref ref-type="fig" rid="pone-0011631-g004">Figure 4(d)</xref> illustrates a visual representation of the estimated MOGs of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e057" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e058" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e059" xlink:type="simple"/></inline-formula>.</p>
<fig id="pone-0011631-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g004</object-id><label>Figure 4</label><caption>
<title>User input and nematode segmentation.</title>
<p>Figures (<bold>a</bold>) through (<bold>d</bold>) illustrate the stages of the segmentation process in MEME for a sample environment (source: Supplemental Video in Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>). (<bold>a</bold>) The user selects the boundary of the nematode on a given image. From this manual segmentation, the distribution of nematode features can be extracted. (<bold>b</bold>) Distribution of pixel intensities from the nematode region. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e060" xlink:type="simple"/></inline-formula> for illustrative purposes. (<bold>c</bold>) The background scene is partitioned into a grid, where each cell corresponds to a particular pixel block. Two arbitrary cells are labeled for clarity; their corresponding intensity distributions are shown in (<bold>b</bold>). For both the nematode and the cells, MOG parameters are then learned. (<bold>d</bold>) Representation of the MOG models for the nematode (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e061" xlink:type="simple"/></inline-formula>) and the two background cells (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e062" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e063" xlink:type="simple"/></inline-formula>).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g004" xlink:type="simple"/></fig>
<p>Next, modeling of the background (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e064" xlink:type="simple"/></inline-formula>) is done by partitioning the image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e065" xlink:type="simple"/></inline-formula>) into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e066" xlink:type="simple"/></inline-formula> distinct and non-overlapping cells, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e067" xlink:type="simple"/></inline-formula>, as shown in <xref ref-type="fig" rid="pone-0011631-g004">Fig. 4(c)</xref>. Each cell (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e068" xlink:type="simple"/></inline-formula>) is then treated as a random variable and modeled with its own independent MOG. Hence, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e069" xlink:type="simple"/></inline-formula>, where each pixel in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e070" xlink:type="simple"/></inline-formula> is associated with a unique <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e071" xlink:type="simple"/></inline-formula>; in our implementation, we choose <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e072" xlink:type="simple"/></inline-formula>. The parameters of each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e073" xlink:type="simple"/></inline-formula> are computed from extracted samples in the partition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e074" xlink:type="simple"/></inline-formula>. Similarly to building the nematode model, samples are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e075" xlink:type="simple"/></inline-formula> pixel patches from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e076" xlink:type="simple"/></inline-formula>, which have been vectorized. Examples of intensity distributions for two arbitrary cells (<xref ref-type="fig" rid="pone-0011631-g004">Fig. 4c</xref>) are displayed in <xref ref-type="fig" rid="pone-0011631-g004">Fig. 4(b)</xref> along with their corresponding MOG representations in <xref ref-type="fig" rid="pone-0011631-g004">Fig. 4(d)</xref>. Two consequences arise from such partitioning. First, only a total of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e077" xlink:type="simple"/></inline-formula> parameters need to be estimated, as opposed to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e078" xlink:type="simple"/></inline-formula>. Secondly, a single image is sufficient to estimate these parameters, as background regions covered by the nematode can still be modeled by neighboring pixels in a cell. This reduces the number of training images required and relaxes the constraint that training images must only contain background pixels. Note that when a cell is reduced to a single pixel (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e079" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e080" xlink:type="simple"/></inline-formula> is similar to the model described in <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>. Alternatively, when a cell corresponds to the entire image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e081" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e082" xlink:type="simple"/></inline-formula> is similar to models typically used by thresholding techniques <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang2">[34]</xref>.</p>
<p>Nematode segmentation for image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e083" xlink:type="simple"/></inline-formula> can then be computed at each pixel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e084" xlink:type="simple"/></inline-formula>, belonging to cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e085" xlink:type="simple"/></inline-formula>, as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e086" xlink:type="simple"/><label>(2)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e087" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>The procedure above allows one to compute the nematode segmentation for a given image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e088" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e089" xlink:type="simple"/></inline-formula> in our system. Notice that using the ratio of MOGs (see Eq. (3)) is an effective way to avoid any form of thresholding. This is due to the fact that both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e090" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e091" xlink:type="simple"/></inline-formula> are explicitly modeled. Finally, opening and closing morphological operations are used to smooth nematode segmentations.</p>
</sec><sec id="s2b">
<title>Nematode Skeleton</title>
<p>Over the years, a large number of methods have been used to extract skeletons from segmented nematodes. Methods have ranged from using specific nematode models <xref ref-type="bibr" rid="pone.0011631-Huang2">[34]</xref>, <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, to heuristically constructing the nematode's medial axis <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0011631-Hoshi1">[35]</xref>, <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang3">[41]</xref>. While these various methods have shown success, they are generally influenced by the quality of the segmentation. In an attempt to reduce sensitivity to segmentation noise, we propose an original algorithm which balances geometric features (<italic>i.e.</italic> nematode boundary) and global shape (<italic>i.e.</italic> nematode undulating posture) in a seamless framework. The proposed method has the advantage of being intuitive and simple to implement.</p>
<p>We cast our problem once again in a probabilistic manner such that the nematode skeleton (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e092" xlink:type="simple"/></inline-formula>) is considered to be a sequence of discrete unknown skeleton pixel locations (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e093" xlink:type="simple"/></inline-formula>), where each location is a point on the skeleton and must be determined. It is assumed here that either the head or tail pixel location (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e094" xlink:type="simple"/></inline-formula>) is initially known; determining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e095" xlink:type="simple"/></inline-formula> is then viewed as a sequential Bayesian estimation problem <xref ref-type="bibr" rid="pone.0011631-Kalman1">[48]</xref>–<xref ref-type="bibr" rid="pone.0011631-Sznitman4">[50]</xref>. Given the initial position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e096" xlink:type="simple"/></inline-formula>, we infer the location of the next point (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e097" xlink:type="simple"/></inline-formula>) by observing the likelihood of potential locations (<italic>e.g.</italic> the likelihood of a pixel being <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e098" xlink:type="simple"/></inline-formula>) as well as the history of directions between subsequent pairs of points (<italic>e.g.</italic> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e099" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e100" xlink:type="simple"/></inline-formula>). The ‘skeleton’ algorithm is iterative such that a new location along <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e101" xlink:type="simple"/></inline-formula> is inferred at each iteration step (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e102" xlink:type="simple"/></inline-formula>). To infer all points in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e103" xlink:type="simple"/></inline-formula>, this process is simply repeated.</p>
<p>First, the input of our algorithm is the segmentation of the nematode for a given image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e104" xlink:type="simple"/></inline-formula>). A skeleton pixel location is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e105" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e106" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e107" xlink:type="simple"/></inline-formula> are pixel locations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e108" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e109" xlink:type="simple"/></inline-formula> be a discrete random vector describing the direction from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e110" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e111" xlink:type="simple"/></inline-formula>, such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e112" xlink:type="simple"/></inline-formula>. This corresponds to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e113" xlink:type="simple"/></inline-formula> being one pixel away from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e114" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e115" xlink:type="simple"/></inline-formula> be the corresponding probability distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e116" xlink:type="simple"/></inline-formula> at iteration step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e117" xlink:type="simple"/></inline-formula>. As more skeleton pixels are inferred, the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e118" xlink:type="simple"/></inline-formula> will evolve. Initially this distribution is uniform, as no prior information between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e119" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e120" xlink:type="simple"/></inline-formula> is known. The initial position (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e121" xlink:type="simple"/></inline-formula>) is found by using maximal response locations when running a coarse corner detector on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e122" xlink:type="simple"/></inline-formula>. Selecting the following point on the skeleton can then be computed by maximizing the Maximum a Posteriori (MAP) estimator,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e123" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e124" xlink:type="simple"/></inline-formula> is the likelihood that direction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e125" xlink:type="simple"/></inline-formula> leads to the next skeleton point and is modeled by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e126" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e127" xlink:type="simple"/></inline-formula> is the distance computed when applying the Chamfer distance transform <xref ref-type="bibr" rid="pone.0011631-Barrow1">[51]</xref>, <xref ref-type="bibr" rid="pone.0011631-Gavrila1">[52]</xref> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e128" xlink:type="simple"/></inline-formula>. This transformation computes the Euclidean distance of each pixel in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e129" xlink:type="simple"/></inline-formula> to its closest nematode boundary pixel. An example of this distance transform is shown in the contour plot of <xref ref-type="fig" rid="pone-0011631-g005">Fig. 5</xref>. Here, the boundary of the nematode has a distance of zero, while values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e130" xlink:type="simple"/></inline-formula> increase steadily for pixels approaching the medial axis of the nematode. Equation (4) then implies that skeleton locations are picked by (i) weighing how likely pixels are to be at the center of the segmented nematode, combined with (ii) the history of the chosen vector directions. This strategy is particularly useful in cases where the segmentation is noisy, as the history of vector directions guides where the following pixel location should be located. In order to remove the possibility of selecting the same pixel several times, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e131" xlink:type="simple"/></inline-formula> is removed from possible future locations by setting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e132" xlink:type="simple"/></inline-formula>.</p>
<fig id="pone-0011631-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g005</object-id><label>Figure 5</label><caption>
<title>Computing the nematode skeleton.</title>
<p>Representation of the Chamfer distance transform field (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e133" xlink:type="simple"/></inline-formula>) applied to the segmented nematode of <xref ref-type="fig" rid="pone-0011631-g004">Fig. 4</xref>. The value associated at each pixel of the image is the Euclidean distance (in pix) to the closest point of the nematode boundary; the distance on the boundary is zero and higher distances lie towards the nematode medial axis. <bold>(Inset)</bold> Resulting skeleton is achieved by balancing geometric features (<italic>i.e.</italic> Chamfer distance) and global shape (<italic>i.e.</italic> nematode curvature).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g005" xlink:type="simple"/></fig>
<p>Once <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e134" xlink:type="simple"/></inline-formula> is determined, the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e135" xlink:type="simple"/></inline-formula> must be updated for the following iteration. Using Bayes rules, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e136" xlink:type="simple"/></inline-formula> is computed for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e137" xlink:type="simple"/></inline-formula> by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e138" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e139" xlink:type="simple"/></inline-formula> is a normalization constant.</p>
<p>Inferring <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e140" xlink:type="simple"/></inline-formula> for a given image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e141" xlink:type="simple"/></inline-formula> then consists in the following algorithm. First, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e142" xlink:type="simple"/></inline-formula> is given at iteration step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e143" xlink:type="simple"/></inline-formula>. Three steps are then repeated: (i) compute the next skeleton location from Eq. (4); (ii) update the distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e144" xlink:type="simple"/></inline-formula> from Eq. (6); and finally (iii) increment the iteration step. These operations are repeated until a point on the boundary is encountered (<italic>i.e.</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e145" xlink:type="simple"/></inline-formula>). An example of the resulting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e146" xlink:type="simple"/></inline-formula> (skeleton) is shown in the inset of <xref ref-type="fig" rid="pone-0011631-g005">Fig. 5</xref>.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<p>We aim at providing a versatile nematode segmentation framework with performances comparable to, or better than, state-of-the-art image analysis systems <xref ref-type="bibr" rid="pone.0011631-Baek1">[27]</xref>, <xref ref-type="bibr" rid="pone.0011631-Cronin1">[30]</xref>, <xref ref-type="bibr" rid="pone.0011631-Feng1">[31]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang1">[33]</xref>–<xref ref-type="bibr" rid="pone.0011631-Tsibidis1">[36]</xref>, <xref ref-type="bibr" rid="pone.0011631-Geng2">[40]</xref>, <xref ref-type="bibr" rid="pone.0011631-Huang3">[41]</xref>. To compare the MEME framework against such systems, we evaluate our algorithm quantitatively for a series of image sequences obtained for various <italic>C. elegans</italic> locomotive environments. The sequences include one or more data sets for behavioral assays such as (i) crawling on substrates (<xref ref-type="supplementary-material" rid="pone.0011631.s003">Video S2</xref> and <xref ref-type="supplementary-material" rid="pone.0011631.s004">S3</xref>), (ii) swimming in a drop (<xref ref-type="supplementary-material" rid="pone.0011631.s005">Video S4</xref>), (iii) swimming in shallow acrylic channels (<xref ref-type="supplementary-material" rid="pone.0011631.s006">Video S5</xref>), (iv) locomotion in a gelatin-based solution (<xref ref-type="supplementary-material" rid="pone.0011631.s007">Video S6</xref>), and (v) locomotion in a microfluidic substrate (<xref ref-type="supplementary-material" rid="pone.0011631.s008">Video S7</xref>). A total of 13 image sequences are investigated (see <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref> for complete listing and data source). In each sequence, the target nematode is present in all images. The MEME framework is implemented using Matlab; computing the nematode segmentation and skeleton for a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e147" xlink:type="simple"/></inline-formula> pixel size image requires approximately 1 second on a standard PC (<italic>i.e.</italic> 2.0 Ghz).</p>
<p>The state-of-the-art method of choice for comparison with MEME is an in-house developed thresholding algorithm <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref>, similar to standard intensity-based threshold approaches <xref ref-type="bibr" rid="pone.0011631-Cronin1">[30]</xref>, <xref ref-type="bibr" rid="pone.0011631-Feng1">[31]</xref>, <xref ref-type="bibr" rid="pone.0011631-Hoshi1">[35]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsibidis1">[36]</xref>, <xref ref-type="bibr" rid="pone.0011631-Geng2">[40]</xref>. To perform a fair comparison between MEME and the thresholding framework, both methods are initially provided with a single image to tune their respective parameters. As described for MEME (see <xref ref-type="sec" rid="s2">Methods</xref>), the user selects from the initial image (i) the nematode region and (ii) the nematode width (<xref ref-type="supplementary-material" rid="pone.0011631.s002">Video S1</xref>). For the threshold-based method, all images of a sequence are first used to compute a background image of the environment by pixel averaging. Background subtraction is then applied to each image. Next, several thresholds are used to prune the remaining background pixels. These are manually selected by optimizing segmentation results on the initial image (<xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref>). Finally, opening and closing morphological operators are used to smooth and discard final background regions. Note that in the case where the number of images in the sequence is small, background subtraction is omitted and only threshold intensities are used.</p>
<p>In order to quantitatively evaluate any segmentation algorithm, results must be compared to a <italic>ground truth</italic> <xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref>. For the present purpose, the ground truth is set as the true, or optimal, nematode segmentation provided by an expert. Hence, we manually segment a small set of images (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e148" xlink:type="simple"/></inline-formula>–40) from each sequence (<italic>e.g.</italic> <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>, second row) and compare the performance of each algorithm to this image sub-set. Determining such ground truth allows for a precise definition of correct and incorrect pixel classification.</p>
<fig id="pone-0011631-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g006</object-id><label>Figure 6</label><caption>
<title>Nematode segmentation for various locomotive environments.</title>
<p><bold>(top row)</bold> Snapshots of raw images are respectively shown for crawling (<xref ref-type="supplementary-material" rid="pone.0011631.s003">Video S2</xref>), swimming in a drop (<xref ref-type="supplementary-material" rid="pone.0011631.s005">Video S4</xref>), swimming in a channel (<xref ref-type="supplementary-material" rid="pone.0011631.s006">Video S5</xref>), and locomotion in various microfluidic substrates (source: Supplemental Videos in Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>). Comparisons between nematode segmentations are respectively shown for (i) the ground truth, i.e. hand-segmented nematodes <bold>(second row)</bold>, (ii) a threshold-based approach <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref> <bold>(third row)</bold>, and (iii) the Multi-Environment Model Estimation (MEME) algorithm <bold>(bottom row)</bold>. See <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref> for data on all 13 cases investigated.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g006" xlink:type="simple"/></fig>
<p>The performance of a segmentation algorithm can be evaluated by measuring two distinct metrics <xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref>: (i) the <italic>surface error</italic> and (ii) the <italic>nematode yield</italic>. The former quantity computes the proportion of pixels which are misclassified by the algorithm over the entire image. This metric is mathematically defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e149" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e150" xlink:type="simple"/></inline-formula> is a pixel location and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e151" xlink:type="simple"/></inline-formula> is the ground truth image for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e152" xlink:type="simple"/></inline-formula>. Hence, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e153" xlink:type="simple"/></inline-formula> attributes equivalent weight to errors on the background and the nematode regions. The nematode yield, however, only computes the proportion of the nematode region which is correctly segmented. Consequently, misclassified pixels belonging to the background have no impact on the nematode yield. This metric is defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.e154" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e155" xlink:type="simple"/></inline-formula> is the set of pixels which satisfy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e156" xlink:type="simple"/></inline-formula>. Together, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e157" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e158" xlink:type="simple"/></inline-formula> provide a quantitative and reliable measure of segmentation performance <xref ref-type="bibr" rid="pone.0011631-Sznitman3">[44]</xref>.</p>
<p>Qualitative segmentation results are shown for a selection of motility environments in <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref> as well as in the <xref ref-type="supplementary-material" rid="pone.0011631.s003">Videos S2</xref> to <xref ref-type="supplementary-material" rid="pone.0011631.s008">S7</xref>. In general, the MEME method is capable of segmenting nematodes at least as well as the thresholding method. For the “Crawl”, “Drop”, and “Channel” environments (first three columns, <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>), both methods yield qualitatively similar results. Here, the environments illustrate a relatively homogenous background. However, in the complex “Microfluidic” environments (<xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>), results contrast more sharply between the two approaches; MEME provides cleaner segmentations which capture more closely the original shape of the nematodes.</p>
<p><xref ref-type="fig" rid="pone-0011631-g007">Figure 7</xref> shows the results from the computation of the surface error (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7a</xref>) and the nematode yield (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7b</xref>) for the environments of <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>. Data for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e159" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e160" xlink:type="simple"/></inline-formula> is reported in <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref> for the complete 13 image sequences. In general, computations of surface error (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e161" xlink:type="simple"/></inline-formula>) illustrate comparable performances between MEME and the threshold-based approach (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7a</xref>). Yet, in two complex “Microfluidic” environments, MEME does significantly better. Note that for all environments investigated here (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7a</xref> and <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e162" xlink:type="simple"/></inline-formula> remains below <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e163" xlink:type="simple"/></inline-formula>. In fact, for homogeneous background environments such as “Crawl”, “Drop”, and “Channel”, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e164" xlink:type="simple"/></inline-formula>, emphasizing the good results obtained both by MEME and the threshold-based approach.</p>
<fig id="pone-0011631-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g007</object-id><label>Figure 7</label><caption>
<title>Performance evaluation of nematode segmentation algorithms.</title>
<p>Here, the Multi-Environment Model Estimation (MEME) algorithm is compared to a state-of-the-art thresholding approach <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref> for the environments shown in <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>. (<bold>a</bold>) Surface error (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e165" xlink:type="simple"/></inline-formula>): proportion of pixels which are misclassified by an algorithm over the entire image (see Eq. (7)). (<bold>b</bold>) Nematode yield (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e166" xlink:type="simple"/></inline-formula>): proportion of the nematode region which is correctly segmented (see Eq. (8)). Complete data on surface error and nematode yield is available in <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref> for all 13 cases investigated.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g007" xlink:type="simple"/></fig>
<p>We observe, in contrast, significant improvements in nematode yield (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e167" xlink:type="simple"/></inline-formula>) when using MEME compared to the thresholding method (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7b</xref>). From the set of 13 assays tested here, 10 cases show examples of MEME significantly outperforming the threshold-based method (<xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref>); in some cases, with margins greater than 20 percentage points (<italic>e.g.</italic> “Microfluidic” and “Microfluidic II”, <xref ref-type="fig" rid="pone-0011631-g007">Fig. 7b</xref>). In the remaining environments where the thresholding method performs relatively better (<italic>e.g.</italic> “Microfluidic III”, <xref ref-type="fig" rid="pone-0011631-g007">Fig. 7b</xref>), the differences in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e168" xlink:type="simple"/></inline-formula> remain however small, <italic>i.e.</italic> between 1.79 and 4.71 percentage points. Overall, our MEME algorithm outperforms the threshold-based approach for the overwhelming majority of cases examined.</p>
</sec><sec id="s4">
<title>Discussion</title>
<p>Our experiments show that MEME provides a reliable framework to obtain nematode segmentations of <italic>C. elegans</italic> across various locomotive environments. In addition, MEME offers significant improvements over alternative image analysis systems available; these include (i) better, or similar, performances compared to state-of-the-art thresholding approaches <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref>, (ii) no nematode-free image sequence required for learning background appearances <xref ref-type="bibr" rid="pone.0011631-Roussel1">[38]</xref>, <xref ref-type="bibr" rid="pone.0011631-Tsechpenakis1">[39]</xref>; and (iii) a small amount of user input needed, <italic>i.e.</italic> a single hand-segmentation of the nematode and a marking of its width (<xref ref-type="supplementary-material" rid="pone.0011631.s002">Video S1</xref>). This last improvement is particularly attractive from a user point of view as substantial effort may be needed with thresholding techniques to obtain similar results. Overall, these attributes make the MEME framework both attractive and straightforward to use for a broad range of researchers.</p>
<p>While computing good nematode segmentations with threshold-based methods is possible (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7</xref>), this process can quickly become laborious. Indeed, several iterations are required by the user to find optimal thresholds for a given environment (<xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref>). The main complication arises from the non-uniform backgrounds and appearance (<italic>i.e.</italic> pixel intensities) which characterize many environments. For example, a single threshold is incapable of distinguishing between the nematode and the background in the presence of pillars in microfluidic substrates (<italic>e.g.</italic> <xref ref-type="fig" rid="pone-0011631-g006">Fig. 6</xref>, last column). Similarly, single thresholds cannot adapt to specific locations in an image. This becomes crucial for accurate segmentation of nematodes in environments where lighting conditions may not be uniform (<italic>e.g.</italic> <xref ref-type="supplementary-material" rid="pone.0011631.s006">Video S5</xref>).</p>
<p>In general, the improvement observed with MEME can be attributed to two main reasons: (1) the nematode appearance model is explicitly learned and used to help decide whether pixels belong to the nematode. In practice, when using threshold-based methods, many of the regions which are considered “not background” after applying a threshold do not resemble the nematode at all (<italic>e.g.</italic> pillars in “artificial dirt” assays of Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>, <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1f</xref> and <xref ref-type="supplementary-material" rid="pone.0011631.s008">Video S7</xref>). Using both the nematode and background appearance models significantly reduces the need of using intense pruning schemes to reject such regions. (2) The background scene is partitioned into a grid of sub-regions (<xref ref-type="fig" rid="pone-0011631-g004">Fig. 4c</xref>), where each cell is explicitly modeled. This allows for local variations in intensities to be grouped by region, providing a localized statistical model for each area of the background scene. This strategy has the advantage of appropriately modeling backgrounds where large variations in lighting occur (<italic>e.g.</italic> <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1g</xref>).</p>
<p>In cases where the nematode appearance differs significantly from the background, such as in crawling and swimming assays (<italic>e.g.</italic> <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1a and b</xref>), we observe nematode yields (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e169" xlink:type="simple"/></inline-formula>) beyond <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e170" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pone-0011631-g007">Fig. 7</xref> and <xref ref-type="supplementary-material" rid="pone.0011631.s001">Table S1</xref>). In contrast, more complex environments can substantially reduce this performance (<italic>e.g.</italic> microfluidic substrates). The main difficulty therein lies in that only pixel intensities are modeled; this represents an important limitation when pixel intensities of the nematode and the background are too similar. A typical illustration of this problem occurs at the head and tail of <italic>C. elegans</italic>, where the nematode extremities are often transparent against the background. For example, this problem is observed in microfluidic substrates (<italic>e.g.</italic> <xref ref-type="fig" rid="pone-0011631-g001">Fig. 1e and f</xref>) where the ends of the nematode are lost during the segmentation process. A direct consequence of this is the truncated length of nematode skeletons (<italic>e.g.</italic> inset of <xref ref-type="fig" rid="pone-0011631-g005">Fig 5</xref> and <xref ref-type="supplementary-material" rid="pone.0011631.s008">Video S7</xref>).</p>
<p>Our MEME framework is currently optimized for segmenting a single target nematode within an image sequence. Nevertheless, scenarios where multiple nematodes enter the scene in subsequent images are still supported by our algorithm as long as only one nematode is present in the input image. That is, an arbitrary number of nematodes may be segmented for a given image sequence. Note, however, that cases where the appearance of either the nematode or the background changes significantly over the length of an image sequence will cause improper segmentations. Furthermore, extracting skeletons remains a challenge in some scenarios. For example, cases where the nematode coils on itself, or when its head and tail touch (<italic>e.g.</italic> omega bend), are currently not supported with the implemented skeleton algorithm. In the former case, the segmentation simply does not provide a correct shape representation of the nematode (<italic>i.e.</italic> a closed circle as opposed to a ‘snake’). The problem lies in the fact that estimating the medial axis of the nematode with the Chamfer distance transform is ill-suited. In principle, the latter scenario (<italic>i.e.</italic> omega bend) is not problematic. In practice, however, initializing the skeleton algorithm is ill-posed; there is no a priori knowledge as to where the head or tail lie.</p>
<sec id="s4a">
<title>Motility Metrics</title>
<p>We briefly discuss the feasibility of using nematode skeletons obtained with MEME (<xref ref-type="supplementary-material" rid="pone.0011631.s003">Videos S2</xref> to <xref ref-type="supplementary-material" rid="pone.0011631.s008">S7</xref>). Skeleton data often provides the building blocks to quantify locomotive traits of <italic>C. elegans</italic> <xref ref-type="bibr" rid="pone.0011631-Karbowski1">[11]</xref>, <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>, <xref ref-type="bibr" rid="pone.0011631-Korta1">[16]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman2">[19]</xref>. Here, we illustrate some of these motility metrics across sample environments. In <xref ref-type="fig" rid="pone-0011631-g008">Fig. 8</xref> (top row), nematode tracking data is shown over multiple body bending cycles for crawling on a substrate (left column), swimming in a drop (middle column), and locomotion in so-called “artificial dirt” (right column), <italic>i.e.</italic> a microfluidic substrate (Supplemental Videos in Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref>). Trajectories swept by the nematode tail (or head) are labeled, illustrating striking differences in the travel paths adopted by <italic>C. elegans</italic> as a function of the surrounding environment. Snapshots of nematode skeletons over one beating cycle are shown in <xref ref-type="fig" rid="pone-0011631-g008">Fig. 8</xref> (middle row); the time evolution of skeletons is color-coded as a function of the corresponding beating period (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e171" xlink:type="simple"/></inline-formula>). Plots reveal the existence of well-confined envelopes of body postures which vary dramatically with motility assay. Here, envelopes of postures are constructed using a principal component analysis (PCA) to find the skeleton's principal axis and orientation at each instant in time. Further metrics including the nematode wavelength as well as the amplitude of body undulations can be obtained in a straightforward manner from the construction of such envelopes <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>.</p>
<fig id="pone-0011631-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0011631.g008</object-id><label>Figure 8</label><caption>
<title>Examples of nematode locomotive features in sample environments.</title>
<p>Here, nematode skeleton data is shown for a crawling assay (left column), for swimming in a 5 ml drop (middle column), and for locomotion in a microfluidic substrate obtained from Lockery <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0011631-Lockery1">[21]</xref> (right column). Additional skeleton data is shown in <xref ref-type="supplementary-material" rid="pone.0011631.s003">Videos S2</xref> to <xref ref-type="supplementary-material" rid="pone.0011631.s008">S7</xref>. <bold>(top row)</bold> Tracking data of path swept by nematode head (or tail) over multiple beating cycles. <bold>(middle row)</bold> Color-coded temporal evolution of <italic>C. elegans</italic> skeletons over one beating period (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e172" xlink:type="simple"/></inline-formula>). Results reveal a distinct envelope of body postures for each environment. <bold>(bottom row)</bold> Spatio-temporal contour plot of body curvature (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e173" xlink:type="simple"/></inline-formula>) along the length of the nematode's skeleton. Red and blue colors represent positive and negative curvature values, respectively. The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e174" xlink:type="simple"/></inline-formula>-axis corresponds to the dimensionless position (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e175" xlink:type="simple"/></inline-formula>) along the <italic>C. elegans</italic>' body length where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e176" xlink:type="simple"/></inline-formula> is the head and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e177" xlink:type="simple"/></inline-formula> is the tail.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.g008" xlink:type="simple"/></fig>
<p>Next, we illustrate measures of body curvature (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e178" xlink:type="simple"/></inline-formula>) along the nematode's length (<xref ref-type="fig" rid="pone-0011631-g008">Fig. 8</xref>, bottom row); such plots have been shown to characterize swimming and crawling gaits <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>, <xref ref-type="bibr" rid="pone.0011631-Korta1">[16]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>. Curvature is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e179" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e180" xlink:type="simple"/></inline-formula> is the angle made by the tangent to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e181" xlink:type="simple"/></inline-formula>-axis at each point along the nematode skeleton; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e182" xlink:type="simple"/></inline-formula> is the arc-length coordinate spanning the nematode's head (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e183" xlink:type="simple"/></inline-formula>) to its tail (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e184" xlink:type="simple"/></inline-formula>). The spatio-temporal evolution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e185" xlink:type="simple"/></inline-formula> is shown over several beating cycles for each environment. Here, curvature values are color-coded; red and blue represent positive and negative values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e186" xlink:type="simple"/></inline-formula>, respectively. Note that the vertical axis in each contour plot corresponds to the non-dimensional body position (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e187" xlink:type="simple"/></inline-formula>), where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e188" xlink:type="simple"/></inline-formula> is the nematode length. Each contour plot shows the existence of highly periodic, well-defined diagonally oriented lines. These diagonal lines are characteristic of bending waves of motion which propagate in time along the nematode body length (<italic>i.e.</italic> traveling waves).</p>
<p>In <xref ref-type="fig" rid="pone-0011631-g008">Fig. 8</xref>, forward motion displays curvature lines with a positive slope (left and middle column); waves are initiated at the nematode head <xref ref-type="bibr" rid="pone.0011631-PierceShimomura2">[13]</xref>, <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>. Conversely, backward motion displays lines with a negative slope, where bending motion is initiated at the tail (right column). In general, a number of motility metrics may be directly extracted from such curvature contour plots. For example, the body bending frequency (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e189" xlink:type="simple"/></inline-formula>) may be obtained by applying a one-dimensional (1D) Fast Fourier Transform (FFT) to the curvature field <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e190" xlink:type="simple"/></inline-formula> at multiple body positions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e191" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0011631-Sznitman1">[18]</xref>. Similarly, the wave speed (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e192" xlink:type="simple"/></inline-formula>) may be directly extracted from the slope of the curvature <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e193" xlink:type="simple"/></inline-formula> propagating along the nematode's body; the wavelength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0011631.e194" xlink:type="simple"/></inline-formula> is then computed in a straightforward manner. With our MEME platform, nematode skeleton data is made ready available for use for motility analysis of <italic>C. elegans</italic>.</p>
</sec><sec id="s4b">
<title>Future Directions</title>
<p>The proposed MEME framework provides researchers with an attractive and reliable platform for nematode segmentation and ‘skeletonizing’ across a large spectrum of <italic>C. elegans</italic> motility assays. The MEME software is freely available upon request (contact person: J. Sznitman; website for download will be provided). Improving our system to further assist researchers conduct quantitative analysis of <italic>C. elegans</italic> is of course desired. In the near future, one immediate goal is to provide segmentations and skeletons simultaneously for multiple nematodes. This ‘upgrade’ would be of great interest for high-throughput drug screening applications <xref ref-type="bibr" rid="pone.0011631-Rhode1">[24]</xref>, <xref ref-type="bibr" rid="pone.0011631-Shi1">[25]</xref>. From a performance point of view, combining larger sets of image features (<italic>e.g.</italic> edges, texture, etc.) with MOG models may provide better appearance models for difficult environments. This may yield better segmentation results, in particular at the nematode extremities (<italic>i.e.</italic> head and tail). Finally, our MEME platform is not restricted to image analysis of <italic>C. elegans</italic> only. For instance, MOG methods may be used for applications relating cell tracking and motility <xref ref-type="bibr" rid="pone.0011631-DublinThaler1">[53]</xref>–<xref ref-type="bibr" rid="pone.0011631-Xiong1">[55]</xref>. We illustrate here an example of such possible application with Albino Swiss mouse embryo fibroblast cells (<xref ref-type="supplementary-material" rid="pone.0011631.s009">Video S8</xref>).</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0011631.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s001" xlink:type="simple"><label>Table S1</label><caption>
<p>Compiled data on segmentation results for the Multi-Environment Model Estimation (MEME) and threshold-based algorithms. Performances of each algorithm (i.e., surface error and nematode yield) are evaluated for 13 different image sequences representative of various locomotive environments (e.g., crawling on agar plate, swimming in a channel or a drop, locomotion in microfluidic substrates).</p>
<p>(0.37 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s002" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s002" xlink:type="simple"><label>Video S1</label><caption>
<p>MEME software tutorial shown for a sample image sequence (source: berrigel2.0perc.mov, Supplementary Material in Berri et al. [2009]).</p>
<p>(9.57 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s003" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s003" xlink:type="simple"><label>Video S2</label><caption>
<p>Example of crawling assay. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. Here, a young adult, wild-type (N2) <italic>C. elegans</italic> is seen crawling on an agar plate. Nematode is approximately 1 mm long (image resolution: 1/78 mm/pix; image acquisition rate: 28 frames per second).</p>
<p>(9.57 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s004" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s004" xlink:type="simple"><label>Video S3</label><caption>
<p>Example of crawling on a substrate. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. The original data is obtained from the Supplementary Information (Movie 1) in Pierce-Shimomura et al. (2008).</p>
<p>(0.87 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s005" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s005" xlink:type="simple"><label>Video S4</label><caption>
<p>Example of swimming assay in a liquid drop. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. Here, a young adult, wild-type (N2) <italic>C. elegans</italic> is seen swimming in a 5 ml drop of M9 buffer solution. Nematode is approximately 1 mm long (image resolution: 1/78 mm/pix; image acquisition rate: 28 frames per second).</p>
<p>(9.54 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s006" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s006" xlink:type="simple"><label>Video S5</label><caption>
<p>Example of swimming assay in a shallow channel. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. Here, a young adult, wild-type (N2) <italic>C. elegans</italic> is seen swimming in a narrow acrylic channel filled with M9 buffer solution. Details are given in Sznitman et al. (2010). Nematode is approximately 1 mm long (image resolution: 1/400 mm/pix; image acquisition rate: 125 frames per second).</p>
<p>(8.27 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s007" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s007" xlink:type="simple"><label>Video S6</label><caption>
<p>Example of nematode locomotion in a gelatin-based solution. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. The original data is obtained from the Supplementary Information (berrigel2.0perc.mov) in Berri et al. (2009).</p>
<p>(3.75 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s008" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s008" xlink:type="simple"><label>Video S7</label><caption>
<p>Example of nematode locomotion in “artificial dirt”, i.e., a microfluidic substrate. From left to right: (i) raw image, (ii) binary segmentation from MEME, and (iii) resulting skeleton superimposed on raw image. The original data is obtained from the Supplementary Information (Video 2) in Lockery et al. (2008).</p>
<p>(1.20 MB AVI)</p>
</caption></supplementary-material><supplementary-material id="pone.0011631.s009" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pone.0011631.s009" xlink:type="simple"><label>Video S8</label><caption>
<p>Application of the MEME software to segmentation of Albino Swiss Mouse Embryo Fibroblast cells (3T3 Line). The original video (Video 2) is extracted from live-cell imaging videos available at Nikon Microscopy U (<ext-link ext-link-type="uri" xlink:href="http://www.microscopyu.com/moviegallery/livecellimaging/3t3/index.html" xlink:type="simple">http://www.microscopyu.com/moviegallery/livecellimaging/3t3/index.html</ext-link>), as obtained with Differential Interference Contrast (DIC) microscopy.</p>
<p>(5.75 MB AVI)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>Strains of <italic>C. elegans</italic> were obtained from the Caenorhabditis elegans Genetic Stock Center (University of Minnesota), supported by the National Institutes of Health (Bethesda MD, USA). The authors would like to thank Dr. R. Ghosh (Lewis-Sigler Institute for Integrative Genomics, Princeton U.), X. Shen (Department of Mechanical Engineering and Applied Mechanics, U. of Penn), and Dr. A.E.X. Brown (MRC Lab of Molecular Biology, Cambridge U.) for their support and helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0011631-Brenner1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brenner</surname><given-names>S</given-names></name>
</person-group>             <year>1974</year>             <article-title>The genetics of <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Genetics</source>             <volume>77</volume>             <fpage>71</fpage>             <lpage>94</lpage>          </element-citation></ref>
<ref id="pone.0011631-Rankin1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rankin</surname><given-names>CH</given-names></name>
</person-group>             <year>2002</year>             <article-title>From gene to indentified neuron to behaviour in <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Nature Rev Genetics</source>             <volume>3</volume>             <fpage>622</fpage>             <lpage>630</lpage>          </element-citation></ref>
<ref id="pone.0011631-Link1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Link</surname><given-names>EM</given-names></name>
<name name-style="western"><surname>Hardiman</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Sluder</surname><given-names>AE</given-names></name>
<name name-style="western"><surname>Johnson</surname><given-names>CD</given-names></name>
<name name-style="western"><surname>Liu</surname><given-names>LX</given-names></name>
</person-group>             <year>2000</year>             <article-title>Therapeutic target discovery using <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Pharmacogenomics</source>             <volume>1</volume>             <fpage>203</fpage>             <lpage>217</lpage>          </element-citation></ref>
<ref id="pone.0011631-Jorgensen1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jorgensen</surname><given-names>EM</given-names></name>
<name name-style="western"><surname>Mango</surname><given-names>SE</given-names></name>
</person-group>             <year>2002</year>             <article-title>The art and design of genetic screens: <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Nature Rev Genetics</source>             <volume>3</volume>             <fpage>356</fpage>             <lpage>369</lpage>          </element-citation></ref>
<ref id="pone.0011631-Chamberlain1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chamberlain</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Benian</surname><given-names>GM</given-names></name>
</person-group>             <year>2000</year>             <article-title>Muscular dystrophy: the worm turns to genetic disease.</article-title>             <source>Curr Biol</source>             <volume>10</volume>             <fpage>795</fpage>             <lpage>797</lpage>          </element-citation></ref>
<ref id="pone.0011631-Silverman1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Silverman</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Luke</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Bhatia</surname><given-names>SR</given-names></name>
<name name-style="western"><surname>Long</surname><given-names>OS</given-names></name>
<name name-style="western"><surname>Vetica</surname><given-names>AC</given-names></name>
<etal/></person-group>             <year>2009</year>             <article-title>Modeling molecular and cellular aspects of human disease using the nematode <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Pediatr Res</source>             <volume>65</volume>             <fpage>10</fpage>             <lpage>18</lpage>          </element-citation></ref>
<ref id="pone.0011631-Sulston1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sulston</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Horvitz</surname><given-names>HR</given-names></name>
</person-group>             <year>1977</year>             <article-title>Post-embryonic cell lineages of the nematode <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Dev Biol</source>             <volume>56</volume>             <fpage>110</fpage>             <lpage>156</lpage>          </element-citation></ref>
<ref id="pone.0011631-Sulston2"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sulston</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Schierenberg</surname><given-names>E</given-names></name>
<name name-style="western"><surname>White</surname><given-names>JG</given-names></name>
<name name-style="western"><surname>Thomson</surname><given-names>JN</given-names></name>
</person-group>             <year>1983</year>             <article-title>The embryonic cell lineage of the nematode <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Dev Biol</source>             <volume>100</volume>             <fpage>64</fpage>             <lpage>119</lpage>          </element-citation></ref>
<ref id="pone.0011631-White1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>White</surname><given-names>JG</given-names></name>
<name name-style="western"><surname>Southgate</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Thomson</surname><given-names>JN</given-names></name>
<name name-style="western"><surname>Brenner</surname><given-names>S</given-names></name>
</person-group>             <year>1986</year>             <article-title>The structure of the nervous system of the nematode <italic>C. elegans</italic>.</article-title>             <source>Phil Trans R Soc Lond B Biol Sci</source>             <volume>314</volume>             <fpage>1</fpage>             <lpage>340</lpage>          </element-citation></ref>
<ref id="pone.0011631-CES1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <collab xlink:type="simple">CES Consortium</collab>             <year>1998</year>             <article-title>Genome sequence of the nematode <italic>C. elegans</italic>: a platform for investigating biolog.</article-title>             <source>Science</source>             <volume>282</volume>             <fpage>2012</fpage>             <lpage>2018</lpage>          </element-citation></ref>
<ref id="pone.0011631-Karbowski1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karbowski</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Cronin</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Seah</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Mendel</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Cleary</surname><given-names>D</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>Conservation rules, their breakdown, and optimality in <italic>Caenorhabditis</italic> sinusoidal locomotion.</article-title>             <source>J Theor Biol</source>             <volume>242</volume>             <fpage>652</fpage>             <lpage>669</lpage>          </element-citation></ref>
<ref id="pone.0011631-PierceShimomura1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pierce-Shimomura</surname><given-names>JT</given-names></name>
<name name-style="western"><surname>Morse</surname><given-names>TM</given-names></name>
<name name-style="western"><surname>Lockery</surname><given-names>SR</given-names></name>
</person-group>             <year>1999</year>             <article-title>The fundamental role of pirouettes in <italic>Caenorhabditis elegans</italic> chemotaxis.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>9557</fpage>             <lpage>9569</lpage>          </element-citation></ref>
<ref id="pone.0011631-PierceShimomura2"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pierce-Shimomura</surname><given-names>JT</given-names></name>
<name name-style="western"><surname>Chen</surname><given-names>BL</given-names></name>
<name name-style="western"><surname>Mun</surname><given-names>JJ</given-names></name>
<name name-style="western"><surname>Ho</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sarkis</surname><given-names>R</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Genetic analysis of crawling and swimming locomotory patterns in <italic>C. elegans</italic>.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>105</volume>             <fpage>20982</fpage>             <lpage>20987</lpage>          </element-citation></ref>
<ref id="pone.0011631-Tavernarakis1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tavernarakis</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Shreffler</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Driscoll</surname><given-names>M</given-names></name>
</person-group>             <year>1997</year>             <article-title>unc-8, a deg/enac family member, encodes a subunit of a candidate mechanically gated channel that modulates <italic>C. elegans</italic> locomotion.</article-title>             <source>Neuron</source>             <volume>18</volume>             <fpage>107</fpage>             <lpage>119</lpage>          </element-citation></ref>
<ref id="pone.0011631-Berri1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Berri</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Boyle</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Tassieri</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Hope</surname><given-names>IA</given-names></name>
<name name-style="western"><surname>Cohen</surname><given-names>N</given-names></name>
</person-group>             <year>2009</year>             <article-title>Forward locomotion of the nematode <italic>C. elegans</italic> is achieved through modulation of a single gait.</article-title>             <source>HFSP J</source>             <volume>3</volume>             <fpage>186</fpage>             <lpage>193</lpage>          </element-citation></ref>
<ref id="pone.0011631-Korta1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Korta</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Clark</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Gabel</surname><given-names>CV</given-names></name>
<name name-style="western"><surname>Mahadevan</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Samuel</surname><given-names>ADT</given-names></name>
</person-group>             <year>2007</year>             <article-title>Mechanosensation and mechanical load modulate the locomotory gait of swimming <italic>C. elegans</italic>.</article-title>             <source>J Exp Biol</source>             <volume>210</volume>             <fpage>2383</fpage>             <lpage>2389</lpage>          </element-citation></ref>
<ref id="pone.0011631-Ghosh1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ghosh</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Emmons</surname><given-names>SW</given-names></name>
</person-group>             <year>2008</year>             <article-title>Episodic swimming behavior in the nematode <italic>C. elegans</italic>.</article-title>             <source>J Exp Biol</source>             <volume>211</volume>             <fpage>3703</fpage>             <lpage>3711</lpage>          </element-citation></ref>
<ref id="pone.0011631-Sznitman1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sznitman</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Purohit</surname><given-names>PK</given-names></name>
<name name-style="western"><surname>Krajacic</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Lamitina</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Arratia</surname><given-names>PE</given-names></name>
</person-group>             <year>2010</year>             <article-title>Material properties of <italic>Caenorhabditis elegans</italic> swimming at low Reynolds number.</article-title>             <source>Biophys J</source>             <volume>98</volume>             <fpage>617</fpage>             <lpage>626</lpage>          </element-citation></ref>
<ref id="pone.0011631-Sznitman2"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sznitman</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Shen</surname><given-names>X</given-names></name>
<name name-style="western"><surname>Purohit</surname><given-names>PK</given-names></name>
<name name-style="western"><surname>Arratia</surname><given-names>PE</given-names></name>
</person-group>             <year>2010</year>             <article-title>The effects of fluid viscosity on the kinematics and material properties of <italic>C. elegans</italic> swimming at low Reynolds number.</article-title>             <source>Exp Mech</source>             <comment>DOI 10.1007/s11340-010-9339-1</comment>          </element-citation></ref>
<ref id="pone.0011631-Chronis1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chronis</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Zimmer</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bargmann</surname><given-names>CI</given-names></name>
</person-group>             <year>2007</year>             <article-title>Microfluidics for in vivo imaging of neuronal and behavioral activity in <italic>Caenorhabditis elegans</italic>.</article-title>             <source>Nature Methods</source>             <volume>4</volume>             <fpage>727</fpage>             <lpage>731</lpage>          </element-citation></ref>
<ref id="pone.0011631-Lockery1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lockery</surname><given-names>SR</given-names></name>
<name name-style="western"><surname>Lawton</surname><given-names>KJ</given-names></name>
<name name-style="western"><surname>Doll</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Faumont</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Couthard</surname><given-names>SM</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Artificial dirt: microfluidic substrates for nematode neurobiology.</article-title>             <source>J Neurophysiol</source>             <volume>99</volume>             <fpage>3136</fpage>             <lpage>3143</lpage>          </element-citation></ref>
<ref id="pone.0011631-Park1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Park</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Hwang</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Nam</surname><given-names>SW</given-names></name>
<name name-style="western"><surname>Martinez</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Austin</surname><given-names>RH</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Enhanced <italic>Caenorhabditis elegans</italic> locomotion in a structured microfluidic environment.</article-title>             <source>PLOS One</source>             <volume>3</volume>             <fpage>e2550</fpage>          </element-citation></ref>
<ref id="pone.0011631-Qin1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Qin</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Wheeler</surname><given-names>AR</given-names></name>
</person-group>             <year>2007</year>             <article-title>Maze exploration and learning in <italic>C. elegans</italic>.</article-title>             <source>Lab Chip</source>             <volume>7</volume>             <fpage>186</fpage>             <lpage>192</lpage>          </element-citation></ref>
<ref id="pone.0011631-Rhode1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rhode</surname><given-names>CB</given-names></name>
<name name-style="western"><surname>Zeng</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Gonzalesz-Rubio</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Angel</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Yanik</surname><given-names>MF</given-names></name>
</person-group>             <year>2007</year>             <article-title>Microfluidic system for on-chip high-throughput whole-animal sorting and screening at subcellular resolution.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>104</volume>             <fpage>13891</fpage>             <lpage>13895</lpage>          </element-citation></ref>
<ref id="pone.0011631-Shi1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shi</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Qin</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Ye</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Lin</surname><given-names>B</given-names></name>
</person-group>             <year>2008</year>             <article-title>Droplet-based microfluidic system for individual <italic>Caenorhabditis elegans</italic> assay.</article-title>             <source>Lab Chip</source>             <volume>8</volume>             <fpage>1432</fpage>             <lpage>1435</lpage>          </element-citation></ref>
<ref id="pone.0011631-Bessou1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bessou</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Giugia</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Franks</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Holden-Dye</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Segalat</surname><given-names>L</given-names></name>
</person-group>             <year>1998</year>             <article-title>Mutations in the <italic>Caenorhabditis elegans</italic> dystrophin-like gene dys-1 lead to hyperactivity and suggest a link with cholinergic transmission.</article-title>             <source>Neurogenetics</source>             <volume>2</volume>             <fpage>61</fpage>             <lpage>72</lpage>          </element-citation></ref>
<ref id="pone.0011631-Baek1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Baek</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Feng</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Silver</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2002</year>             <article-title>Using machine vision to analyze and classify <italic>Caenorhabditis elegans</italic> behavioral phenotypes quantitatively.</article-title>             <source>J Neurosci Meth</source>             <volume>118</volume>             <fpage>9</fpage>             <lpage>21</lpage>          </element-citation></ref>
<ref id="pone.0011631-Buckingham1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buckingham</surname><given-names>SD</given-names></name>
<name name-style="western"><surname>Sattelle</surname><given-names>DB</given-names></name>
</person-group>             <year>2008</year>             <article-title>Strategies for automated analysis of <italic>C. elegans</italic> locomotion.</article-title>             <source>Invert Neurosci</source>             <volume>8</volume>             <fpage>121</fpage>             <lpage>131</lpage>          </element-citation></ref>
<ref id="pone.0011631-Buckingham2"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buckingham</surname><given-names>SD</given-names></name>
<name name-style="western"><surname>Sattelle</surname><given-names>DB</given-names></name>
</person-group>             <year>2009</year>             <article-title>Fast, automated measurement of nematode swimming (thrashing) without morphometry.</article-title>             <source>BMC Neuroscience</source>             <volume>10</volume>             <fpage>84</fpage>          </element-citation></ref>
<ref id="pone.0011631-Cronin1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cronin</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Mendel</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Mukhtar</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Kim</surname><given-names>YM</given-names></name>
<name name-style="western"><surname>Stirb</surname><given-names>RC</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>An automated system for measuring parameters of nematode sinusoidal movement.</article-title>             <source>BMC Genetics</source>             <volume>6</volume>             <fpage>5</fpage>          </element-citation></ref>
<ref id="pone.0011631-Feng1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Feng</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Cronin</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Wittig</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Sternberg</surname><given-names>PW</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2004</year>             <article-title>An imaging system for standardized quantitative analysis of <italic>C. elegans</italic> behavior.</article-title>             <source>BMC Bioinformatics</source>             <volume>5</volume>             <fpage>115</fpage>          </element-citation></ref>
<ref id="pone.0011631-Geng1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Geng</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Berry</surname><given-names>CC</given-names></name>
<name name-style="western"><surname>Feng</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2004</year>             <article-title>Automatic tracking, feature extraction and classification of <italic>C. elegans</italic> phenotypes.</article-title>             <source>IEEE Trans Biomed Eng</source>             <volume>51</volume>             <fpage>1811</fpage>             <lpage>1820</lpage>          </element-citation></ref>
<ref id="pone.0011631-Huang1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huang</surname><given-names>KM</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2006</year>             <article-title>Machine vision based detection of omega bends and reversals in <italic>C. elegans</italic>.</article-title>             <source>J Neurosc Meth</source>             <volume>158</volume>             <fpage>323</fpage>             <lpage>336</lpage>          </element-citation></ref>
<ref id="pone.0011631-Huang2"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huang</surname><given-names>KM</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2008</year>             <article-title>Automated detection and analysis of foraging behavior in <italic>Caenorhabditis elegans</italic>.</article-title>             <source>J Neurosc Meth</source>             <volume>171</volume>             <fpage>153</fpage>             <lpage>164</lpage>          </element-citation></ref>
<ref id="pone.0011631-Hoshi1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hoshi</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Shingai</surname><given-names>R</given-names></name>
</person-group>             <year>2006</year>             <article-title>Computer-driven automatic identification of locomotion states in <italic>Caenorhabditis elegans</italic>.</article-title>             <source>J Neuro Meth</source>             <volume>157</volume>             <fpage>355</fpage>             <lpage>363</lpage>          </element-citation></ref>
<ref id="pone.0011631-Tsibidis1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsibidis</surname><given-names>GD</given-names></name>
<name name-style="western"><surname>Tavernarakis</surname><given-names>N</given-names></name>
</person-group>             <year>2007</year>             <article-title>Nemo: a computational tool for anayzing nematode locomotion.</article-title>             <source>BMC Neuroscience</source>             <volume>8</volume>             <fpage>86</fpage>          </element-citation></ref>
<ref id="pone.0011631-Ramot1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ramot</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Johnson</surname><given-names>BE</given-names></name>
<name name-style="western"><surname>Berry</surname><given-names>TL</given-names></name>
<name name-style="western"><surname>Carnell</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Goodman</surname><given-names>MB</given-names></name>
</person-group>             <year>2008</year>             <article-title>The parallel worm tracker: a platform for measuring average speed and drug-induced paralysis in nematodes.</article-title>             <source>PLOS One</source>             <volume>3</volume>             <fpage>e2208</fpage>          </element-citation></ref>
<ref id="pone.0011631-Roussel1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roussel</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Morton</surname><given-names>CA</given-names></name>
<name name-style="western"><surname>Finger</surname><given-names>FP</given-names></name>
<name name-style="western"><surname>Roysam</surname><given-names>B</given-names></name>
</person-group>             <year>2007</year>             <article-title>A computational model for <italic>C. elegans</italic> locomotory behavior: application to multiworm tracking.</article-title>             <source>IEEE Trans Biomed Eng</source>             <volume>54</volume>             <fpage>1786</fpage>             <lpage>1797</lpage>          </element-citation></ref>
<ref id="pone.0011631-Tsechpenakis1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsechpenakis</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Bianchi</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Metaxas</surname><given-names>DN</given-names></name>
<name name-style="western"><surname>Driscoll</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>A novel computational approach for simultaneous tracking and feature extraction of <italic>C. elegans</italic> populations in fluid environments.</article-title>             <source>IEEE Trans Biomed Eng</source>             <volume>55</volume>             <fpage>1539</fpage>             <lpage>1549</lpage>          </element-citation></ref>
<ref id="pone.0011631-Geng2"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Geng</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Baek</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Berry</surname><given-names>CC</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2003</year>             <article-title>Quantitative classification and natural clustering of <italic>Caenorhabditis elegans</italic> behavioral phenotypes.</article-title>             <source>Genetics</source>             <volume>165</volume>             <fpage>1117</fpage>             <lpage>1126</lpage>          </element-citation></ref>
<ref id="pone.0011631-Huang3"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huang</surname><given-names>KM</given-names></name>
<name name-style="western"><surname>Cosman</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Schafer</surname><given-names>WR</given-names></name>
</person-group>             <year>2009</year>             <article-title>Using articulated models for tracking multiple <italic>C. elegans</italic> in physical contact.</article-title>             <source>J Sign Process Syst</source>             <volume>55</volume>             <fpage>113</fpage>             <lpage>126</lpage>          </element-citation></ref>
<ref id="pone.0011631-Stauffer1"><label>42</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stauffer</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Grimson</surname><given-names>W</given-names></name>
</person-group>             <year>1999</year>             <article-title>Adaptive background mixture models for real-time tracking.</article-title>             <fpage>246</fpage>             <lpage>252</lpage>             <comment>In: IEEE Conference on Computer Vision and Pattern Recognition</comment>          </element-citation></ref>
<ref id="pone.0011631-Piccardi1"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Piccardi</surname><given-names>M</given-names></name>
</person-group>             <year>2004</year>             <article-title>Background subtraction techniques: a review.</article-title>             <fpage>3099</fpage>             <lpage>3104</lpage>             <comment>In: IEEE International Conference on Systems, Man and Cybernetics</comment>          </element-citation></ref>
<ref id="pone.0011631-Sznitman3"><label>44</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sznitman</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Lin</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Gupta</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Hager</surname><given-names>G</given-names></name>
</person-group>             <year>2009</year>             <article-title>Active background modeling: Actors on a stage.</article-title>             <fpage>1222</fpage>             <lpage>1228</lpage>             <comment>In: IEEE 12<italic><sup>th</sup></italic> International Conference on Computer Vision, Workshop on Visual Surveillance</comment>          </element-citation></ref>
<ref id="pone.0011631-Fleuret1"><label>45</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fleuret</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Blanchard</surname><given-names>G</given-names></name>
</person-group>             <year>2005</year>             <article-title>Pattern recognition from one example by chopping.</article-title>             <fpage>371</fpage>             <lpage>378</lpage>             <comment>In: Proceedings of the Neural Information Processing Systems conference (NIPS)</comment>          </element-citation></ref>
<ref id="pone.0011631-FeiFei1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fei-Fei</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Fergus</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Perona</surname><given-names>P</given-names></name>
</person-group>             <year>2006</year>             <article-title>One-shot learning of object categories.</article-title>             <source>IEEE Trans Pattern Analysis and Machine Intelligence</source>             <volume>28</volume>             <fpage>594</fpage>             <lpage>611</lpage>          </element-citation></ref>
<ref id="pone.0011631-Laird1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Laird</surname><given-names>NM</given-names></name>
<name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name>
<name name-style="western"><surname>Dempster</surname><given-names>AP</given-names></name>
</person-group>             <year>1997</year>             <article-title>Maximum likelihood from incomplete data via the em algorithm.</article-title>             <source>J Roy Stat Soc B</source>             <volume>39</volume>             <fpage>1</fpage>             <lpage>38</lpage>          </element-citation></ref>
<ref id="pone.0011631-Kalman1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kalman</surname><given-names>RE</given-names></name>
</person-group>             <year>1960</year>             <article-title>A new approach to linear filtering and prediction problems.</article-title>             <source>ASME J Basic Eng</source>             <volume>82</volume>             <fpage>35</fpage>             <lpage>45</lpage>          </element-citation></ref>
<ref id="pone.0011631-Isard1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Isard</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Blake</surname><given-names>A</given-names></name>
</person-group>             <year>1998</year>             <article-title>CONDENSATION-conditional density propagation for visual tracking.</article-title>             <source>Int J Comp Vis</source>             <volume>29</volume>             <fpage>5</fpage>             <lpage>28</lpage>          </element-citation></ref>
<ref id="pone.0011631-Sznitman4"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sznitman</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Jedynak</surname><given-names>B</given-names></name>
</person-group>             <year>2010</year>             <article-title>Active testing for face detection and localization.</article-title>             <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>             <volume>99</volume>             <comment>in press</comment>          </element-citation></ref>
<ref id="pone.0011631-Barrow1"><label>51</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barrow</surname><given-names>HG</given-names></name>
<name name-style="western"><surname>Tenenbaum</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Bolles</surname><given-names>RC</given-names></name>
<name name-style="western"><surname>Wolf</surname><given-names>HC</given-names></name>
</person-group>             <year>1977</year>             <article-title>Parametric correspondence and chamfer matching: Two new techniques for image matching.</article-title>             <fpage>659</fpage>             <lpage>663</lpage>             <comment>In: Proceedings of the 5th International Joint Conference on Artificial Intelligence</comment>          </element-citation></ref>
<ref id="pone.0011631-Gavrila1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gavrila</surname><given-names>DM</given-names></name>
</person-group>             <year>2007</year>             <article-title>A bayesian, exemplar-based approach to hierarchical shape matching.</article-title>             <source>IEEE Trans on Pattern Analysis and Machine Intelligence</source>             <volume>29</volume>             <fpage>1408</fpage>             <lpage>1421</lpage>          </element-citation></ref>
<ref id="pone.0011631-DublinThaler1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dublin-Thaler</surname><given-names>BJ</given-names></name>
<name name-style="western"><surname>Hofman</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Cai</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Xenias</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Spielman</surname><given-names>I</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Quantification of cell edge velocities and traction forces reveals distinct motility modules during cell spreading.</article-title>             <source>PLOS One</source>             <volume>3</volume>             <fpage>e3735</fpage>          </element-citation></ref>
<ref id="pone.0011631-Li1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Li</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Chen</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kanade</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>ED</given-names></name>
<name name-style="western"><surname>Weiss</surname><given-names>LE</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Cell population tracking and lineage construction with spatiotemporal context.</article-title>             <source>Med Image Anal</source>             <volume>12</volume>             <fpage>546</fpage>             <lpage>566</lpage>          </element-citation></ref>
<ref id="pone.0011631-Xiong1"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Xiong</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Feng</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Ji</surname><given-names>L</given-names></name>
</person-group>             <year>2006</year>             <article-title>Dynamical Gaussian mixture model for tracking elliptical living objects.</article-title>             <source>Patt Rec Lett</source>             <volume>27</volume>             <fpage>838</fpage>             <lpage>842</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>