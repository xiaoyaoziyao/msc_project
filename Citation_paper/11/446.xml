<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-12-08402</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0038011</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Anatomy and physiology</subject>
            <subj-group>
              <subject>Neurological system</subject>
              <subj-group>
                <subject>Central nervous system</subject>
                <subject>Ganglia</subject>
                <subject>Motor systems</subject>
                <subject>Nerve tissue</subject>
                <subject>Nervous system components</subject>
                <subject>Nervous system physiology</subject>
                <subject>Neural homeostasis</subject>
                <subject>Neural pathways</subject>
                <subject>Neuroanatomy</subject>
                <subject>Peripheral nervous system</subject>
                <subject>Sensory physiology</subject>
                <subject>Synapses</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Circuit models</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Neuroanatomy</subject>
              <subj-group>
                <subject>Connectomics</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Neuroimaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Computer applications</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Physiology</subject>
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
          <subject>Computer Science</subject>
        </subj-group>
      </article-categories><title-group><article-title>TrakEM2 Software for Neural Circuit Reconstruction</article-title><alt-title alt-title-type="running-head">TrakEM2 Software for Neural Circuit Reconstruction</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Cardona</surname>
            <given-names>Albert</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Saalfeld</surname>
            <given-names>Stephan</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Schindelin</surname>
            <given-names>Johannes</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Arganda-Carreras</surname>
            <given-names>Ignacio</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Preibisch</surname>
            <given-names>Stephan</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Longair</surname>
            <given-names>Mark</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Tomancak</surname>
            <given-names>Pavel</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Hartenstein</surname>
            <given-names>Volker</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Douglas</surname>
            <given-names>Rodney J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Massachusetts Institute of Technology, Boston, Massachusetts, United States of America</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>Molecular Cell and Developmental Biology Department, University of California Los Angeles, Los Angeles, California, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Samuel</surname>
            <given-names>Aravinthan</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Harvard University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">sapristi@gmail.com</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: AC SS RJD. Performed the experiments: AC SS JS IA SP ML RJD. Contributed reagents/materials/analysis tools: PT VH. Wrote the paper: AC SS RJD.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>19</day>
        <month>6</month>
        <year>2012</year>
      </pub-date><volume>7</volume><issue>6</issue><elocation-id>e38011</elocation-id><history>
        <date date-type="received">
          <day>22</day>
          <month>3</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>28</day>
          <month>4</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Cardona et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>A key challenge in neuroscience is the expeditious reconstruction of neuronal circuits. For model systems such as <italic>Drosophila</italic> and <italic>C. elegans</italic>, the limiting step is no longer the acquisition of imagery but the extraction of the circuit from images. For this purpose, we designed a software application, TrakEM2, that addresses the systematic reconstruction of neuronal circuits from large electron microscopical and optical image volumes. We address the challenges of image volume composition from individual, deformed images; of the reconstruction of neuronal arbors and annotation of synapses with fast manual and semi-automatic methods; and the management of large collections of both images and annotations. The output is a neural circuit of 3d arbors and synapses, encoded in NeuroML and other formats, ready for analysis.</p>
      </abstract><funding-group><funding-statement>This work was funded primarily by Kevan A. Martin and the Institute of Neuroinformatics, University of Zurich and ETH Zurich; and also by grant NIH 1-R01 NS054814-05 to VH and grant SNSF 31003A_132969 to AC. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="8"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>There is a growing consensus that detailed volumetric reconstructions of thousands of neurons in millimeter-scale blocks of tissue are necessary for understanding neuronal circuits <xref ref-type="bibr" rid="pone.0038011-Helmstaedter1">[1]</xref>, <xref ref-type="bibr" rid="pone.0038011-Briggman1">[2]</xref>. Modern electron microscopes (EM) with automatic image acquisition are able to deliver very large collections of image tiles <xref ref-type="bibr" rid="pone.0038011-Denk1">[3]</xref>–<xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>. Unfortunately, the problems of acquiring the data have so far been easier to solve than that of interpreting it <xref ref-type="bibr" rid="pone.0038011-Jain1">[9]</xref>, . Increasingly, neuroscience laboratories require automated tools for managing these vast EM data sets using affordable consumer desktop computers.</p>
      <p>Here, we present such a tool. It is an open source software package, named TrakEM2, that is optimised for neural circuit reconstruction from tera-scale serial section EM image data sets. The software handles all the required steps: rapid entry, organization, and navigation through tera-scale EM image collections. Semi- and automatic image registration is easily perfomed within and across sections. Efficient tools enable manipulating, visualizing, reconstructing, annotating, and measuring neuronal components embedded in the data. An ontology-controlled tree structure is used to assemble hierarchical groupings of reconstructed components in terms of biologically meaningful entities such as neurons, synapses, tracts and tissues. TrakEM2 allows millions of reconstructed entities to be manipulated in nested groups that encapsulate the desired abstract level of analysis, such as “neuron”, “compartment” or “neuronal lineage”. The end products are 3D morphological reconstructions, measurements, and neural circuits specified in <italic>NeuroML</italic> <xref ref-type="bibr" rid="pone.0038011-Gleeson1">[11]</xref> and other formats for functional analysis elsewhere.</p>
      <p>TrakEM2 has been used successfully for the reconstruction of targeted EM microvolumes of <italic>Drosophila</italic> larval central nervous system <xref ref-type="bibr" rid="pone.0038011-Cardona1">[7]</xref>, for array tomography <xref ref-type="bibr" rid="pone.0038011-Oberti1">[12]</xref>, for the reconstruction and automatic recognition of neural lineages in LSM stacks <xref ref-type="bibr" rid="pone.0038011-Cardona2">[13]</xref>, for the reconstruction of thalamo-cortical connections in the cat visual cortex <xref ref-type="bibr" rid="pone.0038011-daCosta1">[14]</xref> and for the reconstruction of the inhibitory network relating selective-orientation interneurons in a 10 Terabyte EM image data set of the mouse visual cortex <xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>, amongst others.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>From Raw Collections of 2d Images to Browsable Recomposed Sample Volumes</title>
        <p>An EM volume large enough to encapsulate significant fractions of neuronal tissue and with a resolution high enough to discern synapses presents numerous challenges for visualization, processing and annotation. The data generally consists of collections of 2d image tiles acquired from serial tissue sections (<xref ref-type="fig" rid="pone-0038011-g001">Figure 1</xref>; <xref ref-type="bibr" rid="pone.0038011-Cardona1">[7]</xref>, <xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>) or from the trimmed block face (Block-face Serial EM or SBEM, <xref ref-type="bibr" rid="pone.0038011-Denk1">[3]</xref>, <xref ref-type="bibr" rid="pone.0038011-Briggman2">[15]</xref>; focused ion beam scanning EM or FIBSEM, <xref ref-type="bibr" rid="pone.0038011-Knott1">[6]</xref>) that are collectively far larger than Random Access Memory (RAM) of common lab computers and must be loaded and unloaded on demand from file storage systems. Additional experiments on the same data sample may have generated light-microscopical image volumes that must then be overlaid on the EM images, such as in array tomography <xref ref-type="bibr" rid="pone.0038011-Oberti1">[12]</xref>, <xref ref-type="bibr" rid="pone.0038011-Micheva1">[16]</xref> or correlative calcium imaging <xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>, <xref ref-type="bibr" rid="pone.0038011-Briggman2">[15]</xref>. TrakEM2 makes browsing and annotating mixed, overlaid types of images (<xref ref-type="supplementary-material" rid="pone.0038011.s001">Figure S1</xref>) over terabyte-sized volumes fast (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Browsing large serial EM image sets”) while enabling the independent manipulation of every single image both from a point-and-click graphical user interface (GUI; <xref ref-type="fig" rid="pone-0038011-g001">Figure 1e</xref>, <xref ref-type="supplementary-material" rid="pone.0038011.s002">S2</xref>, <xref ref-type="supplementary-material" rid="pone.0038011.s003">S3</xref>, <xref ref-type="supplementary-material" rid="pone.0038011.s004">S4</xref>) and by automatic means (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Image adjustment”).</p>
        <fig id="pone-0038011-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0038011.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>From a resin block to serial 2d image montages.</title>
            <p><bold>A</bold> Serial EM is performed on a block of tissue embedded in hardened plastic resin. <bold>B</bold> Sections are imaged with multiple overlapping image tiles. <bold>C</bold> The imprecision in the positioning of the camera and the numerous non-linear deformations demand of an automatic multi-section image registration procedure that computes the best possible transformation for each tile without introducing gross deformations. <bold>D</bold> TrakEM2 operates only on original images, which are treated as read-only. A <italic>preprocessor script</italic> specified invidually for every image alters the image after loading from disk and before the rest of TrakEM2 has access to it, enabling changes of scale, of look-up table, data type, and any pixel-level operation. A <italic>Patch</italic> object encapsulates the image file path and a set of properties such as the alpha mask, the coordinate transforms (linear and non-linear image transformations) and the desired image display range and composite mode, among others. The precomputed mipmaps store most of the <italic>Patch</italic> information in compressed 8-bit files ready for display. The image for the field of view is constructed from composing multiple <italic>Patch</italic> instances according to their location and composite rules (overlay, subtract, add, multiply, difference and Colorize YCbCr), and is then filtered, if desired, for dynamic interactive image enhancement. <bold>E</bold> The TrakEM2 <italic>Display</italic> presents the field of view showing a single section and the images, segmentations and annotations present in that section. The <italic>Display</italic> provides access to tools for manipulating and analyzing all imported images and reconstructed elements.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.g001" xlink:type="simple"/>
        </fig>
        <p>The images acquired with the EM microscope represent views of tissue that has been deformed by the sectioning process, by the heat of the electron beam, by charging effects, and by the magnetic lenses. For serial sections, part of the section may be hidden away by a section fold or support-film fold (<xref ref-type="supplementary-material" rid="pone.0038011.s005">Figure S5</xref>), and counterstaining with heavy metals further increases the difficulty of the task by occluding parts of the section with accidental precipitates (<xref ref-type="supplementary-material" rid="pone.0038011.s005">Figure S5</xref>). All images require illumination adjustments (<xref ref-type="supplementary-material" rid="pone.0038011.s005">Figure S5</xref>, <xref ref-type="supplementary-material" rid="pone.0038011.s006">S6</xref>).</p>
        <p>TrakEM2 recovers the original sample present in the resin block from the images with a robust automatic multi-step image registration approach. First images are corrected for distortions induced by the EM magnetic lenses <xref ref-type="bibr" rid="pone.0038011-Kaynig1">[17]</xref>. Then, image tiles belonging to individual sections are montaged combining a linear alignment established from invariant image features (SIFT; <xref ref-type="bibr" rid="pone.0038011-Lowe1">[18]</xref>) and an elastic alignment that compensates for the remaining non-linear distortion <xref ref-type="bibr" rid="pone.0038011-Saalfeld1">[19]</xref>.</p>
        <p>Similarly, the section series are aligned by firstly using invariant features to estimate a linear transformation followed by elastic alignment to compensate for non-linear distortion. Alternatively to an immediate elastic alignment of the series of montages, feature correspondences can be used to estimate each image tile’s globally optimal pose with respect to overlapping tiles within the same section and in adjacent sections <xref ref-type="bibr" rid="pone.0038011-Saalfeld2">[20]</xref>. This method enables the reconstruction of section series from section montages that cover only a few regions of interest disconnected in the section plane but related across sections (e.g. sparse images of different branches of a neuron). The methods implemented for montaging, global tile pose estimation and elastic alignment calculate global alignments for groups of images while explicitly minimizing the local deformation applied to each single image. Only by that constraint, very large montages or series of montages can be aligned without accumulating artificial deformation <xref ref-type="bibr" rid="pone.0038011-Saalfeld1">[19]</xref>.</p>
        <p>In combination, TrakEM2’s alignment and deformation correction tools both manual and automatic allow high quality volume reconstruction from very large section series. Complex imaging arrangements are supported, including low-resolution images of large fields of view that were then complemented with high-resolution images for areas of interest, or different tilts of the same section. Tens of thousands of images are registered with an off-the-shelf computer in a few days.</p>
        <p>Both linear and non-linear transformations are expressed with a system that brings pixels from the original image space to the transformed space in one single computational step, concatenating all transformations and expressing the final transformation in the precomputed mipmap images (<xref ref-type="fig" rid="pone-0038011-g001">Figure 1d</xref>; <xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Browsing large serial EM image sets”). Additionally, the TrakEM2 GUI enables direct point-and-click manipulation of the transformation of any image in the volume, before or after the automatic registration without significant cost in data storage (relative to the dimensions of the image) or image quality (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Assembling the volume with automatic registration of image tiles” and “Manually correcting automatic image registration with affine and non-linear transformations”; <xref ref-type="supplementary-material" rid="pone.0038011.s002">Figure S2</xref>, <xref ref-type="supplementary-material" rid="pone.0038011.s003">S3</xref>).</p>
      </sec>
      <sec id="s2b">
        <title>Reconstructing a Neuronal Circuit from an Image Volume</title>
        <p>The second step in neuronal circuit reconstruction consists in identifying and labeling the neurons and synapses in the image volume. The current gold standard is computer-assisted manual labeling, either by brushing 2d areas (<xref ref-type="bibr" rid="pone.0038011-Cardona1">[7]</xref>, <xref ref-type="bibr" rid="pone.0038011-Fiala1">[21]</xref>; not practical for large volumes) or by marking skeletons <xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>, <xref ref-type="bibr" rid="pone.0038011-Briggman2">[15]</xref>, <xref ref-type="bibr" rid="pone.0038011-Helmstaedter2">[22]</xref>. Automated methods for neuronal reconstruction are currently the focus of intensive research in Computer Vision (for review see <xref ref-type="bibr" rid="pone.0038011-Jain1">[9]</xref>). TrakEM2 offers manual and semi-automatic methods for image segmentation (<xref ref-type="supplementary-material" rid="pone.0038011.s007">Figure S7</xref>) and for sketching structures with <italic>spheres</italic> and <italic>tubes</italic> (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Stick-and-ball models”; <xref ref-type="supplementary-material" rid="pone.0038011.s008">Figure S8</xref>), and interfaces with automatic image segmentation programs (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Image segmentation for 3d object reconstruction”).</p>
        <p>Manual skeletonization of a neuronal arbor requires continuous recognition operations that are not always done with full confidence given ambiguity in the image data. In our experience an all-or-nothing approach (edge or no edge, that is, to connect two parts of a neuronal arbor or not) does not sufficiently express all the information available to the human operator. Therefore TrakEM2’s <italic>skeleton</italic> data types are composed of nodes and directional edges that express parent/child relationships between nodes with a confidence value that captures the degree of certainty in the continuity of the skeleton at that edge (<xref ref-type="fig" rid="pone-0038011-g002">Figure 2</xref>). Edge confidence values are particularly useful to restrict ulterior circuit analysis to the most trustable subsets of the skeletons. Additionally each node holds a list of text annotations (“tags”) to highlight structures of interest or to label nodes as places to branch out later (e.g. with a <italic>TODO</italic> tag), and also a radius value (<italic>treeline</italic> skeleton subtype) or a 2d area (<italic>areatree</italic> skeleton subtype) to render 3d skeletons as stick models or volumes, respectively (<xref ref-type="fig" rid="pone-0038011-g002">Figure 2</xref>; <xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref>, section “Image segmentation for 3d object reconstruction”). To correct mistakes skeletons are cut or joined at any node. Node edges accept any color (e.g. to label a branch), or follow a color code that expresses betweeness-centrality (computed as in <xref ref-type="bibr" rid="pone.0038011-Brandes1">[23]</xref>) relative to other nodes, branches or synapses.</p>
        <fig id="pone-0038011-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0038011.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Neural circuit reconstruction with skeletonized neural arbors and connectors to relate them at synaptic sites.</title>
            <p><bold>A</bold> Snapshot illustrating the use of connectors to relate neural arbors. The connector in green (notice the ‘o’ node with a yellow circle around; it has three targets–it’s a polyadic insect synapse), each of which is represented within the section by a node with an arrow head that falls within the circle of each target. To the left, notice the use of text annotations to describe the synapse. <bold>B</bold> Search with regular expressions locates any objects of interest, in this case a “membrane specializations” tag in a neuronal arbor. <bold>C</bold> The tabular view for a neural arbor lists all nodes, branch nodes, end nodes or a subset whose tags match a regular expression. All columns are sortable, and clicking on each row positions the display on the node. The last column titled “Reviews” indicates which cables of the neuron have already been reviewed (in green) to correct for missing branches or synapses or other issues. <bold>D</bold> A review stack is precomputed for fast visualization of the cable of interest, each section centered on the node. The visual flow through the stack helps in catching reconstruction errors. <bold>E</bold> “Area trees” are skeleton arbors whose nodes have 2d areas associated. <bold>F</bold> 3d rendering of two “area trees”, a section of which are depicted in E. <bold>G</bold> 3d rendering of the nucleus (represented by a “ball”) and the arbor (represented by a “treeline”) of a neuron in the insect brain. <bold>H–J</bold> Cartons of the skeletons used for reconstruction. The root node is labeled with an “S”, the branch nodes with “Y” and the end nodes with “e”. In H, a “connector” relates the nodes of two arbors, with specific confidence value for the relationship. These confidence values exist on the edges that relate the arbor’s nodes as well (not shown). <bold>I</bold> Rerooting changes the perspective, but not the topology, of the tree. By convention we position the root node at the soma. <bold>J</bold> Two common and trivial operations on trees are split and merge.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.g002" xlink:type="simple"/>
        </fig>
        <p>Given the unreliability of human-based skeletonization (<italic>tracing</italic>) of neurons <xref ref-type="bibr" rid="pone.0038011-Helmstaedter2">[22]</xref>, TrakEM2 facilitates the revision of skeleton nodes. An interactive GUI table lists all skeleton nodes and sorts them by location, edge confidence or tags, allowing quick targeted review of interesting or problematic parts of the skeleton (<xref ref-type="fig" rid="pone-0038011-g002">Figure 2</xref>). To systematically review complete neuronal arbors, TrakEM2 generates sequences of images centered at each node (<italic>fly-throughs</italic>) for each skeleton branch (<xref ref-type="fig" rid="pone-0038011-g002">Figure 2</xref>) that exploit the human ability to detect small changes in optic flow: missassignments across sections are readily identified as sudden shifts in the field of view. This review method aids as well in locating unlabeled synapses and untraced branches.</p>
        <p>TrakEM2 expresses synapses with <italic>connector</italic> elements that relate areas or skeleton nodes with other areas or nodes. Each <italic>connector</italic> consists of an origin and a number of targets, each assigned a confidence value, to express from monadic to diadic and polyadic synapses (<xref ref-type="fig" rid="pone-0038011-g002">Figure 2h</xref>). To aid the systematic reconstruction of all upstream and downstream neuron partners of a specific neuron, TrakEM2 presents an interactive table that lists all the incoming and outgoing connectors of a skeleton, and who they connect to. Incomplete synaptic partners are then visited one at a time and reconstructed. All tables are dynamically updated as nodes and connectors are added to or removed from the skeletons. The resulting neuronal circuit is then exported in various formats including NeuroML <xref ref-type="bibr" rid="pone.0038011-Gleeson1">[11]</xref>.</p>
      </sec>
      <sec id="s2c">
        <title>Structuring Reconstructions Hierarchically with Semantically Meaningful Groups</title>
        <p>The reconstruction of one or a few neuronal arbors is very different to the reconstruction of a complete neuronal processing module. The main difference is the scale: the latter is generally composed of dozens or thousands of neuronal arbors. While a human operator tracks the identities of a small collection of elements with ease, the task becomes very time consuming and error prone for large collections of neurons. In our experience the cut off is at about 50 elements.</p>
        <p>Nesting arbitrary groupings of reconstructed elements collapses a collection of arbitrary reconstructions into a meaningful entity such as a neuron. For example, a neuron may be represented with a nucleus (represented by a <italic>sphere</italic>), an arbor (represented by an <italic>areatree</italic>) and a list of synapses (each represented by a <italic>connector</italic>). Large collections of neurons are grouped by modality (“sensory neurons” versus “motor neurons” or “interneurons”), or by lineage (such as “BLD5”, “DALcl2”, etc. in the fly larval brain), or by experimental condition (“GFP-labeled”, “RFP-labeled”), or by any desirable arbitrary grouping or nested groupings. Hierarchical grouping effectively reduces the complexity in the management of large collections of objects by collapsing them into high-level entities meaningful for the human researcher. These groups are application-specific and in TrakEM2 are constrained by a controlled vocabulary with the required hierarchical groups (<xref ref-type="fig" rid="pone-0038011-g003">Figure 3</xref>). With hierarchical data organization and a search tool that supports regular-expressions, TrakEM2 enables the location, manipulation, measurement (<xref ref-type="supplementary-material" rid="pone.0038011.s010">Text S1</xref> “Measurements”; <xref ref-type="supplementary-material" rid="pone.0038011.s009">Figure S9</xref>) and visualization of entities at the desired level of abstraction, be it fragments of neurons, individual neurons, a lineage of neurons, neuronal circuits, or arbitrary compartments or areas of the brain.</p>
        <fig id="pone-0038011-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0038011.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Hierarchical organization of reconstructed objects.</title>
            <p>A <italic>Template</italic> (<italic>to the left</italic>) restricts the expression of nested abstract concepts (such as “brain”, “mitochondria”, etc.) and indicates what other abstract types (e.g. a “glia” is represented by one or more “glial process” instances) or primitive types (such as “area list”, “treeline”, “connector”, “ball”, etc) they may be represented with. All elements of the <italic>Template</italic> are specific of each reconstruction project and user-defined. In the center, <italic>Project Objects</italic> displays the actual instances of the abstract, templated objects, which encapsulate and organize in many levels of abstract types the primitive segmentation types (e.g. “area list”). The hierarchical structure assigns meaning to what otherwise would be an unordered heap of primitive types. Each instance of a primitive type acquires a unique identifier (such as “#101 [area list]” ). Each group may be measured jointly, or visualized in 3d, shown/hidden, removed, etc., as illustrated in the contextual menu for the selected “mitochondria” group (<italic>highlighted in blue</italic>). To the right, the <italic>Layers</italic> list all sections in the project (a “Layer” holds the data for a single tissue section). From this graphical interface, an independent view may be opened for each section.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.g003" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>We have described the key properties of TrakEM2, an open source software that is optimized for neural circuit reconstruction from serial section EM image data sets. TrakEM2 answers the quickly growing demand for a flexible and robust application for implementing at tera-scale the workflows typical of current connectomics projects that require volumetric reconstruction, visualization, and analysis of objects observed through 2D images. In this way, TrakEM2 supports the quest of neuroscientists to obtain a complete picture of the circuits embedded in the densely connected neurons of nervous systems. Indeed, ever since Schwann’s theory of the cell and Cajal’s neuron doctrine, neuroscientists have struggled to describe the diversity of neurons in the brain and their synaptic contacts that define the neuronal circuitry underlying brain functions.</p>
      <p>The turning point in this quest occurred in 1986, when Sydney Brenner and collaborators published their monumental work, the complete wiring diagram of the nematode <italic>Caenorhabditis elegans</italic>, with only 302 neurons <xref ref-type="bibr" rid="pone.0038011-White1">[24]</xref>. The choice of organism was key to their success, given the technological means of the time. However, a quarter of a century later, no other central nervous system has been reconstructed in full.</p>
      <p>Brenner’s reconstruction of the <italic>C. elegans</italic> nervous system was performed largely without the assistance of a computer. The work consisted in photographing (with film) serial 50 nanometer sections of the nematode worm, and annotating neurons and synapses on paper prints. An early computer-based system <xref ref-type="bibr" rid="pone.0038011-Stevens1">[25]</xref> was used for three-dimensional reconstruction of a few very small volumes. The introduction of personal computers in the mid-eighties opened the way for the development of the first computer-assisted reconstruction systems such as TRAKA <xref ref-type="bibr" rid="pone.0038011-Botha1">[26]</xref> and three years later Neurolucida (<xref ref-type="bibr" rid="pone.0038011-Glaser1">[27]</xref>; MicroBrightField), bringing feasibility to computer-assisted neuronal reconstruction. Both these systems were oriented towards the reconstruction of labeled neurons at the optical level. They solved the data storage problem of the time, that very large fields of view were far too large for computerized storage, by operating on microscope stage coordinates rather than pixel coordinates in a digitized image. Meanwhile, the results of Moore’s Law, and improving electronic camera technology, have opened opportunities for storing and manipulating very large datasets of images. For large-scale serial section electron microscopy (EM) in its many variants (serial section electron tomography or SSET, <xref ref-type="bibr" rid="pone.0038011-Soto1">[28]</xref>; serial section transmission EM or ssTEM; block-face EM or SBEM <xref ref-type="bibr" rid="pone.0038011-Denk1">[3]</xref>; focused ion beam scanning EM or FIBSEM, <xref ref-type="bibr" rid="pone.0038011-Knott1">[6]</xref>), coupling live imaging with neuronal reconstruction would result in damage to, and eventually disruption of, the nanometer-thick sections, or it is not possible (such as in block-face EM or FIBSEM). Acquiring images first and then performing the analysis offline is necessary.</p>
      <p>The software IMOD <xref ref-type="bibr" rid="pone.0038011-Kremer1">[29]</xref> revolutionized EM image volume analysis with tools for visualizing and aligning the sections of image stacks, and for manually counting, measuring and modeling objects in the 3d volume. The software Reconstruct <xref ref-type="bibr" rid="pone.0038011-Fiala1">[21]</xref> catered to the special needs of neuronal reconstruction from EM, namely tools for manual and semi-automated image registration within a section (montaging, for large fields of view) and across serial sections, and tools for volumetric reconstruction and measurement of neuronal structures. The software package ir-tools <xref ref-type="bibr" rid="pone.0038011-Anderson1">[30]</xref> made new developments of the computer vision field accessible for serial EM reconstructions, including automated image montaging and contrast limited adaptive histogram equalization for image enhancement (CLAHE; <xref ref-type="bibr" rid="pone.0038011-Pizer1">[31]</xref>), among others. All these softwares evolved considerably since their publication dates and complement each other to various degrees. Originally, each was designed with specific technological problems and scientific questions in mind.</p>
      <p>TrakEM2 is deployed along with all the necessary image processing libraries with Fiji <xref ref-type="bibr" rid="pone.0038011-Schindelin1">[32]</xref>, an open source image processing application. Fiji provides automatic deployment of software updates and comprehensive documentation via a publicly accessible wiki (<ext-link ext-link-type="uri" xlink:href="http://pacific.mpi-cbg.de" xlink:type="simple">http://pacific.mpi-cbg.de</ext-link>). Fiji supports a variety of scripting languages useful for the programmatic manipulation of data structures in TrakEM2. The functionality and batch-processing capabilities of TrakEM2 are extensible at will.</p>
      <p>TrakEM2 has already been employed in a variety of applications. While originally designed for reconstructing neural circuits in anisotropic serial section EM (for example, see <xref ref-type="bibr" rid="pone.0038011-Cardona1">[7]</xref>, <xref ref-type="bibr" rid="pone.0038011-Bock1">[8]</xref>, <xref ref-type="bibr" rid="pone.0038011-daCosta1">[14]</xref>), researchers have found TrakEM2 useful for other EM modalities, for example for registering series of images from FIBSEM and annotating synapses by hand <xref ref-type="bibr" rid="pone.0038011-Kreshuk1">[33]</xref>. The segmentation tools have been used for generating a gold standard segmentation of brain tissue to compare with the output of automatic segmentation algorithms on EM images <xref ref-type="bibr" rid="pone.0038011-Kaynig2">[34]</xref>, and for reconstructing neuronal lineages <xref ref-type="bibr" rid="pone.0038011-Cardona1">[7]</xref> and organs <xref ref-type="bibr" rid="pone.0038011-Grigorian1">[35]</xref> in laser-scanning microscopy data sets.</p>
      <p>TrakEM2 must evolve as new imaging methods deliver higher-resolution data sets of ever increasing volumes. The open source nature of TrakEM2 allows any researcher to modify the program to suit specialized needs, and to incorporate implementations for novel algorithms from the computer vision and image processing fields. For example, TrakEM2 currenty exploits the anisotropic nature of serial section EM data, in which the X and Y dimensions have about 10 times higher resolution than Z (which is limited by the thickness of the section). Now, novel algorithms for tomographic reconstruction of serial sections <xref ref-type="bibr" rid="pone.0038011-Veeraraghavan1">[36]</xref> and more isotropic EM imaging with BFSSEM <xref ref-type="bibr" rid="pone.0038011-Denk1">[3]</xref> and FIBSEM <xref ref-type="bibr" rid="pone.0038011-Knott1">[6]</xref> suggest that the approach, which limits the manipulation of image data to the XY plane will need to evolve to meet this challenge. General improvements in data storage and computing capacity will be very helpful for handling the coming new kind of large isotropic high-resolution EM data sets.</p>
      <p>TrakEM2 source code is under a distributed version control system (git) that encourages forking the source code base, while retaining the capability of contributing back to the main development branch. TrakEM2 has been publicly available as open source since day one. The many contributions of interested users and developers have, and will, greatly enhance the utility of TrakEM2, for the benefit of all.</p>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Source Code</title>
        <p>TrakEM2 has been written using the Java programming language and uses numerous image processing libraries including ImageJ (Wayne Rasband), mpicbg (Stephan Saalfeld), LOCI bio-formats <xref ref-type="bibr" rid="pone.0038011-Linkert1">[37]</xref>, ImgLib (Stephan Preibisch, Stephan Saalfeld, Tobias Pietzsch and others), ImageJ 3D Viewer <xref ref-type="bibr" rid="pone.0038011-Schmid1">[38]</xref>, Stitching <xref ref-type="bibr" rid="pone.0038011-Preibisch1">[39]</xref>, bUnwarpJ <xref ref-type="bibr" rid="pone.0038011-ArgandaCarreras1">[40]</xref>, JaMa (Mathworks and NIST), postgresql-jdbc, JFreeChart (jfree.org), edu_mines_jtk (Dave Hale), Level Sets (Erwin Frise) and Simple Neurite Tracer <xref ref-type="bibr" rid="pone.0038011-Longair1">[41]</xref>, among others. The source code is released under the General Public License and is under version control with git at <ext-link ext-link-type="uri" xlink:href="http://repo.or.cz/w/TrakEM2.git" xlink:type="simple">http://repo.or.cz/w/TrakEM2.git</ext-link>. Binaries are distributed with Fiji (Schindelin et al, submitted to Nature Methods) via the automatic plugin updater.</p>
      </sec>
      <sec id="s4b">
        <title>Example EM Data</title>
        <p>The EM data used here to exemplify the use of TrakEM2 corresponds to the abdominal neuropil of the first instar larva of <italic>Drosophila</italic>, and will be made available in full elsewhere.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pone.0038011.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p><bold>Section and image compositing rules for simultaneous visualization of multiple sections or multiple channels.</bold> <bold>A</bold> Three consecutive sections (called <italic>Layer</italic> in TrakEM2 parlance), each with numerous tiles, are simultaneously rendered in red (previous), green (current) and blue (next). The gray area indicates that the overlap is very good. <bold>B</bold> The previous section is overlaid using a ‘difference’ composite: regions of the image that do not match will get highlighted in white. <bold>C</bold> RGB image tile from an antibody labeling manually registered on top of a collection of montaged EM tiles using a Color YCbCr composite. <bold>D</bold> Higher magnification of a similar region shown in C, where specific sectioned axons and dendrites are seen labeled in red or green. The overlay greatly facilitates identifying neurons in reasonably stereotypical animals such as <italic>Drosophila</italic>.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s002" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p><bold>Manual affine transform of collections of image tiles.</bold> <bold>A</bold> The affine transform mode is used for interactive multi-tile transformations. In conjunction with multi-section visualization (the editable section in green, and the previous, reference section in red–the best overlap in yellow), a section is manually aligned to the previous–a capability most useful for correcting or refining the results of automatic registration algorithms. <italic>A2</italic> Enlarged inset, revealing the lack of overlap of the two adjacent sections. Notice near top right how the green section doesn’t overlap with the red section. Three landmarks that define an affine transformation are used to interactively adjust the pose of all tiles in the section. <bold>B, B2</bold> After manually dragging the landmark the two sections now overlap more accurately. The transformation is then propagated to subsequent sections to preserve the relative pose of all tiles (see menu snapshot in <bold>A</bold>).</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s003" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p><bold>Manual non-linear transform of collections of image tiles for fine cross-section alignment.</bold> <bold>A,B</bold> Two consecutive sections numbered 344 and 345 present an artefactual stretch, as indicated by the widening of the marked profiles (in white). <bold>C,D</bold> The manual non-linear transformation mode is used here in conjunction with the transparent section overlay (notice the slider above the green panel in <bold>C</bold>) to reveal the local misalignment. The inset in <bold>C,D</bold> indicates the local transformation performed by dragging numerous landmarks.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s004" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p><bold>Expressing image transformations without duplicating the original images by using alpha masks.</bold> Duplicating images has a huge cost in data storage which TrakEM2 avoids by using highly compressible alpha masks and precomputed mipmaps stored with lossy compression. <bold>A</bold> Images present borders which are apparent when overlapping (red arrowheads). An alpha mask with zero values for the borders (see adjacent cartoon) removes the border from the field of view. A1 and A2 images show the rectangular region marked in red in the cartoons. <bold>B</bold> Manual non-linear transformations before (A1) and after (A2) corrects a section fold in an image tile. <italic>Inset</italic>, the alpha mask of the corrected tile. <bold>C</bold> Alternatively, the manual image splitting mode cuts image tiles in two or more parts using a polygonal line (C1), so that each half is now an independent <italic>Patch</italic> object that represents a tile, each relying on the original image but with a different alpha mask (inset in C2). Rigid image registration may now proceed, visualized in C3 by overlaying two consecutive sections. Data in B and C courtesy of Ian Meinertzhagen, Dalhousie University (Canada).</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s005" xlink:type="simple">
        <label>Figure S5</label>
        <caption>
          <p><bold>Correctable noise on EM images.</bold> <bold>A1, A2</bold> A large blob occludes information on an EM image when the display range is adjusted for the whole image (A1), but reveals its content when CLAHE is applied (A2). <bold>B1-4</bold> A support-film fold generates a dark band (B1) whose content is discernible at a lower value region of the histogram (inset in B2). Applying CLAHE with a small window partially solves the problem (B3) but composing the image from both ranges restores it best (B4).</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s006" xlink:type="simple">
        <label>Figure S6</label>
        <caption>
          <p><bold>On-the-fly processing of the field of view for enhanced contrast.</bold> The live filter tab of the display offers a few filters, to adjust <bold>A</bold> the display range; invert the image (not shown) or <bold>B</bold> CLAHE. Yellow rectangle indicates the original view without filters.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s007" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s007" xlink:type="simple">
        <label>Figure S7</label>
        <caption>
          <p><bold>Volumetric reconstruction with series of complex 2d areas or “area lists”.</bold> The “Z space” tab lists all segmentation objects that exist in 3d. <bold>A</bold> With the <italic>brush</italic> tool, a selected “area list” instance is painted in yellow (notice the mouse pointer with circle), labeling the sectioned profile of a neuron. The selected object (listed in the cyan panel) may be visible or hidden, locked, or linked to the underlying images. <bold>B</bold> Labeled meshes are rendered in 3d by generating a mesh of triangles with marching cubes. <bold>C</bold> Dense reconstruction of a cube of neuropil.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s008" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s008" xlink:type="simple">
        <label>Figure S8</label>
        <caption>
          <p><bold>Sketching and quantifying neural tissue with spheres and tubes.</bold> <bold>A,B</bold> Two sections with a “ball” to represent the nucleus and a “pipe” to model the main process of a monopolar insect neuron. The colors indicate relative depth: red means below the current section and blue above. <bold>C</bold> 3d representation of the “ball” and “pipe” traversing multiple sections. <bold>D</bold> Usage of “ball” sketching type for quantifying the number of synaptic vesicles. The synaptic cleft is modeled with an “area list”. <bold>E</bold> 3d representation of the synaptic vesicles and cleft modeled in D. <bold>F</bold> Results table with the count and position of labeled vesicles. Data in D,E courtesy of Graham Knott, EPFL (Switzerland).</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s009" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s009" xlink:type="simple">
        <label>Figure S9</label>
        <caption>
          <p><bold>Measurements.</bold> <bold>A</bold> Example of a “connector” instance, expressing a synapse between an axon (large profile at lower left with numerous microtubules) whose tree is tagged “presynaptic site”, with numerous terminal dendrites (small target circles, one in red indicating it’s in the previous section). <bold>B</bold> Measurement of the distances from the root node (the soma, by convention) to all nodes labeled “presynaptic site” like in A. The inset schematizes the measurements (dotted red lines from “root” to “nodes labeled as “pre”). <bold>C</bold> A double disector is used together with an overlay grid (in green, cell size is one micron) to detect the number of objects appearing new in the next section (objects labeled as little yellow squares, with blue circles for the position of the same object in the next section, if present). The table shows the list of all marked objects. Note how “3″ occurs only once, indicating that it appears new in the next section. See <xref ref-type="bibr" rid="pone.0038011-Geinisman1">[42]</xref> for details on the double disector technique. <bold>D</bold> The built-in scripting editor in Fiji shows a small python script to extract statistics on the distances of synaptic vesicles (modeled with a “ball”) to a synaptic cleft (modeled with an “area list”), as shown in Supplemental Figure 11 d, e.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0038011.s010" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0038011.s010" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>
            <bold>Supplemental Text containing detailed information on various aspects of the TrakEM2 software, including image registration, dealing with noise, alpha masks, manual segmentation with areas, balls and pipe objects, and measurements.</bold>
          </p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>A.C. thanks Kevan A. Martin and the Institute of Neuroinformatics for generous support and encouragement. The authors thank Benjamin Schmid, Larry Lindsey, Verena Kaynig, Davi Bock, Jena-Yves Tinevez, Curtis Rueden, Kai Uwe Barthel and Jacques Pecreaux for contributing source code, and Wayne Rasband, Nuno da Costa, German Koestinger, Rita Bopp, John Anderson, Richard D. Fetter, Wei-Chung Allen Lee, Daniele Oberti, Martin O’Reilly, Bjorn Quast, J.C Rah, Xavier Heiligenstein, Lou Scheffer, Dan Bumbarger, Casey Schneider-Mizell, Kenny Floria, Alexander Seitz, Steve Butterfield, Alexander Böhm, Parvez Ahammad, Nitai Steinberg, Raju Tomer, Marta Rivera-Alba, Wayne Pereanu, Janet Altman, Paul Wieringa, Siaumin Fung and Leon Espinosa, among others, for feedback, testing and ideas. A.C. thanks Gerald M. Rubin and Mitya Chklovskii (both at HHMI Janelia Farm), the Max Planck Institute of Molecular Cell Biology and Genetics and the Institute of Neuroinformatics for generously hosting hackathons where key parts of TrakEM2 were developed. We thank <ext-link ext-link-type="uri" xlink:href="http://repo.or.cz" xlink:type="simple">http://repo.or.cz</ext-link> for hosting the source code.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0038011-Helmstaedter1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Helmstaedter</surname><given-names>M</given-names></name><name name-style="western"><surname>Briggman</surname><given-names>K</given-names></name><name name-style="western"><surname>Denk</surname><given-names>W</given-names></name></person-group>             <year>2008</year>             <article-title>3D structural imaging of the brain with photons and electrons.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>18</volume>             <fpage>633</fpage>             <lpage>41</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Briggman1">
        <label>2</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Briggman</surname><given-names>K</given-names></name><name name-style="western"><surname>Bock</surname><given-names>D</given-names></name></person-group>             <year>2011</year>             <article-title>Volume electron microscopy for neuronal circuit reconstruction.</article-title>             <source>Curr Opin Neurobiol: [Nov 23 Epub ahead of print]</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Denk1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Denk</surname><given-names>W</given-names></name><name name-style="western"><surname>Horstmann</surname><given-names>H</given-names></name></person-group>             <year>2004</year>             <article-title>Serial block–face scanning electron microscopy to reconstruct threedimensional tissue nanostructure.</article-title>             <source>PLoS Biology</source>             <volume>2</volume>             <fpage>e329</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Suloway1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Suloway</surname><given-names>C</given-names></name><name name-style="western"><surname>Pulokas</surname><given-names>J</given-names></name><name name-style="western"><surname>Fellmann</surname><given-names>D</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>A</given-names></name><name name-style="western"><surname>Guerra</surname><given-names>F</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Automated molecular microscopy: the new Leginon system.</article-title>             <source>Journal of Structural Biology</source>             <volume>151</volume>             <fpage>41</fpage>             <lpage>60</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Mastronarde1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mastronarde</surname><given-names>D</given-names></name></person-group>             <year>2005</year>             <article-title>Automated electron microscope tomography using robust prediction of specimen movements.</article-title>             <source>J Struct Biol</source>             <volume>152</volume>             <fpage>36</fpage>             <lpage>51</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Knott1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Knott</surname><given-names>G</given-names></name><name name-style="western"><surname>Marchman</surname><given-names>H</given-names></name><name name-style="western"><surname>Wall</surname><given-names>D</given-names></name><name name-style="western"><surname>Lich</surname><given-names>B</given-names></name></person-group>             <year>2008</year>             <article-title>Serial Section Scanning Electron Microscopy of Adult Brain Tissue Using Focused Ion Beam Milling.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>2959</fpage>             <lpage>64</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Cardona1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cardona</surname><given-names>A</given-names></name><name name-style="western"><surname>Saalfeld</surname><given-names>S</given-names></name><name name-style="western"><surname>Preibisch</surname><given-names>S</given-names></name><name name-style="western"><surname>Schmid</surname><given-names>B</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>A</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>An integreated micro- and macroarchitectural analysis of the Drosophila brain by computer-assisted serial section electron microscopy.</article-title>             <source>PLoS Biology</source>             <volume>8</volume>             <fpage>e100050</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Bock1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bock</surname><given-names>D</given-names></name><name name-style="western"><surname>Lee</surname><given-names>W</given-names></name><name name-style="western"><surname>Kerlin</surname><given-names>A</given-names></name><name name-style="western"><surname>Andermann</surname><given-names>M</given-names></name><name name-style="western"><surname>Hood</surname><given-names>G</given-names></name><etal/></person-group>             <year>2011</year>             <article-title>Network anatomy and in vivo physiology of visual cortical neurons.</article-title>             <source>Nature</source>             <volume>47</volume>             <fpage>177</fpage>             <lpage>82</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Jain1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jain</surname><given-names>V</given-names></name><name name-style="western"><surname>Seung</surname><given-names>H</given-names></name><name name-style="western"><surname>Turaga</surname><given-names>C</given-names></name></person-group>             <year>2010</year>             <article-title>Machines that learn to segment images: a crucial technology for connectomics.</article-title>             <source>Current Opinion in Neurobiology</source>             <volume>20</volume>             <fpage>653</fpage>             <lpage>66</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Chklovskii1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name><name name-style="western"><surname>Vitaladevuni</surname><given-names>S</given-names></name><name name-style="western"><surname>Scheffer</surname><given-names>L</given-names></name></person-group>             <year>2010</year>             <article-title>Semi-automated reconstruction of neural circuits using electron microscopy.</article-title>             <source>Current Opinion in Neurobiology</source>             <volume>20</volume>             <fpage>667</fpage>             <lpage>75</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Gleeson1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gleeson</surname><given-names>P</given-names></name><name name-style="western"><surname>Crook</surname><given-names>S</given-names></name><name name-style="western"><surname>Cannon</surname><given-names>RC</given-names></name><name name-style="western"><surname>Hines</surname><given-names>ML</given-names></name><name name-style="western"><surname>Billings</surname><given-names>GO</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Neuroml: A language for describing data driven models of neurons and networks with a high degree of biological detail.</article-title>             <source>PLoS Comput Biol</source>             <volume>6</volume>             <fpage>e1000815</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Oberti1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Oberti</surname><given-names>D</given-names></name><name name-style="western"><surname>Kirschmann</surname><given-names>MA</given-names></name><name name-style="western"><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group>             <year>2010</year>             <article-title>Correlative microscopy of densely labeled projection neurons using neural tracers.</article-title>             <source>Frontiers in Neuroanatomy</source>             <volume>4</volume>             <fpage>24</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Cardona2">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cardona</surname><given-names>A</given-names></name><name name-style="western"><surname>Saalfeld</surname><given-names>S</given-names></name><name name-style="western"><surname>Arganda Carreras</surname><given-names>I</given-names></name><name name-style="western"><surname>Pereanu</surname><given-names>W</given-names></name><name name-style="western"><surname>Schindelin</surname><given-names>J</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Identifying neuronal lineages of Drosophila by sequence analysis of axon tracts.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>7538</fpage>             <lpage>53</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-daCosta1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>da Costa</surname><given-names>N</given-names></name><name name-style="western"><surname>Martin</surname><given-names>K</given-names></name></person-group>             <year>2011</year>             <article-title>How thalamus connects to spiny stellate cells in the cat’s visual cortex.</article-title>             <source>J Neurosci</source>             <volume>31</volume>             <fpage>2925</fpage>             <lpage>37</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Briggman2">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Briggman</surname><given-names>KL</given-names></name><name name-style="western"><surname>Helmstaedter</surname><given-names>M</given-names></name><name name-style="western"><surname>Denk</surname><given-names>W</given-names></name></person-group>             <year>2011</year>             <article-title>Wiring specificity in the direction-selectivity circuit of the retina.</article-title>             <source>Nature</source>             <volume>471</volume>             <fpage>183</fpage>             <lpage>8</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Micheva1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Micheva</surname><given-names>K</given-names></name><name name-style="western"><surname>Smith</surname><given-names>S</given-names></name></person-group>             <year>2007</year>             <article-title>Array tomography: a new tool for imaging the molecular architecture and ultrastructure of neural circuits.</article-title>             <source>Neuron</source>             <volume>55</volume>             <fpage>25</fpage>             <lpage>36</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Kaynig1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaynig</surname><given-names>V</given-names></name><name name-style="western"><surname>Fischer</surname><given-names>B</given-names></name><name name-style="western"><surname>Muller</surname><given-names>E</given-names></name><name name-style="western"><surname>Buhmann</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Fully Automatic Stitching and Distortion Correction of Transmission Electron Microscope Images.</article-title>             <source>Journal of Structural Biology</source>             <volume>171</volume>             <fpage>163</fpage>             <lpage>73</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Lowe1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lowe</surname><given-names>DG</given-names></name></person-group>             <year>2004</year>             <article-title>Distinctive image features from scale-invariant keypoints.</article-title>             <source>International Journal of Computer Vision</source>             <volume>60</volume>             <fpage>91</fpage>             <lpage>110</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Saalfeld1">
        <label>19</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Saalfeld</surname><given-names>S</given-names></name><name name-style="western"><surname>Fetter</surname><given-names>R</given-names></name><name name-style="western"><surname>Cardona</surname><given-names>A</given-names></name><name name-style="western"><surname>Tomancak</surname><given-names>P</given-names></name></person-group>             <year>2012</year>             <article-title>Elastic volume reconstruction from series of ultra-thin microscopy sections.</article-title>             <source>Nature Methods in press</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Saalfeld2">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Saalfeld</surname><given-names>S</given-names></name><name name-style="western"><surname>Cardona</surname><given-names>A</given-names></name><name name-style="western"><surname>Hartenstein</surname><given-names>V</given-names></name><name name-style="western"><surname>Tomancak</surname><given-names>P</given-names></name></person-group>             <year>2010</year>             <article-title>As-rigid-as-possible mosaicking and serial section registration of large ssTEM datasets.</article-title>             <source>Bioinformatics</source>             <volume>26</volume>             <fpage>i57</fpage>             <lpage>i63</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Fiala1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fiala</surname><given-names>J</given-names></name></person-group>             <year>2005</year>             <article-title>Reconstruct: a free editor for serial section microscopy.</article-title>             <source>J Microscopy</source>             <volume>218</volume>             <fpage>52</fpage>             <lpage>61</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Helmstaedter2">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Helmstaedter</surname><given-names>M</given-names></name><name name-style="western"><surname>Briggman</surname><given-names>K</given-names></name><name name-style="western"><surname>Denk</surname><given-names>W</given-names></name></person-group>             <year>2011</year>             <article-title>High-accuracy neurite reconstruction for highthroughput neuroanatomy.</article-title>             <source>Nature Neuroscience</source>             <volume>14</volume>             <fpage>1081</fpage>             <lpage>8</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Brandes1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brandes</surname><given-names>U</given-names></name></person-group>             <year>2001</year>             <article-title>A faster algorithm for betweenness centrality.</article-title>             <source>Journal of Mathematical Sociology</source>             <volume>25</volume>             <fpage>163</fpage>             <lpage>77</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-White1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>White</surname><given-names>JG</given-names></name><name name-style="western"><surname>Southgate</surname><given-names>E</given-names></name><name name-style="western"><surname>Thomson</surname><given-names>JN</given-names></name><name name-style="western"><surname>Brenner</surname><given-names>S</given-names></name></person-group>             <year>1986</year>             <article-title>The Structure of the Nervous System of the Nematode Caenorhabditis elegans.</article-title>             <source>Phil Trans R Soc Lond B</source>             <volume>314</volume>             <fpage>1</fpage>             <lpage>340</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Stevens1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stevens</surname><given-names>B</given-names></name><name name-style="western"><surname>White</surname><given-names>J</given-names></name></person-group>             <year>1979</year>             <article-title>Computer reconstruction of mitochondria from yeast.</article-title>             <source>Meth Enzym</source>             <volume>56</volume>             <fpage>718</fpage>             <lpage>728</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Botha1">
        <label>26</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Botha</surname><given-names>D</given-names></name><name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name><name name-style="western"><surname>Martin</surname><given-names>K</given-names></name></person-group>             <year>1987</year>             <article-title>TRAKA: a microcomputer-assisted system for digitizing the three-dimensional structure of neurones.</article-title>             <source>J Physiol 394: 16 P</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Glaser1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Glaser</surname><given-names>JR</given-names></name><name name-style="western"><surname>Glaser</surname><given-names>EM</given-names></name></person-group>             <year>1990</year>             <article-title>Neuron imaging with neurolucida–a PC-based system for image combining microscopy.</article-title>             <source>Computerized Medical Imaging Graphics</source>             <volume>14</volume>             <fpage>307</fpage>             <lpage>17</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Soto1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Soto</surname><given-names>GE</given-names></name><name name-style="western"><surname>Young</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Martone</surname><given-names>ME</given-names></name><name name-style="western"><surname>Deerinck</surname><given-names>TJ</given-names></name><name name-style="western"><surname>Lamont</surname><given-names>S</given-names></name><etal/></person-group>             <year>1994</year>             <article-title>Serial Section Electron Tomography: A Method for Three-Dimensional Reconstruction of Large Structures.</article-title>             <source>NeuroImage</source>             <volume>1</volume>             <fpage>230</fpage>             <lpage>243</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Kremer1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kremer</surname><given-names>J</given-names></name><name name-style="western"><surname>Mastronarde</surname><given-names>D</given-names></name><name name-style="western"><surname>McIntosh</surname><given-names>J</given-names></name></person-group>             <year>1996</year>             <article-title>Computer visualization of three-dimensional image data using IMOD.</article-title>             <source>J Struct Biol</source>             <volume>116</volume>             <fpage>71</fpage>             <lpage>76</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Anderson1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>JR</given-names></name><name name-style="western"><surname>Jones</surname><given-names>BW</given-names></name><name name-style="western"><surname>Yang</surname><given-names>JH</given-names></name><name name-style="western"><surname>Shaw</surname><given-names>MV</given-names></name><name name-style="western"><surname>Watt</surname><given-names>CB</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>A computational framework for ultrastructural mapping of neural circuitry.</article-title>             <source>PLoS Biol</source>             <volume>7</volume>             <fpage>e1000074</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Pizer1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pizer</surname><given-names>SM</given-names></name><name name-style="western"><surname>Amburn</surname><given-names>EP</given-names></name><name name-style="western"><surname>Austin</surname><given-names>JD</given-names></name><name name-style="western"><surname>Cromartie</surname><given-names>R</given-names></name><name name-style="western"><surname>Geselowitz</surname><given-names>A</given-names></name><etal/></person-group>             <year>1987</year>             <article-title>Adaptive histogram equalization and its variations, Computer Vision, Graphics, and Image Processing”</article-title>             <source>Computer Vision, Graphics and Image Processing</source>             <volume>39</volume>             <fpage>355</fpage>             <lpage>68</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Schindelin1">
        <label>32</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schindelin</surname><given-names>J</given-names></name><name name-style="western"><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name name-style="western"><surname>Frise</surname><given-names>E</given-names></name><name name-style="western"><surname>Kaynig</surname><given-names>V</given-names></name><name name-style="western"><surname>Longair</surname><given-names>M</given-names></name><etal/></person-group>             <year>2012</year>             <article-title>Fiji - an open source platform for biological image analysis.</article-title>             <source>Nature Methods in press</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Kreshuk1">
        <label>33</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kreshuk</surname><given-names>A</given-names></name><name name-style="western"><surname>Straehle</surname><given-names>C</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>C</given-names></name><name name-style="western"><surname>Koethe</surname><given-names>U</given-names></name><name name-style="western"><surname>Knott</surname><given-names>G</given-names></name><etal/></person-group>             <year>2011</year>             <article-title>Automated segmentation of synapses in 3D EM data.</article-title>             <source>ISBI</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Kaynig2">
        <label>34</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaynig</surname><given-names>V</given-names></name><name name-style="western"><surname>Fischer</surname><given-names>B</given-names></name><name name-style="western"><surname>Muller</surname><given-names>E</given-names></name><name name-style="western"><surname>Buhmann</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Neuron Geometry Extraction by Perceptual Grouping in ssTEM Images.</article-title>             <source>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>             <comment>(CVPR).</comment>          </element-citation>
      </ref>
      <ref id="pone.0038011-Grigorian1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grigorian</surname><given-names>M</given-names></name><name name-style="western"><surname>Mandal</surname><given-names>L</given-names></name><name name-style="western"><surname>Hakimi</surname><given-names>M</given-names></name><name name-style="western"><surname>Ortiz</surname><given-names>I</given-names></name><name name-style="western"><surname>Hartenstein</surname><given-names>V</given-names></name></person-group>             <year>2011</year>             <article-title>The convergence of Notch and MAPK signaling specifies the blood progenitor fate in the Drosophila mesoderm.</article-title>             <source>Developmental Biology</source>             <volume>353</volume>             <fpage>105</fpage>             <lpage>18</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Veeraraghavan1">
        <label>36</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Veeraraghavan</surname><given-names>A</given-names></name><name name-style="western"><surname>Genkin</surname><given-names>A</given-names></name><name name-style="western"><surname>Vitaladevuni</surname><given-names>S</given-names></name><name name-style="western"><surname>Scheffer</surname><given-names>L</given-names></name><name name-style="western"><surname>Xu</surname><given-names>S</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Increasing Depth Resolution of Electron Microscopy of Neural Circuits Using Sparse Tomographic Reconstruction.</article-title>             <source>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>             <comment>(CVPR).</comment>          </element-citation>
      </ref>
      <ref id="pone.0038011-Linkert1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Linkert</surname><given-names>M</given-names></name><name name-style="western"><surname>Rueden</surname><given-names>CT</given-names></name><name name-style="western"><surname>Allan</surname><given-names>C</given-names></name><name name-style="western"><surname>Burel</surname><given-names>JM</given-names></name><name name-style="western"><surname>Moore</surname><given-names>W</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Metadata matters: access to image data in the real world.</article-title>             <source>J Cell Biol</source>             <volume>189</volume>             <fpage>777</fpage>             <lpage>82</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Schmid1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schmid</surname><given-names>B</given-names></name><name name-style="western"><surname>Schindelin</surname><given-names>J</given-names></name><name name-style="western"><surname>Cardona</surname><given-names>A</given-names></name><name name-style="western"><surname>Longair</surname><given-names>M</given-names></name><name name-style="western"><surname>Heisenberg</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>A high-level 3 D visualization API for Java and ImageJ.</article-title>             <source>BMC Bioinformatics</source>             <volume>11</volume>             <fpage>274</fpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-Preibisch1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Preibisch</surname><given-names>S</given-names></name><name name-style="western"><surname>Saalfeld</surname><given-names>S</given-names></name><name name-style="western"><surname>Tomancak</surname><given-names>P</given-names></name></person-group>             <year>2009</year>             <article-title>Globally optimal stitching of tiled 3D microscopic image acquisitions.</article-title>             <source>Bioinformatics</source>             <volume>25</volume>             <fpage>1463</fpage>             <lpage>5</lpage>          </element-citation>
      </ref>
      <ref id="pone.0038011-ArgandaCarreras1">
        <label>40</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name name-style="western"><surname>Sorzano</surname><given-names>COS</given-names></name><name name-style="western"><surname>Marabini</surname><given-names>R</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Consistent and elastic registration of histological sections using vector-spline regularization.</article-title>             <source>In: Computer Vision Approaches to Medical Image Analysis. Berlin/Heidelberg, GER: Springer, volume 4241 of Lecture Notes in Computer Science, 85–95.</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Longair1">
        <label>41</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Longair</surname><given-names>M</given-names></name><name name-style="western"><surname>Baker</surname><given-names>D</given-names></name><name name-style="western"><surname>Armstrong</surname><given-names>J</given-names></name></person-group>             <year>2011</year>             <article-title>Simple Neurite Tracer: Open Source software for reconstruction, visualization and analysis of neuronal processes.</article-title>             <source>Bioinformatics</source>          </element-citation>
      </ref>
      <ref id="pone.0038011-Geinisman1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Geinisman</surname><given-names>Y</given-names></name><name name-style="western"><surname>Gundersen</surname><given-names>H</given-names></name><name name-style="western"><surname>van der Zee</surname><given-names>E</given-names></name><name name-style="western"><surname>West</surname><given-names>M</given-names></name></person-group>             <year>1996</year>             <article-title>Unbiased stereological estimation of the total numberof synapses in a brain region.</article-title>             <source>Journal of Neurocytology</source>             <volume>25</volume>             <fpage>805</fpage>             <lpage>19</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>