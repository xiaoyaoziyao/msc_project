<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0188562</article-id>
<article-id pub-id-type="publisher-id">PONE-D-16-46581</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Short-term memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Short-term memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Recall (memory)</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Recall (memory)</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Synaptic plasticity</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Developmental neuroscience</subject><subj-group><subject>Synaptic plasticity</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject><subj-group><subject>Signaling networks</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Cortical computations via transient attractors</article-title>
<alt-title alt-title-type="running-head">Cortical computations via transient attractors</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0914-8450</contrib-id>
<name name-style="western">
<surname>Rourke</surname>
<given-names>Oliver L. C.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Butts</surname>
<given-names>Daniel A.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Program in Applied Mathematics, Statistics and Scientific Computation, University of Maryland, College Park, MD, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Biology and Program in Neuroscience and Cognitive Science, University of Maryland, College Park, MD, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Bensmaia</surname>
<given-names>Sliman J.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Chicago, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">orourke@math.umd.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>7</day>
<month>12</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<year>2017</year>
</pub-date>
<volume>12</volume>
<issue>12</issue>
<elocation-id>e0188562</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>11</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>11</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Rourke, Butts</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0188562"/>
<abstract>
<p>The ability of sensory networks to transiently store information on the scale of seconds can confer many advantages in processing time-varying stimuli. How a network could store information on such intermediate time scales, between typical neurophysiological time scales and those of long-term memory, is typically attributed to persistent neural activity. An alternative mechanism which might allow for such information storage is through temporary modifications to the neural connectivity which decay on the same second-long time scale as the underlying memories. Earlier work that has explored this method has done so by emphasizing one attractor from a limited, pre-defined set. Here, we describe an alternative, a Transient Attractor network, which can learn any pattern presented to it, store several simultaneously, and robustly recall them on demand using targeted probes in a manner reminiscent of Hopfield networks. We hypothesize that such functionality could be usefully embedded within sensory cortex, and allow for a flexibly-gated short-term memory, as well as conferring the ability of the network to perform automatic de-noising, and separation of input signals into distinct perceptual objects. We demonstrate that the stored information can be refreshed to extend storage time, is not sensitive to noise in the system, and can be turned on or off by simple neuromodulation. The diverse capabilities of transient attractors, as well as their resemblance to many features observed in sensory cortex, suggest the possibility that their actions might underlie neural processing in many sensory areas.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>National Science Foundation (US)</institution>
</funding-source>
<award-id>IIS-1350990</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Butts</surname>
<given-names>Daniel A.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work supported by National Science Foundation grant IIS-1350990, URL: <ext-link ext-link-type="uri" xlink:href="https://www.nsf.gov/" xlink:type="simple">https://www.nsf.gov/</ext-link>.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="1"/>
<page-count count="16"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The real world “causes” of sensory inputs usually persist for much longer than the time scales of neural processing in sensory areas. As a result, there is great utility for neural and circuit mechanisms within sensory cortex that can hold information for several seconds, much longer than the timescale of neural integration. Storage of information on this time scale is commonly addressed in the context of “short-term memory” [<xref ref-type="bibr" rid="pone.0188562.ref001">1</xref>], but there is more general utility for seconds-long storage of information. For example, such aggregation of information over time can be used to segregate auditory stimuli into perceptual auditory objects [<xref ref-type="bibr" rid="pone.0188562.ref002">2</xref>]. Similarly, features of visual objects can be assembled over time using such associations despite temporary occlusions and visual noise [<xref ref-type="bibr" rid="pone.0188562.ref003">3</xref>].</p>
<p>The most common models of short-term memory rely on the concept of a “persistent attractor” [<xref ref-type="bibr" rid="pone.0188562.ref004">4</xref>,<xref ref-type="bibr" rid="pone.0188562.ref005">5</xref>]. A network with a fixed set of recurrent connections can support “attractors”, which correspond to particular patterns of activity that remain stable or decay slowly with seconds-long time scales. In this context, placing the network in one of these attractors (via inputs) can result in short-term memory, which can be ‘recalled’ by observing the activity at a later time (before the attractor decays). Persistent activity is typically maintained by a combination of excitatory and inhibitory activity [<xref ref-type="bibr" rid="pone.0188562.ref006">6</xref>,<xref ref-type="bibr" rid="pone.0188562.ref007">7</xref>], and persistent states can even exist in random networks with particular properties [<xref ref-type="bibr" rid="pone.0188562.ref008">8</xref>]. The unifying feature of persistent attractor networks is that information is stored in neural activity itself, thus keeping it readily accessible.</p>
<p>The persistence of memory-specific neural activity in certain cortical regions during short-term memory tasks has been cited as evidence supporting the persistent attractor hypothesis for short-term memory [<xref ref-type="bibr" rid="pone.0188562.ref009">9</xref>,<xref ref-type="bibr" rid="pone.0188562.ref010">10</xref>]. More recently, however, it has been shown that this activity is not necessary for the persistence of the underlying memories [<xref ref-type="bibr" rid="pone.0188562.ref005">5</xref>,<xref ref-type="bibr" rid="pone.0188562.ref011">11</xref>,<xref ref-type="bibr" rid="pone.0188562.ref012">12</xref>], and that some form of short-term memory also occurs in the sensory cortices themselves [<xref ref-type="bibr" rid="pone.0188562.ref013">13</xref>–<xref ref-type="bibr" rid="pone.0188562.ref015">15</xref>]. An alternative location for the storage of information about recent inputs is in the local connectivity within the network itself. Indeed, such memory storage is implicit in models of long-term memory [<xref ref-type="bibr" rid="pone.0188562.ref016">16</xref>], where memories are encoded in the excitatory connectivity which is established using a simple form of associative plasticity. Such a scheme could also be used for short-term memory if such changes in synaptic connectivity were temporary, allowing for the short-term preservation of information within the network without affecting the network’s long-term structure [<xref ref-type="bibr" rid="pone.0188562.ref017">17</xref>–<xref ref-type="bibr" rid="pone.0188562.ref020">20</xref>]. The temporary change would support a particular attractor in the presence of appropriate inputs [<xref ref-type="bibr" rid="pone.0188562.ref021">21</xref>], thus allowing for memory recall over this period. We label such attractors ‘transient’ as they only exist during appropriate input and due to relevant changes to network connectivity (which are themselves temporary).</p>
<p>Here, we propose transient attractors as a unifying mechanism within cortical networks that can support multiple types of computation that require combining information across time scales longer than those of the underlying neurons (similar to another recently published model [<xref ref-type="bibr" rid="pone.0188562.ref022">22</xref>]). We first demonstrate how a transient attractor functions in the context of a classic short-term memory task. Several memories can be stored in the network structure, allowing for their recall in the presence of suitable inputs. These memories then fade over several seconds. The same network can be used to extract information from time varying stimuli, specifically in the tasks of stream segregation and signal de-noising. We finish by considering some issues that impact the various uses of transient attractors, including transient attractor maintenance, the effect of top-down attention and the overall robustness of the network.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>We consider here a simple form of a transient attractor network (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1A</xref>), which demonstrates the basic behavior without requiring intricate models of any one process. To this end, each neuron’s activity is summarized by a single, continuous variable, the firing rate (<italic>y</italic><sub><italic>i</italic></sub> (<italic>t</italic>) for neuron <italic>i</italic> at time <italic>t</italic>). This is calculated using a standard firing rate model (see <xref ref-type="sec" rid="sec013">Methods</xref>) that integrates recurrent excitation and inhibition, along with feedforward inputs which represent the stimulus. Short-term memory is supported within the network by varying the recurrent excitatory currents.</p>
<fig id="pone.0188562.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Transient attractors in single layer network via associative weight modifications.</title>
<p>(A) Network structure. (B) When presented with stimulus, recurrent connections between simultaneously active neurons are strengthened. (C) Stimulus: two patterns shown successively at 4 Hz, capped at beginning and end by probe (D) Activity of excitatory neurons in response to stimulus (E) Weight changes for representative sample of recurrent connections. (F) Potential of sample excitatory neuron #3. Initially, both probes cause some inhibition while after training the in-pattern probe causes elevated potential (firing), while other probe causes increased inhibition. (G) Inhibitory cell’s firing rate.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g001" xlink:type="simple"/>
</fig>
<p>The network behavior is then shaped primarily by the dynamics of recurrent excitation. At any given moment, the strength of a recurrent excitatory connection between (postsynaptic) neuron <italic>i</italic> from a (presynaptic) excitatory neuron <italic>j</italic>, <italic>W</italic><sub><italic>ij</italic></sub>(<italic>t</italic>), is the product of three terms: a fixed baseline synaptic weight <italic>S</italic><sub><italic>ij</italic></sub>, an associative (Hebbian) gain <italic>H</italic><sub><italic>ij</italic></sub>(<italic>t</italic>), and a synaptic depression term <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>):
<disp-formula id="pone.0188562.e001">
<alternatives>
<graphic id="pone.0188562.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula></p>
<p>The Hebbian plasticity term <italic>H</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) increases with coincident pre- and postsynaptic activity <italic>y</italic><sub><italic>i</italic></sub> (<italic>t</italic>)<italic>y</italic><sub><italic>j</italic></sub>(<italic>t</italic>), and decays towards some minimum value <italic>H</italic><sub><italic>min</italic></sub> in the absence of any coincident activity:
<disp-formula id="pone.0188562.e002">
<alternatives>
<graphic id="pone.0188562.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
<p>The growth term is scaled so that the connection strength cannot exceed a maximum value <italic>H</italic><sub><italic>max</italic></sub>. The rates of growth and decay are governed by their respective timescales, <inline-formula id="pone.0188562.e003"><alternatives><graphic id="pone.0188562.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0188562.e004"><alternatives><graphic id="pone.0188562.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> (with rate of growth significantly faster than that of decay).</p>
<p>Excitation is regulated by (and stable due to) two mechanisms: feedback inhibition, and the synaptic depression term <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>). For this simple network, we only consider a single inhibitory unit, which receives inputs from, and projects back to, the excitatory neurons and itself; connections to and from the inhibitory neuron are uniform. This inhibitory unit therefore suppresses all neurons by an amount proportional to the total excitatory activity, resulting in competition between the excitatory neurons. Synaptic depression <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is governed by a standard model [<xref ref-type="bibr" rid="pone.0188562.ref023">23</xref>]:
<disp-formula id="pone.0188562.e005">
<alternatives>
<graphic id="pone.0188562.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>This decreases the strength of a given connection <italic>W</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) (<xref ref-type="disp-formula" rid="pone.0188562.e008">Eq 6</xref>) due to presynaptic activity <italic>y</italic><sub><italic>i</italic></sub>(<italic>t</italic>), and otherwise increases back to a baseline (unity).</p>
<p>In this simple network, the baseline strength is assumed to be uniform (<italic>S</italic><sub><italic>ij</italic></sub> = <italic>S</italic><sub>0</sub>). As we will describe, this gives the network the maximum potential for memory storage, but alternatives will be considered later.</p>
<sec id="sec003">
<title>Short-term memory via transient attractors</title>
<p>The behavior of this network can be understood in the context of attractor dynamics [<xref ref-type="bibr" rid="pone.0188562.ref024">24</xref>]. In the presence of a constant external input, firing rates in the network will settle into a stable pattern of neural activity–an attractor–that depends on both the external input and the state of the network. Note that such a definition of an attractor is broader than that used in much of the persistent attractor literature, which only considers attractors that remain active when external input is removed. Because both the stimulus and effective synaptic strengths can change in time, the attractor for a given network itself is time-varying, and–crucially–will depend on recent history of network activity through the associative gain term (<italic>H</italic><sub><italic>ij</italic></sub>). This approach of the memory being the attractor that results from time-varying synaptic strengths–and not the neural activity itself–not only allows for more flexible storage of information, but also the targeted recall of certain memories and effects a significant reduction in the interference between simultaneously stored memories.</p>
<p>We first illustrate how the transient attractor network works within a minimal network with just four excitatory neurons (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1A</xref>). We select two patterns to store: the first with neurons #1 and #3 coactive, and the second with neurons #2 and #4 coactive (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1B</xref>). Before the memory is stored, we present “probe” stimuli, each driving a single neuron (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1C</xref>, <italic>left</italic>) in order to verify there are no preexisting network attractors. Indeed, such probe stimuli only evoke activity in the neurons that were externally stimulated (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1D</xref>, <italic>left</italic>). To imprint the memory, the two patterns are displayed alternately at 4 Hz for 1 sec (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1C</xref>, <italic>center</italic>). Following this, both probe stimuli are displayed again (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1C</xref>, <italic>right</italic>) to determine if the memories are recalled in the network activity. Indeed, while only the stimulated neurons fire in response to the probe stimuli at the beginning (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1D</xref>, <italic>left</italic>), the patterns emerge after training (<italic>right</italic>).</p>
<p>During the training period, the memory is imprinted in the increased recurrent weights between coactive neurons over repeated presentations (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1E</xref>). These strengthened connections then lead to increases of membrane voltages when even a part of the recently imprinted pattern is shown (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1F</xref>). This in turn causes an increase in inhibitory firing rates proportional to the additional excitatory activity (<xref ref-type="fig" rid="pone.0188562.g001">Fig 1G</xref>), and an increase in suppression of the non-paired neurons.</p>
<p>We next extend this simple example to a much larger network, capable of learning multiple, overlapping patterns. This network has 100 excitatory neurons, arranged in a 10×10 grid. Note that the grid arrangement is only to make visualizing the patterns of activity easier, and it does not represent any biases in connectivity; the excitatory connections are all-to-all, and of equal strength. We train this network with three patterns, two digits (to be easily recognizable) and a third composed of randomly selected neurons. This set of patterns illustrates how any pattern can be stored in the network, but also note that the two digits chosen have a large number of shared elements. Random subsets of each pattern are selected as probe stimuli, and the network is tested to have no preexisting attractors, and trained as described above (<xref ref-type="fig" rid="pone.0188562.g002">Fig 2A</xref>). The successful storage of the memories in the network can be verified by comparing the levels of activity of the excitatory neurons to the initial and final probes (<xref ref-type="fig" rid="pone.0188562.g002">Fig 2B</xref>). This shows that an attractor has been created for each pattern. Furthermore, due to the inhibition-mediated competition, activity does not ‘leak’ between overlapping attractors, and the stored information is recalled in the presence of a relevant probe. This demonstrates that this network is capable of performing short-term memory tasks involving multiple (potentially overlapping) memories held simultaneously. As with Hopfield networks, the memory capacity of this network (i.e., the number of patterns that can be stored simultaneously in memory) increases with the number of neurons [<xref ref-type="bibr" rid="pone.0188562.ref025">25</xref>], but in practice such a capacity cannot realistically be used due to the limitation of the transient time scale over which the trained patterns of connectivity maintain themselves.</p>
<fig id="pone.0188562.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Transient attractors store several arbitrary patterns.</title>
<p>(A) Stimulus composed of probe stimuli and training stimuli, with three different patterns (two recognizable patterns, one random, all overlapping). Probes are random subset of 25% of each pattern respectively. (B) Excitatory activity (firing rate) at time of probes.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g002" xlink:type="simple"/>
</fig>
<p>Stored short-term memories in this network have an additional attractive property in contrast to persistent-activity-based attractors: namely that they are stable while being stored. Such stability can be demonstrated in an example network where there is a clear topography between different activity states of the network. Thus, we next consider a ring attractor [<xref ref-type="bibr" rid="pone.0188562.ref026">26</xref>]. A ring attractor is composed of a circle of neurons, with each neuron preferentially connected to its neighbors (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3A</xref>). In principle, ring attractors based on persistent activity can store a continuous variable because activity at any point on the ring can be stable. However, it has been shown that any noise in recurrent connections will cause a severe reduction in the number of stable equilibriums: typically down to a handful [<xref ref-type="bibr" rid="pone.0188562.ref027">27</xref>]. In practice, this means that the system will always drift to one of the relatively few global attractors (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3B</xref>).</p>
<fig id="pone.0188562.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Short-term memory in a ring attractor.</title>
<p>(A) Structure of ring attractor (inset: bidirectional excitatory weight from neuron i to neuron j). All plots have noise (epsilon) = 0.05. (B) Persistent activity subject to drift. Center of distribution of activity shown for ten initializations, one typical trajectory shown by shading. (C) Plastic synapses allow for information storage in transient attractors at any single location (D) Transient attractors stabilize activity in case of persistent activity (initial departure due to immediate depressive feedback) (E) Transient attractors allow for simultaneous storage of multiple locations (recall prompted by stimulating either upper or lower half of cells).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g003" xlink:type="simple"/>
</fig>
<p>Transient attractors avoid this drift by having the network inactive in between training and read-out (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3C</xref>), meaning that the memory cannot drift. Any unpatterned noise in the intervening period will not consistently activate pairs, and thus the presence of the attractor itself will also be robust to noise (see below). This observation complements earlier work [<xref ref-type="bibr" rid="pone.0188562.ref027">27</xref>] showing plastic synapses will reduce the rate of drift in the case of persistent activity (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3D</xref>). Furthermore, analogous to the more general network considered above (<xref ref-type="fig" rid="pone.0188562.g002">Fig 2</xref>), this network is capable of storing multiple locations simultaneously (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3E</xref>), each re-activated by their own probe. This demonstrates how storing information in modified synaptic connections, as opposed to persistent activity, prevents slow distortion of the information by small errors within the network (in this case, attractor drift).</p>
</sec>
<sec id="sec004">
<title>Maintenance of information over time</title>
<p>By design, information stored in transient attractors degrades at the time scale of the underlying transient synaptic plasticity. While this would appear to limit the amount of time a memory can be stored by the transient attractor, such a network can extend to storage over longer periods of time through reactivation of the attractor [<xref ref-type="bibr" rid="pone.0188562.ref018">18</xref>]. Such reactivation will strengthen all relevant connections, and thereby allow information to be stored for durations well past the time scales of the decay of the transient synaptic plasticity.</p>
<p>To demonstrate how the transient attractor is capable of this, we first store two overlapping patterns (<xref ref-type="fig" rid="pone.0188562.g004">Fig 4A</xref>, <italic>left</italic>). Without any further activity, the information stored will become inaccessible over several seconds due to the timescale of decay of the induced synaptic plasticity. However, here the stored information is refreshed by regular reactivation of the attractors via pulsing background activity (<xref ref-type="fig" rid="pone.0188562.g004">Fig 4A</xref>, <italic>center</italic>). Background stimulation causing the refresh need not be specific to any stored pattern; in this example, background stimulation is uniform across all channels, but as a result momentarily activates individual attractors within the network. Furthermore, the pulsing nature allows for sequential activation of multiple attractors due to the synaptic depression of synapses which were most recently activated. The pulsing uniform activity is not the only conceivable method of refreshing memories; for example, specific memories might be targeted using an appropriate probe. As a result of this attractor reactivation, it can be seen that the duration of the memories has been extended (<xref ref-type="fig" rid="pone.0188562.g004">Fig 4A</xref>, <italic>right</italic> and <xref ref-type="fig" rid="pone.0188562.g004">Fig 4B</xref>). This demonstrates the how transient attractors could store information over variable time scales.</p>
<fig id="pone.0188562.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Network can separate patterns using temporal coherence.</title>
<p>(A) Two training patterns and their temporal envelopes. (B) Excitatory activation at time of probes revealing transient attractors have formed for each pattern.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Associating distinct patterns of input via temporal coherence</title>
<p>For the above examples of memory, stimuli were presented separately in time in order to focus on the storage and retrieval of patterns. However, real world stimuli will often not be so conveniently separated in time, with different components that can only be distinguished by detecting shared temporal features. Such a theory of “temporal coherence” has been suggested as a solution for the “cocktail party” problem, that is the ability to associate the features comprising different sounds and focus on those components while suppressing others [<xref ref-type="bibr" rid="pone.0188562.ref028">28</xref>,<xref ref-type="bibr" rid="pone.0188562.ref029">29</xref>]. Temporal coherence has likewise been used for visual object separation [<xref ref-type="bibr" rid="pone.0188562.ref003">3</xref>].</p>
<p>The network described above can perform a simple example of such segregation based on temporal coherence. The training stimulus is composed of two random, non-overlapping patterns of activation, which are then modulated by two random and independent temporal envelopes (<xref ref-type="fig" rid="pone.0188562.g005">Fig 5A</xref>). As with earlier examples, probes are displayed before and after exposure to patterns to demonstrate the creation of transient attractors. While both patterns were present at some amplitude throughout the training period, the network responses to the probes (<xref ref-type="fig" rid="pone.0188562.g005">Fig 5B</xref>) following training reveal that the network has learned both patterns. This happens due to the inhibitory feedback which prevents both patterns from being represented simultaneously. As patterns in the network are not represented simultaneously (even if both are present in the stimulus), they are essentially temporally segregated within the network allowing associations to be learned. Conversely, any inputs which have been co-active for a significant period of time are temporally associated, and will be bound while the two inputs are displayed. We conclude that the network is capable in-principle of performing some form of on-line temporal coherence analysis [<xref ref-type="bibr" rid="pone.0188562.ref030">30</xref>].</p>
<fig id="pone.0188562.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Transient attractors for de-noising and object recognition.</title>
<p>(A) Stimulus composed of two parts. Signal (top) is occluded pattern (25% occlusion) for 25 ms, repeats every 100ms. Noise (bottom) random across all non-signal channels. Noise and signal have approximately same amplitude, average activity and temporal correlations. (B) Network activity in response to stimulus. Initially network responds to noise and signal equally, but over time correlations in input allow it to filter out noise and complete the pattern.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Separating signal from noise</title>
<p>Just as networks with persistent activity may act as neural integrators [<xref ref-type="bibr" rid="pone.0188562.ref031">31</xref>], the transient attractor network may also act as an integrator, allowing it to filter out noise and store an uncorrupted version of the signal. This works because changes to network connectivity sum for short time scales (those less than the time scale of decay). We demonstrate this ability with an example where the signal corruption is due to both occlusion (part of pattern temporarily absent) and uniform noise (additional spurious inputs). We construct a stimulus composed of two parts, signal and noise (<xref ref-type="fig" rid="pone.0188562.g006">Fig 6A</xref>). Different partially occluded versions of the pattern are presented briefly. Noise is also introduced, with other inputs randomly active such that the average firing rate is constant across all inputs.</p>
<fig id="pone.0188562.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Maintenance of transient attractor by uniform input.</title>
<p>(A) Two overlapping patterns stored in memory during first second, recall attempted between 4.8 and 5 seconds. Intermediate period filled with either pulsing low intensity uniform network inputs (top) or no input (bottom). (B) Continued activity allows network to maintain transient attractors and extends duration of memory.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g006" xlink:type="simple"/>
</fig>
<p>In the context of such stimulation, it is not possible to distinguish between signal and noise by examining either any individual channel over all time, or all channels together at one individual point in time. However, because the plasticity integrates over all temporal associations on the second-long time scale, the noise ends up contributing much less to the connectivity compared with the more consistent signal over this time scale, resulting in an attractor dominated by the combinations of associates that got presented. By the end of training, presentation of a part of the pattern will activate a transient attractor corresponding to the entire pattern (<xref ref-type="fig" rid="pone.0188562.g006">Fig 6B</xref>), both filtering out the noise and filling in the majority of the occluded channels.</p>
</sec>
<sec id="sec007">
<title>Modeling attention and the role of inhibition</title>
<p>The transient attractor network also has the ability to turn on or off its function through straightforward modulation of inhibition. When the overall strength of inhibition is increased, recurrent activation of attractors will be suppressed such that the network will have no attractors other than faithfully relaying the stimulus. To demonstrate this, we consider the network described in <xref ref-type="fig" rid="pone.0188562.g002">Fig 2</xref>, and re-run the simulations when the level of inhibition is increased by doubling the strength of all inhibitory synapses. Although exposure to patterns still leads to synaptic strengthening, such changes are insufficient to create a stable attractor, and the final probe no longer leads to pattern recall (<xref ref-type="fig" rid="pone.0188562.g007">Fig 7</xref>). In this example, inhibitory modulation works to prevent retrieval of previous associations. Such basic modulation coincides with observations of the requirement of attention or engagement for the storage of short-term memories [<xref ref-type="bibr" rid="pone.0188562.ref009">9</xref>], as well as for changes associated with auditory streaming [<xref ref-type="bibr" rid="pone.0188562.ref029">29</xref>], and is generally useful to selectively perform the various functions of a transient attractor network.</p>
<fig id="pone.0188562.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Inhibition as proxy for attention.</title>
<p>Network from <xref ref-type="fig" rid="pone.0188562.g001">Fig 1A</xref> with either standard (A, C) or increased (B, D) levels of inhibition. Excitatory neuron responses (A, B) and potentials (C, D) reveal dependence on level of inhibition, and suggest inhibition as proxy for attention.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Model robustness</title>
<p>Stability is often a large concern in neural networks with recurrent excitation; a slight modification to the strength of recurrent connections can either lead to runaway excitation or silence activity throughout the network. We can test how fine this balance is in our model by changing the baseline synaptic strengths of all neurons of a certain type, for example halving all feedback inhibition, and determining if the network continues to successfully store and recall patterns. Each individual parameter could be varied by at least 25% in either direction (<xref ref-type="fig" rid="pone.0188562.g008">Fig 8A</xref>), showing the model to be highly resilient to the average sizes of synaptic strengths. We attribute this stability to the close link between inhibition and excitation, as the amount of inhibition scales with the amount of excitation, similar to many E-I networks [<xref ref-type="bibr" rid="pone.0188562.ref024">24</xref>]. Additional stability to the network is a result of saturating firing rates within the single-neuron models.</p>
<fig id="pone.0188562.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Network resilience.</title>
<p>(A) The network continues to be able to successfully recall information for a wide variety of values of each parameter (ratio compared to default plotted). (B) Network performance for sparse network over 100 trials. PPV = Positive Predictive Value, TPR = True Positive Rate. Dashed/solid lines are median before/after training, shaded region lies between first and third quartile.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.g008" xlink:type="simple"/>
</fig>
<p>We also perform a much more extreme manipulation. We randomly removed a percentage of recurrent connections while keeping total recurrent connection strength constant. Such a manipulation results renders the network structure highly heterogeneous. It was found that the network still functions remarkably well at recalling any pattern for connection densities as low as 20% (<xref ref-type="fig" rid="pone.0188562.g008">Fig 8B</xref>). This result comes from the manner in which memories are stored–as associations between many different pairs of neurons–which is only perturbed when a large proportion of connections have been removed. This demonstrates that the underlying functionality of the network is not overly reliant on a homogeneous network structure, and therefore may function well within biological networks that can be highly heterogeneous in nature.</p>
<p>The transient attractor model becomes more robust in larger networks; the larger number of neurons comprising each pattern make it exponentially less likely that any two patterns will significantly overlap (relative to the number of neurons in the patterns). This is related to the reason that the memory capacity of a Hopfield network scales linearly with network size. Likewise, memories in larger networks are stored across multiple synapses, so that the network will be more robust to irregularities at single synapses.</p>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>Here we have presented the transient attractor network, defined primarily by recurrent excitatory connections that are governed by an associative (Hebbian) plasticity that decays within seconds. We have demonstrated that such a network is capable of a wide range of useful behaviors, including short-term memory (Figs <xref ref-type="fig" rid="pone.0188562.g001">1</xref>–<xref ref-type="fig" rid="pone.0188562.g003">3</xref>), source (or stream) segregation (<xref ref-type="fig" rid="pone.0188562.g004">Fig 4</xref>), signal de-noising (<xref ref-type="fig" rid="pone.0188562.g005">Fig 5</xref>), memory maintenance (<xref ref-type="fig" rid="pone.0188562.g006">Fig 6</xref>), top-down modulation (<xref ref-type="fig" rid="pone.0188562.g007">Fig 7</xref>). Furthermore, we demonstrated the robustness of the model with respect to both synapse strength and homogeneity (<xref ref-type="fig" rid="pone.0188562.g008">Fig 8</xref>). The concept that the same underlying network mechanism might have several uses in sensory computation is compelling in its simplicity. In fact, each of the tasks in Figs <xref ref-type="fig" rid="pone.0188562.g002">2</xref> and <xref ref-type="fig" rid="pone.0188562.g004">4</xref>–<xref ref-type="fig" rid="pone.0188562.g007">7</xref> was performed using the exact same network with the same parameters. Furthermore, while many of the above functions of transient attractor networks are demonstrated with these simplified networks, the networks size should actually make its desirable properties more robust.</p>
<p>The mechanisms and network structure underlying transient attractors are known to exist in the cortex–except, perhaps, for associative transient plasticity (see below). It does not depend on a set of stable attractors, or some finely prescribed structure. This allows it to be a candidate for short-term memory in a wide variety of regions, such as the primary sensory cortex [<xref ref-type="bibr" rid="pone.0188562.ref014">14</xref>,<xref ref-type="bibr" rid="pone.0188562.ref015">15</xref>]. This is in contrast with a large number of short-term memory models which prescribe such tasks to particularly specialized regions of the brain. The broad applicability of short-term memory benefits from widely applicable mechanisms, perhaps working in tandem with more specialized regions.</p>
<sec id="sec010">
<title>Alternative models for short-term memory</title>
<p>The classic model for short-term memory stores information in persistent attractors [<xref ref-type="bibr" rid="pone.0188562.ref005">5</xref>], that is through a self-sustaining state within the network. Once such an attractor is activated, activity will persist until externally stopped, while the identity of the persistent attractor stores the information. This self-sustenance is typically achieved in neural networks through different combinations of recurrent excitation [<xref ref-type="bibr" rid="pone.0188562.ref004">4</xref>,<xref ref-type="bibr" rid="pone.0188562.ref032">32</xref>], inhibition [<xref ref-type="bibr" rid="pone.0188562.ref033">33</xref>], or both [<xref ref-type="bibr" rid="pone.0188562.ref006">6</xref>,<xref ref-type="bibr" rid="pone.0188562.ref007">7</xref>,<xref ref-type="bibr" rid="pone.0188562.ref034">34</xref>]. Of the many models of persistent attractors, an interesting subset made use of synaptic modifications to the attractor to aid in the persistence of activity [<xref ref-type="bibr" rid="pone.0188562.ref027">27</xref>,<xref ref-type="bibr" rid="pone.0188562.ref035">35</xref>]. The combination of persistent activity and underlying synaptic modifications does resemble the transient attractor network (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3D</xref>), but nevertheless information storage in these networks relies on persistent activity. While various experiments [<xref ref-type="bibr" rid="pone.0188562.ref036">36</xref>–<xref ref-type="bibr" rid="pone.0188562.ref040">40</xref>] support the idea of persistent activity underlying short-term memories, a number of conflicting studies in different brain areas have drawn doubt on the universality of such a mechanism [<xref ref-type="bibr" rid="pone.0188562.ref005">5</xref>,<xref ref-type="bibr" rid="pone.0188562.ref011">11</xref>,<xref ref-type="bibr" rid="pone.0188562.ref018">18</xref>].</p>
<p>As a result, other models for short-term memory have been proposed, using processes such as cell assemblies [<xref ref-type="bibr" rid="pone.0188562.ref041">41</xref>], non-stationary activity [<xref ref-type="bibr" rid="pone.0188562.ref042">42</xref>], cross-regional networks [<xref ref-type="bibr" rid="pone.0188562.ref043">43</xref>,<xref ref-type="bibr" rid="pone.0188562.ref044">44</xref>], or purely feed-forward circuits [<xref ref-type="bibr" rid="pone.0188562.ref032">32</xref>]. These other ideas all rely on neural activity for information storage, and thus are still distinct from the idea of storing information in neural connectivity.</p>
<p>Several models have also been proposed which store short-term memories as temporary changes in synaptic strength–as the transient attractor network does–using either direct associative plasticity [<xref ref-type="bibr" rid="pone.0188562.ref017">17</xref>,<xref ref-type="bibr" rid="pone.0188562.ref019">19</xref>,<xref ref-type="bibr" rid="pone.0188562.ref020">20</xref>,<xref ref-type="bibr" rid="pone.0188562.ref022">22</xref>] or synaptic facilitation [<xref ref-type="bibr" rid="pone.0188562.ref018">18</xref>]. In the majority of these, the scope of the memories was pre-defined by the structure of the network. Sandberg et al. [<xref ref-type="bibr" rid="pone.0188562.ref017">17</xref>] used a ring attractor which could store individual variables due to the ring structure, Szatmary and Izhikevich [<xref ref-type="bibr" rid="pone.0188562.ref019">19</xref>] used randomly created periodic attractors, while Mongillo et al. [<xref ref-type="bibr" rid="pone.0188562.ref018">18</xref>] facilitated pre-defined cell assemblies. This is in contrast to the transient attractor network, which considers how recent stimuli might shift the locations of the attractors. In this respect, our model is highly similar to a model recently proposed by Fieberg and Lansner [<xref ref-type="bibr" rid="pone.0188562.ref022">22</xref>], which stored short-term memories in transient associative changes to the connectivity. Our work adds to this idea by demonstrating how such a mechanism occurring within the sensory cortices might assist with a variety of other functions such as temporal coherence analysis, signal denoising, and memory maintenance, combined with analysis of the systems robustness to a variety of perturbations.</p>
</sec>
<sec id="sec011">
<title>Experimental evidence for transient associative synaptic plasticity</title>
<p>The transient attractor network above relies on an associative learning rule that decays on the order of seconds. There is scattered experimental evidence for transient associative effects (i.e., where strengthening of connectivity occurs between coactive neurons), which has been observed in ferret auditory cortex [<xref ref-type="bibr" rid="pone.0188562.ref029">29</xref>], macaque ITC [<xref ref-type="bibr" rid="pone.0188562.ref045">45</xref>], and dissociated networks [<xref ref-type="bibr" rid="pone.0188562.ref046">46</xref>]. It is known that associative learning takes place over a variety of timescales due to multiple mechanisms [<xref ref-type="bibr" rid="pone.0188562.ref047">47</xref>], including some direct associative connections which decay in minutes [<xref ref-type="bibr" rid="pone.0188562.ref048">48</xref>,<xref ref-type="bibr" rid="pone.0188562.ref049">49</xref>]. It is conceivable such processes might exist for shorter timescales, but have proven difficult to separate from non-associative plasticity similar timescales (such as synaptic facilitation and depression). Such associative plasticity also may be possible to achieve associative changes in effective coupling using non-associative facilitation within certain network structures; this is the subject of future work.</p>
</sec>
<sec id="sec012">
<title>Extensions of the transient attractor network</title>
<p>It is hypothesized that the pre-existing wiring of neural networks in sensory cortices is informed by the structure of natural stimuli [<xref ref-type="bibr" rid="pone.0188562.ref050">50</xref>], which is equivalent to non-uniform connectivity (<italic>S</italic><sub><italic>ij</italic></sub>) in the transient attractor network. While such non-uniformity would bias the network towards some attractors, this could be advantageous in sensory cortex, as the location of transient attractors will be guided both by the immediate history and by the pre-learned nature of typical stimuli. When presented with a novel stimulus, the network’s interpretation may be biased by learned stimuli, which are presumably the stimuli that have proven the most useful (given rules of long-term plasticity). This coordination of short- and long-term plasticity is distinct from earlier work that stored short-term memories by strengthening some pre-existing attractors: in the transient attractor model, recent activity may change the nature of (e.g. strengthen, make stable or shift) pre-existing attractors. This allows for much greater flexibility in memory storage; the number of possible transient attractors (as influenced by pre-learned patterns, recent history, and by the nature of the instantaneous input) is far larger than that of pre-existing attractors.</p>
</sec>
</sec>
<sec id="sec013" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec014">
<title>Neuron model</title>
<p>In our model, the firing rate of neuron <italic>i</italic> at time <italic>t, y</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is governed by the neuron’s instantaneous membrane potential, <italic>v</italic><sub><italic>i</italic></sub>(<italic>t</italic>). The dependence of firing rate on the potential is described using a saturating, rectified linear function
<disp-formula id="pone.0188562.e006">
<alternatives>
<graphic id="pone.0188562.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula></p>
<p>The membrane potential evolves proportional to the sum of the recurrent excitatory <italic>I</italic><sub><italic>Exc</italic></sub>(<italic>t</italic>), inhibitory <italic>I</italic><sub><italic>Inh</italic></sub>(<italic>t</italic>), input <italic>I</italic><sub><italic>in</italic></sub>(<italic>t</italic>) and leak <italic>I</italic><sub><italic>Leak</italic></sub>(<italic>t</italic>) currents,
<disp-formula id="pone.0188562.e007">
<alternatives>
<graphic id="pone.0188562.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
<disp-formula id="pone.0188562.e008">
<alternatives>
<graphic id="pone.0188562.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
<disp-formula id="pone.0188562.e009">
<alternatives>
<graphic id="pone.0188562.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
<disp-formula id="pone.0188562.e010">
<alternatives>
<graphic id="pone.0188562.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>Note that the excitatory and inhibitory recurrent currents are themselves a weighted sum of other neurons’ firing rates (with weight <italic>W</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) between excitatory neuron <italic>i</italic> and <italic>j</italic>, and <italic>W</italic><sub><italic>Inh</italic></sub> from the inhibitory neuron to all excitatory neurons). Finally, the inhibitory current acts to return the membrane potential to the inhibitory reversal potentials (<inline-formula id="pone.0188562.e011"><alternatives><graphic id="pone.0188562.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>), while the excitatory currents are independent of the membrane potential; this is simplification is valid since the excitatory reversal potential is far larger than typical values for the membrane potential, so that the difference between the two is approximately constant.</p>
</sec>
<sec id="sec015">
<title>Parameters</title>
<p>Simulation parameters which remain constant across all simulations are listed in <xref ref-type="table" rid="pone.0188562.t001">Table 1</xref>. Weights between neurons depend on the network structures used in each Figure, as follows:</p>
<p>For <xref ref-type="fig" rid="pone.0188562.g001">Fig 1</xref>: <italic>W</italic><sub><italic>SE</italic></sub> = 5, <italic>W</italic><sub><italic>IE</italic></sub> = 5, <italic>W</italic><sub><italic>II</italic></sub> = 20, <italic>W</italic><sub><italic>EI</italic></sub> = 10, <italic>W</italic><sub><italic>EE</italic></sub> = 1</p>
<p>For <xref ref-type="fig" rid="pone.0188562.g003">Fig 3</xref> (ring attractor): <italic>W</italic><sub><italic>SE</italic></sub> = 1, <italic>W</italic><sub><italic>IE</italic></sub> = 10, <italic>W</italic><sub><italic>EI</italic></sub> = 2, <italic>W</italic><sub><italic>EE</italic></sub> = 1.5</p>
<p>For Figs <xref ref-type="fig" rid="pone.0188562.g002">2</xref> and <xref ref-type="fig" rid="pone.0188562.g004">4</xref>–<xref ref-type="fig" rid="pone.0188562.g008">8</xref>: <italic>W</italic><sub><italic>SE</italic></sub> = 5, <italic>W</italic><sub><italic>IE</italic></sub> = 5, <italic>W</italic><sub><italic>II</italic></sub> = 20, <italic>W</italic><sub><italic>EI</italic></sub> = 1, <italic>W</italic><sub><italic>EE</italic></sub> = 0.1</p>
<table-wrap id="pone.0188562.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0188562.t001</object-id>
<label>Table 1</label> <caption><title>Simulation parameters.</title></caption>
<alternatives>
<graphic id="pone.0188562.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Name</th>
<th align="left" style="border-bottom:thick">Symbol</th>
<th align="left" style="border-bottom:thick">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Max Hebbian</td>
<td align="center"><italic>H</italic><sub><italic>max</italic></sub></td>
<td align="left">5</td>
</tr>
<tr>
<td align="left">Min Hebbian</td>
<td align="center"><italic>H</italic><sub><italic>min</italic></sub></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">Facilitation increase</td>
<td align="center"><inline-formula id="pone.0188562.e012"><alternatives><graphic id="pone.0188562.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">100ms</td>
</tr>
<tr>
<td align="left">Facilitation decrease</td>
<td align="center"><inline-formula id="pone.0188562.e013"><alternatives><graphic id="pone.0188562.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">200ms</td>
</tr>
<tr>
<td align="left">Depression increase</td>
<td align="center"><inline-formula id="pone.0188562.e014"><alternatives><graphic id="pone.0188562.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">50ms</td>
</tr>
<tr>
<td align="left">Depression decrease</td>
<td align="center"><inline-formula id="pone.0188562.e015"><alternatives><graphic id="pone.0188562.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0188562.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">100ms</td>
</tr>
<tr>
<td align="left">Leak current</td>
<td align="center"><italic>τ</italic><sub><italic>Leak</italic></sub></td>
<td align="left">1ms</td>
</tr>
<tr>
<td align="left">Firing scale</td>
<td align="center"><italic>a</italic></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">Firing threshold</td>
<td align="center"><italic>b</italic></td>
<td align="left">1</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Ring model (<xref ref-type="fig" rid="pone.0188562.g003">Fig 3</xref>): The profile of the recurrent excitatory baseline weights across space follow a Gaussian bell curve with a standard deviation of 10 centered at the postsynaptic neuron’s location, and a strength of 1.5 in the center (recorded in Parameters above). All weights are then multiplied by a random noise term, drawn from normal distribution, μ = 1, σ = 0.05.</p>
<p>Temporal Coherence Model (<xref ref-type="fig" rid="pone.0188562.g005">Fig 5</xref>): Time courses were generated using a continuous low-pass filter applied to Gaussian noise; in particular, a filter was used in which the energy at a frequency <italic>f</italic> was multiplied by exp(-0.1*f).</p>
<p>De-noising model (<xref ref-type="fig" rid="pone.0188562.g006">Fig 6</xref>): The signal pattern was deliberately chosen for its distinctive shape; the pattern was then used to classify all input channels as either signal or non-signal. The signal channels were only ever active when a significant number of the other signal channels were active. In particular, an occluded pattern (a subset of 75% of all signal channels) was shown for the initial 25 ms of each 100 ms window. The subset included was chosen in a manner that meant the occluded pattern would be spatially continuous. In contrast, the activity of each non-signal channel was composed of 25 ms long bursts of activity. At any time, each dormant non-signal channel had a constant probability of starting a burst. This probability was selected so that the average activity across non-signal channels is equal to average activity in signal channels.</p>
<p>Robustness analysis (<xref ref-type="fig" rid="pone.0188562.g008">Fig 8</xref>): In order to test robustness to changes in synaptic strengths, the baseline strength for each type of connection was modified until the memory recall is no longer ‘successful’. The change in baseline strength was applied to all connections of any single type, and the default case used was that presented in <xref ref-type="fig" rid="pone.0188562.g002">Fig 2</xref>. Recall was deemed ‘successful’ if, during relevant probe, the average firing rate within either pattern was at least 0.1 (10% of the maximal firing rate), and at least five times greater than the average firing rate of the most active non-pattern channel.</p>
<p>The sensitivity to sparsity was tested by changing the density of recurrent connections. 20 different sparsity values were tested (from 0.05 up to 1, with a step size of 0.05), with 100 trials at each value. The recurrent connection matrix was then randomly set using according to the sparsity value; each connection was independently set to zero with probability = 1 –density. All the remaining weights were then scaled uniformly to ensure that the total strength of recurrent excitatory connections remained constant. For each trial, two random patterns were selected, with each pattern being a subset of 20 randomly selected excitatory neurons. From each of these patterns a probe (a subset of 5 neurons) was then selected. The results record the behavior of the various neurons after training in the presence of the probe; because the probe neurons are externally stimulated, they were excluded from the analysis. Each excitatory neuron was considered active if its average firing rate was over 0.1 while the probe displayed. These results were then summarized using two measures. The first of these, Positive Predictive Value (PPV). This represents what proportion of cells that were active were actually members of the appropriate pattern (that is, the pattern which matches the probe used). The second measure used is the True Positive Rate (TPR), which is the proportion of the neurons from the appropriate pattern which were active. These two measures combined give a complete description of how the different populations of neurons reacted to the probe.</p>
</sec>
<sec id="sec016">
<title>Source code</title>
<p>All code was written in MATLAB, and is accessible as supplementary information (<xref ref-type="supplementary-material" rid="pone.0188562.s001">S1 File</xref>).</p>
</sec>
</sec>
<sec id="sec017">
<title>Supporting information</title>
<supplementary-material id="pone.0188562.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0188562.s001" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>MATLAB code for all simulations.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pone.0188562.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maex</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Steuber</surname> <given-names>V</given-names></name>. <article-title>The first second: Models of short-term memory traces in the brain</article-title>. <source>Neural Networks</source>. <year>2009</year>;<volume>22</volume>:<fpage>1105</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neunet.2009.07.022" xlink:type="simple">10.1016/j.neunet.2009.07.022</ext-link></comment> <object-id pub-id-type="pmid">19635658</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krishnan</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>. <article-title>Segregating Complex Sound Sources through Temporal Coherence</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>12</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Becker</surname> <given-names>S</given-names></name>. <article-title>Learning to categorize objects using temporal coherence</article-title>. <year>1992</year>.</mixed-citation></ref>
<ref id="pone.0188562.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seung</surname> <given-names>HS</given-names></name>. <article-title>How the brain keeps the eyes still</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1996</year>;<volume>93</volume>(<issue>23</issue>):<fpage>13339</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">8917592</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>. <article-title>Working models of working memory</article-title>. <source>Curr Opin Neurobiol</source>. <year>2014</year>;<volume>25</volume>:<fpage>20</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2013.10.008" xlink:type="simple">10.1016/j.conb.2013.10.008</ext-link></comment> <object-id pub-id-type="pmid">24709596</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brody</surname> <given-names>CD</given-names></name>. <article-title>Flexible Control of Mutual Inhibition: A Neural Model of Two-Interval Discrimination</article-title>. <source>Science (80-)</source>. <year>2005</year>;<volume>307</volume>(<issue>5712</issue>):<fpage>1121</fpage>–<lpage>4</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aksay</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Olasagasti</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mensh</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Goldman</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Tank</surname> <given-names>DW</given-names></name>. <article-title>Functional dissection of circuitry in a neural integrator</article-title>. <source>Nat Neurosci</source>. <year>2007</year>;<volume>10</volume>(<issue>4</issue>):<fpage>494</fpage>–<lpage>504</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1877" xlink:type="simple">10.1038/nn1877</ext-link></comment> <object-id pub-id-type="pmid">17369822</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ganguli</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Huh</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Somploinsky</surname> <given-names>H</given-names></name>. <article-title>Memory traces in dynamical systems</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year> <month>Dec</month> <day>2</day>;<volume>105</volume>(<issue>48</issue>):<fpage>18970</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0804451105" xlink:type="simple">10.1073/pnas.0804451105</ext-link></comment> <object-id pub-id-type="pmid">19020074</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>D’Esposito</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Postle</surname> <given-names>BR</given-names></name>. <article-title>The Cognitive Neuroscience of Working Memory</article-title>. <source>Annu Rev Psychol</source>. <year>2015</year>;<volume>66</volume>(<issue>1</issue>):<fpage>115</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zylberberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Strowbridge</surname> <given-names>BW</given-names></name>. <article-title>Mechanisms of Persistent Activity in Cortical Circuits: Possible Neural Substrates for Working Memory</article-title>. <source>Annu Rev Neurosci</source>. <year>2017</year>;<volume>40</volume>:<fpage>603</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-070815-014006" xlink:type="simple">10.1146/annurev-neuro-070815-014006</ext-link></comment> <object-id pub-id-type="pmid">28772102</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stokes</surname> <given-names>MG</given-names></name>. <article-title>“Activity-silent” working memory in prefrontal cortex: a dynamic coding framework</article-title>. <source>Trends Cogn Sci</source>. <year>2015</year>;<volume>19</volume>(<issue>7</issue>):<fpage>394</fpage>–<lpage>405</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2015.05.004" xlink:type="simple">10.1016/j.tics.2015.05.004</ext-link></comment> <object-id pub-id-type="pmid">26051384</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sreenivasan</surname> <given-names>KK</given-names></name>, <name name-style="western"><surname>Curtis</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>D’Esposito</surname> <given-names>M</given-names></name>. <article-title>Revisiting the role of persistent neural activity during working memory</article-title>. <source>Trends Cogn Sci</source>. <year>2014</year>;<volume>18</volume>(<issue>2</issue>):<fpage>82</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2013.12.001" xlink:type="simple">10.1016/j.tics.2013.12.001</ext-link></comment> <object-id pub-id-type="pmid">24439529</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petrides</surname> <given-names>M</given-names></name>. <article-title>Dissociable roles of mid-dorsolateral prefrontal and anterior inferotemporal cortex in visual working memory</article-title>. <source>J Neurosci</source>. <year>2000</year>;<volume>20</volume>(<issue>19</issue>):<fpage>7496</fpage>–<lpage>503</lpage>. <object-id pub-id-type="pmid">11007909</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pasternak</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Greenlee</surname> <given-names>MW</given-names></name>. <article-title>Working memory in primate sensory systems</article-title>. <source>Nat Rev Neurosci</source>. <year>2005</year>;<volume>6</volume>(<issue>2</issue>):<fpage>97</fpage>–<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn1603" xlink:type="simple">10.1038/nrn1603</ext-link></comment> <object-id pub-id-type="pmid">15654324</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref015"><label>15</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Postle</surname> <given-names>BR</given-names></name>. <chapter-title>Neural Bases of the Short-Term Retention of Visual Information</chapter-title>. In: <source>Attention &amp; Performance XXV: Mechanisms of Sensory Working Memory</source>. <publisher-name>Elsevier</publisher-name>; <year>2015</year>. p. <fpage>43</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1982</year>;<volume>79</volume>:<fpage>2554</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">6953413</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sandberg</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tegnér</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lansner</surname> <given-names>A</given-names></name>. <article-title>A working memory model based on fast Hebbian learning</article-title>. <source>Network</source>. <year>2003</year>;<volume>14</volume>(<issue>4</issue>):<fpage>789</fpage>–<lpage>802</lpage>. <object-id pub-id-type="pmid">14653503</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mongillo</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>. <article-title>Synaptic theory of working memory</article-title>. <source>Science</source>. <year>2008</year>;<volume>319</volume>:<fpage>1543</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1150769" xlink:type="simple">10.1126/science.1150769</ext-link></comment> <object-id pub-id-type="pmid">18339943</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szatmáry</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>. <article-title>Spike-Timing Theory of Working Memory</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e1000879</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000879" xlink:type="simple">10.1371/journal.pcbi.1000879</ext-link></comment> <object-id pub-id-type="pmid">20808877</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buhmann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schulten</surname> <given-names>K</given-names></name>. <article-title>Associative recognition and storage in a model network of physiological neurons</article-title>. <source>Biol Cybern</source>. <year>1986</year>;<volume>54</volume>(<issue>4–5</issue>):<fpage>319</fpage>–<lpage>35</lpage>. <object-id pub-id-type="pmid">3755622</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref021"><label>21</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Schneegans</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>. <chapter-title>Dynamic field theory as a framework for understanding embodied cognition</chapter-title>. <source>Handbook of Cognitive Science: An Embodied Approach</source>. <publisher-name>Elsevier Inc.</publisher-name>; <year>2008</year>. <fpage>241</fpage>–<lpage>271</lpage> p.</mixed-citation></ref>
<ref id="pone.0188562.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fiebig</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Lansner</surname> <given-names>A</given-names></name>. <article-title>A Spiking Working Memory Model Based on Hebbian Short-Term Potentiation</article-title>. <year>2017</year>;<volume>37</volume>(<issue>1</issue>):<fpage>83</fpage>–<lpage>96</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1989-16.2016" xlink:type="simple">10.1523/JNEUROSCI.1989-16.2016</ext-link></comment> <object-id pub-id-type="pmid">28053032</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>. <article-title>The neural code between neocortical pyramidal neurons depends</article-title>. <source>Proc Natl Acad Sci</source>. <year>1997</year>;<volume>94</volume>(<issue>2</issue>):<fpage>719</fpage>–<lpage>23</lpage>. <object-id pub-id-type="pmid">9012851</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beer</surname> <given-names>R</given-names></name>. <article-title>On the dynamics of small continuous-time recurrent neural networks</article-title>. <source>Adapt Behav</source>. <year>1995</year>;<volume>3</volume>:<fpage>471</fpage>–<lpage>511</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amit</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Gutfreund</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Storing infinite numbers of patterns in a spin-glass model of neural networks</article-title>. <source>Phys Rev Lett</source>. <year>1985</year>;<volume>55</volume>(<issue>14</issue>):<fpage>1530</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.55.1530" xlink:type="simple">10.1103/PhysRevLett.55.1530</ext-link></comment> <object-id pub-id-type="pmid">10031847</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ben-Yishai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bar-Or</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Theory of orientation tuning in visual cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1995</year>;<volume>92</volume>(<issue>9</issue>):<fpage>3844</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">7731993</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Itskov</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Hansel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>. <article-title>Short-term facilitation may stabilize parametric working memory trace</article-title>. <source>Front Comput Neurosci</source>. <year>2011</year>;<volume>5</volume>:<fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2011.00001" xlink:type="simple">10.3389/fncom.2011.00001</ext-link></comment></mixed-citation></ref>
<ref id="pone.0188562.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>YE</given-names></name>. <article-title>The what, where and how of auditory-object perception</article-title>. <source>Nat Rev Neurosci</source>. <year>2013</year>;<volume>14</volume>(<issue>10</issue>):<fpage>693</fpage>–<lpage>707</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3565" xlink:type="simple">10.1038/nrn3565</ext-link></comment> <object-id pub-id-type="pmid">24052177</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Micheyl</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Oxenham</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Pressnitzer</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Temporal Coherence and the Streaming of Complex Sounds</article-title>. <source>Adv Exp Med Biol</source>. <year>2013</year>;<volume>787</volume>:<fpage>535</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-1-4614-1590-9_59" xlink:type="simple">10.1007/978-1-4614-1590-9_59</ext-link></comment> <object-id pub-id-type="pmid">23716261</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Micheyl</surname> <given-names>C</given-names></name>. <article-title>Temporal coherence and attention in auditory scene analysis</article-title>. <source>Trends Neurosci</source>. <year>2011</year>;<volume>34</volume>(<issue>3</issue>):<fpage>114</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2010.11.002" xlink:type="simple">10.1016/j.tins.2010.11.002</ext-link></comment> <object-id pub-id-type="pmid">21196054</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shen</surname> <given-names>L</given-names></name>. <article-title>Neural Integration by Short Term Potentiation</article-title>. <source>Biol Cybern</source>. <year>1989</year>;<volume>61</volume>:<fpage>319</fpage>–<lpage>25</lpage>. <object-id pub-id-type="pmid">2550085</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goldman</surname> <given-names>MS</given-names></name>. <article-title>Memory without Feedback in a Neural Network</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>61</volume>(<issue>4</issue>):<fpage>621</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2008.12.012" xlink:type="simple">10.1016/j.neuron.2008.12.012</ext-link></comment> <object-id pub-id-type="pmid">19249281</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref033"><label>33</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>McDougal</surname> <given-names>RA</given-names></name>. <source>Excitatory-inhibitory interactions as the basis of working memory</source>. <publisher-name>Ohio State University</publisher-name>; <year>2011</year>.</mixed-citation></ref>
<ref id="pone.0188562.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lim</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Goldman</surname> <given-names>MS</given-names></name>. <article-title>Balanced cortical microcircuitry for maintaining short-term memory</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>(<issue>9</issue>):<fpage>1306</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3492" xlink:type="simple">10.1038/nn.3492</ext-link></comment> <object-id pub-id-type="pmid">23955560</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>. <article-title>Persistent activity in neural networks with dynamic synapses</article-title>. <source>PLoS Comput Biol</source>. <year>2007</year>;<volume>3</volume>(<issue>2</issue>):<fpage>0323</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fuster</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Alexander</surname> <given-names>GE</given-names></name>. <article-title>Neuron Activity Related to Short-Term Memory</article-title>. Vol. <volume>173</volume>, <source>Science</source>. <year>1971</year>. p. <fpage>652</fpage>–<lpage>4</lpage>. <object-id pub-id-type="pmid">4998337</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Courtney</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Keil</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>J V</given-names></name>. <article-title>Transient and sustained activity in a distributed neural system for human working memory</article-title>. Vol. <volume>386</volume>, <source>Nature</source>. <year>1997</year>. p. <fpage>608</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/386608a0" xlink:type="simple">10.1038/386608a0</ext-link></comment> <object-id pub-id-type="pmid">9121584</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaminski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sullivan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mamelak</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rutishauser</surname> <given-names>U</given-names></name>. <article-title>Persistently active neurons in human medial frontal and medial temporal lobe supporting working memory</article-title>. <source>Nat Neurosci</source>. <year>2017</year>;<volume>20</volume>(<issue>4</issue>):<fpage>590</fpage>–<lpage>601</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4509" xlink:type="simple">10.1038/nn.4509</ext-link></comment> <object-id pub-id-type="pmid">28218914</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leavitt</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Mendoza-halliday</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Martinez-trujillo</surname> <given-names>JC</given-names></name>. <article-title>Sustained Activity Encoding Working Memories: Not Fully Distributed</article-title>. <source>Trends Neurosci</source>. <year>2017</year>;<volume>40</volume>(<issue>6</issue>):<fpage>328</fpage>–<lpage>46</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2017.04.004" xlink:type="simple">10.1016/j.tins.2017.04.004</ext-link></comment> <object-id pub-id-type="pmid">28515011</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wimmer</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nykamp</surname> <given-names>DQ</given-names></name>, <name name-style="western"><surname>Constantinidis</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Compte</surname> <given-names>A</given-names></name>. <article-title>Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>3</issue>):<fpage>431</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3645" xlink:type="simple">10.1038/nn.3645</ext-link></comment> <object-id pub-id-type="pmid">24487232</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lansner</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fransen</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sandberg</surname> <given-names>A</given-names></name>. <article-title>Cell Assembly Dynamics in Detailed and Abstract Attractor Models of Cortical Associative Memory</article-title>. <source>Theory Biosci</source>. <year>2003</year>;<volume>122</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amit</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Fusi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yakovlev</surname> <given-names>V</given-names></name>. <article-title>Paradigmatic working memory (attractor) cell in IT cortex</article-title>. <source>Neural Comput</source>. <year>1997</year>;<volume>9</volume>(<issue>5</issue>):<fpage>1071</fpage>–<lpage>92</lpage>. <object-id pub-id-type="pmid">9188192</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubreuil</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>. <article-title>Storing structured sparse memories in a multi-modular cortical network model</article-title>. <source>J Comput Neurosci</source>. <year>2016</year>;<volume>40</volume>(<issue>2</issue>):<fpage>157</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-016-0590-z" xlink:type="simple">10.1007/s10827-016-0590-z</ext-link></comment> <object-id pub-id-type="pmid">26852335</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verduzco-Flores</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bodner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ermentrout</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Fuster</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>Y</given-names></name>. <article-title>Working memory cells’ behavior may be explained by cross-regional networks with synaptic facilitation</article-title>. <source>PLoS One</source>. <year>2009</year>;<volume>4</volume>(<issue>8</issue>):<fpage>e6399</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0006399" xlink:type="simple">10.1371/journal.pone.0006399</ext-link></comment> <object-id pub-id-type="pmid">19652716</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sugase-Miyamoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wiener</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Optican</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Richmond</surname> <given-names>BJ</given-names></name>. <article-title>Short-term memory trace in rapidly adapting synapses of inferior temporal cortex</article-title>. <source>PLoS Comput Biol</source>. <year>2008</year>;<volume>4</volume>(<issue>5</issue>):<fpage>e1000073</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000073" xlink:type="simple">10.1371/journal.pcbi.1000073</ext-link></comment> <object-id pub-id-type="pmid">18464917</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dranias</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Ju</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Rajaram</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>VanDongen</surname> <given-names>AMJ</given-names></name>. <article-title>Short-Term Memory in Networks of Dissociated Cortical Neurons</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>(<issue>5</issue>):<fpage>1940</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2718-12.2013" xlink:type="simple">10.1523/JNEUROSCI.2718-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23365233</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref047"><label>47</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kandel</surname> <given-names>ER</given-names></name>. <chapter-title>Cellular Mechanisms of Learning and the Biological Basis of Individuality</chapter-title>. In: <source>Principles of Neural Science</source>. <publisher-name>McGraw-Hill Companies, Inc.</publisher-name>; <year>2014</year>. p. <fpage>1248</fpage>–<lpage>80</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erickson</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Maramara</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Lisman</surname> <given-names>J</given-names></name>. <article-title>A single 2-spike burst induces GluR1-dependent associative short-term potentiation: a potential mechanism for short term memory</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year>;<volume>22</volume>(<issue>11</issue>):<fpage>2530</fpage>–<lpage>40</lpage>.</mixed-citation></ref>
<ref id="pone.0188562.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malenka</surname> <given-names>RC</given-names></name>. <article-title>Postsynaptic factors control the duration of synaptic enhancement in area CA1 of the hippocampus</article-title>. <source>Neuron</source>. <year>1991</year>;<volume>6</volume>(<issue>1</issue>):<fpage>53</fpage>–<lpage>60</lpage>. <object-id pub-id-type="pmid">1670922</object-id></mixed-citation></ref>
<ref id="pone.0188562.ref050"><label>50</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hebb</surname> <given-names>DO</given-names></name>. <source>The Organization of Behavior</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1949</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>