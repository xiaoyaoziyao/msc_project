<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-54263</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0105206</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Cognitive neurology</subject></subj-group></subj-group><subj-group><subject>Neural networks</subject><subject>Neuroimaging</subject><subject>Neuropsychology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject></subj-group></subj-group></subj-group><subj-group><subject>Neurology</subject><subj-group><subject>Locked-in syndrome</subject></subj-group></subj-group><subj-group><subject>Radiology and imaging</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Neural Network Approach to fMRI Binocular Visual Rivalry Task Analysis</article-title>
<alt-title alt-title-type="running-head">fMRI Binocular Visual Rivalry Task Analysis</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bertolino</surname><given-names>Nicola</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ferraro</surname><given-names>Stefania</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Nigri</surname><given-names>Anna</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bruzzone</surname><given-names>Maria Grazia</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ghielmetti</surname><given-names>Francesco</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><on-behalf-of>on behalf of the Coma Research Centre (CRC) – Besta Institute</on-behalf-of></contrib>
<contrib contrib-type="author" xlink:type="simple"><collab xlink:type="simple">The Coma Research Centre (CRC) multidisciplinary team, on behalf of which the present publication was submitted, acknowledges the following members:<contrib-group>
<contrib xlink:type="simple"><name name-style="western"><surname>Leonardi</surname><given-names>Matilde</given-names></name><aff>Scientific Director CRC</aff>
</contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Agostino Parati</surname><given-names>Eugenio</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Grazia Bruzzone</surname><given-names>Maria</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Franceschetti</surname><given-names>Silvana</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Caldiroli</surname><given-names>Dario</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Sattin</surname><given-names>Davide</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Giovannetti</surname><given-names>Ambra</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Pagani</surname><given-names>Marco</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Covelli</surname><given-names>Venusia</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Ciaraffa</surname><given-names>Francesca</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Vela Gomez</surname><given-names>Jesus</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Reggiori</surname><given-names>Barbara</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Ferraro</surname><given-names>Stefania</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Nigri</surname><given-names>Anna</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>D'Incerti</surname><given-names>Ludovico</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Minati</surname><given-names>Ludovico</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Andronache</surname><given-names>Adrian</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Rosazza</surname><given-names>Cristina</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Fazio</surname><given-names>Patrik</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Rossi</surname><given-names>Davide</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Varotto</surname><given-names>Giulia</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Panzica</surname><given-names>Ferruccio</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Benti</surname><given-names>Riccardo</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Marotta</surname><given-names>Giorgio</given-names></name></contrib>
<contrib xlink:type="simple"><name name-style="western"><surname>Molteni</surname><given-names>Franco</given-names></name></contrib>
</contrib-group></collab></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Health Department, Carlo Besta Neurological Institute, Milan, Italy</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Neuro-Radiology Department, Carlo Besta Neurological Institute, Milan, Italy</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Stamatakis</surname><given-names>Emmanuel Andreas</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University Of Cambridge, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">nicola.bertolino@istituto-besta.it</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: NB SF AN MGB FG. Performed the experiments: NB FS AN. Analyzed the data: NB SF AN FG. Contributed reagents/materials/analysis tools: MGB. Wrote the paper: NB SF AN MGB FG.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>14</day><month>8</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>8</issue>
<elocation-id>e105206</elocation-id>
<history>
<date date-type="received"><day>27</day><month>12</month><year>2013</year></date>
<date date-type="accepted"><day>22</day><month>7</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Bertolino et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>The purpose of this study was to investigate whether artificial neural networks (ANN) are able to decode participants’ conscious experience perception from brain activity alone, using complex and ecological stimuli. To reach the aim we conducted pattern recognition data analysis on fMRI data acquired during the execution of a binocular visual rivalry paradigm (BR). Twelve healthy participants were submitted to fMRI during the execution of a binocular non-rivalry (BNR) and a BR paradigm in which two classes of stimuli (faces and houses) were presented. During the binocular rivalry paradigm, behavioral responses related to the switching between consciously perceived stimuli were also collected. First, we used the BNR paradigm as a functional localizer to identify the brain areas involved the processing of the stimuli. Second, we trained the ANN on the BNR fMRI data restricted to these regions of interest. Third, we applied the trained ANN to the BR data as a ‘brain reading’ tool to discriminate the pattern of neural activity between the two stimuli. Fourth, we verified the consistency of the ANN outputs with the collected behavioral indicators of which stimulus was consciously perceived by the participants. Our main results showed that the trained ANN was able to generalize across the two different tasks (i.e. BNR and BR) and to identify with high accuracy the cognitive state of the participants (i.e. which stimulus was consciously perceived) during the BR condition. The behavioral response, employed as control parameter, was compared with the network output and a statistically significant percentage of correspondences (p-value &lt;0.05) were obtained for all subjects. In conclusion the present study provides a method based on multivariate pattern analysis to investigate the neural basis of visual consciousness during the BR phenomenon when behavioral indicators lack or are inconsistent, like in disorders of consciousness or sedated patients.</p>
</abstract>
<funding-group><funding-statement>The start-up Coma Research Centre (CRC) project was funded by a healthcare grant (N° IX/000407 - 05/08/2010) awarded by Regione Lombardia. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="7"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Multivariate pattern analysis (MVPA) is able to process information coming from differently located clusters of voxels and makes it possible to detect particular patterns of neural activity that may remain hidden to conventional analyses (e.g., univariate statistical methods) <xref ref-type="bibr" rid="pone.0105206-Norman1">[1]</xref>. Indeed, in these last years, MVPA has been extensively applied as a “mind reading” tool to decode mental states from functional magnetic resonance imaging (fMRI) data, such as to assess perceptual states <xref ref-type="bibr" rid="pone.0105206-Pereira1">[2]</xref> or to evaluate deception and differentiate lying from truth-telling <xref ref-type="bibr" rid="pone.0105206-Gao1">[3]</xref>, <xref ref-type="bibr" rid="pone.0105206-Langleben1">[4]</xref>, <xref ref-type="bibr" rid="pone.0105206-Davatzikos1">[5]</xref>. A great interest arose around fMRI studies using MVPA that allowed the investigation of how the contents of conscious experience are encoded in the brain <xref ref-type="bibr" rid="pone.0105206-Weil1">[6]</xref>.</p>
<p>Most of the work on this topic examined only the prediction of static and unchanging perceptual states during extended periods of stimulation <xref ref-type="bibr" rid="pone.0105206-Minati1">[7]</xref>, <xref ref-type="bibr" rid="pone.0105206-MouraoMiranda1">[8]</xref>, <xref ref-type="bibr" rid="pone.0105206-Yamamura1">[9]</xref>.</p>
<p>A dynamic perceptual phenomenon particularly suitable to be studied with MVPA is the binocular visual rivalry (BR): two different visual stimuli are presented, one to each eye, and the two conflicting monocular images compete for access to consciousness and the subject usually experiences an alternate perception of the two images. The perceptual dominance of one image can endure for a few seconds before switching to the other, fluctuating stochastically over time <xref ref-type="bibr" rid="pone.0105206-Blake1">[10]</xref>, <xref ref-type="bibr" rid="pone.0105206-Blake2">[11]</xref>. Thus, the visual input is the same, but the perceptual interpretation changes. Due to this characteristic, the BR paradigm was shown to be an important tool to explore the neural correlates of visual conscious experience <xref ref-type="bibr" rid="pone.0105206-Blake2">[11]</xref>, <xref ref-type="bibr" rid="pone.0105206-Zhang1">[12]</xref>.</p>
<p>In this framework, Haynes et al. (2005) investigated BR using MVPA on fMRI signals <xref ref-type="bibr" rid="pone.0105206-Haynes1">[13]</xref>. They showed that linear discriminant analysis was able to predict in healthy subjects from brain activity alone the stream of visual consciousness by means of the fluctuation between two classes of simple stimuli (blue and red orthogonal rotating gratings). This study also demonstrated that accurate prediction of the perception during BR could be established with signals recorded during stable monocular viewing, suggesting the possibility to use this approach in the absence of behavioral indicators, such as in animals or patients with locked-in syndrome.</p>
<p>A seminal study by Tong et al. (1998) demonstrated that during BR in which houses and faces were presented, the fusiform face area (FFA) and the parahippocampal place area (PPA) reflected the perceived stimulus, showing that changes from house to face led to an increase in blood oxygen level dependent (BOLD) signal in FFA and a decrease in PPA, while changes from face to house led to the opposite pattern. Moreover they showed a striking resemblance of BOLD signal changes during non-rivalry and rivalry paradigms, not only in the qualitative pattern but also in the amplitude of FFA and PPA responses <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref>. However, they did not test for generalization between training with non-rivalry, and testing with rivalry in absence of behavior.</p>
<p>The brain regions involved in the processing of these stimuli are the bilateral occipital area, collateral sulcus, PPA, occipital face area (OFA), and FFA. In particular FFA and OFA were identified as areas responding more to face stimuli, whereas bilateral PPA as more reactive to houses and objects <xref ref-type="bibr" rid="pone.0105206-Rossion1">[15]</xref>, <xref ref-type="bibr" rid="pone.0105206-Cant1">[16]</xref>.</p>
<p>These results allowed us to investigate whether multivariate classification methods are able to decode a dynamic perception phenomenon of complex and ecological stimuli using rivalry and non-rivalry paradigms.</p>
<p>The aim of our study was to provide a method based on artificial neural networks (ANN) <xref ref-type="bibr" rid="pone.0105206-Picton1">[17]</xref> able to identify the different neural pattern of activity related to the processing of two classes of visual stimuli (houses and faces) during a visual rivalry paradigm, applicable in the absence of behavioral indicators, indicating which stimulus is perceived by participant.</p>
<p>We studied 12 healthy subjects with fMRI as they viewed binocular non-rivalry (BNR) and BR tasks. First we used the BNR to identify brain areas involved in face and house decoding, then we trained the ANN on these data, and finally we employed the trained ANN in order to discriminate the pattern of activity in BR task analysis and verified the consistency of these results with the behavioral response.</p>
<p>A major challenge of this study was the signal decoding due to a low signal to noise ratio (SNR). Many system imperfections and physical phenomena (eddy currents, asymmetric anti-aliasing filter response, concomitant magnetic field, mismatched gradient group delays, and hysteresis) affected echo planar imaging (EPI), and especially sequences with short TR, by artifacts and signal loss <xref ref-type="bibr" rid="pone.0105206-Bernstein1">[18]</xref>. Hence, a processing protocol for signal optimization was implemented in order to increase the network performance.</p>
</sec><sec id="s2" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s2a">
<title>Participants</title>
<p>We recruited 12 healthy volunteers for this study (mean age 32.5 years, range 18–47 years) with no history of neurological disease, 5 of whom were female. The experimental protocol was approved by the ethics committee (Comitato Etico) of IRCCS Carlo Besta Neurological Institute and all the participants gave written informed consent. All clinical investigation has been conducted according to the principles expressed in the Declaration of Helsinki.</p>
</sec><sec id="s2b">
<title>MRI acquisitions</title>
<p>Anatomical and functional data were collected using a 3.0 Tesla MRI scanner (Achieva TX, Philips Medical Systems BV, Best, NL) equipped with a 32 channel phase-array head coil. Each participant underwent to an imaging protocol including anatomical 3D T1 (TFE with FOV = 240×240 mm<sup>2</sup> and voxel = 1×1×1 mm<sup>3</sup>, TR/TE = 9.8/4.6 ms) and two EPI sequences, one for the BNR (200 volumes) and the other for the BR fMRI paradigm (600 volumes). Both fMRI sequences had a FOV = 240×240 mm<sup>2</sup>, an isotropic voxel (3×3×3 mm<sup>3</sup>), a 90° flip angle and a TE = 40 ms. The TR of the BNR-localizer sequence was 3000 ms, while for the rivalry sequence TR was 1000 ms. We chose a short TR of 1000 ms for the BR sequence in order to be sure to capture the rapid alternate perception between the two images. The perception dominance of one image was shown to be in the range between 2.5 to 5.5 s <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref>. Because of the different TR, slices number of the package was set to 30 for the first EPI sequence and 16 for the second.</p>
</sec><sec id="s2c">
<title>fMRI paradigms</title>
<p>All participants performed two fMRI block design tasks (<xref ref-type="fig" rid="pone-0105206-g001">Fig. 1</xref>): the BNR-localizer and the BR paradigm. During the BNR-localizer task participants were presented with 5 blocks showing a set of faces alternating with 5 blocks showing a set of houses, spaced out by 10 rest blocks. Each block duration was 30 seconds and included 10 stimuli, each shown for 3 seconds.</p>
<fig id="pone-0105206-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.g001</object-id><label>Figure 1</label><caption>
<title>Diagrams showing the fMRI block tasks design.</title>
<p>The letter H in the red box represents the house block, the letter F in the blue box represents the face block, and the white cross in the black box represents the rest block. The BNR task is shown on the top, while the BR task is shown on the bottom.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.g001" position="float" xlink:type="simple"/></fig>
<p>During the BR task participants were presented with 15 picture blocks broken up by 15 rest blocks. For the picture blocks, a house was shown to one eye and a face was shown to the other simultaneously. These two pictures were chosen from those used for the BNR-localizer task. Each block duration was 20 seconds. The house and face images were presented to the right and left eye, respectively, for half of the participants, and vice versa for the other half. For both tasks a white fixation cross on a black background was presented during rest blocks. Additionally the house pictures were red-filtered while the face pictures were blue-filtered in order to employ stimuli similar to the ones used in the previous literature <xref ref-type="bibr" rid="pone.0105206-Haynes1">[13]</xref>, <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref> and to increase the perceptual differences between the two classes of stimuli.</p>
<p>All the participants were provided with a pair of stereo LCD goggles for visual stimulation, a pair of headphones, and two keypads (VisuaStim, Resonance Technology Inc., Northridge CA, USA). During the BR task participants were asked to indicate which picture they perceived by pressing a button on the keypad at transition points from one stimulus perception to the other, and behavioral data were collected.</p>
</sec><sec id="s2d">
<title>Data Analysis</title>
<p>In order to illustrate the multiple steps of the method employed, a flow chart is provided in <xref ref-type="fig" rid="pone-0105206-g002">Fig. 2</xref>.</p>
<fig id="pone-0105206-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.g002</object-id><label>Figure 2</label><caption>
<title>Diagram illustrating signal processing steps.</title>
<p>In the green boxes the steps concerning the BNR ROI signals are described, in the blue boxes the steps concerning BR ROI signals are described, and in the orange boxes the steps in common for both signals are described.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.g002" position="float" xlink:type="simple"/></fig>
<p>For all the data analyses we used SPM 8 (Statistical Parametric Mapping, <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk" xlink:type="simple">http://www.fil.ion.ucl.ac.uk</ext-link>), MatLab 7.13 (The MathWorks Inc., Natick, MA, 2012), and SPSS 17.0 (SPSS Inc., Chicago, 2008).</p>
</sec><sec id="s2e">
<title>Behavioral data analysis</title>
<p>During the BR task, the mean value of the duration of the perceptual dominance for each image (house or face) and its standard deviation were calculated for each participant and for the whole group.</p>
</sec><sec id="s2f">
<title>Data preprocessing</title>
<p>Both fMRI acquisitions (i.e., BNR and BR scans) were co-registered to the T1 and pre-processed to correct 3D motion artifacts, linear drifts, and low-frequency non linear drifts. Spatial smoothing was applied using a Gaussian kernel with a 5 mm full width at half maximum isotropic. For the BR scan, a slice timing correction was also performed.</p>
</sec><sec id="s2g">
<title>Single-subject analysis and ROIs identification</title>
<p>In order to identify the functional regions of interest (ROIs) (i.e., FFA, PPA, and OFA) necessary to extract the time course signals to train and to run the ANN we performed standard single-subject analyses <xref ref-type="bibr" rid="pone.0105206-Turner1">[19]</xref> on the BNR-localizer data in the framework of the general linear model (GLM). In the design matrix we modeled the presentations of faces and houses as predictors. We performed two t-contrasts: faces&gt;houses and houses&gt;faces <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref>. The package volume of the sequence, employed in the BR task, was applied as an inclusive mask to the obtained con-images in order to verify that the identified areas were included in the BR acquisition package and to control for I type error <xref ref-type="bibr" rid="pone.0105206-Poldrack1">[20]</xref>. For every single subject the activations clusters, resulting from the analysis, were selected as ROIs with a voxel-level threshold of <italic>P</italic>&lt;0.05 FWE-corrected and a minimum cluster size of 5 voxels. If using these threshold at least N = 3 ROIs (1 ROI for the first t-contrast and 2 ROIs for the second) were not identified, the voxel-level threshold was moved to p&lt;0.05 FDR corrected. A maximum of 3 ROIs for contrast was extracted based on higher T-score. The peak MNI coordinates of every activation cluster, selected as ROI for each subject, is provided in <xref ref-type="table" rid="pone-0105206-t001">Table 1</xref>.</p>
<table-wrap id="pone-0105206-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.t001</object-id><label>Table 1</label><caption>
<title>Selected ROIs coordinates.</title>
</caption><alternatives><graphic id="pone-0105206-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td colspan="12" align="left" rowspan="1">Faces-houses t-contrast</td>
<td colspan="6" align="left" rowspan="1">Houses-Faces t-contrast</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td colspan="3" align="left" rowspan="1">FFA right</td>
<td colspan="3" align="left" rowspan="1">FFA left</td>
<td colspan="3" align="left" rowspan="1">OFA right</td>
<td colspan="3" align="left" rowspan="1">OFA left</td>
<td colspan="3" align="left" rowspan="1">PPA right</td>
<td colspan="3" align="left" rowspan="1">PPA left</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Subject #</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
<td align="left" rowspan="1" colspan="1">x</td>
<td align="left" rowspan="1" colspan="1">y</td>
<td align="left" rowspan="1" colspan="1">z</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">−46</td>
<td align="left" rowspan="1" colspan="1">−22</td>
<td align="left" rowspan="1" colspan="1">−42</td>
<td align="left" rowspan="1" colspan="1">−60</td>
<td align="left" rowspan="1" colspan="1">−20</td>
<td align="left" rowspan="1" colspan="1">42</td>
<td align="left" rowspan="1" colspan="1">−68</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">28</td>
<td align="left" rowspan="1" colspan="1">−46</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">−28</td>
<td align="left" rowspan="1" colspan="1">−54</td>
<td align="left" rowspan="1" colspan="1">−8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">−54</td>
<td align="left" rowspan="1" colspan="1">−16</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">30</td>
<td align="left" rowspan="1" colspan="1">−50</td>
<td align="left" rowspan="1" colspan="1">−8</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−50</td>
<td align="left" rowspan="1" colspan="1">−10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">58</td>
<td align="left" rowspan="1" colspan="1">−28</td>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1">−</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">36</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−12</td>
<td align="left" rowspan="1" colspan="1">−28</td>
<td align="left" rowspan="1" colspan="1">−36</td>
<td align="left" rowspan="1" colspan="1">−4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">46</td>
<td align="left" rowspan="1" colspan="1">−48</td>
<td align="left" rowspan="1" colspan="1">−18</td>
<td align="left" rowspan="1" colspan="1">−42</td>
<td align="left" rowspan="1" colspan="1">−48</td>
<td align="left" rowspan="1" colspan="1">−20</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">32</td>
<td align="left" rowspan="1" colspan="1">−48</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">−28</td>
<td align="left" rowspan="1" colspan="1">−50</td>
<td align="left" rowspan="1" colspan="1">−8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">38</td>
<td align="left" rowspan="1" colspan="1">−44</td>
<td align="left" rowspan="1" colspan="1">−20</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">−68</td>
<td align="left" rowspan="1" colspan="1">−2</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">24</td>
<td align="left" rowspan="1" colspan="1">−42</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−46</td>
<td align="left" rowspan="1" colspan="1">−12</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">44</td>
<td align="left" rowspan="1" colspan="1">−52</td>
<td align="left" rowspan="1" colspan="1">−22</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">−70</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">32</td>
<td align="left" rowspan="1" colspan="1">−48</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">−28</td>
<td align="left" rowspan="1" colspan="1">−56</td>
<td align="left" rowspan="1" colspan="1">−10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">−44</td>
<td align="left" rowspan="1" colspan="1">−50</td>
<td align="left" rowspan="1" colspan="1">−24</td>
<td align="left" rowspan="1" colspan="1">38</td>
<td align="left" rowspan="1" colspan="1">−72</td>
<td align="left" rowspan="1" colspan="1">−20</td>
<td align="left" rowspan="1" colspan="1">−38</td>
<td align="left" rowspan="1" colspan="1">−78</td>
<td align="left" rowspan="1" colspan="1">−10</td>
<td align="left" rowspan="1" colspan="1">26</td>
<td align="left" rowspan="1" colspan="1">−50</td>
<td align="left" rowspan="1" colspan="1">−14</td>
<td align="left" rowspan="1" colspan="1">−24</td>
<td align="left" rowspan="1" colspan="1">−52</td>
<td align="left" rowspan="1" colspan="1">−14</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">−60</td>
<td align="left" rowspan="1" colspan="1">−18</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">30</td>
<td align="left" rowspan="1" colspan="1">−52</td>
<td align="left" rowspan="1" colspan="1">−8</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−44</td>
<td align="left" rowspan="1" colspan="1">−10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">−38</td>
<td align="left" rowspan="1" colspan="1">−56</td>
<td align="left" rowspan="1" colspan="1">−18</td>
<td align="left" rowspan="1" colspan="1">44</td>
<td align="left" rowspan="1" colspan="1">−80</td>
<td align="left" rowspan="1" colspan="1">−18</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">28</td>
<td align="left" rowspan="1" colspan="1">−60</td>
<td align="left" rowspan="1" colspan="1">−6</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−52</td>
<td align="left" rowspan="1" colspan="1">−10</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">−40</td>
<td align="left" rowspan="1" colspan="1">−16</td>
<td align="left" rowspan="1" colspan="1">−36</td>
<td align="left" rowspan="1" colspan="1">−48</td>
<td align="left" rowspan="1" colspan="1">−14</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">28</td>
<td align="left" rowspan="1" colspan="1">−40</td>
<td align="left" rowspan="1" colspan="1">−8</td>
<td align="left" rowspan="1" colspan="1">−26</td>
<td align="left" rowspan="1" colspan="1">−44</td>
<td align="left" rowspan="1" colspan="1">−6</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>The table shows the peak MNI coordinates of every activation cluster, selected as ROI for each subject for PPAs, FFAs and OFAs.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2h">
<title>Network input signal preparation</title>
<p>For both BNR and BR datasets, we extracted the fMRI signal time-courses from each voxel in the identified N ROIs and the mean fMRI signal time-course from the whole brain. The ROIs and the mean whole brain signal time-courses obtained from both fMRI task scans were detrended with a third degree polynomial function to eliminate the signal drift. Afterwards, the k-means clusterization algorithm <xref ref-type="bibr" rid="pone.0105206-Goutte1">[21]</xref> was employed to split the BR detrended ROI signal time-courses in two clusters. Considering that the ROIs were selected by the analysis on BNR data, we employed the clusterization algorithm in order to discriminate the voxels participating in BR phenomenon and remove the voxels not involved in the activation pattern and also affected by higher noise. Then, the mean fMRI signal time-course of the remaining voxels of each ROI was calculated.</p>
<p>These signals and the mean fMRI time-course from the whole brain were converted in percent signal changes relative to their mean values over time. In order to minimize most of the non-task-related signal fluctuations, the percent signal changes of the whole brain fMRI signal time-course was subtracted from the percent signal changes of each single ROI <xref ref-type="bibr" rid="pone.0105206-Desjardins1">[22]</xref>; the resulting signal was shifted to account for the BOLD response delay. Finally, we removed the rest block time points and detrended the signals with a second degree polynomial, obtaining the ultimate neural network input signal. In order to assess the reliability of the network output we used the removed rest block time points of the BR dataset as a control signal.</p>
</sec><sec id="s2i">
<title>Training and Running the network</title>
<p>We implemented a one-layer Feed-Forward Neural Network with a Log-Sigmoid Transfer Function <xref ref-type="bibr" rid="pone.0105206-Picton1">[17]</xref>. We chose an hidden layer size of 65 neurons and, as performance function, the Mean Square Error (MSE) relative to the difference between the target outputs (presented stimuli) and the values predicted by the model (network outputs).</p>
<p>The network was trained and run separately for each subject. As a training dataset, we used a matrix in which the columns were the processed BNR ROIs time courses, divided randomly in train set (75%) and valuation set (25%). The training set was used for computing the gradient descent and updating the network weights and biases in the direction in which the performance function decreases more rapidly, while the evaluation set was used for the MSE value computation. At the end of the training, the network weights and biases were saved at the minimum of the MSE. If the training process performance did not achieve a selected threshold (MSE &lt;0.02), chosen to have a good and homogeneous training between subjects <xref ref-type="bibr" rid="pone.0105206-Jiang1">[23]</xref>, the algorithm repeated the process using new initialization seeds (weights and biases).</p>
<p>Next, we ran the trained network using the matrix in which the columns were the processed ROIs BR time courses as input data. The ANN produced an output matrix <bold>X</bold>, in which the rows were the time points and the two columns were the outputs of classification for the presented stimuli in a range between zero and one. The ideal output matrix row (1 0) represented the face, while (0 1) represented the house. In order to assign time points to one of the two conditions, we set up a threshold |X<sub>t,1</sub>– X<sub>t,2</sub>| &gt;0.9, where t = 1,…,N, with N number of time points. If a time point did not reach the threshold, it was labeled as not assigned and discarded; the whole process, including training and run, was reiterated until the number of unassigned time points was smaller than 16.7%.</p>
<p>To evaluate the accuracy of the network to discriminate between perception status, we computed (1) the percentage of successes, obtained comparing the network output with the behavioral response vector, and (2) the p-value, obtained by using a binomial distribution, considering two conditions with a probability of 50% to be equal or different from behavioral responses.</p>
</sec><sec id="s2j">
<title>Assessment of reliability of the network output</title>
<p>As the network weights and biases change during initialization and optimization, the resulting output is affected by a certain variability, reflecting the stochastic nature of ANN training <xref ref-type="bibr" rid="pone.0105206-Jiang1">[23]</xref>. Hence, to evaluate the consistency of the results, for each subject we repeated the whole process described in the previous section 1000 times. In order to have a negative control set of data we applied the 1000 repetition again substituting the BR with the rest block time-course. For each repetition we collected the number of time points assigned to houses or faces. Based on the hypothesis that the rest block signal is unrelated to BR phenomenon, in order to highlight differences between the distribution of predicted stimuli (houses and faces), we analyzed the different outputs. Frequency histograms of houses and faces were produced and normality tests <xref ref-type="bibr" rid="pone.0105206-Shapiro1">[24]</xref> were performed on the distribution of percentage value of the two stimuli over the total time points allocated along with mean, variance, kurtosis, and asymmetry computation. We expect that for participants who experienced the phenomenon, the event distribution in the BR-task signal ANN output is balanced between the two stimuli (i.e. ratio between the percentage of number of houses and faces &gt;1/4) and leptokurtic or at the most normally distributed over the 1000 reiterations. We also collected evaluative information performing a comparison between the task and the rest block signal ANN output (control). This signal is expected to be characterized by a more asymmetric and/or platykurtic events distribution and/or an unbalanced distribution between stimuli, with a larger variance, because of the unpredictable random effects involved in the ANN time points attribution of a non-task-related signal.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<p>We discarded two of the subjects from our analysis: the first because we did not find the expected activations (FFAs, OFAs, PPAs) during the GLM analysis of BNR paradigm, and the second because the subject declared that he did not experience the perception alternation phenomenon.</p>
<p>During the BR paradigm, the participants reported alternations between face-dominant and house-dominant percepts. The mean phase duration was 3.37 s (range: 1.78 to 4.47 s; standard deviation = 0.93 s).</p>
<p>Consistent with the literature <xref ref-type="bibr" rid="pone.0105206-Rossion1">[15]</xref>, <xref ref-type="bibr" rid="pone.0105206-Cant1">[16]</xref>, the single-subject analysis of BNR data revealed that the participants showed activity for the contrast faces&gt;houses in the posterior fusiform gyrus (i.e., FFA) and in the inferior occipital gyrus (i.e., OFA) (<xref ref-type="fig" rid="pone-0105206-g003">Fig. 3A</xref>), while for the contrast houses&gt;faces in the parahippocampal gyrus (<xref ref-type="fig" rid="pone-0105206-g003">Fig. 3B</xref>). We identified a maximum of 5 ROIs for 2 participants, 4 ROIs for 5 participants, and 3 ROIs for 3 participants (<xref ref-type="table" rid="pone-0105206-t001">Table 1</xref>).</p>
<fig id="pone-0105206-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.g003</object-id><label>Figure 3</label><caption>
<title>Example of resulting BOLD activity from GLM single-subject analysis of BNR-localizer task.</title>
<p>Picture A shows t-contrast activations of face-house (FWE&lt;0.05) in BNR time-course of PPA on top and FFA ROI on the bottom. Picture B shows t-contrast activations of house-face (FWE&lt;0.05) in BNR-localizer time-course of FFA on top and PPA ROI on the bottom.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.g003" position="float" xlink:type="simple"/></fig>
<p>The mean number of signal time points not assigned to each of the two conditions was 10.7±3.7%.</p>
<p>For 9 of the 10 participants, combined information of 3 ROIs was sufficient to allow the neural network to predict which stimulus the subject was experiencing with up to 75% accuracy (<italic>p</italic>&lt;0.05). When the signals from 4 ROIs were combined the classification accuracy improved slightly for all but 1 participant, and the ANN predicted the perceived stimulus in all the participants (up to 78% accuracy; <italic>p</italic>&lt;0.05). The only 2 participants in which 5 ROIs were detected showed a further slight increase of the accuracy of the neural network (up to 80%; p&lt;0.05) combining the information coming from all of them (<xref ref-type="table" rid="pone-0105206-t002">Table 2</xref>; <xref ref-type="fig" rid="pone-0105206-g004">Fig. 4</xref>).</p>
<fig id="pone-0105206-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.g004</object-id><label>Figure 4</label><caption>
<title>Bar plot of ANN percentage of successes for each subject.</title>
<p>The plot shows in ordinate the percentage of time points correctly allocate to conditions (house or face) and in abscissa the number associated to the participants.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.g004" position="float" xlink:type="simple"/></fig><table-wrap id="pone-0105206-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.t002</object-id><label>Table 2</label><caption>
<title>Results summary.</title>
</caption><alternatives><graphic id="pone-0105206-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td colspan="3" align="left" rowspan="1">3 ROI</td>
<td colspan="3" align="left" rowspan="1">4 ROI</td>
<td colspan="3" align="left" rowspan="1">5 ROI</td>
<td colspan="2" align="left" rowspan="1">Behavioral</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">#</td>
<td align="left" rowspan="1" colspan="1">sex</td>
<td align="left" rowspan="1" colspan="1">age</td>
<td align="left" rowspan="1" colspan="1">Successes %</td>
<td align="left" rowspan="1" colspan="1">p</td>
<td align="left" rowspan="1" colspan="1">Descardedtrials (%)</td>
<td align="left" rowspan="1" colspan="1">Successes %</td>
<td align="left" rowspan="1" colspan="1">p</td>
<td align="left" rowspan="1" colspan="1">Descardedtrials (%)</td>
<td align="left" rowspan="1" colspan="1">Successes %</td>
<td align="left" rowspan="1" colspan="1">p</td>
<td align="left" rowspan="1" colspan="1">Descardedtrials (%)</td>
<td align="left" rowspan="1" colspan="1">mean (s)</td>
<td align="left" rowspan="1" colspan="1">SD (s)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">32</td>
<td align="left" rowspan="1" colspan="1"><bold>58,1</bold></td>
<td align="left" rowspan="1" colspan="1">0,004</td>
<td align="left" rowspan="1" colspan="1">6,7</td>
<td align="left" rowspan="1" colspan="1"><bold>61,7</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">8,7</td>
<td align="left" rowspan="1" colspan="1"><bold>67,6</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">12,6</td>
<td align="left" rowspan="1" colspan="1">3,13</td>
<td align="left" rowspan="1" colspan="1">1,28</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">47</td>
<td align="left" rowspan="1" colspan="1"><bold>56,8</bold></td>
<td align="left" rowspan="1" colspan="1">0,016</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">2,89</td>
<td align="left" rowspan="1" colspan="1">1,28</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">F</td>
<td align="left" rowspan="1" colspan="1">24</td>
<td align="left" rowspan="1" colspan="1"><bold>67,3</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">13,3</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">2,97</td>
<td align="left" rowspan="1" colspan="1">1,08</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">35</td>
<td align="left" rowspan="1" colspan="1"><bold>59,2</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1"><bold>60,5</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">4,47</td>
<td align="left" rowspan="1" colspan="1">1,6</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1"><bold>49,4</bold></td>
<td align="left" rowspan="1" colspan="1">0,603</td>
<td align="left" rowspan="1" colspan="1">16,7</td>
<td align="left" rowspan="1" colspan="1"><bold>56,3</bold></td>
<td align="left" rowspan="1" colspan="1">0,026</td>
<td align="left" rowspan="1" colspan="1">10,3</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">2,57</td>
<td align="left" rowspan="1" colspan="1">1,58</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">17</td>
<td align="left" rowspan="1" colspan="1"><bold>58,2</bold></td>
<td align="left" rowspan="1" colspan="1">0,005</td>
<td align="left" rowspan="1" colspan="1">9,7</td>
<td align="left" rowspan="1" colspan="1"><bold>57,8</bold></td>
<td align="left" rowspan="1" colspan="1">0,009</td>
<td align="left" rowspan="1" colspan="1">14,3</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">1,78</td>
<td align="left" rowspan="1" colspan="1">0,76</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">F</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1"><bold>75,5</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">1,1</td>
<td align="left" rowspan="1" colspan="1"><bold>78,3</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">13,7</td>
<td align="left" rowspan="1" colspan="1"><bold>80,6</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">12,6</td>
<td align="left" rowspan="1" colspan="1">4,35</td>
<td align="left" rowspan="1" colspan="1">2,03</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">37</td>
<td align="left" rowspan="1" colspan="1"><bold>61,3</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">9,7</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">3,97</td>
<td align="left" rowspan="1" colspan="1">2,4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">F</td>
<td align="left" rowspan="1" colspan="1">23</td>
<td align="left" rowspan="1" colspan="1"><bold>65,3</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">15,3</td>
<td align="left" rowspan="1" colspan="1"><bold>75,9</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">14,3</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">2,94</td>
<td align="left" rowspan="1" colspan="1">2,5</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">M</td>
<td align="left" rowspan="1" colspan="1">32</td>
<td align="left" rowspan="1" colspan="1"><bold>69,2</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">2,6</td>
<td align="left" rowspan="1" colspan="1"><bold>74,0</bold></td>
<td align="left" rowspan="1" colspan="1">0,000</td>
<td align="left" rowspan="1" colspan="1">6,3</td>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">–</td>
<td align="left" rowspan="1" colspan="1">4,6</td>
<td align="left" rowspan="1" colspan="1">3,15</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt102"><label/><p>Neural Network results obtained from all participants, making use of 3, 4, or 5 ROIs as input data for the algorithm. The rate of success increases with the number of ROIs employed.</p></fn></table-wrap-foot></table-wrap>
<p>We tested the reliability of ANN output for all 10 participants, as described in the previous section. Analyzing the BR task signal, we found that in all cases the events distributions were leptokurtic (kurtosis coefficient &gt;0) or normal (Shapiro-Wilk, p&gt;0.05) and the mean number of predicted stimuli was balanced, with a percentage of houses and faces in the range between 25% and 75% for all the participants, except one. Moreover for the rest block signal output the events distribution was unbalanced and/or platykurtic (Kurtosis coefficient &lt;0), with a larger variance and asymmetry than for task signal in all cases (<xref ref-type="fig" rid="pone-0105206-g005">Fig. 5A</xref>).</p>
<fig id="pone-0105206-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0105206.g005</object-id><label>Figure 5</label><caption>
<title>Examples of stimuli distributions after 1000 output repetitions.</title>
<p>In panel A on top the bar histogram shows for subject 7 the results of the 1000 reiterations using the BR task time course signal. In y axis is represented the percentage number (frequency) of house and face over all time points in a reiteration, and in the x axis the percentage number of reiterations (events) in which we obtained a determined frequency of houses and faces over all 1000 reiterations. In the plot on the bottom of panel A the BR time course signal has been replaced with Rest time course signal. In panel B the same bar histograms, for BR and rest time courses, are shown for the subject excluded because he did not experience the BR phenomenon.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0105206.g005" position="float" xlink:type="simple"/></fig>
<p>We also performed the reliability assessment for the discarded participant who declared that he did not experience the rivalry phenomenon. In this case the events distribution was unbalanced, platykurtic for both task and rest signal ANN output; moreover, asymmetry was larger for task than for rest ANN output (<xref ref-type="fig" rid="pone-0105206-g005">Fig. 5B</xref>).</p>
</sec><sec id="s4">
<title>Discussion and Conclusions</title>
<p>The present study provides a method based on MVPA to investigate the neural basis of visual consciousness during the BR phenomenon when behavioral indicators, of what the participant is experiencing, are lacking or inconsistent.</p>
<p>Our main results showed that the trained ANN was able to generalize across two different fMRI paradigms (i.e. BNR and BR) and to identify with high accuracy the cognitive state of the participant (i.e. which stimulus was consciously perceived) during the BR condition. These results were obtained combining information from 3 ROIs in all the participants, except one, although the best performances were obtained by combining information from 4 or 5 ROIs. The possibility to apply this procedure using a limited number of ROIs makes it applicable to a wide variety of patients with cerebral insult.</p>
<p>Based on the literature, we decided to use faces and houses as stimuli because they induce very different patterns of neural activity supporting an optimal training of ANN and because faces, due to their ecological relevance, are easily discriminated than other stimuli <xref ref-type="bibr" rid="pone.0105206-Hoshiyama1">[25]</xref>.</p>
<p>The ability to identify a common pattern of neural activity during two different paradigms is extremely important in a context where behavioral indicators lack or are difficult to detect. As in the study by Haynes et al. <xref ref-type="bibr" rid="pone.0105206-Haynes1">[13]</xref>, we trained the neural network with data obtained in a controlled condition (i.e., BNR condition) that allowed us to know what the participant was perceiving, and tested it on data obtained in a condition where there was no external control (except for the behavioral response, used only to assess the prediction accuracy of the algorithm) of what the individual was perceiving (i.e., the BR condition). This clearly supports the use of our ANN in conditions where the conscious perception of an individual is not accessible to an external observer. Unlike Haynes <xref ref-type="bibr" rid="pone.0105206-Haynes1">[13]</xref>, who trained the neural network on data obtained from a monocular non-rivalry condition, we trained it on data obtained from a binocular non-rivalry condition. The ability of the ANN to predict the conscious perception during BR using a training on BNR fMRI signal indicates that the BOLD signal changes in the ROIs were strictly modulated by the conscious percept and not by the eye of origin of the stimuli.</p>
<p>The behavioral data showed that the mean perception dominance duration was variable between subjects and consistent with the previous studies using similar stimuli <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref>, although an EEG study reported a shorter perception dominance duration using rotating gratings as stimuli <xref ref-type="bibr" rid="pone.0105206-Roeber1">[26]</xref>. Interestingly, we noticed that the worst performance of our brain states classifier was obtained from subjects 5 and 6, who experienced shorter mean perception durations (respectively 2.57 s and 1.78 s); we speculate that it may be harder to decode a signal when perception changes are too quick.</p>
<p>The single-subject GLM analysis of the BNR task did not activate the same number of areas in all participants. Thus, it was not feasible to identify 4 or 5 ROIs for each subject, because OFA and FFA are functional areas and they do not correspond to an easily recognizable and circumscribed anatomical location <xref ref-type="bibr" rid="pone.0105206-Rossion1">[15]</xref>. For this reason we trained and tested the ANN using information extracted from 3, 4 and 5 ROIs, based on the available identified regions for each participant.</p>
<p>In order to create a non-user dependent standard procedure, two thresholds were fixed, one related to the network training performance (MSE &lt;0.02) and the other to the time points assignment (|X<sub>t,1</sub>–X<sub>t,2</sub>| &gt;0.9), based on the best results obtained for our group of healthy volunteers.</p>
<p>In the last decade there has been a great ongoing debate about the neural processes underlying BR, with some studies describing this phenomenon as a high-level and representation-based process <xref ref-type="bibr" rid="pone.0105206-Tong1">[14]</xref>, <xref ref-type="bibr" rid="pone.0105206-Hsieh1">[27]</xref>, <xref ref-type="bibr" rid="pone.0105206-Logothetis1">[28]</xref>, <xref ref-type="bibr" rid="pone.0105206-Lumer1">[29]</xref> and others describing it as a low–level and eye-based process <xref ref-type="bibr" rid="pone.0105206-Haynes1">[13]</xref>, <xref ref-type="bibr" rid="pone.0105206-Wunderlich1">[30]</xref>, <xref ref-type="bibr" rid="pone.0105206-Tong2">[31]</xref>. In our study, we decided to use a paradigm based on the hypothesis of high-level and representation based processes during BR.</p>
<p>The future development of this study lies in the application of the described method to investigate BR phenomenon in patients with different levels of sedation, disorder of consciousness or patients with profound physical disabilities, where it is difficult even for experienced clinicians to diagnose cognitive ability <xref ref-type="bibr" rid="pone.0105206-Andrews1">[32]</xref>. The neuroscience community used fMRI paradigms extensively to detect willful behavior in these patients <xref ref-type="bibr" rid="pone.0105206-Laureys1">[33]</xref>, <xref ref-type="bibr" rid="pone.0105206-Monti1">[34]</xref>.</p>
<p>The absence of any feedback from these patients creates the tricky problem of the ANN output truthfulness assessment.</p>
<p>We addressed this criticism by outlining some criteria that were derived from the described training method and reliability assessment. The conditions that should be fulfilled to consider the ANN output reliable and infer that the subject experienced the perception of BR, even in absence of any feedback, are as follows:</p>
<list list-type="roman-lower"><list-item>
<p>activation clusters present in BNR task single-subject analysis necessary to identify at least 3 ROIs;</p>
</list-item><list-item>
<p>high network training performance: MSE &lt;0.02;</p>
</list-item><list-item>
<p>after 1000 runs the BR-task signal ANN outputs must be balanced between stimuli and presenting a leptokurtic, or at most normal, events distribution;</p>
</list-item><list-item>
<p>the BR-task signal ANN output events distribution must have a smaller variance and symmetry than the rest events distribution.</p>
</list-item></list>
<p>Despite the significance of the results obtained, we underline that the classification performances of the ANN could have been more accurate in consideration of some limits of our study. The main issues that cannot be easily resolved lies in the behavioral responses registration method and more specifically we identified three critical aspects: first we did not ask to the participants to inform us when the two percepts were overlapping, second subject reaction times and errors in button-pressing may alter our recorded data and bias our final estimation on ANN output and third during BNR task registration the motor behavioral responses were absent.</p>
<p>Another limit of this study may be linked to pulse sequences parameters used for BNR and BR scans: it would likely be possible to achieve a better performance of the network using the same EPI sequence parameters for both tasks, though differences between the two sequences are slight.</p>
<p>In conclusion, the present study provides a method based on multivariate pattern analysis to investigate the neural basis of visual consciousness during the BR phenomenon when behavioral indicators lack or are inconsistent.</p>
</sec></body>
<back>
<ack>
<p>The authors are grateful to Domenico Aquino for excellent support during data processing and insightful advice.</p>
<sec>
<title>Contributors</title>
<p>The Coma Research Centre (CRC) multidisciplinary team, on behalf of which the present publication was submitted, acknowledges the following members: Matilde Leonardi (Scientific Director CRC), Eugenio Agostino Parati, Maria Grazia Bruzzone, Silvana Franceschetti, Dario Caldiroli, Davide Sattin, Ambra Giovannetti, Marco Pagani, Venusia Covelli, Francesca Ciaraffa, Jesus Vela Gomez, Barbara Reggiori, Stefania Ferraro, Anna Nigri, Ludovico D’Incerti, Ludovico Minati, Adrian Andronache, Cristina Rosazza, Patrik Fazio, Davide Rossi, Giulia Varotto, Ferruccio Panzica, Riccardo Benti, Giorgio Marotta, Franco Molteni.</p>
<p>Study realized also in collaboration with FERB- European Federation Biomedical Research.</p>
<p>The authors are grateful to two anonymous reviewers for insightful feedback on an earlier draft of this paper.</p>
</sec></ack>
<ref-list>
<title>References</title>
<ref id="pone.0105206-Norman1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Polyn</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Detre</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name> (<year>2006</year>) <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends Cogn Sci</source>, <volume>10</volume><issue>(9)</issue>, <fpage>424</fpage>–<lpage>430</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Pereira1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pereira</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Mitchell</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Machine learning classifiers and fMRI: A tutorial overview</article-title>. <source>NeuroImage</source>, <volume>45</volume><issue>(1 Suppl)</issue>, <fpage>S199</fpage>–<lpage>209</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Gao1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Tao</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>A novel approach for lie detection based on F-score and extreme learning machine</article-title>. <source>PloS One</source>, <volume>8</volume><issue>(6)</issue>, <fpage>e64704</fpage></mixed-citation>
</ref>
<ref id="pone.0105206-Langleben1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Langleben</surname><given-names>DD</given-names></name>, <name name-style="western"><surname>Moriarty</surname><given-names>JC</given-names></name> (<year>2013</year>) <article-title>Using brain imaging for lie detection: Where science, law and research policy collide</article-title>. <source>Psychol Public Policy Law</source>, <volume>19</volume><issue>(2)</issue>, <fpage>222</fpage>–<lpage>234</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Davatzikos1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Ruparel</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Shen</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Acharyya</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Classifying spatial patterns of brain activity with machine learning methods: application to lie detection</article-title>. <source>NeuroImage</source>, <volume>28</volume><issue>(3)</issue>, <fpage>663</fpage>–<lpage>668</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Weil1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weil</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name> (<year>2010</year>) <article-title>Decoding the neural correlates of consciousness</article-title>. <source>Curr Opin Neurol</source>, <volume>23(6)</volume>, <fpage>649</fpage>–<lpage>655</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Minati1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Minati</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Nigri</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rosazza</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Bruzzone</surname><given-names>MG</given-names></name> (<year>2012</year>) <article-title>Thoughts turned into high-level commands: Proof-of-concept study of a vision-guided robot arm driven by functional MRI (fMRI) signals</article-title>. <source>Med Eng Phys</source>, <volume>34</volume><issue>(5)</issue>, <fpage>650</fpage>–<lpage>658</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-MouraoMiranda1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mourao-Miranda</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Almeida</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Hassel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>De Oliveira</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Versace</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Pattern recognition analyses of brain activation elicited by happy and neutral faces in unipolar and bipolar depression</article-title>. <source>Bipolar Disord</source>, <volume>14(4)</volume>, <fpage>451</fpage>–<lpage>460</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Yamamura1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamamura</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Sawahata</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yamamoto</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kamitani</surname><given-names>Y</given-names></name> (<year>2009</year>) <article-title>Neural art appraisal of painter: Dali or picasso</article-title>? <source>Neuroreport</source>, <volume>20(18)</volume>, <fpage>1630</fpage>–<lpage>1633</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Blake1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name> (<year>2011</year>) <article-title>Binocular vision</article-title>. <source>Vision Res</source>, <volume>51(7)</volume>, <fpage>754</fpage>–<lpage>770</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Blake2"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name> (<year>2002</year>) <article-title>Visual competition</article-title>. <source>Nat Rev Neurosci</source>, <volume>3(1)</volume>, <fpage>13</fpage>–<lpage>21</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Zhang1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>He</surname><given-names>S</given-names></name> (<year>2012</year>) <article-title>Voluntary attention modulates processing of eye-specific visual information</article-title>. <source>Psychol Sci</source>, <volume>23(3)</volume>, <fpage>254</fpage>–<lpage>260</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Haynes1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haynes</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name> (<year>2005</year>) <article-title>Predicting the stream of consciousness from activity in human visual cortex</article-title>. <source>Curr Biol : CB</source><volume>15(14)</volume>, <fpage>1301</fpage>–<lpage>1307</lpage>.</mixed-citation>
</ref>
<ref id="pone.0105206-Tong1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Nakayama</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Vaughan</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>1998</year>) <article-title>Binocular rivalry and visual awareness in human extrastriate cortex</article-title>. <source>Neuron</source>, <volume>21(4)</volume>, <fpage>753</fpage>–<lpage>759</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Rossion1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rossion</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hanseeuw</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dricot</surname><given-names>L</given-names></name> (<year>2012</year>) <article-title>Defining face perception areas in the human brain: A large-scale factorial fMRI face localizer analysis</article-title>. <source>Brain Cogn</source>, <volume>79(2)</volume>, <fpage>138</fpage>–<lpage>157</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Cant1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cant</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Goodale</surname><given-names>MA</given-names></name> (<year>2011</year>) <article-title>Scratching beneath the surface: New insights into the functional properties of the lateral occipital area and parahippocampal place area</article-title>. <source>J Neurosci</source>, <volume>31(22)</volume>, <fpage>8248</fpage>–<lpage>8258</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Picton1"><label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">Picton P (2000) <italic>Neural networks</italic>. Basingstoke, UK: Palgrave Macmillan. 195 p.</mixed-citation>
</ref>
<ref id="pone.0105206-Bernstein1"><label>18</label>
<mixed-citation publication-type="book" xlink:type="simple">Bernstein MA, King KF, Zhou XJ (2004) <italic>Handbook of MRI pulse sequences.</italic> ELSEVIER ACADEMIC PRESS. 1017 p.</mixed-citation>
</ref>
<ref id="pone.0105206-Turner1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Howseman</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>GE</given-names></name>, <name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>1998</year>) <article-title>Functional magnetic resonance imaging of the human brain: Data acquisition and analysis</article-title>. <source>Exp Brain Res</source>, <volume>123(1–2)</volume>, <fpage>5</fpage>–<lpage>12</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Poldrack1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poldrack</surname><given-names>RA</given-names></name> (<year>2007</year>) <article-title>Region of interest analysis for fMRI</article-title>. <source>Soc Cogn Affect Neurosci</source>, <volume>2(1)</volume>, <fpage>67</fpage>–<lpage>70</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Goutte1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goutte</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Toft</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Rostrup</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Nielsen</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hansen</surname><given-names>LK</given-names></name> (<year>1999</year>) <article-title>On clustering fMRI time series</article-title>. <source>NeuroImage</source>, <volume>9(3)</volume>, <fpage>298</fpage>–<lpage>310</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Desjardins1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desjardins</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Kiehl</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Liddle</surname><given-names>PF</given-names></name> (<year>2001</year>) <article-title>Removal of confounding effects of global signal in functional MRI analyses</article-title>. <source>NeuroImage</source>, <volume>13(4)</volume>, <fpage>751</fpage>–<lpage>8</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Jiang1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name> (<year>2003</year>) <article-title>Uncertainty in the output of artificial neural networks</article-title>. <source>IEEE Trans Med Imaging</source>, <volume>22(7)</volume>, <fpage>913</fpage>–<lpage>21</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Shapiro1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shapiro</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wilk</surname><given-names>MB</given-names></name> (<year>1965</year>) <article-title>An analysis of variance test for normality</article-title>. <source>Biometrika</source><volume>52(3)</volume>, <fpage>591</fpage></mixed-citation>
</ref>
<ref id="pone.0105206-Hoshiyama1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hoshiyama</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kakigi</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Takeshima</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Miki</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Watanabe</surname><given-names>S</given-names></name> (<year>2006</year>) <article-title>Priority of face perception during subliminal stimulation using a new color-opponent flicker stimulation</article-title>. <source>Neurosci Lett</source>, <volume>402(1–2)</volume>, <fpage>57</fpage>–<lpage>61</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Roeber1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roeber</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Veser</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Schroger</surname><given-names>E</given-names></name>, <name name-style="western"><surname>O’Shea</surname><given-names>RP</given-names></name> (<year>2011</year>) <article-title>On the role of attention in binocular rivalry: Electrophysiological evidence PloS One</article-title>, <volume>6(7)</volume>, <fpage>e22612</fpage></mixed-citation>
</ref>
<ref id="pone.0105206-Hsieh1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsieh</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Colas</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>NG</given-names></name> (<year>2012</year>) <article-title>Pre-stimulus pattern of activity in the fusiform face area predicts face percepts during binocular rivalry</article-title>. <source>Neuropsychologia</source>, <volume>50(4)</volume>, <fpage>522</fpage>–<lpage>9</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Logothetis1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name> (<year>1998</year>) <article-title>Single units and conscious vision</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>, <volume>353(1377)</volume>, <fpage>1801</fpage>–<lpage>18</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Lumer1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lumer</surname><given-names>ED</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name> (<year>1998</year>) <article-title>Neural correlates of perceptual rivalry in the human brain</article-title>. <source>Science</source>, <volume>280(5371)</volume>, <fpage>1930</fpage>–<lpage>4</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Wunderlich1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wunderlich</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Kastner</surname><given-names>S</given-names></name> (<year>2005</year>) <article-title>Neural correlates of binocular rivalry in the human lateral geniculate nucleus</article-title>. <source>Nat Neurosci</source>, <volume>8(11)</volume>, <fpage>1595</fpage>–<lpage>602</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Tong2"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Engel</surname><given-names>SA</given-names></name> (<year>2001</year>) <article-title>Interocular rivalry revealed in the human cortical blind-spot representation</article-title>. <source>Nature</source>, <volume>411(6834)</volume>, <fpage>195</fpage>–<lpage>9</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Andrews1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andrews</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Murphy</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Munday</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Littlewood</surname><given-names>C</given-names></name> (<year>1996</year>) <article-title>Misdiagnosis of the vegetative state: Retrospective study in a rehabilitation unit</article-title>. <source>BMJ</source>, <volume>313(7048)</volume>, <fpage>13</fpage>–<lpage>16</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Laureys1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laureys</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Giacino</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Schiff</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Schabus</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Owen</surname><given-names>AM</given-names></name> (<year>2006</year>) <article-title>How should functional imaging of patients with disorders of consciousness contribute to their clinical rehabilitation needs</article-title>? <source>Curr Opin Neurol</source>, <volume>19(6)</volume>, <fpage>520</fpage>–<lpage>7</lpage></mixed-citation>
</ref>
<ref id="pone.0105206-Monti1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Monti</surname><given-names>MM</given-names></name>, <name name-style="western"><surname>Coleman</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Owen</surname><given-names>AM</given-names></name> (<year>2009</year>) <article-title>Neuroimaging and the vegetative state: Resolving the behavioral assessment dilemma</article-title>? <source>Ann N Y Acad Sci</source>, <volume>1157</volume>, <fpage>81</fpage>–<lpage>9</lpage></mixed-citation>
</ref>
</ref-list></back>
</article>