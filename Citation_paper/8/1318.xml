<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-47064</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0096485</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject></subj-group></subj-group><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group><subj-group><subject>Molecular cell biology</subject></subj-group></subj-group><subj-group><subject>Biochemistry</subject><subj-group><subject>Neurochemistry</subject></subj-group></subj-group><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Circuit models</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Synaptic plasticity</subject></subj-group></subj-group><subj-group><subject>Cognitive neuroscience</subject><subject>Developmental neuroscience</subject><subject>Learning and memory</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Research and analysis methods</subject><subj-group><subject>Specimen preparation and treatment</subject><subj-group><subject>Mechanical treatment of specimens</subject><subj-group><subject>Specimen disruption</subject><subj-group><subject>Electroporation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Computerized simulations</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine and health sciences</subject></subj-group></article-categories>
<title-group>
<article-title>Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect</article-title>
<alt-title alt-title-type="running-head">Structural Synaptic Plasticity and Memory</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>Andreas</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Körner</surname><given-names>Edgar</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Körner</surname><given-names>Ursula</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sommer</surname><given-names>Friedrich T.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Engineering Faculty, Albstadt-Sigmaringen University, Albstadt, Germany</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Honda Research Institute Europe, Offenbach am Main, Germany</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Redwood Center for Theoretical Neuroscience, University of California, Berkeley, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Vasilaki</surname><given-names>Eleni</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Sheffield, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">knoblauch@hs-albsig.de</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: AK. Performed the experiments: AK. Analyzed the data: AK. Contributed reagents/materials/analysis tools: AK. Wrote the paper: AK EK UK FS.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>23</day><month>5</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>5</issue>
<elocation-id>e96485</elocation-id>
<history>
<date date-type="received"><day>9</day><month>11</month><year>2013</year></date>
<date date-type="accepted"><day>8</day><month>4</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Knoblauch et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Although already William James and, more explicitly, Donald Hebb's theory of cell assemblies have suggested that activity-dependent rewiring of neuronal networks is the substrate of learning and memory, over the last six decades most theoretical work on memory has focused on plasticity of existing synapses in prewired networks. Research in the last decade has emphasized that structural modification of synaptic connectivity is common in the adult brain and tightly correlated with learning and memory. Here we present a parsimonious computational model for learning by structural plasticity. The basic modeling units are “potential synapses” defined as locations in the network where synapses can potentially grow to connect two neurons. This model generalizes well-known previous models for associative learning based on weight plasticity. Therefore, existing theory can be applied to analyze how many memories and how much information structural plasticity can store in a synapse. Surprisingly, we find that structural plasticity largely outperforms weight plasticity and can achieve a much higher storage capacity per synapse. The effect of structural plasticity on the structure of sparsely connected networks is quite intuitive: Structural plasticity increases the “effectual network connectivity”, that is, the network wiring that specifically supports storage and recall of the memories. Further, this model of structural plasticity produces gradients of effectual connectivity in the course of learning, thereby explaining various cognitive phenomena including graded amnesia, catastrophic forgetting, and the spacing effect.</p>
</abstract>
<funding-group><funding-statement>FTS received support from the National Science Foundation through the grants NSF-0855272 and NSF-1219212. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="19"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Traditionally, learning and memory are attributed to <italic>weight plasticity</italic>, that is, the modification of the strength of existing synapses according to variants of the Hebb rule <xref ref-type="bibr" rid="pone.0096485-Hebb1">[1]</xref>–<xref ref-type="bibr" rid="pone.0096485-Song1">[5]</xref>. Although the theory of weight plasticity has been crucially important in neuroscience and applications of artificial neural networks, it could not easily explain various fundamental memory-related effects in cognitive psychology such as graded amnesia, the prevention of catastrophic forgetting, and the spacing effect.</p>
<p>Another form of synaptic plasticity is <italic>structural plasticity</italic>, that is, the creation and erasure of synapses <xref ref-type="bibr" rid="pone.0096485-Raisman1">[6]</xref>–<xref ref-type="bibr" rid="pone.0096485-Schuemann1">[13]</xref>. Originally thought of setting up connectivity during development <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>–<xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref> or after injuries <xref ref-type="bibr" rid="pone.0096485-Keck1">[17]</xref>, <xref ref-type="bibr" rid="pone.0096485-Butz1">[18]</xref>, it has recently been shown to correlate with memory formation and learning in the healthy adult brain <xref ref-type="bibr" rid="pone.0096485-Yang1">[19]</xref>–<xref ref-type="bibr" rid="pone.0096485-Fu1">[23]</xref>.</p>
<p>Here we introduce and analyze a simple computational model of structural plasticity which exhibits surprisingly high memory capacity and is able to explain the mentioned cognitive effects. A key to understanding the role of structural plasticity in memory has to do with the observation that the brain, even its most densely connected local circuits, is far from being fully connected <xref ref-type="bibr" rid="pone.0096485-Braitenberg1">[24]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hellwig1">[25]</xref>. Thus, for any given network computation, the existing synapses may or may not provide the optimal structure of the network. To assess the match between existing synapses and the synapses required by a computation, we define <italic>effectual connectivity</italic> as the fraction of required synapses that are present in the network. By erasure and creation of synapses, structural plasticity can “migrate” synapses and thereby increase the effectual connectivity for a given network function. By integrating our model with well-known Hopfield- or Willshaw-type neural network models of memory storage and retrieval <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hopfield1">[27]</xref> we can quantitatively asses the benefits of structural plasticity compared to weight plasticity. In section 0.6 we show that ongoing structural plasticity can strongly increase storage capacity for sparsely connected networks, which is in line with related approaches counting possible synaptic network configurations <xref ref-type="bibr" rid="pone.0096485-Poirazi1">[28]</xref>–<xref ref-type="bibr" rid="pone.0096485-Chklovskii1">[30]</xref> or analyzing storage capacity for structural plasticity during development <xref ref-type="bibr" rid="pone.0096485-Chechik1">[15]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>. Moreover, our theory of structural plasticity suggests immediate explanations for various memory phenomena <xref ref-type="bibr" rid="pone.0096485-Knoblauch2">[31]</xref>–<xref ref-type="bibr" rid="pone.0096485-Knoblauch4">[33]</xref>. In particular, in section 7 we analyze the role of structural synaptic plasticity in cortico-hippocampal memory replay and consolidation <xref ref-type="bibr" rid="pone.0096485-Ji1">[34]</xref>, <xref ref-type="bibr" rid="pone.0096485-McClelland1">[35]</xref>, preventing catastrophic forgetting in brains <xref ref-type="bibr" rid="pone.0096485-French1">[36]</xref>, <xref ref-type="bibr" rid="pone.0096485-Grossberg1">[37]</xref>, graded retrograde amnesia following brain lesions <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>–<xref ref-type="bibr" rid="pone.0096485-Ribot1">[40]</xref>, and the pedagogically relevant spacing effect of learning <xref ref-type="bibr" rid="pone.0096485-Crowder1">[41]</xref>–<xref ref-type="bibr" rid="pone.0096485-Ebbinghaus1">[43]</xref>.</p>
</sec><sec id="s2" sec-type="methods">
<title>Concepts and Models</title>
<sec id="s2a">
<title>1 Synapse Ensembles and Effectual Connectivity</title>
<p>Common memory theories based on neural associative network models consider only Hebbian-type weight plasticity in networks with fixed structure, thus, neglecting processes involving structural plasticity. Such models predict that the maximal information that can be stored in a given neural network increases in proportion to the number of synaptic connections rather than number of neurons. Therefore, <italic>storage capacity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e001" xlink:type="simple"/></inline-formula> is often expressed in terms of stored information per synapse. For example, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e002" xlink:type="simple"/></inline-formula> bit per synapse (bps) for networks of binary synapses <xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm1">[44]</xref>, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e003" xlink:type="simple"/></inline-formula> bps for real-valued synaptic weights <xref ref-type="bibr" rid="pone.0096485-Palm2">[45]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch5">[46]</xref>. To judge how many memories can be stored in a network <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e004" xlink:type="simple"/></inline-formula> connecting two neuron populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e005" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e006" xlink:type="simple"/></inline-formula> each comprising <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e007" xlink:type="simple"/></inline-formula> neurons, it is therefore important to know the <italic>anatomical network connectivity</italic><disp-formula id="pone.0096485.e008"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e008" xlink:type="simple"/><label>(1)</label></disp-formula></p>
<p>defined as the chance that there is a synaptic connection between two randomly chosen neurons (<xref ref-type="fig" rid="pone-0096485-g001">Fig. 1A</xref>).</p>
<fig id="pone-0096485-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g001</object-id><label>Figure 1</label><caption>
<title>Definitions of network connectivity.</title>
<p>Illustration of different connectivity measures for a synaptic network <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e009" xlink:type="simple"/></inline-formula> connecting neuron populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e010" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e011" xlink:type="simple"/></inline-formula> (which may be identical for recurrent networks). <bold>A,</bold> <italic>Anatomical connectivity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e012" xlink:type="simple"/></inline-formula> and <italic>potential connectivity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e013" xlink:type="simple"/></inline-formula> are fractions of neuron pairs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e014" xlink:type="simple"/></inline-formula> connected by an actual (black circles) and potential synapse (blue rectangles), respectively. <bold>B,</bold> The <italic>consolidation signal</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e015" xlink:type="simple"/></inline-formula> specifies the ensemble of neuron pairs that request a synapse (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e016" xlink:type="simple"/></inline-formula>, red circles) to support storage of a given memory set. The corresponding <italic>effectual connectivity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e017" xlink:type="simple"/></inline-formula> is then the fraction of neuron pairs requesting a synapse that are already connected by an actual synapse. The <italic>consolidation load</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e018" xlink:type="simple"/></inline-formula> is the fraction of neuron pairs that request a synapse.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g001" position="float" xlink:type="simple"/></fig>
<p>For memory theories including structural plasticity the situation is different because we can assume that processes including generation of new synapses, consolidation of useful synapses, elimination of useless synapses, and maintenance of anatomical connectivity at a given level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e019" xlink:type="simple"/></inline-formula> will effectively “migrate” synapses to locations that are most appropriate for storing a particular set of memories. Evidently, anatomical connectivity will then be a bad predictor of storage capacity. Rather storage capacity will depend crucially on the number of locations where a synapse could potentially be generated. Such locations have been called potential synapses <xref ref-type="bibr" rid="pone.0096485-Stepanyants1">[29]</xref>, where <italic>potential network connectivity</italic><disp-formula id="pone.0096485.e020"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e020" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>is the chance that there is a potential synapse between two neurons.</p>
<p>It is now tempting to apply the old memory theories for weight plasticity as well to structurally plastic networks by simply replacing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e021" xlink:type="simple"/></inline-formula> by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e022" xlink:type="simple"/></inline-formula>. The underlying argument is that the structurally plastic network with potential connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e023" xlink:type="simple"/></inline-formula> would be functionally equivalent to a structurally static network with anatomical connectivity at the same level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e024" xlink:type="simple"/></inline-formula> because real synapses could “migrate” to any one of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e025" xlink:type="simple"/></inline-formula> potential locations. Such an approach would be valid only if the number of required synapses does not exceed the number of actual synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e026" xlink:type="simple"/></inline-formula>. However, the question which or how many synapses are actually necessary for storing a particular memory set is usually neglected by theories for fixed networks without structural plasticity. Moreover, from such theories it is impossible to infer any temporal dynamics of structural modifications during memory formation.</p>
<p>We therefore have to introduce another type of connectivity measure that specifies how many synapses have actually been formed at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e027" xlink:type="simple"/></inline-formula> between neurons that belong to a particular memory representation. More generally, we can specify the <italic>synapse ensemble</italic> requested to support storage of a memory set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e028" xlink:type="simple"/></inline-formula> by a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e029" xlink:type="simple"/></inline-formula> matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e030" xlink:type="simple"/></inline-formula>. In the simplest case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e031" xlink:type="simple"/></inline-formula> is binary where non-zero matrix entries with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e032" xlink:type="simple"/></inline-formula> “tag” potential synapses from neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e033" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e034" xlink:type="simple"/></inline-formula> that need to be realized or consolidated for storing the memories <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e035" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pone-0096485-g001">Fig. 1B</xref>). Then with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e036" xlink:type="simple"/></inline-formula> being the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e037" xlink:type="simple"/></inline-formula> matrix of actual synaptic weights (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e038" xlink:type="simple"/></inline-formula> if there is no real synapse from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e039" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e040" xlink:type="simple"/></inline-formula>), we define the <italic>effectual connectivity of memories</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e041" xlink:type="simple"/></inline-formula> as the “overlap” of actual and requested synaptic weights, for example,<disp-formula id="pone.0096485.e042"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e042" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>for binary synaptic weights with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e043" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pone-0096485-g001">Fig. 1B</xref>). For real-valued weights one could generalize this definition (e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e044" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e045" xlink:type="simple"/></inline-formula> may be either binary or real-valued, specifying the “desired” synaptic weight). It is obviously <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e046" xlink:type="simple"/></inline-formula> and, for eq. 3, effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e047" xlink:type="simple"/></inline-formula> corresponds simply to the probability that a requested synapse is actually realized and potentiated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e048" xlink:type="simple"/></inline-formula>). We call the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e049" xlink:type="simple"/></inline-formula> also <italic>learning signal</italic> or <italic>consolidation signal</italic> because it specifies which synapses should be potentiated or stabilized during memory consolidation. For example, simple Hebbian consolidation signals can be based on the correlations between presynaptic and postsynaptic spike activity (see next section). Such <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e050" xlink:type="simple"/></inline-formula> could be provided either by repeated bottom-up stimulus presentation or, in the case of episodic memory, by replay from a hippocampus-like short-term memory buffer (<xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B–D</xref>). The fraction of non-zero entries in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e051" xlink:type="simple"/></inline-formula> is called the <italic>consolidation load</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e052" xlink:type="simple"/></inline-formula>. In larger networks it is typically <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e053" xlink:type="simple"/></inline-formula> if locations of requested synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e054" xlink:type="simple"/></inline-formula> are uncorrelated to the (initial) locations of potential and actual synapses. Our main hypothesis is that the primary function of structural plasticity is to adapt network structure to the particular memories to be stored. This process corresponds to an increase in effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e055" xlink:type="simple"/></inline-formula> from the level of anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e056" xlink:type="simple"/></inline-formula> towards the level of potential connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e057" xlink:type="simple"/></inline-formula> which increases storage capacity per synapse as well as space and energy efficiency of the network <xref ref-type="bibr" rid="pone.0096485-Lennie1">[47]</xref>–<xref ref-type="bibr" rid="pone.0096485-Attwell1">[49]</xref>.</p>
<fig id="pone-0096485-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g002</object-id><label>Figure 2</label><caption>
<title>Model of structural plasticity and consolidation.</title>
<p><bold>A</bold>, State/transition model of a single potential synapse (see text for details). <bold>B</bold>, In the following we consider potential synapses in a network <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e058" xlink:type="simple"/></inline-formula>, for example, connecting two cortical neuron populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e059" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e060" xlink:type="simple"/></inline-formula>. Memories correspond to associations between activity patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e061" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e062" xlink:type="simple"/></inline-formula>. We will specifically analyze how well noisy activity patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e063" xlink:type="simple"/></inline-formula> can reactivate the corresponding memories <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e064" xlink:type="simple"/></inline-formula> in order to estimate storage capacity. <bold>C, D</bold>: LTM storage (solid) by structural plasticity requires repetitive reactivation of activity patterns in cortical populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e065" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e066" xlink:type="simple"/></inline-formula> to provide an appropriate consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e067" xlink:type="simple"/></inline-formula> to the synapses. This may happen by repeated bottom-up stimulation (<bold>D</bold>) or, for episodic memories, by top-down replay (<bold>C</bold>) from a HC-type STM buffer (dashed). LTM = long-term memory; STM = short-term memory; HC = hippocampus.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g002" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>2 Model of Structural Plasticity and Consolidation</title>
<p><xref ref-type="fig" rid="pone-0096485-g002">Figure 2A</xref> illustrates a minimal state model for a “potential” synapse. Here a potential synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e091" xlink:type="simple"/></inline-formula> is the possible location of a real synapse connecting neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e092" xlink:type="simple"/></inline-formula> to neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e093" xlink:type="simple"/></inline-formula>, for example, a cortical location where axonal and dendritic branches of neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e094" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e095" xlink:type="simple"/></inline-formula> are close enough to allow the formation of a novel connection by spine growth and synaptogenesis <xref ref-type="bibr" rid="pone.0096485-Stepanyants1">[29]</xref>. As dendrites and axons may closely overlap at multiple locations, in general, there may be multiple potential synapses (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e096" xlink:type="simple"/></inline-formula>) between a neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e097" xlink:type="simple"/></inline-formula>. Our minimal model has only three states: A synapse can be either potential but not yet realized (state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e098" xlink:type="simple"/></inline-formula>), realized but silent (state and weight <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e099" xlink:type="simple"/></inline-formula>), or realized and consolidated (state and weight <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e100" xlink:type="simple"/></inline-formula>). For real synapses, state transitions are modulated by the consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e101" xlink:type="simple"/></inline-formula>.</p>
<p>Then <italic>structural plasticity</italic> means the transition processes between states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e102" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e103" xlink:type="simple"/></inline-formula> described by transition probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e104" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e105" xlink:type="simple"/></inline-formula>. Similarly, <italic>weight plasticity</italic> means the transitions between states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e106" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e107" xlink:type="simple"/></inline-formula> described by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e108" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e109" xlink:type="simple"/></inline-formula>. In accordance with the diagram of <xref ref-type="fig" rid="pone-0096485-g002">Fig. 2A</xref>, the evolution of synaptic states can then be described by probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e110" xlink:type="simple"/></inline-formula> that a given potential synapse is in a certain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e111" xlink:type="simple"/></inline-formula> at time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e112" xlink:type="simple"/></inline-formula>,<disp-formula id="pone.0096485.e113"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e113" xlink:type="simple"/></disp-formula><disp-formula id="pone.0096485.e114"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e114" xlink:type="simple"/></disp-formula><disp-formula id="pone.0096485.e115"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e115" xlink:type="simple"/><label>(4)</label></disp-formula>where the (Hebbian) consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e116" xlink:type="simple"/></inline-formula> may depend on time. Note that we assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e117" xlink:type="simple"/></inline-formula> to be independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e118" xlink:type="simple"/></inline-formula> because it is unclear how to provide <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e119" xlink:type="simple"/></inline-formula> with high spatial precision <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e120" xlink:type="simple"/></inline-formula> to not yet realized potential synapses. Instead, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e121" xlink:type="simple"/></inline-formula> may rather be under the control of homeostatic mechanisms to keep the number of synapses or the resulting mean firing rates of a neuron at a desired level <xref ref-type="bibr" rid="pone.0096485-Butz3">[50]</xref>. The model could easily be extended towards more biological realism by additional state transitions (e.g., from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e122" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e123" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>), a cascade of further synaptic states <xref ref-type="bibr" rid="pone.0096485-Fusi1">[52]</xref>, or graded synaptic weights <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch7">[54]</xref>, but here the focus is on the essential properties of the interplay between structural and weight plasticity.</p>
<p>For the microscopic simulations of individual synapses as displayed in <xref ref-type="fig" rid="pone-0096485-g004">Figs. 4</xref> and <xref ref-type="fig" rid="pone-0096485-g006">6</xref> we have used the Felix++ simulation tool <xref ref-type="bibr" rid="pone.0096485-Knoblauch8">[55]</xref> to implement large networks with many potential synapses and to simulate network evolution by random sampling of synaptic state variables in discrete time steps. A simple match of the simulation time scale to physiological data can be obtained from the mean lifetime of unconsolidated unrequested synapses: For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e124" xlink:type="simple"/></inline-formula> the mean lifetime is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e125" xlink:type="simple"/></inline-formula> simulation steps. This may be compared, for example, to the few days lifetime reported for unstable spines in adult animals <xref ref-type="bibr" rid="pone.0096485-Trachtenberg1">[10]</xref>.</p>
<p>On the network level we use corresponding <italic>macroscopic</italic> variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e215" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e216" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e217" xlink:type="simple"/></inline-formula> defined as the fraction of neuron pairs that have a potential synapse in a certain state and receive a certain consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e218" xlink:type="simple"/></inline-formula>. From this we can derive the connectivity variables defined in the previous section, in particular, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e219" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e220" xlink:type="simple"/></inline-formula> for binary <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e221" xlink:type="simple"/></inline-formula> (see Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> I for details). In most simulations of (adult) memory processes (<xref ref-type="fig" rid="pone-0096485-g004">Figs. 4</xref>,<xref ref-type="fig" rid="pone-0096485-g003">3D</xref>,<xref ref-type="fig" rid="pone-0096485-g006">6</xref>), we have assumed that the rates of synapse generation and elimination are in homeostatic balance to maintain either a constant anatomical network connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e222" xlink:type="simple"/></inline-formula> or a constant number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e223" xlink:type="simple"/></inline-formula> of actual synapses.</p>
<fig id="pone-0096485-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g003</object-id><label>Figure 3</label><caption>
<title>Learning in Willshaw-type associative networks.</title>
<p><bold>A</bold>, Memory storage by Hebbian weight plasticity (Eq. 5) in a fully connected network (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e068" xlink:type="simple"/></inline-formula>). Address patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e069" xlink:type="simple"/></inline-formula> are associated to content patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e070" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e071" xlink:type="simple"/></inline-formula> (here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e072" xlink:type="simple"/></inline-formula>). Each memory is represented by a binary activity vector of length <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e073" xlink:type="simple"/></inline-formula> having <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e074" xlink:type="simple"/></inline-formula> active units (which define the corresponding cell assembly). <bold>B</bold>, One-step retrieval of the first memory from a noisy query pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e075" xlink:type="simple"/></inline-formula> having two of the four active units in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e076" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e077" xlink:type="simple"/></inline-formula>). Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e078" xlink:type="simple"/></inline-formula> can perfectly reactivate the corresponding memory pattern in population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e079" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e080" xlink:type="simple"/></inline-formula>) applying a firing threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e081" xlink:type="simple"/></inline-formula> on dendritic potentials <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e082" xlink:type="simple"/></inline-formula>. <bold>C</bold>, As a simple form of structural plasticity, silent synapses can be pruned <italic>after</italic> learning. The resulting network has only 28 (instead of 49) synapses corresponding to a lower anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e083" xlink:type="simple"/></inline-formula>, whereas the effectual connectivity is still <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e084" xlink:type="simple"/></inline-formula>. Thus, pruning does not change network function, but increases stored information per synapse. <bold>D</bold>, Ongoing structural plasticity can similarly increase storage capacity during more realistic learning in networks with low anatomical connectivity (here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e085" xlink:type="simple"/></inline-formula>). During each time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e086" xlink:type="simple"/></inline-formula>, Hebbian weight plasticity potentiates and consolidates synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e087" xlink:type="simple"/></inline-formula> with non-zero consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e088" xlink:type="simple"/></inline-formula> (which equals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e089" xlink:type="simple"/></inline-formula> of panel A), whereas the remaining silent synapses are eliminated and replaced by new synapses at random locations. Note that the resulting network at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e090" xlink:type="simple"/></inline-formula> is the same as in panel C.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g003" position="float" xlink:type="simple"/></fig><fig id="pone-0096485-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g004</object-id><label>Figure 4</label><caption>
<title>Increase of effectual connectivity during memory consolidation with ongoing structural plasticity.</title>
<p>Each curve shows the evolution of effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e126" xlink:type="simple"/></inline-formula> as a function of time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e127" xlink:type="simple"/></inline-formula> for different parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e128" xlink:type="simple"/></inline-formula> (anatomical connectivity), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e129" xlink:type="simple"/></inline-formula> (potential connectivity), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e130" xlink:type="simple"/></inline-formula> (consolidation load), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e131" xlink:type="simple"/></inline-formula> (fraction of initially consolidated synapses). Data are from single microscopic network simulations (solid black; cf. Eq. 4; network size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e132" xlink:type="simple"/></inline-formula>) and macroscopic theory (dashed gray; Eq. 11). See <xref ref-type="table" rid="pone-0096485-t001">Table 1</xref> for further simulation parameters. <bold>A</bold>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e133" xlink:type="simple"/></inline-formula> for different consolidation loads <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e134" xlink:type="simple"/></inline-formula> and constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e135" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e136" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e137" xlink:type="simple"/></inline-formula>. <bold>B</bold>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e138" xlink:type="simple"/></inline-formula> for different fractions of initially consolidated synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e139" xlink:type="simple"/></inline-formula> and constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e140" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e141" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e142" xlink:type="simple"/></inline-formula>. <bold>C</bold>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e143" xlink:type="simple"/></inline-formula> for different anatomical connectivities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e144" xlink:type="simple"/></inline-formula> and constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e145" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e146" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e147" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g004" position="float" xlink:type="simple"/></fig>
<p>The relation between synapse and network variables is non-trivial in general because there may be multiple potential synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e224" xlink:type="simple"/></inline-formula> per neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e225" xlink:type="simple"/></inline-formula> (see Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> I.1), for example around 5–10 between two connected neighboring cortical neurons <xref ref-type="bibr" rid="pone.0096485-Deuchars1">[56]</xref>–<xref ref-type="bibr" rid="pone.0096485-Deger1">[60]</xref>. Nevertheless, we argue that even our simple binary model with only a <italic>single synapse</italic> per connected neuron pair bears significant biological relevance because it has been reported that the number of actual synapses per connected neuron pair and also the total synaptic weight is surprisingly similar across neurons (see discussion section; cf. <xref ref-type="bibr" rid="pone.0096485-Fares1">[59]</xref>, <xref ref-type="bibr" rid="pone.0096485-London1">[61]</xref>). Therefore, we have analyzed this simple model to obtain the results presented below and in Section 6 (see <xref ref-type="fig" rid="pone-0096485-g004">Figs. 4</xref>–<xref ref-type="fig" rid="pone-0096485-g005">5</xref>). To improve biological realism of our simulation experiments in Section 7 (<xref ref-type="fig" rid="pone-0096485-g006">Fig. 6</xref>), we have tested our ideas also with a second model variant that allows <italic>multiple synapses</italic> per neuron pair, where each of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e226" xlink:type="simple"/></inline-formula> actual synapses of the network can be allocated to one of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e227" xlink:type="simple"/></inline-formula> potential locations independently of other synapses. Additional simulations (not shown) have indicated that both model variants yield qualitatively very similar results unless the replay time for a given consolidation signal was very long. Then the second model variant tended to accumulate all available synapses at the locations specified by the consolidation signal such that neuron pairs were connected by a large number of synapses.</p>
<fig id="pone-0096485-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g005</object-id><label>Figure 5</label><caption>
<title>Storage capacities for a finite Willshaw network having the size of a cortical macrocolumn (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e148" xlink:type="simple"/></inline-formula>).</title>
<p><bold>A,</bold> Contour plot of pattern capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e149" xlink:type="simple"/></inline-formula> (number of stored memories) as a function of assembly size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e150" xlink:type="simple"/></inline-formula> (number of active units in a memory vector) and effectual network connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e151" xlink:type="simple"/></inline-formula> assuming output noise level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e152" xlink:type="simple"/></inline-formula> and noise-free input patterns (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e153" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e154" xlink:type="simple"/></inline-formula>). <bold>B,</bold> Weight capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e155" xlink:type="simple"/></inline-formula> for the same setting as in panel <bold>A</bold>. <bold>C,</bold> Total storage capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e156" xlink:type="simple"/></inline-formula> including structural plasticity for the same setting as in <bold>A</bold>. Note that even modest increases of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e157" xlink:type="simple"/></inline-formula> can strongly increase storage capacity, in particular for sparse neural activity (small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e158" xlink:type="simple"/></inline-formula>) <xref ref-type="bibr" rid="pone.0096485-Waydo1">[82]</xref>. All data computed from Gaussian approximation of dendritic potential distributions (see appendix II. 2).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g005" position="float" xlink:type="simple"/></fig><fig id="pone-0096485-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g006</object-id><label>Figure 6</label><caption>
<title>Simulation of catastrophic forgetting, Ribot gradients, and the spacing effect.</title>
<p><bold>A</bold>, Networks without structural plasticity suffer from catastrophic forgetting (top), but networks with structural plasticity do not (bottom). Plots show output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e199" xlink:type="simple"/></inline-formula> over time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e200" xlink:type="simple"/></inline-formula> simulating networks of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e201" xlink:type="simple"/></inline-formula> and activity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e202" xlink:type="simple"/></inline-formula> storing 25 memory blocks one after the other (only the interesting part between storage of blocks 6 and 21 are visible). Each curve (with a distinct color) corresponds to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e203" xlink:type="simple"/></inline-formula> for noisy test patterns of a particular memory block with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e204" xlink:type="simple"/></inline-formula> correct and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e205" xlink:type="simple"/></inline-formula> false active units. The steep descent of each curve corresponds to the time when the Hippocampus started to replay the corresponding memory block for 5 time steps. <bold>B</bold>, Networks employing structural plasticity show Ribot gradients after a cortical lesion (top) due to gradients in effectual connectivity (bottom). The lesion was simulated by deactivating half of the neurons in population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e206" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e207" xlink:type="simple"/></inline-formula>. <bold>C</bold>, Networks employing structural plasticity reproduce the spacing effect of learning. In the first simulation (blue) novel memories were rehearsed once for 20 time steps (blue arrow at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e208" xlink:type="simple"/></inline-formula>). In a second simulation (red) the same total rehearsal time was “spaced” or distributed to four brief intervals of five steps each (red arrows at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e209" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e210" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e211" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e212" xlink:type="simple"/></inline-formula>). Here the network achieves a higher effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e213" xlink:type="simple"/></inline-formula> (bottom) and less retrieval noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e214" xlink:type="simple"/></inline-formula> (top). See Sections 2, 3 and <xref ref-type="table" rid="pone-0096485-t001">Table 1</xref> for further details and simulation parameters.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g006" position="float" xlink:type="simple"/></fig></sec><sec id="s2c">
<title>3 Models for Memory Storage and Retrieval</title>
<p>The model presented so far is of general relevance for any neural theory of memory, because it is independent of any specific mechanisms for memory storage and retrieval: Any learning and storing mechanisms are only implicitly conveyed by the learning signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e228" xlink:type="simple"/></inline-formula> that “tags” potential synapses for later consolidation. Similarly, memory recall is not directly described in the model so far. Rather, our theory describes effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e229" xlink:type="simple"/></inline-formula> which is closely linked to retrieval performance for a given memory set. To explain this link and to allow a more quantitative performance evaluation, the next section instantiates and analyzes our model within a common neural network framework of memory storage and recall.</p>
<p>A particularly simple memory model based on Hebbian learning of binary synapses is the <italic>Steinbuch</italic> or <italic>Willshaw model</italic> <xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm1">[44]</xref>, <xref ref-type="bibr" rid="pone.0096485-Steinbuch1">[62]</xref>. In the general <italic>hetero-associative</italic> setup (<xref ref-type="fig" rid="pone-0096485-g003">Fig. 3A</xref>), memories correspond to binary spike activity vectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e230" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e231" xlink:type="simple"/></inline-formula> stored in a synaptic connection <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e232" xlink:type="simple"/></inline-formula> linking two neuron populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e233" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e234" xlink:type="simple"/></inline-formula>. By choosing the <italic>auto-associative</italic> setup with identical <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e235" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e236" xlink:type="simple"/></inline-formula>, the Willshaw model can be applied as well to model memory processes in local recurrent connections (cf. <xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B</xref>). The average number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e237" xlink:type="simple"/></inline-formula> of one-entries in an activity vector is called <italic>pattern activity</italic> and corresponds to the mean size of local Hebbian cell assemblies in populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e238" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e239" xlink:type="simple"/></inline-formula>. After <italic>storing</italic> a set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e240" xlink:type="simple"/></inline-formula> memory associations in a network without structural plasticity, the weight of an actual synapse connecting neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e241" xlink:type="simple"/></inline-formula> to neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e242" xlink:type="simple"/></inline-formula> is<disp-formula id="pone.0096485.e243"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e243" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>Note that a synapse in the Willshaw model is actually a special case of our model of a potential synapse because Eq. 5 instantiates Eq. 4 for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e244" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e245" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e246" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e247" xlink:type="simple"/></inline-formula></p>
<p><italic>Memory retrieval</italic> means the re-activation of a previously stored content pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e248" xlink:type="simple"/></inline-formula> in neuron population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e249" xlink:type="simple"/></inline-formula> following the activation of a (noisy) address pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e250" xlink:type="simple"/></inline-formula> in population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e251" xlink:type="simple"/></inline-formula>. The simplest retrieval procedure is “one-step retrieval” with adaptive threshold control <xref ref-type="bibr" rid="pone.0096485-Schwenker1">[63]</xref>. Specifically, an input pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e252" xlink:type="simple"/></inline-formula> is propagated synchronously from population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e253" xlink:type="simple"/></inline-formula> to population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e254" xlink:type="simple"/></inline-formula> as illustrated in <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3B</xref>. Then dendritic potentials of the neurons in population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e255" xlink:type="simple"/></inline-formula> are given by simple vector-matrix-multiplication, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e256" xlink:type="simple"/></inline-formula>, and the retrieval output <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e257" xlink:type="simple"/></inline-formula> is obtained from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e258" xlink:type="simple"/></inline-formula> by applying a vector of spike thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e259" xlink:type="simple"/></inline-formula>,<disp-formula id="pone.0096485.e260"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e260" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e261" xlink:type="simple"/></inline-formula> is chosen to obtain close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e262" xlink:type="simple"/></inline-formula> active units in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e263" xlink:type="simple"/></inline-formula>. We can then evaluate retrieval quality by estimating the <italic>output noise</italic> level</p>
<p><disp-formula id="pone.0096485.e264"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e264" xlink:type="simple"/><label>(7)</label></disp-formula>defined as the mean Hamming distance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e265" xlink:type="simple"/></inline-formula> between retrieval output <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e266" xlink:type="simple"/></inline-formula> and the original memory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e267" xlink:type="simple"/></inline-formula> normalized to the cell assembly size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e268" xlink:type="simple"/></inline-formula>. Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e269" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e270" xlink:type="simple"/></inline-formula> are component error probabilities. Similarly, we can define input noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e271" xlink:type="simple"/></inline-formula> as the normalized Hamming distance between input pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e272" xlink:type="simple"/></inline-formula> and the original address memory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e273" xlink:type="simple"/></inline-formula>. We will also express input noise in terms of parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e274" xlink:type="simple"/></inline-formula> (completeness) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e275" xlink:type="simple"/></inline-formula> (add noise).</p>
<p>We have used one-step retrieval for some of our experiments (<xref ref-type="fig" rid="pone-0096485-g005">Fig. 5</xref>) because it is most easy to analyze, for example, for estimating the memory capacity of a single network (see below). However, for the investigation of memory phenomena, there exist more realistic retrieval methods that are based on spiking neurons and iterative (gamma range) oscillatory activity propagation <xref ref-type="bibr" rid="pone.0096485-Knoblauch9">[64]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch10">[65]</xref>. As such models are computationally very demanding, in particular, when simulating longer time intervals in the range of months to years, it is more favorable to use simple iterative extensions of one-step retrieval <xref ref-type="bibr" rid="pone.0096485-Hopfield1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096485-Schwenker1">[63]</xref>, <xref ref-type="bibr" rid="pone.0096485-Sommer1">[66]</xref>, <xref ref-type="bibr" rid="pone.0096485-Kosko1">[67]</xref>) that can still mimic many relevant properties of the realistic models.</p>
<p>In particular, iterative retrieval avoids the most serious limitation of one-step retrieval, that is, the lack of a sufficient attractor behavior: High output noise after one-step retrieval does not exclude perfect retrieval after iterated retrieval steps. In fact, as long as the output noise level after the first step is smaller than the input noise level, the iterative retrieval procedure is likely to reduce output noise to zero in subsequent retrieval steps. As a consequence, for <italic>individual</italic> memories, the relation between input and output noise will be much steeper if using the iterative models: A memory pattern can be retrieved either perfectly or the number of component errors is very high. Still, one-step retrieval is useful by providing lower bounds (because of its suboptimality) and upper bounds (assuming zero input noise) of the true storage capacity.</p>
<p>For our long-term simulations of memory phenomena (<xref ref-type="fig" rid="pone-0096485-g006">Fig. 6</xref>) we have therefore extended the Willshaw model in two ways: First, similar as illustrated by <xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B</xref>, we have included also Willshaw-type auto-associative connections in addition to the hetero-associative link from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e276" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e277" xlink:type="simple"/></inline-formula> in order to account for the rich recurrent connectivity of cortex and to enable iterative refinement of retrieval outputs. Second, we have implemented an <italic>iterative retrieval</italic> procedure as follows (cf. <xref ref-type="bibr" rid="pone.0096485-Schwenker1">[63]</xref>): In an initial step, the input pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e278" xlink:type="simple"/></inline-formula> is propagated through the hetero-associative connections from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e279" xlink:type="simple"/></inline-formula> to population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e280" xlink:type="simple"/></inline-formula>, in which the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e281" xlink:type="simple"/></inline-formula> neurons with the largest dendritic potentials become active, resulting in a preliminary retrieval result <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e282" xlink:type="simple"/></inline-formula>. In similar further steps, this preliminary result was then iteratively propagated through the auto-associative network of population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e283" xlink:type="simple"/></inline-formula> yielding refined retrieval outputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e284" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e285" xlink:type="simple"/></inline-formula> (where all recurrent connections to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e286" xlink:type="simple"/></inline-formula> were inactivated). Typically, a small number of iterations was sufficient to obtain stable outputs. For evaluation of output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e287" xlink:type="simple"/></inline-formula> we used the activity pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e288" xlink:type="simple"/></inline-formula> after 3 iterations and compared it to the original memory pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e289" xlink:type="simple"/></inline-formula> to estimate component error probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e290" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e291" xlink:type="simple"/></inline-formula> (see Eq. 7).</p>
<p>For the simulations involving structurally plastic networks and long-term consolidation (<xref ref-type="fig" rid="pone-0096485-g006">Fig. 6</xref>) we have divided the overall memory set into multiple blocks <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e292" xlink:type="simple"/></inline-formula> each containing several individual memory patterns. Each memory block defines a consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e293" xlink:type="simple"/></inline-formula> that is identical to the Willshaw matrix (Eq.5) obtained from the corresponding subset of memories. Thus, memory blocks are consolidated one after the other, each for a certain number of simulation steps, by reactivating the corresponding activity patterns in populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e294" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e295" xlink:type="simple"/></inline-formula> to mimic either hippocampal short-term storage and top-down replay (<xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B,C</xref>) or repeated bottom-up rehearsal of the corresponding memories (<xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B,D</xref>). <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6</xref> shows simulations with structural plasticity in the connection <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e296" xlink:type="simple"/></inline-formula> linking <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e297" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e298" xlink:type="simple"/></inline-formula>. By contrast, the recurrent connections within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e299" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e300" xlink:type="simple"/></inline-formula> were prewired without any structural plasticity and auto-associatively stored the individual patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e301" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e302" xlink:type="simple"/></inline-formula> with a fixed connectivity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e303" xlink:type="simple"/></inline-formula> for <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6A</xref>, upper panel; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e304" xlink:type="simple"/></inline-formula> for <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6A</xref>, lower panel; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e305" xlink:type="simple"/></inline-formula> for <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6B,C</xref>). <xref ref-type="table" rid="pone-0096485-t001">Table 1</xref> summarizes the remaining simulation parameters.</p>
<table-wrap id="pone-0096485-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.t001</object-id><label>Table 1</label><caption>
<title>Simulation parameters.</title>
</caption><alternatives><graphic id="pone-0096485-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Figure No.</td>
<td align="left" rowspan="1" colspan="1">synapse model</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e159" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e160" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e161" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e162" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e163" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">#blocks</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e164" xlink:type="simple"/></inline-formula>/block</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e165" xlink:type="simple"/></inline-formula></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">4A</td>
<td align="left" rowspan="1" colspan="1">single</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e166" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">100–6931</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4B</td>
<td align="left" rowspan="1" colspan="1">single</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e167" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">100</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4C</td>
<td align="left" rowspan="1" colspan="1">single</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e168" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">100</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6A, upper</td>
<td align="left" rowspan="1" colspan="1">multi</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e169" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">0.9</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">0</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6A, lower</td>
<td align="left" rowspan="1" colspan="1">multi</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e170" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">0.9</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6B</td>
<td align="left" rowspan="1" colspan="1">multi</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e171" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">0.9</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6C</td>
<td align="left" rowspan="1" colspan="1">multi</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e172" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1000</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">0.9</td>
<td align="left" rowspan="1" colspan="1">0.1</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">0.01</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Model parameters for the simulations shown in <xref ref-type="fig" rid="pone-0096485-g004">Figs. 4</xref> and <xref ref-type="fig" rid="pone-0096485-g006">6</xref>. All simulations used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e173" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e174" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e175" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e176" xlink:type="simple"/></inline-formula> and a homeostatic setting maintaining a constant anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e177" xlink:type="simple"/></inline-formula> where the number of eliminated synapses per time step was equal to the number of generated synapses, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e178" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e179" xlink:type="simple"/></inline-formula> is the potential connectivity and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e180" xlink:type="simple"/></inline-formula> is the fraction of unconsolidated silent synapses at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e181" xlink:type="simple"/></inline-formula>. Synapse model: “single”  =  at most a single synapse per neuron pair; “multi”  =  multiple synapses per neuron pair are possible. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e182" xlink:type="simple"/></inline-formula> is anatomical connectivity of the synaptic projection from population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e183" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e184" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e185" xlink:type="simple"/></inline-formula> is population size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e186" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e187" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e188" xlink:type="simple"/></inline-formula> is cell assembly size (i.e., number of one-entries in memory patterns). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e189" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e190" xlink:type="simple"/></inline-formula> denote completeness and add noise in input patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e191" xlink:type="simple"/></inline-formula> (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e192" xlink:type="simple"/></inline-formula> has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e193" xlink:type="simple"/></inline-formula> correct and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e194" xlink:type="simple"/></inline-formula> false one-entries). # blocks is number of memory blocks that are subsequentially stored. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e195" xlink:type="simple"/></inline-formula>/block is the number of memories per memory block. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e196" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e197" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e198" xlink:type="simple"/></inline-formula> are the state transition probabilities of the (potential) synapses.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2d">
<title>4 Definitions of Storage Capacity</title>
<p>The <italic>storage capacity</italic> is the amount of information (in bits) that a neural network can store (and retrieve) per synapse. There are two contributions to the total capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e306" xlink:type="simple"/></inline-formula> of a synapse,<disp-formula id="pone.0096485.e307"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e307" xlink:type="simple"/><label>(8)</label></disp-formula></p>
<p>First, the <italic>weight capacity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e308" xlink:type="simple"/></inline-formula> is the information stored by modification of the synaptic weight for a fixed network structure. (a more general definition could as well include any other modifications of synaptic <italic>state</italic> variables such as synaptic transmission delay). Second, the <italic>structural capacity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e309" xlink:type="simple"/></inline-formula> is the information stored by selecting an appropriate target location for a synapse with fixed weight. We would like to evaluate storage capacity at a limited small output noise level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e310" xlink:type="simple"/></inline-formula> (see Eq. 7): The “stored information” can then be computed from the <italic>pattern capacity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e311" xlink:type="simple"/></inline-formula> defined as the maximum number of memories that can be stored at noise level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e312" xlink:type="simple"/></inline-formula>, whereas the <italic>weight capacity</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e313" xlink:type="simple"/></inline-formula> is the stored information normalized to the number of synapses in a static network (no structural plasticity) with connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e314" xlink:type="simple"/></inline-formula>,<disp-formula id="pone.0096485.e315"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e315" xlink:type="simple"/><label>(9)</label></disp-formula><disp-formula id="pone.0096485.e316"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e316" xlink:type="simple"/><label>(10)</label></disp-formula></p>
<p>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e317" xlink:type="simple"/></inline-formula> is the transinformation (or mutual information) when transmitting independent memory components <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e318" xlink:type="simple"/></inline-formula> (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e319" xlink:type="simple"/></inline-formula>) over a binary channel (with transition probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e320" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e321" xlink:type="simple"/></inline-formula> as in Eq. 7) and receiving <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e322" xlink:type="simple"/></inline-formula> (for details see appendix A in <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>). In general, it is difficult to disentangle the two contributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e323" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e324" xlink:type="simple"/></inline-formula>. Thus, in the results section we will compute the total capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e325" xlink:type="simple"/></inline-formula> for some special cases.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>5 Structural Plasticity Increases Effectual Connectivity</title>
<p>In the previous section we have introduced effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e326" xlink:type="simple"/></inline-formula> as a measure of how well a given set of memories is stored in a synaptic network. Without any structural changes of the network, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e327" xlink:type="simple"/></inline-formula> will obviously remain constant, for example, at the level of anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e328" xlink:type="simple"/></inline-formula> for novel memories that do not correlate with the current network structure. It is therefore more interesting to investigate the dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e329" xlink:type="simple"/></inline-formula> during phases of ongoing structural plasticity. For consistency with experimental observations it seems most reasonable to focus on a parameter range where structural plasticity operates on a slower time scale than Hebbian-type weight plasticity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e330" xlink:type="simple"/></inline-formula>), but on a faster time scale than the lifetime of stable consolidated synapses (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e331" xlink:type="simple"/></inline-formula>).</p>
<p>It is indeed possible to analyze our model in such a parameter regime: In Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> I.2 we compute the temporal evolution of effectual connectivity during consolidation of a novel memory set under the following simplifying assumptions: 1) Large networks with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e332" xlink:type="simple"/></inline-formula> such that all macroscopic variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e333" xlink:type="simple"/></inline-formula> are close to their means; 2) at most a single synapse per neuron pair; 3) binary consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e334" xlink:type="simple"/></inline-formula>; 4) new memories specified by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e335" xlink:type="simple"/></inline-formula> are independent of initial network structure and any old memories; 5) immediate consolidation with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e336" xlink:type="simple"/></inline-formula>; 6) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e337" xlink:type="simple"/></inline-formula>; 7) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e338" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e339" xlink:type="simple"/></inline-formula> in homeostatic balance such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e340" xlink:type="simple"/></inline-formula> is constant. Then effectual connectivity for a new set of memories increases from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e341" xlink:type="simple"/></inline-formula> before any learning starts to<disp-formula id="pone.0096485.e342"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e342" xlink:type="simple"/></disp-formula><disp-formula id="pone.0096485.e343"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e343" xlink:type="simple"/><label>(11)</label></disp-formula></p>
<p>assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e344" xlink:type="simple"/></inline-formula> is provided at each time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e345" xlink:type="simple"/></inline-formula> (e.g., by memory replay) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e346" xlink:type="simple"/></inline-formula> is the fraction of initially consolidated synapses (corresponding to old memories). The second approximation additionally presumes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e347" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e348" xlink:type="simple"/></inline-formula>. Thus, convergence of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e349" xlink:type="simple"/></inline-formula> towards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e350" xlink:type="simple"/></inline-formula> requires <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e351" xlink:type="simple"/></inline-formula> (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e352" xlink:type="simple"/></inline-formula>) or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e353" xlink:type="simple"/></inline-formula> (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e354" xlink:type="simple"/></inline-formula>). Also note that during the first consolidation step there is a quick increase from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e355" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e356" xlink:type="simple"/></inline-formula> followed by a much slower increase towards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e357" xlink:type="simple"/></inline-formula> in the subsequent steps. Section 7.1 relates this behavior to the spacing effect as a possible explanation why several brief learning sessions are generally more effective than a single long session.</p>
<p><xref ref-type="fig" rid="pone-0096485-g004">Figure 4</xref> shows that the approximations accurately predict microscopic model simulations. Consolidation becomes slower for larger consolidation loads <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e358" xlink:type="simple"/></inline-formula> which limits maximal storage capacity (panel A; see Section 6). Similarly, consolidation becomes slower for increasing fractions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e359" xlink:type="simple"/></inline-formula> of initially consolidated synapses (panel B). As <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e360" xlink:type="simple"/></inline-formula> will correlate with the number of previously consolidated memories and, thus, with age, this implies that memory consolidation should be faster in young compared to old subjects, even if the anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e361" xlink:type="simple"/></inline-formula> would be constant over lifetime. Moreover, the corresponding gradients in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e362" xlink:type="simple"/></inline-formula> resulting after a fixed number of consolidation steps can be related to gradients in memory performance in graded retrograde amnesia (Section 7.2) and the absence of catastrophic forgetting (Section 7.1). Finally, panel C shows that even slight increases in anatomical connectivity (as reported after learning new concepts or tasks <xref ref-type="bibr" rid="pone.0096485-Xu1">[68]</xref>; cf. <xref ref-type="fig" rid="pone-0096485-g007">Fig. 7</xref>) can strongly speed-up memory consolidation if a large proportion of synapses are in the consolidated state (as expected for adult networks after synaptic pruning <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096485-Chechik1">[15]</xref>).</p>
<fig id="pone-0096485-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0096485.g007</object-id><label>Figure 7</label><caption>
<title>Sketch of network connectivity reflecting lifelong structural plasticity.</title>
<p>During development anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e363" xlink:type="simple"/></inline-formula> (thick solid) quickly increases reaching a peak level (around 2–3y in humans), where the initial increase is followed by a short period of stable connectivity (until age 5y in humans), a phase of significant decrease of connectivity until puberty, and finally a phase of stable connectivity during adulthood <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>, <xref ref-type="bibr" rid="pone.0096485-Huttenlocher2">[77]</xref>. Recent experiments suggest a temporary novelty-driven (thick arrows) increase of connectivity during adulthood <xref ref-type="bibr" rid="pone.0096485-Fu1">[23]</xref>, <xref ref-type="bibr" rid="pone.0096485-Xu1">[68]</xref>, <xref ref-type="bibr" rid="pone.0096485-Yu1">[116]</xref>. Our model of structural plasticity predicts that learning is fastest for high levels of anatomical connectivity and structural plasticity. Thus, memories acquired during early phases can reach higher levels of effectual connectivity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e364" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e365" xlink:type="simple"/></inline-formula>; thin solid lines) compared to memories acquired during later phases (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e366" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e367" xlink:type="simple"/></inline-formula>). The resulting gradients in effectual connectivity can explain various memory phenomena (see Section 7 for details).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0096485.g007" position="float" xlink:type="simple"/></fig>
<p>Our analysis and further simulations (data not shown) reveal that the described increase of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e368" xlink:type="simple"/></inline-formula> is very stable and occurs for virtual any plausible configuration of model parameters. Before we discuss the mentioned memory phenomena in more detail, the following shows that, by increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e369" xlink:type="simple"/></inline-formula>, structural plasticity can store much more information per synapse than Hebbian-type weight plasticity.</p>
</sec><sec id="s3b">
<title>6 How Much Information can a Synapse Store?</title>
<p>It is a well-known result of information theory <xref ref-type="bibr" rid="pone.0096485-Shannon1">[69]</xref> that optimally coding an entity taken at random from a set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e370" xlink:type="simple"/></inline-formula> different entities takes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e371" xlink:type="simple"/></inline-formula> bits of information <xref ref-type="bibr" rid="pone.0096485-Shannon1">[69]</xref> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e372" xlink:type="simple"/></inline-formula>). From this we can derive simple upper bounds for the maximal information that a synapse can store by counting the number of possible synaptic states, i.e. the number of possible weights and locations, that can be realized by weight plasticity and structural plasticity, respectively. The resulting upper bounds for weight capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e373" xlink:type="simple"/></inline-formula> and structural capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e374" xlink:type="simple"/></inline-formula> are<disp-formula id="pone.0096485.e375"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e375" xlink:type="simple"/><label>(12)</label></disp-formula></p>
<p>assuming that weight plasticity can choose one out of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e376" xlink:type="simple"/></inline-formula> possible discrete weights for an individual synapse, and structural plasticity can choose between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e377" xlink:type="simple"/></inline-formula> targets where to grow a novel synapse. These bounds could trivially be reached by an ideal observer that has direct access to synaptic attributes (i.e., weights and locations). However, here we are rather interested in how much information a synaptic network can store <italic>and</italic> safely retrieve employing biologically plausible mechanisms. In particular, we have to measure the amount of retrieved information from plausible neural output variables such as spikes or mean firing rates. For this it is necessary to link our theory to concrete neural network models of memory storage and retrieval, such as Willshaw and Hopfield-type models (<xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hopfield1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm2">[45]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hertz1">[70]</xref>, <xref ref-type="bibr" rid="pone.0096485-Lansner1">[71]</xref>; see section 3).</p>
<p>Our theory yields the surprising result that the weight capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e378" xlink:type="simple"/></inline-formula> in the brain might actually be negligible compared to structural capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e379" xlink:type="simple"/></inline-formula>. First, it is well understood that weight capacity of biologically plausible memory models is limited by hard theoretical bounds suggesting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e380" xlink:type="simple"/></inline-formula> bit per synapse even for an infinite computing precision with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e381" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Hopfield1">[27]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm2">[45]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch5">[46]</xref>, <xref ref-type="bibr" rid="pone.0096485-Gardner1">[72]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch11">[73]</xref>. Second, due to noisy transmission characteristics and various adaptation mechanisms, real synapses are likely to have a rather small number of functionally distinctive states, perhaps <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e382" xlink:type="simple"/></inline-formula> being on the order of ten or even binary <xref ref-type="bibr" rid="pone.0096485-Petersen1">[74]</xref>–<xref ref-type="bibr" rid="pone.0096485-OConnor1">[76]</xref>. Third, unlike <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e383" xlink:type="simple"/></inline-formula>, the number of potential targets <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e384" xlink:type="simple"/></inline-formula> may actually be very large in the brain: For example, for a cortical neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e385" xlink:type="simple"/></inline-formula> is on the order of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e386" xlink:type="simple"/></inline-formula> corresponding to the number of neighboring cells within the same macrocolumn <xref ref-type="bibr" rid="pone.0096485-Braitenberg1">[24]</xref>, and the number of targets <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e387" xlink:type="simple"/></inline-formula> may be even much larger because each neuron may have a large number of functionally distinct dendritic compartments <xref ref-type="bibr" rid="pone.0096485-Poirazi1">[28]</xref>. Fourth, it has been recently shown that the upper bound of structural capacity can be tightly reached for synaptic pruning following learning in completely connected networks <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>.</p>
<p>Before generalizing these results to ongoing structural plasticity in sparsely connected networks, let us first re-analyze the classical Willshaw model (without structural plasticity) as illustrated in <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3A,B</xref>. There, synaptic weight plasticity follows a simple binary Hebbian rule (Eq. 5). Due to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e388" xlink:type="simple"/></inline-formula> (cf. Eq. 4) the fraction of consolidated synapses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e389" xlink:type="simple"/></inline-formula> increases monotonically with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e390" xlink:type="simple"/></inline-formula> until it reaches a maximal value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e391" xlink:type="simple"/></inline-formula> beyond which the output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e392" xlink:type="simple"/></inline-formula> exceeds the tolerable level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e393" xlink:type="simple"/></inline-formula>. Some theory presented in Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> II.1 shows that the corresponding pattern capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e394" xlink:type="simple"/></inline-formula> crucially depends on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e395" xlink:type="simple"/></inline-formula>: For networks of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e396" xlink:type="simple"/></inline-formula>, randomly generated cell assemblies of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e397" xlink:type="simple"/></inline-formula>, and input noise with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e398" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e399" xlink:type="simple"/></inline-formula>, it is (see text below Eq. 28 in Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> II.1)<disp-formula id="pone.0096485.e400"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e400" xlink:type="simple"/></disp-formula><disp-formula id="pone.0096485.e401"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e401" xlink:type="simple"/><label>(13)</label></disp-formula>where factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e402" xlink:type="simple"/></inline-formula> comes close to one for large networks. Multiplication by the stored information per memory and dividing by the number of synapses gives the well known weight capacity of the Willshaw model (see Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> II. 1),</p>
<p><disp-formula id="pone.0096485.e403"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e403" xlink:type="simple"/><label>(14)</label></disp-formula>where the upper bound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e404" xlink:type="simple"/></inline-formula> bps can be reached for large networks, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e405" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e406" xlink:type="simple"/></inline-formula>, sparse activity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e407" xlink:type="simple"/></inline-formula>, and zero input noise with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e408" xlink:type="simple"/></inline-formula>.</p>
<p>In previous works on structural plasticity we have focused on <italic>synaptic pruning</italic> of silent synapses after learning all memories in a <italic>fully connected</italic> network (<xref ref-type="fig" rid="pone-0096485-g003">Fig. 3C</xref>). Here we extend these results to networks with incomplete (“diluted”) connectivity and ongoing structural plasticity. Let us first consider synaptic pruning which has been described as one of three phases during brain development (e.g., in humans, synaptic density increases until age of 2–3 years, then remains stable until 5 y, then decreases until puberty and remains relatively stable during adulthood; cf. <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>, <xref ref-type="bibr" rid="pone.0096485-Huttenlocher2">[77]</xref>; see also <xref ref-type="fig" rid="pone-0096485-g007">Fig. 7</xref>):</p>
<list list-type="order"><list-item>
<p>Synaptic overgrowth: The synaptic generation rate is much larger than the elimination rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e409" xlink:type="simple"/></inline-formula>, such that anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e410" xlink:type="simple"/></inline-formula> can come close to potential connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e411" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p>Critical consolidation phase: Weight plasticity potentiates and consolidates useful synapses that support memory contents specified by the consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e412" xlink:type="simple"/></inline-formula>, e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e413" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e414" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p>Synaptic pruning: Useless synapses are eliminated, e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e415" xlink:type="simple"/></inline-formula> (cf. <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3C</xref>).</p>
</list-item></list>
<p>Because only a fraction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e416" xlink:type="simple"/></inline-formula> of the synapses survives phase three, the total storage capacity at maximal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e417" xlink:type="simple"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e418" xlink:type="simple"/></inline-formula>) is obtained from renormalizing Eq. 14,<disp-formula id="pone.0096485.e419"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e419" xlink:type="simple"/><label>(15)</label></disp-formula></p>
<p>Using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e420" xlink:type="simple"/></inline-formula> from Eq. 13 reveals that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e421" xlink:type="simple"/></inline-formula> for sufficiently small cell assembly sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e422" xlink:type="simple"/></inline-formula> (see Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> II. 1). Thus, the Willshaw model with structural plasticity comes close to the information-theoretic capacity bound (Eq. 12). We have shown elsewhere that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e423" xlink:type="simple"/></inline-formula> can be reached tightly with much weaker assumptions on cell assembly sizes and effectual connectivity by inhibitory implementations of the Willshaw model <xref ref-type="bibr" rid="pone.0096485-Knoblauch5">[46]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch12">[78]</xref> and both excitatory and inhibitory implementations of Bayesian networks with discrete synaptic weights <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch7">[54]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch13">[79]</xref>.</p>
<p>Unlike in development, during adulthood anatomical connectivity is stable. This means that ongoing generation and elimination of synapses must be in homeostatic balance such that the total number of synaptic connections remains approximately constant over time <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096485-Huttenlocher3">[80]</xref>, <xref ref-type="bibr" rid="pone.0096485-Bourgeois1">[81]</xref>. In the following we show that ongoing structural plasticity during adulthood can reach the same high storage capacity as during development, although this process may require significantly more time. The basic idea is that the three developmental processing phases (synaptic generation, consolidation, and elimination) run in parallel during each time step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e424" xlink:type="simple"/></inline-formula>. For example, by choosing the synapse parameters.<disp-formula id="pone.0096485.e425"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e425" xlink:type="simple"/><label>(16)</label></disp-formula>the anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e426" xlink:type="simple"/></inline-formula> remains constant and, in essence, all actual synapses “migrate” to the locations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e427" xlink:type="simple"/></inline-formula> specified by the consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e428" xlink:type="simple"/></inline-formula> (cf. <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3D</xref>). <italic>IF</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e429" xlink:type="simple"/></inline-formula> specifies <italic>all</italic> memories to be stored, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e430" xlink:type="simple"/></inline-formula> is applied during each time step, and the consolidation load <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e431" xlink:type="simple"/></inline-formula> is sufficiently large such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e432" xlink:type="simple"/></inline-formula>, <italic>THEN</italic> memories will be stored at effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e433" xlink:type="simple"/></inline-formula>, there will be no silent synapses left, and the resulting total capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e434" xlink:type="simple"/></inline-formula> is given by Eq. 15. In particular, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e435" xlink:type="simple"/></inline-formula> the resulting network will be identical as for developmental learning described before (see <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3D</xref> and compare to <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3C</xref>). This shows that also adult learning in structurally plastic networks with constant low anatomical connectivity can reach the information theoretic bound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e436" xlink:type="simple"/></inline-formula> (see Eq. 12).</p>
<p>In the following we apply our theory to networks with biologically relevant parameters. For example, a typical network size may correspond to a cortical macrocolumn of size 1 mm<sup>3</sup> containing about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e438" xlink:type="simple"/></inline-formula> neurons and relatively dense recurrent connections with an anatomical connectivity of about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e439" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Braitenberg1">[24]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hellwig1">[25]</xref>. Then we can estimate potential connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e440" xlink:type="simple"/></inline-formula> from experimental measurements of the <italic>filling fraction</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e441" xlink:type="simple"/></inline-formula> defined as the fraction of potential synapses that is actually realized (i.e., in state 0 or state 1). For typical <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e442" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Stepanyants1">[29]</xref>, structural plasticity of dendritic spines alone may account already for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e443" xlink:type="simple"/></inline-formula> within a neocortical macrocolumn. The corresponding storage capacities are depicted in <xref ref-type="fig" rid="pone-0096485-g005">Figure 5</xref>. Note that without structural plasticity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e444" xlink:type="simple"/></inline-formula>) the storage capacity remains tiny, e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e445" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e446" xlink:type="simple"/></inline-formula>. In particular, sparse activity patterns <xref ref-type="bibr" rid="pone.0096485-Waydo1">[82]</xref> cannot be stored at a low connectivity, e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e447" xlink:type="simple"/></inline-formula> requires <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e448" xlink:type="simple"/></inline-formula> to stabilize even a single memory pattern.</p>
<p>By contrast, networks employing structural plasticity with potential connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e449" xlink:type="simple"/></inline-formula> can have a large total capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e450" xlink:type="simple"/></inline-formula>. Interestingly, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e451" xlink:type="simple"/></inline-formula> increases with decreasing connectivity. Thus, even slight increases of effectual connectivity towards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e452" xlink:type="simple"/></inline-formula> can strongly increase number of stored memories (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e453" xlink:type="simple"/></inline-formula>) and even maximize stored information per synapse (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e454" xlink:type="simple"/></inline-formula>). Note that an increase in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e455" xlink:type="simple"/></inline-formula> during consolidation would also allow a simultaneous decrease of activity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e456" xlink:type="simple"/></inline-formula> to maximize capacity. This means that consolidation involving structural plasticity and sparsification will move the “working point” from the lower right towards the upper left in the contour plots of <xref ref-type="fig" rid="pone-0096485-g005">Fig. 5</xref>. Thus, by emulating high effectual connectivity, structural plasticity may also support the sparsification of memory representations <xref ref-type="bibr" rid="pone.0096485-Waydo1">[82]</xref>–<xref ref-type="bibr" rid="pone.0096485-Weinberger1">[85]</xref> and stabilize small cell assemblies that would appear unstable for a fixed low connectivity <xref ref-type="bibr" rid="pone.0096485-Latham1">[86]</xref>, <xref ref-type="bibr" rid="pone.0096485-Aviel1">[87]</xref>.</p>
<p>The following sections show that structural plasticity, in addition to increasing storage capacity, can explain several well known memory phenomena in the brain much better than previous theories.</p>
</sec><sec id="s3c">
<title>7 Relevance of Structural Plasticity for Memory Phenomena</title>
<sec id="s3c1">
<title>7.1 Absence of Catastrophic Forgetting</title>
<p>Artificial neural networks such as multi-layer-perceptrons are well known to suffer from what was called catastrophic forgetting (CF) or the stability-plasticity dilemma <xref ref-type="bibr" rid="pone.0096485-French1">[36]</xref>, <xref ref-type="bibr" rid="pone.0096485-Grossberg2">[88]</xref>–<xref ref-type="bibr" rid="pone.0096485-Abraham1">[91]</xref>. It is the problem that optimizing synaptic weights to store a set of new memories will deteriorate or even destroy previous memories. Freezing synaptic weights can avoid CF, but it also hampers the ability to learn new memories.</p>
<p>Another form of CF has been described for Hopfield-type network models of associative memory <xref ref-type="bibr" rid="pone.0096485-Robins1">[92]</xref>. Here CF means that a neural network with fixed structure can almost perfectly store and retrieve memories until the maximal pattern capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e457" xlink:type="simple"/></inline-formula> is reached. However, exceeding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e458" xlink:type="simple"/></inline-formula> even by a few additional patterns can destroy the ability to retrieve any of the memories. The same problem occurs when increasing the number of stored memory patterns in the Willshaw-type binary learning models (<xref ref-type="fig" rid="pone-0096485-g003">Fig. 3A, B</xref>), even before the point where <italic>all</italic> synapses are uniformly potentiated and therefore have lost specific information about the memory patterns.</p>
<p>CF poses problems for technical applications, but also for modeling memory processes because it does not normally occur in our brains. It has been argued that the capacity of the brain might just be too large for running into CF during a normal lifetime. In addition, several alternative solutions have been suggested. For example, many previous approaches suggested to have an additional hidden neural layer (e.g., between populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e459" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e460" xlink:type="simple"/></inline-formula>) in which a new node is allocated for each new input that deviates significantly from previously stored items. The underlying idea is that in a modular organization, separate subnetworks (comprising different subsets of neuron in the intermediate layer) could be trained independently to represent different memories or categories. Such approaches include ART-type architectures <xref ref-type="bibr" rid="pone.0096485-Carpenter1">[90]</xref>, emergent category-specific modularity <xref ref-type="bibr" rid="pone.0096485-French2">[93]</xref>, hard-wired modularity <xref ref-type="bibr" rid="pone.0096485-Murre1">[94]</xref>, and also ideas involving grandmother cells <xref ref-type="bibr" rid="pone.0096485-Barlow1">[95]</xref> or, in technical terms, look-up-tables <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>. One problem with these approaches is that some high-level mechanism is required for allocating or even generating new neurons in the intermediate layer. However, in most parts of the adult brain, there is little evidence for structural plasticity involving neuron genesis. But without neurogenesis such models also predict catastrophic forgetting at a later time unless plasticity is explicitly switched off after all neurons in the intermediate reservoir have been allocated. Alternative high level mechanisms for preventing CF involve pseudo-rehearsal using self-generated training stimuli from previously learned memories <xref ref-type="bibr" rid="pone.0096485-Robins1">[92]</xref>. In the following we are focusing on solutions to CF that can be built at the level of synapses. For example, palimpsests network models <xref ref-type="bibr" rid="pone.0096485-Nadal1">[96]</xref>–<xref ref-type="bibr" rid="pone.0096485-Sandberg1">[98]</xref> assume a slow decay of synaptic weights (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e461" xlink:type="simple"/></inline-formula>) to prevent approaching the network's capacity limit, however, are not plausible for long-term storage in neocortex. Similarly, synaptic cascade models <xref ref-type="bibr" rid="pone.0096485-Fusi1">[52]</xref> introduce several consolidated states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e462" xlink:type="simple"/></inline-formula> with decreasing decay rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e463" xlink:type="simple"/></inline-formula>. However, this cannot prevent exponential decay of memories unless the lowest decay rate is zero causing again CF.</p>
<p>A novel role in preventing CF can be attributed to structural synaptic plasticity: <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6A</xref> illustrates simulation experiments investigating consolidation of multiple memory blocks each consisting of several novel memories. Each memory block is stored in the hippocampus and replayed to neocortical cell populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e464" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e465" xlink:type="simple"/></inline-formula> for a certain time as described before (<xref ref-type="fig" rid="pone-0096485-g002">Fig. 2B, C</xref>). As expected, without any structural plasticity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e466" xlink:type="simple"/></inline-formula>) the network exhibits CF when approaching the capacity limit (upper panel). In contrast, CF is absent in networks with structural plasticity (lower panel). In this case, early stored memories remain stable all the time whereas the ability to store novel memories fades gradually when approaching the capacity limit. This behavior is more consistent with aging effects of human memory <xref ref-type="bibr" rid="pone.0096485-Hedden1">[99]</xref> and results from the fraction of consolidated synapses steadily increasing with age and the number of stored memories. Correspondingly, the fraction of unconsolidated synapses participating in structural plasticity gradually decreases with age as observed in neurophysiological experiments <xref ref-type="bibr" rid="pone.0096485-Holtmaat1">[21]</xref>.</p>
<p>More precisely, for memories stored with a certain effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e467" xlink:type="simple"/></inline-formula>, structural plasticity can prevent CF only if the filling fraction is below the maximal fraction of consolidated synapses at the capacity limit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e468" xlink:type="simple"/></inline-formula> (see Eq. 13). This condition ensures that the total number of synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e469" xlink:type="simple"/></inline-formula>, is smaller than the maximally allowed number of consolidated synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e470" xlink:type="simple"/></inline-formula>, at the network's capacity limit. If fulfilled, the network can never exceed its capacity limit which effectively prevents catastrophic forgetting. Brain networks could satisfy this condition by maintaining a constant (or slowly decreasing; cf, <xref ref-type="fig" rid="pone-0096485-g007">Fig. 7</xref>) anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e471" xlink:type="simple"/></inline-formula> and by adapting cell assembly size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e472" xlink:type="simple"/></inline-formula> appropriately in relation to network size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e473" xlink:type="simple"/></inline-formula> and some target effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e474" xlink:type="simple"/></inline-formula>. Thus, early memories can be consolidated up to some target connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e475" xlink:type="simple"/></inline-formula> which depends on the replay time per memory block. However, at least if replay time per memory remains constant over lifetime, then for later memories <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e476" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e477" xlink:type="simple"/></inline-formula> will decrease gradually with the decreasing fraction of available structurally plastic synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e478" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pone-0096485-g004">Fig. 4B</xref>). Therefore, the ability to learn new memories will begin to fade when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e479" xlink:type="simple"/></inline-formula> approaches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e480" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s3c2">
<title>7.2 Ribot gradients in retrograde amnesia</title>
<p>Patients with lesions of the hippocampus or neighboring neocortex in the medial temporal lobe often suffer from graded retrograde amnesia <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>, <xref ref-type="bibr" rid="pone.0096485-Ribot1">[40]</xref>, <xref ref-type="bibr" rid="pone.0096485-Zola1">[100]</xref>, <xref ref-type="bibr" rid="pone.0096485-Baddeley1">[101]</xref>. This form of memory loss shows characteristic “Ribot gradients” describing the tendency that recently stored memories are more likely to be lost than remote memories acquired at an earlier time. Simple palimpsests-type memory models (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e481" xlink:type="simple"/></inline-formula>) cannot account for these findings, in fact they predict the reverse effect <xref ref-type="bibr" rid="pone.0096485-Nadal1">[96]</xref>–<xref ref-type="bibr" rid="pone.0096485-Sandberg1">[98]</xref>.</p>
<p>A body of previous work has proposed that the lesions may disrupt cortico-hippocampal memory replay and, as a result, recent memories disappear because they are not sufficiently consolidated in intact neocortex <xref ref-type="bibr" rid="pone.0096485-Ji1">[34]</xref>, <xref ref-type="bibr" rid="pone.0096485-McClelland1">[35]</xref>, <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>, <xref ref-type="bibr" rid="pone.0096485-Ross1">[39]</xref>, <xref ref-type="bibr" rid="pone.0096485-Meeter1">[102]</xref>–<xref ref-type="bibr" rid="pone.0096485-Alvarez1">[104]</xref>. According to such models, the cause of Ribot gradients is a gradient in accumulated replay and consolidation time <xref ref-type="bibr" rid="pone.0096485-Meeter1">[102]</xref>, <xref ref-type="bibr" rid="pone.0096485-Alvarez1">[104]</xref>.</p>
<p>In one of the models <xref ref-type="bibr" rid="pone.0096485-Meeter1">[102]</xref>, for example, replay is controlled by a random walk over the attractor-landscape in Hopfield-type networks where each stored memory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e482" xlink:type="simple"/></inline-formula> corresponds to one of the attractors. After acquiring the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e483" xlink:type="simple"/></inline-formula>th memory, each memory obtains an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e484" xlink:type="simple"/></inline-formula> share of replay time. It is concluded that Ribot gradients occur because early memories (smaller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e485" xlink:type="simple"/></inline-formula>) can accumulate a larger total consolidation time of about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e486" xlink:type="simple"/></inline-formula> than recent memories, resulting in a larger strength of the memory trace.</p>
<p>Such models predict either that memories would be replayed and consolidated for an unlimited time <xref ref-type="bibr" rid="pone.0096485-Meeter1">[102]</xref> or that Ribot gradients would occur only for memories acquired during a limited time interval before the lesion occurred <xref ref-type="bibr" rid="pone.0096485-Alvarez1">[104]</xref>. Although there are not yet final experimental answers <xref ref-type="bibr" rid="pone.0096485-Ji1">[34]</xref>, <xref ref-type="bibr" rid="pone.0096485-Nadel1">[105]</xref>, both predictions may be in conflict with evidence that novel memories are buffered and replayed by the hippocampus for a limited time only <xref ref-type="bibr" rid="pone.0096485-Ji1">[34]</xref>, <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>, <xref ref-type="bibr" rid="pone.0096485-Ross1">[39]</xref> and that, depending on the lesion size, graded amnesia can reach back to early childhood <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>.</p>
<p>Synaptic learning based on structural plasticity offers an alternative explanation for Ribot gradients without relying on unlimited memory replay (<xref ref-type="fig" rid="pone-0096485-g006">Fig. 6B</xref>). According to our model, the substrate of Ribot gradients are gradients in effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e487" xlink:type="simple"/></inline-formula> instead of (or in addition to) gradients in accumulated consolidation time. Even with constant replay time per memory, remote memories are stored with a larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e488" xlink:type="simple"/></inline-formula> than recent memories, for the very same reasons that explained the absence of catastrophic forgetting. Correspondingly, output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e489" xlink:type="simple"/></inline-formula> will be largest for most recent memories. During normal operation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e490" xlink:type="simple"/></inline-formula> is sufficiently low to accurately retrieve both remote and recent memories. However, cortical or hippocampal lesions will increase noise-levels such that memories get lost for which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e491" xlink:type="simple"/></inline-formula> is below some critical value, or equivalently, that have been stored after some critical time point.</p>
</sec><sec id="s3c3">
<title>7.3 Spacing effect</title>
<p>Another interesting feature of memory is that learning new items is more effective if rehearsal is spaced over time compared to single block rehearsal <xref ref-type="bibr" rid="pone.0096485-Crowder1">[41]</xref>–<xref ref-type="bibr" rid="pone.0096485-Ebbinghaus1">[43]</xref>, <xref ref-type="bibr" rid="pone.0096485-Cepeda1">[106]</xref>. For example, learning a list of vocabularies in two sessions each lasting 10 minutes turns out to be more effective than learning in a single session lasting 20 minutes. This so-called spacing effect is remarkably robust and occurs in many explicit and implicit memory tasks in humans and many animals being effective over many time scales from single days to months.</p>
<p>Previous cognitive models attributed the spacing effect either to deficient processing of repeated items during single block rehearsal <xref ref-type="bibr" rid="pone.0096485-Bregman1">[107]</xref> or to improved storage by exploiting context variability between spaced rehearsal sessions <xref ref-type="bibr" rid="pone.0096485-Glenberg1">[108]</xref>. Typically, these explanations presumed specific high-level structures and mechanisms of memory systems including attention, novelty, and context processing. Although detailed modeling of memory systems may be required to explain specific properties in particular memory tasks, the ubiquity of the spacing effect suggests a common underlying mechanism at the cellular level. We propose that structural plasticity in sparsely connected neural networks is such a mechanism.</p>
<p><xref ref-type="fig" rid="pone-0096485-g006">Figure 6C</xref> shows that structurally plastic networks reproduce the spacing effect naturally when learning a new set of memories in a similar protocol as described for the previous simulations (only here the memory replay should be interpreted more generally as rehearsal, not necessarily generated by the hippocampus). In the first simulation (blue) the memories are rehearsed in a single long time block, while in the second simulation (red) rehearsal is spaced over several shorter blocks such that total rehearsal time is equal for both simulations. For spaced rehearsal the resulting effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e492" xlink:type="simple"/></inline-formula> of the memories turns out to be much higher and, correspondingly, the output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e493" xlink:type="simple"/></inline-formula> much lower than for single block rehearsal.</p>
<p>Further simulation experiments (not shown) have indicated that the spacing effect induced by structural plasticity is very stable. Similar to the psychological experiments, it is remarkably difficult to find conditions without spacing effect. In essence, the spacing effect occurs if weight plasticity is faster than structural plasticity and if consolidated synapses are more stable than silent synapses (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e494" xlink:type="simple"/></inline-formula>). Both properties are strongly supported by experiments <xref ref-type="bibr" rid="pone.0096485-Paulsen1">[4]</xref>, <xref ref-type="bibr" rid="pone.0096485-Trachtenberg1">[10]</xref>, <xref ref-type="bibr" rid="pone.0096485-Holtmaat1">[21]</xref>, <xref ref-type="bibr" rid="pone.0096485-Martin1">[109]</xref>. In this case, our theory predicts that even in brief rehearsal sessions Hebbian plasticity can quickly consolidate all available synapses useful to store a set of memories. Thus, instead of continuing a rehearsal session, it is better to wait until structural plasticity has grown additional useful synapses that can then be consolidated in a brief second rehearsal session. As a consequence, spacing effects will necessarily occur whenever learning in the brain depends on structural plasticity. Interestingly, our model with structural plasticity can also quantitatively reproduce long-term spacing effects as recently observed in psychological experiments that investigated optimal spacing intervals to maximize memory retention <xref ref-type="bibr" rid="pone.0096485-Knoblauch14">[110]</xref>, <xref ref-type="bibr" rid="pone.0096485-Cepeda2">[111]</xref>.</p>
</sec></sec></sec><sec id="s4">
<title>Discussion</title>
<p>One important limitation in the brain seems to be the number or density of functional (non-silent) synapses, both for anatomical and metabolic reasons. For example, the number of synapses per cortical volume is remarkably similar across different species <xref ref-type="bibr" rid="pone.0096485-Abeles1">[112]</xref>, and theoretical considerations suggest that the energy consumption of the brain is dominated by the number of postsynaptic potentials or, equivalently, the number of functional non-silent synapses <xref ref-type="bibr" rid="pone.0096485-Lennie1">[47]</xref>–<xref ref-type="bibr" rid="pone.0096485-Attwell1">[49]</xref>. In face of these limitation, it might be beneficial that learning in brain circuits “moves” synapses to computationally useful locations <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch2">[31]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch15">[113]</xref>.</p>
<p>To get a quantitative grip of these ideas we have introduced the concept of effectual connectivity, a macroscopic measure for how useful network structure is for memory storage. Structural plasticity can increase effectual connectivity while keeping the anatomical connectivity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e495" xlink:type="simple"/></inline-formula>) at a low constant level. This has been analyzed for a simple model of structural plasticity assuming the following three basic mechanisms: (1) blind synaptogenesis, (2) consolidation of useful synapses, and (3) elimination of irrelevant synapses. Further, we have focused on the most plausible parameter range where structural plasticity (1,3) operates on a slower time scale than weight plasticity and consolidation (2), but the lifetime of consolidated synapses is long compared to the turnover of unstable synapses (see Section 2 and Section 5 for details; cf. <xref ref-type="bibr" rid="pone.0096485-Paulsen1">[4]</xref>, <xref ref-type="bibr" rid="pone.0096485-Trachtenberg1">[10]</xref>, <xref ref-type="bibr" rid="pone.0096485-Holtmaat1">[21]</xref>). In our current model implementation we identify strong synapses with stable synapses (weight and state 1) as well as weak synapses with unstable synapses (weight and state 0). This contrasts with some experimental results suggesting that silent synapses could be quite stable <xref ref-type="bibr" rid="pone.0096485-Hofer1">[114]</xref> whereas even strong synapses could be eliminated, for example, during development <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>. Such findings may be explained by the probabilistic nature of state transitions in our synapse model or a dissociation between synaptic strength and stability, perhaps including a cascade of several different stable and unstable states <xref ref-type="bibr" rid="pone.0096485-Fusi1">[52]</xref>.</p>
<p>Our model is applicable to learning during development, as well as during adulthood (<xref ref-type="fig" rid="pone-0096485-g007">Fig. 7</xref>). During development the three mechanisms appear to dominate different phases separated on a large time scale of years <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>–<xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>, <xref ref-type="bibr" rid="pone.0096485-Huttenlocher2">[77]</xref>, <xref ref-type="bibr" rid="pone.0096485-Miyoshi1">[115]</xref>. Still, on a smaller time scale of days or months <xref ref-type="bibr" rid="pone.0096485-Butz2">[20]</xref>, <xref ref-type="bibr" rid="pone.0096485-Holtmaat1">[21]</xref>, <xref ref-type="bibr" rid="pone.0096485-Fu1">[23]</xref>, ongoing structural plasticity, involving the three mechanisms simultaneously, could control the anatomical connectivity to be approximately constant (see Eq. 16). Such homeostatic regulation of generation and elimination of synapses is even more evident during adulthood where the anatomical connectivity appears almost stable over several decades <xref ref-type="bibr" rid="pone.0096485-Huttenlocher1">[14]</xref>, <xref ref-type="bibr" rid="pone.0096485-Elston1">[51]</xref>, <xref ref-type="bibr" rid="pone.0096485-Huttenlocher2">[77]</xref>. However, recent experiments demonstrate that there can be novelty-driven excursions from homeostatic balance on the time scale of several days in specific cortical areas of the adult brain, for example, during learning of motor memories <xref ref-type="bibr" rid="pone.0096485-Fu1">[23]</xref>, <xref ref-type="bibr" rid="pone.0096485-Xu1">[68]</xref>, <xref ref-type="bibr" rid="pone.0096485-Yu1">[116]</xref>. This phenomenon can be understood within our modeling framework as a different control strategy of the anatomical connectivity, one which is driven by learning load. Specifically, in instances of high learning load, up-regulating the anatomical network connectivity is the means to achieve faster learning by increasing the number of unstable silent synapses that may be recruited into new memories by structural plasticity and consolidation. Taken together, the model can explain the major differences of structural plasticity during development and adulthood by shifts in how metabolic constraints and learning speed are leveraged.</p>
<p>To simulate structural and weight plasticity we have used a simple three state Markov model of a potential synapse where state transition probabilities (with exception of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e496" xlink:type="simple"/></inline-formula>) depend on a Hebbian-type consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e497" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pone-0096485-g002">Fig. 2A</xref>, Eq. 4). Our plasticity model generalizes the binary Willshaw model <xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm1">[44]</xref> and strongly simplifies realistic weight plasticity models, for example, those based on spike-timing dependent synaptic plasticity (STDP) where potentiation depends on the precise temporal order of presynaptic and postsynaptic spikes <xref ref-type="bibr" rid="pone.0096485-Markram2">[117]</xref>–<xref ref-type="bibr" rid="pone.0096485-Clopath1">[119]</xref>. In fact, it has been discussed controversially whether STDP-type learning rules would at all be consistent with the Hebbian idea that “what fires together wires together” because, unlike the Willshaw model, simple STDP models predict decoupling of neurons firing at the same time <xref ref-type="bibr" rid="pone.0096485-Lubenov1">[120]</xref>–<xref ref-type="bibr" rid="pone.0096485-Fell1">[123]</xref>. However, we have recently shown that more realistic STDP models (including dendritic propagation delays and parameters fitted to physiological data) are generally consistent with Hebbian learning and local cell assemblies <xref ref-type="bibr" rid="pone.0096485-Knoblauch17">[124]</xref>.</p>
<p>Similarly, we argue that our model is also consistent with more realistic models of structural plasticity based on homeostatic mechanisms for maintaining mean neuronal firing rates at a constant level <xref ref-type="bibr" rid="pone.0096485-Butz2">[20]</xref>, <xref ref-type="bibr" rid="pone.0096485-Butz3">[50]</xref>. In such models, generation and elimination of synapses is induced by firing rates being below and above the homeostatic level, respectively. This is similar to our model with a homeostatic constraint for maintaining a constant anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e498" xlink:type="simple"/></inline-formula> (see Section 2), because the mean firing rate of a neuron (e.g., during phases of ongoing activity <xref ref-type="bibr" rid="pone.0096485-Arieli1">[125]</xref>) will strongly correlate with the number of synapses on its dendrite (cf. <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch18">[126]</xref>). Thus, keeping firing rates in homeostasis is essentially equivalent to maintaining the number of synapses per neuron and, thus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e499" xlink:type="simple"/></inline-formula>, at a constant level. In our simulations, we have explicitly adjusted the generation rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e500" xlink:type="simple"/></inline-formula> in each step in order to keep <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e501" xlink:type="simple"/></inline-formula> constant, but in a more realistic setting, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e502" xlink:type="simple"/></inline-formula> could as well be driven by factors representing each neuron's mean firing rate.</p>
<p>Thus, we argue that both Hebbian and homeostatic structural plasticity are necessary to optimize information storage: Hebbian structural plasticity (via <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e503" xlink:type="simple"/></inline-formula>) is necessary to eliminate those synapses that are not useful for storing a memory set. But homeostatic structural plasticity (via <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e504" xlink:type="simple"/></inline-formula>) is also necessary: First, to balance the requirements of fast learning (large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e505" xlink:type="simple"/></inline-formula>) and space and energy efficiency (low <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e506" xlink:type="simple"/></inline-formula>). Second, homeostatic structural plasticity may also contribute to <italic>uniformly</italic> sample new memory representations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e507" xlink:type="simple"/></inline-formula> from the space of all possible activity patterns (with unit usages <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e508" xlink:type="simple"/></inline-formula> being equal for all neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e509" xlink:type="simple"/></inline-formula>), which is known to be optimal for minimizing output noise and maximizing storage capacity in multi-layer networks (see <xref ref-type="fig" rid="pone-0096485-g007">Fig. 7</xref> in <xref ref-type="bibr" rid="pone.0096485-Knoblauch19">[127]</xref>; cf. <xref ref-type="bibr" rid="pone.0096485-Knoblauch18">[126]</xref>, <xref ref-type="bibr" rid="pone.0096485-Buckingham1">[128]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref>): For example, a neuron representing only a few memories will have few state-1 synapses and, correspondingly, low firing rates. This may increase <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e510" xlink:type="simple"/></inline-formula> to generate new state-0 synapses, rendering this neuron more plastic and receptive for being used to represent new memories, thereby increasing state-1 synapse number and firing rates until the desired homeostatic level is reached. Some previous works have actually argued that non-Hebbian homeostatic structural plasticity could be sufficient to explain memory formation <xref ref-type="bibr" rid="pone.0096485-Butz1">[18]</xref>, <xref ref-type="bibr" rid="pone.0096485-Dammasch1">[130]</xref>. Although this may hold true if cell assemblies representing different memories would be spatially separated with only little overlap, our results emphasize also the need of Hebbian-type structural plasticity with a specific elimination of unconsolidated synapses. Without Hebbian structural plasticity it seems impossible to stabilize a larger number of overlapping cell assemblies and to come close to the high memory capacity of our model <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>.</p>
<p>By introducing the concepts of effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e511" xlink:type="simple"/></inline-formula> and consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e512" xlink:type="simple"/></inline-formula>, our theory remains largely independent of a specific underlying neural network model of memory. In fact, the performance of the specific model in terms of output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e513" xlink:type="simple"/></inline-formula> is generally a non-linear monotonic function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e514" xlink:type="simple"/></inline-formula> of effectual connectivity, e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e515" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e516" xlink:type="simple"/></inline-formula> depends on the network model, network size, number of active units per memory vector, number of stored memories, and other factors. Here we have investigated Willshaw-type networks with binary synapses <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Willshaw1">[26]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm1">[44]</xref> because they give a simple and intuitive answer to the question which synapses are irrelevant and thus eligible for pruning. However, the efficiency of structural plasticity generalizes to learning employing graded synaptic states <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch7">[54]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch13">[79]</xref>. Previous approaches to memory formation by structural plasticity have also discussed that memories could be encoded in the number of synapses rather than by changing weights of individual synapses <xref ref-type="bibr" rid="pone.0096485-Poirazi1">[28]</xref>.</p>
<p>There are several lines of evidence suggesting that the binary weight model (corresponding to states 0 and 1) is already quite useful, in particular, if one would add suitable noise terms to account for distributed synaptic strength: First, experiments indicate that real synapses may have only a small number of functionally distinctive states or may even be binary <xref ref-type="bibr" rid="pone.0096485-Petersen1">[74]</xref>–<xref ref-type="bibr" rid="pone.0096485-OConnor1">[76]</xref>, <xref ref-type="bibr" rid="pone.0096485-Song2">[131]</xref>. Second, real synapses tend to scale their strengths such that in the soma (where spikes are generated) the resulting postsynaptic potentials have a relatively constant amplitude <xref ref-type="bibr" rid="pone.0096485-London1">[61]</xref>. Third, anatomical experiments have shown that the number of real synapses per connected neuron pair is relatively constant in cortical areas <xref ref-type="bibr" rid="pone.0096485-Fares1">[59]</xref> which indicates active regulation, for example, based on spike correlations <xref ref-type="bibr" rid="pone.0096485-Helias1">[132]</xref>, <xref ref-type="bibr" rid="pone.0096485-Deger2">[133]</xref>. Together, these findings support the hypothesis that the number of synapses per neuron pair and the strength of synapses at different dendritic locations might be co-regulated in order to keep the effect of a neuron onto a <italic>connected</italic> neighbor close to a desired constant magnitude. From a functional viewpoint, this perfectly makes sense at least for some functions such as memory storage (or the storage of “random” memory indices <xref ref-type="bibr" rid="pone.0096485-Teyler1">[134]</xref>) where binary synapses are optimal for storing sparse neural activity patterns <xref ref-type="bibr" rid="pone.0096485-Knoblauch5">[46]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch11">[73]</xref>.</p>
<p>Although our definition of effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e517" xlink:type="simple"/></inline-formula> is tailored for the analysis of structural plasticity and memory storage, it shares many features with previous definitions of effective connectivity, e.g., based on “Granger causality” or “transfer entropy” used for analyzing the functional structure of brain networks from measured neural activity <xref ref-type="bibr" rid="pone.0096485-Sporns1">[135]</xref>–<xref ref-type="bibr" rid="pone.0096485-Schreiber1">[137]</xref>. For example, transfer entropy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e518" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Schreiber1">[137]</xref> is a measure of the directional information flow from one brain area <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e519" xlink:type="simple"/></inline-formula> to another area <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e520" xlink:type="simple"/></inline-formula>. In the simplest case the transfer entropy between activities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e521" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e522" xlink:type="simple"/></inline-formula> measured in two brain areas <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e523" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e524" xlink:type="simple"/></inline-formula> is defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e525" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e526" xlink:type="simple"/></inline-formula> denotes the distribution of activity patterns, see Eq. 4 in <xref ref-type="bibr" rid="pone.0096485-Schreiber1">[137]</xref> for details. This measure is very similar to the transinformation-based capacity measure <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e527" xlink:type="simple"/></inline-formula> (see Eqs. 10,14) which depends monotonically on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e528" xlink:type="simple"/></inline-formula> rendering effectual connectivity an equivalent measure of how well an input activity pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e529" xlink:type="simple"/></inline-formula> in one area can reactivate a corresponding target pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e530" xlink:type="simple"/></inline-formula> in another area. In fact, the equivalence of the two measures, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e531" xlink:type="simple"/></inline-formula>, can be shown for a simplified model of neural activity propagation in brain areas <xref ref-type="bibr" rid="pone.0096485-Knoblauch21">[138]</xref>.</p>
<p>Adding to previous results of storage capacity based on counting possible synaptic network configurations <xref ref-type="bibr" rid="pone.0096485-Poirazi1">[28]</xref>–<xref ref-type="bibr" rid="pone.0096485-Chklovskii1">[30]</xref> (cf. Eq. 12), our model proves that simple memory networks of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e532" xlink:type="simple"/></inline-formula> neurons with structural plasticity can indeed store <italic>and</italic> retrieve up to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e533" xlink:type="simple"/></inline-formula> bits per synapse. By comparison, even with real-valued synapses that have an infinite number of states, Hebbian-type weight plasticity without structural plasticity achieves less than one bit per synapse <xref ref-type="bibr" rid="pone.0096485-Gardner1">[72]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch11">[73]</xref>, <xref ref-type="bibr" rid="pone.0096485-Tsodyks1">[139]</xref>, <xref ref-type="bibr" rid="pone.0096485-Palm3">[140]</xref>. Technical adaptations of our model to applications such as information storage and pattern recognition have exhibited advantages in terms of recognition time and memory requirements compared to methods based on traditional weight plasticity <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch6">[53]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch19">[127]</xref>.</p>
<p>Besides increasing storage capacity and energy efficiency of neural networks, our results suggest that structural plasticity is a key element in understanding various memory phenomena. One key prediction of the model under homeostatic maintenance of anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e534" xlink:type="simple"/></inline-formula> are time-dependent gradients in effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e535" xlink:type="simple"/></inline-formula>, such that memories from an earlier time have higher <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e536" xlink:type="simple"/></inline-formula> than memories from a later time. These gradients occur because consolidation of an increasing number of memories will continuously decrease the number of “migratable” (not yet consolidated) synapses and, thus, learning of new memories becomes slower and slower. We have shown that such gradients in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e537" xlink:type="simple"/></inline-formula> can explain both aging effects and the absence of catastrophic forgetting because learning may stop just before the number of stored memories reaches the critical capacity limit <xref ref-type="bibr" rid="pone.0096485-Knoblauch2">[31]</xref>, <xref ref-type="bibr" rid="pone.0096485-French1">[36]</xref>, <xref ref-type="bibr" rid="pone.0096485-Hedden1">[99]</xref>. The same gradients in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e538" xlink:type="simple"/></inline-formula> can also explain Ribot gradients in amnesic patients suffering from lesions of the medio-temporal lobe <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>–<xref ref-type="bibr" rid="pone.0096485-Ribot1">[40]</xref>. Ribot gradients can also be explained by gradients in accumulated consolidation time, assuming unlimited cortico-hippocampal consolidation <xref ref-type="bibr" rid="pone.0096485-Meeter1">[102]</xref>, <xref ref-type="bibr" rid="pone.0096485-Alvarez1">[104]</xref>. However, our model is unique in producing Ribot gradients even for finite consolidation times, in accordance with findings of a time-limited role of the hippocampal system in consolidation <xref ref-type="bibr" rid="pone.0096485-Ji1">[34]</xref>, <xref ref-type="bibr" rid="pone.0096485-Squire1">[38]</xref>, <xref ref-type="bibr" rid="pone.0096485-Ross1">[39]</xref>.</p>
<p>Last, our model is able to bridge different models, describing the spacing effect <xref ref-type="bibr" rid="pone.0096485-Ebbinghaus1">[43]</xref> on psychological <xref ref-type="bibr" rid="pone.0096485-Crowder1">[41]</xref>, <xref ref-type="bibr" rid="pone.0096485-Greene1">[42]</xref>, <xref ref-type="bibr" rid="pone.0096485-Cepeda1">[106]</xref> and molecular levels <xref ref-type="bibr" rid="pone.0096485-Pagani1">[141]</xref> by identifying structural synaptic plasticity as the potential cellular mechanism for spacing effects. The presence of structural plasticity in the adult brain is not only strongly supported by recent experimental evidence. As our results show, it is necessary to achieve high storage capacity and energy efficiency, and inevitably causes spacing effects. Structural plasticity is consistent with psychological theories that explained the spacing effect by encoding variability <xref ref-type="bibr" rid="pone.0096485-Cepeda1">[106]</xref>, <xref ref-type="bibr" rid="pone.0096485-Glenberg1">[108]</xref> but attributes the increased variability for spaced rehearsal to the changing pattern of synaptic connections rather than a changing learning context. While previous models based on delayed synaptic consolidation induced by molecular signaling cascades <xref ref-type="bibr" rid="pone.0096485-Fusi1">[52]</xref>, <xref ref-type="bibr" rid="pone.0096485-Pagani1">[141]</xref> may account for short-term spacing effects on the time-scale of minutes, structural plasticity can also explain long-term spacing effects on the time scale of months to years <xref ref-type="bibr" rid="pone.0096485-Knoblauch14">[110]</xref>, <xref ref-type="bibr" rid="pone.0096485-Cepeda2">[111]</xref>. As the temporal profile of optimal learning depends on parameters of structural plasticity, predictions from theories of structural plasticity will be testable by future experiments that can link memory performance (behavioral data) and structural plasticity (physiological data) in cortical areas where these memories are stored.</p>
</sec><sec id="s5">
<title>Mathematical Analysis</title>
<sec id="s5a">
<title>I Temporal Dynamics of Effectual Connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e539" xlink:type="simple"/></inline-formula></title>
<sec id="s5a1">
<title>I.1 Relation between synapse and network states</title>
    <p>As will be shown, effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e540" xlink:type="simple"/></inline-formula> is a macroscopic network state that can be computed from the (microscopic) states of individual potential synapses. For this we first have to describe the relation between microscopic synaptic state variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e541" xlink:type="simple"/></inline-formula> (Eq. 4) and the corresponding macroscopic connectivity variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e542" xlink:type="simple"/></inline-formula>. As indicated in the main text this relation is non-trivial (see text below Eq. 4), because there may be multiple actual and/or potential synapses between each neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e543" xlink:type="simple"/></inline-formula>, whereas connectivity of a neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e544" xlink:type="simple"/></inline-formula> has to be defined in terms of the presence of <italic>at least</italic> one synapse or the absence of <italic>all</italic> synapses. For example, we could define neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e545" xlink:type="simple"/></inline-formula> to be in state 1 if there is at least one potential synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e546" xlink:type="simple"/></inline-formula> that is in state 1. Similarly, we define that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e547" xlink:type="simple"/></inline-formula> iff <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e548" xlink:type="simple"/></inline-formula> and there is at least one real synapse with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e549" xlink:type="simple"/></inline-formula>. Finally, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e550" xlink:type="simple"/></inline-formula> iff <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e770" xlink:type="simple"/></inline-formula> and there is at least one potential synapse with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e551" xlink:type="simple"/></inline-formula>.</p>
<p>Next we divide neuron pairs into distinct groups, where two neuron pairs are in the same group if they receive identical consolidation signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e552" xlink:type="simple"/></inline-formula>. Then, in analogy to Eq. 4 we can define the (macroscopic) fractions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e553" xlink:type="simple"/></inline-formula> of neuron pairs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e554" xlink:type="simple"/></inline-formula> belonging to group <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e555" xlink:type="simple"/></inline-formula> and being in a certain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e556" xlink:type="simple"/></inline-formula>,<disp-formula id="pone.0096485.e557"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e557" xlink:type="simple"/><label>(17)</label></disp-formula><disp-formula id="pone.0096485.e558"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e558" xlink:type="simple"/><label>(18)</label></disp-formula><disp-formula id="pone.0096485.e559"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e559" xlink:type="simple"/><label>(19)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e560" xlink:type="simple"/></inline-formula> is the fraction of neuron pairs that have a potential synapse and receive consolidation signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e561" xlink:type="simple"/></inline-formula> (typically <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e562" xlink:type="simple"/></inline-formula> if the matrix of potential connections is independent of the stored memories), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e563" xlink:type="simple"/></inline-formula> is the probability that there are exactly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e564" xlink:type="simple"/></inline-formula> potential synapses given that there is at least one potential synapse for neuron pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e565" xlink:type="simple"/></inline-formula>. See ref. <xref ref-type="bibr" rid="pone.0096485-Fares1">[59]</xref> for neuroanatomical estimates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e566" xlink:type="simple"/></inline-formula> in various cortical areas.</p>
<p>From this we can compute the macroscopic state variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e567" xlink:type="simple"/></inline-formula> defined as the fractions of neuron pairs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e568" xlink:type="simple"/></inline-formula> that are in a particular <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e569" xlink:type="simple"/></inline-formula> (where state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e570" xlink:type="simple"/></inline-formula> denotes neuron pairs without any potential synapses) and the various connectivity measures defined in Section 1,<disp-formula id="pone.0096485.e571"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e571" xlink:type="simple"/><label>(20)</label></disp-formula><disp-formula id="pone.0096485.e572"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e572" xlink:type="simple"/><label>(21)</label></disp-formula><disp-formula id="pone.0096485.e573"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e573" xlink:type="simple"/><label>(22)</label></disp-formula><disp-formula id="pone.0096485.e574"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e574" xlink:type="simple"/><label>(23)</label></disp-formula><disp-formula id="pone.0096485.e575"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e575" xlink:type="simple"/><label>(24)</label></disp-formula></p>
<p>By these definitions we are in the position to do microscopic simulations of networks of potential synapses and compute the corresponding connectivity measures (e.g., as we have done for <xref ref-type="fig" rid="pone-0096485-g006">Fig. 6</xref>; see also Section 1).</p>
<p>While we have worked out a general theoretical framework of structural plasticity <xref ref-type="bibr" rid="pone.0096485-Knoblauch22">[142]</xref>, the following analyses will be limited to the much simpler case where a neuron pair has at most one synapse, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e576" xlink:type="simple"/></inline-formula>. Such a setting is justified by experimental findings that there is an active regulation of the total connection strength of the synapses connecting two neurons towards a constant value (see discussion section).</p>
</sec><sec id="s5a2">
<title>I.2 Increase of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e577" xlink:type="simple"/></inline-formula> towards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e578" xlink:type="simple"/></inline-formula></title>
<p>To prove Eq. 11 let us now analyze the temporal dynamics of effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e579" xlink:type="simple"/></inline-formula> under simplified conditions. Specifically, we analyze the increase of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e580" xlink:type="simple"/></inline-formula> towards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e581" xlink:type="simple"/></inline-formula> during consolidation in a <italic>large</italic> network with <italic>constant</italic> anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e582" xlink:type="simple"/></inline-formula> having at most a <italic>single</italic> potential synapse per neuron pair. For this we will assume a simple <italic>constant</italic> consolidation signal, i.e., ongoing rehearsal or replay with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e583" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e584" xlink:type="simple"/></inline-formula>. Constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e585" xlink:type="simple"/></inline-formula> requires a <italic>homeostatic constraint</italic> where generation and elimination of synapses are in approximate balance,<disp-formula id="pone.0096485.e586"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e586" xlink:type="simple"/><label>(25)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e587" xlink:type="simple"/></inline-formula> is as defined in Sect. <xref ref-type="sec" rid="s5">Mathematical Analysis</xref> I.1. Furthermore, we assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e588" xlink:type="simple"/></inline-formula> and sufficiently large neuron populations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e589" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e590" xlink:type="simple"/></inline-formula> with sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e591" xlink:type="simple"/></inline-formula> (cf. <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3</xref>) such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e592" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e593" xlink:type="simple"/></inline-formula> (and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e594" xlink:type="simple"/></inline-formula>) are always close to their expectations. Thus, at any point in time, there exist <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e595" xlink:type="simple"/></inline-formula> synapses distributed over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e596" xlink:type="simple"/></inline-formula> possible locations. Before learning starts, the network has already <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e597" xlink:type="simple"/></inline-formula> consolidated synapses (e.g., due to earlier learned memories) that are unrelated to the novel memories specified by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e598" xlink:type="simple"/></inline-formula>. Thus, initially <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e599" xlink:type="simple"/></inline-formula> (Eq. 24). After the first learning step at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e600" xlink:type="simple"/></inline-formula> all available synapses get potentiated and consolidated, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e601" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e602" xlink:type="simple"/></inline-formula> it is</p>
<p><disp-formula id="pone.0096485.e603"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e603" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e604" xlink:type="simple"/></inline-formula> is the number of new synapses generated at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e605" xlink:type="simple"/></inline-formula> (which equals the number of eliminated synapses), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e606" xlink:type="simple"/></inline-formula> is the number of potential locations to put them, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e607" xlink:type="simple"/></inline-formula> is the probability that a given potential synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e608" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e609" xlink:type="simple"/></inline-formula> is not yet realized and consolidated until time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e610" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e611" xlink:type="simple"/></inline-formula> we can assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e612" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e613" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e614" xlink:type="simple"/></inline-formula> it is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e615" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e616" xlink:type="simple"/></inline-formula>, where the number of unconsolidated synapses, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e617" xlink:type="simple"/></inline-formula>, computes from</p>
<p><disp-formula id="pone.0096485.e618"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e618" xlink:type="simple"/></disp-formula></p>
<p>i.e., all real synapses minus initially consolidated (and not yet deconsolidated) synapses minus the newly consolidated synapses marked by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e619" xlink:type="simple"/></inline-formula>. Thus, the factors in the product become <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e620" xlink:type="simple"/></inline-formula>. Therefore<disp-formula id="pone.0096485.e621"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e621" xlink:type="simple"/></disp-formula></p>
<p>proving Eq. 11. The second approximation in Eq. 11 becomes valid if all product terms are approximately equal, i.e., if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e622" xlink:type="simple"/></inline-formula> (set of novel memories is small) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e623" xlink:type="simple"/></inline-formula> (deconsolidation during the time interval of rehearsal or replay is negligible). Note that here the increase of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e624" xlink:type="simple"/></inline-formula> does not depend on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e625" xlink:type="simple"/></inline-formula> since synapses with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e626" xlink:type="simple"/></inline-formula> that get deconsolidated are immediately (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e627" xlink:type="simple"/></inline-formula>) reconsolidated.</p>
</sec></sec><sec id="s5b">
<title>II Evaluation of Memory Capacity</title>
<sec id="s5b1">
<title>II.1 Asymptotic analysis for one-step retrieval</title>
<p>As argued in Section 6, the storage capacity of structurally plastic networks where memories are stored with effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e628" xlink:type="simple"/></inline-formula> is equivalent to the capacity of a structurally static network with increased anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e629" xlink:type="simple"/></inline-formula> (cf. <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3</xref>). Therefore the following computes the storage capacity for one-step retrieval in the Willshaw network without any structural plasticity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e630" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e631" xlink:type="simple"/></inline-formula>; see Section 3 and <xref ref-type="fig" rid="pone-0096485-g003">Fig. 3A</xref>) where synaptic weights are given by Eq. 5.</p>
<p>For the following approximate asymptotic analysis we use several simplifications. First, Address and content memory patterns <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e632" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e633" xlink:type="simple"/></inline-formula> are binary random vectors of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e634" xlink:type="simple"/></inline-formula> each having <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e635" xlink:type="simple"/></inline-formula> active units (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e636" xlink:type="simple"/></inline-formula> is the size of a Hebbian cell assembly representing the memory in population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e637" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e638" xlink:type="simple"/></inline-formula>). Second, the The query pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e639" xlink:type="simple"/></inline-formula> has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e640" xlink:type="simple"/></inline-formula> randomly chosen “correct” one-entries of an address pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e641" xlink:type="simple"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e642" xlink:type="simple"/></inline-formula>) but no additional “false” one-entries (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e643" xlink:type="simple"/></inline-formula>). Third, as previously suggested <xref ref-type="bibr" rid="pone.0096485-Knoblauch12">[78]</xref>, <xref ref-type="bibr" rid="pone.0096485-Buckingham2">[143]</xref>–<xref ref-type="bibr" rid="pone.0096485-Bosch1">[145]</xref>, we assume that each neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e644" xlink:type="simple"/></inline-formula> can optimize its firing threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e645" xlink:type="simple"/></inline-formula> according to the number of connected active “correct” query neurons, that is, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e646" xlink:type="simple"/></inline-formula>.</p>
<p>Let us first estimate error probabilities after storing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e647" xlink:type="simple"/></inline-formula> associations. We have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e648" xlink:type="simple"/></inline-formula> due to the assumptions of optimal threshold control and zero add noise (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e649" xlink:type="simple"/></inline-formula>). To see this note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e650" xlink:type="simple"/></inline-formula> for any actual synapse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e651" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e652" xlink:type="simple"/></inline-formula> (which implies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e653" xlink:type="simple"/></inline-formula> due to the zero add noise assumption) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e654" xlink:type="simple"/></inline-formula>. Therefore the dendritic potential <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e655" xlink:type="simple"/></inline-formula> will equal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e656" xlink:type="simple"/></inline-formula> and thus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e657" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e658" xlink:type="simple"/></inline-formula>. By contrast, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e659" xlink:type="simple"/></inline-formula> depends on the probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e660" xlink:type="simple"/></inline-formula> that a given synapse is potentiated (see Eqs. 4, 5). After storing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e661" xlink:type="simple"/></inline-formula> memory associations we have<disp-formula id="pone.0096485.e662"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e662" xlink:type="simple"/><label>(26)</label></disp-formula></p>
<p>This follows from the fact that a synapse is potentiated with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e663" xlink:type="simple"/></inline-formula> during presentation of a single memory. After presentation of all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e664" xlink:type="simple"/></inline-formula> memories, the synapse will therefore still be in state 0 (unpotentiated) with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e665" xlink:type="simple"/></inline-formula>. The state probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e666" xlink:type="simple"/></inline-formula> has been called “memory load” or “matrix load” in previous works <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref> because, for fully connected networks, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e667" xlink:type="simple"/></inline-formula> corresponds to the fraction of one-entries in the weight matrix. From Eq. 26 we obtain that a “low neuron” <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e668" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e669" xlink:type="simple"/></inline-formula> may fire with error probability<disp-formula id="pone.0096485.e670"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e670" xlink:type="simple"/><label>(27)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e671" xlink:type="simple"/></inline-formula> is the binomial probability. Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e672" xlink:type="simple"/></inline-formula> follows a binomial distribution such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e673" xlink:type="simple"/></inline-formula>. Thus, the sum in Eq. 27 averages over all possible values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e674" xlink:type="simple"/></inline-formula> where the error probability given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e675" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e676" xlink:type="simple"/></inline-formula>. This is because an error requires that all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e677" xlink:type="simple"/></inline-formula> relevant synapses of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e678" xlink:type="simple"/></inline-formula> are potentiated, where the probability of one synapse being potentiated is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e679" xlink:type="simple"/></inline-formula>. An exact analysis shows that this binomial approximation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e680" xlink:type="simple"/></inline-formula> becomes exact in the limit of large networks and sufficiently small cell assemblies with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e681" xlink:type="simple"/></inline-formula> (see <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref>; see also Section II.2).</p>
<p>Now we can compute the storage capacity by limiting output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e682" xlink:type="simple"/></inline-formula> (Eq. 7) by some constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e683" xlink:type="simple"/></inline-formula>. Thus, we have to solve<disp-formula id="pone.0096485.e684"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e684" xlink:type="simple"/><label>(28)</label></disp-formula></p>
<p>for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e685" xlink:type="simple"/></inline-formula> which gives the maximal matrix load <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e686" xlink:type="simple"/></inline-formula> of Eq. 13 that satisfies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e687" xlink:type="simple"/></inline-formula>. With this, solving Eq. 26 for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e688" xlink:type="simple"/></inline-formula> yields the pattern capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e689" xlink:type="simple"/></inline-formula> of Eq. 13. For small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e690" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e691" xlink:type="simple"/></inline-formula> it is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e692" xlink:type="simple"/></inline-formula> and with Eq. 10 it follows the weight capacity Eq. 14.</p>
<p>For networks with structural plasticity Eq. 13 is still valid but effectual connectivity will be typically larger than anatomical connectivity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e693" xlink:type="simple"/></inline-formula>. As silent synapses are functionally irrelevant and can be pruned (but see the remarks below) we can compute total storage capacity in bits per synapse from renormalizing Eq. 14. Thus, dividing the totally stored information by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e694" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e695" xlink:type="simple"/></inline-formula> yields<disp-formula id="pone.0096485.e696"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e696" xlink:type="simple"/><label>(29)</label></disp-formula></p>
<p>For large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e697" xlink:type="simple"/></inline-formula> and small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e698" xlink:type="simple"/></inline-formula> the total storage capacity per synapse diverges with network size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e699" xlink:type="simple"/></inline-formula>,<disp-formula id="pone.0096485.e700"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e700" xlink:type="simple"/><label>(30)</label></disp-formula></p>
<p>Together with Eq. 11 this proves that in networks with structural plasticity, high potential connectivity, and sufficiently small cell assembly size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e701" xlink:type="simple"/></inline-formula>, it is possible to come close to the information theoretic capacity bound (see Eq. 12).</p>
<p>One limitation of this analysis is the assumption of an optimal threshold control. In fact, an optimal threshold control as presumed above would actually require silent synapses in order to compute spike thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e702" xlink:type="simple"/></inline-formula> in incompletely connected <italic>excitatory</italic> networks with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e703" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Buckingham2">[143]</xref>, <xref ref-type="bibr" rid="pone.0096485-Graham1">[144]</xref> (so they should not be pruned). Therefore we will use the resulting expressions for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e704" xlink:type="simple"/></inline-formula> merely for approximating the storage capacity for a more conservative threshold control (see next section). Nevertheless the results are still asymptotically correct for high effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e705" xlink:type="simple"/></inline-formula> because then the optimal spike threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e706" xlink:type="simple"/></inline-formula> gets independent of remaining silent synapses <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>. Corresponding results hold true also for <italic>inhibitory</italic> network models where an optimal spike threshold control could easily be realized (including pruning of silent synapses) because it is independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e707" xlink:type="simple"/></inline-formula> for any <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e708" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0096485-Knoblauch12">[78]</xref>. This suggests that structural plasticity could store information in inhibitory networks even more efficiently than in excitatory networks (cf. <xref ref-type="bibr" rid="pone.0096485-Schuemann1">[13]</xref>).</p>
</sec><sec id="s5b2">
<title>II.2 Numerical evaluation for finite networks</title>
<p>The analysis of the previous section is asymptotically correct for large networks (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e709" xlink:type="simple"/></inline-formula>), large connectivity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e710" xlink:type="simple"/></inline-formula>), and sparse activity (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e711" xlink:type="simple"/></inline-formula>) <xref ref-type="bibr" rid="pone.0096485-Knoblauch1">[16]</xref>, <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref>. It is also useful to get an overview about the qualitative effect of increasing effectual connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e712" xlink:type="simple"/></inline-formula> and its relation to the memory load <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e713" xlink:type="simple"/></inline-formula>. To compute storage capacity of finite networks with large activity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e714" xlink:type="simple"/></inline-formula> and low connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e715" xlink:type="simple"/></inline-formula> it is possible to do an exact analysis by generalizing the approach of <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref>. However, as such an approach would be computationally very expensive, the following develops a Gaussian approximation of dendritic potential distributions, which can reduce reduce computation time by several orders of magnitude. For example, in some preliminary experiments we have evaluated the exact storage capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e716" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e717" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e718" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e719" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e720" xlink:type="simple"/></inline-formula> which took about 57 h on a single core of an 2.2 GHz AMD Opteron compute server. By comparison, using the Gaussian approximation developed in this section yields <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e721" xlink:type="simple"/></inline-formula>, quite close to the exact value, but took only 2.5 sec computing time.</p>
<p>Let us first consider the Willshaw-Palm distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e722" xlink:type="simple"/></inline-formula> defined as the exact probability that a content neuron's dendritic potential <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e723" xlink:type="simple"/></inline-formula> equals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e724" xlink:type="simple"/></inline-formula> given that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e725" xlink:type="simple"/></inline-formula> random memories are stored in a heteroassociative Willshaw-Palm network with size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e726" xlink:type="simple"/></inline-formula>, anatomical connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e727" xlink:type="simple"/></inline-formula>, and (constant) activity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e728" xlink:type="simple"/></inline-formula> if stimulating with a random pattern (unrelated to the stored memories) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e729" xlink:type="simple"/></inline-formula> active units. From Eq. 3.22 in <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref> we obtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e730" xlink:type="simple"/></inline-formula> for the special case of fully connected networks (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e731" xlink:type="simple"/></inline-formula>),<disp-formula id="pone.0096485.e732"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e732" xlink:type="simple"/><label>(31)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e733" xlink:type="simple"/></inline-formula>. In network with general connectivity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e734" xlink:type="simple"/></inline-formula> each of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e735" xlink:type="simple"/></inline-formula> active input units is connected to neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e736" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e737" xlink:type="simple"/></inline-formula>. Therefore the number of connected neurons is binomially distributed and</p>
<p><disp-formula id="pone.0096485.e738"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e738" xlink:type="simple"/><label>(32)</label></disp-formula>We can now determine the first two moments of this distribution, The mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e739" xlink:type="simple"/></inline-formula> can easily be computed from the memory load Eq. 26,<disp-formula id="pone.0096485.e740"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e740" xlink:type="simple"/><label>(33)</label></disp-formula>and the variance</p>
<p><disp-formula id="pone.0096485.e741"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e741" xlink:type="simple"/><label>(34)</label></disp-formula><disp-formula id="pone.0096485.e742"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e742" xlink:type="simple"/><label>(35)</label></disp-formula><disp-formula id="pone.0096485.e743"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e743" xlink:type="simple"/><label>(36)</label></disp-formula></p>
<p>can be computed from the corresponding variance of a fully connected network which is well approximated by (see Eq. 4.25 in <xref ref-type="bibr" rid="pone.0096485-Knoblauch20">[129]</xref>)<disp-formula id="pone.0096485.e744"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e744" xlink:type="simple"/><label>(37)</label></disp-formula></p>
<p>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e745" xlink:type="simple"/></inline-formula> (cf. Eq. 26) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e746" xlink:type="simple"/></inline-formula>. Therefore the variance of the diluted network is well approximated by<disp-formula id="pone.0096485.e747"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e747" xlink:type="simple"/><label>(38)</label></disp-formula></p>
<p>From these results we can easily compute mean values and variances of the dendritic potential distributions of high and low units. Here high units are neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e748" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e749" xlink:type="simple"/></inline-formula>, i.e., neurons that should be activated during retrieval. Similarly, low units are neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e750" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e751" xlink:type="simple"/></inline-formula>. Thus, if the query pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e752" xlink:type="simple"/></inline-formula> has exactly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e753" xlink:type="simple"/></inline-formula> correct units from an address memory <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e754" xlink:type="simple"/></inline-formula> and additionally <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e755" xlink:type="simple"/></inline-formula> randomly chosen false units (not active in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e756" xlink:type="simple"/></inline-formula>) then the mean and variance of a low unit's dendritic potential will be<disp-formula id="pone.0096485.e757"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e757" xlink:type="simple"/><label>(39)</label></disp-formula><disp-formula id="pone.0096485.e758"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e758" xlink:type="simple"/><label>(40)</label></disp-formula>and mean and variance of a high unit's dendritic potential will be</p>
<p><disp-formula id="pone.0096485.e759"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e759" xlink:type="simple"/><label>(41)</label></disp-formula><disp-formula id="pone.0096485.e760"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0096485.e760" xlink:type="simple"/><label>(42)</label></disp-formula></p>
<p>Assuming Gaussian distributions we can compute a globally optimal firing threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e761" xlink:type="simple"/></inline-formula> that minimizes output noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e762" xlink:type="simple"/></inline-formula> by applying some standard methods (e.g., see appendix D in <xref ref-type="bibr" rid="pone.0096485-Knoblauch5">[46]</xref>). Then we can determine pattern capacity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e763" xlink:type="simple"/></inline-formula> by doing a binary search to efficiently find the maximal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e764" xlink:type="simple"/></inline-formula> that satisfies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e765" xlink:type="simple"/></inline-formula>. Finally, we can determine <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e766" xlink:type="simple"/></inline-formula> from Eq. 10 and thus also <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e767" xlink:type="simple"/></inline-formula> from Eq. 26 and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e768" xlink:type="simple"/></inline-formula>. Corresponding data for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0096485.e769" xlink:type="simple"/></inline-formula> is shown in <xref ref-type="fig" rid="pone-0096485-g005">Fig. 5</xref>.</p>
</sec></sec></sec></body>
<back>
<ack>
<p>We thank Günther Palm and Marc-Oliver Gewaltig for many fruitful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0096485-Hebb1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Hebb D (1949) The organization of behavior. A neuropsychological theory. New York: Wiley.</mixed-citation>
</ref>
<ref id="pone.0096485-Bliss1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bliss</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Collingridge</surname><given-names>G</given-names></name> (<year>1993</year>) <article-title>A synaptic model of memory: long-term potentiation in the hippocampus</article-title>. <source>Nature</source> <volume>361</volume>: <fpage>31</fpage>–<lpage>39</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Frey1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frey</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>R</given-names></name> (<year>1997</year>) <article-title>Synaptic tagging and long-term potentiation</article-title>. <source>Nature</source> <volume>385</volume>: <fpage>533</fpage>–<lpage>536</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Paulsen1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paulsen</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name> (<year>2000</year>) <article-title>Natural patterns of activity and long-term synaptic plasticity</article-title>. <source>Current Opinion in Neurobiology</source> <volume>10</volume>: <fpage>172</fpage>–<lpage>179</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Song1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name> (<year>2000</year>) <article-title>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</article-title>. <source>Nature Neuroscience</source> <volume>3(9)</volume>: <fpage>919</fpage>–<lpage>926</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Raisman1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raisman</surname><given-names>G</given-names></name> (<year>1969</year>) <article-title>Neuronal plasticity in the septal nuclei of the adult rat</article-title>. <source>Brain Research</source> <volume>14</volume>: <fpage>25</fpage>–<lpage>48</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Engert1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Engert</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bonhoeffer</surname><given-names>T</given-names></name> (<year>1999</year>) <article-title>Dendritic spine changes associated with hippocampal long-term synaptic plasticity</article-title>. <source>Nature</source> <volume>399</volume>: <fpage>66</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Witte1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Witte</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Stier</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Cline</surname><given-names>H</given-names></name> (<year>1996</year>) <article-title>In vivo observations of timecourse and distribution of morphological dynamics in Xenopus retinotectal axon arbors</article-title>. <source>Journal of Neurobiology</source> <volume>31</volume>: <fpage>219</fpage>–<lpage>234</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Woolley1"><label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">Woolley C (1999) Structural plasticity of dendrites. In: Stuart G, Spruston N, Häusser M, editors, Dendrites., Oxford, UK: Oxford University Press. pp. 339–364.</mixed-citation>
</ref>
<ref id="pone.0096485-Trachtenberg1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trachtenberg</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Knott</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Feng</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sanes</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Long-term in vivo imaging of experience-dependent synaptic plasticity in adult cortex</article-title>. <source>Nature</source> <volume>420</volume>: <fpage>788</fpage>–<lpage>794</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Lamprecht1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lamprecht</surname><given-names>R</given-names></name>, <name name-style="western"><surname>LeDoux</surname><given-names>J</given-names></name> (<year>2004</year>) <article-title>Structural plasticity and memory</article-title>. <source>Nature Reviews Neuroscience</source> <volume>5</volume>: <fpage>45</fpage>–<lpage>54</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-DePaola1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DePaola</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Holtmaat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Knott</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wilbrecht</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Cell type-specific structural plasticity of axonal branches and boutons in the adult neocortex</article-title>. <source>Neuron</source> <volume>49</volume>: <fpage>861</fpage>–<lpage>875</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Schuemann1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schuemann</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Klawiter</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bonhoeffer</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Wierenga</surname><given-names>C</given-names></name> (<year>2013</year>) <article-title>Structural plasticity of GABAergic axons is regulated by network activity and GABA-A receptor activation</article-title>. <source>Frontiers in Neural Circuits 7</source> <volume>113</volume>: <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Huttenlocher1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huttenlocher</surname><given-names>P</given-names></name>, <name name-style="western"><surname>De Courten</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Garey</surname><given-names>L</given-names></name>, <name name-style="western"><surname>van der Loos</surname><given-names>H</given-names></name> (<year>1982</year>) <article-title>Synaptogenesis in human visual cortex - evidence for synapse elimination during normal development</article-title>. <source>Neuroscience Letters</source> <volume>33</volume>: <fpage>247</fpage>–<lpage>252</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Chechik1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chechik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Meilijson</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Ruppin</surname><given-names>E</given-names></name> (<year>1998</year>) <article-title>Synaptic pruning in development: A computational account</article-title>. <source>Neural Computation</source> <volume>10(7)</volume>: <fpage>1759</fpage>–<lpage>1777</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>F</given-names></name> (<year>2010</year>) <article-title>Memory capacities for synaptic and structural plasticity</article-title>. <source>Neural Computation</source> <volume>22(2)</volume>: <fpage>289</fpage>–<lpage>341</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Keck1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keck</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Mrsic-Flogel</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Vaz Afonso</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Eysel</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Bonhoeffer</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Massive restructuring of neuronal circuits during functional reorganization of adult visual cortex</article-title>. <source>Nature Neuroscience</source> <volume>11(10)</volume>: <fpage>1162</fpage>–<lpage>1167</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Butz1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>van Ooyen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wörgötter</surname><given-names>F</given-names></name> (<year>2009</year>) <article-title>A model for cortical rewiring following deafferentation and focal stroke</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>3</volume>: <fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Yang1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Pan</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Gan</surname><given-names>WB</given-names></name> (<year>2009</year>) <article-title>Stably maintained dendritic spines are associated with lifelong memories</article-title>. <source>Nature</source> <volume>462</volume>: <fpage>920</fpage>–<lpage>924</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Butz2"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wörgötter</surname><given-names>F</given-names></name>, <name name-style="western"><surname>van Ooyen</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Activity-dependent structural plasticity</article-title>. <source>Brain Research Reviews</source> <volume>60(2)</volume>: <fpage>287</fpage>–<lpage>305</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Holtmaat1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holtmaat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Svoboda</surname><given-names>K</given-names></name> (<year>2009</year>) <article-title>Experience-dependent structural synaptic plasticity in the mammalian brain</article-title>. <source>Nature Reviews Neuroscience</source> <volume>10</volume>: <fpage>647</fpage>–<lpage>658</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Leuner1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leuner</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Gould</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Structural plasticity and hippocampal function</article-title>. <source>Annual Review of Psychology</source> <volume>61</volume>: <fpage>111</fpage>–<lpage>140</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Fu1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fu</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Zuo</surname><given-names>Y</given-names></name> (<year>2011</year>) <article-title>Experience-dependent structural plasticity in the cortex</article-title>. <source>Trends in Neurosciences</source> <volume>34(4)</volume>: <fpage>177</fpage>–<lpage>187</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Braitenberg1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Braitenberg V, Schüz A (1991) Anatomy of the cortex. Statistics and geometry. Berlin: Springer-Verlag.</mixed-citation>
</ref>
<ref id="pone.0096485-Hellwig1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hellwig</surname><given-names>B</given-names></name> (<year>2000</year>) <article-title>A quantitative analysis of the local connectivity between pyramidal neurons in layers 2/3 of the rat visual cortex</article-title>. <source>Biological Cybernetics</source> <volume>82</volume>: <fpage>111</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Willshaw1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willshaw</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Buneman</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Longuet-Higgins</surname><given-names>H</given-names></name> (<year>1969</year>) <article-title>Non-holographic associative memory</article-title>. <source>Nature</source> <volume>222</volume>: <fpage>960</fpage>–<lpage>962</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Hopfield1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname><given-names>J</given-names></name> (<year>1982</year>) <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the National Academy of Science, USA</source> <volume>79</volume>: <fpage>2554</fpage>–<lpage>2558</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Poirazi1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poirazi</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Mel</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Impact of active dendrites and structural plasticity on the memory capacity of neural tissue</article-title>. <source>Neuron</source> <volume>29</volume>: <fpage>779</fpage>–<lpage>796</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Stepanyants1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stepanyants</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hof</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2002</year>) <article-title>Geometry and structural plasticity of synaptic connectivity</article-title>. <source>Neuron</source> <volume>34</volume>: <fpage>275</fpage>–<lpage>288</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Chklovskii1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Mel</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Svoboda</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>Cortical rewiring and information storage</article-title>. <source>Nature</source> <volume>431</volume>: <fpage>782</fpage>–<lpage>788</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch2"><label>31</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2009) The role of structural plasticity and synaptic consolidation for memory and amnesia in a model of cortico-hippocampal interplay. In: Mayor J, Ruh N, Plunkett K, editors, Connectionist Models of Behavior and Cognition II: Proceedings of the 11th Neural Computation and Psychology Workshop. Singapore: World Scientific Publishing, pp. 79–90.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch3"><label>32</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2009) Structural plasticity, cortical memory, and the spacing effect. BMC Neuroscience (Suppl 1): O16.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch4"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2008) On structural plasticity in neural associative networks. HRI-EU Report 08-04, Honda Research Institute Europe GmbH, D-63073 Offenbach/Main, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Ji1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ji</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Coordinated memory replay in the visual cortex and hippocampus during sleep</article-title>. <source>Nature Neuroscience</source> <volume>10(1)</volume>: <fpage>100</fpage>–<lpage>107</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-McClelland1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McClelland</surname><given-names>J</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>O'Reilly</surname><given-names>R</given-names></name> (<year>1995</year>) <article-title>Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychological Review</source> <volume>102(3)</volume>: <fpage>419</fpage>–<lpage>457</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-French1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>French</surname><given-names>R</given-names></name> (<year>1999</year>) <article-title>Catastrophic forgetting in connectionist networks: causes, consequences and solutions</article-title>. <source>Trends in Cognitive Sciences</source> <volume>3(4)</volume>: <fpage>128</fpage>–<lpage>135</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Grossberg1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name> (<year>1987</year>) <article-title>Competitive Learning: From interactive activation to adaptive resonance</article-title>. <source>Cognitive Science</source> <volume>11</volume>: <fpage>23</fpage>–<lpage>63</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Squire1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Squire</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bayley</surname><given-names>P</given-names></name> (<year>2007</year>) <article-title>The neuroscience of remote memory</article-title>. <source>Current Opinion in Neurobiology</source> <volume>17</volume>: <fpage>185</fpage>–<lpage>196</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Ross1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Dynamics of hippocampal and cortical activation during consolidation of a nonspatial memory</article-title>. <source>The Journal of Neuroscience</source> <volume>26(18)</volume>: <fpage>4852</fpage>–<lpage>4859</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Ribot1"><label>40</label>
<mixed-citation publication-type="other" xlink:type="simple">Ribot T (1881) Les maladies de la memoire. Paris: Germer Baillare.</mixed-citation>
</ref>
<ref id="pone.0096485-Crowder1"><label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Crowder R (1976) Principles of learning and memory. Oxford: Lawrence Erlbaum.</mixed-citation>
</ref>
<ref id="pone.0096485-Greene1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greene</surname><given-names>R</given-names></name> (<year>1989</year>) <article-title>Spacing effects in memory: evidence for a two-process account</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source> <volume>15(3)</volume>: <fpage>371</fpage>–<lpage>377</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Ebbinghaus1"><label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Ebbinghaus H (1885) Über das Gedächtnis: Untersuchungen zur experimentellen Psychologie. Leipzig: Duncker &amp; Humblot.</mixed-citation>
</ref>
<ref id="pone.0096485-Palm1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>1980</year>) <article-title>On associative memories</article-title>. <source>Biological Cybernetics</source> <volume>36</volume>: <fpage>19</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Palm2"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>1991</year>) <article-title>Memory capacities of local rules for synaptic modification. A comparative review</article-title>. <source>Concepts in Neuroscience</source> <volume>2</volume>: <fpage>97</fpage>–<lpage>128</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch5"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Neural associative memory with optimal bayesian learning</article-title>. <source>Neural Computation</source> <volume>23(6)</volume>: <fpage>1393</fpage>–<lpage>1451</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Lennie1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name> (<year>2003</year>) <article-title>The cost of cortical computation</article-title>. <source>Current Biology</source> <volume>13</volume>: <fpage>493</fpage>–<lpage>497</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Laughlin1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name> (<year>2003</year>) <article-title>Communication in neuronal networks</article-title>. <source>Science</source> <volume>301</volume>: <fpage>1870</fpage>–<lpage>1874</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Attwell1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attwell</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>S</given-names></name> (<year>2001</year>) <article-title>An energy budget for signaling in the grey matter of the brain</article-title>. <source>Journal of Cerebral Blood Flow and Metabolism</source> <volume>21</volume>: <fpage>1133</fpage>–<lpage>1145</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Butz3"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>van Ooyen</surname><given-names>A</given-names></name> (<year>2013</year>) <article-title>A simple rule for dendritic spine and axonal bouton formation can account for cortical reorganization after focal retinal lesions</article-title>. <source>PLOS Computational Biology</source> <volume>9(10)</volume>: <fpage>e1003259</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Elston1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elston</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Oga</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fujita</surname><given-names>I</given-names></name> (<year>2009</year>) <article-title>Spinogenesis and pruning scales across functional hierarchies</article-title>. <source>The Journal of Neuroscience</source> <volume>29(10)</volume>: <fpage>3271</fpage>–<lpage>3275</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Fusi1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Drew</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name> (<year>2005</year>) <article-title>Cascade models of synaptically stored memories</article-title>. <source>Neuron</source> <volume>45</volume>: <fpage>599</fpage>–<lpage>611</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch6"><label>53</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2010) Zip nets: Efficient associative computation with binary synapses. In: Proceedings of the International Joint Conference on Neural Networks (IJCNN). Barcelona, Spain: IEEE World Congress on Computational Intelligence (WCCI), pp. 4271–4278.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch7"><label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2009) Zip nets: Neural associative networks with non-linear learning. HRI-EU Report 09-03, Honda Research Institute Europe GmbH, D-63073 Offenbach/Main, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch8"><label>55</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2003) Synchronization and pattern separation in spiking associative memory and visual cortical areas. PhD thesis, Department of Neural Information Processing, University of Ulm, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Deuchars1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deuchars</surname><given-names>J</given-names></name>, <name name-style="western"><surname>West</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Thomson</surname><given-names>A</given-names></name> (<year>1994</year>) <article-title>Relationships between morphology and physiology of pyramid-pyramid single axon connections in rat neocortex in vitro</article-title>. <source>Journal of Physiology</source> <volume>478(3)</volume>: <fpage>423</fpage>–<lpage>435</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Markram1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Lübke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Frotscher</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Roth</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name> (<year>1997</year>) <article-title>Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex</article-title>. <source>Journal of Physiology 500(Pt</source> <volume>2)</volume>: <fpage>409</fpage>–<lpage>440</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-AngusSilver1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Angus Silver</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Lübke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Feldmeyer</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>High-probability uniquantal transmission at excitatory synapses in barrel cortex</article-title>. <source>Science</source> <volume>302(5652)</volume>: <fpage>1981</fpage>–<lpage>1984</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Fares1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fares</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Stepanyants</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Cooperative synapse formation in the neocortex</article-title>. <source>Proceedings of the National Academy of Sciences, USA</source> <volume>106(38)</volume>: <fpage>16463</fpage>–<lpage>16468</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Deger1"><label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Deger M, Helias M, Rotter S, Diesmann M (2011) Cooperative structural plasticity based on pre- and postsynaptic spike timing. Frontiers in Computational Neuroscience Conference Abstract: BC11: Computational Neuroscience &amp; Neurotechnology Bernstein Conference &amp; Neurex Annual Meeting.</mixed-citation>
</ref>
<ref id="pone.0096485-London1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>London</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>I</given-names></name> (<year>2001</year>) <article-title>Synaptic scaling in vitro and in vivo</article-title>. <source>Nature Neuroscience</source> <volume>4(9)</volume>: <fpage>853</fpage>–<lpage>854</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Steinbuch1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steinbuch</surname><given-names>K</given-names></name> (<year>1961</year>) <article-title>Die Lernmatrix</article-title>. <source>Kybernetik</source> <volume>1</volume>: <fpage>36</fpage>–<lpage>45</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Schwenker1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwenker</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>1996</year>) <article-title>Iterative retrieval of sparsely coded associative memory patterns</article-title>. <source>Neural Networks</source> <volume>9</volume>: <fpage>445</fpage>–<lpage>455</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch9"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>2001</year>) <article-title>Pattern separation and synchronization in spiking associative memories and visual areas</article-title>. <source>Neural Networks</source> <volume>14</volume>: <fpage>763</fpage>–<lpage>780</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch10"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>2002</year>) <article-title>Scene segmentation by spike synchronization in reciprocally connected visual areas. II. Global assemblies and synchronization on larger space and time scales</article-title>. <source>Biological Cybernetics</source> <volume>87(3)</volume>: <fpage>168</fpage>–<lpage>184</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Sommer1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sommer</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>1999</year>) <article-title>Improved bidirectional retrieval of sparse patterns stored by Hebbian learning</article-title>. <source>Neural Networks</source> <volume>12</volume>: <fpage>281</fpage>–<lpage>297</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Kosko1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kosko</surname><given-names>B</given-names></name> (<year>1988</year>) <article-title>Bidirectional associative memories</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics</source> <volume>18</volume>: <fpage>49</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Xu1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xu</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Perlik</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Tobin</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zweig</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Rapid formation and selective stabilization of synapses for enduring motor memories</article-title>. <source>Nature</source> <volume>462</volume>: <fpage>915</fpage>–<lpage>919</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Shannon1"><label>69</label>
<mixed-citation publication-type="other" xlink:type="simple">Shannon C, Weaver W (1949) The mathematical theory of communication. Urbana/Chicago: University of Illinois Press.</mixed-citation>
</ref>
<ref id="pone.0096485-Hertz1"><label>70</label>
<mixed-citation publication-type="other" xlink:type="simple">Hertz J, Krogh A, Palmer R (1991) Introduction to the theory of neural computation. Redwood City: Addison-Wesley.</mixed-citation>
</ref>
<ref id="pone.0096485-Lansner1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lansner</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Associative memory models: from the cell-assembly theory to biophysically detailed cortex simulations</article-title>. <source>Trends in Neurosciences</source> <volume>32(3)</volume>: <fpage>178</fpage>–<lpage>186</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Gardner1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Derrida</surname><given-names>B</given-names></name> (<year>1988</year>) <article-title>Optimal storage properties of neural network models</article-title>. <source>JPhys A: Math Gen</source> <volume>21</volume>: <fpage>271</fpage>–<lpage>284</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch11"><label>73</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2010) Optimal synaptic learning in non-linear associative memory. In: Proceedings of the International Joint Conference on Neural Networks (IJCNN). Barcelona, Spain: IEEE World Congress on Computational Intelligence (WCCI), pp. 3205–3211.</mixed-citation>
</ref>
<ref id="pone.0096485-Petersen1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petersen</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Malenka</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Nicoll</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hopfield</surname><given-names>J</given-names></name> (<year>1998</year>) <article-title>All-or-none potentiation at CA3-CA1 synapses</article-title>. <source>Proceedings of the National Academy of Science, USA</source> <volume>95</volume>: <fpage>4732</fpage>–<lpage>4737</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Montgomery1"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Montgomery</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Madison</surname><given-names>D</given-names></name> (<year>2004</year>) <article-title>Discrete synaptic states define a major mechanism of synapse plasticity</article-title>. <source>Trends in Neuroscience</source> <volume>27(12)</volume>: <fpage>744</fpage>–<lpage>750</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-OConnor1"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Connor</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wittenberg</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>SH</given-names></name> (<year>2005</year>) <article-title>Graded bidirectional synaptic plasticity is composed of switch-like unitary events</article-title>. <source>Proceedings of the National Academy of Sciences, USA</source> <volume>102(27)</volume>: <fpage>9679</fpage>–<lpage>9684</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Huttenlocher2"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huttenlocher</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Dabholkar</surname><given-names>A</given-names></name> (<year>1997</year>) <article-title>Regional differences in synaptogenesis in human cerebral cortex</article-title>. <source>Journal of Comparative Neurology</source> <volume>387</volume>: <fpage>167</fpage>–<lpage>178</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch12"><label>78</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2007) On the computational benefits of inhibitory neural associative networks. HRI-EU Report 07-05, Honda Research Institute Europe GmbH, D-63073 Offenbach/Main, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch13"><label>79</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2013) Efficient associative computation with discrete synapses and structural plasticity in preparation.</mixed-citation>
</ref>
<ref id="pone.0096485-Huttenlocher3"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huttenlocher</surname><given-names>P</given-names></name> (<year>1979</year>) <article-title>Synaptic density in human frontal cortex - developmental changes and effects of aging</article-title>. <source>Brain Research</source> <volume>163(2)</volume>: <fpage>195</fpage>–<lpage>205</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Bourgeois1"><label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bourgeois</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rakic</surname><given-names>P</given-names></name> (<year>1993</year>) <article-title>Changes of synaptic density in the primary visual cortex of the macaque monkey from fetal to adult stage</article-title>. <source>The Journal of Neuroscience</source> <volume>73(7)</volume>: <fpage>2801</fpage>–<lpage>2820</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Waydo1"><label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waydo</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kraskov</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Quiroga</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Fried</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>2006</year>) <article-title>Sparse representation in the human medial temporal lobe</article-title>. <source>Journal of Neuroscience</source> <volume>26(40)</volume>: <fpage>10232</fpage>–<lpage>10234</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Freedman1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freedman</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Riesenhuber</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>E</given-names></name> (<year>2006</year>) <article-title>Experience-dependent sharpening of visual shape selectivity in inferior temporal cortex</article-title>. <source>Cerebral Cortex</source> <volume>16(11)</volume>: <fpage>1631</fpage>–<lpage>1644</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-McNamara1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNamara</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Buccino</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Menz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gläscher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wolbers</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Neural dynamics of learning sound-action associations</article-title>. <source>PLoS ONE</source> <volume>3(12)</volume>: <fpage>e3845</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Weinberger1"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weinberger</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Miasnikov</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Sensory memory consolidation observed: Increased specificity of detail over days</article-title>. <source>Neurobiology of Learning and Memory</source> <volume>91</volume>: <fpage>273</fpage>–<lpage>286</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Latham1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Latham</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Nirenberg</surname><given-names>S</given-names></name> (<year>2004</year>) <article-title>Computing and stability in cortical networks</article-title>. <source>Neural Computation</source> <volume>16(7)</volume>: <fpage>1385</fpage>–<lpage>1412</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Aviel1"><label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aviel</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Horn</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Memory capacity of balanced networks</article-title>. <source>Neural Computation</source> <volume>17</volume>: <fpage>691</fpage>–<lpage>713</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Grossberg2"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name> (<year>1980</year>) <article-title>How does a brain build a cognitive code</article-title>. <source>Psychological Review</source> <volume>87</volume>: <fpage>1</fpage>–<lpage>51</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-McCloskey1"><label>89</label>
<mixed-citation publication-type="other" xlink:type="simple">McCloskey M, Cohen N (1989) Catastrophic interference in connectionist networks: The sequential learning problem. In: Bower G, editor, Psychology of Learning and Motivation: Vol. 24, New York: Academic Press. 109–164.</mixed-citation>
</ref>
<ref id="pone.0096485-Carpenter1"><label>90</label>
<mixed-citation publication-type="other" xlink:type="simple">Carpenter G, Grossberg S (2003) Adaptive resonance theory. In: Arbib M, editor, The Handbook of Brain Theory and Neural Networks, Second Edition, Cambridge, MA: MIT Press. pp. 87–90.</mixed-citation>
</ref>
<ref id="pone.0096485-Abraham1"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abraham</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Robins</surname><given-names>A</given-names></name> (<year>2005</year>) <article-title>Memory retention - the synaptic stability versus plasticity dilemma</article-title>. <source>Trends in Neuroscience</source> <volume>28(2)</volume>: <fpage>73</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Robins1"><label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robins</surname><given-names>A</given-names></name>, <name name-style="western"><surname>McCallum</surname><given-names>S</given-names></name> (<year>1998</year>) <article-title>Catastrophic forgetting and the pseudorehearsal solution in Hopfield type networks</article-title>. <source>Connection Science</source> <volume>7</volume>: <fpage>121</fpage>–<lpage>135</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-French2"><label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>French</surname><given-names>R</given-names></name> (<year>1992</year>) <article-title>Semi-distributed representations and catastrophic forgetting in connectionist networks</article-title>. <source>Connection Science</source> <volume>4</volume>: <fpage>365</fpage>–<lpage>377</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Murre1"><label>94</label>
<mixed-citation publication-type="other" xlink:type="simple">Murre J (1992) Learning and categorization in modular neural networks. LEA, NJ: Hillsdale.</mixed-citation>
</ref>
<ref id="pone.0096485-Barlow1"><label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>H</given-names></name> (<year>1972</year>) <article-title>Single units and sensation: a neuron doctrine for perceptual psychology</article-title>. <source>Perception</source> <volume>1</volume>: <fpage>371</fpage>–<lpage>394</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Nadal1"><label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nadal</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Toulouse</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Changeux</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dehaene</surname><given-names>S</given-names></name> (<year>1986</year>) <article-title>Networks of formal neurons and memory palimpsests</article-title>. <source>Europhysics Letters</source> <volume>1(10)</volume>: <fpage>535</fpage>–<lpage>542</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-vanHemmen1"><label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Hemmen</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Keller</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kühn</surname><given-names>R</given-names></name> (<year>1988</year>) <article-title>Forgetful memories</article-title>. <source>Europhysics Letters</source> <volume>5</volume>: <fpage>663</fpage>–<lpage>668</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Sandberg1"><label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sandberg</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lansner</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Petersson</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Ekeberg</surname><given-names>O</given-names></name> (<year>2000</year>) <article-title>A palimpsest memory based on an incremental Bayesian learning rule</article-title>. <source>Neurocomputing</source> <volume>32–33</volume>: <fpage>987</fpage>–<lpage>994</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Hedden1"><label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hedden</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Gabrieli</surname><given-names>J</given-names></name> (<year>2004</year>) <article-title>Insights into the ageing mind: a view from cognitive neuroscience</article-title>. <source>Nature Reviews Neuroscience</source> <volume>5</volume>: <fpage>87</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Zola1"><label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zola</surname><given-names>S</given-names></name> (<year>2000</year>) <article-title>Amnesia I: Neuroanatomic and clinical issues</article-title>. <source>In: Farah M, Feinberg T, editors, Patient-based approaches to cognitive neuroscience., Cambridge, MA: MIT-Press, chapter</source> <volume>21</volume>: <fpage>275</fpage>–<lpage>290</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Baddeley1"><label>101</label>
<mixed-citation publication-type="other" xlink:type="simple">Baddeley A (1990) Human memory: theory and practice. Hillsdale, NJ: Lawrence Erlbaum.</mixed-citation>
</ref>
<ref id="pone.0096485-Meeter1"><label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meeter</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Murre</surname><given-names>J</given-names></name> (<year>2005</year>) <article-title>TraceLink: A model of consolidation and amnesia</article-title>. <source>Cognitive Neuropsychology</source> <volume>22(5)</volume>: <fpage>559</fpage>–<lpage>587</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Buzsaki1"><label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name> (<year>1996</year>) <article-title>The hippocampo-neocortical dialogue</article-title>. <source>Cerebral Cortex</source> <volume>6</volume>: <fpage>81</fpage>–<lpage>92</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Alvarez1"><label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvarez</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Squire</surname><given-names>L</given-names></name> (<year>1994</year>) <article-title>Memory consolidation and the medial temporal lobe: a simple network model</article-title>. <source>Proceedings of the National Academy of Sciences (USA)</source> <volume>91</volume>: <fpage>7041</fpage>–<lpage>7045</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Nadel1"><label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nadel</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Moscovitch</surname><given-names>M</given-names></name> (<year>1997</year>) <article-title>Memory consolidation, retrograde amnesia and the hippocampal complex</article-title>. <source>Current Opinion in Neurobiology</source> <volume>7(2)</volume>: <fpage>217</fpage>–<lpage>227</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Cepeda1"><label>106</label>
<mixed-citation publication-type="other" xlink:type="simple">Cepeda N, Pashler H, Vul E, Wixted J, Rohrer D (2006) Distributed practice in verbal recall tasks: A review and quantitative synthesis. Psychological Bulletin 132(3): 354–380. Cepeda/Pashler/Vul/Wixted/Rohrer:2006.</mixed-citation>
</ref>
<ref id="pone.0096485-Bregman1"><label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bregman</surname><given-names>A</given-names></name> (<year>1967</year>) <article-title>Distribution of practice and between-trials interference</article-title>. <source>Canadian Journal of Psychology</source> <volume>21</volume>: <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Glenberg1"><label>108</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glenberg</surname><given-names>A</given-names></name> (<year>1979</year>) <article-title>Component-levels theory of the effects of spacing of repetitions on recall and recognition</article-title>. <source>Memory &amp; Cognition</source> <volume>7</volume>: <fpage>95</fpage>–<lpage>112</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Martin1"><label>109</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Martin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Grimwood</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>R</given-names></name> (<year>2000</year>) <article-title>Synaptic plasticity and memory: an evaluation of the hypothesis</article-title>. <source>Annual Review of Neuroscience</source> <volume>23</volume>: <fpage>649</fpage>–<lpage>711</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch14"><label>110</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2010) Bimodal structural plasticity can explain the spacing effect in long-term memory tasks. Frontiers in Systems Neuroscience Conference Abstract: Computational and Systems Neuroscience.</mixed-citation>
</ref>
<ref id="pone.0096485-Cepeda2"><label>111</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cepeda</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Vul</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Rohrer</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wixted</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pashler</surname><given-names>H</given-names></name> (<year>2008</year>) <article-title>Spacing effects in learning: A temporal ridgeline of optimal retention</article-title>. <source>Psychological Science</source> <volume>19(11)</volume>: <fpage>1095</fpage>–<lpage>1102</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Abeles1"><label>112</label>
<mixed-citation publication-type="other" xlink:type="simple">Abeles M (1991) Corticonics: Neural circuits of the cerebral cortex. Cambridge UK: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch15"><label>113</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2006) On compressing the memory structures of binary neural associative networks. HRI-EU Report 06-02, Honda Research Institute Europe GmbH, D-63073 Offenbach/Main, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Hofer1"><label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hofer</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Structural traces of past experience in the cerebral cortex</article-title>. <source>Journal of Molecular Medicine (Berlin)</source> <volume>88(3)</volume>: <fpage>235</fpage>–<lpage>239</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Miyoshi1"><label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miyoshi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Okada</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Storage capacity diverges with synaptic efficiency in an associative memory model with synaptic delay and pruning</article-title>. <source>IEEE Transaction on Neural Networks</source> <volume>15(5)</volume>: <fpage>1215</fpage>–<lpage>1227</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Yu1"><label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zuo</surname><given-names>Y</given-names></name> (<year>2011</year>) <article-title>Spine plasticity in the motor cortex</article-title>. <source>Current Opinion in Neurobiology</source> <volume>21(1)</volume>: <fpage>169</fpage>–<lpage>174</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Markram2"><label>117</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Lübke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Frotscher</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name> (<year>1997</year>) <article-title>Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs</article-title>. <source>Science</source> <volume>275</volume>: <fpage>213</fpage>–<lpage>215</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Bi1"><label>118</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Poo</surname><given-names>M</given-names></name> (<year>1998</year>) <article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title>. <source>The Journal of Neuroscience</source> <volume>18(24)</volume>: <fpage>10464</fpage>–<lpage>10472</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Clopath1"><label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Büsing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Vasilaki</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2010</year>) <article-title>Connectivity reflects coding: a model of voltage-based STDP with homeostasis</article-title>. <source>Nature Neuroscience</source> <volume>13(3)</volume>: <fpage>344</fpage>–<lpage>352</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Lubenov1"><label>120</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lubenov</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Siapas</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Decoupling through synchrony in neuronal circuits with propagation delays</article-title>. <source>Neuron</source> <volume>58</volume>: <fpage>118</fpage>–<lpage>131</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch16"><label>121</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>F</given-names></name> (<year>2003</year>) <article-title>Synaptic plasticity, conduction delays, and inter-areal phase relations of spike activity in a model of reciprocally connected areas</article-title>. <source>Neurocomputing</source> <volume>52–54</volume>: <fpage>301</fpage>–<lpage>306</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Gerstner1"><label>122</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kempter</surname><given-names>R</given-names></name>, <name name-style="western"><surname>van Hemmen</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wagner</surname><given-names>H</given-names></name> (<year>1996</year>) <article-title>A neuronal learning rule for sub-millisecond temporal coding</article-title>. <source>Nature</source> <volume>386</volume>: <fpage>76</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Fell1"><label>123</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fell</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Axmacher</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>The role of phase synchronization in memory processes</article-title>. <source>Nature Reviews Neuroscience</source> <volume>12</volume>: <fpage>105</fpage>–<lpage>118</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch17"><label>124</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hauser</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Gewaltig</surname><given-names>MO</given-names></name>, <name name-style="western"><surname>Körner</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Palm</surname><given-names>G</given-names></name> (<year>2012</year>) <article-title>Does spike-timing-dependent synaptic plasticity couple or decouple neurons firing in synchrony?</article-title> <source>Frontiers in Computational Neuroscience</source> <volume>6</volume>: <fpage>1</fpage>–<lpage>27</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Arieli1"><label>125</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arieli</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sterkin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name> (<year>1996</year>) <article-title>Dynamics of ongoing activity: Explanation of the large variability in evoked cortical responses</article-title>. <source>Science</source> <volume>273</volume>: <fpage>1868</fpage>–<lpage>1871</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch18"><label>126</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2010) Efficient associative computation with binary or low precision synapses and structural plasticity. In: Proceedings of the 14th International Conference on Cognitive and Neural Systems (ICCNS). Boston, MA: Center of Excellence for Learning in Education, Science, and Technology (CELEST), p. 66.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch19"><label>127</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2008) Best-match hashing with inhibitory associative networks for real-world object recognition. HRI-EU Report 08-05, Honda Research Institute Europe GmbH, D-63073 Offenbach/Main, Germany.</mixed-citation>
</ref>
<ref id="pone.0096485-Buckingham1"><label>128</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckingham</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Willshaw</surname><given-names>D</given-names></name> (<year>1992</year>) <article-title>Performance characteristics of the associative net</article-title>. <source>Network: Computation in Neural Systems</source> <volume>3</volume>: <fpage>407</fpage>–<lpage>414</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch20"><label>129</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Neural associative memory and the Willshaw-Palm probability distribution</article-title>. <source>SIAM Journal on Applied Mathematics</source> <volume>69(1)</volume>: <fpage>169</fpage>–<lpage>196</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Dammasch1"><label>130</label>
<mixed-citation publication-type="other" xlink:type="simple">Dammasch I (1989) Structural realization of a hebb-type learning rule. In: Cotterill R, editor, Models of Brain Function., Cambridge University Press. 539–552.</mixed-citation>
</ref>
<ref id="pone.0096485-Song2"><label>131</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sjöström</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Reigl</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title>. <source>PLOS Biology</source> <volume>3(3)</volume>: <fpage>507</fpage>–<lpage>519</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Helias1"><label>132</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Helias</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gewaltig</surname><given-names>MO</given-names></name>, <name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Structural plasticity controlled by calcium based correlation detection</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>2</volume>: <fpage>7</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Deger2"><label>133</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deger</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Helias</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Spike-timing dependence of structural plasticity explains cooperative synapse formation in the neocortex</article-title>. <source>PLoS Computational Biology</source> <volume>8(9)</volume>: <fpage>e1002689</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Teyler1"><label>134</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Teyler</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Rudy</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>The hippocampal indexing theory and episodic memory: Updating the index</article-title>. <source>Hippocampus</source> <volume>17(12)</volume>: <fpage>1158</fpage>–<lpage>1169</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Sporns1"><label>135</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2007</year>) <article-title>Brain connectivity</article-title>. <source>Scholarpedia</source> <volume>2</volume>: <fpage>4695</fpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Granger1"><label>136</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Granger</surname><given-names>C</given-names></name> (<year>1969</year>) <article-title>Investigating causal relations by econometric models and cross-spectral methods</article-title>. <source>Econometrica</source> <volume>37(3)</volume>: <fpage>424</fpage>–<lpage>438</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Schreiber1"><label>137</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schreiber</surname><given-names>T</given-names></name> (<year>2000</year>) <article-title>Measuring information transfer</article-title>. <source>Physical Review Letters</source> <volume>85</volume>: <fpage>461</fpage>–<lpage>464</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch21"><label>138</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2014) Structural plasticity and effective connectivity in preparation.</mixed-citation>
</ref>
<ref id="pone.0096485-Tsodyks1"><label>139</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Feigel'man</surname><given-names>M</given-names></name> (<year>1988</year>) <article-title>The enhanced storage capacity in neural networks with low activity level</article-title>. <source>Europhysics Letters</source> <volume>6</volume>: <fpage>101</fpage>–<lpage>105</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Palm3"><label>140</label>
<mixed-citation publication-type="other" xlink:type="simple">Palm G, Sommer F (1996) Associative data storage and retrieval in neural nets. In: Domany E, van Hemmen J, Schulten K, editors, Models of Neural Networks III, New York: Springer-Verlag. 79–118.</mixed-citation>
</ref>
<ref id="pone.0096485-Pagani1"><label>141</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pagani</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Oishi</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Gelb</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Zhong</surname><given-names>Y</given-names></name> (<year>2009</year>) <article-title>The phosphatase SHP2 regulates the spacing effect for long-term memory induction</article-title>. <source>Cell</source> <volume>139</volume>: <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Knoblauch22"><label>142</label>
<mixed-citation publication-type="other" xlink:type="simple">Knoblauch A (2014) Efficient simulation of structural plasticity in the brain in preparation.</mixed-citation>
</ref>
<ref id="pone.0096485-Buckingham2"><label>143</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckingham</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Willshaw</surname><given-names>D</given-names></name> (<year>1993</year>) <article-title>On setting unit thresholds in an incompletely connected associative net</article-title>. <source>Network: Computation in Neural Systems</source> <volume>4</volume>: <fpage>441</fpage>–<lpage>459</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Graham1"><label>144</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Willshaw</surname><given-names>D</given-names></name> (<year>1995</year>) <article-title>Improving recall from an associative memory</article-title>. <source>Biological Cybernetics</source> <volume>72</volume>: <fpage>337</fpage>–<lpage>346</lpage>.</mixed-citation>
</ref>
<ref id="pone.0096485-Bosch1"><label>145</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bosch</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kurfess</surname><given-names>F</given-names></name> (<year>1998</year>) <article-title>Information storage capacity of incompletely connected associative memories</article-title>. <source>Neural Networks</source> <volume>11(5)</volume>: <fpage>869</fpage>–<lpage>876</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>