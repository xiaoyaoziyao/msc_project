<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02234</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004566</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Mirrored STDP Implements Autoencoder Learning in a Network of Spiking Neurons</article-title>
<alt-title alt-title-type="running-head">Mirrored STDP Implements Autoencoder Learning with Spiking Neurons</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Burbank</surname> <given-names>Kendra S.</given-names></name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Department of Statistics, University of Chicago, Chicago, Illinois, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Graham</surname> <given-names>Lyle J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Université Paris Descartes, Centre National de la Recherche Scientifique, FRANCE</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The author has declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: KSB. Performed the experiments: KSB. Analyzed the data: KSB. Contributed reagents/materials/analysis tools: KSB. Wrote the paper: KSB.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">burbank@galton.uchicago.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>3</day>
<month>12</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>12</issue>
<elocation-id>e1004566</elocation-id>
<history>
<date date-type="received">
<day>11</day>
<month>12</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>23</day>
<month>9</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Kendra S. Burbank</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004566" xlink:type="simple"/>
<abstract>
<p>The autoencoder algorithm is a simple but powerful unsupervised method for training neural networks. Autoencoder networks can learn sparse distributed codes similar to those seen in cortical sensory areas such as visual area V1, but they can also be stacked to learn increasingly abstract representations. Several computational neuroscience models of sensory areas, including Olshausen &amp; Field’s Sparse Coding algorithm, can be seen as autoencoder variants, and autoencoders have seen extensive use in the machine learning community. Despite their power and versatility, autoencoders have been difficult to implement in a biologically realistic fashion. The challenges include their need to calculate differences between two neuronal activities and their requirement for learning rules which lead to identical changes at feedforward and feedback connections. Here, we study a biologically realistic network of integrate-and-fire neurons with anatomical connectivity and synaptic plasticity that closely matches that observed in cortical sensory areas. Our choice of synaptic plasticity rules is inspired by recent experimental and theoretical results suggesting that learning at feedback connections may have a different form from learning at feedforward connections, and our results depend critically on this novel choice of plasticity rules. Specifically, we propose that plasticity rules at feedforward versus feedback connections are temporally opposed versions of spike-timing dependent plasticity (STDP), leading to a symmetric combined rule we call Mirrored STDP (mSTDP). We show that with mSTDP, our network follows a learning rule that approximately minimizes an autoencoder loss function. When trained with whitened natural image patches, the learned synaptic weights resemble the receptive fields seen in V1. Our results use realistic synaptic plasticity rules to show that the powerful autoencoder learning algorithm could be within the reach of real biological networks.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>In the brain areas responsible for sensory processing, neurons learn over time to respond to specific features in the external world. Here, we propose a new, biologically plausible model for how groups of neurons can learn which specific features to respond to. Our work connects theoretical arguments about the optimal forms of neuronal representations with experimental results showing how synaptic connections change in response to neuronal activity. Specifically, we show that biologically realistic neurons can implement an algorithm known as autoencoder learning, in which the neurons learn to form representations that can be used to reconstruct their inputs. Autoencoder networks can successfully model neuronal responses in early sensory areas, and they are also frequently used in machine learning for training deep neural networks. Despite their power and utility, autoencoder networks have not been previously implemented in a fully biological fashion. To perform the autoencoder algorithm, neurons must modify their incoming, feedforward synaptic connections as well as their outgoing, feedback synaptic connections—and the changes to both must depend on the errors the network makes when it tries to reconstruct its input. Here, we propose a model for activity in the network and show that the commonly used spike-timing-dependent plasticity paradigm will implement the desired changes to feedforward synaptic connection weights. Critically, we use recent experimental evidence to propose that feedback connections learn according to a temporally reversed plasticity rule. We show mathematically that the two rules combined can approximately implement autoencoder learning, and confirm our results using simulated networks of integrate-and-fire neurons. By showing that biological neurons can implement this powerful algorithm, our work opens the door for the modeling of many learning paradigms from both the fields of computational neuroscience and machine learning.</p>
</abstract>
<funding-group>
<funding-statement>The author received no specific funding for this work.</funding-statement>
</funding-group>
<counts>
<fig-count count="10"/>
<table-count count="0"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Neurons in the brain’s sensory areas need to form useful internal representations of the external world. Over the course of development, as these neurons create and modify their synaptic connections, they develop receptive fields which allow them to respond to characteristic stimulus features. The preferred features are relatively simple for neurons in primary areas such as primary visual cortex (V1) and primary auditory cortex (A1), but increase in complexity, sparsity, abstractness, and size in higher brain areas. It is an intriguing possibility that the brain uses a similar mechanism to learn receptive fields in higher sensory areas as it does in the primary areas. If so, that mechanism must be flexible enough to work across the different regimes of sparsity, complexity, and abstraction. The mechanism must also be capable of producing representations which are potentially “stackable”, so that the output from one area can be represented in more abstract form in the subsequent area. For instance, if pairwise or higher order correlations in neuronal activity are present in one area, those correlations might be captured to form a more abstract representation in the next area. Finally, the mechanism must be implementable by biological neurons: all computations must be local, and synaptic weight changes should match experimentally observed synaptic plasticity. Here, we introduce a model for learning in a single area which we argue fulfills these requirements: it is biologically plausible while allowing varying levels of sparsity and producing representations that need not be uncorrelated.</p>
<p>Many previous biologically plausible models of receptive field development learn local or “one-hot” representations, in which each stimulus causes approximately <italic>one</italic> neuron (or one small neighborhood of neurons) to respond; models in this class include Kohonen’s Self-Organizing Map [<xref ref-type="bibr" rid="pcbi.1004566.ref001">1</xref>], LISSOM [<xref ref-type="bibr" rid="pcbi.1004566.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref003">3</xref>], and Winner-Take-All models [<xref ref-type="bibr" rid="pcbi.1004566.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref005">5</xref>]. Learning in these models moves the winning neuron’s receptive field closer to the current stimulus using procedures which are simple, synaptically local, and do not require feedback connections. However, local representations have very limited capacity: they can represent <inline-formula id="pcbi.1004566.e001"><alternatives><graphic id="pcbi.1004566.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e001"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> distinct inputs with <italic>N</italic> neurons, thus requiring that the number of neurons is comparable to the number of features to be distinguished. Local models of low-level vision can succeed because natural image patches seem to exist in a space of low dimensionality [<xref ref-type="bibr" rid="pcbi.1004566.ref006">6</xref>], and spatially localized features can be characterized using only a few parameters (such as orientation, spatial frequency, and phase). However, in higher brain areas with larger and more complex receptive fields, the number of neurons required for a local model to be able to represent all possible stimuli would grow tremendously.</p>
<p>By contrast, distributed models can represent many more potential inputs, from <inline-formula id="pcbi.1004566.e002"><alternatives><graphic id="pcbi.1004566.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e002"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">O</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> for sparse models with <italic>k</italic> active units up to <inline-formula id="pcbi.1004566.e003"><alternatives><graphic id="pcbi.1004566.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e003"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mn>2</mml:mn> <mml:mi>N</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> for dense models [<xref ref-type="bibr" rid="pcbi.1004566.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref009">9</xref>], and may therefore be better suited for modeling at all levels of the sensory hierarchy. Several biologically plausible models have been proposed for learning distributed representations in the special case where neuronal activity is very sparse and uncorrelated [<xref ref-type="bibr" rid="pcbi.1004566.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref012">12</xref>]; under these conditions, a simple learning rule similar to that seen in the local models can be used. However, a model which does not require neurons to be uncorrelated is desirable because neurons in real cortical networks respond to stimuli in highly correlated ways. This stimulus-dependent correlation should be distinguished from noise correlation, which measures the similarities of <italic>fluctuations</italic> in neuronal responses to identical stimuli. Noise correlation is frequently measured to be small, and so cortical firing is often described as “decorrelated” (e.g. [<xref ref-type="bibr" rid="pcbi.1004566.ref013">13</xref>]). However, stimulus-dependent correlation is strong; in V1, from 20–50% of neurons have been estimated to respond to each stimulus in their receptive field [<xref ref-type="bibr" rid="pcbi.1004566.ref014">14</xref>]. Many pairs of neurons have highly correlated responses when measured across multiple stimuli (e.g. [<xref ref-type="bibr" rid="pcbi.1004566.ref015">15</xref>]). Importantly, in the context of a hierarchy, the correlations remaining in the neurons of one layer can be captured by neurons in subsequent layers.</p>
<p>Perhaps the most well-known model for learning in V1 is Olshausen and Field’s Sparse Coding model [<xref ref-type="bibr" rid="pcbi.1004566.ref016">16</xref>]. Their algorithm attempts to find receptive fields which simultaneously preserve information while maintaining sparse neuronal activity, but it does not require neuronal activity to be uncorrelated in order to function. However, the algorithm thus far lacks a biological interpretation. A different spike-based matching pursuit model [<xref ref-type="bibr" rid="pcbi.1004566.ref017">17</xref>] uses different interactions to determine the neuronal activities but the same learning rule, and that learning rule similarly lacks a biological interpretation.</p>
<p>Here, we introduce a novel biological mechanism for a well-known learning algorithm known as the autoencoder. Autoencoders are two-layer neural networks which attempt to learn distributed representations that can be used to accurately reconstruct their inputs. In an autoencoder, external stimuli induce activity in the lower-layer “visible” units. This activity, combined with feedforward connections, then creates a pattern of activity in the upper-layer “hidden” units. Finally, the network uses symmetric or “tied” feedback weights in order to create an attempted reconstruction in the visible layer. The objective of autoencoder learning is to find weights such that the reconstruction closely matches the original stimulus input, thus ensuring that the hidden unit representation is a good one; intuitively, reconstructions can only be accurate when the hidden layer retains sufficient information about the visible layer. An autoencoder can be made to find an <italic>efficient</italic> representation by adding a constraint on the activity or architecture of the hidden layer. This forces the network to find features which are useful for describing the particular types of stimuli seen during training. The constraint can take the form of a regularization term added to the loss function. Alternatively, it can be a hard limit, such as a limit on the number of hidden units, a requirement that hidden units be binary, or a requirement that hidden unit activity be sparse. Typically, autoencoders are trained using stochastic gradient descent on the squared reconstruction error (or on the reconstruction error plus regularizer term); for each stimulus presentation, synaptic weights are changed in the direction that would most decrease this loss function. In this work, networks are trained instead using the “autoencoder rule”, also known as Oja’s subspace rule [<xref ref-type="bibr" rid="pcbi.1004566.ref018">18</xref>], which is an approximation to the full gradient descent expression. If the vector of input values is given by <inline-formula id="pcbi.1004566.e004"><alternatives><graphic id="pcbi.1004566.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e004"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, hidden unit activities are given by <inline-formula id="pcbi.1004566.e005"><alternatives><graphic id="pcbi.1004566.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e005"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and the attempted reconstruction is the vector <inline-formula id="pcbi.1004566.e006"><alternatives><graphic id="pcbi.1004566.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e006"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, then the autoencoder rule states that for learning rate <italic>η</italic>, the change in synaptic weights <italic>w</italic><sub><italic>ij</italic></sub> between visible unit <italic>i</italic> and hidden unit <italic>j</italic> is given by
<disp-formula id="pcbi.1004566.e007"><alternatives><graphic id="pcbi.1004566.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="8.0pt"/><mml:mtext>(Autoencoder</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>learning</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>rule)</mml:mtext></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
Autoencoders can be used to accurately model responses in early sensory areas; indeed, Olhausen &amp; Field’s Sparse Coding network is an autoencoder with lateral interactions between the hidden units used to impose a sparsity constraint. But the autoencoder is a very general algorithm. With different neuronal activation functions and lateral interactions, autoencoders can also find the subspace spanned by Principal Component Analysis (PCA) eigenvectors [<xref ref-type="bibr" rid="pcbi.1004566.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref018">18</xref>] or perform an online implementation of K-means clustering [<xref ref-type="bibr" rid="pcbi.1004566.ref019">19</xref>]. (See [<xref ref-type="bibr" rid="pcbi.1004566.ref009">9</xref>] for an extensive review of autoencoders and their relationship to other learning algorithms.) These cases show that autoencoders can span the range between learning dense distributed models, as in PCA [<xref ref-type="bibr" rid="pcbi.1004566.ref020">20</xref>], and local models, as in K-means. Sparse Coding, where several hidden units respond to each stimulus, falls in between these two extremes. Autoencoders have been used extensively in the machine learning community, where they have been stacked to form multi-layer representations of increasing abstraction [<xref ref-type="bibr" rid="pcbi.1004566.ref021">21</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref023">23</xref>] or used to pre-train deep neural networks that perform classification tasks [<xref ref-type="bibr" rid="pcbi.1004566.ref024">24</xref>].</p>
<p>There are two main difficulties regarding a biologically plausible implementation of the autoencoder. The first challenge arises from the fact that learning must depend on the <italic>difference</italic> of two neuronal activities: the original visible unit activity <inline-formula id="pcbi.1004566.e008"><alternatives><graphic id="pcbi.1004566.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e008"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and the reconstructed activity <inline-formula id="pcbi.1004566.e009"><alternatives><graphic id="pcbi.1004566.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e009"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1004566.e007">Eq (1)</xref>). The second difficulty comes from the required symmetry of learning tied weights, where feedforward weights are equal to feedback weights. Preserving this symmetry over the course of learning dictates that any change to the feedforward synaptic strength between two neurons must be accompanied by an identical change to the feedback strength. If a feedforward synapse is weakened, the feedback synapse must also be weakened, and vice versa. In real neurons, feedforward and feedback synapses are physically distinct entities, and a biologically realistic model must account for how the two can experience identical (or very similar) plasticity.</p>
<p>Previous implementations have addressed these two challenges by positing that hidden layer neurons are inhibitory and create negative reconstructions, so that the final activity in the visible layer is <inline-formula id="pcbi.1004566.e010"><alternatives><graphic id="pcbi.1004566.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e010"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ϵ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, and stipulating that learning then proceeds according to symmetric Hebbian rules Δ<italic>w</italic><sub><italic>ij</italic></sub> = <italic>ϵ</italic><sub><italic>i</italic></sub> <italic>y</italic><sub><italic>j</italic></sub> [<xref ref-type="bibr" rid="pcbi.1004566.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref026">26</xref>]. However, these implementations are biologically unrealistic in three important ways. First, they require visible unit activity levels <inline-formula id="pcbi.1004566.e011"><alternatives><graphic id="pcbi.1004566.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e011"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>ϵ</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> to become <italic>negative</italic> at times in order to create synaptic depression. Second, the inhibitory nature of the feedback connections is unrealistic, since it is known that most feedback connections between cortical areas arise from excitatory neurons, and most feature-selective neurons are excitatory [<xref ref-type="bibr" rid="pcbi.1004566.ref027">27</xref>]. Third, the learning rules themselves are unrealistic; experiments have shown that in real neurons, unlike those modeled in inhibitory feedback networks, synaptic plasticity is neither purely Hebbian nor symmetric. Instead, the sign of synaptic plasticity often depends on the relative timing of activity in pre- and post-synaptic neurons [<xref ref-type="bibr" rid="pcbi.1004566.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref029">29</xref>], in a process known as spike-timing dependent plasticity (STDP) [<xref ref-type="bibr" rid="pcbi.1004566.ref029">29</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref032">32</xref>].</p>
<p>Here, we instead propose a spiking neural network in which feedback creates a weak, <italic>positive</italic> reconstruction. Unlike a previous proposal with a similar architecture [<xref ref-type="bibr" rid="pcbi.1004566.ref033">33</xref>], our model uses a biologically realistic synaptic plasticity rule to implement learning. The required negative sign in the learning rule arises naturally from an additive version of STDP, while our proposed differences in the plasticity rules at feedforward versus feedback synapses [<xref ref-type="bibr" rid="pcbi.1004566.ref034">34</xref>] lead to effective symmetry in learning. We show analytically that the learning in our network approximates the autoencoder learning rule.</p>
<p>To examine the behavior of our model in the sparse regime, we use a very simple, biologically plausible method for inducing individual hidden neurons to have high lifetime sparsity. Our method uses local homeostatic mechanisms within each neuron to drive the network to find sparse solutions, and is designed to mimic a biological process known as “synaptic scaling” [<xref ref-type="bibr" rid="pcbi.1004566.ref035">35</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref037">37</xref>], in which neurons regulate their activity levels by modifying their susceptibility to synaptic inputs. The resulting sparsity is important because it is well known that algorithms which yield sparse representations of natural stimuli can learn synaptic weights which closely resemble the receptive field structures of simple cells in primary sensory cortices (reviewed in [<xref ref-type="bibr" rid="pcbi.1004566.ref038">38</xref>]). The specific choice of algorithm seems to matter less than its basic ability to create a sparse representation [<xref ref-type="bibr" rid="pcbi.1004566.ref039">39</xref>]; while Sparse Coding was an early and famous example [<xref ref-type="bibr" rid="pcbi.1004566.ref016">16</xref>], various well-known sparse algorithms give qualitatively and even quantitatively similar results on visual, auditory, and somatosensory stimuli. These include independent component analysis [<xref ref-type="bibr" rid="pcbi.1004566.ref040">40</xref>], sparse autoencoders [<xref ref-type="bibr" rid="pcbi.1004566.ref041">41</xref>], restricted Boltzmann machines [<xref ref-type="bibr" rid="pcbi.1004566.ref041">41</xref>], and K-means clustering [<xref ref-type="bibr" rid="pcbi.1004566.ref042">42</xref>] (all are reviewed in [<xref ref-type="bibr" rid="pcbi.1004566.ref043">43</xref>] and [<xref ref-type="bibr" rid="pcbi.1004566.ref039">39</xref>]).</p>
<p>We use simulated networks of integrate-and-fire neurons in two experiments to show that our network is capable of minimizing reconstruction error in these example datasets. For the first experiment, in which we train the network using a dataset containing handwritten digits, we use model neurons that approximate the idealized units in a neural network by having synaptic weights that can become positive or negative and an additive form of synaptic scaling that resembles a neural network bias term. For the second experiment, we use a dataset containing whitened natural image patches and we verify that the learned receptive fields resemble those measured in primary visual cortex. Here, we more closely model biological excitatory neurons by restricting synaptic weights to be positive and by using a multiplicative form of synaptic scaling. In both experiments, dynamic parameters such as membrane time constants and synaptic transmission delays are set to biologically realistic values.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>The autoencoder rule</title>
<p>We begin by defining the general autoencoder problem in a two-layer neural network. Each neuron in the first, visible layer is connected reciprocally to each neuron in the second, hidden layer, and there are no lateral connections. During each training trial, the network is presented with stimulus <inline-formula id="pcbi.1004566.e012"><alternatives><graphic id="pcbi.1004566.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e012"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in the visible layer. The network then computes a representation <inline-formula id="pcbi.1004566.e013"><alternatives><graphic id="pcbi.1004566.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e013"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in the hidden layer, using feedforward weights <bold>W</bold> (with the <italic>j</italic>th column vector denoted by <inline-formula id="pcbi.1004566.e014"><alternatives><graphic id="pcbi.1004566.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e014"/><mml:math id="M14" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>) and other parameters <italic>θ</italic> according to the potentially non-linear function
<disp-formula id="pcbi.1004566.e015"><alternatives><graphic id="pcbi.1004566.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula></p>
<p>The network then computes an attempted reconstruction <inline-formula id="pcbi.1004566.e016"><alternatives><graphic id="pcbi.1004566.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e016"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in the visible layer using symmetrical or “tied” feedback weights <inline-formula id="pcbi.1004566.e017"><alternatives><graphic id="pcbi.1004566.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e017"/><mml:math id="M17" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:math></alternatives></inline-formula> and an activation function <italic>g</italic>, so that
<disp-formula id="pcbi.1004566.e018"><alternatives><graphic id="pcbi.1004566.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e018"/><mml:math id="M18" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>g</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
A squared reconstruction error is defined as
<disp-formula id="pcbi.1004566.e019"><alternatives><graphic id="pcbi.1004566.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e019"/><mml:math id="M19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">E</mml:mi> <mml:mo>=</mml:mo> <mml:mo>‖</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mrow><mml:mo>‖</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula></p>
<p>How should this network modify its weights so as to minimize this error, using stochastic gradient descent? The derivative of <inline-formula id="pcbi.1004566.e020"><alternatives><graphic id="pcbi.1004566.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e020"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mi mathvariant="script">E</mml:mi></mml:math></alternatives></inline-formula> with respect to the weights <italic>w</italic><sub><italic>ij</italic></sub> between a visible neuron <italic>i</italic> and a hidden neuron <italic>j</italic> is
<disp-formula id="pcbi.1004566.e021"><alternatives><graphic id="pcbi.1004566.e021g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e021"/><mml:math id="M21" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="script">E</mml:mi></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>The initial visible activities <italic>x</italic><sub><italic>i</italic></sub> don’t depend on the weights, so <inline-formula id="pcbi.1004566.e022"><alternatives><graphic id="pcbi.1004566.e022g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e022"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for all <italic>i</italic>′. Similarly, the hidden unit activity <italic>y</italic><sub><italic>j</italic></sub> is independent of the weights to other hidden units, so <inline-formula id="pcbi.1004566.e023"><alternatives><graphic id="pcbi.1004566.e023g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e023"/><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for <italic>j</italic> ≠ <italic>j</italic>′. If we define
<disp-formula id="pcbi.1004566.e024"><alternatives><graphic id="pcbi.1004566.e024g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e024"/><mml:math id="M24" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi> <mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>≡</mml:mo> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi>g</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:mfrac> <mml:msub><mml:mo>|</mml:mo> <mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
then
<disp-formula id="pcbi.1004566.e025"><alternatives><graphic id="pcbi.1004566.e025g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e025"/><mml:math id="M25" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>g</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>′</mml:mo></mml:msubsup> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:msub><mml:mi>y</mml:mi> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>g</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>′</mml:mo></mml:msubsup> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula></p>
<p>Therefore,
<disp-formula id="pcbi.1004566.e026"><alternatives><graphic id="pcbi.1004566.e026g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e026"/><mml:math id="M26" display="block" overflow="scroll"><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="script">E</mml:mi></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mfenced> <mml:msubsup><mml:mi>g</mml:mi> <mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>g</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:msup><mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>There are two terms above because of the tied weights: changing <italic>w</italic><sub><italic>ij</italic></sub> modifies both feedforward and feedback connections, and these changes have two independent effects on the reconstruction error. The first term is simpler, and reflects the contribution from the changed feedback connections. Importantly, it depends only on the activities of the connected neurons <italic>i</italic> and <italic>j</italic>. We therefore say that it is a “local” computation, and one that might plausibly be computed by biological neurons.</p>
<p>By contrast, the second term, which reflects the contribution from the changed feedforward connections, is non-local. It depends on the activities of every visible neuron; this information would not be available to a biological synapse. Previous authors have noted that the second term is often small [<xref ref-type="bibr" rid="pcbi.1004566.ref044">44</xref>], so that an <italic>approximate</italic> gradient descent using only the first term works nearly as well as the full equation [<xref ref-type="bibr" rid="pcbi.1004566.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref045">45</xref>]. For linear reconstructions, where <italic>g</italic>′ is a constant, this becomes the autoencoder learning rule (<xref ref-type="disp-formula" rid="pcbi.1004566.e007">Eq 1</xref>). This is the rule that we will implement biologically.</p>
<p>We note that the designation of “local” or “non-local” depends upon the activity in the network. We could have written <inline-formula id="pcbi.1004566.e027"><alternatives><graphic id="pcbi.1004566.e027g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e027"/><mml:math id="M27" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1004566.e007">Eq (1)</xref> as <italic>g</italic>(∑<sub><italic>j</italic>′</sub> <italic>y</italic><sub><italic>j</italic>′</sub> <italic>w</italic><sub><italic>ij</italic>′</sub>), and the learning rule would have appeared non-local due to its dependence on the <italic>y</italic><sub><italic>j</italic>′</sub> terms. Indeed, it is this exact non-locality that has caused previous authors to argue that autoencoder learning is not biologically plausible (e.g. [<xref ref-type="bibr" rid="pcbi.1004566.ref012">12</xref>]). Here, instead, information about all hidden-unit activities is incorporated into the reconstruction activations <inline-formula id="pcbi.1004566.e028"><alternatives><graphic id="pcbi.1004566.e028g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e028"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> of the visible units themselves. Any synaptic plasticity rule which incorporates <inline-formula id="pcbi.1004566.e029"><alternatives><graphic id="pcbi.1004566.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e029"/><mml:math id="M29" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> will allow synaptic changes to depend on the activity of all the hidden units and the initial activity of all the visible units—even though the learning rule is purely local.</p>
</sec>
<sec id="sec004">
<title>Spiking network for autoencoder learning</title>
<p>To implement the autoencoder learning rule with biologically realistic neurons, we propose a two-layer network of spiking neurons with <italic>N</italic><sub>vis</sub> neurons in the visible layer and <italic>N</italic><sub>hid</sub> neurons in the hidden layer (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1a</xref>). Every visible neuron is connected reciprocally with every hidden one, and there are no lateral connections within a layer. The matrix of feedforward connections is denoted <bold>W</bold> and the feedback connection matrix is <bold>Q</bold>; following sections will show how the weights become symmetric.</p>
<fig id="pcbi.1004566.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Architecture of the model network and stimulus preprocessing.</title>
<p>Architecture of the model network and network activity. <bold>a:</bold> Architecture of the model network and stimulus preprocessing. The final preprocessing step of separating the stimulus into two non-negative “ON” and “OFF” populations allows the visible layer activities to remain positive. <bold>b:</bold> Example activity of two neurons in the spiking network. In response to external stimulus onset (gray bar), the visible neuron <italic>i</italic> fires several spikes in the “initial bout” of activity. After a delay, feedforward excitation causes the hidden neuron <italic>j</italic> to fires spikes in the “intermediate bout”. After another delay, feedback causes the visible neuron to spike in the “final bout”, the network’s attempted reconstruction. The average time between spikes in the initial and intermediate bouts and intermediate and final bouts are given by Δ<italic>t</italic><sub>1</sub> and Δ<italic>t</italic><sub>2</sub>, respectively. Every pair of visible and hidden spikes contributes to plasticity, dependent on their relative times. Learning from two example dotted spikes is described in <xref ref-type="fig" rid="pcbi.1004566.g002">Fig 2</xref>. <bold>c:</bold> Biological feedforward and feedback connections are physically distinct. For the feedforward connection, the visible neuron is pre-synaptic, the hidden neuron is post-synaptic, and the synapse lies close to the hidden neuron’s cell body. For the feedback connection, the hidden neuron is pre-synaptic, the visible neuron post-synaptic, and the synapse is far out on the visible neuron’s dendritic tree.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g001"/>
</fig>
<p>Inputs to the network are pixel values of preprocessed training images, and they stimulate only the visible neurons (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1a</xref>). Plasticity in the system has two components: inter-layer synaptic weights evolve according to the mirrored STDP (mSTDP) rules, and hidden neurons homeostatically adjust synaptic scaling to maintain target average activity levels (both are described below). In our simulations, we use the leaky-integrate-and-fire (LIF) model for the neurons. However, our main results only depend on an approximately linear relationship between input strength and neuronal firing rate, so other neuron models could work as well. The details of the model implementation and all parameters used in the simulations are summarized in <xref ref-type="supplementary-material" rid="pcbi.1004566.s002">S1</xref>–<xref ref-type="supplementary-material" rid="pcbi.1004566.s008">S7</xref> Tables.</p>
<p>Our input preprocessing begins with a mean-subtraction step. This leaves pixel values <inline-formula id="pcbi.1004566.e030"><alternatives><graphic id="pcbi.1004566.e030g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e030"/><mml:math id="M30" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> that can be either positive or negative, which allows for a parsimonious representation of input pixels that are above or below their average values. However, biological neurons cannot have negative firing rates. We accommodate this by using an “ON-OFF cell” strategy, which uses twice as many visible neurons as pixels in the stimulus image. The inputs for the first half of the visible neurons are <inline-formula id="pcbi.1004566.e031"><alternatives><graphic id="pcbi.1004566.e031g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e031"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mtext>ON</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, while the inputs to the second half of visible neurons are <inline-formula id="pcbi.1004566.e032"><alternatives><graphic id="pcbi.1004566.e032g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e032"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mtext>OFF</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. This strategy closely resembles that used by subcortical cells in the mammalian visual system [<xref ref-type="bibr" rid="pcbi.1004566.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref047">47</xref>], and it allows both the positive and negative areas of the mean-subtracted natural image patches to be represented with positive neuronal activities of similar magnitude.</p>
<p>The network is trained through the sequential presentations of input stimuli. We choose parameters such that activity in the spiking network occurs in three rough bouts. <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref> shows activity for one visible and one hidden unit during a presentation. For each stimulus, visible neurons receive a brief pulse of excitatory synaptic input proportional to stimulus strength. This input causes the neurons to generate a series of spikes; the spike counts during this period are represented by the vector <inline-formula id="pcbi.1004566.e033"><alternatives><graphic id="pcbi.1004566.e033g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e033"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mi mathvariant="double-struck">Z</mml:mi> <mml:mrow><mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Feedforward synaptic excitation causes some of the hidden units to spike; their spike counts are given by <inline-formula id="pcbi.1004566.e034"><alternatives><graphic id="pcbi.1004566.e034g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e034"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mi mathvariant="double-struck">Z</mml:mi> <mml:mrow><mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>hid</mml:mtext></mml:msub></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. These hidden-unit spikes occur at a delay with respect to the initial visible unit activity because of a short synaptic transmission delay and because excitation from many spikes is required before the neurons reach threshold. Finally, after a further delay, visible units may spike again due to feedback excitation. The total number of visible spikes occurring due to feedback is <inline-formula id="pcbi.1004566.e035"><alternatives><graphic id="pcbi.1004566.e035g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e035"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mi mathvariant="double-struck">Z</mml:mi> <mml:mrow><mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. In <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref> <italic>x</italic><sub><italic>i</italic></sub> = 5, <italic>y</italic><sub><italic>j</italic></sub> = 3, and <inline-formula id="pcbi.1004566.e036"><alternatives><graphic id="pcbi.1004566.e036g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e036"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>; here, the three bouts are temporally separate, but in simulations there can be some overlap.</p>
<p>To prevent reverberating activity from growing exponentially during the course of a trial, we can consider parameters that lead to <italic>weak feedback</italic>, such that the number of spikes in the attempted reconstructions <inline-formula id="pcbi.1004566.e037"><alternatives><graphic id="pcbi.1004566.e037g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e037"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is several times smaller than that in the the initial activities <inline-formula id="pcbi.1004566.e038"><alternatives><graphic id="pcbi.1004566.e038g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e038"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1004566.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref048">48</xref>]. We denote the constant scaling factor <italic>α</italic> &lt; 1, and say that the network makes a successful reconstruction when <inline-formula id="pcbi.1004566.e039"><alternatives><graphic id="pcbi.1004566.e039g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e039"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover> <mml:mo>≈</mml:mo> <mml:mi>α</mml:mi> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Tied weights along with weak feedback will be maintained when learning rules enforce the relationship <inline-formula id="pcbi.1004566.e040"><alternatives><graphic id="pcbi.1004566.e040g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e040"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>=</mml:mo> <mml:mi>α</mml:mi> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Because feedforward and feedback synapses occur at physically distinct locations (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1c</xref>), we will show separate, biologically plausible plasticity rules for both feedforward and feedback connections and describe how they can maintain this symmetrical relationship.</p>
<p>We define a scaled spiking reconstruction error <inline-formula id="pcbi.1004566.e041"><alternatives><graphic id="pcbi.1004566.e041g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e041"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi> <mml:mtext>spike</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>α</mml:mi></mml:mfrac> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. To determine what synaptic weight changes will decrease this error, we first need to specify how the spike counts depend on the weights. If the neurons in the network behave like standard leaky integrate-and-fire neurons (and time periods are short compared to the membrane time constant), their spike counts will be well approximated by rectified linear functions, so that <inline-formula id="pcbi.1004566.e042"><alternatives><graphic id="pcbi.1004566.e042g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e042"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>≈</mml:mo> <mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">W</mml:mi> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004566.e043"><alternatives><graphic id="pcbi.1004566.e043g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e043"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover> <mml:mo>≈</mml:mo> <mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>α</mml:mi> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. In this case, the first term of the gradient descent expression for <italic>w</italic><sub><italic>ij</italic></sub> becomes <inline-formula id="pcbi.1004566.e044"><alternatives><graphic id="pcbi.1004566.e044g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e044"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>α</mml:mi></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. In the common cases where <italic>x</italic><sub><italic>i</italic></sub> and <inline-formula id="pcbi.1004566.e045"><alternatives><graphic id="pcbi.1004566.e045g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e045"/><mml:math id="M45" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> are both zero or are both nonzero, this gives the approximate gradient descent rule which the network should follow:
<disp-formula id="pcbi.1004566.e046"><alternatives><graphic id="pcbi.1004566.e046g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e046"/><mml:math id="M46" display="block" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>α</mml:mi></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="8.0pt"/><mml:mtext>(Scaled</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>autoencoder</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>rule)</mml:mtext></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
Our goal will be to show that biologically realistic synaptic plasticity rules used by the neurons in our network can implement this scaled autoencoder rule both for feedforward and feedback connections.</p>
<sec id="sec005">
<title>Mirrored STDP rule leads to learning of symmetric connections</title>
<p>In our model, feedforward weights between any two neurons <italic>i</italic> and <italic>j</italic> are learned according to the commonly used additive STDP paradigm (<xref ref-type="fig" rid="pcbi.1004566.g002">Fig 2a</xref>), which specifies weight changes due to each pair of spikes in the two neurons. STDP captures the fact that in many biological synapses, the direction of plasticity depends on the relative timing of pre- vs post-synaptic activity [<xref ref-type="bibr" rid="pcbi.1004566.ref029">29</xref>]. The identities of the pre- and post-synaptic neurons depend on the connection direction: for a connection running from neuron <italic>i</italic> to neuron <italic>j</italic>, neuron <italic>i</italic> is the pre-synaptic one and <italic>j</italic> is post-synaptic. Under STDP, if the pre-synaptic neuron spikes first and is closely followed by a postsynaptic spike, the connection is strengthened. Conversely, if the post-synaptic neuron spikes first, the connection is weakened. The magnitude of the depression or potentiation decreases exponentially with the absolute value of the timing difference. When multiple spikes are fired, the weight change is the sum of the individual change calculated from all possible spike pairs. If <inline-formula id="pcbi.1004566.e047"><alternatives><graphic id="pcbi.1004566.e047g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e047"/><mml:math id="M47" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004566.e048"><alternatives><graphic id="pcbi.1004566.e048g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e048"/><mml:math id="M48" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>o</mml:mi> <mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> are the sets of spikes of the pre- and post-synaptic neurons, respectively, and <italic>t</italic><sub><italic>k</italic></sub> is the time of the spike <italic>k</italic>, the STDP learning rule is given by:
<disp-formula id="pcbi.1004566.e049"><alternatives><graphic id="pcbi.1004566.e049g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e049"/><mml:math id="M49" display="block" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>o</mml:mi> <mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>-</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mspace width="8.0pt"/><mml:mtext>(STDP,</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>used</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>for</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>feedforward</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>connections)</mml:mtext> <mml:mspace width="4.pt"/></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula></p>
<fig id="pcbi.1004566.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Plasticity rules.</title>
<p>Each plot shows plasticity from spikes <italic>k</italic> and <italic>l</italic> from a visible and hidden neuron, respectively, which occur at times <italic>t</italic><sub><italic>k</italic></sub> and <italic>t</italic><sub><italic>l</italic></sub>. Red cross and blue triangle show learning from the two example dashed spikes in <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref> for feedforward and feedback connections, respectively. Note different <italic>x</italic>-axes on each plot. <bold>a:</bold> Standard STDP rule. Used for feedforward connections in the model, for which spike <italic>l</italic> is post-synaptic. <italic>x</italic>-axis shows time difference between post- and pre-synaptic spikes. The example spikes would strengthen the feedforward connection (red cross) but weaken the feedback connection, if feedback followed this rule (blue triangle). <bold>b:</bold> aSTDP rule, in which the time dependence is reversed. Used for feedback connections, for which spike <italic>k</italic> is post-synaptic. Learning rate is scaled by a constant <italic>ζ</italic>/<italic>η</italic> relative to STDP. <bold>c:</bold> Combined mSTDP rule. <italic>x</italic>-axis shows time difference between hidden and visible spikes, leading to identical profiles for STDP and aSTDP. Feedforward and feedback learning is symmetric (red cross and blue triangle).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g002"/>
</fig>
<p>Here, <italic>η</italic> is the learning rate and <italic>τ</italic><sub>+</sub> and <italic>τ</italic><sub>−</sub> are timescales for synaptic potentiation and depression, respectively; for biological synapses, these are typically on the order of tens of milliseconds.</p>
<p>Motivated by two experimental results, we use a slightly different plasticity rule for our feedback connections. First, feedback connections in cortex tend to be at synapses far out on the dendrites of the post-synaptic neuron, unlike feedforward connections which usually arrive close to the cell body (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1c</xref>) [<xref ref-type="bibr" rid="pcbi.1004566.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref049">49</xref>]. Second, in several cortical systems, plasticity at distal synapses has been observed to have a reversed temporal dependence as compared with traditional STDP [<xref ref-type="bibr" rid="pcbi.1004566.ref050">50</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref052">52</xref>]. We have previously postulated [<xref ref-type="bibr" rid="pcbi.1004566.ref034">34</xref>] that feedback synapses themselves experience anti-Hebbian STDP [<xref ref-type="bibr" rid="pcbi.1004566.ref053">53</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref055">55</xref>], or “aSTDP”, which is temporally reversed compared with standard STDP. With aSTDP, pre-synaptic activity occurring before post-synaptic activity leads to depression, and vice versa. The aSTDP rule is given by (<xref ref-type="fig" rid="pcbi.1004566.g002">Fig 2b</xref>):
<disp-formula id="pcbi.1004566.e050"><alternatives><graphic id="pcbi.1004566.e050g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e050"/><mml:math id="M50" display="block" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>ζ</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>o</mml:mi> <mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>-</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mspace width="8.0pt"/><mml:mtext>(aSTDP,</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>used</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>for</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>feedback</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>connections)</mml:mtext></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula>
This differs from <xref ref-type="disp-formula" rid="pcbi.1004566.e049">Eq (10)</xref> only in the directions of the greater than/less than signs and in the use of ζ as a learning rate, potentially different from that for STDP.</p>
<p>Critically, we note that for feedforward connections, visible units are pre-synaptic—but the reverse is true for feedback connections (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1c</xref>). We can use this fact to update <xref ref-type="disp-formula" rid="pcbi.1004566.e049">Eq (10)</xref> by replacing <inline-formula id="pcbi.1004566.e051"><alternatives><graphic id="pcbi.1004566.e051g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e051"/><mml:math id="M51" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> with the set of visible neuron spikes <inline-formula id="pcbi.1004566.e052"><alternatives><graphic id="pcbi.1004566.e052g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e052"/><mml:math id="M52" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, and similarly update <xref ref-type="disp-formula" rid="pcbi.1004566.e050">Eq (11)</xref> by replacing <inline-formula id="pcbi.1004566.e053"><alternatives><graphic id="pcbi.1004566.e053g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e053"/><mml:math id="M53" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> with the set of <italic>hidden</italic> neuron spikes <inline-formula id="pcbi.1004566.e054"><alternatives><graphic id="pcbi.1004566.e054g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e054"/><mml:math id="M54" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. After making analogous replacements for <inline-formula id="pcbi.1004566.e055"><alternatives><graphic id="pcbi.1004566.e055g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e055"/><mml:math id="M55" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>o</mml:mi> <mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, we see that, up to a constant, the equations have become identical. We call this combined learning rule mSTDP, for mirrored STDP (<xref ref-type="fig" rid="pcbi.1004566.g002">Fig 2c</xref>):
<disp-formula id="pcbi.1004566.e056"><alternatives><graphic id="pcbi.1004566.e056g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e056"/><mml:math id="M56" display="block" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>η</mml:mi> <mml:mi>ζ</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">S</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mrow><mml:mo>-</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>/</mml:mo></mml:mrow> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>-</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mspace width="8.0pt"/><mml:mtext>(mSTDP,</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>for</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>feedforward</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>and</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>feedback</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>connections)</mml:mtext></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
Thus, under mSTDP the plasticity due to any pair of visible and hidden spikes will be the same for the feedforward connections as for the feedback connections, up to a scaling factor. We note that if we had instead used simple STDP for both feedforward and feedback connections, the plasticity for any pair of spikes would have had the opposite sign for the the two directions—exactly the opposite of the symmetry needed for autoencoder learning (<xref ref-type="fig" rid="pcbi.1004566.g002">Fig 2a</xref>, blue triangle and red cross.)</p>
<p>If the weights are initially symmetric up to a scaling factor, such that <inline-formula id="pcbi.1004566.e057"><alternatives><graphic id="pcbi.1004566.e057g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e057"/><mml:math id="M57" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>η</mml:mi> <mml:mi>ζ</mml:mi></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, mSTDP will maintain that symmetry. Moreover, if the weights are initially small but non-symmetric, mSTDP learning will eventually make them approximately symmetric [<xref ref-type="bibr" rid="pcbi.1004566.ref056">56</xref>]. This symmetry is assumed in many neural network models (from Hopfield [<xref ref-type="bibr" rid="pcbi.1004566.ref057">57</xref>] onward), but here we have shown how it can arise naturally from biologically realistic assumptions. We note that these scaled weights will lead to to a scaled feedback reconstruction, as described earlier, and identify <inline-formula id="pcbi.1004566.e058"><alternatives><graphic id="pcbi.1004566.e058g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e058"/><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:mi>α</mml:mi> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mi>η</mml:mi> <mml:mi>ζ</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. In our simulations, for the first experiment we use the approximation that symmetric plasticity has already led to symmetric weights, and henceforth apply the substitution <inline-formula id="pcbi.1004566.e059"><alternatives><graphic id="pcbi.1004566.e059g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e059"/><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>→</mml:mo> <mml:mfrac><mml:mi>η</mml:mi> <mml:mi>ζ</mml:mi></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, but in the second experiment we initialize <bold>W</bold> and <bold>Q</bold> separately and measure how quickly they become symmetric.</p>
</sec>
<sec id="sec006">
<title>Spiking network implements scaled autoencoder learning rule</title>
<p>To begin our analysis of the effects of the mSTDP learning rule, we consider the timing of the three bouts of activity in our network (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref>). We note that early visible layer spikes occur before hidden layer spikes, while late visible layer spikes due to feedback occur after the hidden layer spikes. Defining <italic>S</italic><sub><italic>i</italic>,E</sub> and <italic>S</italic><sub><italic>i</italic>,L</sub> as the sets of early and late visible layer spikes, respectively, and <italic>S</italic><sub><italic>j</italic></sub> as the set of hidden layer spikes, the mSTDP learning rule becomes:
<disp-formula id="pcbi.1004566.e060"><alternatives><graphic id="pcbi.1004566.e060g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e060"/><mml:math id="M60" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>η</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle> <mml:mo>−</mml:mo> <mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:msup><mml:mi>k</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>∈</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:msup><mml:mi>l</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>∈</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:msup><mml:mi>k</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:msup><mml:mi>l</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
We next approximate the time differences (<italic>t</italic><sub><italic>l</italic></sub> − <italic>t</italic><sub><italic>k</italic></sub>) by the average time between the early and intermediate activity bouts, which we call Δ<italic>t</italic><sub>1</sub> (<xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref>). We similarly approximate (<italic>t</italic>′<sub><italic>l</italic></sub> − <italic>t</italic>′<sub><italic>k</italic></sub>) by the average time between the intermediate and late activity bouts, Δ<italic>t</italic><sub>2</sub>; we can now move the exponential terms outside the sums. We recall that the spike counts in the three bouts are given by <inline-formula id="pcbi.1004566.e061"><alternatives><graphic id="pcbi.1004566.e061g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e061"/><mml:math id="M61" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1004566.e062"><alternatives><graphic id="pcbi.1004566.e062g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e062"/><mml:math id="M62" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1004566.e063"><alternatives><graphic id="pcbi.1004566.e063g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e063"/><mml:math id="M63" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, so we finally have
<disp-formula id="pcbi.1004566.e064"><alternatives><graphic id="pcbi.1004566.e064g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e064"/><mml:math id="M64" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>η</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>≈</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:msup> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:mi>β</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>γ</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula>
for <italic>β</italic> = <italic>e</italic><sup>−Δ<italic>t</italic><sub>1</sub>/<italic>τ</italic><sub>+</sub></sup> and <italic>γ</italic> = <italic>e</italic><sup>−Δ<italic>t</italic><sub>2</sub>/<italic>τ</italic><sub>−</sub></sup>. A similar result holds if we do not approximate the times of the spikes but instead integrate over the shape of their distribution: If the density of spikes in the first bout is given by <italic>x</italic><sub><italic>i</italic></sub> <italic>d</italic><sub><italic>x</italic></sub>(<italic>t</italic>)<italic>dt</italic>, where <italic>d</italic><sub><italic>x</italic></sub>(<italic>t</italic>)<italic>dt</italic> integrates to 1 and is zero for times outside the bout, and if we define similar densities for the other bouts, then the learning rule is <inline-formula id="pcbi.1004566.e065"><alternatives><graphic id="pcbi.1004566.e065g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e065"/><mml:math id="M65" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>η</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>≈</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup> <mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1pt"/> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:msub></mml:mrow></mml:mrow></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:msup> <mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1pt"/><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> This has the same form as <xref ref-type="disp-formula" rid="pcbi.1004566.e064">Eq 14</xref>, except with different values for <italic>β</italic> and <italic>γ</italic>. In either case, our learning rule becomes
<disp-formula id="pcbi.1004566.e066"><alternatives><graphic id="pcbi.1004566.e066g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e066"/><mml:math id="M66" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>η</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>ζ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:mfrac> <mml:mo>Δ</mml:mo> <mml:msubsup><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow><mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>≈</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mfrac><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:msubsup><mml:mi>y</mml:mi> <mml:mi>j</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula>
If parameters are such that <inline-formula id="pcbi.1004566.e067"><alternatives><graphic id="pcbi.1004566.e067g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e067"/><mml:math id="M67" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>α</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, this is exactly proportional to the desired autoencoder learning ruley <inline-formula id="pcbi.1004566.e068"><alternatives><graphic id="pcbi.1004566.e068g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e068"/><mml:math id="M68" display="inline" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi mathvariant="normal">W</mml:mi> <mml:mspace width="1pt"/> <mml:mtext>=</mml:mtext> <mml:mspace width="1pt"/> <mml:mo stretchy="false">(</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>α</mml:mi></mml:mfrac> <mml:mover accent="true"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>^</mml:mo></mml:mover> <mml:mo stretchy="false">)</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Concluding, we have shown that biologically plausible plasticity rules for feedforward and feedback connections in our spiking network cause it to approximately follow the scaled autoencoder learning rule. With our simulations, we will examine whether this approximation does in fact allow the network to minimize reconstruction error.</p>
</sec>
<sec id="sec007">
<title>Synaptic scaling for sparsity</title>
<p>In order to learn sparse representations, autoencoder networks require additional regularizations or constraints. Here, we use a very simple mechanism with a clear biological interpretation: throughout the course of training, we adjusted each hidden neuron’s responsiveness to synaptic inputs so that it would maintain a low target average activity rate. This can be seen as an implementation of the experimentally observed phenomenon known as synaptic scaling [<xref ref-type="bibr" rid="pcbi.1004566.ref035">35</xref>–<xref ref-type="bibr" rid="pcbi.1004566.ref037">37</xref>]. Different values of the target activity rate correspond to different levels of sparsity in the learned representation; when the target activity rate is high, most hidden neurons respond to any given stimulus and the representation is very distributed. By contrast, for low target activity rates, most hidden neurons respond only to a small fraction of stimuli, leading to a sparse representation.</p>
</sec>
</sec>
<sec id="sec008">
<title>Simulation results in spiking networks</title>
<p>We numerically simulated a network of LIF neurons. Because of spiking neurons’ nonlinear responses to input, the variable time courses of activity in the network, and the exponential STDP rules, a LIF network does not exactly follow the scaled autoencoder learning rule given in <xref ref-type="disp-formula" rid="pcbi.1004566.e046">Eq (9)</xref>. Moreover, the autoencoder learning rule itself performs only an approximate gradient descent on the reconstruction error. Our numerical simulations allowed us to investigate whether the LIF network could minimize the autoencoder loss function while still maintaining sparsity. (<xref ref-type="supplementary-material" rid="pcbi.1004566.s002">S1</xref>–<xref ref-type="supplementary-material" rid="pcbi.1004566.s008">S7</xref> Tables).</p>
<p>The architecture of our simulated network was the same as that in <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1a</xref>, except that to control overall activity levels we included a pool of <italic>N</italic><sub>inh</sub> inhibitory neurons in each layer (<xref ref-type="fig" rid="pcbi.1004566.g003">Fig 3</xref>). The inhibitory neurons in each pool were connected reciprocally with every excitatory neuron in the layer. Connection weights to and from inhibitory neurons did not change during the simulations.</p>
<fig id="pcbi.1004566.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Model architecture for the integrate-and-fire simulations, including pools of inhibitory neurons in each layer.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g003"/>
</fig>
<p>Our model neurons were conductance-based leaky integrate-and-fire neurons with a spike frequency adaptation term, similar to those in [<xref ref-type="bibr" rid="pcbi.1004566.ref058">58</xref>] (<xref ref-type="supplementary-material" rid="pcbi.1004566.s007">S6 Table</xref>). In our first experiment, where we trained the network with the MNIST dataset of handwritten numerals, synaptic weights from the visible and hidden units could take on positive or negative values. In our second experiment, where we trained the network with natural image patches, we imposed more biologically realistic constraints, and restricted weights from visible and hidden units to be positive only.</p>
<sec id="sec009">
<title>Synaptic scaling</title>
<p>To implement synaptic scaling in the MNIST experiment, we defined for each hidden neuron <italic>j</italic> a property <italic>ϕ</italic><sub><italic>j</italic></sub> that we called the “synaptic offset”. We used this to modify each of that neuron’s incoming synaptic connections, creating effective weights <inline-formula id="pcbi.1004566.e069"><alternatives><graphic id="pcbi.1004566.e069g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e069"/><mml:math id="M69" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. In practice, this approach is very similar to a threshold modification [<xref ref-type="bibr" rid="pcbi.1004566.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004566.ref012">12</xref>] or to a standard neural network bias term, and it has consistent effects whether weights are positive or negative.</p>
<p>By contrast, in the natural image patches experiment, we implemented synaptic scaling with a multiplicative factor <italic>Φ</italic><sub><italic>j</italic></sub>, for effective weights <inline-formula id="pcbi.1004566.e070"><alternatives><graphic id="pcbi.1004566.e070g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e070"/><mml:math id="M70" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>×</mml:mo> <mml:msub><mml:mi>Φ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Because the weights were non-negative, neurons could consistently increase or decrease their net excitation, and thus their average activity, by increasing or decreasing this scaling factor.</p>
<p>Biological synaptic scaling typically has <italic>multiplicative</italic> effects on individual synaptic weights, but the scaling factors can differ between excitatory and inhibitory inputs [<xref ref-type="bibr" rid="pcbi.1004566.ref037">37</xref>], leading to additive as well as multiplicative effects on net synaptic inputs. Our synaptic offsets <italic>ϕ</italic><sub><italic>j</italic></sub> can be seen as modeling just the additive components of synaptic scaling, whereas the scaling factors <italic>Φ</italic><sub><italic>j</italic></sub> directly model multiplicative synaptic scaling on the excitatory weights.</p>
<p>During both experiments, we kept a running average <italic>A</italic><sub><italic>j</italic></sub> of the fraction of trials when each hidden unit fired at least one spike. We compared <italic>A</italic><sub><italic>j</italic></sub> to a target activation rate <italic>ρ</italic>, and after each trial changed <italic>ϕ</italic><sub><italic>j</italic></sub> or <italic>Φ</italic><sub><italic>j</italic></sub> according to Δ<italic>ϕ</italic><sub><italic>j</italic></sub> (or Δ<italic>Φ</italic><sub><italic>j</italic></sub>) = <italic>β</italic>(<italic>ρ</italic> − <italic>A</italic><sub><italic>j</italic></sub>) for learning rate <italic>β</italic> (<xref ref-type="supplementary-material" rid="pcbi.1004566.s006">S5 Table</xref>).</p>
</sec>
<sec id="sec010">
<title>Training procedure</title>
<p>For the MNIST dataset, each of 50,000 training images was down-sampled to 14x14 pixels and the mean value across the training set was subtracted from each pixel before images are doubled to 392 ON/OFF input pixels. For each input, a Poisson train of input spikes was generated with mean rate equal to the pixel value of the input. Our network had 5,000 hidden units and was trained for two passes through the training set. We used a target activation rate <italic>ρ</italic> = 0.03, meaning that each hidden unit should fire at least one spike for approximately 3% of stimuli. For the second dataset, we used 16x16 pixel patches taken from the whitened natural images used in [<xref ref-type="bibr" rid="pcbi.1004566.ref016">16</xref>], which we mean-subtracted and doubled to 512 pixel inputs. We found that many of the patches had no high-contrast features; these patches activated the visible neurons only weakly and did not produce any activity in hidden units (and thus no learning.) For speeding up our simulations, then, we restricted training to high-contrast patches where the average value in the pre-processed patch was at least 0.06. We trained the network with 500 hidden units on 300,000 randomly selected high-contrast patches with a target activation rate of <italic>ρ</italic> = 0.02.</p>
<p>For each training stimulus, the network spiking response was calculated and feedforward and feedback weights were changed according to <xref ref-type="disp-formula" rid="pcbi.1004566.e056">Eq 12</xref>. The learning rates were the same for feedforward and feedback weights. For the MNIST experiments, feedforward and feedback weights were initialized with symmetrical values, and <xref ref-type="disp-formula" rid="pcbi.1004566.e056">Eq 12</xref> exactly maintained this symmetry. For the more biologically realistic natural image patch experiments, the feedforward and feedback weights were independently initialized to random values.</p>
</sec>
<sec id="sec011">
<title>Learned hidden unit receptive fields</title>
<p>In <xref ref-type="fig" rid="pcbi.1004566.g004">Fig 4a</xref>, we show the incoming weights <italic>w</italic><sub><italic>ij</italic></sub> or “receptive fields” for 100 out of the 5,000 hidden neurons in the MNIST network. For visualization, the weights from the visible cells with OFF inputs were subtracted from the weights from the visible cells with ON inputs. The network learned hidden-unit input weights with complex spatial structures (<xref ref-type="fig" rid="pcbi.1004566.g004">Fig 4a</xref>) somewhere between full digits and individual strokes. The development of the weights over time is shown in <xref ref-type="fig" rid="pcbi.1004566.g005">Fig 5</xref>, along with attempted reconstructions made with the weights at several different points in training. At the earliest time, the few hidden units that happened to have strong incoming weights would respond to any stimulus, making the different attempted reconstructions very similar.</p>
<fig id="pcbi.1004566.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Feedforward weights after training for the MNIST and natural image patch datasets.</title>
<p><bold>a:</bold> Weights learned from the MNIST dataset. Each square in the grid represents the incoming weights to a single hidden unit; weights to the first 100 hidden units are shown. Weights from visible neurons which receive OFF inputs are subtracted from the weights from visible neurons which receive ON inputs. Then, weights to each neuron are normalized by dividing by the largest absolute value. <bold>b:</bold> Same as (a), but for the natural image patch dataset.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g004"/>
</fig>
<fig id="pcbi.1004566.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Evolution of weights and reconstructions in the spiking model.</title>
<p><bold>a–b</bold>: Evolution of weights in the spiking model. Weights as learned after different numbers of stimulus presentations are shown for 10 example hidden units. <bold>c–d</bold>: Attempted reconstructions at different points in training for the two spiking model experiments, for the stimuli shown in the bottom rows. Early in training, the same few hidden units whose incoming weights happened to be strongest were often activated regardless of the stimulus, leading to similar reconstruction attempts for different stimuli (first rows). Over time, the attempted reconstructions came to resemble the input stimuli.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g005"/>
</fig>
<p>In contrast to MNIST, the receptive fields learned by the natural image patch dataset (<xref ref-type="fig" rid="pcbi.1004566.g004">Fig 4b</xref>) were compact. They resembled the Gabor filters found in simple cells of primary visual cortex. Most receptive fields had two or more slightly elongated subregions receiving inputs from ON or OFF visible units.</p>
</sec>
<sec id="sec012">
<title>Autoencoder performance</title>
<p>
<xref ref-type="fig" rid="pcbi.1004566.g006">Fig 6a</xref> shows an example raster plot of network activity for all the neurons that spiked during a single MNIST stimulus presentation after training was completed. (Compare with <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref>). There were 255 active visible neurons, 198 hidden ones, 1,175 active visible inhibitory neurons, and 962 hidden inhibitory neurons. The visible unit activity during the initial phase, from 0–10ms, was similar (but not identical) to that during the final reconstruction phase, from about 10–20ms. There were slightly fewer spikes in the later phase, corresponding to scaled feedback weights, but the general pattern is similar, indicating that the network has learned to reconstruct the inputs.</p>
<fig id="pcbi.1004566.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Behavior of the simulated spiking network for the MNIST dataset.</title>
<p><bold>a:</bold> Behavior of the network during a typical image presentation; compare with <xref ref-type="fig" rid="pcbi.1004566.g001">Fig 1b</xref>. Time period of external stimulation shown by grey bar. Raster plot includes all neurons which fired at least one spike during the presentation. The spikes of the visible neurons are in the bottom row and those of the hidden neurons are directly above. The top two rows, in grey, show the spikes for the inhibitory pools at each layer. Although the each training presentation ran for 65ms, all spikes occurred before 30ms so the raster plot was ended there. <bold>b:</bold> Reconstruction loss function, black dots, (defined in text) decreases over time, as does sparsity loss function (red, note log scale on y axis). <bold>c</bold>: The trained networks’ attempted reconstruction of representative training images. Each image shows the ON cell values minus the OFF cells. The first row shows the inputs to the network. The second row shows the attempted reconstruction <inline-formula id="pcbi.1004566.e071"><alternatives><graphic id="pcbi.1004566.e071g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e071"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g006"/>
</fig>
<p>We note that the onset latency for hidden unit activity was between 5 and 10ms, and that most hidden units which produced spikes did so near the end of the initial bout of visible unit spikes. This onset delay was slightly shorter than the latency differences between visual areas in the primate visual system [<xref ref-type="bibr" rid="pcbi.1004566.ref059">59</xref>], and was not due to the synaptic transmission delay, which was 2ms; instead, the delay occurred because the network had learned feedforward weights which were weak enough that hidden units needed to integrate many incoming spikes before they could fire. These weak feedforward weights were maintained because any hidden units with strong incoming weights would fire earlier, while initial visible unit activity was ongoing; initial visible spikes occurring after the hidden unit spikes would cause depression instead of potentiation, and the hidden unit’s incoming weights would be weakened in the future.</p>
<p>To quantify how the network’s reconstruction ability changed over the course of training, we periodically disabled plasticity and calculated the network’s response to the same 100 test images. For each test presentation, we recorded the network inputs <inline-formula id="pcbi.1004566.e072"><alternatives><graphic id="pcbi.1004566.e072g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e072"/><mml:math id="M72" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and calculated <inline-formula id="pcbi.1004566.e073"><alternatives><graphic id="pcbi.1004566.e073g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e073"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as the number of hidden neuron spikes. We measured the network’s feedback excitation as <inline-formula id="pcbi.1004566.e074"><alternatives><graphic id="pcbi.1004566.e074g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e074"/><mml:math id="M74" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, and calculated a reconstruction loss as:
<disp-formula id="pcbi.1004566.e075"><alternatives><graphic id="pcbi.1004566.e075g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e075"/><mml:math id="M75" display="block" overflow="scroll"><mml:mrow><mml:mtext>Reconstruction</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>loss</mml:mtext> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mo form="prefix">corr</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(16)</label></disp-formula>
We defined average hidden unit activity levels <italic>A</italic><sub><italic>j</italic></sub> = ⟨<italic>y</italic><sub><italic>j</italic></sub> &gt; 0⟩, where the average was taken across all test stimuli. We then defined a sparsity loss function as:
<disp-formula id="pcbi.1004566.e076"><alternatives><graphic id="pcbi.1004566.e076g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e076"/><mml:math id="M76" display="block" overflow="scroll"><mml:mrow><mml:mtext>Sparsity loss</mml:mtext> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>‖</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>ρ</mml:mi> <mml:mo>‖</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>/</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula></p>
<p>In <xref ref-type="fig" rid="pcbi.1004566.g006">Fig 6b</xref>, we plotted both of these losses. The network quickly improved its reconstruction ability, arriving at reconstructions that were on average 80% correlated with their inputs. Meanwhile, lifetime sparsity was closely maintained. We conclude that the network successfully minimized its reconstruction error.</p>
<p>
<xref ref-type="fig" rid="pcbi.1004566.g006">Fig 6c</xref> shows reconstructions for 10 representative input stimuli at the network’s final trained weights. The first row shows the input stimulus and the second row shows <inline-formula id="pcbi.1004566.e077"><alternatives><graphic id="pcbi.1004566.e077g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004566.e077"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi> <mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> (always with the OFF unit values subtracted from the ON unit values.) In all cases, the reconstructions closely resembled the inputs.</p>
<p>We obtained similar results for the natural images dataset (<xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7</xref>), albeit with substantially decreased final reconstruction performance. In the example presentation shown in the raster plot (<xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7a</xref>), there were 311 active visible neurons, 25 hidden ones, 1,692 active visible inhibitory neurons, and 981 hidden inhibitory neurons. Initial visible unit spiking stopped while the input was still active, due to the influence of inhibition and spike frequency adaptation. The main difference, as compared to the MNIST dataset, is that the correlation between the input and the reconstruction remains at just below 35% (<xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7b</xref>). The attempted reconstructions in <xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7d</xref> captured many of the important features of the inputs but differed in the details. Light and dark areas in the reconstruction generally correspond to similar features in the stimulus, but many fine features, in particular thin and elongated features, are missed. Consequently, stimuli with wide features, such as the third stimulus in <xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7d</xref>, are reconstructed with considerable success, while the network fails to adequately reconstruct the sixth stimulus in this Fig., which contains a prominent narrow line. Reconstruction performance could be improved slightly by increasing excitability in the network after training. We tried increasing each hidden unit’s scaling factor <italic>Φ</italic><sub><italic>j</italic></sub> by 50% during our reconstruction testing steps. This allowed more hidden neurons to become active during each presentation, including some which would otherwise have received only sub-threshold excitation. The activation of additional hidden units allowed reconstruction performance to improve visually in some cases (<xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7</xref>); for instance, the curve in the upper-right-hand corner of the final stimulus is more fully traced out, and the dark band in the center of the first stimulus is more filled in. But the additional excitation did not fully resolve the difficulties in reconstruction; for example, in the second-to-last stimulus, the network is only able to reproduce about half of the black diagonal band across the center, and the reconstruction in the sixth stimulus is still poor. Quantitatively, correlations increased from between 1%-5% when tested at different points in training (<xref ref-type="supplementary-material" rid="pcbi.1004566.s001">S1 Fig</xref>).</p>
<fig id="pcbi.1004566.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Behavior of the simulated spiking network for the natural image patch dataset.</title>
<p><bold>a–d:</bold> As <xref ref-type="fig" rid="pcbi.1004566.g006">Fig 6</xref>, with addition of <bold>c</bold>, which shows the Pearson correlation coefficient between the feedback weights <bold>Q</bold> and the feedforward weights <bold>W</bold> as they become symmetric over time. Because of the sparsity constraint on learning, the network cannot learn a perfect representation, so final autoencoder loss is still quite large (b), but the network nevertheless captures many salient features when attempting reconstruction (d). <bold>e</bold>: Reconstruction attempts for the same input stimuli as in (d), when the scaling factors Φ<sub><italic>j</italic></sub> were uniformly multiplied by 1.5 after training.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g007"/>
</fig>
</sec>
<sec id="sec013">
<title>Network learns distributed representations</title>
<p>We have argued that an important strength of autoencoders is their ability to learn distributed representations without requiring the hidden units to be uncorrelated. To show that our network is not in the uncorrelated regime, we studied the stimulus-dependent correlations of the hidden unit receptive fields and activity. <xref ref-type="fig" rid="pcbi.1004566.g008">Fig 8a</xref> shows a histogram of the Pearson correlation coefficients between the vectors of incoming weights for each pair of hidden units in the trained MNIST network. Some pairs had positive correlations, indicating that the neurons could be excited by similar stimuli, while other pairs had negative correlations, meaning they would be unlikely to be activated at the same time. We confirmed that this implied correlated firing rates by measuring the responses of hidden units to 1,000 stimulus presentations, and calculating the Pearson correlation coefficients between the two vectors of spike counts for each neuron pair (<xref ref-type="fig" rid="pcbi.1004566.g008">Fig 8b</xref>). Because firing rates could not go below zero, this distribution was biased towards positive values. <xref ref-type="fig" rid="pcbi.1004566.g008">Fig 8c and 8d</xref> show similar results for natural image patches. We thus confirmed that our algorithm neither requires nor enforces hidden unit decorrelation.</p>
<fig id="pcbi.1004566.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Hidden unit correlations after training.</title>
<p>Neither the incoming weights nor the spiking activity is uncorrelated between hidden units. <bold>a:</bold> Correlations of the final trained synaptic weights between every pair of hidden units in the MNIST network. <bold>b:</bold> Correlations of the spike numbers from 1,000 stimulus presentations between every pair of hidden neurons for MNIST. <bold>c–d:</bold> Same, for the natural image network.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g008"/>
</fig>
<p>
<xref ref-type="fig" rid="pcbi.1004566.g009">Fig 9</xref> shows how multiple hidden units in our networks jointly represent each stimulus input. Using 5 example input stimuli for each of our two datasets, we selected the 10 hidden units which fired the most spikes in response to that input. We plotted the receptive fields for these hidden units in order, with the most strongly activated on the left. The reconstruction, calculated from all hidden units, is shown in the final column.</p>
<fig id="pcbi.1004566.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Highly activated weights for example image presentations in the two datasets.</title>
<p><bold>a:</bold> Weights for the MNIST dataset. First column shows 5 example inputs. Next 10 columns show the receptive fields of the 10 hidden units most activated for that input. Opacity codes the relative strength of the hidden unit’s responses with respect to the most active hidden unit; weakly activated hidden units are drawn nearly transparent. Final column shows the network’s attempted construction as measured by the late-time spike count. <bold>b:</bold> Same as (a), but for the the natural image patch dataset.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g009"/>
</fig>
<p>For MNIST (<xref ref-type="fig" rid="pcbi.1004566.g009">Fig 9a</xref>), some stimuli were well-matched by a single unit’s receptive field (for example, the bottom-most digit “1” stimulus.) However, others were not well-matched, and instead activated many hidden units. The “4” in the fourth row activated many hidden units, each of which differed from the input stimulus, but which nevertheless jointly created a very good reconstruction. This ability is dependent on the existence of a correlated representation; for instance, the first two hidden units in the third row have very similar receptive field structures and are likely to frequently be activated for the same stimuli.</p>
<p>For the natural image dataset (<xref ref-type="fig" rid="pcbi.1004566.g009">Fig 9b</xref>), the network strung together the Gabor-like receptive fields to represent stimuli. Here, because the receptive fields are more spatially localized, the hidden units activated for each stimulus did not typically have overlapping receptive fields. However, this does not mean that the different hidden units had uncorrelated firing responses across stimulus presentations. Indeed, particular groups of hidden units can be frequently co-active even though their receptive fields do not overlap. Consider the last four hidden units in the third row. Combined, these units’ receptive fields form a curve, a white “u” shape on a black background which resembles that seen near the bottom of the input stimulus. In natural images, elongated or curved structures like these are likely to occur relatively frequently, meaning that these four units might often be co-activated, leading to increased pairwise and higher-order correlations between these units. These correlations provide a signal that could be potentially learned by another layer of neurons; for instance, a neuron which learned to respond strongly to these four hidden units would be a curve detector.</p>
</sec>
<sec id="sec014">
<title>The effect of changing the target activity level</title>
<p>The parameter <italic>ρ</italic> determined the level of sparsity in the learned representations, and thus was expected to greatly affect the forms of the hidden unit receptive fields. The results shown above were from simulations with <italic>ρ</italic> = 0.03 and <italic>ρ</italic> = 0.02, for the MNIST and natural image patch datasets, respectively. This corresponded to each hidden unit being active in about 3% or 2% of the stimulus presentations, respectively, which is significantly less than the fraction of neurons in early visual areas seen experimentally to respond to given stimuli [<xref ref-type="bibr" rid="pcbi.1004566.ref014">14</xref>]. Learned hidden unit receptive fields for different values of <italic>ρ</italic> are shown in <xref ref-type="fig" rid="pcbi.1004566.g010">Fig 10</xref>. For <italic>ρ</italic> = 0.001, corresponding to an even more sparse solution, hidden neurons tended to learn individual receptive fields that had larger support (<xref ref-type="fig" rid="pcbi.1004566.g010">Fig 10a and 10b</xref>). However, <xref ref-type="fig" rid="pcbi.1004566.g010">Fig 10a</xref> illustrates a potential shortcoming of the use of synaptic scaling to create sparsity: it can only control “lifetime sparseness” rather than “population sparseness” [<xref ref-type="bibr" rid="pcbi.1004566.ref060">60</xref>]. In <xref ref-type="fig" rid="pcbi.1004566.g010">Fig 10a</xref>, many hidden units have receptive fields that resemble the digit 0. Each individual unit fires very infrequently, but when a stimulus resembling a 0 appears, many units fire at the same time. To achieve true population sparsity, a model with some form of lateral interaction between hidden units would be needed. By contrast, high values of <italic>ρ</italic> meant that many hidden units would work together to represent each stimulus, so there was no requirement that individual receptive fields resemble any part of the stimulus. The MNIST network with <italic>ρ</italic> = 0.3 learned very distributed representations without clear structure to the receptive fields (<xref ref-type="fig" rid="pcbi.1004566.g010">Fig 10c</xref>). This network performed even better on the reconstruction task than the network with <italic>ρ</italic> = 0.03 in the main results, achieving a final reconstruction correlation of 91% compared with 80% for the main results. The natural image patch experiments, where weights were constrained to be non-negative, had difficulties with runaway excitation, and training results are therefore not available.</p>
<fig id="pcbi.1004566.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004566.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Learned hidden unit weights for different target activation rates <italic>ρ</italic>.</title>
<p><bold>a:</bold> Learned weights for the MNIST dataset with <italic>ρ</italic> = 0.001. <bold>b:</bold> Learned weights for the natural image patch dataset with <italic>ρ</italic> = 0.001. <bold>c:</bold> Learned weights for the MNIST dataset with <italic>ρ</italic> = 0.3.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.g010"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>In this work, we propose a detailed and biologically realistic model for how spiking neurons could implement the commonly used unsupervised autoencoder learning algorithm. Our work provides a necessary first step in making biologically realistic models for any of the many unsupervised learning algorithms which include an autoencoder term, ranging from those inspired by machine learning to those inspired by biology, such as Sparse Coding [<xref ref-type="bibr" rid="pcbi.1004566.ref016">16</xref>]. We describe how strong feedforward and weak feedback excitation can drive a pattern of spiking activity that corresponds to the autoencoder’s visible unit input, hidden unit activity, and attempted reconstruction. Given this activity pattern, we show how STDP, a biological learning rule with strong experimental evidence, will cause changes in feedforward synaptic strength that approximate those dictated by the autoencoder learning rule. We argue that pure Hebbian STDP does <italic>not</italic>, however, cause the correct changes for the feedback synapses given this activity pattern. Instead, we draw upon recent experimental evidence to argue that those feedback synapses might learn according to a temporally reversed version of the learning rule, aSTDP, and show how STDP and aSTDP combine in the two-layer network context to form a symmetric learning rule we call mirrored STDP, or mSTDP. Finally, we show how mSTDP can allow both feedforward and feedback synapses to correctly implement the autoencoder learning rule.</p>
<p>We further describe how the network can find sparse representations by requiring its hidden units to fire infrequently. We argue that biological neurons could accomplish this through the experimentally observed process known as synaptic scaling.</p>
<p>This constraint was chosen here for its simplicity, but other forms of regularizers or sparsity constraint would also be compatible with our mirrored STDP model. For instance, in the Olshausen &amp; Field Sparse Coding algorithm [<xref ref-type="bibr" rid="pcbi.1004566.ref016">16</xref>], hidden units in each trial find an optimal sparse steady-state through inhibitory lateral interactions and a term that could be modeled as spike rate adaptation. Once this steady-state is achieved, synaptic plasticity proceeds according to the autoencoder learning rule and could therefore be implemented with a model similar to ours.</p>
<p>Although we show here how networks could use mirrored STDP to implement autoencoder learning, we note that the basic principle can work independently of the specific plasticity mechanism. It only requires two factors. First, the network should have both a sensory-driven feedforward phase and feedback-driven attempted reconstruction phase. Second, during the feedforward phase, correlated firing should increase synaptic strength for both feedforward and feedback connections; in contrast, during the feedback phase, correlated firing should <italic>decrease</italic> synaptic strength. In our model, the decrease in synaptic strength during the feedback phase occurs because of the relative timing of activity in this phase. But similar results could be obtained, for instance, in a spike frequency model of plasticity in which weak firing due to feedback leaves neurons in a depressive regime (e.g. [<xref ref-type="bibr" rid="pcbi.1004566.ref061">61</xref>]).</p>
<p>Several previous spike-timing-based models of unsupervised feature learning have been successful at learning receptive fields that resemble those seen in V1; these include Rank Order Coding using SpikeNET, by Delorme, Perrinet and Thorpe [<xref ref-type="bibr" rid="pcbi.1004566.ref004">4</xref>], and the SAILNet model of Zylberberg and colleagues [<xref ref-type="bibr" rid="pcbi.1004566.ref012">12</xref>]. Neither network can learn a dense distributed code: in Rank Order Coding, only a single hidden unit responds to each local stimulus, while in SAILNet, hidden units are encouraged to be uncorrelated and fire very infrequently. Non-distributed, biologically realistic models have even successfully been extended into mid-level visual areas; for instance, Masquelier and Thorpe have shown that a winner-take-all STDP model was capable of learning good features in the second level of a max-pooling hierarchy [<xref ref-type="bibr" rid="pcbi.1004566.ref005">5</xref>]. We argue that distributed representations are likely to be better models for yet higher visual areas because of their increased representational capacity. However, additional work will be required to elucidate the conditions under which distributed representations—such as those which can be learned by the autoencoder—are warranted, and when the simpler learning mechanisms used in winner-take-all networks will suffice.</p>
<p>We test our model using two-layer networks of simulated integrate-and-fire neurons using two datasets: handwritten digits in the MNIST dataset and whitened natural image patches. In both cases, the network learns distributed hidden unit representations which are capable of reconstructions. However, the reconstruction performance is not as good for the natural image patches as for the MNIST dataset. This may in part be due to the fact that our current implementation only allowed us to explore the extremely sparse regime with low hidden unit activity, since parameters that led to less sparse solutions caused difficulties with runaway excitation during training. Indeed, when we increased the network activity after training by manually increasing synaptic scaling factors by 1.5, reconstruction performance improved (<xref ref-type="fig" rid="pcbi.1004566.g007">Fig 7</xref>). Future work will be required to elucidate whether the training principles described here would continue to function in a more complicated network that is more robust to runaway excitation.</p>
<p>In the case of the natural image patches, the learned feedforward weights resemble those observed in the early mammalian visual system. As such, the autoencoder may be a useful model to consider when studying the development of connections between pyramidal neurons in the lateral geniculate nucleus and primary visual cortex, or between primary and secondary visual cortex. Of course, early visual areas of the brain cannot learn different sets of receptive fields for different stimuli, as in the two datasets we used here. They must learn very general representations that can be used to build more specific representations further up in the cortical hierarchy. However, in those higher brain areas, if specific sets of neurons are activated in response to different types of stimuli (such as faces), it is conceivable that an autoencoder-like algorithm could allow the development of more specialized receptive fields.</p>
<p>By restricting our model neurons in the natural image patch experiments to have non-negative weights, we show that autoencoder learning can work when the neurons follow Dale’s law. However, a true understanding of how sparse response patterns can arise will require a model for the development of selective inhibition. Neurons with purely excitatory receptive fields can exhibit sparse firing when those receptive fields are very small or the excitation very weak. Indeed, the receptive fields learned by our model neurons with the natural image patches were localized to small regions. By contrast, when receptive fields can have inhibitive components, as in our MNIST experiment, neurons can fire in a sparse manner even when the receptive fields are large and complex. Future work is needed to explore how plasticity in inhibitory neurons might help develop these complex receptive fields.</p>
</sec>
<sec id="sec016">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004566.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s001" mimetype="image/tiff" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Reconstruction losses for natural images, calculated using unscaled (dashed line) feedforward weights versus those scaled by a factor of 1.5 (solid line).</title>
<p>Reconstruction losses were calculated for the weights as learned at different points in the training. Weights were always unscaled during the training process, and scaling was applied only during the measurements of reconstruction loss.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s002" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s002" mimetype="application/pdf" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Model summary table.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s003" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s003" mimetype="application/pdf" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>The neuronal populations present in the model.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s004" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s004" mimetype="application/pdf" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>The connectivity between different neuronal populations.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s005" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s005" mimetype="application/pdf" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>The inputs used to train the neural networks.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s006" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s006" mimetype="application/pdf" xlink:type="simple">
<label>S5 Table</label>
<caption>
<title>The equations describing plasticity in the network.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s007" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s007" mimetype="application/pdf" xlink:type="simple">
<label>S6 Table</label>
<caption>
<title>The equations describing the internal dynamics of model neurons.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004566.s008" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004566.s008" mimetype="application/pdf" xlink:type="simple">
<label>S7 Table</label>
<caption>
<title>The specific parameters used in the simulations described in the text.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We wish to thank Gabriel Kreiman and Yali Amit for support and many fruitful discussions during the development of this project, and Nicolas Brunel and Stephanie Palmer for their helpful comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004566.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kohonen</surname> <given-names>T</given-names></name>. <article-title>Self-organized formation of topologically correct feature maps</article-title>. <source>Biol Cybern</source>. <year>1982</year>;<volume>43</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00337288" xlink:type="simple">10.1007/BF00337288</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sirosh</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname> <given-names>R</given-names></name>. <article-title>Cooperative self-organization of afferent and lateral connections in cortical maps</article-title>. <source>Biol Cybern</source>. <year>1994</year>;<volume>71</volume>(<issue>1</issue>):<fpage>65</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00198912" xlink:type="simple">10.1007/BF00198912</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Choe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname> <given-names>R</given-names></name>. <article-title>Self-organization and segmentation in a laterally connected orientation map of spiking neurons</article-title>. <source>Neurocomputing</source>. <year>1998</year> <month>Nov</month>;<volume>21</volume>(<issue>1–3</issue>):<fpage>139</fpage>–<lpage>158</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0925-2312(98)00040-X" xlink:type="simple">10.1016/S0925-2312(98)00040-X</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Delorme</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name>. <article-title>Networks of integrate-and-fire neurons using Rank Order Coding B: Spike timing dependent plasticity and emergence of orientation selectivity</article-title>. <source>Neurocomputing</source>. <year>2001</year> <month>Jun</month>;<volume>38–40</volume>:<fpage>539</fpage>–<lpage>545</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0925-2312(01)00403-9" xlink:type="simple">10.1016/S0925-2312(01)00403-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Masquelier</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name>. <article-title>Unsupervised learning of visual features through spike timing dependent plasticity</article-title>. <source>PLOS Comput Biol</source>. <year>2007</year> <month>Feb</month>;<volume>3</volume>(<issue>2</issue>):<fpage>e31</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0030031" xlink:type="simple">10.1371/journal.pcbi.0030031</ext-link></comment> <object-id pub-id-type="pmid">17305422</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Carlsson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ishkhanov</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Silva</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Zomorodian</surname> <given-names>A</given-names></name>. <article-title>On the Local Behavior of Spaces of Natural Images</article-title>. <source>Int J Comput Vision</source>. <year>2007</year> <month>Dec</month>;<volume>76</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11263-007-0056-x" xlink:type="simple">10.1007/s11263-007-0056-x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Foldiak</surname> <given-names>P</given-names></name>. <article-title>Forming sparse representations by local anti-Hebbian learning</article-title>. <source>Biol Cybern</source>. <year>1990</year> <month>Jan</month>;<volume>64</volume>(<issue>2</issue>):<fpage>165</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02331346" xlink:type="simple">10.1007/BF02331346</ext-link></comment> <object-id pub-id-type="pmid">2291903</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Foldiak</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>MP</given-names></name>. <article-title>Sparse Coding in the Primate Cortex</article-title>. <source>The handbook of brain theory and neural networks</source>. <year>1995</year>;<volume>1</volume>:<fpage>1064</fpage>–<lpage>1068</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Courville</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Vincent</surname> <given-names>P</given-names></name>. <article-title>Representation Learning: A Review and New Perspectives</article-title>. <source>IEEE T Pattern Anal</source>. <year>2013</year> <month>Feb</month>;<volume>35</volume>(<issue>8</issue>):<fpage>1798</fpage>–<lpage>1828</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TPAMI.2013.50" xlink:type="simple">10.1109/TPAMI.2013.50</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Foldiak</surname> <given-names>P</given-names></name>. <article-title>Adaptive network for optimal linear feature extraction</article-title>. <source>IEEE IJCNN</source>. <year>1989</year>;p. <fpage>401</fpage>–<lpage>405</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Falconbridge</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Stamps</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Badcock</surname> <given-names>DR</given-names></name>. <article-title>A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images</article-title>. <source>Neural Comput</source>. <year>2006</year> <month>Feb</month>;<volume>18</volume>(<issue>2</issue>):<fpage>415</fpage>–<lpage>429</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976606775093891" xlink:type="simple">10.1162/089976606775093891</ext-link></comment> <object-id pub-id-type="pmid">16378520</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zylberberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Murphy</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>DeWeese</surname> <given-names>MR</given-names></name>. <article-title>A sparse coding model with synaptically local plasticity and spiking neurons can account for the diverse shapes of V1 simple cell receptive fields</article-title>. <source>PLOS Comput Biol</source>. <year>2011</year> <month>Oct</month>;<volume>7</volume>(<issue>10</issue>):<fpage>e1002250</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002250" xlink:type="simple">10.1371/journal.pcbi.1002250</ext-link></comment> <object-id pub-id-type="pmid">22046123</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Keliris</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Logothetis</surname> <given-names>NK</given-names></name>, <name name-style="western"><surname>Tolias</surname> <given-names>AS</given-names></name>. <article-title>Decorrelated neuronal firing in cortical microcircuits</article-title>. <source>Science</source>. <year>2010</year> <month>Jan</month>;<volume>327</volume>(<issue>5965</issue>):<fpage>584</fpage>–<lpage>587</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1179867" xlink:type="simple">10.1126/science.1179867</ext-link></comment> <object-id pub-id-type="pmid">20110506</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Levy</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Hasson</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>. <article-title>One picture is worth at least a million neurons</article-title>. <source>Curr Biol</source>. <year>2004</year> <month>Jun</month>;<volume>14</volume>(<issue>11</issue>):<fpage>996</fpage>–<lpage>1001</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2004.05.045" xlink:type="simple">10.1016/j.cub.2004.05.045</ext-link></comment> <object-id pub-id-type="pmid">15182673</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hofer</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Ko</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Pichler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Vogelstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ros</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zeng</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex</article-title>. <source>Nat Neurosci</source>. <year>2011</year> <month>Aug</month>;<volume>14</volume>(<issue>8</issue>):<fpage>1045</fpage>–<lpage>1052</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2876" xlink:type="simple">10.1038/nn.2876</ext-link></comment> <object-id pub-id-type="pmid">21765421</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source>. <year>1996</year> <month>Jun</month>;<volume>381</volume>(<issue>6583</issue>):<fpage>607</fpage>–<lpage>609</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/381607a0" xlink:type="simple">10.1038/381607a0</ext-link></comment> <object-id pub-id-type="pmid">8637596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Perrinet</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Samuelides</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>S</given-names></name>. <article-title>Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit</article-title>. <source>Neurocomputing</source>. <year>2004</year> <month>Mar</month>;<volume>57</volume>:<fpage>125</fpage>–<lpage>134</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neucom.2004.01.010" xlink:type="simple">10.1016/j.neucom.2004.01.010</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Oja</surname> <given-names>E</given-names></name>. <article-title>Neural networks, principal components, and subspaces</article-title>. <source>Int J Neural Syst</source>. <year>1989</year>;<volume>1</volume>(<issue>1</issue>):<fpage>61</fpage>–<lpage>68</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1142/S0129065789000475" xlink:type="simple">10.1142/S0129065789000475</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="other">Marroquin JL, Girosi F. Some Extensions of the K-Means Algorithm for Image Segmentation and Pattern Classification. AI Memo No 1390, MIT AI Lab. 1993 Jan;.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="other">Zemel, R. A minimum description length framework for unsupervised learning. PhD Thesis, Department of Computer Science, University of Toronto. 1993 Jan;.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lamblin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Popovici</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Larochelle</surname> <given-names>H</given-names></name>. <article-title>Greedy Layer-Wise Training of Deep Networks</article-title>. <source>Adv Neur In</source>. <year>2007</year> <month>Jun</month>;(<issue>19</issue>):<fpage>153</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="other">Larochelle H, Erhan D, Courville A, Bergstra J. An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation. In: Proc 24th Int Conf Mach Learn; 2007. p. 473–480.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Vincent</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Larochelle</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Lajoie</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Manzagol</surname> <given-names>PA</given-names></name>. <article-title>Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</article-title>. <source>J Mach Learn Res</source>. <year>2010</year>;<volume>11</volume>:<fpage>3371</fpage>–<lpage>3408</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Delalleau</surname> <given-names>O</given-names></name>. <article-title>Justifying and generalizing contrastive divergence</article-title>. <source>Neural Comput</source>. <year>2009</year> <month>Jan</month>;<volume>21</volume>(<issue>6</issue>):<fpage>1601</fpage>–<lpage>1621</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.11-07-647" xlink:type="simple">10.1162/neco.2008.11-07-647</ext-link></comment> <object-id pub-id-type="pmid">19018704</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Harpur</surname> <given-names>GF</given-names></name>, <name name-style="western"><surname>Prager</surname> <given-names>RW</given-names></name>. <article-title>Development of low entropy coding in a recurrent network</article-title>. <source>Network</source>. <year>1996</year> <month>May</month>;<volume>7</volume>(<issue>2</issue>):<fpage>277</fpage>–<lpage>284</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X_7_2_007" xlink:type="simple">10.1088/0954-898X_7_2_007</ext-link></comment> <object-id pub-id-type="pmid">16754387</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fyfe</surname> <given-names>C</given-names></name>. <article-title>A neural network for PCA and beyond</article-title>. <source>Neural Process Lett</source>. <year>1997</year>;<volume>6</volume>(<issue>1–2</issue>):<fpage>33</fpage>–<lpage>41</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1009606706736" xlink:type="simple">10.1023/A:1009606706736</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Salin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Bullier</surname> <given-names>J</given-names></name>. <article-title>Corticocortical Connections in the Visual System: Structure And Function</article-title>. <source>Physiol Rev</source>. <year>1994</year> <month>Dec</month>;<volume>75</volume>(<issue>1</issue>):<fpage>107</fpage>–<lpage>154</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Levy</surname> <given-names>WB</given-names></name>, <name name-style="western"><surname>Steward</surname> <given-names>O</given-names></name>. <article-title>Temporal contiguity requirements for long-term associative potentiation/depression in the hippocampus</article-title>. <source>Neuroscience</source>. <year>1983</year> <month>Apr</month>;<volume>8</volume>(<issue>4</issue>):<fpage>791</fpage>–<lpage>797</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0306-4522(83)90010-6" xlink:type="simple">10.1016/0306-4522(83)90010-6</ext-link></comment> <object-id pub-id-type="pmid">6306504</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bi</surname> <given-names>GQ</given-names></name>, <name name-style="western"><surname>Poo</surname> <given-names>MM</given-names></name>. <article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title>. <source>J Neurosci</source>. <year>1998</year> <month>Dec</month>;<volume>18</volume>(<issue>24</issue>):<fpage>10464</fpage>–<lpage>10472</lpage>. <object-id pub-id-type="pmid">9852584</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Lübke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Frotscher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sakmann</surname> <given-names>B</given-names></name>. <article-title>Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs</article-title>. <source>Science</source>. <year>1997</year> <month>Jan</month>;<volume>275</volume>(<issue>5297</issue>):<fpage>213</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.275.5297.213" xlink:type="simple">10.1126/science.275.5297.213</ext-link></comment> <object-id pub-id-type="pmid">8985014</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>. <article-title>Phenomenological models of synaptic plasticity based on spike timing</article-title>. <source>Biol Cybern</source>. <year>2008</year> <month>Jun</month>;<volume>98</volume>(<issue>6</issue>):<fpage>459</fpage>–<lpage>478</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-008-0233-1" xlink:type="simple">10.1007/s00422-008-0233-1</ext-link></comment> <object-id pub-id-type="pmid">18491160</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Feldman</surname> <given-names>DE</given-names></name>. <article-title>The spike-timing dependence of plasticity</article-title>. <source>Neuron</source>. <year>2012</year> <month>Aug</month>;<volume>75</volume>(<issue>4</issue>):<fpage>556</fpage>–<lpage>571</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.08.001" xlink:type="simple">10.1016/j.neuron.2012.08.001</ext-link></comment> <object-id pub-id-type="pmid">22920249</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schölkopf</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hofmann</surname> <given-names>T</given-names></name>. <article-title>Temporal Coding using the Response Properties of Spiking Neurons</article-title>. In: <source>Adv Neur In</source>; <year>2007</year>. p. <fpage>1457</fpage>–<lpage>1464</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Burbank</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>. <article-title>Depression-biased reverse plasticity rule is required for stable learning at top-down connections</article-title>. <source>PLOS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>3</issue>):<fpage>e1002393</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002393" xlink:type="simple">10.1371/journal.pcbi.1002393</ext-link></comment> <object-id pub-id-type="pmid">22396630</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Turrigiano</surname> <given-names>GG</given-names></name>, <name name-style="western"><surname>Leslie</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Desai</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Rutherford</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>SB</given-names></name>. <article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons</article-title>. <source>Nature</source>. <year>1998</year> <month>Feb</month>;<volume>391</volume>(<issue>6670</issue>):<fpage>892</fpage>–<lpage>896</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/36103" xlink:type="simple">10.1038/36103</ext-link></comment> <object-id pub-id-type="pmid">9495341</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Marder</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Goaillard</surname> <given-names>JM</given-names></name>. <article-title>Variability, compensation and homeostasis in neuron and network function</article-title>. <source>Nat Rev Neurosci</source>. <year>2006</year>;<volume>7</volume>(<issue>7</issue>):<fpage>563</fpage>–<lpage>574</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1949" xlink:type="simple">10.1038/nrn1949</ext-link></comment> <object-id pub-id-type="pmid">16791145</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Karmarkar</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Buonomano</surname> <given-names>DV</given-names></name>. <article-title>Different forms of homeostatic plasticity are engaged with distinct temporal profiles</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>23</volume>(<issue>6</issue>):<fpage>1575</fpage>–<lpage>1584</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>Sparse coding of sensory inputs</article-title>. <source>Curr Opin Neurobiol</source>. <year>2003</year> <month>Dec</month>;<volume>14</volume>(<issue>4</issue>):<fpage>481</fpage>–<lpage>487</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2004.07.007" xlink:type="simple">10.1016/j.conb.2004.07.007</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bhand</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mudur</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Suresh</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Saxe</surname> <given-names>A</given-names></name>. <article-title>Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</article-title>. <source>Adv Neur In</source>. <year>2011</year>;p. <fpage>1971</fpage>–<lpage>1979</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bell</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision Res</source>. <year>1997</year> <month>Dec</month>;<volume>37</volume>(<issue>23</issue>):<fpage>3327</fpage>–<lpage>3338</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(97)00121-1" xlink:type="simple">10.1016/S0042-6989(97)00121-1</ext-link></comment> <object-id pub-id-type="pmid">9425547</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="other">Vincent P, Larochelle H, Bengio Y, Manzagol P. Extracting and composing robust features with denoising autoencoders. Proc 25th Int Conf Mach Learn. 2008;p. 1096–1103.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="other">MacQueen J. Some methods for classification and analysis of multivariate observations. In: Proc Fifth Symp Math Statist Prob; 1967. p. 281–297.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="other">Coates A, Ng AY, Lee H. An Analysis of Single-Layer Networks in Unsupervised Feature Learning. Int Conf Art Int Statist. 2011;p. 215–223.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Xu</surname> <given-names>L</given-names></name>. <article-title>Least MSE reconstruction for self-organization. II. Further theoretical and experimental studies on one-layer nets</article-title>. In: <source>IEEE IJCNN. IEEE</source>; <year>1991</year>. p. <fpage>2368</fpage>–<lpage>2373</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Karhunen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Joutsensalo</surname> <given-names>J</given-names></name>. <article-title>Representation and Separation of Signals Using Nonlinear Pca Type Learning</article-title>. <source>Neural Networks</source>. <year>1994</year>;<volume>7</volume>(<issue>1</issue>):<fpage>113</fpage>–<lpage>127</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0893-6080(94)90060-4" xlink:type="simple">10.1016/0893-6080(94)90060-4</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kuffler</surname> <given-names>SW</given-names></name>. <article-title>Discharge patterns and functional organization of mammalian retina</article-title>. <source>J Neurophysiol</source>. <year>1953</year> <month>Jan</month>;<volume>16</volume>(<issue>1</issue>):<fpage>37</fpage>–<lpage>68</lpage>. <object-id pub-id-type="pmid">13035466</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hubel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wiesel</surname> <given-names>T</given-names></name>. <article-title>Receptive Fields, Binocular Interaction and Functional Architecture in Cats Visual Cortex</article-title>. <source>J Physiol</source>. <year>1962</year> <month>Jan</month>;<volume>160</volume>(<issue>1</issue>):<fpage>106</fpage>–<lpage>154</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1962.sp006837" xlink:type="simple">10.1113/jphysiol.1962.sp006837</ext-link></comment> <object-id pub-id-type="pmid">14449617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Crick</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>. <article-title>Constraints on cortical and thalamic projections: the no-strong-loops hypothesis</article-title>. <source>Nature</source>. <year>1998</year> <month>Jan</month>;<volume>391</volume>(<issue>6664</issue>):<fpage>245</fpage>–<lpage>250</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/34584" xlink:type="simple">10.1038/34584</ext-link></comment> <object-id pub-id-type="pmid">9440687</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Felleman</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>van Essen</surname> <given-names>DC</given-names></name>. <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source>Cereb Cortex</source>. <year>1991</year> <month>Jan</month>;<volume>1</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/1.1.1" xlink:type="simple">10.1093/cercor/1.1.1</ext-link></comment> <object-id pub-id-type="pmid">1822724</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sjöström</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Häusser</surname> <given-names>M</given-names></name>. <article-title>A cooperative switch determines the sign of synaptic plasticity in distal dendrites of neocortical pyramidal neurons</article-title>. <source>Neuron</source>. <year>2006</year> <month>Jul</month>;<volume>51</volume>(<issue>2</issue>):<fpage>227</fpage>–<lpage>238</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2006.06.017" xlink:type="simple">10.1016/j.neuron.2006.06.017</ext-link></comment> <object-id pub-id-type="pmid">16846857</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Letzkus</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Kampa</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Stuart</surname> <given-names>GJ</given-names></name>. <article-title>Learning rules for spike timing-dependent plasticity depend on dendritic synapse location</article-title>. <source>J Neurosci</source>. <year>2006</year> <month>Oct</month>;<volume>26</volume>(<issue>41</issue>):<fpage>10420</fpage>–<lpage>10429</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2650-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2650-06.2006</ext-link></comment> <object-id pub-id-type="pmid">17035526</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Caporale</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Spike timing-dependent plasticity: a Hebbian learning rule</article-title>. <source>Annu Rev Neurosci</source>. <year>2008</year> <month>Jan</month>;<volume>31</volume>:<fpage>25</fpage>–<lpage>46</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.31.060407.125639" xlink:type="simple">10.1146/annurev.neuro.31.060407.125639</ext-link></comment> <object-id pub-id-type="pmid">18275283</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Carnell</surname> <given-names>A</given-names></name>. <article-title>An analysis of the use of Hebbian and Anti-Hebbian spike time dependent plasticity learning functions within the context of recurrent spiking neural networks</article-title>. <source>Neurocomputing</source>. <year>2009</year>;<volume>72</volume>(<issue>4–6</issue>):<fpage>685</fpage>–<lpage>692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neucom.2008.07.012" xlink:type="simple">10.1016/j.neucom.2008.07.012</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Patrick D Roberts</surname> <given-names>TKL</given-names></name>. <article-title>Anti-Hebbian Spike-Timing-Dependent Plasticity and Adaptive Sensory Processing</article-title>. <source>Front Comput Neurosci</source>. <year>2010</year>;<volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2010.00156" xlink:type="simple">10.3389/fncom.2010.00156</ext-link></comment> <object-id pub-id-type="pmid">21228915</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Koch</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ponzo</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Di Lorenzo</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Caltagirone</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Veniero</surname> <given-names>D</given-names></name>. <article-title>Hebbian and Anti-Hebbian Spike-Timing-Dependent Plasticity of Human Cortico-Cortical Connections</article-title>. <source>J Neurosci</source>. <year>2013</year> <month>Jun</month>;<volume>33</volume>(<issue>23</issue>):<fpage>9725</fpage>–<lpage>9733</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4988-12.2013" xlink:type="simple">10.1523/JNEUROSCI.4988-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23739969</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Fyfe</surname> <given-names>C</given-names></name>. <source>Hebbian learning and negative feedback networks</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2005</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>1982</year> <month>Apr</month>;<volume>79</volume>(<issue>8</issue>):<fpage>2554</fpage>–<lpage>2558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.79.8.2554" xlink:type="simple">10.1073/pnas.79.8.2554</ext-link></comment> <object-id pub-id-type="pmid">6953413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>. <article-title>Mean-field analysis of neuronal spike dynamics</article-title>. <source>Network-Comp Neural</source>. <year>1993</year>;<volume>4</volume>(<issue>3</issue>):<fpage>259</fpage>–<lpage>284</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004566.ref059">
<label>59</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schmolesky</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hanes</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>KG</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schall</surname> <given-names>JD</given-names></name>, <etal>et al</etal>. <article-title>Signal timing across the macaque visual system</article-title>. <source>J Neurophysiol</source>. <year>1998</year> <month>Jun</month>;<volume>79</volume>(<issue>6</issue>):<fpage>3272</fpage>–<lpage>3278</lpage>. <object-id pub-id-type="pmid">9636126</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref060">
<label>60</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Willmore</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tolhurst</surname> <given-names>DJ</given-names></name>. <article-title>Characterizing the sparseness of neural codes</article-title>. <source>Network</source>. <year>2001</year> <month>Aug</month>;<volume>12</volume>(<issue>3</issue>):<fpage>255</fpage>–<lpage>270</lpage>. <object-id pub-id-type="pmid">11563529</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004566.ref061">
<label>61</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Graupner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>. <article-title>Calcium-based plasticity model explains sensitivity of synaptic changes to spike pattern, rate, and dendritic location</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2012</year> <month>Mar</month>;<volume>109</volume>(<issue>10</issue>):<fpage>3991</fpage>–<lpage>3996</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1109359109" xlink:type="simple">10.1073/pnas.1109359109</ext-link></comment> <object-id pub-id-type="pmid">22357758</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>