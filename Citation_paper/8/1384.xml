<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">08-PONE-RA-03465R1</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0002148</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>On How Network Architecture Determines the Dominant Patterns of Spontaneous Neural Activity</article-title><alt-title alt-title-type="running-head">Spontaneous Activity Patterns</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Galán</surname><given-names>Roberto F.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1">          <addr-line>Department of Neurosciences, School of Medicine, Case Western Reserve University, Cleveland, Ohio, United States of America</addr-line>       </aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes><corresp id="cor1">* E-mail: <email xlink:type="simple">rfgalan@case.edu</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: RG. Performed the experiments: RG. Analyzed the data: RG. Wrote the paper: RG.</p></fn><fn fn-type="conflict"><p>The author has declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><year>2008</year></pub-date><pub-date pub-type="epub"><day>14</day><month>5</month><year>2008</year></pub-date><volume>3</volume><issue>5</issue><elocation-id>e2148</elocation-id><history><date date-type="received"><day>30</day><month>1</month><year>2008</year></date><date date-type="accepted"><day>25</day><month>3</month><year>2008</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder>Roberto Galán</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>In the absence of sensory stimulation, neocortical circuits display complex patterns of neural activity. These patterns are thought to reflect relevant properties of the network, including anatomical features like its modularity. It is also assumed that the synaptic connections of the network constrain the repertoire of emergent, spontaneous patterns. Although the link between network architecture and network activity has been extensively investigated in the last few years from different perspectives, our understanding of the relationship between the network connectivity and the structure of its spontaneous activity is still incomplete. Using a general mathematical model of neural dynamics we have studied the link between spontaneous activity and the underlying network architecture. In particular, here we show mathematically how the synaptic connections between neurons determine the repertoire of spatial patterns displayed in the spontaneous activity. To test our theoretical result, we have also used the model to simulate spontaneous activity of a neural network, whose architecture is inspired by the patchy organization of horizontal connections between cortical columns in the neocortex of primates and other mammals. The dominant spatial patterns of the spontaneous activity, calculated as its principal components, coincide remarkably well with those patterns predicted from the network connectivity using our theory. The equivalence between the concept of dominant pattern and the concept of attractor of the network dynamics is also demonstrated. This in turn suggests new ways of investigating encoding and storage capabilities of neural networks.</p></abstract><funding-group><funding-statement>The author is grateful to the Mount Sinai Health Care Foundation for financial support.</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>A major challenge in current neuroscience is to understand the emergence of coherent complex activity from the interactions between neurons and its role in normal and pathological brain function. Approaches to facing this challenge have become more urgent in the last few years, as experimental techniques to record from many neurons simultaneously are being developed and improved, providing valuable data sets for analysis <xref ref-type="bibr" rid="pone.0002148-Cossart1">[1]</xref>, <xref ref-type="bibr" rid="pone.0002148-Froemke1">[2]</xref>. These techniques have revealed that, even in the absence of stimulation, network activity organizes in complex spatiotemporal patterns <xref ref-type="bibr" rid="pone.0002148-Cossart1">[1]</xref>, <xref ref-type="bibr" rid="pone.0002148-Mao1">[3]</xref>–<xref ref-type="bibr" rid="pone.0002148-Ikegaya1">[8]</xref> that reflect, at least to some extent, the underlying network architecture <xref ref-type="bibr" rid="pone.0002148-Tsodyks1">[5]</xref>, <xref ref-type="bibr" rid="pone.0002148-Kenet1">[6]</xref>. Likewise, recent experimental studies <italic>in vitro</italic> and <italic>in vivo</italic> have shown that cortical networks tend to reproduce spontaneous patterns consistently, known as cortical songs <xref ref-type="bibr" rid="pone.0002148-Ikegaya1">[8]</xref> because of their reliable temporal modulation. Although complementary studies suggest that these motifs are fully arbitrary <xref ref-type="bibr" rid="pone.0002148-Mokeichev1">[9]</xref>, parallel studies of propagation of up-and-down states have shown highly stereotypical motifs in cortical circuits locally, leaving open the functional role of the cortical song and spontaneous activity in the brain <xref ref-type="bibr" rid="pone.0002148-Luczak1">[10]</xref>. Together, these results vindicate the necessity to understand in detail how neural circuitry constrains the repertoire of activity patterns that a network supports. This goal turns out to be even more significant, as we realize that encoding capabilities and storage capacity in a neural network are likely to rely on those repertoires. In this paper, we make a step toward this goal by showing both mathematically and in computer simulations how network connectivity determines the dominant patterns, or <italic>modes</italic> of the spontaneous activity.</p><p>We are focusing here on a rather microscopic level, where only the interactions among few cortical columns are investigated. Several authors have extensively studied the link between network architecture and network activity at the level of pathways and connections between brain areas previously <xref ref-type="bibr" rid="pone.0002148-Sporns1">[11]</xref>–<xref ref-type="bibr" rid="pone.0002148-Honey1">[16]</xref>. Whereas the philosophy and mathematical framework used in this article parallel with those of the aforementioned studies, here we concentrate on the spontaneous activity: in addition to showing the link between network architecture and spontaneous activity, we also demonstrate the equivalence between dominant modes and network attractors.</p></sec><sec id="s2"><title>Results</title><p>Using the general model of neural network dynamics described in <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>, we have simulated spontaneous activity in a neural network whose architecture resembles the patchy structure of horizontal connections in the neocortex of macaques and other mammals <xref ref-type="bibr" rid="pone.0002148-Lund1">[17]</xref>. In particular, the sign and strength of synaptic connections between a given neuron and the rest of neurons in the network are approximated by a Gabor function (<xref ref-type="fig" rid="pone-0002148-g001">Fig. 1A and 1B</xref>). Other authors have previously used this synaptic kernel to model network dynamics in the prefrontal cortex during working memory tasks <xref ref-type="bibr" rid="pone.0002148-Laing1">[18]</xref>. Nonetheless, the analyses below yielded qualitatively the same results with a Mexican-hat and with a Gabor kernel. While the vast literature on synaptic connections makes this a reduced model, our purpose here is to focus on a plausible architecture that allows us to illustrate the accuracy of our theoretical predictions on the relationship between anatomical connectivity and the patterns of spontaneous activity.</p><fig id="pone-0002148-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0002148.g001</object-id><label>Figure 1</label><caption><title>Biologically inspired connectivity.</title><p>A: Synaptic strengths of an arbitrary neuron located at the center with its neighbors as a function of distance in two dimensions (Gabor kernel). Positive values indicate excitatory connections and negative values indicate inhibitory connections. B: Projection of the synaptic kernel along an axis crossing the center. Excitatory and inhibitory synapses are spatially periodic, interleaved and their strength decays with distance.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.g001" xlink:type="simple"/></fig><p>In the absence of stimulation, our network is driven by intrinsic, random background fluctuations modeled as uncorrelated, white noise; noise which emerges from fluctuations in channel opening and closing events and spontaneous synaptic release, among other sources of biological variability. These random currents trigger moderate firing rates in single neurons that propagate through the network as a result of synaptic interactions. This form of spontaneous activity organizes in complex spatiotemporal patterns. An example of simulated spontaneous activity is provided as <xref ref-type="supplementary-material" rid="pone.0002148.s004">Movie S1</xref> of the <italic>Supporting Information</italic>. Some snapshots of the movie are also shown in <xref ref-type="fig" rid="pone-0002148-g002">figure 2</xref>. The color scale indicates the spontaneous firing rates in arbitrary units: red being above firing baseline (represented in green) and blue below. A significant feature of these snapshots is that they reveal a striking modularity, reminiscent of the spatial patterns observed via voltage sensitive dye imaging in V1 of cats <xref ref-type="bibr" rid="pone.0002148-Tsodyks1">[5]</xref>. In effect, red and blue areas segregate forming domains of approximately the same extension. These modules vary in time but have a pronounced tendency to reemerge, as shown in the movie.</p><fig id="pone-0002148-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0002148.g002</object-id><label>Figure 2</label><caption><title>Snapshots of spontaneous activity.</title><p>The patterns of spontaneous activity display excited (red) and inhibited (blue) spots with respect to the baseline firing rate (green) that evolve in time (red spots can turn blue and vice versa). The whole movie of the spontaneous activity is provided as <xref ref-type="supplementary-material" rid="pone.0002148.s004">Movie S1</xref> in <italic>Supporting Information</italic>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.g002" xlink:type="simple"/></fig><p><xref ref-type="fig" rid="pone-0002148-g003">Figure 3A</xref> shows the power spectral density of traces from three arbitrarily chosen neurons as well as the average across all neurons. Single neurons clearly have some oscillatory components revealed by peaks in the spectral density. However, not all the network is oscillating with the same frequency as indicated by different positions of the peaks for different neurons. In fact, on average there is no preferred frequency (<xref ref-type="fig" rid="pone-0002148-g003">Fig. 3A, black line</xref>). As explained below, the spontaneous activity consists of a summation of network modes analogue to the vibrations of a drum's membrane, which can be represented as the superposition of two-dimensional modes (Bessel functions) that oscillate in time at different frequencies. In the neural network, the spatial modes also oscillate at different frequencies, and a given neuron participates in many of these modes but with different weights. Therefore, the spectral densities of different neural traces are typically different as well.</p><fig id="pone-0002148-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0002148.g003</object-id><label>Figure 3</label><caption><title>Properties of the spontaneous activity.</title><p>A: Power spectral density of the arbitrarily chosen neural traces (blue, red, green) and the average across all neural traces (black). Neurons have some oscillatory behavior in the low frequency band (&lt;5 Hz). B: The elements of the theoretically predicted covariance matrix and of the estimated covariance matrix coincide remarkable well (blue dots), as shown by a linear regression (red line) that perfectly overlaps with the identity (<italic>y</italic> = <italic>x</italic>, black crosses). C: The eigenvalues of both matrices (blue dots) are accordingly highly correlated (regression in red; identitiy in black dashed lines). D: The principal components of both matrices are also highly correlated. Note the pronounced band along the diagonal of their cross-correlation matrix, which indicates high similarity of the predicted and the estimated dominant modes.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.g003" xlink:type="simple"/></fig><p>As a first step to uncover the dominant patterns of the simulated spontaneous activity we calculate the covariance matrix from the spontaneous activity, which consists of the products of each pair of neural traces (pixels of the movie) averaged in time (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). We then compare the covariance matrix of the spontaneous activity from the simulations with the covariance matrix derived analytically from the connectivity matrix in the mathematical model (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). Remarkably, a strong correlation can be seen between the elements of both matrices (<xref ref-type="fig" rid="pone-0002148-g003">Fig. 3B</xref>). Then, we compute the dominant patterns of the spontaneous activity as the principal components, i.e. as the eigenvectors of the covariance matrix. We also compute their relative weight, i.e. the associated eigenvalues. When we do this from the covariance matrix of the simulated data and from the covariance matrix derived mathematically from the connectivity matrix (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>), we obtain a remarkable agreement (<xref ref-type="fig" rid="pone-0002148-g003">Fig. 3C and D</xref>). Note the pronounced band along the diagonal of the in <xref ref-type="fig" rid="pone-0002148-g003">Fig. 3D</xref>, which indicates high similarity (cross-correlation) between the predicted and the estimated dominant modes.</p><p>In <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref>, the dominant patterns predicted by our theory are compared with the dominant patterns estimated from the simulations. Again, we note a good agreement, especially in the size and distribution of interleaved spots of excitation and inhibition. These results demonstrate that our theory can predict the dominant modes of the spontaneous activity just by knowing the architecture of the network.</p><fig id="pone-0002148-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0002148.g004</object-id><label>Figure 4</label><caption><title>Decomposition of the spontaneous activity in dominant modes.</title><p>The spontaneous activity can be mathematically described as a linear superposition of spatial modes (principal components) modulated in time. On the left, we compare some predicted spatial modes with the observed ones noting a good agreement overall. The blue traces on the right represent the temporal modulation of each pattern. The eigenvalue associated with the <italic>i</italic>-th principal component, or equivalently, the mean quadratic amplitude (variance) of that mode in the spontaneous activity is given by λ<italic><sub>i</sub></italic>. The relative variance contained in that mode is expressed as a percentage in parentheses.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.g004" xlink:type="simple"/></fig><p>As shown in <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>, the spontaneous network activity can be expressed as the summation of dominant patterns (modes) whose amplitudes are modulated in time. This modulation is represented by the traces in <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref> on the right, which are mathematically obtained by projecting the spontaneous activity onto each dominant pattern (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). The oscillatory nature of these traces is quantified in their power spectral density (<xref ref-type="fig" rid="pone-0002148-g005">Fig. 5A</xref>). Although they all fluctuate more strongly in the low frequencies, different modes do not necessarily oscillate at the same frequency. The fact that the modes are spatially extensive and that their temporal modulation is rather regular but not constrained to a specific time scale explains the emergence of coherent, complex dynamics in the neural network. In effect, the patchy structure of the dominant patterns in <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref> means that segregated regions fluctuate coherently in time. In addition, these fluctuations occur in different time scales for different modes. Thus, the superposition of all these modes modulated in time results in the complex spatiotemporal patterns of the spontaneous activity, as recently observed in experimental data <xref ref-type="bibr" rid="pone.0002148-Cossart1">[1]</xref>, <xref ref-type="bibr" rid="pone.0002148-Cossart2">[4]</xref>, <xref ref-type="bibr" rid="pone.0002148-Ikegaya1">[8]</xref>, <xref ref-type="bibr" rid="pone.0002148-Luczak1">[10]</xref>.</p><fig id="pone-0002148-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0002148.g005</object-id><label>Figure 5</label><caption><title>Coherent behavior and network attractors.</title><p>A: Power spectral density of the dominant modes shown in <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref> in the same order. The dominant modes are clearly oscillatory with at least one preferred frequency. The superposition of the oscillatory modes endows the spontaneous activity with coherent behavior in space and time. B: The normalized projection, <italic>R</italic> of the chosen modes onto the spontaneous activity yields the instantaneous contribution of each mode. Thus, the spontaneous activity can also be regarded as fluctuations of the network state around the basins of attraction of different attractors (modes). The black dots represent an instantaneous incursion into the basin of attraction of the corresponding mode. The percentage indicates the relative amount of time spent in the corresponding basin of attraction, i.e. the attractor's dwell time (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.g005" xlink:type="simple"/></fig><p>According to the decomposition of spontaneous activity in modes, one expects that at each point in time a given mode prevails over the rest, i.e. at some points in time the spontaneous activity will mostly resemble one of the dominant spatial patterns. To test this prediction, one can use a “template matching” algorithm, similar to the strategy used to identify repetitive motifs in cortical songs <xref ref-type="bibr" rid="pone.0002148-Ikegaya1">[8]</xref>. The template in our case is one of the dominant patterns, which is compared with each snapshot of the spontaneous activity. Interestingly, this approach allows us to demonstrate the equivalence of the concept of dominant pattern and the concept of network attractor. In effect, one can think of the spontaneous activity as a series of random transitions between attractors of the stochastic network dynamics. To show that the dominant modes are actually these attractors we estimate their <italic>basin of attraction</italic> by applying the aforementioned template matching algorithm in the following way: we first calculate the correlation coefficient of the dominant patterns with each snapshot (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). In other words, we calculate the instantaneous similarity between the spontaneous activity and its dominant patterns. We then check whether it is significant and if so, we mark that point in time with a black dot. This allows us to visualize when the state of the network approaches a given attractor (<xref ref-type="fig" rid="pone-0002148-g005">Fig. 5B</xref>) and to quantify the fraction of points in time when this happens. As expected, the dominant modes have “larger” basins, i.e. stronger attraction, the larger their eigenvalues are. In fact, the correlation coefficient between the eigenvalues and the fraction of time spent in the basin of attraction is <italic>r</italic> = 0.968. This demonstrates the equivalence between the concept of principal component or dominant pattern of the spontaneous activity and the concept of network attractor.</p></sec><sec id="s3"><title>Discussion</title><p>Using a general firing-rate model of neural dynamics <xref ref-type="bibr" rid="pone.0002148-Wilson1">[19]</xref>, <xref ref-type="bibr" rid="pone.0002148-Hoppensteadt1">[20]</xref>, we have shown how the network architecture determines the dominant patterns of the spontaneous activity. In particular, we have described mathematically the relationship between the connectivity matrix and the principal components of the spontaneous activity. The examples provided reveal how regularities in the connections lead to spatial patterns that vary in time but tend to reappear consistently. In the simulations described, these patterns contain several <italic>modules</italic> of excited and inhibited domains, characteristic of modular architecture and spontaneous activity in the cortex <xref ref-type="bibr" rid="pone.0002148-Tsodyks1">[5]</xref>, <xref ref-type="bibr" rid="pone.0002148-Kenet1">[6]</xref>. The modules are functional rather than anatomical, since the domains wax and wane in time.</p><p>The relationship between network activity and network architecture has been extensively studied recently by several authors, but mostly at a macroscopic level, describing interactions between brain areas, or in a more general context of complex network architectures <xref ref-type="bibr" rid="pone.0002148-Sporns1">[11]</xref>–<xref ref-type="bibr" rid="pone.0002148-Honey1">[16]</xref>, <xref ref-type="bibr" rid="pone.0002148-Steuer1">[21]</xref>. Here, in contrast, we have focused on the microscopic level describing interactions of local neural groups, in particular, across a few cortical columns. The mathematical framework used in this article is similar to those used by other authors investigating complex biological networks <xref ref-type="bibr" rid="pone.0002148-Sporns1">[11]</xref>, <xref ref-type="bibr" rid="pone.0002148-Sporns2">[12]</xref>, <xref ref-type="bibr" rid="pone.0002148-Steuer1">[21]</xref>, <xref ref-type="bibr" rid="pone.0002148-Steuer2">[22]</xref>. More specifically, we describe network interactions in terms of linear stochastic processes along the lines of such studies. In this manuscript, however, we have devoted special attention to the principal components of the spontaneous activity and we have demonstrated that they represent the basins of attraction of its stochastic dynamics.</p><p>Other groups have previously shown that the complexity of the architecture determines the complexity of the interactions between different brain areas <xref ref-type="bibr" rid="pone.0002148-Sporns1">[11]</xref>, <xref ref-type="bibr" rid="pone.0002148-Sporns2">[12]</xref>. In particular, dense local connections and sparse long-range connections tend to generate large-scale, complex behavior <xref ref-type="bibr" rid="pone.0002148-Sporns1">[11]</xref>, <xref ref-type="bibr" rid="pone.0002148-Sporns2">[12]</xref>. Moreover, the analysis of large-scale neuroanatomical data sets has revealed characteristic building blocks of the network architecture <xref ref-type="bibr" rid="pone.0002148-Sporns3">[13]</xref>. Combining those findings with the model presented here, it would be interesting to investigate the extent to which the dominant patterns of large-scale, spontaneous activity actually represent structural building blocks.</p><p>Here we have shown how to predict dominant patterns in the spontaneous activity from the network connections. From an experimentalist's perspective the inverse problem may be even more relevant, i.e., whether the network architecture can be reconstructed from the principal components of the spontaneous activity. The connectivity can be <italic>inferred</italic> from the spontaneous activity but not exactly determined. The limitations for this are twofold: technical and theoretical. The technical difficulties are due to the finite size of the data that allow us to calculate only a few principal components reliably. But even if infinite data sets were feasible, there is a fundamental limitation to perfectly retrieve the connectivity matrix. Equation (5) in <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref> shows the relationship between the network architecture (implicit in <italic>A</italic>) and the covariance matrix of the spontaneous activity <italic>C</italic>, from which the dominant patterns are calculated. Whereas equation (5) is linear if we take the elements of <italic>C</italic> as the unknowns and the elements of <italic>A</italic> and <italic>Q</italic> as parameters, equation (5) is nonlinear if we take the elements of <italic>A</italic> as unknowns and the elements of <italic>C</italic> and <italic>Q</italic> as parameters. Due to the nonlinearity, when solving for <italic>A</italic>, the solution will not be unique in general. In fact, this is a well-known result of stochastic theory: the drift matrix (in our case, the connectivity matrix A) of a linear Langevin process (in our case, the spontaneous activity) cannot be uniquely retrieved from its covariance matrix <xref ref-type="bibr" rid="pone.0002148-Haken1">[23]</xref>, <xref ref-type="bibr" rid="pone.0002148-Honerkamp1">[24]</xref>. Nonetheless, an elegant way of overcoming this limitation has been recently proposed in the context of metabolomic networks <xref ref-type="bibr" rid="pone.0002148-Steuer1">[21]</xref>: first, some entries of the connectivity matrix are set as fixed parameters and then, a parametric solution is found. However, whereas this trick works efficiently for small networks, it becomes intractable for relatively large ones. Despite all these limitations, our results show that the connectivity of the network can indeed be qualitatively inferred. In effect, by looking at the modular structure of the dominant patterns one gets an idea of the connectivity kernel. For example, the spots of center surround inhibition in the dominant patterns of <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref> have the size of the central wiggle in <xref ref-type="fig" rid="pone-0002148-g001">figure 1B</xref>.</p><p>In addition to the resolving power of our model to elucidate underlying anatomical connectivity from the patterns of spontaneous activity, it also provides an interpretation of the role of that activity in framework of neural network dynamics. The concept of attractor network has dominated computational neuroscience for about three decades <xref ref-type="bibr" rid="pone.0002148-Haken1">[23]</xref>, <xref ref-type="bibr" rid="pone.0002148-Hopfield1">[25]</xref>–<xref ref-type="bibr" rid="pone.0002148-Hertz1">[29]</xref>. The idea that neural dynamics encode and store representations of stimuli in the form of attractors of the network dynamics has been fueled by the findings of several experimental studies in different systems <xref ref-type="bibr" rid="pone.0002148-Galn1">[7]</xref>, <xref ref-type="bibr" rid="pone.0002148-Miyashita1">[30]</xref>–<xref ref-type="bibr" rid="pone.0002148-Mazor1">[33]</xref>. Moreover, it has been proposed recently that the highly consistent, spontaneously-evoked network up-states observed in cortical slices represent circuit attractors <xref ref-type="bibr" rid="pone.0002148-Cossart1">[1]</xref>, <xref ref-type="bibr" rid="pone.0002148-Cossart2">[4]</xref>. Here, we have demonstrated that the principal components of the spontaneous activity can be interpreted as attractors of the stochastic background activity of the network. In particular, the eigenvalues of the covariance matrix roughly represent the fraction of time spent by the network in the basin of attraction (dwell time) of the associated eigenvector or principal component. Furthermore, changes in the principal component of the spontaneous activity during behavioral experiments can be used to quantify changes in the network connectivity and hence, to uncover Hebbian memory traces, as recently shown in an insect's brain <italic>in vivo</italic> <xref ref-type="bibr" rid="pone.0002148-Galn1">[7]</xref>.</p><p>It is worth mentioning that each spatial pattern (snapshot) of the spontaneous activity is not necessarily identical to any of the principal components. From a mathematical point of view, however, each spatial pattern can be expressed as a linear combination of principal components, provided that they are not degenerate, i.e. if all eigenvalues are different. Degeneracy appears when the connectivity matrix is “highly symmetrical”. For example, several sets of degenerate eigenvalues occur from a kernel like that in <xref ref-type="fig" rid="pone-0002148-g001">figure 1</xref>, which has rotational symmetry. By construction, the network also displays translation invariance (due in part to wrap-around boundaries). In reality, however, synaptic connections display large variability over the main architectural theme (see e.g., figure 3 in <xref ref-type="bibr" rid="pone.0002148-White1">[34]</xref>). We have modeled this variability as 25% random connections on top of the architecture obtained from the Gabor kernel (see <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). This is more than sufficient to remove degeneracy completely, as shown in <xref ref-type="fig" rid="pone-0002148-g003">Fig. 3C</xref>, where no eigenvalues coincide on the same spot. In principle, since the set of non-degenerate patterns forms a basis of the “snapshots space”, any arbitrary spatial pattern might be possible at any given time during the spontaneous activity. However, as mentioned in the previous paragraph, the spontaneous activity is biased to the dominant patterns proportionally to their eigenvalues and not any arbitrary pattern will realize. This implies that the repertoire or “alphabet” with which the network can encode and store information is constrained by the dominant modes, or equivalently, constrained by the network architecture.</p><p>One can possibly argue that any other basis different from the basis of principal components may be used to decompose the spontaneous activity. One may also wonder whether those alternative basis vectors could also be considered as attractors. In principle, one could choose another basis to decompose the spontaneous activity, but it would not be adequate in the sense that it would not make the relationship between the basis and the network architecture explicit, as it is the case with the basis of principal components. To demonstrate this, we have also used a Fourier basis (see figures in <italic>Supporting Information</italic>). In particular, we have first calculated the power spectrum of the spatial frequencies for each snapshot of the spontaneous activity. Then, we have averaged the power spectra of all snapshots. Interestingly, the averaged spectrum clearly reveals an elevated ring (see <xref ref-type="supplementary-material" rid="pone.0002148.s001">figure S1</xref>), whose radius roughly corresponds to the reciprocal of the period of the Gabor kernel, indicating that the Fourier decomposition captures an important feature of the network connectivity. We note that the ring does not have a uniform height. This means that we can rank the dominant spatial frequencies along the ring according their power. In <xref ref-type="supplementary-material" rid="pone.0002148.s002">figure S2</xref>, we display the spatial patterns associated with the six dominant spatial frequencies. However, as seen in <xref ref-type="supplementary-material" rid="pone.0002148.s003">figure S3</xref>, the dominant patterns of the Fourier basis cannot be regarded as attractors because their instantaneous correlation with the spontaneous activity is negligible. In other words, the projections of those vectors onto the spontaneous activity do not quantify the dwell time, which is the idea behind the concept of attractor. In fact, as seen in <xref ref-type="supplementary-material" rid="pone.0002148.s003">figure S3</xref>, the network spends 0% of the time in the basins of the Fourier modes.</p><p>Here we have modeled the spontaneous activity as a linearly stable, stochastic system. The assumption of linearity comes from the observation that the baseline firing rates of neurons in the absence of stimulation are typically much lower than during stimulation <xref ref-type="bibr" rid="pone.0002148-Galn1">[7]</xref> and far from saturation. In such stochastic systems (like eq. 3), the stability criterion is that all eigenvalues of the linear operator (<italic>A</italic>, in eq. 3) has magnitude less than one. If one or several modes have eigenvalues which do not fulfill this condition, the spontaneous activity will grow quickly in time entering the saturation regime (nonlinearity in equation 1). This kind of behavior resembles an epileptic seizure and the physiological mechanisms leading to this instability can be studied to some extent with our approach. For example, an obvious way of inducing a seizure in the network consists in reducing the relaxation parameter, α until one mode of <italic>A</italic> becomes linearly unstable. Interestingly, some <italic>in vitro</italic> preparations of the cortex display distinct episodes of spontaneous network activity <xref ref-type="bibr" rid="pone.0002148-Schiff1">[35]</xref>. Thus, in real networks, the parameter α is not strictly constant but varies in time, although at a slower time scale than that of the activity fluctuations. In addition, the dimensionality of the dynamics, i.e. the number of modes that significantly contribute to the spontaneous activity, increases close to a transition between episodes <xref ref-type="bibr" rid="pone.0002148-Schiff1">[35]</xref>. These transitions (or bifurcations) are associated with changes of neuronal excitability, which are originated in ion shifts from inside to outside of the neurons and in oxygen limitations in the brain tissue <xref ref-type="bibr" rid="pone.0002148-Schiff1">[35]</xref>, <xref ref-type="bibr" rid="pone.0002148-Lennie1">[36]</xref>.</p><p>In this paper we have exclusively focused on the spontaneous activity of neural networks. At this point, however, we should say a few words about the behavior of the model in response to stimulation. In the model used here, a stimulus will drive equation (1) into saturation of firing rates quickly. This happens because in various neurons the inhibition and the relaxation rate cannot catch up with the excitation plus the stimulus drive. The spatial patterns of saturated firing rates will generally depend on which neurons are driven and how much (<italic>I<sub>i</sub></italic>, in equation 1). In particular, since the dominant modes are built-in in the network architecture, a spatial input pattern <italic>I<sub>i</sub></italic> may <italic>resonate</italic> with the dominant mode that it most resembles until reaching saturation. Using the jargon of synergetics <xref ref-type="bibr" rid="pone.0002148-Haken1">[23]</xref>, the whole network activity will then be <italic>enslaved</italic> by that dominant mode.</p></sec><sec id="s4"><title>Materials and Methods</title><sec id="s4a"><title>Mathematical model of spontaneous neural activity</title><p>We start with a general model of neural network dynamics of the Wilson-Cowan type <xref ref-type="bibr" rid="pone.0002148-Wilson1">[19]</xref>, <xref ref-type="bibr" rid="pone.0002148-Hoppensteadt1">[20]</xref> that describes the variations of firing rate in the neurons due to synaptic and external currents. The model is slightly modified to take into account the effect of intrinsic noise:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e001" xlink:type="simple"/><label>(1)</label></disp-formula>where <italic>u<sub>i</sub></italic> represents the activity (firing-rate) of the <italic>i</italic>-th neuron in the network; α is the inverse of the relaxation time; <italic>W<sub>ij</sub></italic> is the synaptic strength between neuron <italic>i</italic> and <italic>j</italic>, i.e. the connectivity matrix; <italic>I<sub>i</sub></italic> is the external input to the <italic>i</italic>-th neuron; and η<italic><sub>i</sub></italic> is a random, fluctuating input into the <italic>i</italic>-th neuron (modeled as white noise) accounting for channel noise, spontaneous synaptic release and other sources of biophysical variability. The nonlinear function Θ(<italic>x</italic>), typically a sigmoid of hyperbolic-tangent type, limits the growth of its argument to an asymptotic value which accounts for the saturation of firing rates in real neurons.</p><p>In the absence of stimulation, the external inputs to all neurons in the network vanish, <italic>I<sub>i</sub></italic> = 0. Thus, the only driving force are intrinsic, random fluctuations η<italic><sub>i</sub></italic> with standard deviation σ. Because those fluctuations are not sufficiently strong to evoke large variations of the firing rate, the saturation due to the nonlinear function Θ can be ignored in the study of spontaneous activity. In these conditions, the dynamical equations can be easily linearized around the quiescent state of the network:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e002" xlink:type="simple"/><label>(2)</label></disp-formula>where we have factorized the last term into σ and η<italic><sub>i</sub></italic>, which now has unitary standard deviation. In practice, to simulate system (2) the differential equations are discretized in time with a finite time step Δ<italic>t</italic>, taking the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e003" xlink:type="simple"/></disp-formula>which in vector notation can be rewritten as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e004" xlink:type="simple"/><label>(3)</label></disp-formula>using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e005" xlink:type="simple"/></inline-formula>, and <italic>A</italic>≡(1−αΔ<italic>t</italic>) <italic>E</italic>+<italic>W</italic>Δ<italic>t</italic>, where <italic>E</italic>≡δ<italic><sub>ij</sub></italic> is the identity matrix.</p></sec><sec id="s4b"><title>Estimation of dominant patterns from the traces of spontaneous activity</title><p>The dominant patterns can be directly computed from the time series of spontaneous neural activity obtained either from a model, like the one exposed above or from actual recordings of neural activity. To this end, one first calculates the covariance matrix of the neural traces <italic>u<sub>i</sub></italic>(<italic>t</italic>)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e006" xlink:type="simple"/></disp-formula>where the brackets indicate temporal average. Equivalently, in vector notation the covariance matrix of the spontaneous activity reads<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e007" xlink:type="simple"/><label>(4)</label></disp-formula></p><p>Then, one calculates the eigenvectors and eigenvalues of <italic>C</italic>. The covariance matrix <italic>C</italic> is symmetric by construction and therefore, it has only real eigenvectors and eigenvalues. The eigenvectors of <italic>C</italic> are by definition the principal components of the spontaneous activity, i.e. the dominant patterns or modes, and they represent the spatial patterns in which it can be decomposed. In other words, each snapshot of the spontaneous activity can be represented as a linear superposition of these modes, being their relative weights different in each snapshot.</p><p>The overall weight of each mode in the spontaneous activity is given by the magnitude of the associated eigenvalue. This poses an interesting link between the dominant patterns and the concept of attractor in neural dynamics, as recently illustrated in the olfactory system of an insect <xref ref-type="bibr" rid="pone.0002148-Galn1">[7]</xref>, <xref ref-type="bibr" rid="pone.0002148-Galn2">[32]</xref>. In effect, it can be shown that the temporal average of the similarity (projection) of the spontaneous patterns onto the dominant eigenvector of the covariance matrix, or first principal component, is maximal. In other words, the neural activity fluctuates most of the time around the <italic>basin of attraction</italic> of the dominant pattern. The amount of time spent around the basin of attraction of the remaining principal components is proportional to the magnitude of their eigenvalues.</p></sec><sec id="s4c"><title>Mathematical proof of the relationship between connectivity and dominant patterns</title><p>We start with equation (3); multiplying it with its transpose and averaging in time we obtain<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e008" xlink:type="simple"/></disp-formula>where all terms containing a single product with noise, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e009" xlink:type="simple"/></inline-formula> have vanished after averaging. As in (4) we now define the covariance matrix of the spontaneous activity as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e010" xlink:type="simple"/></disp-formula>where the equality is justified by the stationary character of the spontaneous activity, i.e. temporal averages are invariant under translation in time. Note that <italic>C</italic> is now calculated directly from the model rather than being estimated from the traces of simulated neural activity. Then, defining <italic>Q</italic> as the covariance matrix of the intrinsic noise<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e011" xlink:type="simple"/></disp-formula>we arrive at a matrix equation relating the covariance matrices with the network connectivity via <italic>A</italic><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e012" xlink:type="simple"/><label>(5)</label></disp-formula></p><p>Although our derivation is valid for any <italic>Q</italic>, we can assume for our purposes that the noise sources are uncorrelated in different neurons, i.e. <italic>Q</italic> = (σΔ<italic>t</italic>)<sup>2</sup> <italic>E</italic>. Note that in this case, <italic>Q</italic> is a diagonal, constant matrix.</p><p>Our goal now is to solve for <italic>C</italic> in (5). To this end, we start considering the eigen-decomposition of matrix <italic>A</italic><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e013" xlink:type="simple"/><label>(6)</label></disp-formula>where the columns of matrix <italic>L</italic> are the eigenvectors of <italic>A</italic> and the diagonal matrix <italic>D</italic> contains the associated eigenvalues, λ. Note that the eigenvalues of <italic>A</italic> are the eigenvalues of <italic>W</italic> scaled by the factor Δ<italic>t</italic> and shifted by the constant 1−αΔ<italic>t</italic>. In a purely deterministic system, i.e. in the case of ξ<italic><sub>i</sub></italic>(<italic>t</italic>) = 0, the stability of the model with respect to any finite input pattern <italic>I<sub>i</sub></italic>(<italic>t</italic>)≠0 is guaranteed if all eigenvalues of <italic>A</italic> are negative, which can always be achieved if α is sufficiently large. However, in the case of the stochastic system (3) considered here, stability is guaranteed if all the eigenvalues of <italic>A</italic> have magnitude less than unity <xref ref-type="bibr" rid="pone.0002148-Priestley1">[37]</xref>, <xref ref-type="bibr" rid="pone.0002148-Neumaier1">[38]</xref>, which means that the spontaneous activity cannot grow infinitely in response to noise, but will remain fluctuating around its mean value.</p><p>Since the connectivity matrix <italic>W</italic> is not symmetric in general, neither is <italic>A</italic>, and therefore, <italic>A</italic> can have complex eigenvalues and eigenvectors. As a result we need to replace the transpose operation <italic>X<sup>T</sup></italic> by the conjugate transpose operation <italic>X</italic><sup>†</sup>. Then, substituting (6) in (5) we obtain<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e014" xlink:type="simple"/><label>(7)</label></disp-formula>where we have used <italic>L</italic><sup>−†</sup>≡(<italic>L</italic><sup>−1</sup>)<sup>†</sup> = (<italic>L</italic><sup>†</sup>)<sup>−1</sup>. Multiplying (7) by <italic>L</italic> from the left, then by <italic>L</italic><sup>†</sup> from the right and defining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e015" xlink:type="simple"/></inline-formula> we get<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e016" xlink:type="simple"/><label>(8)</label></disp-formula></p><p>Since <italic>D</italic> is a diagonal matrix, equation (8) can easily be rewritten in terms of the matrix components<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e017" xlink:type="simple"/></disp-formula>where the asterisk denotes complex conjugation. Then, solving for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e018" xlink:type="simple"/></inline-formula> one has<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e019" xlink:type="simple"/><label>(9)</label></disp-formula></p><p>Multiplying (9) by <italic>L</italic> from the left and by <italic>L</italic><sup>†</sup> from the right we arrive at the most relevant theoretical result of this paper: the covariance matrix of the spontaneous activity is determined by the covariance matrix of the intrinsic noise and the eigenvalues of the connectivity matrix:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e020" xlink:type="simple"/><label>(10)</label></disp-formula></p><p>Finally, taking into account that the spatial modes of the spontaneous activity are the eigenvectors of <italic>C</italic>, we calculate the eigen-decomposition of the covariance matrix<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e021" xlink:type="simple"/><label>(11)</label></disp-formula>where the columns of <italic>V</italic> are the eigenvectors and the diagonal matrix <italic>H</italic> contains the corresponding eigenvalues (since <italic>C</italic> is symmetric, all eigenvalues and eigenvectors are real and in addition, <italic>V</italic> is an orthogonal matrix, i.e. <italic>V</italic><sup>−1</sup> = <italic>V<sup>T</sup></italic>). The absolute value of the eigenvalues indicates the relative importance of the corresponding eigenvectors in the spontaneous activity of the network.</p><p>Summing up, the modes of the spontaneous activity are fully determined by the connectivity matrix via the eigenvectors and eigenvalues of matrix <italic>A</italic>. This theoretical derivation allows us to compare the dominant patterns obtained from the covariance matrix of the time series <italic>u<sub>i</sub></italic>(<italic>t</italic>), via (4), with the dominant patterns obtained from the covariance matrix derived from the connectivity matrix via (10) and (11). As shown in <italic>Results</italic>, there is a remarkable agreement between the results of both methods.</p></sec><sec id="s4d"><title>Decomposition of the spontaneous activity in dominant modes</title><p>Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e022" xlink:type="simple"/></inline-formula> be the <italic>k</italic>-th eigenvector of the covariance matrix, i.e. the <italic>k</italic>-th dominant pattern or mode. The spontaneous activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e023" xlink:type="simple"/></inline-formula> can be expressed as a linear combination of these modes, which are pairwise orthonormal, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e024" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e025" xlink:type="simple"/><label>(12)</label></disp-formula>where <italic>N</italic> is the number of modes (which coincides with the number of neurons in the network) the coefficients <italic>a<sub>k</sub></italic>(<italic>t</italic>) represent the instantaneous contribution of each mode to the spontaneous activity and are obtained using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e026" xlink:type="simple"/></inline-formula>. The eigenvalues λ<italic><sub>k</sub></italic> associated with the dominant modes are the mean squared amplitude, i.e. the variance, of these coefficients <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e027" xlink:type="simple"/></inline-formula>. Therefore, only the modes with larger eigenvalues are relevant in practice for expansion (12). The decomposition of the spontaneous activity in dominant modes is analogue to the decomposition of the vibrations of a drum's membrane in vibrating modes, i.e. cylindrical harmonics (Bessel functions). In general, the decomposition of spatiotemporal neural activity into modes has been used by other authors in different contexts <xref ref-type="bibr" rid="pone.0002148-Schiff1">[35]</xref>, <xref ref-type="bibr" rid="pone.0002148-Schiff2">[39]</xref>.</p></sec><sec id="s4e"><title>Dominant modes and network attractors</title><p>As mentioned above, the dominant patterns of the spontaneous activity can be regarded as attractors of the network dynamics. A link between both concepts is provided by the estimation of their basins of attraction. To this end, we first calculate the normalized projection of the principal components on each snapshot of the spontaneous activity (i.e. the correlation coefficient, <italic>r</italic>(<italic>t</italic>)). The magnitude of this correlation is plotted in <xref ref-type="fig" rid="pone-0002148-g004">figure 4</xref>. Specifically, if the <italic>k</italic>-th principal component is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e028" xlink:type="simple"/></inline-formula>, <italic>r</italic>(<italic>t</italic>) is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e029" xlink:type="simple"/></disp-formula>and we plot <italic>R</italic>(<italic>t</italic>) = |<italic>r</italic>(<italic>t</italic>)|. We then calculate the confidence interval using Fisher's z-transformation:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e030" xlink:type="simple"/></disp-formula></p><p>The confidence interval of the random variable <italic>z</italic> at each point in time is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e031" xlink:type="simple"/></inline-formula>, where <italic>N</italic> is the dimension of the vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e032" xlink:type="simple"/></inline-formula>, i.e., the number of neurons. Thus, the fraction of <italic>z</italic>(<italic>t</italic>) samples exceeding σ<italic><sub>z</sub></italic> in absolute value is a measure of the attraction of the spontaneous activity to the <italic>k</italic>-th principal component, i.e. a measure of its basin of attraction. For visualization purposes, in <xref ref-type="fig" rid="pone-0002148-g005">figure 5B</xref> we show the fraction of <italic>z</italic>(<italic>t</italic>) samples exceeding 3σ<italic><sub>z</sub></italic> in absolute value (black dots).</p></sec><sec id="s4f"><title>Numerical details of simulations and analyses</title><p>All simulations and analyses were performed in Matlab 6.5. The model consisted of a square network of 30×30 = 900 units (neurons). The elements of the connectivity matrix <italic>W<sub>ij</sub></italic> were first obtained by convolving the kernel in <xref ref-type="fig" rid="pone-0002148-g001">Fig. 1a</xref> with a delta function of unitary amplitude on the <italic>i</italic>-th neuron of the network and considering periodic (wrap around) boundary conditions. Then, a random connectivity matrix of normally distributed synaptic weights was added to introduce 25% variability. Finally, the elements were divided by the norm of the matrix and multiplied by 1.03. This, together with the following parameter choices ensured the stability of stochastic system (3): α = 1, σ = 1, Δ<italic>t</italic> = 0.2.</p><p>Our model is adimensional in nature. In order to endow the model with biological spatiotemporal scales we first notice that the period of the Gabor kernel must be within the range of 400 to 900 µm <xref ref-type="bibr" rid="pone.0002148-Lund1">[17]</xref>. We take the period to be 0.7 mm. Then, we observe that 10 s of spontaneous cortical traces embrace 6 to 8 peaks of fluctuating activity <xref ref-type="bibr" rid="pone.0002148-Kenet1">[6]</xref>. This implies that the units of our integration time step Δ<italic>t</italic> must be s×10<sup>−2</sup>.</p><p><xref ref-type="fig" rid="pone-0002148-g003">Figure 3D</xref> displays the correlation between the predicted and the observed dominants patterns. More technically, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e033" xlink:type="simple"/></inline-formula> is the <italic>i</italic>-th predicted pattern and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0002148.e034" xlink:type="simple"/></inline-formula> is the <italic>j</italic>-th observed pattern, then the correlation matrix <italic>R<sub>ij</sub></italic> is defined as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.e035" xlink:type="simple"/></disp-formula></p><p>If the predicted and the observed patterns are similar, one expects larger correlation values along the diagonal of the matrix, as seen in <xref ref-type="fig" rid="pone-0002148-g003">figure 3D</xref>.</p></sec></sec><sec id="s5"><title>Supporting Information</title><supplementary-material id="pone.0002148.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.s001" xlink:type="simple"><label>Figure S1</label><caption><p>Power spectrum of the spatial frequencies (Fourier decomposition) averaged across all snapshots of the spontaneous activity. The dominant Fourier modes are arranged along a ring of inhomogeneous height, which indicates the relative weight of each mode in the stochastic network dynamics. The radius of the ring corresponds to the reciprocal of the period of the oscillation in the Gabor kernel.</p><p>(1.13 MB TIF)</p></caption></supplementary-material><supplementary-material id="pone.0002148.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.s002" xlink:type="simple"><label>Figure S2</label><caption><p>Spatial patterns with largest power in the Fourier decomposition of the spontaneous activity. The patterns exhibit the spatial frequency of the Gabor kernel. Thus, the dominant Fourier modes capture a relevant feature of the network architecture.</p><p>(1.70 MB TIF)</p></caption></supplementary-material><supplementary-material id="pone.0002148.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.s003" xlink:type="simple"><label>Figure S3</label><caption><p>Normalized projection of the dominant Fourier modes onto the spontaneous activity. The projections are negligible, which means that, contrary to the principal components, the Fourier modes cannot be considered as attractors of the stochastic network dynamics.</p><p>(0.41 MB TIF)</p></caption></supplementary-material><supplementary-material id="pone.0002148.s004" mimetype="video/mpeg" position="float" xlink:href="info:doi/10.1371/journal.pone.0002148.s004" xlink:type="simple"><label>Movie S1</label><caption><p>Simulated Spontaneous Activity. The spontaneous activity organizes in complex spatiotemporal patterns (some snapshots of the movie are also shown in <xref ref-type="fig" rid="pone-0002148-g002">figure 2</xref>). The color scale indicates spontaneous firing rates in arbitrary units: red being above firing baseline (represented in green) and blue below. The spontaneous patterns reveal some spatial modularity, reminiscent of the spatial patterns observed via voltage sensitive dye imaging in V1 of cats. In effect, red and blue areas segregate forming domains of approximately the same extension. These modules vary in time but have a pronounced tendency to reemerge. Black scale bar: 0.7 mm.</p><p>(9.89 MB MPG)</p></caption></supplementary-material></sec></body><back><ack><p>The author thanks Krishnan Padmanabhan for inspiring discussions and for constructive comments on the manuscript's draft. The author is also grateful to Steven J. Schiff and to another anonymous reviewer for helpful suggestions.</p></ack><ref-list><title>References</title><ref id="pone.0002148-Cossart1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name><name name-style="western"><surname>Ikegaya</surname><given-names>Y</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Calcium imaging of cortical networks dynamics.</article-title>             <source>Cell Calcium</source>             <volume>37</volume>             <fpage>451</fpage>             <lpage>457</lpage>          </element-citation></ref><ref id="pone.0002148-Froemke1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Froemke</surname><given-names>RC</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>VS</given-names></name><name name-style="western"><surname>Czkwianianc</surname><given-names>P</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>             <year>2002</year>             <article-title>Analysis of multineuronal activation patterns from calcium-imaging experiments in brain slices.</article-title>             <source>Trends Cardiovasc Med</source>             <volume>12</volume>             <fpage>247</fpage>             <lpage>252</lpage>          </element-citation></ref><ref id="pone.0002148-Mao1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mao</surname><given-names>BQ</given-names></name><name name-style="western"><surname>Hamzei-Sichani</surname><given-names>F</given-names></name><name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name><name name-style="western"><surname>Froemke</surname><given-names>RC</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>             <year>2001</year>             <article-title>Dynamics of spontaneous activity in neocortical slices.</article-title>             <source>Neuron</source>             <volume>32</volume>             <fpage>883</fpage>             <lpage>898</lpage>          </element-citation></ref><ref id="pone.0002148-Cossart2"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name><name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>             <year>2003</year>             <article-title>Attractor dynamics of network UP states in the neocortex.</article-title>             <source>Nature</source>             <volume>423</volume>             <fpage>283</fpage>             <lpage>288</lpage>          </element-citation></ref><ref id="pone.0002148-Tsodyks1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name><name name-style="western"><surname>Kenet</surname><given-names>T</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name><name name-style="western"><surname>Arieli</surname><given-names>A</given-names></name></person-group>             <year>1999</year>             <article-title>Linking spontaneous activity of single cortical neurons and the underlying functional architecture.</article-title>             <source>Science</source>             <volume>286</volume>             <fpage>1943</fpage>             <lpage>1946</lpage>          </element-citation></ref><ref id="pone.0002148-Kenet1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kenet</surname><given-names>T</given-names></name><name name-style="western"><surname>Bibitchkov</surname><given-names>D</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name><name name-style="western"><surname>Arieli</surname><given-names>A</given-names></name></person-group>             <year>2003</year>             <article-title>Spontaneously emerging cortical representations of visual attributes.</article-title>             <source>Nature</source>             <volume>425</volume>             <fpage>954</fpage>             <lpage>956</lpage>          </element-citation></ref><ref id="pone.0002148-Galn1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Galán</surname><given-names>RF</given-names></name><name name-style="western"><surname>Weidert</surname><given-names>M</given-names></name><name name-style="western"><surname>Menzel</surname><given-names>R</given-names></name><name name-style="western"><surname>Herz</surname><given-names>AV</given-names></name><name name-style="western"><surname>Galizia</surname><given-names>CG</given-names></name></person-group>             <year>2006</year>             <article-title>Sensory memory for odors is encoded in spontaneous correlated activity between olfactory glomeruli.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>10</fpage>             <lpage>25</lpage>          </element-citation></ref><ref id="pone.0002148-Ikegaya1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ikegaya</surname><given-names>Y</given-names></name><name name-style="western"><surname>Aaron</surname><given-names>G</given-names></name><name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name><name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name><name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Synfire chains and cortical songs: temporal modules of cortical activity.</article-title>             <source>Science</source>             <volume>304</volume>             <fpage>559</fpage>             <lpage>564</lpage>          </element-citation></ref><ref id="pone.0002148-Mokeichev1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mokeichev</surname><given-names>A</given-names></name><name name-style="western"><surname>Okun</surname><given-names>M</given-names></name><name name-style="western"><surname>Barak</surname><given-names>O</given-names></name><name name-style="western"><surname>Katz</surname><given-names>Y</given-names></name><name name-style="western"><surname>Ben-Shahar</surname><given-names>O</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Stochastic emergence of repeating cortical motifs in spontaneous membrane potential fluctuations in vivo.</article-title>             <source>Neuron</source>             <volume>53</volume>             <fpage>413</fpage>             <lpage>425</lpage>          </element-citation></ref><ref id="pone.0002148-Luczak1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Luczak</surname><given-names>A</given-names></name><name name-style="western"><surname>Bartho</surname><given-names>P</given-names></name><name name-style="western"><surname>Marguet</surname><given-names>SL</given-names></name><name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name></person-group>             <year>2007</year>             <article-title>Sequential structure of neocortical spontaneous activity in vivo.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>347</fpage>             <lpage>352</lpage>          </element-citation></ref><ref id="pone.0002148-Sporns1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name></person-group>             <year>2000</year>             <article-title>Theoretical neuroanatomy: relating anatomical and functional connectivity in graphs and cortical connection matrices.</article-title>             <source>Cereb Cortex</source>             <volume>10</volume>             <fpage>127</fpage>             <lpage>141</lpage>          </element-citation></ref><ref id="pone.0002148-Sporns2"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name><name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name></person-group>             <year>2000</year>             <article-title>Connectivity and complexity: the relationship between neuroanatomy and brain dynamics.</article-title>             <source>Neural Netw</source>             <volume>13</volume>             <fpage>909</fpage>             <lpage>922</lpage>          </element-citation></ref><ref id="pone.0002148-Sporns3"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name><name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name></person-group>             <year>2004</year>             <article-title>Motifs in brain networks.</article-title>             <source>PLoS Biol</source>             <volume>2</volume>             <fpage>e369</fpage>          </element-citation></ref><ref id="pone.0002148-Zemanova1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zemanova</surname><given-names>L</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>C</given-names></name><name name-style="western"><surname>Kurths</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>Structural and functional clusters of complex brain networks.</article-title>             <source>Physica D</source>             <volume>224</volume>             <fpage>202</fpage>             <lpage>212</lpage>          </element-citation></ref><ref id="pone.0002148-Zhou1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>C</given-names></name><name name-style="western"><surname>Zemanova</surname><given-names>L</given-names></name><name name-style="western"><surname>Zamora</surname><given-names>G</given-names></name><name name-style="western"><surname>Hilgetag</surname><given-names>CC</given-names></name><name name-style="western"><surname>Kurths</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>Hierarchical organization unveiled by functional connectivity in complex brain networks.</article-title>             <source>Phys Rev Lett</source>             <volume>97</volume>             <fpage>238103</fpage>          </element-citation></ref><ref id="pone.0002148-Honey1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Honey</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name><name name-style="western"><surname>Breakspear</surname><given-names>M</given-names></name><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name></person-group>             <year>2007</year>             <article-title>Network structure of cerebral cortex shapes functional connectivity on multiple time scales.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>10240</fpage>             <lpage>10245</lpage>          </element-citation></ref><ref id="pone.0002148-Lund1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lund</surname><given-names>JS</given-names></name><name name-style="western"><surname>Yoshioka</surname><given-names>T</given-names></name><name name-style="western"><surname>Levitt</surname><given-names>JB</given-names></name></person-group>             <year>1993</year>             <article-title>Comparison of intrinsic connectivity in different areas of macaque monkey cerebral cortex.</article-title>             <source>Cereb Cortex</source>             <volume>3</volume>             <fpage>148</fpage>             <lpage>162</lpage>          </element-citation></ref><ref id="pone.0002148-Laing1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Laing</surname><given-names>CR</given-names></name><name name-style="western"><surname>Troy</surname><given-names>WC</given-names></name><name name-style="western"><surname>Gutkin</surname><given-names>B</given-names></name><name name-style="western"><surname>Ermentrout</surname><given-names>GB</given-names></name></person-group>             <year>2002</year>             <article-title>Multiple bumps in a neuronal model of working memory.</article-title>             <source>Siam Journal on Applied Mathematics</source>             <volume>63</volume>             <fpage>62</fpage>             <lpage>97</lpage>          </element-citation></ref><ref id="pone.0002148-Wilson1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name><name name-style="western"><surname>Cowan</surname><given-names>JD</given-names></name></person-group>             <year>1973</year>             <article-title>A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue.</article-title>             <source>Kybernetik</source>             <volume>13</volume>             <fpage>55</fpage>             <lpage>80</lpage>          </element-citation></ref><ref id="pone.0002148-Hoppensteadt1"><label>20</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hoppensteadt</surname><given-names>FC</given-names></name><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name></person-group>             <year>1997</year>             <source>Weakly Connected Neural Networks</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref><ref id="pone.0002148-Steuer1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Steuer</surname><given-names>R</given-names></name><name name-style="western"><surname>Kurths</surname><given-names>J</given-names></name><name name-style="western"><surname>Fiehn</surname><given-names>O</given-names></name><name name-style="western"><surname>Weckwerth</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Interpreting correlations in metabolomic networks.</article-title>             <source>Biochem Soc Trans</source>             <volume>31</volume>             <fpage>1476</fpage>             <lpage>1478</lpage>          </element-citation></ref><ref id="pone.0002148-Steuer2"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Steuer</surname><given-names>R</given-names></name><name name-style="western"><surname>Kurths</surname><given-names>J</given-names></name><name name-style="western"><surname>Fiehn</surname><given-names>O</given-names></name><name name-style="western"><surname>Weckwerth</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Observing and interpreting correlations in metabolomic networks.</article-title>             <source>Bioinformatics</source>             <volume>19</volume>             <fpage>1019</fpage>             <lpage>1026</lpage>          </element-citation></ref><ref id="pone.0002148-Haken1"><label>23</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haken</surname><given-names>H</given-names></name></person-group>             <year>1983</year>             <source>Advanced Synergetics: Instability Hierarchies of Self-Organizing Systems and Devices.</source>             <publisher-name>Springer Verlag</publisher-name>          </element-citation></ref><ref id="pone.0002148-Honerkamp1"><label>24</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Honerkamp</surname><given-names>J</given-names></name></person-group>             <year>1998</year>             <source>Stochastische Dynamische Systeme. Konzepte, numerische Methoden, Datenanalysen.</source>             <publisher-name>Wiley-VCH</publisher-name>          </element-citation></ref><ref id="pone.0002148-Hopfield1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group>             <year>1982</year>             <article-title>Neural networks and physical systems with emergent collective computational abilities.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>79</volume>             <fpage>2554</fpage>             <lpage>2558</lpage>          </element-citation></ref><ref id="pone.0002148-Rummelhart1"><label>26</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rummelhart</surname><given-names>DE</given-names></name><name name-style="western"><surname>McClelland</surname><given-names>JL</given-names></name></person-group>             <year>1986</year>             <source>Parallel Distributed Processing. Explorations in the Microstructure of Cognition. Volume 1: Foundations.</source>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref><ref id="pone.0002148-Rummelhart2"><label>27</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rummelhart</surname><given-names>DE</given-names></name><name name-style="western"><surname>McClelland</surname><given-names>JL</given-names></name></person-group>             <year>1987</year>             <source>Parallel Distributed Processing. Explorations in the Microstructure of Cognition. Volume 2: Psychological and Biological Models.</source>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref><ref id="pone.0002148-Haken2"><label>28</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haken</surname><given-names>H</given-names></name></person-group>             <year>1991</year>             <source>Synergetic Computers and Cognition.</source>             <publisher-name>Springer Verlag</publisher-name>          </element-citation></ref><ref id="pone.0002148-Hertz1"><label>29</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hertz</surname><given-names>JA</given-names></name><name name-style="western"><surname>Palmer</surname><given-names>RG</given-names></name><name name-style="western"><surname>Krogh</surname><given-names>AS</given-names></name></person-group>             <year>1991</year>             <source>Introduction to the Theory of Neural Computation.</source>             <publisher-name>Westview Press</publisher-name>          </element-citation></ref><ref id="pone.0002148-Miyashita1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miyashita</surname><given-names>Y</given-names></name><name name-style="western"><surname>Chang</surname><given-names>HS</given-names></name></person-group>             <year>1988</year>             <article-title>Neuronal correlate of pictorial short-term memory in the primate temporal cortex.</article-title>             <source>Nature</source>             <volume>331</volume>             <fpage>68</fpage>             <lpage>70</lpage>          </element-citation></ref><ref id="pone.0002148-Miyashita2"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miyashita</surname><given-names>Y</given-names></name></person-group>             <year>1988</year>             <article-title>Neuronal correlate of visual associative long-term memory in the primate temporal cortex.</article-title>             <source>Nature</source>             <volume>335</volume>             <fpage>817</fpage>             <lpage>820</lpage>          </element-citation></ref><ref id="pone.0002148-Galn2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Galán</surname><given-names>RF</given-names></name><name name-style="western"><surname>Sachse</surname><given-names>S</given-names></name><name name-style="western"><surname>Galizia</surname><given-names>CG</given-names></name><name name-style="western"><surname>Herz</surname><given-names>AVM</given-names></name></person-group>             <year>2004</year>             <article-title>Odor-driven attractor dynamics in the antennal lobe allow for simple and rapid olfactory pattern classification.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>999</fpage>             <lpage>1012</lpage>          </element-citation></ref><ref id="pone.0002148-Mazor1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mazor</surname><given-names>O</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Transient dynamics versus fixed points in odor representations by locust antennal lobe projection neurons.</article-title>             <source>Neuron</source>             <volume>48</volume>             <fpage>661</fpage>             <lpage>673</lpage>          </element-citation></ref><ref id="pone.0002148-White1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>White</surname><given-names>LE</given-names></name><name name-style="western"><surname>Coppola</surname><given-names>DM</given-names></name><name name-style="western"><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group>             <year>2001</year>             <article-title>The contribution of sensory experience to the maturation of orientation selectivity in ferret visual cortex.</article-title>             <source>Nature</source>             <volume>411</volume>             <fpage>1049</fpage>             <lpage>1052</lpage>          </element-citation></ref><ref id="pone.0002148-Schiff1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schiff</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Huang</surname><given-names>X</given-names></name><name name-style="western"><surname>Wu</surname><given-names>JY</given-names></name></person-group>             <year>2007</year>             <article-title>Dynamical evolution of spatiotemporal patterns in mammalian middle cortex.</article-title>             <source>Phys Rev Lett</source>             <volume>98</volume>             <fpage>178102</fpage>          </element-citation></ref><ref id="pone.0002148-Lennie1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name></person-group>             <year>2003</year>             <article-title>The cost of cortical computation.</article-title>             <source>Curr Biol</source>             <volume>13</volume>             <fpage>493</fpage>             <lpage>497</lpage>          </element-citation></ref><ref id="pone.0002148-Priestley1"><label>37</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Priestley</surname><given-names>MB</given-names></name></person-group>             <year>2001</year>             <source>Spectral Analysis and Time Series.</source>             <publisher-name>Academic Press</publisher-name>          </element-citation></ref><ref id="pone.0002148-Neumaier1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Neumaier</surname><given-names>A</given-names></name><name name-style="western"><surname>Schneider</surname><given-names>T</given-names></name></person-group>             <year>2001</year>             <article-title>Estimation of parameters and eigenmodes of multivariate autoregressive models.</article-title>             <source>Acm Transactions on Mathematical Software</source>             <volume>27</volume>             <fpage>27</fpage>             <lpage>57</lpage>          </element-citation></ref><ref id="pone.0002148-Schiff2"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schiff</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Sauer</surname><given-names>T</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>R</given-names></name><name name-style="western"><surname>Weinstein</surname><given-names>SL</given-names></name></person-group>             <year>2005</year>             <article-title>Neuronal spatiotemporal pattern discrimination: the dynamical evolution of seizures.</article-title>             <source>Neuroimage</source>             <volume>28</volume>             <fpage>1043</fpage>             <lpage>1055</lpage>          </element-citation></ref></ref-list></back></article>