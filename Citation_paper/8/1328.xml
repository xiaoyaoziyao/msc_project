<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-25147</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0079138</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories>
<title-group>
<article-title>On the Relationships between Generative Encodings, Regularity, and Learning Abilities when Evolving Plastic Artificial Neural Networks</article-title>
<alt-title alt-title-type="running-head">Artificial Evolution, Regularity and Plasticity</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Tonelli</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Mouret</surname><given-names>Jean-Baptiste</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><addr-line>ISIR, Université Pierre et Marie Curie-Paris 6, CNRS UMR 7222, Paris, France</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Bongard</surname><given-names>Josh</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Vermont, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">mouret@isir.upmc.fr</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: PT JBM. Performed the experiments: PT. Analyzed the data: JBM. Contributed reagents/materials/analysis tools: PT JBM. Wrote the paper: JBM.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>13</day><month>11</month><year>2013</year></pub-date>
<volume>8</volume>
<issue>11</issue>
<elocation-id>e79138</elocation-id>
<history>
<date date-type="received"><day>17</day><month>6</month><year>2013</year></date>
<date date-type="accepted"><day>18</day><month>9</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Tonelli, Mouret</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>A major goal of bio-inspired artificial intelligence is to design artificial neural networks with abilities that resemble those of animal nervous systems. It is commonly believed that two keys for evolving nature-like artificial neural networks are (1) the developmental process that links genes to nervous systems, which enables the evolution of large, regular neural networks, and (2) synaptic plasticity, which allows neural networks to change during their lifetime. So far, these two topics have been mainly studied separately. The present paper shows that they are actually deeply connected. Using a simple operant conditioning task and a classic evolutionary algorithm, we compare three ways to encode plastic neural networks: a direct encoding, a developmental encoding inspired by computational neuroscience models, and a developmental encoding inspired by morphogen gradients (similar to HyperNEAT). Our results suggest that using a developmental encoding could improve the learning abilities of evolved, plastic neural networks. Complementary experiments reveal that this result is likely the consequence of the bias of developmental encodings towards regular structures: (1) in our experimental setup, encodings that tend to produce more regular networks yield networks with better general learning abilities; (2) whatever the encoding is, networks that are the more regular are statistically those that have the best learning abilities.</p>
</abstract>
<funding-group><funding-statement>This work was funded by the Agence Nationale de la Recherche (<ext-link ext-link-type="uri" xlink:href="http://www.agence-nationale-recherche.fr/" xlink:type="simple">http://www.agence-nationale-recherche.fr/</ext-link>) by the grants Creadapt (ANR-12-JS03-0009) and EvoNeuro (ANR-09-EMER-005). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="12"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>A major goal of bio-inspired artificial intelligence is to design artificial neural networks (ANNs) with abilities that resemble those of animal nervous systems <xref ref-type="bibr" rid="pone.0079138-Pfeifer1">[1]</xref>–<xref ref-type="bibr" rid="pone.0079138-Mouret1">[4]</xref>. A promising approach to design such “artificial nervous systems” is to use evolution-inspired algorithms, in particular because Darwinian evolution is regarded as the primary process responsible for shaping their natural counterparts. Despite the large amount of work in this direction, striking differences still separate most artificially-evolved networks from biological ones: biological nervous systems are <italic>much larger</italic> <xref ref-type="bibr" rid="pone.0079138-Braitenberg1">[5]</xref>, <italic>much more organized</italic> <xref ref-type="bibr" rid="pone.0079138-Meunier1">[6]</xref>, <italic>much more plastic</italic> <xref ref-type="bibr" rid="pone.0079138-Abbott1">[7]</xref> and, overall, much more complex <xref ref-type="bibr" rid="pone.0079138-Kandel1">[8]</xref>.</p>
<p>It is commonly believed that the key for understanding the evolution of large and organized neural networks is the developmental process that links genes to nervous systems <xref ref-type="bibr" rid="pone.0079138-Pfeifer1">[1]</xref>, <xref ref-type="bibr" rid="pone.0079138-Hornby1">[9]</xref>–<xref ref-type="bibr" rid="pone.0079138-Clune1">[11]</xref>. The genotype of animals does not encode each synapse individually, it instead describes rules of development that are executed multiple times to give birth to networks with regular patterns of connection. Influenced by this concept, many researchers proposed <italic>artificial developmental systems</italic> with diverse inspirations including chemical gradients <xref ref-type="bibr" rid="pone.0079138-Clune1">[11]</xref>, <xref ref-type="bibr" rid="pone.0079138-Stanley2">[12]</xref>, gene regulatory networks <xref ref-type="bibr" rid="pone.0079138-Bongard1">[13]</xref>, <xref ref-type="bibr" rid="pone.0079138-Mattiussi1">[14]</xref>, cell divisions <xref ref-type="bibr" rid="pone.0079138-Gruau1">[15]</xref>, computational neuro-science models <xref ref-type="bibr" rid="pone.0079138-Mouret2">[16]</xref> and L-systems <xref ref-type="bibr" rid="pone.0079138-Hornby1">[9]</xref>.</p>
<p>Nonetheless, most networks evolved with developmental systems cannot change during the “lifetime” of the controlled agent, whereas animal nervous systems are continuously changing to enable on-line behavioral adaptation and learning <xref ref-type="bibr" rid="pone.0079138-Abbott1">[7]</xref>. The basis of most of these changes seems to be provided by <italic>synaptic plasticity</italic>, that is, by the ability of synapses to strengthen or weaken over time <xref ref-type="bibr" rid="pone.0079138-Abbott1">[7]</xref>, <xref ref-type="bibr" rid="pone.0079138-Hebb1">[17]</xref>. Several papers report experiments in which neural networks with synaptic plasticity are evolved <xref ref-type="bibr" rid="pone.0079138-Floreano1">[2]</xref>, <xref ref-type="bibr" rid="pone.0079138-Gruau1">[15]</xref>, <xref ref-type="bibr" rid="pone.0079138-Niv1">[18]</xref>–<xref ref-type="bibr" rid="pone.0079138-Risi2">[24]</xref>. Yet, only a handful of them use developmental systems <xref ref-type="bibr" rid="pone.0079138-Gruau1">[15]</xref>, <xref ref-type="bibr" rid="pone.0079138-Soltoggio1">[20]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi2">[24]</xref>.</p>
<p>The present paper shows that these two topics–developmental systems and synaptic plasticity–are actually deeply connected.</p>
<p>One of the main challenge when designing ANNs with learning abilities is to make them capable of learning in a large class of situations, that is, designing them so they can adapt their behavior to maximize a reward signal (or minimize an error) in as many situations as possible. For instance, it has been famously shown that single layer perceptrons are only capable of learning linearly separable patterns <xref ref-type="bibr" rid="pone.0079138-Minsky1">[25]</xref>, whereas multi-layer perceptrons can learn any non-linear function (provided enough neurons are available) <xref ref-type="bibr" rid="pone.0079138-Cybenko1">[26]</xref>. Single-layer perceptrons therefore possess lower learning abilities than multi-layer perceptrons: their architecture critically constrains what they can learn. When artificial evolution is used to design a plastic ANN, the topology of the networks is the result of the interactions between the fitness function, the encoding and the associated variation operators. As a consequence, the encoding and the fitness function have to be carefully crafted so that plastic neural networks are able to learn in as many situations as possible and, specifically, in situations that are not explicitly tested in the fitness function.</p>
<p>The most classic approach is to design a fitness function that tests each neural network in several test cases and rewards individuals that successfully adapt their behavior to each of them. To ensure that networks possess general learning abilities, it is then required to assess their abilities to learn in a new set of test cases, that is, test cases that have never been encountered by the evolutionary process <xref ref-type="bibr" rid="pone.0079138-Chalmers1">[27]</xref>. The success of this “episodic fitness” approach relies on the assumption that if enough test cases are used, then it should become easier for the evolutionary process to design a generic structure than a specialized one.</p>
<p>Unfortunately, even in simplistic and constrained toy problems, the reported experiments show that many test cases need to be included in the fitness function to obtain general learning abilities. For instance <xref ref-type="bibr" rid="pone.0079138-Soltoggio2">[21]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi3">[28]</xref>, don't assess how evolved neural networks can cope with an unknown situation; counter-examples are <xref ref-type="bibr" rid="pone.0079138-Urzelai1">[19]</xref> and <xref ref-type="bibr" rid="pone.0079138-Chalmers1">[27]</xref>. (e.g. 10 to 20 test cases in <xref ref-type="bibr" rid="pone.0079138-Chalmers1">[27]</xref>). For more complex problems, one can expect an exponential growth in the number of required test cases, because the number of possible test cases grows exponentially with the number of inputs/outputs. This approach is, therefore, unlikely to scale-up to life-like neural-networks.</p>
<p>This is where developmental systems have a role to play. These systems evolve short descriptions of large structures by exploiting regularities observed in Nature, such as repetition of useful sub-parts, symmetries, and symmetries with variation <xref ref-type="bibr" rid="pone.0079138-Stanley2">[12]</xref>, <xref ref-type="bibr" rid="pone.0079138-Hornby2">[29]</xref>. They more easily describe regular structures than irregular ones, because the former can be described by a few general rules whereas the latter require describing either each element, or a list of exceptions to general rules. As a consequence, developmental systems bias the search space towards regular structures <xref ref-type="bibr" rid="pone.0079138-Clune1">[11]</xref>. <italic>We here propose that this bias towards regularity is critical to evolve plastic neural networks that can learn in a large variety of situations</italic> (<xref ref-type="fig" rid="pone-0079138-g001">Figure 1</xref>). Intuitively, this bias makes it more likely to obtain generic networks that apply the same learning rules to whole sets of inputs instead of networks that are finely-tuned to only solve the test cases used in the fitness function. A direct consequence is that <italic>using developmental systems to evolve plastic neural networks should facilitate the evolution of plastic ANNs with general learning abilities</italic>.</p>
<fig id="pone-0079138-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g001</object-id><label>Figure 1</label><caption>
<title>Main hypothesis.</title>
<p>Using developmental encodings should facilitate the evolution of plastic ANNs with high learning abilities.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g001" position="float" xlink:type="simple"/></fig></sec><sec id="s2">
<title>Experimental Setup</title>
<p>This hypothesis is tested using a simulated “Skinner box” (<xref ref-type="fig" rid="pone-0079138-g002">Figure 2</xref>), a classic experimental setup for operant conditioning in which a caged animal must learn to associate stimuli (e.g. lights) to actions (e.g. pushing a lever). If the animal executes the correct action, it is rewarded (e.g. by some food); if it chooses the wrong one, it is punished (e.g. by an electric shock). There is no delay in the reward, so there is no credit assignment problem <xref ref-type="bibr" rid="pone.0079138-Sutton1">[30]</xref>. We consider only one-to-one associations so that, for each simple stimulus (each light), there is a different action to perform. Four stimuli and four actions are used; there are therefore 256 possible sets of stimulus/action (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e001" xlink:type="simple"/></inline-formula>; see Appendix S1 for the list of possible association sets). We formalize the stimulus/action associations using the concept of association sets:</p>
<fig id="pone-0079138-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g002</object-id><label>Figure 2</label><caption>
<title>A. Concept of the “Skinner box”.</title>
<p>A caged animal must learn to associate stimuli (here lights) to actions (here pushing a lever). The experimenter selects a stimulus/action association, presents it to the animal, record the action, and gives the reward to the animal. The experimenter then chooses another association in the association set and starts the cycle again. The association set is learned once the animal associates the right action to each stimulus. <bold>B. Formalization of the Skinner box as a task for an artificial neural network.</bold> Each stimulus is an input of the neural network. Positive and negative rewards are two additional inputs. The output is selected according to a softmax function (<xref ref-type="sec" rid="s5">Methods</xref>) and the result of the softmax is looped back to the input layer.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g002" position="float" xlink:type="simple"/></fig>
<p><bold>Definition 1 (Association):</bold> <italic>An association is a pair </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e002" xlink:type="simple"/></inline-formula><italic> of input/output that leads to the maximum positive reward. In our system (</italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e003" xlink:type="simple"/></inline-formula><italic>: </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e004" xlink:type="simple"/></inline-formula><italic> inputs, </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e005" xlink:type="simple"/></inline-formula><italic> outputs), </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e006" xlink:type="simple"/></inline-formula><italic> is an association that means that the agent must push the </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e007" xlink:type="simple"/></inline-formula><italic> lever when light </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e008" xlink:type="simple"/></inline-formula><italic> is on.</italic></p>
<p><bold>Definition 2 (Association set):</bold> <italic>An association set </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e009" xlink:type="simple"/></inline-formula><italic> is a list of associations that covers all the </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e010" xlink:type="simple"/></inline-formula><italic> possible inputs. For instance, the list of associations </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e011" xlink:type="simple"/></inline-formula><italic> is an association set in our system (</italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e012" xlink:type="simple"/></inline-formula><italic>: </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e013" xlink:type="simple"/></inline-formula><italic> inputs, </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e014" xlink:type="simple"/></inline-formula><italic> outputs). Several inputs can be associated to the same output. For instance, the association set </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e015" xlink:type="simple"/></inline-formula><italic> is also valid in our system.</italic></p>
<p><bold>Definition 3 (Global training set):</bold> <italic>The global training set, called </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e016" xlink:type="simple"/></inline-formula><italic>, is the the set of all the possible association sets of an experimental setup. In our system, there are </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e017" xlink:type="simple"/></inline-formula><italic> possible outputs and </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e018" xlink:type="simple"/></inline-formula><italic> possible inputs (</italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e019" xlink:type="simple"/></inline-formula><italic>), therefore the size of </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e020" xlink:type="simple"/></inline-formula><italic> is </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e021" xlink:type="simple"/></inline-formula><italic> (</italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e022" xlink:type="simple"/></inline-formula><italic>; the complete list of association sets is available in <xref ref-type="supplementary-material" rid="pone.0079138.s001">File S1</xref>). The ideal plastic network should be able to learn every association sets of </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e023" xlink:type="simple"/></inline-formula><italic>.</italic></p>
<p>The fitness function (<xref ref-type="sec" rid="s5">Methods</xref>) assesses the ability to learn a subset of the global training set, called the <italic>evolutionary training set</italic>:</p>
<p><bold>Definition 4 (Evolutionary training set):</bold> <italic>The evolutionary training set, called </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e024" xlink:type="simple"/></inline-formula><italic>, is the set of the association sets used in the fitness function.</italic></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e025" xlink:type="simple"/></inline-formula> is included in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e026" xlink:type="simple"/></inline-formula>; it does not change during an experiment. Depending of the experiment, the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e027" xlink:type="simple"/></inline-formula> varies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e028" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e029" xlink:type="simple"/></inline-formula>. The elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e030" xlink:type="simple"/></inline-formula> have been chosen at random.</p>
<p>The fitness function is normalized by the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e031" xlink:type="simple"/></inline-formula>, so that it actually corresponds to the the number of successfully learned sets divided by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e032" xlink:type="simple"/></inline-formula>. After each evolution experiment, we assess the ability of the network with the best fitness score to learn every possible association set, that is, we evaluate the fitness function on the global training set. We call the success rate of this test the <italic>General Learning Abilities score (GLA score)</italic>. This score reflects how well networks that are selected for their capacity to learn a few association sets are able to learn association sets that have not been encountered during evolution.</p>
<p>The evolved ANNs (<xref ref-type="fig" rid="pone-0079138-g002">Figure 2, B</xref>) have one input for each possible stimulus (i.e., 4 stimuli inputs), one input for positive rewards and one input for negative rewards. They have 4 outputs, each of them representing the probability of choosing each action. The final action is selected thanks to a “softmax” function that randomly selects an action according to a distribution that gives a higher probability to actions that corresponds to high output values distribution <xref ref-type="bibr" rid="pone.0079138-Sutton1">[30]</xref> (<xref ref-type="sec" rid="s5">Methods</xref>). In effect, the neural network can activate any combination of the four available outputs and the softmax function makes sure that only one action is chosen at a time (<xref ref-type="fig" rid="pone-0079138-g002">Figure 2, B</xref>). Only one light (input) is activated at a time.</p>
<p>Plasticity is implemented in the neural networks using <italic>neuro-modulated Hebbian plasticity</italic> <xref ref-type="bibr" rid="pone.0079138-Floreano1">[2]</xref>, <xref ref-type="bibr" rid="pone.0079138-Abbott1">[7]</xref>, <xref ref-type="bibr" rid="pone.0079138-Soltoggio2">[21]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref> (<xref ref-type="sec" rid="s5">Methods</xref>). In this model, neurons are of two kinds, “standard” and “modulatory”; the strength of connection between each pair of neurons is modified using a classic Hebbian rule that is activated only if the sum of inputs from modulatory neurons is above an evolved threshold.</p>
<p>For each association of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e033" xlink:type="simple"/></inline-formula>, the fitness function first presents the stimuli to the neural network for a few time-steps (<xref ref-type="sec" rid="s5">Methods</xref>). Once the final output is computed by the softmax, it is copied to the input layer (feedback inputs). The reward input (positive or negative) is set at the same time. Such feedback loops are often present in computational models of cortex-basal ganglia-thalamus-cortex loops for action selection <xref ref-type="bibr" rid="pone.0079138-Houk1">[31]</xref>–<xref ref-type="bibr" rid="pone.0079138-Girard1">[33]</xref> and are implicit in actor-critic models of reinforcement learning <xref ref-type="bibr" rid="pone.0079138-Sutton1">[30]</xref>. The neural network is then simulated for a few more time-steps (<xref ref-type="sec" rid="s5">Methods</xref>). It is expected that the evolutionary process will connect one or several modulatory neurons to the reward input and that the ANNs will exploit the copied outputs to strengthen/weaken the connections that correspond to the action that has actually been performed. Nonetheless, it must be emphasized that weight changes can occur at any time, including during the first step of the evaluation of the ANN. Only the topology and the synaptic weights of the ANNs, which are designed by evolution, determine when and how synaptic weights change.</p>
<p>The ANNs that solve this task may seem trivial at first sight. However, the evolutionary process needs to add at least one modulatory neuron (inputs cannot be modulatory in our system) and we never found any solution with less than two hidden neurons (one of them being modulatory). Essentially, the challenge raised by this task is to discover learning rules that allow the ANN to exploit a reward to strengthen and weaken the right connections. Typical solutions require three main “discoveries”: (1) identifying and correctly connecting the reward inputs, (2) gating the reward with the softmax choice to modify only the connections corresponding to the chosen action, and (3) applying the resulting reinforcement to a link between the inputs and the output.</p>
<p>The topology and the parameters of evolved ANNs are encoded with three encodings <xref ref-type="bibr" rid="pone.0079138-Floreano1">[2]</xref>, with three different levels of expected regularity (<xref ref-type="fig" rid="pone-0079138-g003">Figure 3</xref>). The first encoding, called the map-based encoding <xref ref-type="bibr" rid="pone.0079138-Mouret2">[16]</xref> (<xref ref-type="sec" rid="s5">Methods</xref>), is inspired by computational neuroscience models in which ANNs are described as graph of single neurons and <italic>neural maps</italic> (spatially-organized identical neurons) that are connected with a few possible connection schemes (usually only one-to-one and one-to-all) <xref ref-type="bibr" rid="pone.0079138-Girard1">[33]</xref>–<xref ref-type="bibr" rid="pone.0079138-Rougier1">[35]</xref>. This encoding produces very regular neural networks because it has to treat each neuron in a map in the exact same way as the other neurons of the same map. The second encoding is a simplified version HyperNEAT <xref ref-type="bibr" rid="pone.0079138-Stanley2">[12]</xref>, called HNN, for Hyper Neural Network (<xref ref-type="sec" rid="s5">Methods</xref>). HyperNEAT-like encodings are developmental encodings in which morphogen gradients are described as feed-forward networks of mathematical functions that operate in a Cartesian space. This indirect approach allows them to encode large networks with Nature-like connection patterns (symmetry, symmetry with variations, repetition, etc.). The last encoding is a classic direct encoding in which evolution directly acts on the structure and the parameters of the ANN (<xref ref-type="sec" rid="s5">Methods</xref>). This encoding has no bias to produce regular networks.</p>
<fig id="pone-0079138-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g003</object-id><label>Figure 3</label><caption>
<title>A. Principle of the map-based, developmental encoding.</title>
<p>The neural network is encoded as a labeled graph (left), which is developped to a graph of maps according to the labels (right). (<xref ref-type="sec" rid="s5">Methods</xref>). <bold>B. Principle of the HNN encoding (minimal HyperNEAT).</bold> Neurons are placed in a 3D substrate (top). To know whether two neurons are connected and the synaptic weight of each connection, a Compositional Pattern Producing Network (CPPN) is queried using the 3D coordinates of the two neurons (<xref ref-type="sec" rid="s5">Methods</xref>). This CPPN is evolved using a direct encoding. To know the parameters of each node (neuron type and threshold value), a second CPPN is queried with the 3D coordinates of the neuron (<xref ref-type="sec" rid="s5">Methods</xref>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g003" position="float" xlink:type="simple"/></fig>
<p>To understand the relationship between encodings, regularity and learning abilities, we have to assess the regularity of evolved ANNs. According to Lipson <xref ref-type="bibr" rid="pone.0079138-Lipson1">[36]</xref>, regularity is the compressibility of the description of the structure. Regrettably, this value is not computable <xref ref-type="bibr" rid="pone.0079138-Li1">[37]</xref> and, to our knowledge, there exists no well-recognized approximation for weighted, directed graphs. The few algorithms designed to compress the graph structure are greedy approximations that only work well for sparse, undirected labeled graphs <xref ref-type="bibr" rid="pone.0079138-Peshkin1">[38]</xref>, <xref ref-type="bibr" rid="pone.0079138-Hayashida1">[39]</xref>. We follow another method to estimate the regularity of networks: counting the number of symmetry axes <xref ref-type="bibr" rid="pone.0079138-Mowshowitz1">[40]</xref>–<xref ref-type="bibr" rid="pone.0079138-Zenil1">[42]</xref>. A graph has an axis of symmetry when two groups of nodes can be swapped without modifying the graph, that is, when there is a repetitive, structural pattern. More axes of symmetry means a better compression because the two groups need to be described only once <xref ref-type="bibr" rid="pone.0079138-Mowshowitz1">[40]</xref>–<xref ref-type="bibr" rid="pone.0079138-Zenil1">[42]</xref>. In graph theory, this kind of symmetry is called an automorphism and fast algorithms exist to count them <xref ref-type="bibr" rid="pone.0079138-McKay1">[43]</xref>–<xref ref-type="bibr" rid="pone.0079138-Katebi1">[45]</xref> (<xref ref-type="sec" rid="s5">Methods</xref>).</p>
<p>Networks are evolved using the classic multi-objective evolutionary algorithm NSGA-II <xref ref-type="bibr" rid="pone.0079138-Deb1">[46]</xref>, <xref ref-type="bibr" rid="pone.0079138-Deb2">[47]</xref>. Two objectives are optimized: the fitness of networks (<xref ref-type="sec" rid="s5">Methods</xref>) and a behavioral novelty objective <xref ref-type="bibr" rid="pone.0079138-Mouret1">[4]</xref>, <xref ref-type="bibr" rid="pone.0079138-Soltoggio3">[22]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref>, <xref ref-type="bibr" rid="pone.0079138-Lehman1">[48]</xref>, <xref ref-type="bibr" rid="pone.0079138-Mouret3">[49]</xref>, to mitigate premature convergence (<xref ref-type="sec" rid="s5">Methods</xref>). These two objectives are optimized during a maximum of 4000 generations of 400 individuals. Experiment are stopped as soon as the best individual of the population reaches a perfect fitness value on the evolutionary training set. At the end of each experiment, the novelty objective is discarded and we consider that the best individual is the one with the best fitness value.</p>
<p>We perform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e034" xlink:type="simple"/></inline-formula> series of independent experiments by varying the size of the evolutionary learning set from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e035" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e036" xlink:type="simple"/></inline-formula> (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e037" xlink:type="simple"/></inline-formula>). For each series, the three investigated encodings are tested (direct encoding, map-based encoding and HNN encoding). Each experiment is replicated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e038" xlink:type="simple"/></inline-formula> times to obtain statistics. We therefore launch a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e039" xlink:type="simple"/></inline-formula> experiments, each one lasting between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e040" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e041" xlink:type="simple"/></inline-formula> hours on our computers (Intel Xeon <email xlink:type="simple">E5520@2.27</email> GHz) depending on the time required to converge and the size of the evolutionary training set. Because of this large computational time, we were not able to extend our experiments to harder problems, for instance with more inputs/outputs.</p>
</sec><sec id="s3">
<title>Results</title>
<p>For each encoding, we compute the GLA score of networks with a perfect fitness on the evolutionary training set and we plot it as a function of the size of the evolutionary training set.</p>
<p>The results show a clear difference in the GLA scores obtained with each encoding (<xref ref-type="fig" rid="pone-0079138-g004">Figure 4, A</xref>). With a direct encoding, the GLA score grows linearly with the size of the evolutionary training set, which is consistent with previous results <xref ref-type="bibr" rid="pone.0079138-Chalmers1">[27]</xref>, and the GLA scores obtained with small values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e042" xlink:type="simple"/></inline-formula> are statistically different from those obtained with larger values (e.g., 1 versus 7: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e043" xlink:type="simple"/></inline-formula>; 4 versus 7, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e044" xlink:type="simple"/></inline-formula>, 3 versus 6, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e045" xlink:type="simple"/></inline-formula>; unless otherwise specified, the statistical test in this paper is the Mann-Whitney U-test). With the direct encoding, using a fitness that tests at least 6 associations sets (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e046" xlink:type="simple"/></inline-formula>) is required to obtain networks with a GLA-score similar to the one reached with the map-based encoding with only 2 association tests (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e047" xlink:type="simple"/></inline-formula>). The HNN encoding appears as a trade-off between the direct encoding and the map-based encoding: for each value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e048" xlink:type="simple"/></inline-formula>, the GLA score obtained with HNN is consistently higher than the one obtained with the direct encoding, yet it is lower than the one reached with the map-based encoding (for 2, 3 or 4 association sets, HNN versus direct encoding, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e049" xlink:type="simple"/></inline-formula>; for 1, 2, 3 or 5 association sets, HNN versus map-based encoding, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e050" xlink:type="simple"/></inline-formula>; with 4 association sets and the HNN encoding, there are not enough networks with a perfect fitness score to perform a statistical analysis).</p>
<fig id="pone-0079138-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g004</object-id><label>Figure 4</label><caption>
<title>Relationship between encodings, general learning abilities and the size of the evolutionary training set (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e051" xlink:type="simple"/></inline-formula>).</title>
<p><bold>A</bold>. Generative encodings yield plastic ANNs with better general learning abilities than those evolved with a direct encoding. Morever, increasing the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e052" xlink:type="simple"/></inline-formula> increases the general learning abilities. Each box extends from the lower to upper quartile values of the data, with a symbol at the median. Whiskers extend to the most extreme data point within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e053" xlink:type="simple"/></inline-formula>, where IQR is the interquartile range. Flier points (outliers) are those past the end of the whiskers. X-values are shifted for the map-based encoding and the direct encoding in order to make the figure readable. <bold>B</bold>. Generative encodings yield more regular networks than a direct encoding, and increasing the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e054" xlink:type="simple"/></inline-formula> increases the regularity of evolved networks.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g004" position="float" xlink:type="simple"/></fig>
<p>As expected, each encoding leads to different levels of regularity, and increasing the number of association sets used in the fitness function increases the regularity of evolved neural networks (<xref ref-type="fig" rid="pone-0079138-g004">Figure 4, B</xref>). All the networks evolved with the map-based encoding are regular: they all have at least one symmetry axis. The HNN encoding also leads to many networks with at least one symmetry axis (from 80% to 100%), whereas the direct encoding leads to substantially fewer regular networks (from 20% to 70%, depending on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e055" xlink:type="simple"/></inline-formula>). These numbers vary with the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e056" xlink:type="simple"/></inline-formula>. With the HNN encoding, three association sets are needed to obtain 100% of regular networks; with the direct encoding, the number of regular networks grows from 20%, when one association set is used during evolution (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e057" xlink:type="simple"/></inline-formula>), to 60–70% when more than 6 association sets are used (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e058" xlink:type="simple"/></inline-formula>).</p>
<p>To further understand this result, we plot the network with the best learning abilities for each encoding and each size of the evolutionary learning set (<xref ref-type="fig" rid="pone-0079138-g005">Figure 5</xref>). We observe the same overall link between learning abilities and regularity as on <xref ref-type="fig" rid="pone-0079138-g004">Figure 4</xref>, but some networks have good learning abilities with only a few automorphisms, like the network evolved with a direct encoding and 6 association sets (GLA score of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e059" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e060" xlink:type="simple"/></inline-formula> automorphisms). This result is possible because nothing encourages a directly encoded network to duplicate the same sub-structure several times: it may be sometimes easier to either re-invent 4 times the same function but with slight changes, or to design an integrated solution that relies on only one complex structure. This particular network seems to use a centralized structure with only one modulatory neuron that modulates all the plastic connections of the network. Conversely, some regular networks have a low GLA score, such as the network evolved with HNN and one association set (GLA score of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e061" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e062" xlink:type="simple"/></inline-formula> automorphisms). There is no paradox in this result: the regularities can be at the wrong place to lead to high-learning abilities.</p>
<fig id="pone-0079138-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g005</object-id><label>Figure 5</label><caption>
<title>Network with the best learning abilities, for each encoding and each size of the evolutionary learning set.</title>
<p>Each network is the best (in term of learning abilities) of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e063" xlink:type="simple"/></inline-formula> independent runs. Inhibitory connections are represented as green line and excitatory ones as red lines. The width of the lines is proportional to the corresponding synaptic weight (for modulated connections, the line width is determined after one of the learning phases, for one of the possible association sets). Input neurons are in green, output neurons in red, modulatory neuron in gray and standard neurons in blue. “#automorphisms” means “number of automorphisms” (<xref ref-type="sec" rid="s5">Methods</xref>). Nodes that are not connected (directly or indirectly) to at least one input and one output are not drawn.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g005" position="float" xlink:type="simple"/></fig>
<p>Whatever the encoding and the size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e064" xlink:type="simple"/></inline-formula> are, networks with the best learning abilities are those that are the most regular (<xref ref-type="fig" rid="pone-0079138-g006">Figure 6, A</xref>; this figure use the same data as <xref ref-type="fig" rid="pone-0079138-g004">Figure 4</xref>). Hence, among networks evolved with the direct encoding, those that have at least 2 automorphisms (one axis of symmetry) have a better GLA score than those that have no automorphism (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e065" xlink:type="simple"/></inline-formula>). Those with more than 3 automorphisms also have statistically better learning abilities than those with two automorphisms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e066" xlink:type="simple"/></inline-formula>) and than those without any symmetry axis (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e067" xlink:type="simple"/></inline-formula>). The same tendency is present with the HNN encoding: networks with at least two automorphisms (i.e., networks with at least one symmetry axis) have a higher GLA score than those that have no symmetry axis (one automorphism, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e068" xlink:type="simple"/></inline-formula>); networks with more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e069" xlink:type="simple"/></inline-formula> automorphisms have a higher GLA score than those with at least two automorphisms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e070" xlink:type="simple"/></inline-formula>).</p>
<fig id="pone-0079138-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g006</object-id><label>Figure 6</label><caption>
<title>Relationship between regularity and general learning abilities.</title>
<p>Data are from the same experiments as <xref ref-type="fig" rid="pone-0079138-g004">Figure 4</xref>. The “minimum number of automorphims” means that if, for example, a network has 4 automorphisms, it is included in columns 1,2,3 and 4. X-values are shifted for the map-based encoding and the direct encoding in order to make the figure readable. <bold>A</bold>. The more automorphisms a network has, the more likely it is to have good general learning abilities (GLA score). Each box extends from the lower to upper quartile values of the data, with a symbol at the median. Whiskers extend to the most extreme data point within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e071" xlink:type="simple"/></inline-formula>, where IQR is the interquartile range. Flier points (outliers) are those past the end of the whiskers. <bold>B</bold>. 7% of networks evolved with a direct encoding have more than 3 autormorphisms. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e072" xlink:type="simple"/></inline-formula> of those evolved with HNN have more than 3 automorphisms. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e073" xlink:type="simple"/></inline-formula> of networks evolved with the map-based encoding have more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e074" xlink:type="simple"/></inline-formula> autmorphisms; 100% of them have at least 10 automorphisms.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g006" position="float" xlink:type="simple"/></fig>
<p>With the HNN encoding, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e075" xlink:type="simple"/></inline-formula> of networks have exactly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e076" xlink:type="simple"/></inline-formula> automorphisms but only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e077" xlink:type="simple"/></inline-formula> of them have 25 or more automorphisms (<xref ref-type="fig" rid="pone-0079138-g006">Figure 6, B</xref>, blue line). With the map-based encoding, a drop from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e078" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e079" xlink:type="simple"/></inline-formula> occurs at the same number of automorphisms (<xref ref-type="fig" rid="pone-0079138-g006">Figure 6, B</xref>, grey line). A network with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e080" xlink:type="simple"/></inline-formula> automorphisms is a network in which a sub-network is repeated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e081" xlink:type="simple"/></inline-formula> times (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e082" xlink:type="simple"/></inline-formula>, <xref ref-type="sec" rid="s5">Methods</xref>). This number is particular in our experiments because both HNN and the map-based encoding group neurons by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e083" xlink:type="simple"/></inline-formula>, therefore the number of automorphisms is expected to be a multiple of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e084" xlink:type="simple"/></inline-formula>: a different number means that at least one neuron of a group has a connectivity pattern that is different from the rest of the group. With HNN, this kind irregularity is possible but unlikely. With the map-based encoding, it is not possible, that is why all map-based networks have a number of automorphisms exactly equals to a multiple of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e085" xlink:type="simple"/></inline-formula> (for instance, on <xref ref-type="fig" rid="pone-0079138-g005">figure 5</xref>, all map-based networks have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e086" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e087" xlink:type="simple"/></inline-formula> automorphisms).</p>
</sec><sec id="s4">
<title>Conclusion and Discussion</title>
<p>The experiments reported in this paper add weight to the hypothesis that using a developmental encoding improves the learning abilities of evolved, plastic neural networks. Complementary experiments reveal that this result is the consequence of the bias of developmental encodings towards regular structures <xref ref-type="bibr" rid="pone.0079138-Clune1">[11]</xref>: (1) encodings that tend to produce more regular networks yielded networks with better general learning abilities; (2) in our experimental setup, whatever the encoding is, networks that are the more regular are statistically those that have the best learning abilities. This second point implies that an indirect encoding that is not biased towards regular network should not lead to ANNs with high learning abilities; it also implies that a direct encoding combined with a helper objective that encourages regularity should lead to ANNs with good learning abilities (see <xref ref-type="bibr" rid="pone.0079138-Mouret1">[4]</xref> and <xref ref-type="bibr" rid="pone.0079138-Clune2">[50]</xref> for examples of helper objectives with a direct encoding). Nonetheless, our experiments show that current generative encodings and neuro-modulated Hebbian plasticity make a promising combination to evolve large, plastic neural networks. Future work in this direction should investigate whether this combination holds its promises in other tasks such as learning in a maze <xref ref-type="bibr" rid="pone.0079138-Soltoggio2">[21]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref> or visual processing <xref ref-type="bibr" rid="pone.0079138-Stanley2">[12]</xref>.</p>
<p>According to our results, neural networks evolved with an encoding biased towards regularity could be more flexible than those evolved with an unbiased encoding: they are better at learning association sets that have never been encountered during their evolution. To achieve this flexibility, they have to possess connections that were not directly selected during evolution. In other words, their flexibility stems from “spandrels” <xref ref-type="bibr" rid="pone.0079138-Gould1">[51]</xref>: they are the byproducts of the bias that make evolution more likely to duplicate a sub-structure than to design a specialized circuit.</p>
<p>These results are in opposition to the general tendency of neural networks to minimize connection costs <xref ref-type="bibr" rid="pone.0079138-Clune2">[50]</xref>, <xref ref-type="bibr" rid="pone.0079138-Chklovskii1">[52]</xref>–<xref ref-type="bibr" rid="pone.0079138-Chen1">[54]</xref> because they show that flexible behaviors require maintaining many “useless” connections. They indicate that a selective pressure for flexibility is likely to favor developmental procedures that would result in connections that do not procure any short-term advantage. In a constant environment, these connections should disappear; but in a constantly changing environment – which puts more pressure on flexibility –, these connections appear critical. This view is consistent with the theory of “variability selection”, which posits that flexibility is one of the primary selective pressure that shaped the brains of hominids <xref ref-type="bibr" rid="pone.0079138-Potts1">[55]</xref>, <xref ref-type="bibr" rid="pone.0079138-Richerson1">[56]</xref>.</p>
<p>The conflict between flexibility and connection costs also echoes the debate about the modularity/non-modularity of the mammalian brain <xref ref-type="bibr" rid="pone.0079138-Meunier1">[6]</xref>, <xref ref-type="bibr" rid="pone.0079138-Grossberg1">[57]</xref>, <xref ref-type="bibr" rid="pone.0079138-Bullmore1">[58]</xref>, since the minimization of connection costs has been linked with the evolution of modularity <xref ref-type="bibr" rid="pone.0079138-Clune2">[50]</xref>, <xref ref-type="bibr" rid="pone.0079138-Striedter1">[59]</xref>. Our results thus suggest that the parts of the brain that heavily rely on synaptic plasticity to achieve flexible behaviors should be less modular than simpler, less plastic parts. To test this proposition, it is possible to launch computational experiments in which plastic neural networks are evolved with a selective pressure to minimize connection costs and different flexibility requirements.</p>
<p>Pushed to the extreme, the results of our experiments suggest that the best flexibility would be achieved with fully connected networks, since this would be the best possible regularity. In real brains, such a connectivity would be challenging for pure physical reasons <xref ref-type="bibr" rid="pone.0079138-Braitenberg1">[5]</xref>, <xref ref-type="bibr" rid="pone.0079138-Chklovskii1">[52]</xref>: if each neuron of a mouse was connected to each other, its brain (about 10 millions neurons) would at least occupy 350 cubic meters <xref ref-type="bibr" rid="pone.0079138-Gould1">[51]</xref> (about the cranial volume of an Orangutan). Artificial brains do not have such limitations and can be designed as fully connected <xref ref-type="bibr" rid="pone.0079138-Hopfield1">[60]</xref>, but most neural networks used in machine learning are made of layers of neurons, with each layer fully connected to the next one <xref ref-type="bibr" rid="pone.0079138-Cybenko1">[26]</xref>, <xref ref-type="bibr" rid="pone.0079138-Haykin1">[61]</xref>. Layers are a very specific structure that prevents some flexibility (non-Markovian tasks cannot be learned), but they make learning easier, because feed-forward networks have no intrinsic dynamics (contrary to recurrent neural networks). These networks are still very regular and flexible. In image processing, convolutional neural networks are classic feed-forward neural networks in which many, well-chosen connections are removed and many synaptic weights are constrained to be equal <xref ref-type="bibr" rid="pone.0079138-LeCun1">[62]</xref>. These networks are much easier to train than classic layered neural networks, but they cannot learn when the input data do not look like images.</p>
<p>These examples highlight a potential trade-off between flexibility and trainability, or, put differently, between learning abilities and learning efficiency: in many situations, it seems beneficial to trade some flexibility to make the system easier to train. Our experiments considered a simple situation in which trainability was not a major concern because the input/output patterns are simple and low-dimensional. In more challenging tasks, the evolutionary process would probably have to find the best trade-off between trainability and flexibility, and therefore between regularity and specialization. Nonetheless, although convolutional networks are less regular than multi-layer perceptrons, they are still very regular and could be generated with a generative encoding. Generative encodings that aim at intermediate regularity might thus be one of the key to explore this trainability/flexibility trade-off.</p>
<p>Overall, the present paper shows that evolution, development and synaptic plasticity are three interleaved processes that are hard to study separately. While an extensive understanding of their interactions is probably out of reach with the current state of knowledge, studies that combine simple models of each of these processes shed light on how one of them – here development – can simplify another – here learning. Such studies appear helpful for both building a global vision of the evolution of intelligent lifeforms as well as harnessing evolution to create intelligent agents.</p>
</sec><sec id="s5" sec-type="methods">
<title>Methods</title>
<sec id="s5a">
<title>Plastic neuron model</title>
<p>Following <xref ref-type="bibr" rid="pone.0079138-Soltoggio2">[21]</xref>–<xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref>, we distinguish two types of neurons: “standard neurons” and “modulatory neurons”. Inputs of each neuron are divided into modulatory inputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e088" xlink:type="simple"/></inline-formula> and standard <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e089" xlink:type="simple"/></inline-formula> inputs. The output <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e090" xlink:type="simple"/></inline-formula> of a neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e091" xlink:type="simple"/></inline-formula> is then defined as follows:<disp-formula id="pone.0079138.e092"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e092" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e093" xlink:type="simple"/></inline-formula> is the identifier of a neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e094" xlink:type="simple"/></inline-formula> its output, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e095" xlink:type="simple"/></inline-formula> its bias, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e096" xlink:type="simple"/></inline-formula> a sigmoid on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e097" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e098" xlink:type="simple"/></inline-formula> the synaptic weight between neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e099" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e100" xlink:type="simple"/></inline-formula>. Each non-modulatory synaptic weight <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e101" xlink:type="simple"/></inline-formula> is modified with regards to the sum of modulatory inputs and a constant coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e102" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e103" xlink:type="simple"/></inline-formula> in our experiments):<disp-formula id="pone.0079138.e104"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e104" xlink:type="simple"/><label>(2)</label></disp-formula><disp-formula id="pone.0079138.e105"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e105" xlink:type="simple"/><label>(3)</label></disp-formula><disp-formula id="pone.0079138.e106"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e106" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e107" xlink:type="simple"/></inline-formula> is a sigmoid on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e108" xlink:type="simple"/></inline-formula> (to allow positive and negative modifications of synaptic weights).</p>
</sec><sec id="s5b">
<title>Fitness function and behavioral descriptors</title>
<p>The fitness function computes the number of associations that the network successfully learn, given an evolutionary learning set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e109" xlink:type="simple"/></inline-formula>.</p>
<p>For each association set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e110" xlink:type="simple"/></inline-formula> (for instance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e111" xlink:type="simple"/></inline-formula>), this function first randomly initializes the modulated weights, that is, the network does not have to un-learn what was previously learned. The network is then allocated 90 learning episodes, each one executing the following steps:</p>
<list list-type="bullet"><list-item>
<p>successively select one of the four associations of the association set (for instance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e112" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>set the stimuli inputs of the neural network according to the chosen association and set the other inputs (reward and feedback) to zero (for instance, for the association <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e113" xlink:type="simple"/></inline-formula>, the input will be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e114" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>compute the output of the network by simulating it during 5 time-steps (5 time-steps is enough to allow a signal to travel from the inputs neurons to the output neurons);</p>
</list-item><list-item>
<p>select an action using the four outputs of the neural network and a softmax function (see section “Output selection”);</p>
</list-item><list-item>
<p>set the reward inputs (i.e., positive reward if the output is correct, negative otherwise) and the feedback inputs (for instance, if the output is “C”, a wrong answer, then the new input will be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e115" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>simulate the network again for 5 time-steps (this is the step where the network is expected to reinforce connections; however, nothing prevents adaptation to occur during the previous activation);</p>
</list-item><list-item>
<p>if the last learning episode for this association set is reached:</p>
<list list-type="simple"><list-item>
<p>the positive reward that corresponds to each input of the set is added to the fitness (for instance, if the network's output was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e116" xlink:type="simple"/></inline-formula> for association <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e117" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e118" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e119" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e120" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e121" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e122" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e123" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e124" xlink:type="simple"/></inline-formula> is added to the current value of the fitness);</p>
</list-item><list-item>
<p>the output of the network (before the softmax) for each input of the set is appended to the behavior descriptor (for instance, for the previously described outputs, we would append the vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e125" xlink:type="simple"/></inline-formula>);</p>
</list-item></list>
</list-item></list>
<p>In summary, the final fitness value corresponds to the average number of associations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e126" xlink:type="simple"/></inline-formula> that have been successfully learned. The final behavior descriptor is a vector that contains the final output of the network for each association of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e127" xlink:type="simple"/></inline-formula>.</p>
<p>This fitness function is described in a more algorithmic on <xref ref-type="fig" rid="pone-0079138-g007">figure 7</xref>.</p>
<fig id="pone-0079138-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g007</object-id><label>Figure 7</label><caption>
<title>Algorithmic view of the fitness function.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g007" position="float" xlink:type="simple"/></fig></sec><sec id="s5c">
<title>Output selection (softmax)</title>
<p>At the ouptut of the neural networks, the action is selected thanks to a softmax function <xref ref-type="bibr" rid="pone.0079138-Sutton1">[30]</xref>:<disp-formula id="pone.0079138.e128"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e128" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e129" xlink:type="simple"/></inline-formula> is the probability of selecting output <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e130" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e131" xlink:type="simple"/></inline-formula> is the activity of output <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e132" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e133" xlink:type="simple"/></inline-formula> is a constant. In effect, this distribution gives a higher probability to actions that corresponds to high output values. If values are close, then they will have similar chances to be selected; if values are very contrasted, then the softmax function is equivalent to a “max” function. Using this distribution instead of a simpler “max” function allows network to explore – which is required to learn – and encourages the contrast between output. This technique is commonly employed in reinforcement learning <xref ref-type="bibr" rid="pone.0079138-Sutton1">[30]</xref>.</p>
</sec><sec id="s5d">
<title>Map-based encoding</title>
<p>Many computational neuroscience models (e.g. <xref ref-type="bibr" rid="pone.0079138-Girard1">[33]</xref>–<xref ref-type="bibr" rid="pone.0079138-Rougier1">[35]</xref>) are described as graph of neural maps (spatially-organized identical neurons) in which each connection is labeled by a set of parameters that represent the connection scheme <xref ref-type="bibr" rid="pone.0079138-Mouret2">[16]</xref>(<xref ref-type="fig" rid="pone-0079138-g003">Figure 3</xref>). This description of neural networks can be seen as a developmental encoding according to which networks of maps are developed to form a neural networks.</p>
<p>In our model, each edge is associated with three parameters: (1) connection type (“1 to 1” or “1 to all” with uniform synaptic weights); (2) synaptic weight (all connections between maps have the same strength) (3) inhibitory or excitatory (a Boolean value). Similarly, three parameters describe each map: (1) isolated neuron or map of neurons (a Boolean value); (2) inhibitory or excitatory (a Boolean value – the whole map will be inhibitory or excitatory); (3) parameters of the neuron (float number, threshold value). Each label is encoded with a real number in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e134" xlink:type="simple"/></inline-formula>, mutated with polynomial mutation in the same way as intrinsic parameters of neurons and synaptic weights in a direct encoding. The section “parameters” describes how these numbers are translated into Boolean values and parameters.</p>
<p>In the present study, all maps have the same size. Each graph of neural maps is developped into a full neural network by analyzing each node and each edge of the graph to create the corresponding neurons, maps and connections.</p>
<p>Labeled graphs are evolved using the direct encoding (<xref ref-type="sec" rid="s5">Methods</xref>).</p>
</sec><sec id="s5e">
<title>HNN encoding (minimal HyperNEAT)</title>
<p>HyperNEAT is a developmental encoding in which morphogen gradients are described as feed-forward networks of mathematical functions that operate in a Cartesian space <xref ref-type="bibr" rid="pone.0079138-Stanley2">[12]</xref>, called Compositional Pattern Producing Networks (CPPNs). When evolving an ANN, HyperNEAT evolves CPPNs that are then <italic>queried</italic> to know each synaptic weight. This indirect approach allows HyperNEAT to evolve large networks with Nature-like connection patterns (symmetry, symmetry with variations, repetition, etc.).</p>
<p>In the present study, we use a simplified version of HyperNEAT in which the CPPNs are evolved using a simple direct encoding instead of the NEAT method. We chose this simplified version to make easier the reproduction of our results, to enable the use of multi-objective evolutionary algorithms and to focus our study on the developmental process. We call this encoding HNN (Hyper Neural Network).</p>
<p>We place 9 input neurons, 5 hidden neurons and 4 output neurons in a 3D substrate (<xref ref-type="fig" rid="pone-0079138-g003">Figure 3, B</xref>). We describe each individual with two CPPNs: one connection-centred CPPN that returns whether a connection exists (LEO link in HyperNEAT <xref ref-type="bibr" rid="pone.0079138-Verbancsics1">[63]</xref>) and the synaptic weigth, and one node-centred CPPN that returns the intrinsic parameters of each neuron, that is, the threshold value used in the sigmoid and whether the neuron is “modulatory” or “standard”. Three functions are available to the CPPNs: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e135" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e136" xlink:type="simple"/></inline-formula> (sigmoid), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e137" xlink:type="simple"/></inline-formula> (Gaussian) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e138" xlink:type="simple"/></inline-formula> (linear).</p>
<p>Many other substrates can be used and some of them undoubtedly lead to faster convergence; it is also possible to use a single CPPN for both the connection and the node parameters. Nevertheless, the present work is centered on the <italic>consequences</italic> of using <italic>any</italic> developmental encoding when evolving plastic neural networks. The relative performance of each encoding is irrelevant.</p>
</sec><sec id="s5f">
<title>Direct encoding (control experiment, labeled graph, CPPN)</title>
<p>We use a straighforward direct encoding, loosely inspired by NEAT <xref ref-type="bibr" rid="pone.0079138-Stanley3">[64]</xref>, to encode both the labeled graph of the map-based encoding and CPPN for the HNN experiments. We also use it as a control experiment. In this case, the evolved graph is employed in a more classic fashion to directly define a neural network.</p>
<p>In this encoding, a neural network (or a CPPN) is described as a directed graph and five mutation operators are implemented:</p>
<list list-type="bullet"><list-item>
<p>add a connection between two randomly chosen neurons (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e139" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>remove a randomly chosen connection (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e140" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>move the target or the source of a randomly chosen connection (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e141" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>add a neuron by splitting an existing connection in two (the connection weight is kept on the two connections) (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e142" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>delete a randomly chosen neuron and all related connections (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e143" xlink:type="simple"/></inline-formula>);</p>
</list-item><list-item>
<p>change random weights using the polynomial mutation <xref ref-type="bibr" rid="pone.0079138-Deb1">[46]</xref> (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e144" xlink:type="simple"/></inline-formula> for each connection);</p>
</list-item><list-item>
<p>change the intrinsic parameter of a neuron (e.g. the activation function when evolving CPPNs) (probability: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e145" xlink:type="simple"/></inline-formula> for each neuron);.</p>
</list-item></list>
<p>Cross-over is not employed. To initiate the evolutionary process, neural networks of the first generation are feed-forward networks without hidden layer, each one with randomly generated weights. This encoding has been previously employed in many papers, with similar parameters <xref ref-type="bibr" rid="pone.0079138-Mouret1">[4]</xref>, <xref ref-type="bibr" rid="pone.0079138-Mouret3">[49]</xref>, <xref ref-type="bibr" rid="pone.0079138-Mouret4">[65]</xref>–<xref ref-type="bibr" rid="pone.0079138-Ollion1">[67]</xref>.</p>
</sec><sec id="s5g">
<title>Counting automorphisms</title>
<p><bold>Definition 5 (Automorphism):</bold> <italic>An automorphism of a graph </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e146" xlink:type="simple"/></inline-formula><italic> is a permutation </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e147" xlink:type="simple"/></inline-formula><italic> of the vertex set </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e148" xlink:type="simple"/></inline-formula><italic>, such that the pair of vertices </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e149" xlink:type="simple"/></inline-formula><italic> forms an edge if and only if the pair </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e150" xlink:type="simple"/></inline-formula><italic> also forms an edge. Put differently, an automorphism is a graph isomorphism from </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e151" xlink:type="simple"/></inline-formula><italic> to itself.</italic></p>
<p><xref ref-type="fig" rid="pone-0079138-g008">Figure 8</xref> shows the number of automorphisms for a few networks.</p>
<fig id="pone-0079138-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0079138.g008</object-id><label>Figure 8</label><caption>
<title>Examples of networks and corresponding number of automorphisms.</title>
<p>(Colors are only here to help seing the symmetry axes, they have no particular meaning). <bold>A</bold>. A random network typically has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e152" xlink:type="simple"/></inline-formula> automorphism (itself). <bold>B</bold>. The central pattern generator of the lamprey <xref ref-type="bibr" rid="pone.0079138-Ijspeert1">[68]</xref> has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e153" xlink:type="simple"/></inline-formula> automorphisms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e154" xlink:type="simple"/></inline-formula>) because it has two axial symmetries: top-down and left-right. The structure of the graph implies that the vertex orderings <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e155" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e156" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e157" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e158" xlink:type="simple"/></inline-formula> all lead to the same connectivity matrix. <bold>C</bold>. This network has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e159" xlink:type="simple"/></inline-formula> automorphisms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e160" xlink:type="simple"/></inline-formula>) because modules marked <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e161" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e162" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e163" xlink:type="simple"/></inline-formula> can be swapped without changing the connectivity of the network. <bold>D</bold>. This fully connected network with uniform synaptic weights has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e164" xlink:type="simple"/></inline-formula> automorphisms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e165" xlink:type="simple"/></inline-formula>) because each of its nodes can be swapped with any other node. <bold>E</bold>. This multi-layer perceptron with uniform synaptic weights has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e166" xlink:type="simple"/></inline-formula> automorphisms(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e167" xlink:type="simple"/></inline-formula>) because each node of each layer can be swapped with any other node of the same layer.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0079138.g008" position="float" xlink:type="simple"/></fig>
<p>Each network has at least one automorphism, itself. The number of symmetry axes of a network therefore corresponds to the number of automorphisms minus one. Counting and enumerating automorphisms is a NP-complete problem, but there exist fast, exact algorithms that work for most graphs <xref ref-type="bibr" rid="pone.0079138-McKay1">[43]</xref>–<xref ref-type="bibr" rid="pone.0079138-Katebi1">[45]</xref>. In the present work, we use the Bliss library <xref ref-type="bibr" rid="pone.0079138-Junttila1">[44]</xref>.</p>
<p>We count the number of automorphisms of the developped neural network (and not those of the genotype). Modulatory neurons are labeled as “m” and other neurons as “n”. The Bliss library does not handle labeled edges, but edge labels can easily be transformed into node labels as follows: first, synaptic weights are binned into four categories (large negative, small negative, small positive, large positive); second, each of them is associated to a unique label; last, on each connection, a node is added and labeled by the category of the corresponding synaptic weight. Bias of neurons are ignored.</p>
</sec><sec id="s5h">
<title>Evolutionary algorithm</title>
<p>Networks are evolved using NSGA-II <xref ref-type="bibr" rid="pone.0079138-Deb2">[47]</xref>. To mitigate premature convergence, we add to the fitness objective a <italic>behavioral novelty objective</italic> <xref ref-type="bibr" rid="pone.0079138-Mouret1">[4]</xref>, <xref ref-type="bibr" rid="pone.0079138-Soltoggio3">[22]</xref>, <xref ref-type="bibr" rid="pone.0079138-Risi1">[23]</xref>, <xref ref-type="bibr" rid="pone.0079138-Lehman1">[48]</xref>, <xref ref-type="bibr" rid="pone.0079138-Mouret3">[49]</xref> that rewards individuals that do something that has not been done before. In effect, we transform the single-objective problem of maximimizing the fitness into a two-objective optimization problem:<disp-formula id="pone.0079138.e168"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0079138.e168" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e169" xlink:type="simple"/></inline-formula> denotes the distance between the behaviors of individuals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e170" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e171" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e172" xlink:type="simple"/></inline-formula> the set of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e173" xlink:type="simple"/></inline-formula> closest individuals to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e174" xlink:type="simple"/></inline-formula> in the archive and the current population. At the end of each learning session (90 episodes), for each input pattern, the 4 outputs of the neural network are appended to a <italic>behavior descriptor</italic> (see the “Fitness function” section). The distance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e175" xlink:type="simple"/></inline-formula> is the Euclidean distance between the behavior descriptors of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e176" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e177" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s5i">
<title>Parameters</title>
<sec id="s5i1">
<title>Evolutionary algorithm (NSGA-II)</title>
<list list-type="bullet"><list-item>
<p>population size: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e178" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>number of generations: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e179" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s5i2">
<title>Plastic neuron model</title>
<list list-type="bullet"><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e180" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>maximum weight: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e181" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>minimum weight: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e182" xlink:type="simple"/></inline-formula> (no negative weight)</p>
</list-item><list-item>
<p>maximum bias: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e183" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>minimum bias: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e184" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e185" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s5i3">
<title>Softmax</title>
<list list-type="bullet"><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e186" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s5i4">
<title>Direct encoding (control experiment, labeled graph, CPPN)</title>
<list list-type="bullet"><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e187" xlink:type="simple"/></inline-formula> (per connection)</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e188" xlink:type="simple"/></inline-formula> (per neuron)</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e189" xlink:type="simple"/></inline-formula> (polynomial mutation)</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e190" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e191" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e192" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e193" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e194" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s5i5">
<title>Map-based encoding</title>
<p>Each connection is labeled by a tuple <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e195" xlink:type="simple"/></inline-formula>:</p>
<list list-type="bullet"><list-item>
<p>synaptic weight: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e196" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>inhibitory/excitatory: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e197" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>connection type: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e198" xlink:type="simple"/></inline-formula></p>
</list-item></list>
<p>Each neuron is labeled by a tuple <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e199" xlink:type="simple"/></inline-formula>:</p>
<list list-type="bullet"><list-item>
<p>map/single neuron: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e200" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>modulatory/standard: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e201" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>bias: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e202" xlink:type="simple"/></inline-formula></p>
</list-item></list>
</sec><sec id="s5i6">
<title>CPPN</title>
<list list-type="bullet"><list-item>
<p>available functions: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e203" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e204" xlink:type="simple"/></inline-formula> (sigmoid), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e205" xlink:type="simple"/></inline-formula> (Gaussian), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e206" xlink:type="simple"/></inline-formula> (linear)</p>
</list-item><list-item>
<p>maximum connection weight: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e207" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>minimum connection weight: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e208" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>other parameters: see direct encoding</p>
</list-item></list>
</sec><sec id="s5i7">
<title>HNN encoding</title>
<list list-type="bullet"><list-item>
<p>threshold for the creation of a connection (LEO link): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e209" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>synaptic weights are scaled to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0079138.e210" xlink:type="simple"/></inline-formula></p>
</list-item><list-item>
<p>modulatory vs standard: modularatory if output is below 0.4</p>
</list-item></list>
</sec></sec><sec id="s5j">
<title>Source code</title>
<p>The source code for all the experiments is available at: <ext-link ext-link-type="uri" xlink:href="http://pages.isir.upmc.fr/evorob_db" xlink:type="simple">http://pages.isir.upmc.fr/evorob_db</ext-link></p>
</sec></sec><sec id="s6">
<title>Supporting Information</title>
<supplementary-material id="pone.0079138.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pone.0079138.s001" position="float" xlink:type="simple"><label>File S1</label><caption>
<p><bold>List of the associations sets used in the experiments.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors thank J. Clune, S. Doncieux and B. Girard for helpful comments on this manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0079138-Pfeifer1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">Pfeifer R, Bongard J (2006) How the Body Shapes the Way we Think. MIT Press.</mixed-citation>
</ref>
<ref id="pone.0079138-Floreano1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Dürr</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Mattiussi</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>Neuroevolution: from architectures to learning</article-title>. <source>Evolutionary Intelligence</source> <volume>1</volume>: <fpage>47</fpage>–<lpage>62</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Floreano2"><label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">Floreano D, Mattiussi C (2008) Bio-Inspired Artificial Intelligence: Theories, Methods, and Technologies. Intelligent Robotics and Autonomous Agents. MIT Press.</mixed-citation>
</ref>
<ref id="pone.0079138-Mouret1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mouret</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Doncieux</surname><given-names>S</given-names></name> (<year>2012</year>) <article-title>Encouraging behavioral diversity in evolutionary robotics: An empirical study</article-title>. <source>Evolutionary computation</source> <volume>20</volume>: <fpage>91</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Braitenberg1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Braitenberg</surname><given-names>V</given-names></name> (<year>2001</year>) <article-title>Brain size and number of neurons: an exercise in synthetic neuroanatomy</article-title>. <source>Journal of computational neuroscience</source> <volume>10</volume>: <fpage>71</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Meunier1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meunier</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Lambiotte</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>ET</given-names></name> (<year>2010</year>) <article-title>Modular and Hierarchically Modular Organization of Brain Networks</article-title>. <source>Frontiers in neuroscience</source> <volume>4</volume>: <fpage>200</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Abbott1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name> (<year>2000</year>) <article-title>Synaptic plasticity: taming the beast</article-title>. <source>Nature neuroscience</source> <volume>3</volume>: <fpage>1178</fpage>–<lpage>1183</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Kandel1"><label>8</label>
<mixed-citation publication-type="book" xlink:type="simple">Kandel ER, Schwartz JH, Jessell TM, Siegelbaum SA, Hudspeth AJ, editors (2012) Principles of Neural Science. McGraw-Hill, 5th edition.</mixed-citation>
</ref>
<ref id="pone.0079138-Hornby1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hornby</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Pollack</surname><given-names>JB</given-names></name> (<year>2002</year>) <article-title>Creating high-level components with a generative representation for body-brain evolution</article-title>. <source>Artificial Life</source> <volume>8</volume>: <fpage>223</fpage>–<lpage>246</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Stanley1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname><given-names>R</given-names></name> (<year>2003</year>) <article-title>A taxonomy for artificial embryogeny</article-title>. <source>Artificial Life</source> <volume>9</volume>: <fpage>93</fpage>–<lpage>130</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Clune1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clune</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name>, <name name-style="western"><surname>Pennock</surname><given-names>RT</given-names></name>, <name name-style="western"><surname>Ofria</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>On the performance of indirect encoding across the continuum of regularity</article-title>. <source>IEEE Transactions on Evolutionary Computation</source> <volume>15</volume>: <fpage>346</fpage>–<lpage>367</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Stanley2"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name>, <name name-style="western"><surname>D'Ambrosio</surname><given-names>DB</given-names></name>, <name name-style="western"><surname>Gauci</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>A hypercube-based encoding for evolving large-scale neural networks</article-title>. <source>Artificial life</source> <volume>15</volume>: <fpage>185</fpage>–<lpage>212</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Bongard1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Bongard J (2002) Evolving modular genetic regulatory networks. In: Proceedings of IEEE-CEC. volume 2, pp. 1872–1877.</mixed-citation>
</ref>
<ref id="pone.0079138-Mattiussi1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mattiussi</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Analog Genetic Encoding for the Evolution of Circuits and Networks</article-title>. <source>Evolutionary Computation</source> <volume>11</volume>: <fpage>596</fpage>–<lpage>607</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Gruau1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gruau</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Whitley</surname><given-names>D</given-names></name> (<year>1993</year>) <article-title>Adding learning to the cellular development of neural networks: Evolution and the Baldwin effect</article-title>. <source>Evolutionary computation</source> <volume>1</volume>: <fpage>213</fpage>–<lpage>233</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Mouret2"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Mouret JB, Doncieux S, Girard B (2010) Importing the computational neuroscience toolbox into neuro-evolution-application to basal ganglia. In: Proceedings of GECCO. ACM, pp. 587–594.</mixed-citation>
</ref>
<ref id="pone.0079138-Hebb1"><label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">Hebb DO (1949) The organization of behavior. Wiley.</mixed-citation>
</ref>
<ref id="pone.0079138-Niv1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Joel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Meilijson</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Ruppin</surname><given-names>E</given-names></name> (<year>2002</year>) <article-title>Evolution of Reinforcement Learning in Uncertain Environments: A Simple Explanation for Complex Foraging Behaviors</article-title>. <source>Adaptive Behavior</source> <volume>10</volume>: <fpage>5</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Urzelai1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Urzelai</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Floreano</surname><given-names>D</given-names></name> (<year>2001</year>) <article-title>Evolution of adaptive synapses: Robots with fast adaptive behavior in new environments</article-title>. <source>Evolutionary Computation</source> <volume>9</volume>: <fpage>495</fpage>–<lpage>524</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Soltoggio1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Soltoggio A, Dürr P, Mattiussi C, Floreano D (2007) Evolving neuromodulatory topologies for reinforcement learning-like problems. In: Proceedings of IEEE-CEC. pp. 2471–2478.</mixed-citation>
</ref>
<ref id="pone.0079138-Soltoggio2"><label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">Soltoggio A, Bullinaria JJA, Mattiussi C, Floreano D, Dürr P (2008) Evolutionary advantages of neuromodulated plasticity in dynamic, reward-based scenarios. In: Proceedings of ALIFE. volume 11, pp. 569–576.</mixed-citation>
</ref>
<ref id="pone.0079138-Soltoggio3"><label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Soltoggio A, Jones B (2009) Novelty of behaviour as a basis for the neuro-evolution of operant reward learning. In: Proceedings of GECCO. ACM, pp. 169–176.</mixed-citation>
</ref>
<ref id="pone.0079138-Risi1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Risi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Hughes</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name> (<year>2010</year>) <article-title>Evolving plastic neural networks with novelty search</article-title>. <source>Adaptive Behavior</source> <volume>18</volume>: <fpage>470</fpage>–<lpage>491</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Risi2"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Risi S, Stanley KO (2010) Indirectly Encoding Neural Plasticity as a Pattern of Local Rules. In: Proceedings of SAB. pp. 533–543.</mixed-citation>
</ref>
<ref id="pone.0079138-Minsky1"><label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">Minsky ML, Papert SA (1987) Perceptrons - Expanded Edition: An Introduction to Computational Geometry. MIT press.</mixed-citation>
</ref>
<ref id="pone.0079138-Cybenko1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cybenko</surname><given-names>G</given-names></name> (<year>1989</year>) <article-title>Approximation by superpositions of a sigmoidal function</article-title>. <source>Mathematics of Control, Signals, and Systems (MCSS)</source> <volume>2</volume>: <fpage>303</fpage>–<lpage>314</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Chalmers1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Chalmers DJ (1990) The evolution of learning: An experiment in genetic connectionism. In: Proceedings of the 1990 connectionist models summer school. pp. 81–90.</mixed-citation>
</ref>
<ref id="pone.0079138-Risi3"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Risi S, Stanley KO (2011) Enhancing es-hyperneat to evolve more complex regular neural networks. In: Proceedings of GECCO. ACM, pp. 1539–1546.</mixed-citation>
</ref>
<ref id="pone.0079138-Hornby2"><label>29</label>
<mixed-citation publication-type="other" xlink:type="simple">Hornby GS (2005) Measuring, enabling and comparing modularity, regularity and hierarchy in evolutionary design. In: Proceedings of GECCO. ACM, pp. 1729–1736.</mixed-citation>
</ref>
<ref id="pone.0079138-Sutton1"><label>30</label>
<mixed-citation publication-type="book" xlink:type="simple">Sutton RS, Barto AG (1998) Reinforcement learning: An introduction. The MIT press, 360 pp. doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1364-6613(99)01331-5" xlink:type="simple">10.1016/S1364-6613(99)01331-5</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0079138-Houk1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Houk</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Adams</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Barto</surname><given-names>AG</given-names></name> (<year>1995</year>) <article-title>A model of how the basal ganglia generate and use neural signals that predict reinforcement</article-title>. <source>Models of information processing in the basal ganglia</source> <fpage>249</fpage>–<lpage>270</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Frank1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Claus</surname><given-names>ED</given-names></name> (<year>2006</year>) <article-title>Anatomy of a decision: striato-orbitofrontal interactions in reinforcement learning, decision making, and reversal</article-title>. <source>Psychological review</source> <volume>113</volume>: <fpage>300</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Girard1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Girard</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Tabareau</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Pham</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Berthoz</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Slotine</surname><given-names>JJ</given-names></name> (<year>2008</year>) <article-title>Where neuroscience and dynamic system theory meet autonomous robotics: a contracting basal ganglia model for action selection</article-title>. <source>Neural Networks</source> <volume>21</volume>: <fpage>628</fpage>–<lpage>641</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Gurney1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gurney</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Prescott</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Redgrave</surname><given-names>P</given-names></name> (<year>2001</year>) <article-title>A computational model of action selection in the basal ganglia. II. Analysis and simulation of behaviour</article-title>. <source>Biological cybernetics</source> <volume>84</volume>: <fpage>411</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Rougier1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rougier</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Vitay</surname><given-names>J</given-names></name> (<year>2006</year>) <article-title>Emergence of attention within a neural population</article-title>. <source>Neural Networks</source> <volume>19</volume>: <fpage>573</fpage>–<lpage>581</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Lipson1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lipson</surname><given-names>H</given-names></name> (<year>2007</year>) <article-title>Principles of modularity, regularity, and hierarchy for scalable systems</article-title>. <source>Journal of Biological Physics and Chemistry</source> <volume>7</volume>: <fpage>125</fpage>–<lpage>128</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Li1"><label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">Li M, Vitányi P (2008) An introduction to Kolmogorov complexity and its applications. Springer.</mixed-citation>
</ref>
<ref id="pone.0079138-Peshkin1"><label>38</label>
<mixed-citation publication-type="other" xlink:type="simple">Peshkin L (2007) Structure induction by lossless graph compression. In: Data Compression Conference. IEEE, pp. 53–62.</mixed-citation>
</ref>
<ref id="pone.0079138-Hayashida1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayashida</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Akutsu</surname><given-names>T</given-names></name> (<year>2010</year>) <article-title>Comparing biological networks via graph compression</article-title>. <source>BMC systems biology</source> <volume>4</volume>: <fpage>S13</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Mowshowitz1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mowshowitz</surname><given-names>A</given-names></name> (<year>1968</year>) <article-title>Entropy and the complexity of graphs: I. an index of the relative complexity of a graph</article-title>. <source>The bulletin of mathematical biophysics</source> <volume>30</volume>: <fpage>175</fpage>–<lpage>204</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Mowshowitz2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mowshowitz</surname><given-names>A</given-names></name> (<year>1968</year>) <article-title>Entropy and the complexity of graphs: Ii. the information content of digraphs and infinite graphs</article-title>. <source>The Bulletin of mathematical biophysics</source> <volume>30</volume>: <fpage>225</fpage>–<lpage>240</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Zenil1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zenil</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Soler-Toscano</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Dingle</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Louis</surname><given-names>AA</given-names></name> (<year>2013</year>) <article-title>Graph automorphism and topological characterization of synthetic and natural complex networks by information content</article-title>. <source>arXiv preprint arXiv</source> <fpage>13060322</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-McKay1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKay</surname><given-names>BD</given-names></name> (<year>1981</year>) <article-title>Practical graph isomorphism</article-title>. <source>Congressus Numerantium</source> <volume>30</volume>: <fpage>45</fpage>–<lpage>87</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Junttila1"><label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Junttila T, Kaski P (2007) Engineering an efficient canonical labeling tool for large and sparse graphs. In: Proceedings of the Ninth Workshop on Algorithm Engineering and Experiments and the Fourth Workshop on Analytic Algorithms and Combinatorics. SIAM, pp. 135–149.</mixed-citation>
</ref>
<ref id="pone.0079138-Katebi1"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Katebi H, Sakallah KA, Markov IL (2012) Graph symmetry detection and canonical labeling: Differences and synergies. In: Proceedings of Turing-100. EPiC Series, pp. 181–195.</mixed-citation>
</ref>
<ref id="pone.0079138-Deb1"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Deb K (2001) Multi-objective optimization. John Wiley &amp; Sons Hoboken, NJ, 13–46 pp.</mixed-citation>
</ref>
<ref id="pone.0079138-Deb2"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deb</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Pratap</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Agarwal</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Meyarivan</surname><given-names>T</given-names></name> (<year>2002</year>) <article-title>A fast and elitist multiobjective genetic algorithm: NSGA-II</article-title>. <source>Evolutionary Computation</source> <volume>6</volume>: <fpage>182</fpage>–<lpage>197</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Lehman1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lehman</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name> (<year>2011</year>) <article-title>Abandoning objectives: Evolution through the search for novelty alone</article-title>. <source>Evolutionary computation</source> <volume>19</volume>: <fpage>189</fpage>–<lpage>223</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Mouret3"><label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Mouret JB (2011) Novelty-based multiobjectivization. In: New Horizons in Evolutionary Robotics, Springer, volume 341 of <italic>Studies in computational intelligence</italic>. pp. 139–154.</mixed-citation>
</ref>
<ref id="pone.0079138-Clune2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clune</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mouret</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Lipson</surname><given-names>H</given-names></name> (<year>2013</year>) <article-title>The evolutionary origins of modularity</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source> <volume>280</volume>: <fpage>20122863</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Gould1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gould</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Lewontin</surname><given-names>R</given-names></name> (<year>1979</year>) <article-title>The spandrels of San Marco and the panglossian paradigm: a critique of the adaptationist programme</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source> <volume>205</volume>: <fpage>581</fpage>–<lpage>598</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Chklovskii1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schikorski</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Stevens</surname><given-names>C</given-names></name> (<year>2002</year>) <article-title>Wiring optimization in cortical circuits</article-title>. <source>Neuron</source> <volume>34</volume>: <fpage>341</fpage>–<lpage>347</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Cherniak1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cherniak</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Mokhtarzada</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Rodriguez-Esteban</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Changizi</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>Global optimization of cerebral cortex layout</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>101</volume>: <fpage>1081</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Chen1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Wiring optimization can relate neuronal structure and function</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>103</volume>: <fpage>4723</fpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Potts1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Potts</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>Variability Selection in Hominid Evolution</article-title>. <source>Evolutionary Anthropology</source> <volume>7</volume>: <fpage>81</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Richerson1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Richerson</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Bettinger</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Boyd</surname><given-names>R</given-names></name> (<year>2005</year>) <article-title>Evolution on a restless planet: Were environmental variability and environmental change major drivers of human evolution?</article-title> <source>Handbook of evolution</source> <volume>2</volume>: <fpage>223</fpage>–<lpage>242</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Grossberg1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name> (<year>2000</year>) <article-title>The complementary brain: unifying brain dynamics and modularity</article-title>. <source>Trends in cognitive sciences</source> <volume>4</volume>: <fpage>233</fpage>–<lpage>246</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Bullmore1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2009</year>) <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nature reviews Neuroscience</source> <volume>10</volume>: <fpage>186</fpage>–<lpage>98</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Striedter1"><label>59</label>
<mixed-citation publication-type="other" xlink:type="simple">Striedter G (2005) Principles of brain evolution. Sinauer Associates Sunderland, MA.</mixed-citation>
</ref>
<ref id="pone.0079138-Hopfield1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name> (<year>1982</year>) <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the national academy of sciences</source> <volume>79</volume>: <fpage>2554</fpage>–<lpage>2558</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Haykin1"><label>61</label>
<mixed-citation publication-type="book" xlink:type="simple">Haykin S (1998) Neural Networks: A Comprehensive Foundation. Prentice Hall.</mixed-citation>
</ref>
<ref id="pone.0079138-LeCun1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LeCun</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Bottou</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Haffner</surname><given-names>P</given-names></name> (<year>1998</year>) <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proceedings of the IEEE</source> <volume>86</volume>: <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Verbancsics1"><label>63</label>
<mixed-citation publication-type="other" xlink:type="simple">Verbancsics P, Stanley KO (2011) Constraining Connectivity to Encourage Modularity in Hyper- NEAT. In: Proceedings of GECCO. ACM, pp. 1483–1490.</mixed-citation>
</ref>
<ref id="pone.0079138-Stanley3"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname><given-names>KO</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname><given-names>R</given-names></name> (<year>2002</year>) <article-title>Evolving neural networks through augmenting topologies</article-title>. <source>Evolutionary Computation</source> <volume>10</volume>: <fpage>99</fpage>–<lpage>127</lpage>.</mixed-citation>
</ref>
<ref id="pone.0079138-Mouret4"><label>65</label>
<mixed-citation publication-type="other" xlink:type="simple">Mouret JB, Doncieux S (2009) Overcoming the bootstrap problem in evolutionary robotics using behavioral diversity. In: Proceedings of CEC. IEEE, pp. 1161–1168.</mixed-citation>
</ref>
<ref id="pone.0079138-Pinville1"><label>66</label>
<mixed-citation publication-type="other" xlink:type="simple">Pinville T, Koos S, Mouret JB, Doncieux S (2011) How to promote generalisation in evolutionary robotics: the progab approach. In: Proceedings of GECCO. ACM, pp. 259–266.</mixed-citation>
</ref>
<ref id="pone.0079138-Ollion1"><label>67</label>
<mixed-citation publication-type="other" xlink:type="simple">Ollion C, Pinville T, Doncieux S (2012) With a little help from selection pressures: evolution of memory in robot controllers. In: Proceedings of ALIFE. volume 13, pp. 407–414.</mixed-citation>
</ref>
<ref id="pone.0079138-Ijspeert1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ijspeert</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Crespi</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Ryczko</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Cabelguen</surname><given-names>JM</given-names></name> (<year>2007</year>) <article-title>From swimming to walking with a salamander robot driven by a spinal cord model</article-title>. <source>Science</source> <volume>315</volume>: <fpage>1416</fpage>–<lpage>1420</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>