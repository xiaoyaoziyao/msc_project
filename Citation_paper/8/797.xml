<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-12-00058</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0032466</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Probability theory</subject>
          </subj-group>
          <subj-group>
            <subject>Statistics</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Medicine</subject>
          <subj-group>
            <subject>Diagnostic medicine</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
          <subject>Mathematics</subject>
        </subj-group>
      </article-categories><title-group><article-title>When Two Become One: The Limits of Causality Analysis of Brain Dynamics</article-title><alt-title alt-title-type="running-head">Limits of Causality Analysis</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Chicharro</surname>
            <given-names>Daniel</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Ledberg</surname>
            <given-names>Anders</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">          <addr-line>Center of Brain and Cognition, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Wennekers</surname>
            <given-names>Thomas</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">The University of Plymouth, United Kingdom</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">chicharro31@yahoo.es</email> (DC); <email xlink:type="simple">anders.ledberg@gmail.com</email> (AL)</corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: DC AL. Performed the experiments: DC AL. Analyzed the data: DC AL. Contributed reagents/materials/analysis tools: DC AL. Wrote the paper: DC AL.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>16</day>
        <month>3</month>
        <year>2012</year>
      </pub-date><volume>7</volume><issue>3</issue><elocation-id>e32466</elocation-id><history>
        <date date-type="received">
          <day>23</day>
          <month>12</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>31</day>
          <month>1</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Chicharro, Ledberg</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Biological systems often consist of multiple interacting subsystems, the brain being a prominent example. To understand the functions of such systems it is important to analyze if and how the subsystems interact and to describe the effect of these interactions. In this work we investigate the extent to which the cause-and-effect framework is applicable to such interacting subsystems. We base our work on a standard notion of causal effects and define a new concept called natural causal effect. This new concept takes into account that when studying interactions in biological systems, one is often not interested in the effect of perturbations that alter the dynamics. The interest is instead in how the causal connections participate in the generation of the observed natural dynamics. We identify the constraints on the structure of the causal connections that determine the existence of natural causal effects. In particular, we show that the influence of the causal connections on the natural dynamics of the system often cannot be analyzed in terms of the causal effect of one subsystem on another. Only when the causing subsystem is autonomous with respect to the rest can this interpretation be made. We note that subsystems in the brain are often bidirectionally connected, which means that interactions rarely should be quantified in terms of cause-and-effect. We furthermore introduce a framework for how natural causal effects can be characterized when they exist. Our work also has important consequences for the interpretation of other approaches commonly applied to study causality in the brain. Specifically, we discuss how the notion of natural causal effects can be combined with Granger causality and Dynamic Causal Modeling (DCM). Our results are generic and the concept of natural causal effects is relevant in all areas where the effects of interactions between subsystems are of interest.</p>
      </abstract><funding-group><funding-statement>The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007- 2013) under grant agreement no. 269921 (BrainScaleS). AL is supported by the Ramon y Cajal program from the Spanish government. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="16"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Biological systems often consist of multiple interacting subsystems. An important step in the analysis of such systems is to uncover how the subsystems are functionally related and to study the effects of functional interactions in the system. A prominent example of a biological system with interacting subsystems is the brain, having interconnected ‘units’ at many different levels of description: e.g. neurons, microcircuits, and brain regions. It is the current belief that much of what we associate with brain function comes about through interactions between these different subsystems, and to characterize these interactions and their effects is one of the greatest challenges of the Neurosciences. Note that this is not only an experimental challenge but also a conceptual one. Indeed, even if given access to all the relevant variables in the nervous system, it is far from obvious how to analyze how brain activity relates to function.</p>
      <p>In neurophysiology, the traditional approach to link brain activity to function is to perturb the nervous system and observe which variables change as a function of the perturbation. For example, many cells in primary sensory cortices elicit spikes at a rate that depends on a particular property of the stimulus (e.g. <xref ref-type="bibr" rid="pone.0032466-Mountcastle1">[1]</xref>, <xref ref-type="bibr" rid="pone.0032466-Hubel1">[2]</xref>), and cells in the primary motor cortex tend to elicit spikes in relation to sensory conditioned movements (e.g. <xref ref-type="bibr" rid="pone.0032466-Evarts1">[3]</xref>). This approach is based on a conceptual cause-and-effect model: The perturbation (e.g. sensory stimulus) is the cause and the response of the nervous system (e.g. an increase in firing rate) the effect. There are two aspects of this experimental situation that allow a cause-and-effect interpretation: the perturbation is exogenous, or external, to the system; and, the effect follows the cause only after some temporal delay. That the perturbation is exogenous makes it possible to disentangle spurious dependencies from those due to a mechanistic (causal) coupling. The temporal delay between cause and effect is in line with the intuitive notion that a cause must precede its effect in time, and with our current understanding of the underlying mechanisms (e.g. how light is transformed into membrane currents and propagated through the visual system of the brain). This cause-and-effect model has been successfully applied to studies of response properties of single cells and brain regions, as well as to the relation between isolated limb movements and corresponding neuronal activity.</p>
      <p>Perhaps inspired by the success of the cause-and-effect models in sensory and motor neurophysiology, workers have more recently started to look at interactions between different brain regions using the same framework. That is, researchers try to characterize the activity of one subsystem in terms of how it is caused by the activities of other subsystems. Indeed, a lot of theoretical and experimental work has been directed at investigating what has been called ‘direction of information flow’ (e.g. <xref ref-type="bibr" rid="pone.0032466-Kaminski1">[4]</xref>), ‘causal relations’ (e.g. <xref ref-type="bibr" rid="pone.0032466-Kaminski2">[5]</xref>), ‘causal influences’ (e.g. <xref ref-type="bibr" rid="pone.0032466-Brovelli1">[6]</xref>), or ‘effective connectivity’ (e.g. <xref ref-type="bibr" rid="pone.0032466-Aertsen1">[7]</xref>, <xref ref-type="bibr" rid="pone.0032466-Friston1">[8]</xref>), to just mention a few. A major difference with respect to the type of studies mentioned above is that the ‘cause’ is typically not a perturbation introduced by the experimenter. Rather, the joint natural activity of the subsystems is decomposed in causes and effects by statistical techniques. One crucial implication of this difference is that direction of the ‘causal flow’ is not restricted <italic>a priori</italic>: Contrary to the case of an externally applied stimulus, where the causality (if any) must ‘flow’ from the stimulus to the brain, in the case of two interacting brain systems it is quite possible that there is ‘causal flow’ in both directions. We will see that this bidirectionality has serious consequences for a cause-and-effect interpretation of interactions in the natural brain dynamics.</p>
      <p>In this work we take a critical look at the cause-and-effect framework and demonstrate some fundamental shortcomings when this framework is used to study the natural dynamics of a system. We base our work on a standard model of causality that has emerged in the fields of statistics and artificial intelligence during the last decades (e.g. <xref ref-type="bibr" rid="pone.0032466-Rubin1">[9]</xref>, <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>), synthesized in the framework of interventional causality proposed by Pearl <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>. In this framework external interventions (i.e. perturbations) of the system play a major role, both in defining the existence of causal connections between variables as well as in quantifying their effects. In our work we focus on situations where the interest is in characterizing the effects of natural interactions going on in a system. In such situations external interventions can not be used to quantify causal effects as they would typically disrupt the natural dynamics (c.f. <xref ref-type="bibr" rid="pone.0032466-Logothetis1">[11]</xref>). We will analyze the conditions under which the natural interactions between subsystems can be interpreted according to a cause-and-effect framework. That is, our work is not about determining if a causal connection exists or not, but rather how to interpret the effects of existing causal connections. We derive conditions for when the interactions between two subsystems can be interpreted in terms of one system causing the other. The main requirement is that the causing subsystem acts as an exogenous source of activity. In particular, we show that the effects of interactions between mutually connected subsystems typically cannot be interpreted in terms of the effects that the individual subsystems exerts on the remaining ones. A conclusion of our work is therefore that the cause-and-effect framework is of limited use when characterizing the internal dynamics of the brain. The analysis is general and our conclusions therefore have important consequences for the interpretation of previous studies using different measures of ‘causality’, including Granger causality and Dynamic Causal Modeling.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>In this section we first argue that it is important to distinguish between three different types of questions asked about causality and we introduce some basic notions about causal graphs. We then, in a number of subsections, develop what is needed to reach the main goal of the paper: to state conditions for when the effects of natural interactions between variables can be given a cause-and-effect interpretation. To reach this goal, we first give a brief overview of the interventional framework of causality. We then introduce an important distinction between situations where the main interest is the effect of external interventions and situations where the main interest is the impact of the causal connections on the dynamics happening naturally in the system. Next the conditions for when the natural interactions can be given a cause-and-effect interpretation are stated. Subsequently, we derive the consequences of these conditions for the special case of bivariate time series. We further suggest some novel approaches to the analysis of causal effects. Then we show how our work complements and extends two common approaches of ‘causality’ analysis: Granger Causality and Dynamic Causal Modeling (DCM). Finally we apply the analysis of causal effects to a simple model system to illustrate some of the theoretical points made.</p>
      <p>In this work we are concerned with sets of variables and their interactions. We assume that the state of the variables is uncertain and that we have access to the (possibly time-dependent) joint probability over the variables. This is to avoid issues related to estimation from data. Our results are generic but it might be instructive to think of the variables as corresponding to the states of a set of neurons or other ‘units’ of the brain. We will further assume that the variables interact directly with each other, that is, that the variables are, or might be, causally connected. Note that experimental data sometimes reflect non-causal variables such as the blood oxygenation level depend (BOLD) signal and local field potentials (LFPs), in which case some additional level of modeling might be needed in order to make inferences about causality (c.f. <xref ref-type="bibr" rid="pone.0032466-Daunizeau1">[12]</xref>).</p>
      <sec id="s2a">
        <title>Three questions about causality</title>
        <p>To put our work in proper context and to facilitate a comparison with existing approaches to causality it is helpful to separate questions about causality into the following three types:</p>
        <list list-type="simple">
          <list-item>
            <p>Q1: Is there a direct causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e001" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e002" xlink:type="simple"/></inline-formula>? (existence)</p>
          </list-item>
          <list-item>
            <p>Q2: How is the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e003" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e004" xlink:type="simple"/></inline-formula> implemented?  (mechanism)</p>
          </list-item>
          <list-item>
            <p>Q3: What is the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e005" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e006" xlink:type="simple"/></inline-formula>? (quantification)</p>
          </list-item>
        </list>
        <p>(here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e007" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e008" xlink:type="simple"/></inline-formula> are two generic, and possibly high-dimensional, variables). We will show that it is important to keep these questions separate, and that different approaches are typically required to answer them. This might seem obvious, but in fact these three questions are often mixed into a ‘causality analysis’, and tools appropriate for the first two questions are often erroneously used to address also the third.</p>
        <p>The first question (Q1) addresses the existence of a direct causal connection between two variables. A causal connection is a directed binary relation that carries only qualitative information. If the distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e009" xlink:type="simple"/></inline-formula> is invariant to perturbations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e010" xlink:type="simple"/></inline-formula> there is no causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e011" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e012" xlink:type="simple"/></inline-formula>. The total set of causal connections in a system is referred to as the <italic>causal structure</italic>. For a system containing a set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e013" xlink:type="simple"/></inline-formula> of variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e014" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e015" xlink:type="simple"/></inline-formula>, the causal structure can very conveniently be represented as a <italic>causal graph</italic> in which the nodes correspond to the variables and directed edges point from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e016" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e017" xlink:type="simple"/></inline-formula> if there is a direct causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e018" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e019" xlink:type="simple"/></inline-formula>. For example, <xref ref-type="fig" rid="pone-0032466-g001">Figure 1A</xref>, shows a causal graph where there are direct causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e020" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e021" xlink:type="simple"/></inline-formula>, from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e022" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e023" xlink:type="simple"/></inline-formula>, and from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e024" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e025" xlink:type="simple"/></inline-formula>. If the causal graph is without cycles (i.e. forming a directed acyclic graph, DAG) then the joint probability over the variables can be factorized according to the causal structure e.g. <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>. This is an important and useful result that we will use below and that is used extensively in the interventional framework of causality (see below). In fact this factorization following the causal structure is fundamental to relate the interventions to the joint probability (see <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref>). The causal graph contains all information needed to answer Q1. Unfortunately inferring the causal graph from observed data (here, the joint distribution) is in general not possible. A given joint distribution might be compatible with different causal structures <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>, in which cases these graphs are said to be <italic>observationally equivalent</italic> <xref ref-type="bibr" rid="pone.0032466-Verma1">[13]</xref>. Furthermore, the difficulty to infer the causal graph increases if there are hidden variables, i.e. variables that are not observed. The traditional approach to Q1 is therefore to experimentally modify (perturb) one variable and study the impact on the remaining ones. For example, the graphs in <xref ref-type="fig" rid="pone-0032466-g001">Figure 1A and 1B</xref> are both consistent with a statistical dependence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e027" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e028" xlink:type="simple"/></inline-formula> is not observed, it is not possible to distinguish between ‘<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e029" xlink:type="simple"/></inline-formula> is causing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e030" xlink:type="simple"/></inline-formula>’ and ‘<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e031" xlink:type="simple"/></inline-formula> is not causing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e032" xlink:type="simple"/></inline-formula>’ without intervening (i.e. perturbing) the system (see below). On the other hand, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e033" xlink:type="simple"/></inline-formula> is observed we see that for the graph in <xref ref-type="fig" rid="pone-0032466-g001">Figure 1B</xref>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e034" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e035" xlink:type="simple"/></inline-formula> are conditionally independent given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e036" xlink:type="simple"/></inline-formula>, while for that in <xref ref-type="fig" rid="pone-0032466-g001">Figure 1A</xref> conditioning on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e037" xlink:type="simple"/></inline-formula> does not render <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e038" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e039" xlink:type="simple"/></inline-formula> independent. In these types of causal structures <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e040" xlink:type="simple"/></inline-formula> is considered a <italic>confounder</italic> because, being a common driver, it produces a statistical dependence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e041" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e042" xlink:type="simple"/></inline-formula> even without the existence of any direct causal connection between them.</p>
        <fig id="pone-0032466-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0032466.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Causal graphs illustrating the effect of interventions.</title>
            <p><bold>A</bold>: Graph showing a case where the statistical dependence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e043" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e044" xlink:type="simple"/></inline-formula> is (partly) due to a causal interaction from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e045" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e046" xlink:type="simple"/></inline-formula>. <bold>B</bold>: Graph showing a case where the statistical dependence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e047" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e048" xlink:type="simple"/></inline-formula> is induced solely by the confounding variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e049" xlink:type="simple"/></inline-formula>. <bold>C</bold>: Graph corresponding to the intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e050" xlink:type="simple"/></inline-formula> in the causal graph shown in <bold>A</bold>. <bold>D</bold>: Graph corresponding to the intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e051" xlink:type="simple"/></inline-formula> in the causal graph shown in <bold>B</bold>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.g001" xlink:type="simple"/>
        </fig>
        <p>Consider now the second question (Q2) about the mechanisms implementing the causal connections. In the ideal case the answer to this question would be given in terms of a biophysically realistic model of the system under study. However, often one has to make do with a phenomenological model that captures enough features of both structure and dynamics to give an adequate description of the system. That is, a model that is at some level functionally equivalent to the real physical system. Such a <italic>functional model</italic> would contain a formal description of how the variables in the system are generated, and how each variable depends on the other ones. For the causal graph of <xref ref-type="fig" rid="pone-0032466-g001">Figure 1A</xref>, the following formal equations define a functional model:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e052" xlink:type="simple"/></disp-formula></p>
        <p>where the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e053" xlink:type="simple"/></inline-formula>-terms stand for random (non-observable) disturbances. We note that deriving a functional model from a detailed biophysical model, without modifying the impact of the causal interactions, might not be trivial. Nor is it trivial to go from experimental observations to a functional model that allows causal inference about the real physical system.</p>
        <p>Since the model built to answer Q2 must already contain all the needed information to draw the corresponding causal graph, answering Q2 implies also answering Q1. In particular, any variable inside the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e054" xlink:type="simple"/></inline-formula> is considered a <italic>parent</italic> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e055" xlink:type="simple"/></inline-formula> (the set of all parents is denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e056" xlink:type="simple"/></inline-formula>) and an arrow from it to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e057" xlink:type="simple"/></inline-formula> is included in the graph. Since the functional model is supposed to reflect the underlying mechanisms generating the variables, the parents <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e058" xlink:type="simple"/></inline-formula> are the minimal set of variables with a direct causal connection to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e059" xlink:type="simple"/></inline-formula>. In such modeling approaches to causality it is important to emphasize that all notions of causality refer to the model and not to the system that is being modeled. In other words, only if the model is a faithful description of the process generating the variables can it be used as a model of real causal interactions.</p>
        <p>In biology in general and in neuroscience in particular, the variables of interest are often functions of time. In such cases the functional model must be formulated in terms of dynamic equations (typically as difference or differential equations) and the variables represented in the causal graph will correspond to particular discrete times. In fact, for differential equations (i.e. representing a time-continuous dynamics), the causal graph corresponds only to a discrete representation of the equations (see <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref> for a discussion of the correspondence between discrete and continuous models).</p>
        <p>Since the answer to Q2 contains a model consistent with the mechanisms implementing the causal connections one may think that this would also be enough to answer Q3, i.e. the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e060" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e061" xlink:type="simple"/></inline-formula>. However, answering Q3 is not so straightforward. It is clear that the causal graph (Q1) does not contain information about the impact of the causal connections but only about their existence. Similarly, from a set of dynamic equations the resulting dynamics are only implicitly represented. This means that the effects of the causal connections modeled by the equations can typically not be read off directly from the equations. Rather, the quantification of the causal effect has to be done by analyzing the dynamics, either using observed data or, given the ‘correct’ model that generated the data, using simulated data from the model or analytical techniques. However, even if the required data are available, one further needs to clearly define what is meant by the <italic>causal effect</italic> that results from the causal connections. Therefore, question Q3 has to be addressed separately and is typically not reducible to answering Q2 or Q1.</p>
        <p>In the rest of this work we will focus on this last question related to the analysis and quantification of causal effects (Q3). Following the distinction between the three questions about causality discussed above we will be very precise with our terminology: First, when talking about <italic>causal connections</italic> we will refer only to the causal structure in the graph. That is, a causal connection from variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e062" xlink:type="simple"/></inline-formula> to variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e063" xlink:type="simple"/></inline-formula> exists if and only if it is possible to go from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e064" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e065" xlink:type="simple"/></inline-formula> following a path composed by arrows whose direction is respected. In particular, a <italic>direct causal connection</italic> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e066" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e067" xlink:type="simple"/></inline-formula> is equivalent to the existence of an arrow from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e068" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e069" xlink:type="simple"/></inline-formula>. For two sets of variables the causal connection between the sets exists if it exists between at least a pair of variables. Second, when talking about the <italic>causal effect</italic> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e070" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e071" xlink:type="simple"/></inline-formula> we will refer to the impact or influence of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e072" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e073" xlink:type="simple"/></inline-formula>. This impact depends on the causal structure, on the actual mechanisms that implement it, and is, as we will see, only appreciable in the dynamics.</p>
      </sec>
      <sec id="s2b">
        <title>Causal effects in the framework of Pearl's interventions</title>
        <p>In this section we will define causal effects using the framework of interventional causality developed by Judea Pearl and coworkers (e.g. <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>). We note that this framework is closely related to the potential outcomes approach to causality developed by Donald Rubin and coworkers (e.g. <xref ref-type="bibr" rid="pone.0032466-Rubin1">[9]</xref>) and that the causal effect used in that approach is fully compatible with the corresponding entity in the interventional framework. The definition of causal effects stated below can therefore be considered a ‘standard’ definition.</p>
        <p>The starting point of the interventional framework is the realization that a causal connection between two variables can typically only be identified by intervening. That is, by <italic>actively perturbing one variable and studying the effect on the other</italic>. This is of course what experimentalists typically would do to study cause-and-effect relations. As a motivating example, consider paired recordings of membrane potentials of two, possibly interconnected, excitatory neurons (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e074" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e075" xlink:type="simple"/></inline-formula> say). If we observe that membrane potential of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e076" xlink:type="simple"/></inline-formula> tends to depolarize briefly after neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e077" xlink:type="simple"/></inline-formula> elicited an action potential, we might be tempted to conclude that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e078" xlink:type="simple"/></inline-formula> has causal influence over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e079" xlink:type="simple"/></inline-formula>. However, the same phenomenon could easily be accounted for by that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e080" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e081" xlink:type="simple"/></inline-formula> are receiving common (or at least highly correlated) inputs. The obvious thing to do in order to distinguish these two scenarios is to intervene, i.e. to force <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e082" xlink:type="simple"/></inline-formula> to emit an action potential (e.g. by injecting current into the cell). If depolarizations of the membrane potential of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e083" xlink:type="simple"/></inline-formula> are consistently found after such interventions, we are clearly much more entitled to conclude that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e084" xlink:type="simple"/></inline-formula> has a causal influence over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e085" xlink:type="simple"/></inline-formula>. Note that the crucial aspect of the intervention is that it ‘forces’ one variable to take a particular value (e.g. fire an action potential) independently of the values of other variables in the system. It therefore ‘breaks’ interdependencies that are otherwise part of the system and hence can be used to distinguish between causal and spurious associations. The recent study by Ko et al. <xref ref-type="bibr" rid="pone.0032466-Ko1">[15]</xref> is an excellent example of how interventions can be used to determine the causal structure between single neurons, and how this structure can account for observed statistical dependencies.</p>
        <p>One of the contributions of the interventional framework of causality is that it formalizes the notion of an intervention and develops rules for how interventions can be incorporated into probability theory <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>. Symbolically an intervention is represented by the ‘<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e086" xlink:type="simple"/></inline-formula>’ operator. For example, setting one variable, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e087" xlink:type="simple"/></inline-formula>, in the system to a particular value, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e088" xlink:type="simple"/></inline-formula>, is denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e089" xlink:type="simple"/></inline-formula>. These interventions to a fixed value are commonly used in framework of Pearl's causality. Experimental interventions rarely can be exactly controlled, but the important point is not that a variable can be fixed to a given value but that the mechanisms generating this variable are perturbed. We will see below that the variability in the intervention can be captured introducing a probability distribution of interventions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e090" xlink:type="simple"/></inline-formula>. The effect of an intervention on the joint distribution is most easily seen when the joint distribution is factorized according to a causal graph. In this case the intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e091" xlink:type="simple"/></inline-formula> corresponds to deleting the term corresponding to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e092" xlink:type="simple"/></inline-formula> in the factorization and setting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e093" xlink:type="simple"/></inline-formula> in all other terms depending on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e094" xlink:type="simple"/></inline-formula>. This truncated factorization of the joint distribution is referred to as the <italic>postinterventional distribution</italic>, that is, the distribution resulting from an intervention. In <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> we give a formal definition of the effect of an intervention and some examples. Graphically, the effect of an intervention is particularly illuminating: intervening in one variable corresponds to the removal of all the arrows pointing to that variable in the causal graph. This represents the crucial aspect of interventions mentioned above: intervention ‘disconnects’ the intervened variable from the rest of the system. <xref ref-type="fig" rid="pone-0032466-g001">Figure 1A and B</xref> illustrate two different scenarios for how a statistical dependence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e095" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e096" xlink:type="simple"/></inline-formula> could come about. If only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e097" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e098" xlink:type="simple"/></inline-formula> are observed, these scenarios are indistinguishable without intervening. The causal graphs corresponding to the intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e099" xlink:type="simple"/></inline-formula> are shown in <xref ref-type="fig" rid="pone-0032466-g001">Figure 1C and D</xref>. It is clear that only the graph shown in <xref ref-type="fig" rid="pone-0032466-g001">Figure 1C</xref> implies a statistical relation between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e100" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e101" xlink:type="simple"/></inline-formula> illustrating how the intervention helps to distinguish between causal and spurious (non-causal) associations. Indeed, interventions can generally be used to infer the existence of causal connections. Conditions and measures to infer causal connectivity from interventions have been studied for example in <xref ref-type="bibr" rid="pone.0032466-Galles1">[16]</xref>, <xref ref-type="bibr" rid="pone.0032466-Ay1">[17]</xref>.</p>
        <p>Given this calculus of interventions, <italic>the causal effect of the intervention of a variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e102" xlink:type="simple"/></inline-formula> on a variable</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e103" xlink:type="simple"/></inline-formula> is defined as the postinterventional probability distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e104" xlink:type="simple"/></inline-formula> (see Definition 3.2.1 in <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref> and <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref>). This definition understands the causal effect as a function from the space of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e105" xlink:type="simple"/></inline-formula> to the space of probability distributions of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e106" xlink:type="simple"/></inline-formula>. In particular, for each intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e107" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e108" xlink:type="simple"/></inline-formula> denotes the probability distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e109" xlink:type="simple"/></inline-formula> given this intervention. In <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> we show how <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e110" xlink:type="simple"/></inline-formula> can be computed from a given factorization of the joint distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e111" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e112" xlink:type="simple"/></inline-formula>. Note that this definition of causal effect is valid also if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e113" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e114" xlink:type="simple"/></inline-formula> are multivariate.</p>
        <p>This definition of causal effects is very general and in practice it is often desirable to condense this family of probability distributions (i.e. one distribution per intervention) to something lower-dimensional. Often the field of study will suggest a suitable measure of the causal effect. Consider the example of the two neurons introduced above, and let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e115" xlink:type="simple"/></inline-formula> denote the intervention corresponding to making neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e116" xlink:type="simple"/></inline-formula> emit an action potential. To not introduce new notation we let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e117" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e118" xlink:type="simple"/></inline-formula> stand for both the identity of the neurons as well as their membrane potentials. Then a reasonable measure of the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e119" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e120" xlink:type="simple"/></inline-formula> could be<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e121" xlink:type="simple"/><label>(1)</label></disp-formula></p>
        <p>That is, the difference between the expected values of the postinterventional distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e122" xlink:type="simple"/></inline-formula> and the marginal distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e123" xlink:type="simple"/></inline-formula> (c.f. <xref ref-type="bibr" rid="pone.0032466-Rosenbaum1">[18]</xref>). In other words, the causal effect would be quantified as the mean depolarization induced in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e124" xlink:type="simple"/></inline-formula> by an action potential in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e125" xlink:type="simple"/></inline-formula>. Clearly this measure does not capture all possible causal effects, for example, the variability of the membrane potential could certainly be affected by the intervention.</p>
        <p>Intervening one variable is similar to conditioning on this variable, this is illustrated both in the notation and also in the effect of an intervention on the joint distribution. However, there is a very important difference in that an intervention actually changes the causal structure whereas conditioning does not. As mentioned above, it is this aspect of the intervention that makes it a key tool in causal analysis. Formally, this difference is expressed in that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e126" xlink:type="simple"/></inline-formula> in general differs from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e127" xlink:type="simple"/></inline-formula>. Consider for example the case when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e128" xlink:type="simple"/></inline-formula> is causing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e129" xlink:type="simple"/></inline-formula> but not the other way around, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e130" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e131" xlink:type="simple"/></inline-formula> whereas, in general, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e132" xlink:type="simple"/></inline-formula>.</p>
        <p>A very important and useful aspect of this definition of casual effect is that if all the variables in the system are observed the causal effect can be computed from the joint distribution over the variables in the observed non-intervened system. That is, even if the causal effect is formulated in terms of interventions, we might not need to actually intervene in order to compute it. See <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> for details of this procedure and S2 for the calculation of causal effects in the graphs of <xref ref-type="fig" rid="pone-0032466-g001">Figure 1</xref>. On the other hand, if there are hidden (non-observed) variables, physical intervention is typically required to estimate the causal effect.</p>
      </sec>
      <sec id="s2c">
        <title>Requirements for a definition of causal effect between neural systems</title>
        <p>The definition of causal effects stated above is most useful when studying the effect of one or a few singular events in a system, that is, events isolated in time that can be thought of in terms of interventions. However, in neuroscience the interest is often in functional relations between different subsystems over an extended period of time (say, during one trial of some task). Furthermore, the main interest is not in the effect of perturbations, but in the interactions that are part of the brains natural dynamics. Consider for example the operant conditioning experiment, a very common paradigm in systems neuroscience. Here a subject is conditioned to express a particular behavior contingent upon the sensory stimuli received. Assume we record the simultaneous activity of many different functional ‘units’. Then a satisfactory notion of causal effect of one unit on another should quantify how much of the task-related activity in one unit can be accounted for by the impact of the causal connections from the other, and not the extent to which it would be changed by an externally imposed intervention. Of course, there are other cases where the effect of an intervention <italic>is</italic> the main interest, such as for example in studies of deep brain stimulation (e.g. <xref ref-type="bibr" rid="pone.0032466-Benabid1">[19]</xref>). In these cases the interventional framework is readily applicable and we will consequently not consider these cases further. We will instead focus on the analysis of natural brain dynamics which is also where DCM and Granger causality typically have been applied.</p>
        <p>These considerations indicate some requirements for a definition of causal effects in the context of natural brain dynamics. First, causal effects should be assessed in relation to the dynamics of the neuronal activity. From a modeling point-of-view this implies that the casal effect can typically not be identified with parameters in the model. Second, the causal effects should characterize the <italic>natural</italic> dynamics, and not the dynamics that would result from an external intervention. This is because we want to learn the impact of the causal connections over the unaltered brain activity.</p>
        <p>We will refer to causal effects that fulfill these requirements as <italic>natural causal effects between dynamics</italic>. We will now see that it is possible to derive a definition of natural causal effects between dynamics from the interventional definition of causal effects. We start by examining when natural causal effects between variables exist and in the following section we consider natural causal effects between dynamics.</p>
      </sec>
      <sec id="s2d">
        <title>Natural causal effects</title>
        <p>As explained above, a standard way to define causal effects is in terms of interventions. Yet, many of the most pertinent questions in neuroscience cannot be formulated in terms of interventions in a straightforward way. Indeed, workers are often interested in the ‘the influence one neural system exerts over another’ in the unperturbed (natural) state <xref ref-type="bibr" rid="pone.0032466-Friston1">[8]</xref>. In this section we will state the conditions for when the impact of causal connections from one subsystem to another (as quantified by the conditional probability distribution) can be given such a cause-and-effect interpretation.</p>
        <p>We first consider the causal effect of one isolated intervention. For a given value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e133" xlink:type="simple"/></inline-formula> of the random variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e134" xlink:type="simple"/></inline-formula>, we define the <italic>natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e135" xlink:type="simple"/></inline-formula> on the random variable</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e136" xlink:type="simple"/></inline-formula> to be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e137" xlink:type="simple"/></inline-formula> if and only if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e138" xlink:type="simple"/><label>(2)</label></disp-formula></p>
        <p>In words, if and only if conditioning on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e139" xlink:type="simple"/></inline-formula> is identical to intervening to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e140" xlink:type="simple"/></inline-formula>, the influence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e141" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e142" xlink:type="simple"/></inline-formula> is a causal effect that we call a <italic>natural causal effect</italic>. Since the observed conditional distribution is equal to the postinterventional distribution given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e143" xlink:type="simple"/></inline-formula>, we interpret this as the intervention naturally occurring in the system. Note that this definition implies that if Eq. 2 does not hold, then the natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e144" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e145" xlink:type="simple"/></inline-formula> does not exist.</p>
        <p>Next we formulate the natural causal effect between two (sets of) random variables. The natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e146" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e147" xlink:type="simple"/></inline-formula> is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e148" xlink:type="simple"/><label>(3)</label></disp-formula></p>
        <p>if and only if Eq. 2 holds for each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e149" xlink:type="simple"/></inline-formula>. Note that Eq. 3 is a factorization of the joint distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e150" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e151" xlink:type="simple"/></inline-formula>. Indeed we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e152" xlink:type="simple"/><label>(4)</label></disp-formula></p>
        <p>This means that if Eq. 2 holds for each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e153" xlink:type="simple"/></inline-formula> then the natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e154" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e155" xlink:type="simple"/></inline-formula> is given by the joint distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e156" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e157" xlink:type="simple"/></inline-formula>. At first glance it might seem strange that the factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e158" xlink:type="simple"/></inline-formula> appears in the definition of the natural causal effect (Eq. 3). After all, the effects of the causal interactions are ‘felt’ only by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e159" xlink:type="simple"/></inline-formula>, and we think of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e160" xlink:type="simple"/></inline-formula> as being the cause. However, it is clear that the conditional distributions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e161" xlink:type="simple"/></inline-formula> will in general depend on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e162" xlink:type="simple"/></inline-formula> which means that to account for the causal effects of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e163" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e164" xlink:type="simple"/></inline-formula> we need to consider all the different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e165" xlink:type="simple"/></inline-formula> according to the distribution with which they are observed. This means that we must consider how often the different single natural interventions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e166" xlink:type="simple"/></inline-formula> happen, that is, we need to include <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e167" xlink:type="simple"/></inline-formula> in the definition.</p>
        <p>An important characteristic of natural causal effects is that the interventions they represent are not chosen by an experimenter (or policy maker) but are ‘chosen’ by the dynamics of the system itself. This means that we can think of the natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e168" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e169" xlink:type="simple"/></inline-formula> as the joint effect of all possible interventions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e170" xlink:type="simple"/></inline-formula> with the additional constraint that the distribution of the interventions is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e171" xlink:type="simple"/><label>(5)</label></disp-formula></p>
        <p>We can thus separate the definition of the natural causal effect from <italic>variable</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e172" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e173" xlink:type="simple"/></inline-formula> into two different criteria. The first one is a <italic>criterion of existence of natural causal effects</italic> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e174" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e175" xlink:type="simple"/></inline-formula> (Eq. 2), which determines when interventions occur naturally in the system. The second one, is a <italic>criterion of maintenance of the natural joint distribution</italic> (Eq. 5), which interprets the observed marginal distribution of the intervened variable as a distribution of interventions, so that the natural joint distribution is preserved (Eq. 4).</p>
        <p>We now turn to the conditions on the causal structure under which natural causal effects exist. This means that we need to identify the conditions for which<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e176" xlink:type="simple"/><label>(6)</label></disp-formula></p>
        <p>In the interventional framework, this condition on the causal effect on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e177" xlink:type="simple"/></inline-formula> of intervening <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e178" xlink:type="simple"/></inline-formula> is called <italic>not confounded</italic> (Ch. 6 in<xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>). Importantly, the fulfillment or not of this condition is determined only by the causal structure. In particular, in <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> we demonstrate that Eq. 6 holds if the following two conditions are fulfilled: First, that there are no causal connections in the opposite direction (i.e. from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e179" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e180" xlink:type="simple"/></inline-formula>). Second, that there is no common driver of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e181" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e182" xlink:type="simple"/></inline-formula>. These two conditions assure that the dependence reflected in the conditional probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e183" xlink:type="simple"/></inline-formula> is specific for the causal flow from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e184" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e185" xlink:type="simple"/></inline-formula>. Notice though, that the presence of mediating variables is allowed, that is, a natural causal effect can be due to indirect causal connections. See <xref ref-type="fig" rid="pone-0032466-g002">Figure 2A</xref> for an illustration of a causal graph supporting natural causal effects that are partly indirect.</p>
        <fig id="pone-0032466-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0032466.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Natural causal effects.</title>
            <p>Examples of causal graphs illustrating when the effect of the influence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e186" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e187" xlink:type="simple"/></inline-formula> can be interpreted as a natural causal effect (<bold>A</bold>) and when it cannot (<bold>B</bold>).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.g002" xlink:type="simple"/>
        </fig>
        <p>We emphasize that if Eq. 6 does not hold then the impact on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e188" xlink:type="simple"/></inline-formula> of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e189" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e190" xlink:type="simple"/></inline-formula> cannot be given a cause-and-effect interpretation. An example of this is given in <xref ref-type="fig" rid="pone-0032466-g002">Figure 2B</xref> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e191" xlink:type="simple"/></inline-formula> is a common driver of both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e192" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e193" xlink:type="simple"/></inline-formula> which therefore precludes a cause-and-effect interpretation of the joint distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e194" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e195" xlink:type="simple"/></inline-formula>. In this case we can still calculate the causal effect of an intervention, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e196" xlink:type="simple"/></inline-formula>, according to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e197" xlink:type="simple"/><label>(7)</label></disp-formula></p>
        <p>see <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> for a detailed calculation. It might seem contradictory that on the one hand side, the impact of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e198" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e199" xlink:type="simple"/></inline-formula> does not result in a natural causal effect and on the other hand side we can still compute the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e200" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e201" xlink:type="simple"/></inline-formula> using the above formula. The key here is what we add by the modifier ‘natural’. To illustrate this, consider what would happen if we were to reconstruct the joint distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e202" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e203" xlink:type="simple"/></inline-formula> from the marginal distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e204" xlink:type="simple"/></inline-formula> and the distribution of the interventions given in Eq. 7. That is, consider the joint distribution<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e205" xlink:type="simple"/></disp-formula></p>
        <p>with the additional constraint that we choose the distribution of interventions according to Eq. 5. Now given the formula in Eq. 7 we see that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e206" xlink:type="simple"/></inline-formula> (unless, of course, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e207" xlink:type="simple"/></inline-formula>, but this condition is not compatible with <xref ref-type="fig" rid="pone-0032466-g002">Figure 2B</xref>, that is, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e208" xlink:type="simple"/></inline-formula> being a common driver). This means that even if we make sure that the marginal distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e209" xlink:type="simple"/></inline-formula> is the correct one, we cannot reconstruct the observed natural joint distribution and hence the natural ’dynamics’ of the variables in the system. In other words, the interventions change the system and the causal effect is with respect to this changed system. As mentioned above, sometimes this is indeed what is desired but in most cases where causality analysis is applied to the neurosciences the aim is to characterize what we have called the natural causal effect.</p>
        <p>Apart from causal effects of the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e210" xlink:type="simple"/></inline-formula>, one could argue that for cases like the one in <xref ref-type="fig" rid="pone-0032466-g002">Figure 2B</xref>, it would be relevant to consider <italic>conditional</italic> causal effects <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e211" xlink:type="simple"/></inline-formula>. That is, given that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e212" xlink:type="simple"/></inline-formula> is a confounder, a way to get rid of its influence is to examine the causal effect for each observed value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e213" xlink:type="simple"/></inline-formula> separately. In analogy with the definition of natural causal effect above we define the <italic>conditional natural causal effect</italic> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e214" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e215" xlink:type="simple"/></inline-formula> given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e216" xlink:type="simple"/></inline-formula> to be<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e217" xlink:type="simple"/><label>(8)</label></disp-formula></p>
        <p>if and only if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e218" xlink:type="simple"/><label>(9)</label></disp-formula></p>
        <p>Eq. 9 is analogous to Eq. 2 and constitutes a criterion for the existence of the conditional natural causal effects. Furthermore, in Eq. 8 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e219" xlink:type="simple"/></inline-formula> should be interpreted as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e220" xlink:type="simple"/></inline-formula> in Eq. 5, being the distribution of the interventions related to the criterion of maintenance of the natural joint distribution. It is important to note the different nature of this causal effect with respect to the unconditional one. In effect, for each value of the conditioned variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e221" xlink:type="simple"/></inline-formula> there is a (potentially) different natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e222" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e223" xlink:type="simple"/></inline-formula>. That is, in this case it does not make sense to talk about the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e224" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e225" xlink:type="simple"/></inline-formula>, instead the causal effect is of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e226" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e227" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e228" xlink:type="simple"/></inline-formula>. In contrast to the criterion of Eq. 2 this criterion (i.e. Eq. 9) is fulfilled in the causal graph of <xref ref-type="fig" rid="pone-0032466-g002">Figure 2B</xref> (see <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> for the details). We will further address the interpretation of unconditional and conditional natural causal effects in a subsequent section below. In <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> we show the conditions under which Eq. 9 holds. Like for the unconditional case one of the requirements is that there are no causal connections in the opposite direction (i.e. from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e229" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e230" xlink:type="simple"/></inline-formula>). The other condition is analogous to the lack of common drivers in the unconditional case. In particular, the influence of any possible common driver should be blocked by the conditioning on the variables in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e231" xlink:type="simple"/></inline-formula>, or in technical language, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e232" xlink:type="simple"/></inline-formula> satisfies the back-door criterion relative to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e233" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e234" xlink:type="simple"/></inline-formula> (see Definition 3.3.1 in <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>).</p>
        <p>We have defined the natural causal effect from one (set of) variables to another as their joint distribution. In practice it will often be more convenient to characterize the natural causal effect with a lower-dimensional measure. Below we will indicate some possible such measures. However, note that the emphasis in this work is not so much in applying this framework to data but to show under which conditions the interactions between subsystems can be given a cause-and-effect interpretation.</p>
      </sec>
      <sec id="s2e">
        <title>Natural causal effects between brain dynamics</title>
        <p>Introducing natural causal effects above we considered <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e235" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e236" xlink:type="simple"/></inline-formula> to be univariate or multivariate random variables. In the case of studying the interactions between different subsystems of the brain we are led to consider natural causal effects between time series. We assume that the variables in the time series are causal, that is, the variables in one time series can potentially have direct causal influence over variables in the other. Since we are modeling a system (e.g. the brain) without instantaneous causality, we will not include instantaneous causality in the models below. (Note that in applications it might be important to have a high enough sampling rate to avoid ‘instantaneous causality’.) Given two subsystems <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e237" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e238" xlink:type="simple"/></inline-formula> with time changing activities we let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e239" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e240" xlink:type="simple"/></inline-formula> denote two time series corresponding to the activities of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e241" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e242" xlink:type="simple"/></inline-formula>. That is, relative to some temporal reference frame, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e243" xlink:type="simple"/></inline-formula> is the random variable that models the activity in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e244" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e245" xlink:type="simple"/></inline-formula>.</p>
        <p>When asking ‘causality questions’ about time series it is important to be specific about exactly what is the type of causal effect of interest. In particular, one could be interested in causal effects at different scales. For example, the interest could be in the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e246" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e247" xlink:type="simple"/></inline-formula>, which would then be viewed as the impact of the totality of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e248" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e249" xlink:type="simple"/></inline-formula>. Indeed, this seem to be the causal effect that has received most interest in neuroscience (e.g. <xref ref-type="bibr" rid="pone.0032466-Friston1">[8]</xref>). Alternatively the interest could be in the causal effect at a particular point in time, e.g. we could ask about the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e250" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e251" xlink:type="simple"/></inline-formula>. Of course, these two types of causal effects at different levels of descriptions are related, but are not equivalent and reflect different aspects of the impact of the causal connections between the subsystems.</p>
        <p>We will use the framework of causal graphs to represent the causal structure of the dynamics of the subsystems. Since we assume that there is no instantaneous causality, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e252" xlink:type="simple"/></inline-formula> cannot interact directly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e253" xlink:type="simple"/></inline-formula> (and vice versa). We use<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e254" xlink:type="simple"/></disp-formula></p>
        <p>to denote the past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e255" xlink:type="simple"/></inline-formula>, relative to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e256" xlink:type="simple"/></inline-formula>. Furthermore, for simplicity we only represent direct causal connections of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e257" xlink:type="simple"/></inline-formula> in the causal graph (i.e. from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e258" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e259" xlink:type="simple"/></inline-formula>), but our results are generic.</p>
        <p>The subsystems can be represented at different scales, according to the type of causal effect one is interested in. We will consider the case of two subsystems with unidirectional causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e260" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e261" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3A–C</xref>), or alternatively with bidirectional causal connections (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3D–F</xref>).</p>
        <fig id="pone-0032466-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0032466.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Graphical representation of causal connections for subsystems changing in time.</title>
            <p>Causal graphs represent two subsystems with unidirectional causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e262" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e263" xlink:type="simple"/></inline-formula> (A–C), or bidirectional causal connections (D–F). From left to right the scale of the graphs changes from a microscopic level, representing the dynamic, to a macroscopic one, in which each subsystem is represented by a single node.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.g003" xlink:type="simple"/>
        </fig>
        <p>The <italic>microscopic</italic> representation of the causal structure displays explicitly all the variables and their causal connections (<xref ref-type="fig" rid="pone-0032466-g003">Figures 3A,D</xref>). At this microscopic level the graph is always a directed acyclic graph (DAG), given the above assumption of no instantaneous interactions. The microscopic level is required to examine types of causal effects that consider some particular intervals of the time series, e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e264" xlink:type="simple"/></inline-formula>. If instead we consider the time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e265" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e266" xlink:type="simple"/></inline-formula> in their totality we get the <italic>macroscopic</italic> causal graph shown in <xref ref-type="fig" rid="pone-0032466-g003">Figure 3C,F</xref>. The macroscopic representation is useful because of its simplicity, with only one node per system, and it has been often used in the literature e.g. <xref ref-type="bibr" rid="pone.0032466-Dahlhaus1">[20]</xref>–<xref ref-type="bibr" rid="pone.0032466-Eichler2">[22]</xref>. Note that at the macroscopic level a microscopic DAG can become cyclic (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3F</xref>). At the macroscopic level the only causal effect to consider is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e267" xlink:type="simple"/></inline-formula>. As one intermediate possibility we could consider a <italic>mesoscopic</italic> representation (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3B,E</xref>). Here the ‘past’ of the two time series at some point in time (referred to by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e268" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e269" xlink:type="simple"/></inline-formula>, respectively) is only implicitly represented, whereas the ‘future’ (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e270" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e271" xlink:type="simple"/></inline-formula>) is explicit. The causal effects related to this representation are of the type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e272" xlink:type="simple"/></inline-formula>, and the conditional causal effects <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e273" xlink:type="simple"/></inline-formula>. As we will see below, this is the representation that best accommodates Granger causality.</p>
        <p>Different levels of representation may be used depending on the type of causal effects to be studied. However, it is important to emphasize that the conditions for the existence of natural causal effects give consistent results independently of the scale of the representation. For example, whether the natural causal effects <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e274" xlink:type="simple"/></inline-formula> exist or not can be checked using the microscopic causal graph. This is because the representations at the different levels are consistent, so that an arrow in the macroscopic graph from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e275" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e276" xlink:type="simple"/></inline-formula> exists only if any directed causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e277" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e278" xlink:type="simple"/></inline-formula> exists. This consistency reflects that at the macroscopic level the time series are conceived, not just as a set of random variables, but as representative of the dynamics of the subsystems. While at the microscopic level the status of the relation of a variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e279" xlink:type="simple"/></inline-formula> with another <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e280" xlink:type="simple"/></inline-formula> may seem equivalent to the one with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e281" xlink:type="simple"/></inline-formula>, being this relation determined by the causal connections, the consideration of the time series as an entity breaks this equivalence, because the variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e282" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e283" xlink:type="simple"/></inline-formula> can be merged as part of the time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e284" xlink:type="simple"/></inline-formula>, while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e285" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e286" xlink:type="simple"/></inline-formula> are not considered together at the macroscopic level.</p>
        <p>At the macroscopic level, the natural causal effect from time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e287" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e288" xlink:type="simple"/></inline-formula> is, in analogy with Eq. 3, given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e289" xlink:type="simple"/><label>(10)</label></disp-formula></p>
        <p>and can be seen as reflecting the total influence of the dynamics of the subsystem <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e290" xlink:type="simple"/></inline-formula> to the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e291" xlink:type="simple"/></inline-formula>. However, as we mentioned above, this high-dimensional causal effect is not the only type of causal effects that can result from the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e292" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e293" xlink:type="simple"/></inline-formula>. Other types of causal effects related to distributions of lower dimension, like the ones mentioned above, also reflect some aspects of the impact of the causal connections. This diversity of types of causal effects indicates that the causal structure should be seen as a medium that channels different types of natural causal effects. The idea of quantifying causal effects with a single measure of strength is an oversimplification, and although in some circumstances focusing on one of these types of natural causal effects may suffice to characterize the dynamics, in general they provide us complementary information.</p>
        <p>The causal graphs at different scales can be related to different types of models. Macroscopic causal graphs have been used to represent structural equation models (SEM), where time is ignored. This type of models have been described in detail in the interventional framework of causality (see Chapter 5 in <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>), but there is no fundamental limitation of this framework to functional models that do not take time into account. In fact, sequential time interventions have also been studied (e. g. <xref ref-type="bibr" rid="pone.0032466-Robins1">[23]</xref>) and recently the relation between interventions and Granger causality in time series was considered <xref ref-type="bibr" rid="pone.0032466-Eichler3">[24]</xref>. See also the so-called Dynamic structural causal modeling in <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>. Once time is explicitly represented like in the microscopic scale, the acyclic structure of the graph is not incompatible with the representation of feedback loops between the subsystems.</p>
      </sec>
      <sec id="s2f">
        <title>The constraints of the causal structure on the existence and characterization of natural causal effects between dynamics</title>
        <p>Here we will consider in more detail when natural causal effects exist and can be characterized, and thus when the question "What is the causal effect of the subsystem <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e294" xlink:type="simple"/></inline-formula> on the subsystem <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e295" xlink:type="simple"/></inline-formula>?" is meaningful. For simplicity we will restrict ourselves to the bivariate case illustrated in <xref ref-type="fig" rid="pone-0032466-g003">Figure 3</xref>.</p>
        <p>Consider first the case of unidirectional causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e296" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e297" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pone-0032466-g003">Figure 3A–C</xref>. For any type of causal effect that involves an intervention of some variables of the time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e298" xlink:type="simple"/></inline-formula>, generally <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e299" xlink:type="simple"/></inline-formula>, we need to examine if they are common drivers between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e300" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e301" xlink:type="simple"/></inline-formula>. Due to the unidirectional causal connections all the common drivers are contained in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e302" xlink:type="simple"/></inline-formula>. This means that any conditional causal effect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e303" xlink:type="simple"/></inline-formula> is a natural causal effect. Furthermore, the criterion of existence is also fulfilled for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e304" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e305" xlink:type="simple"/></inline-formula> (See <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref>). In all these cases one can select the marginal distribution of interventions in agreement with the natural distribution according to Eq. 5 and thus preserve the natural joint distribution (Eq. 4). This implies that in the case of unidirectional causality it is possible to quantify the impact of the casual connections in terms of the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e306" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e307" xlink:type="simple"/></inline-formula>. In the next section we will indicate how this can be done.</p>
        <p>Consider now the case of bidirectional causal connections in <xref ref-type="fig" rid="pone-0032466-g003">Figure 3D–F</xref>. At the microscopic level we see that for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e308" xlink:type="simple"/></inline-formula> and each variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e309" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e310" xlink:type="simple"/></inline-formula>, the variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e311" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e312" xlink:type="simple"/></inline-formula> constitute common drivers (direct or indirect). This is also reflected in the mesoscopic time scale, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e313" xlink:type="simple"/></inline-formula> is a common driver of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e314" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e315" xlink:type="simple"/></inline-formula> and there is a loop between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e316" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e317" xlink:type="simple"/></inline-formula>. Therefore, the criterion of existence of the natural causal effects is not fulfilled in the case of bidirectional causality.</p>
        <p>By contrast, the criterion of existence is fulfilled for the conditional natural causal effects, for example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e318" xlink:type="simple"/></inline-formula> that we mentioned when we introduced the mesoscopic level. In this case all the possible common drivers, contained in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e319" xlink:type="simple"/></inline-formula>, are conditioned. Therefore we can say that there are conditional natural causal effects from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e320" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e321" xlink:type="simple"/></inline-formula> given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e322" xlink:type="simple"/></inline-formula> even in the case of bidirectional causality. However, to determine if this type of conditional causal effects can be used to characterize the impact of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e323" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e324" xlink:type="simple"/></inline-formula>, we still have to consider the preservation of the joint conditional distribution (Eq. 8). In analogy to Eq. 5, to preserve the natural dynamics we need to select the interventions according to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e325" xlink:type="simple"/><label>(11)</label></disp-formula></p>
        <p>That is, we have to choose the interventions conditionally upon <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e326" xlink:type="simple"/></inline-formula>, but this is clearly contradictory to the idea of defining a causal effect from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e327" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e328" xlink:type="simple"/></inline-formula>. Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e329" xlink:type="simple"/></inline-formula> conditions the interventions, we cannot interpret the causal effect as representative of the impact of the causal connections from one subsystem to the other. This is because we do not simply consider the conditional effect of a set of variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e330" xlink:type="simple"/></inline-formula> in a variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e331" xlink:type="simple"/></inline-formula> given a another set of variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e332" xlink:type="simple"/></inline-formula>. The variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e333" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e334" xlink:type="simple"/></inline-formula> are related since we consider them as part of a single entity, namely the time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e335" xlink:type="simple"/></inline-formula>. The conditional natural causal effects <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e336" xlink:type="simple"/></inline-formula> with a distribution according to Eq. 11 occur given how the causal connections generate the observed dynamics, but these conditional causal effects cannot be understood as being from one subsystem to the other. In particular, the distribution of the natural interventions is also determined by the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e337" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e338" xlink:type="simple"/></inline-formula>.</p>
        <p>Altogether, in the case of bidirectional causality, none of the candidate causal effects considered fulfills the criteria for the existence of natural causal effects and the maintenance of the joint distribution. For bidirectional causality the causal effects like <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e339" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e340" xlink:type="simple"/></inline-formula> do not exist as natural causal effects, while conditional causal effects like <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e341" xlink:type="simple"/></inline-formula> take place in the system, but cannot be understood as causal effects between the subsystems.</p>
        <p>We emphasize that what prevents the interpretation of the conditional natural causal effects discussed above as a causal effect between the subsystems is to some extent the point-of-view of the interpreter. What our analysis show is that problems of interpretation arises when grouping variables together as when considering <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e342" xlink:type="simple"/></inline-formula> as standing for the activity of a particular subsystem. At the microscopic level, keeping time locality, one can analyze these conditional natural causal effects. For example, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e343" xlink:type="simple"/></inline-formula> can be viewed the natural causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e344" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e345" xlink:type="simple"/></inline-formula> given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e346" xlink:type="simple"/></inline-formula>. That is, relative to a particular time instant, we can meaningfully talk about conditional natural causal effects. However, note that since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e347" xlink:type="simple"/></inline-formula> does not represent the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e348" xlink:type="simple"/></inline-formula>, this natural causal effect cannot be considered the effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e349" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e350" xlink:type="simple"/></inline-formula>.</p>
        <p>That we cannot in general answer what is the causal effect of a brain subsystem on another while processing some stimulus or performing some neural computation may seem surprising. However, the definition of the natural causal effects (Eq. 3) was derived precisely to be consistent with what should be expected from a definition of causal effect to be used to analyze the natural activity of brain dynamics. We will now give some arguments to indicate that the restrictions imposed by the causal structure are in fact intuitive.</p>
        <p>In <xref ref-type="fig" rid="pone-0032466-g003">Figure 3</xref> we showed that, while at the microscopic scale a DAG is obtained as long as instantaneous interactions are excluded, at the mesoscopic and macroscopic scales the existence of bidirectional causality leads to a cyclic graph (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3E–F</xref>). This means that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e351" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e352" xlink:type="simple"/></inline-formula> are mutually determined. This mutual determination can be understood as the impossibility to write a set of equations such that the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e353" xlink:type="simple"/></inline-formula> can be determined previously without simultaneously determining the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e354" xlink:type="simple"/></inline-formula>. At the microscopic scale, for bidirectional causality (<xref ref-type="fig" rid="pone-0032466-g003">Figure 3D</xref>), one can consider a path from some node <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e355" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e356" xlink:type="simple"/></inline-formula>, to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e357" xlink:type="simple"/></inline-formula> which is directed and thus follows the causal flow, but contains both arrows <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e358" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e359" xlink:type="simple"/></inline-formula>. In this case it is not possible to disentangle in the natural dynamics the causal effect in the opposite directions: when considering the causal effect from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e360" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e361" xlink:type="simple"/></inline-formula>, assuming <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e362" xlink:type="simple"/></inline-formula>, it is not clear to which degree the influence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e363" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e364" xlink:type="simple"/></inline-formula> is intrinsic to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e365" xlink:type="simple"/></inline-formula> or due to the previous influence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e366" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e367" xlink:type="simple"/></inline-formula>.</p>
        <p>That is, in the case of a bidirectional coupling, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e368" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e369" xlink:type="simple"/></inline-formula> form a unique bivariate system in which the contribution of one system to the dynamics of the other cannot be meaningfully quantified. Therefore it does not make sense to ask for the causal effect from one subsystem to the other, but to examine how the causal connections participate in the generation of the joint dynamics. A simple neural example illustrating this view would be the processing of a visual stimulus in the primary visual cortex (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e370" xlink:type="simple"/></inline-formula>). For example, responses of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e371" xlink:type="simple"/></inline-formula> cells are influenced by the spatial context of the the stimulus due to the feedback projection from cortical area MT (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e372" xlink:type="simple"/></inline-formula>), where receptive fields are much larger than in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e373" xlink:type="simple"/></inline-formula>. This means that there is a feedback modulation from a higher level in the visual pathway, which activity depends itself on the processing in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e374" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0032466-Sillito1">[25]</xref>. In this case what is important is to understand how the causal structure, and in particular the existence of the feedback causal connections, are necessary to generate the regime of the responses and to obtain some characteristics of the neurons' responses that are functionally relevant, like the influence of stimulus context.</p>
      </sec>
      <sec id="s2g">
        <title>The analysis of causal effects</title>
        <p>We have complemented the definition of causal effects from the interventional framework with two criteria that reflect the requirements specific for studying causality between subsystems of the brain during their natural activity. In this section we consider how to quantify the natural causal effects between dynamics and more generally any causal effect related to a change in the dynamics. The measures introduced below should be considered devices for further analysis and characterization of natural causal effects and not necessarily as tools for data analysis.</p>
        <p>We start by considering how to quantify single causal effects of a given type, for example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e375" xlink:type="simple"/></inline-formula> for a fixed intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e376" xlink:type="simple"/></inline-formula>. Assume that we check in a causal structure that this type of natural causal effects exists. To quantify this causal effect we need a reference distribution to which the post-intervention distribution can be compared. The appropriate reference distribution will typically be dictated by the context. For example, in Eq. 1 the reference was the marginal distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e377" xlink:type="simple"/></inline-formula>, which is just the average over all interventions. Alternatively, one can consider the same intervention <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e378" xlink:type="simple"/></inline-formula> but for a different configuration of the system, in which some causal mechanisms are assumed to have changed. In this latter case we denote the reference distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e379" xlink:type="simple"/></inline-formula>. Notice that even when a type of natural causal effects exists and thus the impact of the causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e380" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e381" xlink:type="simple"/></inline-formula> can be interpreted in terms of cause-and-effects, one typically cannot quantify the causal effects in absolute terms. Only in some special cases, when the reference distribution can be associated with the absence of causal interactions, can the causal effect be interpreted in absolute terms. In this case, and only in this case, can we talk of the <italic>strength</italic> of the causal effect. In the general case, the measures we consider here reflect relative differences of the causal effects.</p>
        <p>Our analysis of natural causal effects relies on the comparison of probability distributions but we emphasize that the first step in the analysis must be to make sure that the type of natural causal effects studied actually exists in the system. To compare two probability distributions associated with natural causal effects one can use different measures, as for example the expected values as in Eq. 1. Here we will use Kullback-Leibler divergences (see <xref ref-type="sec" rid="s4">Methods</xref>) since these are sensitive to all the moments of the distributions and also because this allows for a more direct comparison with a general measure of Granger causality, the transfer entropy (see below). For example, in the case that the same intervention for another configuration is used as a reference we can use:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e382" xlink:type="simple"/><label>(12)</label></disp-formula></p>
        <p>Here we have assumed that the domain of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e383" xlink:type="simple"/></inline-formula> is the same in the two configurations. When this is not the case, Jensen-Shannon Divergence should be used instead (see <xref ref-type="sec" rid="s4">Methods</xref>). The Kullback-Leibler divergence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e384" xlink:type="simple"/></inline-formula> is an asymmetric measure that quantifies how different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e385" xlink:type="simple"/></inline-formula> is from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e386" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e387" xlink:type="simple"/></inline-formula> corresponds to the reference distribution associated with no causal interactions, the particular form of Eq. 12 enables an absolute comparison of natural casual effects for different configurations. Note, however, that we are not interested in characterizing a particular measure but in examining the principles of the analysis of natural causal effects. The particular measure selected for application to data should also depend on other issues such as the balance between the degree of sensitivity to differences between the distributions (i. e. linear vs. nonlinear measures), and the difficulty to estimate the measures from limited amount of data.</p>
        <p>We now consider how to quantify the natural causal effects in a system, when different causal effects of the same type have to be taken into account. As discussed previously, the impact of causal connections does not depend on single interventions, but on all the different natural causal effects of the same type occurring in the dynamics with a given probability distribution. How to proceed to compare these different natural causal effects depends on the purpose of the analysis. For example, one may be interested in quantifying the average difference of the natural causal effects for two different configurations. In this case one can use the probability of the natural intervention (Eq. 5) to average Eq. 12. That is, one could use<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e388" xlink:type="simple"/><label>(13)</label></disp-formula></p>
        <p>This analysis can be done indistinctively of which type of natural causal effects is analyzed. For processes one can substitute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e389" xlink:type="simple"/></inline-formula> by for example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e390" xlink:type="simple"/></inline-formula> in Eqs. 12 and 13. Again the requirement for these measures to be interpreted as quantifying the natural causal effects between the processes is that the criteria discussed above are fulfilled.</p>
      </sec>
      <sec id="s2h">
        <title>How Dynamic Causal Modeling and Granger causality answer the questions about causality</title>
        <p>We will now review how the three different questions about causality introduced above are addressed by DCM and Granger causality, the two main approaches that are commonly applied to study causality between the brain systems. Although this section is not strictly a ‘Results’ section, casting DCM and Granger Causality in terms of the framework we propose will make it possible to see (in the next section) how our work extends and complements these approaches. Before examining DCM and Granger causality separately, we should note that both have in common that they rely on the statistical analysis of observational data. Both are thus ultimately limited by the existence of observationally equivalent causal structures with regard to the inference of the causal connections (question Q1 about existence). Here we will not consider these limitations further but instead focus on how DCM and Granger causality address question Q3 about the quantification of causal effects. We will focus on the essential aspects of these approaches as formulated by <xref ref-type="bibr" rid="pone.0032466-Friston2">[26]</xref> and <xref ref-type="bibr" rid="pone.0032466-Granger1">[27]</xref>, respectively.</p>
        <p>Dynamic Causal Modeling is based on modeling the observed data, and from our perspective it can be considered an approach to answering Q2. Since DCM explicitly considers the dynamics, in contrast to previous modeling approaches such as SEM, it represents an important step towards obtaining a model that can faithfully reflect the causal structure and the dynamics of the real system. Similarly, since it considers a forward model that maps hidden states to observed quantities it also is an improvement with respect to the approaches based on the parametric autoregressive model formulation of Granger causality <xref ref-type="bibr" rid="pone.0032466-Granger2">[28]</xref>. In DCMs the state equations are causal in the sense that the rate of change of the variables generally depends on the state of the system. This means that a causal structure at the macroscopic scale can be constructed from the state equations. The form of the state equations in DCM makes an interventional interpretation of the model possible due to the asymmetry between the left- and right-hand terms in the equations <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>. Nonetheless, the correspondence of the inherent causal relationships in the model to the causal structure of the real system depends critically on how accurate the state equations model the underlying neuronal activity. With regard to Q1 it remains as an open question how realistic a model should be so that the causal structure of the system can be inferred correctly. Furthermore, in practice, since typically only few subsystems are modeled, latent variables are certainly present and could introduce “spurious causality”, for example making two subsystem appear causally related whereas in fact they are not (see <xref ref-type="bibr" rid="pone.0032466-Ramsey1">[29]</xref> and <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref> for discussion of the missing region problem in the concrete context of fMRI analysis). This is the ultimate limitation when inferring causality without intervening mentioned above.</p>
        <p>We are here mainly interested in how DCM addresses question Q3 about the causal effects. Effective connectivity is generally understood as the influence one region exerts over another <xref ref-type="bibr" rid="pone.0032466-Friston1">[8]</xref>. In practice though, this abstract definition is made concrete considering that the effective connectivity is associated with the coupling parameters between variables representing different brain regions in the state equations <xref ref-type="bibr" rid="pone.0032466-Friston2">[26]</xref>. For example, for two different conditions, a model is fitted and the gain of the coupling parameter that models the connectivity from region <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e391" xlink:type="simple"/></inline-formula> to region <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e392" xlink:type="simple"/></inline-formula> is reported. Therefore, the <italic>strength</italic> of the causal connection is analyzed in terms of the coupling parameters in the model. There is no explicit definition of the causal effect. The change in the coupling parameter is discussed in terms of adaptation or stimulus modulation of the connectivity, thus focusing on the mechanistic change, without considering its impact in the dynamics. In some simple cases, such as when the state dynamics are linear, one can infer interventional causal effects from the model parameters <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>. However, it is important to emphasize that a functional (or biophysical) model (dynamic or not) of the real system does not alleviate the restrictions with respect to natural causal effect imposed by the causal structure. In other words, if a particular causal structure is incompatible with a natural causal effect from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e393" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e394" xlink:type="simple"/></inline-formula> the values of parameters describing the coupling from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e395" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e396" xlink:type="simple"/></inline-formula> can not be interpreted as reflecting the causal effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e397" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e398" xlink:type="simple"/></inline-formula> in the natural dynamics, even if they are informative about what would be the causal effect of an external intervention of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e399" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e400" xlink:type="simple"/></inline-formula>.</p>
        <p>The approach of Granger causality is significantly different from the one of DCM. Many years ago Sir Clive Granger suggested a criterion for testing for causality between time series <xref ref-type="bibr" rid="pone.0032466-Granger2">[28]</xref>. In the bivariate case, this criterion says that there are no causal connections from process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e401" xlink:type="simple"/></inline-formula> to process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e402" xlink:type="simple"/></inline-formula> if and only if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e403" xlink:type="simple"/><label>(14)</label></disp-formula></p>
        <p>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e404" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e405" xlink:type="simple"/></inline-formula> refer to the whole past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e406" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e407" xlink:type="simple"/></inline-formula>, respectively. In words, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e408" xlink:type="simple"/></inline-formula> is causing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e409" xlink:type="simple"/></inline-formula> if the future of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e410" xlink:type="simple"/></inline-formula> given the past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e411" xlink:type="simple"/></inline-formula> is not independent of the past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e412" xlink:type="simple"/></inline-formula>. Therefore the criterion of Granger causality tests for a conditional independence, which corresponds to the type of constraints we mentioned above that the causal structure imposes on the statistical dependencies. Given that these constraints are generally not enough to infer the causal structure the criterion of Granger causality is only applicable under some assumptions. We will called these assumptions <italic>complete observability</italic>. What is assumed is that there is no hidden process which is a common driver of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e413" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e414" xlink:type="simple"/></inline-formula>. This assumption is related to the fundamental limitations of causality inference from observational data and is common to DCM. Furthermore it is assumed that we have access to the relevant processes between which the causal connections exist, so that the probability distributions are estimated for variables directly corresponding to these processes. This assumption avoids the use of a forward model that maps hidden states to observed quantities. This second assumption is specific of Granger causality in contrast to DCM where such a forward model is explicitly included.</p>
        <p>In the original formulation, Granger used the mean of the distributions to test the above equality, but it was clear to him that other measures could be used as well <xref ref-type="bibr" rid="pone.0032466-Granger1">[27]</xref>. The most general test of the equality of the two probability distributions in Equation 14 uses the Kullback-Leibler divergence (See <xref ref-type="sec" rid="s4">Methods</xref>). The resulting measure has been introduced several times in the past and in different contexts <xref ref-type="bibr" rid="pone.0032466-Marko1">[30]</xref>–<xref ref-type="bibr" rid="pone.0032466-Rissanen1">[32]</xref>. Most recently, the same measure was re-introduced under the name ‘transfer entropy’ <xref ref-type="bibr" rid="pone.0032466-Schreiber1">[33]</xref> and due to its recent popularity, we will use this name in the sequel. See e.g. <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>, <xref ref-type="bibr" rid="pone.0032466-Amblard1">[34]</xref> for a more detailed description of how different formulations of Granger causality appeared in different fields and for different types of processes. In particular we can formulate Granger's causality criterion (Eq. 14) as a comparison between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e415" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e416" xlink:type="simple"/></inline-formula> using the KL divergence. The transfer entropy from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e417" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e418" xlink:type="simple"/></inline-formula> is:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e419" xlink:type="simple"/><label>(15)</label></disp-formula></p>
        <p>Note that due to a basic property of the KL-divergence the transfer entropy is zero if and only if the criterion of Eq. 14 is fulfilled.</p>
        <p>We now consider how Granger causality analysis addresses the different questions about causality. Since it provides a criterion to infer the existence of the causal connections it focuses on answering Q1. However, notice that the Granger causality criterion is not designed to infer a causal graph that considers explicitly the temporal dynamics (the microscopic scale in <xref ref-type="fig" rid="pone-0032466-g003">Figure 3</xref>). The Granger causality criterion only intends to infer if there is any causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e420" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e421" xlink:type="simple"/></inline-formula>, that is, allows us to construct the macroscopic causal graph.</p>
        <p>Granger causality is based on a criterion for causal inference and thus in its more general nonparametric formulation does not involve modeling, so that question Q2 is not addressed. The transfer entropy constitutes the most general measure to test for the criterion of Granger causality. This means that theoretically a nonzero <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e422" xlink:type="simple"/></inline-formula> implies the existence of some causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e423" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e424" xlink:type="simple"/></inline-formula>, thus answering Q1 (if the assumption of observability are fulfilled). In practice, one needs a way to assess the significance of the nonzero value and in general bootstrapping or surrogates are needed (e. g. <xref ref-type="bibr" rid="pone.0032466-Kaminski2">[5]</xref>, <xref ref-type="bibr" rid="pone.0032466-Chavez1">[35]</xref>, <xref ref-type="bibr" rid="pone.0032466-Verdes1">[36]</xref>). If instead of transfer entropy the parametric formulation using linear autoregressive models is applied, one could consider that question Q2 is also addressed but this means assuming that the autoregressive model is realistic enough to reflect the causal mechanisms.</p>
        <p>Regarding Q3, the same statistic used to test for causality is commonly used to quantify the strength of the causal connections. For example, Granger (1963) <xref ref-type="bibr" rid="pone.0032466-Granger3">[37]</xref> refers to the Granger causality measure for linear Gaussian processes as the <italic>strength of the causality</italic> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e425" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e426" xlink:type="simple"/></inline-formula>. This idea of strength suggests that, apart from assessing the significance of a nonzero value, one should use the value of the statistic for quantification. As for DCM, there is no explicit definition of what the causal effects are. However, in Granger causality, the causal effect is quantified taking into account the dynamics of the processes, instead of examining the changes of single coupling parameters. The emphasis is put on the impact of the causal connections on the dynamics of the processes, so that the causal effects are implicitly conceived as a result of how the causal connections participate in the generation of such dynamics.</p>
        <p>Our definition of natural causal effects between processes is closer to this implicit notion of causal effects used in Granger causality, since it also considers the impact of the causal connections on the dynamics, in contrast to DCM that compares coupling parameters of the model. However, we also argued that this impact cannot be captured with a single measure of strength. Oppositely, the causal structure results in different types of natural causal effects going on in the dynamics, which are associated with different aspects of how the dynamics arise from the causal structure.</p>
        <p>Furthermore, the constraints for the existence of natural causal effects, that for example determine that natural causal effects between processes do not occur in bidirectionally coupled bivariate systems, are contradictory with the common practice of comparing the causal effect in both directions e.g. <xref ref-type="bibr" rid="pone.0032466-Brovelli1">[6]</xref>, <xref ref-type="bibr" rid="pone.0032466-Roebroeck1">[38]</xref>–<xref ref-type="bibr" rid="pone.0032466-Vicente1">[42]</xref> when applying the Granger causality analysis. It can be shown that this contradiction is due to a misuse of Granger causality measures and in particular of transfer entropy as measures of causal strength <xref ref-type="bibr" rid="pone.0032466-Lizier1">[43]</xref>. A detailed description of why transfer entropy cannot be generally used for the quantification of causal effects and under which conditions it has a meaningful interpretation in terms of natural causal effects is left for a future contribution. We will next discuss to which degree the analysis of causal effects we propose should be considered as complementary or substitutive of DCM and Granger causality.</p>
      </sec>
      <sec id="s2i">
        <title>How to combine the analysis of natural causal effects with Dynamic Causal Modeling and Granger causality</title>
        <p>The approach we proposed for the quantification of natural causal effects should be used instead of Granger causality measures to address the question of quantification (Q3). This means that the transfer entropy should be only used as a statistic to test the existence of the causal interactions based on the general criterion of Granger causality (Eq. 14). Even for inference one should be aware of the strong limitations imposed by the assumption of complete observability. In the interventional framework the limitations of Granger causality and thus transfer entropy to infer the causal structure without complete observability are well known. Alternative measures of information flow have been proposed <xref ref-type="bibr" rid="pone.0032466-Ay1">[17]</xref> and compared to transfer entropy <xref ref-type="bibr" rid="pone.0032466-Lizier1">[43]</xref>.</p>
        <p>Although the value of the transfer entropy cannot be used as a measure of strength of the causal effects under some conditions that depend on the causal structure it quantifies the information transfer from one process to another <xref ref-type="bibr" rid="pone.0032466-Lizier1">[43]</xref>, while more generally it can still be used to characterize the temporal statistical dependencies in the signals. Bressler and Seth (2010) <xref ref-type="bibr" rid="pone.0032466-Bressler2">[44]</xref> distinguished between <italic>effective connectivity</italic> <xref ref-type="bibr" rid="pone.0032466-Friston1">[8]</xref> and a different concept of <italic>causal connectivity</italic>. While the <italic>effective connectivity</italic> is expected to reflect the causal influence one brain area exerts on another, <italic>causal connectivity</italic> is considered more pragmatically as a description of directed dynamical interdependencies present in the recorded signals. Although using the term <italic>causal</italic> can be misleading in this context, the transfer entropy, considered strictly as a statistical measure, has a rigorous meaning in terms of information loss <xref ref-type="bibr" rid="pone.0032466-Cover1">[45]</xref> and can capture aspects of the dynamics which may be less reflected in symmetric measures (like coherence or symmetric mutual information). Therefore, the type of analysis related to Eqs. 12 and 13 should substitute Granger causality to analyze causal effects in the natural dynamics, but it is complementary to the use of transfer entropy as a measure of information loss.</p>
        <p>Our approach is also complementary to Dynamic Causal Modeling: it can be used to examine the dynamic impact of the changes across conditions of the coupling parameters associated with effective connectivity. In particular, the only thing specific for the analysis of natural causal effects in Eq. 12 is the selection of probability distributions that are associated with natural causal effects. Alternatively, one can relate the two compared configurations to a change in a coupling parameter. The comparison of a particular probability distribution across configurations (not necessarily associated with natural causal effects) shows the impact of this change on a particular aspect of the dynamics. For example, one can compare <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e427" xlink:type="simple"/></inline-formula> when a coupling parameter associated with the strength of the causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e428" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e429" xlink:type="simple"/></inline-formula> changes:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e430" xlink:type="simple"/><label>(16)</label></disp-formula></p>
        <p>This change of a coupling parameter can be seen exactly as a punctual intervention. Although in causal graphs associated with the state equations of a DCM model, the coupling parameters do not appear as nodes, if two alternative models are compared they can be merged in a single model where the parameter can be seen as a binary variable, so that choosing one or the other model is equivalent to intervening this variable to one of the values. Therefore the comparison of a particular type of probability distributions like in Eq. 16 quantifies the causal effect of the change in the coupling parameter. This type of causal effect is not a natural causal effect from one brain subsystem to another that occur as part of the generation of the dynamics; it is the causal effect that a change in the mechanisms has on some aspects of the dynamics related to the probability distributions chosen. Also here there is flexibility to examine different aspects of the dynamics selecting different probability distributions, for example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e431" xlink:type="simple"/></inline-formula>, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e432" xlink:type="simple"/></inline-formula>, in the same way that the natural causal effects from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e433" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e434" xlink:type="simple"/></inline-formula> are studied examining different distributions like <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e435" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e436" xlink:type="simple"/></inline-formula>. This type of analysis complements the direct comparison of the coupling parameters (effective connectivity) because it is not obvious without actually examining the distributions to derive how a change in the parameters affects the dynamics.</p>
        <p>DCM addresses question Q2 about the mechanisms aiming to provide a realistic model of how the dynamics are generated. In this regard, the analysis of the causal effects considered above cannot substitute the DCM approach. However, considering that only in some cases the natural causal effects between brain regions exist helps to bound the meaning of effective connectivity, generally understood as the influence one region exert on another. The coupling parameters can be related to causal effects of external interventions <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref> but do not quantify natural causal effects occurring in the recorded dynamics. Furthermore, the analysis we suggested above can straightforwardly be extended to examine the causal effect of a change in a coupling parameter on some aspects of the dynamics, something which is not easy to evaluate from the comparison of the coupling parameters across conditions. We will illustrate this point further when analyzing causal effects in an example system below.</p>
      </sec>
      <sec id="s2j">
        <title>Testing for causality and analyzing causal effects in a simple model</title>
        <p>We now examine a model system to illustrate the distinction between the inference of causality and the analysis of the causal effects. Here we focus on a simple example of a stationary Markov binary process. In <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref> we study the case of linear Gaussian stationary stochastic processes. We note that in these examples all the measures used are calculated analytically (see <xref ref-type="sec" rid="s4">Methods</xref>) to isolate the fundamental properties of the measures from issues related to estimation from data. We consider the transfer entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e437" xlink:type="simple"/></inline-formula> and two measures related to Eqs. 13 and 16, respectively. In particular, instead of the Kullback-Leibler divergence used in these equations we calculate the Jensen-Shannon Divergence (JSD) (see <xref ref-type="sec" rid="s4">Methods</xref>), since it is well defined for probabilities with different domains, as the ones resulting from the Markov process explained below.</p>
        <p>So consider a stationary bivariate Markov binary process of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e438" xlink:type="simple"/></inline-formula>. Both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e439" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e440" xlink:type="simple"/></inline-formula> take only values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e441" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e442" xlink:type="simple"/></inline-formula>. The process is completely determined by the transition probabilities and by the condition of stationarity:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e443" xlink:type="simple"/><label>(17)</label></disp-formula></p>
        <p>Furthermore, we assume that only unidirectional causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e444" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e445" xlink:type="simple"/></inline-formula> exist. Accordingly, the transition probabilities can be separated as the product <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e446" xlink:type="simple"/></inline-formula>. In particular, we let the transition probabilities for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e447" xlink:type="simple"/></inline-formula> be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e448" xlink:type="simple"/></inline-formula>, that is, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e449" xlink:type="simple"/></inline-formula> is the probability that the same value is taken at subsequent steps. The transition probabilities for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e450" xlink:type="simple"/></inline-formula> are such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e451" xlink:type="simple"/></inline-formula>, independently of the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e452" xlink:type="simple"/></inline-formula>. Therefore <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e453" xlink:type="simple"/></inline-formula> determines the strength of the connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e454" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e455" xlink:type="simple"/></inline-formula>, and there is a causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e456" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e457" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e458" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e459" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e460" xlink:type="simple"/></inline-formula> takes value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e461" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e462" xlink:type="simple"/></inline-formula> with equal probability and independently of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e463" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e464" xlink:type="simple"/></inline-formula>. In the case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e465" xlink:type="simple"/></inline-formula>, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e466" xlink:type="simple"/></inline-formula> deterministically alternates between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e467" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e468" xlink:type="simple"/></inline-formula>, this example corresponds to one already discussed in Kaiser and Schreiber (2002) <xref ref-type="bibr" rid="pone.0032466-Kaiser1">[46]</xref>. Here we present results for nonzero values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e469" xlink:type="simple"/></inline-formula> with different degree of stochasticity. We calculate the measures using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e470" xlink:type="simple"/></inline-formula> time lags for the past <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e471" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e472" xlink:type="simple"/></inline-formula>, since this is enough for convergence and for higher lags the values obtained do not differ significantly. In fact, given that causal connections are only of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e473" xlink:type="simple"/></inline-formula>, one time lag is enough when conditioning on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e474" xlink:type="simple"/></inline-formula>. However, since in the transfer entropy (Eq. 15) the conditional entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e475" xlink:type="simple"/></inline-formula> appears, where there is no conditioning on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e476" xlink:type="simple"/></inline-formula>, one has to consider all the information about <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e477" xlink:type="simple"/></inline-formula> that exists in the past <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e478" xlink:type="simple"/></inline-formula>.</p>
        <p>First we examine how the transfer entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e479" xlink:type="simple"/></inline-formula> depends on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e480" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e481" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pone-0032466-g004">Figure 4A</xref>). Supporting its use for the inference of causality from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e482" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e483" xlink:type="simple"/></inline-formula>, the transfer entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e484" xlink:type="simple"/></inline-formula> is zero if and only if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e485" xlink:type="simple"/></inline-formula>. In the opposite direction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e486" xlink:type="simple"/></inline-formula> is always zero for this example (results not shown). In the Granger causality approach the transfer entropy is used also as a measure of the strength of the causal connection. From the Figure it is clear that the relation between the coupling parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e487" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e488" xlink:type="simple"/></inline-formula> depends strongly on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e489" xlink:type="simple"/></inline-formula>. In fact, for low values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e490" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e491" xlink:type="simple"/></inline-formula> is nonmonotonic with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e492" xlink:type="simple"/></inline-formula>. In words, the Granger causality measure is nonmonotonic with the parameter that determines the strength of the connection. This can be understood taking into account that transfer entropy quantifies the extra reduction of uncertainty that results from considering the past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e493" xlink:type="simple"/></inline-formula> after considering the past of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e494" xlink:type="simple"/></inline-formula>. For low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e495" xlink:type="simple"/></inline-formula> the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e496" xlink:type="simple"/></inline-formula> are almost deterministic, and thus when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e497" xlink:type="simple"/></inline-formula> increases the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e498" xlink:type="simple"/></inline-formula> become also more and more deterministic. For such, almost deterministic, dynamics the remaining uncertainty of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e499" xlink:type="simple"/></inline-formula> after conditioning on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e500" xlink:type="simple"/></inline-formula> is already very small, and thus the extra reduction given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e501" xlink:type="simple"/></inline-formula> decreases with high <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e502" xlink:type="simple"/></inline-formula>. In fact, for the extreme values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e503" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e504" xlink:type="simple"/></inline-formula> completely deterministic), the nonmonotonicity leads to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e505" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e506" xlink:type="simple"/></inline-formula> -see Figure <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e507" xlink:type="simple"/></inline-formula> in Kaiser and Schreiber (2002) <xref ref-type="bibr" rid="pone.0032466-Kaiser1">[46]</xref>. In such extreme cases transfer entropy cannot be used even to infer causal interactions. In fact, this limitation of transfer entropy in the inference of causality for strongly synchronized systems is well known e.g. <xref ref-type="bibr" rid="pone.0032466-Ay1">[17]</xref>, <xref ref-type="bibr" rid="pone.0032466-Palus1">[47]</xref>, <xref ref-type="bibr" rid="pone.0032466-Lungarella1">[48]</xref>.</p>
        <fig id="pone-0032466-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0032466.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Causality analysis in a binary Markov process.</title>
            <p>Information theoretic measures used for the inference of causality and the analysis of causal effects calculated for a bivariate binary stationary Markov process of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e508" xlink:type="simple"/></inline-formula>. See the text for a description of the process. The measures are calculated analytically using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e509" xlink:type="simple"/></inline-formula> time lags to account for the past <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e510" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e511" xlink:type="simple"/></inline-formula>. The results are shown for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e512" xlink:type="simple"/></inline-formula> (blue), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e513" xlink:type="simple"/></inline-formula> (green), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e514" xlink:type="simple"/></inline-formula> (red), where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e515" xlink:type="simple"/></inline-formula> is the probability that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e516" xlink:type="simple"/></inline-formula>. A: Transfer entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e517" xlink:type="simple"/></inline-formula> (Eq. 15). B: Jensen-Shannon divergence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e518" xlink:type="simple"/></inline-formula> (Eq. 21). C: Jensen-Shannon divergence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e519" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.g004" xlink:type="simple"/>
        </fig>
        <p>In <xref ref-type="fig" rid="pone-0032466-g004">Figure 4B</xref> we show the Jensen-Shannon Divergence (JSD) for distributions of the type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e520" xlink:type="simple"/></inline-formula>. Since there is only unidirectional causality from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e521" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e522" xlink:type="simple"/></inline-formula> this distribution fulfills the criterion of existence for natural causal effects (Eq. 2), and thus the JSD can be used to quantify the changes in the natural causal effects from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e523" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e524" xlink:type="simple"/></inline-formula> when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e525" xlink:type="simple"/></inline-formula> changes. This corresponds to the type of analysis described in relation to Eq. 13. Here the different configurations are identified by the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e526" xlink:type="simple"/></inline-formula>. In particular we take the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e527" xlink:type="simple"/></inline-formula> obtained for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e528" xlink:type="simple"/></inline-formula>, for which there is no causal connection, as a reference to compare the natural causal effects to. Notice that for this Markov process, since by construction there is no causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e529" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e530" xlink:type="simple"/></inline-formula>, we have that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e531" xlink:type="simple"/></inline-formula>. This means that the natural causal effects <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e532" xlink:type="simple"/></inline-formula> correspond to the distribution appearing in the numerator of the logarithm in the definition of the transfer entropy (Eq. 15). What is different with respect to the transfer entropy is the probability distribution used as a reference for comparison. Now the natural causal effects are compared across configurations. We see that the changes in the natural causal effect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e533" xlink:type="simple"/></inline-formula> monotonically increase with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e534" xlink:type="simple"/></inline-formula> and are independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e535" xlink:type="simple"/></inline-formula>. The independence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e536" xlink:type="simple"/></inline-formula> results from the particular generation of the process, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e537" xlink:type="simple"/></inline-formula> independently of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e538" xlink:type="simple"/></inline-formula> and since the causal interactions are of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e539" xlink:type="simple"/></inline-formula> we have that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e540" xlink:type="simple"/></inline-formula>. The monotonic divergence with respect to the distribution obtained for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e541" xlink:type="simple"/></inline-formula> demonstrating that in this case there is a monotonic relation between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e542" xlink:type="simple"/></inline-formula> (the strength of the connection), and the impact of the causal connection (the natural causal effects). This should be contrasted to the results using transfer entropy described above.</p>
        <p>In <xref ref-type="fig" rid="pone-0032466-g004">Figure 4C</xref> we show the Jensen-Shannon divergences for distributions of the type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e543" xlink:type="simple"/></inline-formula> (Eq. 16). In contrast to the probability distributions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e544" xlink:type="simple"/></inline-formula>, these distributions do not represent a natural causal effect that occurs in the dynamics. However, since the change of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e545" xlink:type="simple"/></inline-formula> can be seen in itself as an external intervention of the system, we can compare <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e546" xlink:type="simple"/></inline-formula> in dependence on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e547" xlink:type="simple"/></inline-formula> as a way to quantify the causal effect of this change in the model. As before we take as a reference the distribution obtained for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e548" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e549" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e550" xlink:type="simple"/></inline-formula> increases monotonically with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e551" xlink:type="simple"/></inline-formula> indicating that an increase in the strength of the connection renders the distributions more different. However, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e552" xlink:type="simple"/></inline-formula> a constant zero value is obtained. Importantly, this should not be seen as a limitation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e553" xlink:type="simple"/></inline-formula> to quantify the causal effect, on the contrary it indicates that, with respect to the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e554" xlink:type="simple"/></inline-formula>, the changes in the effective connectivity (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e555" xlink:type="simple"/></inline-formula>) have no effect for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e556" xlink:type="simple"/></inline-formula>. This illustrates how focusing on the value of a coupling parameter may be insufficient in order to describe the impact that a change has in a particular aspect of the dynamics.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In this work we have analyzed the applicability of the cause-and-effect framework to the study of natural dynamics of systems consisting of interacting subsystems. Our main result is that it is generally not possible to characterize the effects of the interactions for each subsystem separately. That is, the effect of causal interactions can typically not be described in terms of the effect of one subsystem over another. Rather, the interactions unifies the subsystems and creates a dynamics that transcends the limits posed by the individual systems. This result is generic in the sense that it only depends on the causal structure (i.e. on the topology of the causal connections) and not on the details of the system under study. Our work suggests that analyzing the effect of interactions in the natural dynamics in terms of cause-and-effect is of limited use, in particular in systems where the functional units tend to be heavily interconnected, such as the brain. We emphasize that our contribution should not be seen as a new method to substitute other approaches to causal analysis. The conditions of existence of natural causal effects indicate that inference of causal connections and analysis of causal influences should be considered different types of analysis with different requirements. When natural causal effects do not exist, they can not be quantified, no matter what measure is used. Our analysis therefore has important implications for all approaches aiming at characterizing the effects of causal interactions in the unperturbed system. We will now discuss our work in more detail and relate it to some previous work in the literature.</p>
      <p>It might be helpful to first interpret our main result in the light of the three questions about causality introduced above. First, the existence of a causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e557" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e558" xlink:type="simple"/></inline-formula> can always be probed. This is possible even if there are causal connections also from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e559" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e560" xlink:type="simple"/></inline-formula>. The ‘traditional’ way to do this is through interventions, that is by actively perturbing the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e561" xlink:type="simple"/></inline-formula> system. We pointed out that, under certain assumptions, Granger causality and DCM can be used to infer existence of causal connections from observational data. Second, the mechanisms by which these causal connections are instantiated can always be probed (at least in principle) by modeling the systems at the appropriate level. We note that interventions could play an important role also in this case. Indeed to constrain and corroborate the models, interventions might be very useful. Third, and this is our main result, the effect of the interactions naturally happening in the system can typically not be described as the effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e562" xlink:type="simple"/></inline-formula> over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e563" xlink:type="simple"/></inline-formula> (or vice versa). Here, and this is a central point, interventions cannot be used (not even in principle) to quantify the effect of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e564" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e565" xlink:type="simple"/></inline-formula> in the natural dynamics, unless they quantify a natural causal effect. Moreover, in this case our work shows the importance of using interventions that mimic the natural dynamics as closely as possible. Our results demonstrate that the quantification of causal interactions is a question separate from the other two questions and that it might not always be well defined.</p>
      <p>Central to our results is the notion of a <italic>natural causal effect</italic>. This should be considered an adaptation of the interventional framework of causality <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref> to the context of dynamically interacting subsystems. Whereas most work in the interventional framework focuses on causal effects resulting from external interventions, to study the unperturbed system we need a notion of causal effects from one subsystem to another related to the natural dynamics. A natural causal effect can be seen as a result of a naturally occurring intervention. In general, in the natural dynamics, different natural interventions of the same type occur with different probability. This led us to define the natural causal effect between variables as the observed joint distribution, and to consider a distribution of natural interventions determined by the marginal distribution of the intervened variable. Furthermore, we pointed out that there is no unique type of natural causal effect that can be used to study the impact of the causal connections between subsystems. Rather the causal structure constitutes a medium in which multiple types of natural causal effects arise.</p>
      <p>The existence of natural causal effects and the maintenance of the natural joint distribution determine when the question about what is the causal effect from one subsystem to another in the natural dynamics is well-defined. This is in contrast to the question about the causal effect of an external intervention of one subsystem on another, which is not constrained by these criteria. We examined when these criteria are fulfilled in the case of two subsystems. We showed that natural causal effects from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e566" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e567" xlink:type="simple"/></inline-formula> are well-defined if unidirectional causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e568" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e569" xlink:type="simple"/></inline-formula> exist, but not in the case of bidirectional causality. Furthermore, our results indicate that some types of conditional natural causal effects exist even if the impact of the causal connections between the subsystems <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e570" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e571" xlink:type="simple"/></inline-formula> cannot be mutually disentangled. This is because they are defined based on an explicit consideration of time locality and are not compatible with the view of subsystems as macroscopic entities. In general the fulfillment of the criterion of existence depends on the causal structure (see <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref>). This means that only under quite restrictive conditions the natural causal effects exist and can be used to characterize the impact of the causal connections from one to another subsystem in the natural dynamics. A detailed analysis of multivariate systems remains for a future contribution but it is clear that the existence of natural causal effects will be even more limited in the case of more than two interacting systems. Notice that this limitation is of a fundamental nature, since it refers to the existence of the natural causal effects in the natural dynamics. This is in contrast to other limitations which are more of a practical nature, like the existence of hidden states for the inference causality <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>, or computational time for model comparison <xref ref-type="bibr" rid="pone.0032466-Lohmann1">[49]</xref>.</p>
      <p>We considered how the most used approaches to study causality in the brain address the three questions about causality and how compatible they are with the concept of natural causal effects. Granger causality should be seen as a criterion to infer the existence of causal connections between processes that is valid under the quite strong conditions of complete observability. However, Granger causality measures, including transfer entropy, cannot be used in general to quantify causal effects. The existence of a particular type of natural causal effects depends on the causal structure, and only when the causal effect exists a measure of its strength can be meaningful. Even when a type of natural causal effects exists and can be used for the characterization of the impact of the causal connection from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e572" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e573" xlink:type="simple"/></inline-formula> it only makes sense to consider the strength of the causal effects when one can compare to a configuration that corresponds to the case of no causality from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e574" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e575" xlink:type="simple"/></inline-formula>.</p>
      <p>We also introduced the idea of analyzing natural causal effects by comparing them across different configurations, i.e. different regimes of the same system (model). This approach was illustrated in a simple example system where the measures could be calculated analytically. Importantly, this type of comparison is not only useful to compare natural causal effects. When the different configurations are related to a change in the causal mechanism, comparing a particular type of probability distribution allows us to examine the impact of this change on the aspect of the dynamics captured by the probability distribution. Accordingly, the analysis of causal effects, which necessarily requires considering the dynamics of the system, complements the usual way in which Dynamic Causal Modeling is used to examine changes in the coupling parameters. The impact of these changes for some aspect of the dynamics is not easy to predict just from the form of the model, as was shown in the example.</p>
      <p>The distinction between on the one hand the inference of causal connections and the modeling of causal mechanisms and on the other hand the analysis of causal effects is tightly related to the distinction between model fitting and model analysis. For example, in DCM it is common practice to fit a model for different configurations (that can correspond to different experimental settings related to different tasks) and then examine the gain in some coupling parameters associated with effective connectivity. Although this structural comparison is a first step for model comparison, this comparison should also involve comparing the dynamics that result from them. When meaningful given the causal structure, one can analyze the natural causal effects from one subsystem to another. More generally, even when it is not possible to disentangle the impact of the causal connections from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e576" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e577" xlink:type="simple"/></inline-formula> from the ones in the opposite direction and thus the subsystems are not separable, still the causal connections determine the generation of the joint dynamics. This means that in general the analysis of the impact of the causal connections cannot be formulated only in terms of causal effects from one part of the system on another, but examining the emergence of some properties of the dynamics. For example, it is well known that causal connections between two intrinsically non-oscillatory units can make them oscillate synchronously (e.g. <xref ref-type="bibr" rid="pone.0032466-Wilson1">[50]</xref>). That is, increasing the coupling leads to a qualitative change in the dynamics.</p>
      <p>A conclusion from our work is that the notion of causal effects between subsystems might not be very useful in neuroscience. Given the ubiquitous existence of feedback and recurrent connections, the criterion for the existence of natural causal effects can hardly be fulfilled when analyzing neural data. Furthermore, it has been widely studied that these connections play important roles determining properties of the dynamics which are functionally relevant e.g. <xref ref-type="bibr" rid="pone.0032466-Sillito1">[25]</xref>, <xref ref-type="bibr" rid="pone.0032466-Sompolinsky1">[51]</xref>. Therefore, the impact of the causal connections in the brain is generally not related to causal effects from one subsystem to another. Even when considering the effect of an external sensory stimulus, which is closer to an external intervention, one is not interested on the impact of this intervention <italic>per se</italic>, but in which way the brain is capable of encoding and decoding the sensory information. This perspective follows the idea suggested by <xref ref-type="bibr" rid="pone.0032466-David1">[52]</xref> that, regarding the neural code and neural computations, statistical dependencies are more relevant than causal effects. In the same line <xref ref-type="bibr" rid="pone.0032466-Lizier1">[43]</xref> illustrated that while a measure of causality based on interventions <xref ref-type="bibr" rid="pone.0032466-Ay1">[17]</xref> can be informative about the causal structure when the transfer entropy provides erroneous information about it, the transfer entropy, as a measure of statistical dependence quantifying the extra reduction in uncertainty when considering the past of the other process, is in general more informative about the computational properties of the system. This means that in fact, when the transfer entropy is used to study causal interactions between brain regions from experimental data e.g. <xref ref-type="bibr" rid="pone.0032466-Brovelli1">[6]</xref>, <xref ref-type="bibr" rid="pone.0032466-Roebroeck1">[38]</xref>–<xref ref-type="bibr" rid="pone.0032466-Vicente1">[42]</xref>, or neural models e.g. <xref ref-type="bibr" rid="pone.0032466-LungarellaM1">[53]</xref>–<xref ref-type="bibr" rid="pone.0032466-Buehlmann1">[55]</xref>, it may be not only more correct but also more useful to interpret this measure not in terms of the strength of causality but as a measure of statistical dependence. Furthermore the transfer entropy is connected to the mutual information rate <xref ref-type="bibr" rid="pone.0032466-Solo1">[56]</xref>, <xref ref-type="bibr" rid="pone.0032466-Chicharro1">[57]</xref> and under some conditions it quantifies information transfer <xref ref-type="bibr" rid="pone.0032466-Lizier1">[43]</xref>.</p>
      <p>Pearl's interventional approach to causality constitutes a unifying framework that relates different approaches to causal analysis like counterfactual analysis <xref ref-type="bibr" rid="pone.0032466-Rubin1">[9]</xref> and structural equation modeling <xref ref-type="bibr" rid="pone.0032466-Wright1">[58]</xref>. However, the consideration of sequential interventions <xref ref-type="bibr" rid="pone.0032466-Robins1">[23]</xref> or time series is less common in the interventional framework. Only recently the link between Granger causality and the effect of interventions has been examined <xref ref-type="bibr" rid="pone.0032466-Eichler3">[24]</xref> in detail. Also for Dynamic Causal Modeling the interpretation of the coefficients in a bilinear model in terms of single external interventions has recently been pointed out <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>. Examining the way in which this general approach is compatible with the aims of studying causal effects between brain subsystems helped us to clarify when it is meaningful to ask for the causal effect from one brain subsystem to another, and to distinguish what type of information this analysis provide us in comparison to the inference of causal connections or the analysis of dynamic statistical dependencies between the subsystems.</p>
      <p>What is new in our approach with respect to the interventional framework is the idea of considering when causal effects occur naturally in a system. This also led us to consider probability distributions of interventions, while Pearl focuses on the analysis of single interventions <xref ref-type="bibr" rid="pone.0032466-Pearl1">[10]</xref>. The novelty of our contribution, based on the proposal of the criteria of the existence of natural causal effects and the maintenance of the natural joint distribution, results from the different aims that the analysis of causal effects between brain regions has with respect to other applications envisaged in the development of interventional causality. In general, in medical research e.g. <xref ref-type="bibr" rid="pone.0032466-Cai1">[59]</xref> or epidemiology <xref ref-type="bibr" rid="pone.0032466-Greenland1">[60]</xref>, one is really interested in assessing the effect of external interventions that alter the system. However this is not in general the case when studying causality in the brain, at least for the type of analysis in which Granger causality or Dynamic Causal Modeling are commonly applied.</p>
      <p>We expect this work to contribute to clarify the aims and potentials of causal analysis applied to study brain dynamics and to complement a recent vivid debate about brain causality <xref ref-type="bibr" rid="pone.0032466-ValdesSosa1">[14]</xref>. Understanding the links between causal structure, causal effects and statistical dependencies is a line of research complementary to the development of more accurate models of brain dynamics <xref ref-type="bibr" rid="pone.0032466-Friston3">[61]</xref>. We have written this paper in the context of neuroscience but the concept of natural causal effects should clearly be useful in other fields where effects of interacting subsystems are of importance.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <p>We used tools from information theory (e.g. <xref ref-type="bibr" rid="pone.0032466-Cover1">[45]</xref>) to characterize the similarity of two probability distributions and the statistical dependencies between variables. The basic quantity is the Kullback-Leibler divergence (KL divergence). The KL divergence is a measure of the difference between two probability distributions and is defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e578" xlink:type="simple"/><label>(18)</label></disp-formula></p>
      <p>An important characteristic of the KL divergence is that it is a non-negative number and is zero if and only if the two distributions are identical. The mutual information<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e579" xlink:type="simple"/><label>(19)</label></disp-formula></p>
      <p>is a particular average of KL divergences<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e580" xlink:type="simple"/><label>(20)</label></disp-formula></p>
      <p>that quantifies the interdependence between the random variables.</p>
      <p>We have considered two examples, one in the main text and one in <xref ref-type="supplementary-material" rid="pone.0032466.s001">Supporting Information S1</xref>. In these examples we calculated KL divergences for some particular distributions resulting from stationary processes for which these measures can be calculated analytically. For the bivariate Markov binary stationary processes we used the Jensen-Shannon divergence (JSD) instead of the KL divergence because it is well defined for probabilities with different domains <xref ref-type="bibr" rid="pone.0032466-Lin1">[62]</xref>. The JSD corresponds to an average of two KL divergences:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e581" xlink:type="simple"/><label>(21)</label></disp-formula></p>
      <p>and is bounded between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e582" xlink:type="simple"/></inline-formula>.</p>
      <p>For the bivariate linear Gaussian stationary processes the KL divergence can be expressed in terms of the mean and covariance matrix of the distributions. This can be derived in analogy to the entropy of a multivariate Gaussian distribution (see Theorem 8.4.1 in <xref ref-type="bibr" rid="pone.0032466-Cover1">[45]</xref>). For two Gaussian distributions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e583" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0032466.e584" xlink:type="simple"/></inline-formula> The KL divergence is:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.e585" xlink:type="simple"/><label>(22)</label></disp-formula></p>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pone.0032466.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pone.0032466.s001" xlink:type="simple">
        <label>Supporting Information S1</label>
        <caption>
          <p>Supporting text.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pone.0032466-Mountcastle1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mountcastle</surname><given-names>VB</given-names></name><name name-style="western"><surname>Davies</surname><given-names>PW</given-names></name><name name-style="western"><surname>Berman</surname><given-names>AL</given-names></name></person-group>             <year>1957</year>             <article-title>Response properties of neurons of cats somatic sensory cortex to peripheral stimuli.</article-title>             <source>J Neurophysiol</source>             <volume>20</volume>             <fpage>374</fpage>             <lpage>407</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Hubel1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name><name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name></person-group>             <year>1959</year>             <article-title>Receptive fields of single neurones in the cats striate cortex.</article-title>             <source>J Physiol</source>             <volume>148</volume>             <fpage>574</fpage>             <lpage>591</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Evarts1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Evarts</surname><given-names>EV</given-names></name></person-group>             <year>1966</year>             <article-title>Pyramidal tract activity associated with a conditioned hand movement in monkey.</article-title>             <source>J Neurophysiol</source>             <volume>29</volume>             <fpage>1011</fpage>             <lpage>1027</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Kaminski1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaminski</surname><given-names>M</given-names></name><name name-style="western"><surname>Blinowska</surname><given-names>K</given-names></name></person-group>             <year>1991</year>             <article-title>A new method of the description of the information flow in the brain structures.</article-title>             <source>Biol Cybern</source>             <volume>65</volume>             <fpage>203</fpage>             <lpage>210</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Kaminski2">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaminski</surname><given-names>M</given-names></name><name name-style="western"><surname>Ding</surname><given-names>M</given-names></name><name name-style="western"><surname>Truccolo</surname><given-names>W</given-names></name><name name-style="western"><surname>Bressler</surname><given-names>S</given-names></name></person-group>             <year>2001</year>             <article-title>Evaluating causal relations in neural systems: Granger causality, directed transfer function and statistical assessment of significance.</article-title>             <source>Biol Cybern</source>             <volume>85</volume>             <fpage>145</fpage>             <lpage>157</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Brovelli1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brovelli</surname><given-names>A</given-names></name><name name-style="western"><surname>Ding</surname><given-names>M</given-names></name><name name-style="western"><surname>Ledberg</surname><given-names>A</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Y</given-names></name><name name-style="western"><surname>Nakamura</surname><given-names>R</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Beta oscillations in a large-scale sensorimotor cortical network: Directional influences revealed by Granger causality.</article-title>             <source>P Natl Acad Sci USA</source>             <volume>101</volume>             <fpage>9849</fpage>             <lpage>9854</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Aertsen1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Aertsen</surname><given-names>AMHJ</given-names></name><name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name><name name-style="western"><surname>Habib</surname><given-names>MK</given-names></name><name name-style="western"><surname>Palm</surname><given-names>G</given-names></name></person-group>             <year>1989</year>             <article-title>Dynamics of neuronal firing correlation: Modulation of “effective connectivity”.</article-title>             <source>J Neurophys</source>             <volume>61</volume>             <fpage>900</fpage>             <lpage>917</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Friston1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>1994</year>             <article-title>Functional and effective connectivity in neuroimaging: A synthesis.</article-title>             <source>Hum Brain Mapp</source>             <volume>2</volume>             <fpage>56</fpage>             <lpage>78</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Rubin1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name></person-group>             <year>1974</year>             <article-title>Estimating causal effects of treatments in randomized and nonrandomized studies.</article-title>             <source>J Educ Psychol</source>             <volume>66</volume>             <fpage>688</fpage>             <lpage>701</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Pearl1">
        <label>10</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Causality: Models, Reasoning, Inference.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Cambridge University Press, 2nd edition</publisher-name>          </element-citation>
      </ref>
      <ref id="pone.0032466-Logothetis1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Logothetis</surname><given-names>N</given-names></name><name name-style="western"><surname>Augath</surname><given-names>M</given-names></name><name name-style="western"><surname>Murayama</surname><given-names>Y</given-names></name><name name-style="western"><surname>Rauch</surname><given-names>A</given-names></name><name name-style="western"><surname>Sultan</surname><given-names>F</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>The effects of electrical microstimulation on cortical signal propagation.</article-title>             <source>Nature Neurosci</source>             <volume>13</volume>             <fpage>1283</fpage>             <lpage>1291</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Daunizeau1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>David</surname><given-names>O</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name></person-group>             <year>2011</year>             <article-title>Dynamic Causal Modelling: A critical review of the biophysical and statistical foundations.</article-title>             <source>NeuroImage</source>             <volume>58</volume>             <fpage>312</fpage>             <lpage>322</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Verma1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Verma</surname><given-names>T</given-names></name><name name-style="western"><surname>J</surname><given-names>P</given-names></name></person-group>             <year>1990</year>             <article-title>Equivalence and synthesis of causal models.</article-title>             <source>Proceedings of the Sixth Conference on Uncertainty in Artifial Intelligence, Cambridge, MA</source>             <fpage>220</fpage>             <lpage>227</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-ValdesSosa1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Valdes-Sosa</surname><given-names>P</given-names></name><name name-style="western"><surname>Roebroeck</surname><given-names>A</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name></person-group>             <year>2011</year>             <article-title>Effective connectivity: Influence, causality and biophysical modeling.</article-title>             <source>Neuroimage</source>             <volume>58</volume>             <fpage>339</fpage>             <lpage>361</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Ko1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ko</surname><given-names>H</given-names></name><name name-style="western"><surname>Hofer</surname><given-names>SB</given-names></name><name name-style="western"><surname>Pichler</surname><given-names>B</given-names></name><name name-style="western"><surname>Buchanan</surname><given-names>KA</given-names></name><name name-style="western"><surname>Sjostrom</surname><given-names>PJ</given-names></name><etal/></person-group>             <year>2011</year>             <article-title>Functional specificity of local synaptic connections in neocortical networks.</article-title>             <source>Nature</source>             <volume>473</volume>             <fpage>87</fpage>             <lpage>91</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Galles1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Galles</surname><given-names>D</given-names></name><name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name></person-group>             <year>1997</year>             <article-title>Axioms of causal relevance.</article-title>             <source>Artificial Intelligence</source>             <volume>97</volume>             <fpage>9</fpage>             <lpage>43</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Ay1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ay</surname><given-names>N</given-names></name><name name-style="western"><surname>Polani</surname><given-names>D</given-names></name></person-group>             <year>2008</year>             <article-title>Information flows in causal networks.</article-title>             <source>Advances in complex systems</source>             <volume>11</volume>             <fpage>17</fpage>             <lpage>41</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Rosenbaum1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rosenbaum</surname><given-names>PR</given-names></name><name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name></person-group>             <year>1983</year>             <article-title>The central role of the propensity score in observational studies for causal effects.</article-title>             <source>Biometrika</source>             <volume>70</volume>             <fpage>41</fpage>             <lpage>55</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Benabid1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Benabid</surname><given-names>AL</given-names></name></person-group>             <year>2003</year>             <article-title>Deep brain stimulation for Parkinson's disease.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>13</volume>             <fpage>696</fpage>             <lpage>706</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Dahlhaus1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dahlhaus</surname><given-names>R</given-names></name></person-group>             <year>2000</year>             <article-title>Graphical interaction models for multivariate time series.</article-title>             <source>Metrika</source>             <volume>51</volume>             <fpage>157</fpage>             <lpage>172</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Eichler1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eichler</surname><given-names>M</given-names></name></person-group>             <year>2005</year>             <article-title>A graphical approach for evaluating effective connectivity in neural systems.</article-title>             <source>Phil Trans R Soc B</source>             <volume>360</volume>             <fpage>953</fpage>             <lpage>967</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Eichler2">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eichler</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>Granger causality and path diagrams for multivariate time series.</article-title>             <source>J Econometrics</source>             <volume>137</volume>             <fpage>334</fpage>             <lpage>353</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Robins1">
        <label>23</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Robins</surname><given-names>J</given-names></name></person-group>             <year>1997</year>             <article-title>Causal inference from complex longitudinal data.</article-title>             <source>Latent variable modeling and applications to causality, Volume 120, Lectures Notes in Statistics, Springer</source>             <fpage>69</fpage>             <lpage>117</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Eichler3">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eichler</surname><given-names>M</given-names></name><name name-style="western"><surname>Didelez</surname><given-names>V</given-names></name></person-group>             <year>2010</year>             <article-title>On Granger causality and the effect of interventions in time series.</article-title>             <source>Lifetime Data Anal</source>             <volume>16</volume>             <fpage>3</fpage>             <lpage>32</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Sillito1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sillito</surname><given-names>A</given-names></name><name name-style="western"><surname>Cudeiro</surname><given-names>J</given-names></name><name name-style="western"><surname>Jones</surname><given-names>H</given-names></name></person-group>             <year>2006</year>             <article-title>Always returning: Feedback and sensory processing in visual cortex and thalamus.</article-title>             <source>Trends Neurosci</source>             <volume>29</volume>          </element-citation>
      </ref>
      <ref id="pone.0032466-Friston2">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>L</given-names></name><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Dynamic Causal Modelling.</article-title>             <source>Neuroimage</source>             <volume>19</volume>             <fpage>1273</fpage>             <lpage>1302</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Granger1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Granger</surname><given-names>CWJ</given-names></name></person-group>             <year>1980</year>             <article-title>Testing for causality : A personal viewpoint.</article-title>             <source>J Econ Dynamics and Control</source>             <volume>2</volume>             <fpage>329</fpage>             <lpage>352</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Granger2">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Granger</surname><given-names>CWJ</given-names></name></person-group>             <year>1969</year>             <article-title>Investigating causal relations by econometric models and cross-spectral methods.</article-title>             <source>Econometrica</source>             <volume>37</volume>             <fpage>424</fpage>             <lpage>38</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Ramsey1">
        <label>29</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ramsey</surname><given-names>J</given-names></name><name name-style="western"><surname>Hanson</surname><given-names>S</given-names></name><name name-style="western"><surname>Hanson</surname><given-names>C</given-names></name><name name-style="western"><surname>Halchenko</surname><given-names>Y</given-names></name><name name-style="western"><surname>Poldrack</surname><given-names>R</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Six problems for causal inference from fMRI.</article-title>             <publisher-name>Neuroimage</publisher-name>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.08.065" xlink:type="simple">10.1016/j.neuroimage.2009.08.065</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0032466-Marko1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Marko</surname><given-names>H</given-names></name></person-group>             <year>1973</year>             <article-title>Bidirectional communication theory - generalization of information-theory.</article-title>             <source>IEEE T Commun</source>             <volume>12</volume>             <fpage>1345</fpage>             <lpage>1351</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Gourieroux1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gourieroux</surname><given-names>C</given-names></name><name name-style="western"><surname>Monfort</surname><given-names>A</given-names></name><name name-style="western"><surname>Renault</surname><given-names>E</given-names></name></person-group>             <year>1987</year>             <article-title>Kullback causality measures.</article-title>             <source>Annales d'Economie et de Statistique</source>             <volume>6-7</volume>             <fpage>470</fpage>             <lpage>410</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Rissanen1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rissanen</surname><given-names>J</given-names></name><name name-style="western"><surname>Wax</surname><given-names>M</given-names></name></person-group>             <year>1987</year>             <article-title>Measures of mutual information and causal dependence between 2 time-series.</article-title>             <source>IEEE Transactions on information theory</source>             <volume>33</volume>             <fpage>598</fpage>             <lpage>601</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Schreiber1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schreiber</surname><given-names>T</given-names></name></person-group>             <year>2000</year>             <article-title>Measuring information transfer.</article-title>             <source>Phys Rev Lett</source>             <volume>85</volume>             <fpage>461</fpage>             <lpage>464</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Amblard1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Amblard</surname><given-names>PO</given-names></name><name name-style="western"><surname>Michel</surname><given-names>O</given-names></name></person-group>             <year>2011</year>             <article-title>On directed information theory and Granger causality graphs.</article-title>             <source>J Comput Neurosci</source>             <volume>30</volume>             <fpage>7</fpage>             <lpage>16</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Chavez1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ch'avez</surname><given-names>M</given-names></name><name name-style="western"><surname>Martinerie</surname><given-names>J</given-names></name><name name-style="western"><surname>Le Van Quyen</surname><given-names>M</given-names></name></person-group>             <year>2003</year>             <article-title>Statistical assessment of nonlinear causality: Application to epileptic EEG signals.</article-title>             <source>J Neurosci Meth</source>             <volume>124</volume>             <fpage>113</fpage>             <lpage>128</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Verdes1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Verdes</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Assessing causality from multivariate time series.</article-title>             <source>Phys Rev E</source>             <volume>72</volume>             <fpage>026222</fpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Granger3">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Granger</surname><given-names>CWJ</given-names></name></person-group>             <year>1963</year>             <article-title>Economic processes involving feedback.</article-title>             <source>Information and Control</source>             <volume>6</volume>             <fpage>28</fpage>             <lpage>48</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Roebroeck1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Roebroeck</surname><given-names>A</given-names></name><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Mapping directed influence over the brain using Granger causality and fMRI.</article-title>             <source>Neuroimage</source>             <volume>25</volume>             <fpage>230</fpage>             <lpage>242</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Bressler1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bressler</surname><given-names>SL</given-names></name><name name-style="western"><surname>Tang</surname><given-names>W</given-names></name><name name-style="western"><surname>Sylvester</surname><given-names>CM</given-names></name><name name-style="western"><surname>Shulman</surname><given-names>GL</given-names></name><name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Top-down control of human visual cortex by frontal and parietal cortex in anticipatory visual spatial attention.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>10056</fpage>             <lpage>10061</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Kayser1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kayser</surname><given-names>C</given-names></name><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name></person-group>             <year>2009</year>             <article-title>Directed interactions between auditory and superior temporal cortices and their role in sensory integration.</article-title>             <source>Frontiers in Integrative Neuroscience 3: article</source>             <volume>7</volume>          </element-citation>
      </ref>
      <ref id="pone.0032466-Besserve1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Besserve</surname><given-names>M</given-names></name><name name-style="western"><surname>Schoelkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name><name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name></person-group>             <year>2010</year>             <article-title>Causal relationships between frequency bands of extracellular signals in visual cortex revealed by an information theoretic analysis.</article-title>             <source>J Comput Neurosci</source>             <volume>29</volume>             <fpage>547</fpage>             <lpage>566</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Vicente1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vicente</surname><given-names>R</given-names></name><name name-style="western"><surname>Wibral</surname><given-names>M</given-names></name><name name-style="western"><surname>Lindner</surname><given-names>M</given-names></name><name name-style="western"><surname>Pipa</surname><given-names>G</given-names></name></person-group>             <year>2010</year>             <article-title>Transfer entropy: A model-free measure of effective connectivity for the neurosciences.</article-title>             <source>J Comput Neurosci</source>             <volume>30</volume>             <fpage>45</fpage>             <lpage>67</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Lizier1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lizier</surname><given-names>JT</given-names></name><name name-style="western"><surname>Prokopenko</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Differentiating information transfer and causal effect.</article-title>             <source>Eur Phys J B</source>             <volume>73</volume>             <fpage>605</fpage>             <lpage>615</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Bressler2">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bressler</surname><given-names>SL</given-names></name><name name-style="western"><surname>Seth</surname><given-names>AK</given-names></name></person-group>             <year>2011</year>             <article-title>Wiener Granger causality: A well established methodology.</article-title>             <source>Neuroimage</source>             <volume>58</volume>             <fpage>323</fpage>             <lpage>329</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Cover1">
        <label>45</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cover</surname><given-names>TM</given-names></name><name name-style="western"><surname>Thomas</surname><given-names>JA</given-names></name></person-group>             <year>2006</year>             <article-title>Elements of Information Theory.</article-title>             <publisher-name>John Wiley and Sons, 2nd edition</publisher-name>          </element-citation>
      </ref>
      <ref id="pone.0032466-Kaiser1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kaiser</surname><given-names>A</given-names></name><name name-style="western"><surname>Schreiber</surname><given-names>T</given-names></name></person-group>             <year>2002</year>             <article-title>Information transfer in continuous processes.</article-title>             <source>Physica D</source>             <volume>166</volume>             <fpage>43</fpage>             <lpage>62</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Palus1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Palus</surname><given-names>M</given-names></name><name name-style="western"><surname>Vejmelka</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>Directionality of coupling from bivariate time series: How to avoid false causalities and missed connections.</article-title>             <source>Phys Rev E</source>             <volume>75</volume>             <fpage>056211</fpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Lungarella1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lungarella</surname><given-names>M</given-names></name><name name-style="western"><surname>Ishiguro</surname><given-names>K</given-names></name><name name-style="western"><surname>Kuniyoshi</surname><given-names>Y</given-names></name><name name-style="western"><surname>Otsu</surname><given-names>N</given-names></name></person-group>             <year>2007</year>             <article-title>Methods for quantifying the causal structure of bivariate time series.</article-title>             <source>Int J Bifurcat Chaos</source>             <volume>17</volume>             <fpage>903</fpage>             <lpage>921</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Lohmann1">
        <label>49</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lohmann</surname><given-names>G</given-names></name><name name-style="western"><surname>Erfurth</surname><given-names>K</given-names></name><name name-style="western"><surname>Müller</surname><given-names>K</given-names></name><name name-style="western"><surname>Turner</surname><given-names>R</given-names></name></person-group>             <year>2011</year>             <article-title>Critical comments on dynamic causal modelling.</article-title>             <publisher-name>Neuroimage</publisher-name>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2011.09.025" xlink:type="simple">10.1016/j.neuroimage.2011.09.025</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0032466-Wilson1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name><name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name></person-group>             <year>1972</year>             <article-title>Excitatory and inhibitory interactions in localized populations of model neurons.</article-title>             <source>Biophys J</source>             <volume>12</volume>             <fpage>1</fpage>             <lpage>24</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Sompolinsky1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name><name name-style="western"><surname>Shapley</surname><given-names>R</given-names></name></person-group>             <year>1997</year>             <article-title>New perspectives on the mechanisms for orientation selectivity.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>7</volume>             <fpage>514</fpage>             <lpage>522</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-David1">
        <label>52</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>David</surname><given-names>O</given-names></name></person-group>             <year>2009</year>             <article-title>fMRI connectivity, meaning and empriscism comments on: The identification of interacting networks in the brain using fMRI: Model selection, causality and deconvolution.</article-title>             <publisher-name>Neuroimage</publisher-name>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.09.073" xlink:type="simple">10.1016/j.neuroimage.2009.09.073</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0032466-LungarellaM1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>LungarellaM</surname></name><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name></person-group>             <year>2006</year>             <article-title>Mapping information flow in sensory motor networks.</article-title>             <source>PLoS Comput Biol</source>             <volume>2</volume>             <fpage>e144</fpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Seth1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Seth</surname><given-names>AK</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>G</given-names></name></person-group>             <year>2007</year>             <article-title>Distinguising causal interactions in neural populations.</article-title>             <source>Neural Comput</source>             <volume>19</volume>             <fpage>910</fpage>             <lpage>933</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Buehlmann1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Buehlmann</surname><given-names>A</given-names></name><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name></person-group>             <year>2010</year>             <article-title>Optimal information transfer in the cortex through synchronization.</article-title>             <source>PLoS Comput Biol</source>             <volume>6</volume>             <fpage>e10000934</fpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Solo1">
        <label>56</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Solo</surname><given-names>V</given-names></name></person-group>             <year>2008</year>             <article-title>On causality and mutual information.</article-title>             <source>Proceedings of the 47th IEEE Conference on Decision and Control</source>             <fpage>4639</fpage>             <lpage>4944</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Chicharro1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chicharro</surname><given-names>D</given-names></name></person-group>             <year>2012</year>             <article-title>On the spectral formulation of Granger causality.</article-title>             <source>Biological Cybernetics</source>             <volume>105</volume>             <fpage>331</fpage>             <lpage>347</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Wright1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>S</given-names></name></person-group>             <year>1921</year>             <article-title>Correlation and causation.</article-title>             <source>J Agric Res</source>             <volume>20</volume>             <fpage>557</fpage>             <lpage>585</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Cai1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cai</surname><given-names>Z</given-names></name><name name-style="western"><surname>M</surname><given-names>K</given-names></name><name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name><name name-style="western"><surname>J</surname><given-names>T</given-names></name></person-group>             <year>2008</year>             <article-title>Bounds on direct effect in the presence of confound intermediate variables.</article-title>             <source>Biometrics</source>             <volume>64</volume>             <fpage>695</fpage>             <lpage>701</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Greenland1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Greenland</surname><given-names>S</given-names></name><name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name><name name-style="western"><surname>Robins</surname><given-names>J</given-names></name></person-group>             <year>1999</year>             <article-title>Causal diagrams for epidemiologic research.</article-title>             <source>Epidemiology</source>             <volume>10</volume>             <fpage>37</fpage>             <lpage>48</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Friston3">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name></person-group>             <year>2010</year>             <article-title>Computational and dynamic models in neuroimaging.</article-title>             <source>Neuroimage</source>             <volume>52</volume>             <fpage>752</fpage>             <lpage>765</lpage>          </element-citation>
      </ref>
      <ref id="pone.0032466-Lin1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>J</given-names></name></person-group>             <year>1991</year>             <article-title>Divergence measures based on the Shannon entropy.</article-title>             <source>IEEE Transactions on Information Theory</source>             <volume>37</volume>             <fpage>145</fpage>             <lpage>151</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>