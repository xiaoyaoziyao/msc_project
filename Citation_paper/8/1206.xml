<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-39278</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0091015</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Biophysics</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Mammography</subject></subj-group></subj-group></subj-group><subj-group><subject>Medical physics</subject></subj-group><subj-group><subject>Oncology</subject><subj-group><subject>Cancer detection and diagnosis</subject><subj-group><subject>Cancer screening</subject></subj-group></subj-group><subj-group><subject>Cancers and neoplasms</subject><subj-group><subject>Breast tumors</subject><subj-group><subject>Breast cancer</subject></subj-group></subj-group></subj-group></subj-group><subj-group><subject>Public and occupational health</subject><subj-group><subject>Health screening</subject></subj-group></subj-group><subj-group><subject>Radiology and imaging</subject></subj-group><subj-group><subject>Women's health</subject><subj-group><subject>Obstetrics and gynecology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Physics</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Automated Breast Image Classification Using Features from Its Discrete Cosine Transform</article-title>
<alt-title alt-title-type="running-head">Breast Image Classification</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kendall</surname><given-names>Edward J.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Flynn</surname><given-names>Matthew T.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Discipline of Radiology, Memorial University of Newfoundland, St. John's, Newfoundland and Labrador, Canada</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Zhan</surname><given-names>Wang</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Maryland, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">edward.kendall@mun.ca</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: EK MF. Performed the experiments: MF. Analyzed the data: EK MF. Contributed reagents/materials/analysis tools: EK. Wrote the paper: EK MF.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>14</day><month>3</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>3</issue>
<elocation-id>e91015</elocation-id>
<history>
<date date-type="received"><day>24</day><month>9</month><year>2013</year></date>
<date date-type="accepted"><day>6</day><month>2</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Kendall, Flynn</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract><sec>
<title>Purpose</title>
<p>This work aimed to improve breast screening program accuracy using automated classification. The goal was to determine if whole image features represented in the discrete cosine transform would provide a basis for classification. Priority was placed on avoiding false negative findings.</p>
</sec><sec>
<title>Methods</title>
<p>Online datasets were used for this work. No informed consent was required. Programs were developed in Mathematica and, where necessary to improve computational performance ported to C++. The use of a discrete cosine transform to separate normal from cancerous breast tissue was tested. Features (moments of the mean) were calculated in square sections of the transform centered on the origin. K-nearest neighbor and naive Bayesian classifiers were tested.</p>
</sec><sec>
<title>Results</title>
<p>Forty-one features were generated and tested singly, and in combination of two or three. Using a k-nearest neighbor classifier, sensitivities as high as 98% with a specificity of 66% were achieved. With a naive Bayesian classifier, sensitivities as high as 100% were achieved with a specificity of 64%.</p>
</sec><sec>
<title>Conclusion</title>
<p>Whole image classification based on discrete cosine transform (DCT) features was effectively implemented with a high level of sensitivity and specificity achieved. The high sensitivity attained using the DCT generated feature set implied that these classifiers could be used in series with other methods to increase specificity. Using a classifier with near 100% sensitivity, such as the one developed in this project, before applying a second classifier could only boost the accuracy of that classifier.</p>
</sec></abstract>
<funding-group><funding-statement>This work was funded in part by the Canadian Breast Cancer Foundation. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. No additional external funding was received for this study.</funding-statement></funding-group><counts><page-count count="8"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Quality control systems have greatly improved the consistency of mammograms and technical advances have shortened exam time without negatively impacting performance <xref ref-type="bibr" rid="pone.0091015-Pisano1">[1]</xref>. The USA screening programs apparently operate at a sensitivity of 84.1% and a specificity of 90.4% <xref ref-type="bibr" rid="pone.0091015-The1">[2]</xref>. Radiologist performance is an important component of program performance and no matter how skilled, reporting physicians will miss some cancers that, in retrospect, were visible in the mammogram <xref ref-type="bibr" rid="pone.0091015-SmithBindman1">[3]</xref>. Physician performance varies widely. One study reported a mean sensitivity of 77% with a range of 29% to 97%. In that study, specificity ranged from 71% to 99% with an average of 90% <xref ref-type="bibr" rid="pone.0091015-SmithBindman1">[3]</xref>. As may be expected, higher specificity and positive predictive value has been shown to correlate with more experience <xref ref-type="bibr" rid="pone.0091015-SmithBindman1">[3]</xref>–<xref ref-type="bibr" rid="pone.0091015-Dromain1">[5]</xref>. Double readings have been shown to significantly increase accuracy <xref ref-type="bibr" rid="pone.0091015-Fenton1">[6]</xref>–<xref ref-type="bibr" rid="pone.0091015-Gilbert1">[9]</xref>. Sickles and colleagues <xref ref-type="bibr" rid="pone.0091015-Sickles1">[10]</xref> reported performance benchmarks based on an analysis of six breast cancer screening registries and more than 600 radiologists. Of particular interest, the abnormal findings rate was 8% and this was associated with a positive predictive value of 31.4%.</p>
<p>Various factors contribute to physician performance. Experience, specialized training and reading volume correlate with better performance <xref ref-type="bibr" rid="pone.0091015-Coldman1">[4]</xref>. Presentation difficulty is correlated with poorer performance, but readers disagree on what is a difficult presentation <xref ref-type="bibr" rid="pone.0091015-Scott1">[11]</xref>. The reasons for screening misses are varied, but in one study the single largest factor was that patent evidence was overlooked <xref ref-type="bibr" rid="pone.0091015-Bird1">[12]</xref>. This may be due to reader fatigue <xref ref-type="bibr" rid="pone.0091015-TaylorPhillips1">[13]</xref>. In addition, there is evidence to suggest that low prevalence predisposes screening radiologists to false negatives <xref ref-type="bibr" rid="pone.0091015-Evans1">[14]</xref>. Prevalence appeared not to influence aggregate performance measures <xref ref-type="bibr" rid="pone.0091015-Gur1">[15]</xref> but did negatively correlate with inter-observer variability <xref ref-type="bibr" rid="pone.0091015-Gur2">[16]</xref> in that readers were more consistent in the clinical than in the laboratory environment. Evans and colleagues further investigated the prevalence effect <xref ref-type="bibr" rid="pone.0091015-Evans1">[14]</xref>.They were interested to learn if prevalence in breast screening resulted in a criterion shift as noted in other situations <xref ref-type="bibr" rid="pone.0091015-Wolfe1">[17]</xref>. They found that false negative rates fell significantly as prevalence increased (12% high versus 30% low). On the other hand, the false positive rate did not differ significantly between the two states. Thus, it appears that increasing the prevalence of disease in the body of reviewed work may improve performance in the key false negative statistic.</p>
<p>A useful approach to improving detection is by enlisting a second reader. This is implemented in many reading centers. Alternatively, computer algorithms have been enlisted as second readers <xref ref-type="bibr" rid="pone.0091015-Jiang1">[8]</xref>, <xref ref-type="bibr" rid="pone.0091015-Gilbert1">[9]</xref>, <xref ref-type="bibr" rid="pone.0091015-Cupples1">[18]</xref>, <xref ref-type="bibr" rid="pone.0091015-Azavedo1">[19]</xref>. The typical computer aided detection (CAD) approach includes a machine learning or training phase followed by pattern recognition and classification phase. When abnormalities are detected, they are marked for the radiologist's review. An inefficiency with this method is that many uninteresting objects may be marked, potentially reducing the specificity and increasing the time required for review <xref ref-type="bibr" rid="pone.0091015-Dromain1">[5]</xref>, <xref ref-type="bibr" rid="pone.0091015-Sato1">[20]</xref>–<xref ref-type="bibr" rid="pone.0091015-Houssami2">[22]</xref>. As a consequence, an increase in sensitivity may be accompanied by a decrease in specificity <xref ref-type="bibr" rid="pone.0091015-Dromain1">[5]</xref>, <xref ref-type="bibr" rid="pone.0091015-Gur3">[23]</xref>.</p>
<p>An alternate approach to improving the efficiency of screening programs by pre-selecting higher likelihood cases has been reported <xref ref-type="bibr" rid="pone.0091015-Liu1">[24]</xref>–<xref ref-type="bibr" rid="pone.0091015-Kendall1">[26]</xref>. Mammograms were transformed and filtered using a variety of wavelets. Features extracted from the resulting maps were used to remove low risk cases from further consideration. In one report this method provided near perfect sensitivity with greater than 60% specificity <xref ref-type="bibr" rid="pone.0091015-Kendall1">[26]</xref>. We postulated that discriminate use of the discrete cosine transform might provide useful classification features to identify normal mammograms.</p>
<p>This work was undertaken to improve breast screening program accuracy using automated classification. The goal was to determine if whole image features represented in the transform would provide a basis for binary classification, normal or suspicious. The overall approach taken consisted of four sequential steps. 1. Preprocessing, in which images were prepared by removing useless information and standardizing size, resolution, and bit depth. 2. Transformation- Images were cosine transformed to arrange image data by spatial frequency in two dimensions. 3. Feature extraction- A small group of values were calculated from the transform for each image. 4. Classification- Machine learning was used to classify images by comparing them with images of known pathology. The output would be two pools, one containing normal and the other suspicious images. If successful the pool containing suspicious images would be enriched in cancer positive cases and subsequent interpretation achieve a lower false negative rate.</p>
</sec><sec id="s2" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>Programs for this work were developed in Mathematica version 8.0. Input data was obtained from two publicly available mammographic image databases. The Digital Database for Screening Mammography (DDSM) <xref ref-type="bibr" rid="pone.0091015-Heath1">[27]</xref>, <xref ref-type="bibr" rid="pone.0091015-Heath2">[28]</xref> and the Mammographic Image Analysis Society (MIAS) databases <xref ref-type="bibr" rid="pone.0091015-Suckling1">[29]</xref>. Both included “ground truth” data that describes the type and location of abnormalities present in the images. Images were extracted, rescaled to 200 μm resolution and padded or cropped to 1024<sup>2</sup> pixels.</p>
<p>The subset of the MIAS database used in this study consisted of 205 normal, 54 benign cases and 41 malignant cases all in the mediolateral oblique (MLO) view. The DDSM medial lateral oblique (MLO) view data subset consisted of 269 normal, 70 suspicious (5 benign cases and 65 malignant) cases and the DDSM cranio-caudal (CC) view data subset contained 278 normal, 73 suspicious (5 benign cases and 68 malignant) cases.</p>
<p>Artifacts such as orientation tags were removed using a large-bright-object binary mask based on peak separation in the intensity histogram. Half-mean or mean value provided the best discrimination. The Hadamard product of the mask and the original image produced an image containing only the relevant breast tissue.</p>
<p>Frequency space maps were generated using the discrete cosine transform. In these, data were partitioned into L-shaped blocks, each twice the width of the proceeding block. The DC coefficient and the mean, standard deviation, skewness, and kurtosis determined for each of the ten blocks in the map, provided 41 features per map.</p>
<p>Two classification approaches were tested, k-nearest neighbor (KNN) and naive Bayesian.</p>
<sec id="s2a">
<title>K-nearest neighbor</title>
<p>The twenty-five closest neighbors to each image feature were stored in the database as was their ordering and their fractional distance (d/d<sub>max</sub>). Combinations of two and three features were also tested.</p>
<p>Vote taking was used to determine classification. Votes were unweighted or weighted according to distance and/or prior probability. The algorithm was tested for between 1 and 25 calculated neighbors for each test image using the leave-one-out cross validation. The classification was found by adding the values assigned to the first k neighbors for each image. Suspicious images were assigned a vote value of +1 (x weighting) and normal images were assigned a vote value of −1 (x weighting). Adding the votes resulted in a value greater than or equal to zero if the consensus was suspicious and less than zero if normal.</p>
<p>Twelve variations of the classifier were calculated. For each variation, and each number of neighbors, the feature vector with the highest sensitivity was selected and recorded along with its specificity.</p>
</sec><sec id="s2b">
<title>Naive Bayesian classifier</title>
<p>For the naive Bayesian classifier, the program ran in two stages. First, posterior probabilities for all forty-one features were calculated. Next, these were compared with truth-data to determine the sensitivity and specificity of each feature.</p>
<p>Identically binned feature-histograms for normal and suspicious images were established. These were populated with the images according to their feature value. The number of normal and suspicious images in each bin provided the probability value for that feature value. Next each image feature was tested using leave-one-out cross validation.</p>
<p>The likelihood that the test image was suspicious (or normal) was calculated as likelihood<sub>suspicious</sub>  =  (suspicious counts)/(total suspicious).</p>
<p>Posterior probabilities (PP) were calculated as the likelihoods (suspicious or normal) multiplied by the corresponding prior probabilities. Suspicious posterior probability was normalized to the sum of the normal and suspicious posterior probability. The normalized posterior probability that an image was suspicious was then added to the database.</p>
<p>The whole process was repeated for all images in the set, for each feature and using between two and 20 bins. This process was repeated using combinations of two and three features (820 and 10660 possible combinations). For each additional feature added, separate histograms were generated and likelihoods calculated.</p>
<p>Once the database was populated with probabilities for each image for every possible combination of one, two, and three features, then sensitivity and specificity were calculated. In order to determine if an image was deemed suspicious, a certain suspicious-threshold probability had to be chosen, above which the image would be classified as suspicious. Since the classifications of images in the training set were known and all posterior probabilities were calculated, thresholds were chosen based on this data.</p>
<p>For 100% sensitivity, the lowest probability of a suspicious image being suspicious was used as the threshold. Specificity was then incrementally increased by using the second lowest probability of a suspicious image being suspicious as the threshold. Sensitivity and specificity were calculated for various threshold values in order to generate ROC data for each experimental setup. Optimal setup parameters were determined using the single feature classifier.</p>
<p>Statistical comparisons were performed for ROC curves following the methods of Delong <xref ref-type="bibr" rid="pone.0091015-Delong1">[30]</xref>. Paired and unpaired t-tests were performed as appropriate.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<p>Two classification engines were examined, k-nearest neighbor and Bayesian. In both cases, various conditions were investigated to determine each engine's optimal performance. This data is reported in the following sections.</p>
<sec id="s3a">
<title>k-nearest neighbor</title>
<sec id="s3a1">
<title>Determining the best features</title>
<p>Testing the MIAS, DDSM MLO and DDSM CC datasets using single feature classifiers for between 1 and 25 neighbors took on the order of minutes for each set. For each of the 12 variants of the classifier, the most sensitive feature or feature set was recorded with its corresponding specificity (not shown). For MIAS the three best features (sensitivity values in brackets) were block 2 skewness (16.8%), block 2 kurtosis (21.9%), and block 1 standard deviation (39.4%). For DDSM MLO the three best features were block 3 skewness (19.1%), block 4 mean (26.7%), and block 2 standard deviation (42.0%). For DDSM CC the three best features were block 6 kurtosis (10.8%), block 1 kurtosis (21.9%), and block 3 skewness (69.1%). In each trial using a combination of three features provided the best results.</p>
</sec><sec id="s3a2">
<title>Trial 1: Unweighted majority voting</title>
<p>The first variant of the k-nearest neighbor classifier assigned all votes an identical weight. For each data set, the best sensitivity was found using two neighbors and three features (<xref ref-type="table" rid="pone-0091015-t001">Table 1</xref>). This configuration achieved 69.5% sensitivity and 51.7% specificity for MIAS, 82.9% sensitivity and 78.8% specificity for DDSM MLO and 83.6% sensitivity and 80.9% specificity for DDSM CC. The positive predictive value (PPV) ranged from 35 to 52% and the negative predictive value (NPV) from 78 to 95% (<xref ref-type="table" rid="pone-0091015-t001">Table 1</xref>). This classifier trended toward higher specificity and lower sensitivity (<xref ref-type="fig" rid="pone-0091015-g001">Figure 1</xref>) as the number of neighbors included increased.</p>
<fig id="pone-0091015-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.g001</object-id><label>Figure 1</label><caption>
<title>Unweighted KNN classifier.</title>
<p>Sensitivity (Sen, solid lines) and specificity (Sp, dashed lines) versus Number of Neighbors for all three datasets. MIAS (red), DDSM MLO (green), DDSM CC (black).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.g001" position="float" xlink:type="simple"/></fig><table-wrap id="pone-0091015-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.t001</object-id><label>Table 1</label><caption>
<title>KNN classifier performance.</title>
</caption><alternatives><graphic id="pone-0091015-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Data</td>
<td align="left" rowspan="1" colspan="1">No. of Neighbors</td>
<td align="left" rowspan="1" colspan="1">Distance weighting</td>
<td align="left" rowspan="1" colspan="1">Prior Probability Weighting</td>
<td align="left" rowspan="1" colspan="1">Sensitivity (%)</td>
<td align="left" rowspan="1" colspan="1">Specificity (%)</td>
<td align="left" rowspan="1" colspan="1">PPV</td>
<td align="left" rowspan="1" colspan="1">NPV</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">69.5</td>
<td align="left" rowspan="1" colspan="1">51.7</td>
<td align="left" rowspan="1" colspan="1">0.40</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">82.9</td>
<td align="left" rowspan="1" colspan="1">78.8</td>
<td align="left" rowspan="1" colspan="1">0.35</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">83.6</td>
<td align="left" rowspan="1" colspan="1">80.9</td>
<td align="left" rowspan="1" colspan="1">0.52</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">1 or 2</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">51.6</td>
<td align="left" rowspan="1" colspan="1">72.2</td>
<td align="left" rowspan="1" colspan="1">0.47</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">65.7</td>
<td align="left" rowspan="1" colspan="1">85.1</td>
<td align="left" rowspan="1" colspan="1">0.53</td>
<td align="left" rowspan="1" colspan="1">0.91</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">61.6</td>
<td align="left" rowspan="1" colspan="1">89.6</td>
<td align="left" rowspan="1" colspan="1">0.61</td>
<td align="left" rowspan="1" colspan="1">0.90</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">83.2</td>
<td align="left" rowspan="1" colspan="1">34.6</td>
<td align="left" rowspan="1" colspan="1">0.37</td>
<td align="left" rowspan="1" colspan="1">0.81</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">13</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">98.6</td>
<td align="left" rowspan="1" colspan="1">63.2</td>
<td align="left" rowspan="1" colspan="1">0.41</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">23</td>
<td align="left" rowspan="1" colspan="1">N</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">98.6</td>
<td align="left" rowspan="1" colspan="1">75.2</td>
<td align="left" rowspan="1" colspan="1">0.51</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">69.5</td>
<td align="left" rowspan="1" colspan="1">52.5</td>
<td align="left" rowspan="1" colspan="1">0.41</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">98.6</td>
<td align="left" rowspan="1" colspan="1">65.7</td>
<td align="left" rowspan="1" colspan="1">0.43</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">Y</td>
<td align="left" rowspan="1" colspan="1">97.3</td>
<td align="left" rowspan="1" colspan="1">75.9</td>
<td align="left" rowspan="1" colspan="1">0.51</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Note. The factors were tested using the best three features for each dataset.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3a3">
<title>Trial 2: Distance weighted votes</title>
<p>Using votes weighted by distance, the best sensitivities were found using three features (<xref ref-type="table" rid="pone-0091015-t001">Table 1</xref>). For the MIAS set, the highest sensitivity was 51.6% with 72.2% specificity. For the DDSM MLO set, the best performance was 65.7% sensitivity and 85.1% specificity for 3 neighbors. For the DDSM CC set, the best performance obtained was 61.6% sensitivity and 89.6% specificity for 5 neighbors. This classifier achieved a PPV ranging from 47 to 51% and an NPV ranging from 76 to 91%. With more neighbors, the sensitivity and specificity diverge further, with the effect most pronounced in the MIAS set (<xref ref-type="fig" rid="pone-0091015-g002">Figure 2</xref>).</p>
<fig id="pone-0091015-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.g002</object-id><label>Figure 2</label><caption>
<title>Distance weighted KNN classifier.</title>
<p>Sensitivity (Sen, solid lines) and specificity (Sp, dashed lines) versus Number of Neighbors for all three datasets. MIAS (red), DDSM MLO (green), DDSM CC (black).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.g002" position="float" xlink:type="simple"/></fig></sec><sec id="s3a4">
<title>Trial 3: Prior probability weighted votes</title>
<p>With votes adjusted for the prior probabilities (<xref ref-type="table" rid="pone-0091015-t001">Table 1</xref>). For MIAS the highest was 92.7% sensitivity and 39.0% specificity with 6 neighbors. For DDSM MLO the highest was 98.6% sensitivity and 63.2% specificity with 13 neighbors. For DDSM CC the highest was 98.6% sensitivity and 75.2% specificity with 23 neighbors. The classifier achieved a PPV range from 37 to 51% amd an NPV range from 81 to 100%. Unlike the first two classifiers, this one favored sensitivity over specificity (<xref ref-type="fig" rid="pone-0091015-g003">Figure 3</xref>).</p>
<fig id="pone-0091015-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.g003</object-id><label>Figure 3</label><caption>
<title>Prior probability weighted KNN classifier.</title>
<p>Sensitivity (Sen, solid lines) and specificity (Sp, dashed lines) versus Number of Neighbors for all three datasets. MIAS (red), DDSM MLO (green), DDSM CC (black).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.g003" position="float" xlink:type="simple"/></fig></sec><sec id="s3a5">
<title>Trial 4: Distance weighted and prior adjusted voting</title>
<p>When using both distance weighting and prior probabilities, the best classifiers used three features (<xref ref-type="table" rid="pone-0091015-t001">Table 1</xref>). For MIAS the highest was 85.4% sensitivity and 55.1% specificity with 24 neighbors. For DDSM MLO, the highest was 98.6% sensitivity and 65.7% specificity with 15 neighbors. For DDSM CC, the highest was 97.3% sensitivity and 75.9% specificity with 12 neighbors. The classifier provided a PPV range of 41 to 51% and an NPV range of 79 to 99%. Weighting by neighbor distance, did not have a significant positive effect on the performance of the classifiers.</p>
</sec></sec><sec id="s3b">
<title>Bayesian classification</title>
<p>The naive Bayesian classifier was tested for all data sets using 1, 2 and 3 features and 2 to 25 histogram bins. The classification histograms were optimized at 12 bins for MIAS and DDSM MLO and 13 bins for the DDSM CC data. Thresholds were adjusted to generate ROC curves.</p>
</sec><sec id="s3c">
<title>Best performing features at 100% sensitivity</title>
<p>For the MIAS data set, the best performing features were: block 3 kurtosis, for one feature classifiers, DC offset and block 3 kurtosis for two feature classifiers, and DC offset, block 1 skewness and block three kurtosis for three feature classifiers.</p>
<p>For the DDSM MLO data set, the best performing features were block 4 mean for one feature classifiers, block 4 mean and block 3 skewness for two feature classifiers, and block 2 standard deviation, block 2 skewness, and block 3 skewness for three feature classifiers.</p>
<p>Finally, for the DDSM CC data set, the best performing features were: block 2 standard deviation for one feature classifiers, block 2 standard deviation and block 3 skewness for two feature classifiers, and block 4 mean, block 2 standard deviation, and block 3 skewness for three feature classifiers.</p>
</sec><sec id="s3d">
<title>Feature vector size</title>
<p><xref ref-type="fig" rid="pone-0091015-g004">Figure 4</xref> shows the specificity achieved for each of the data sets using one, two, or three features. Two feature classifiers performed better than one, and generally three feature classifiers performed better than two. However, there were diminishing gains with the third added feature.</p>
<fig id="pone-0091015-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.g004</object-id><label>Figure 4</label><caption>
<title>Effect of feature vector size on Bayesian classifier performance.</title>
<p>Specificity versus sensitivity for all datasets. One (light grey), two (medium grey) or three (dark grey) feature combinations were tested at three sensitivity levels.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.g004" position="float" xlink:type="simple"/></fig>
<p>Using a Bayesian classification scheme permits adjusting its performance on the training set. When the sensitivity was adjusted (97–98%) to allow a few false negative images, specificity increased by 2 percentage points for MIAS, 9 percentage points for MLO and 15 percentage points for the CC data set (<xref ref-type="table" rid="pone-0091015-t002">Table 2</xref>). The PPV for MIAS did not change but that of MLO increased by 7 percentage points and that of CC increased by 11 percentage points. The NPV declined by 4 percentage points for MIAS and 1 percentage point for MLO and CC data sets. After classification, the MIAS suspicious data sets had a 15% increased disease prevalence and disease doubled in the MLO and CC data sets.</p>
<table-wrap id="pone-0091015-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.t002</object-id><label>Table 2</label><caption>
<title>Bayesian classifier performance<xref ref-type="table-fn" rid="nt102">a</xref>.</title>
</caption><alternatives><graphic id="pone-0091015-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Data</td>
<td align="left" rowspan="1" colspan="1">Sensitivity (%)</td>
<td align="left" rowspan="1" colspan="1">Specificity (%)</td>
<td align="left" rowspan="1" colspan="1">PPV</td>
<td align="left" rowspan="1" colspan="1">NPV</td>
<td align="left" rowspan="1" colspan="1">Prevalence Gain<xref ref-type="table-fn" rid="nt103">b</xref></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">0.19</td>
<td align="left" rowspan="1" colspan="1">0.37</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">1.15</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">0.20</td>
<td align="left" rowspan="1" colspan="1">0.37</td>
<td align="left" rowspan="1" colspan="1">0.98</td>
<td align="left" rowspan="1" colspan="1">1.15</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS</td>
<td align="left" rowspan="1" colspan="1">0.98</td>
<td align="left" rowspan="1" colspan="1">0.21</td>
<td align="left" rowspan="1" colspan="1">0.37</td>
<td align="left" rowspan="1" colspan="1">0.96</td>
<td align="left" rowspan="1" colspan="1">1.16</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">0.64</td>
<td align="left" rowspan="1" colspan="1">0.42</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">2.04</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">0.72</td>
<td align="left" rowspan="1" colspan="1">0.48</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">2.32</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (MLO)</td>
<td align="left" rowspan="1" colspan="1">0.97</td>
<td align="left" rowspan="1" colspan="1">0.73</td>
<td align="left" rowspan="1" colspan="1">0.49</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">2.35</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">0.62</td>
<td align="left" rowspan="1" colspan="1">0.41</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">1.97</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.52</td>
<td align="left" rowspan="1" colspan="1">1.00</td>
<td align="left" rowspan="1" colspan="1">2.51</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM (CC)</td>
<td align="left" rowspan="1" colspan="1">0.97</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">0.53</td>
<td align="left" rowspan="1" colspan="1">0.99</td>
<td align="left" rowspan="1" colspan="1">2.54</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt102"><label>a</label><p>Classification was performed using the best three features for each dataset.</p></fn><fn id="nt103"><label>b</label><p>Prevalence gain  = TP/(TP+FP)<sub>c</sub>/TP/(TP+FP)<sub>o</sub> is the fractional increase of truly positive images in the suspicious classification.</p></fn></table-wrap-foot></table-wrap><sec id="s3d1">
<title>Overall accuracy</title>
<p>The best classified data sets were the DDSM MLO and DDSM CC. They performed far better than the smaller MIAS set.</p>
<p>Receiver operating characteristic (ROC) curves were calculated for all the datasets using one, two or three features. In all cases classification was better than random. <xref ref-type="fig" rid="pone-0091015-g005">Figure 5</xref> provides the results when three features were used in the classification. The number of features used in classification did not significantly alter the ROC response within each dataset (<xref ref-type="table" rid="pone-0091015-t003">Table 3</xref>). The MIAS set produced the poorest performance (<xref ref-type="fig" rid="pone-0091015-g005">Figure 5</xref>). The DDSM MLO and CC datasets offered better classification and did not differ significantly from each other (<xref ref-type="table" rid="pone-0091015-t003">Table 3</xref>). The MIAS performance differed significantly from that of the other two datasets (<xref ref-type="table" rid="pone-0091015-t003">Table 3</xref>).</p>
<fig id="pone-0091015-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.g005</object-id><label>Figure 5</label><caption>
<title>Bayesian three feature classifier performance.</title>
<p>Sensitivity versus 1-specificity. The performance of the classifier was tested on MIAS (red), DDSM CC (blue and DDSM MLO (black) datasets. as was the case for one and two features the algorithm performed much better on the CC and MLO datasets.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.g005" position="float" xlink:type="simple"/></fig><table-wrap id="pone-0091015-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0091015.t003</object-id><label>Table 3</label><caption>
<title>Bayesian Classifier Performance.</title>
</caption><alternatives><graphic id="pone-0091015-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0091015.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">MIAS-1<xref ref-type="table-fn" rid="nt105">a</xref></td>
<td align="left" rowspan="1" colspan="1">MIAS-2</td>
<td align="left" rowspan="1" colspan="1">MIAS-3</td>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-1</td>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-2</td>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-3</td>
<td align="left" rowspan="1" colspan="1">DDSM-CC-1</td>
<td align="left" rowspan="1" colspan="1">DDSM-CC-2</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS-2</td>
<td align="left" rowspan="1" colspan="1">−1.10<xref ref-type="table-fn" rid="nt106">b</xref></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MIAS-3</td>
<td align="left" rowspan="1" colspan="1">−1.07</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-1</td>
<td align="left" rowspan="1" colspan="1">−5.74</td>
<td align="left" rowspan="1" colspan="1">−4.60</td>
<td align="left" rowspan="1" colspan="1">−4.64</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-2</td>
<td align="left" rowspan="1" colspan="1">−6.92</td>
<td align="left" rowspan="1" colspan="1">−5.74</td>
<td align="left" rowspan="1" colspan="1">−5.78</td>
<td align="left" rowspan="1" colspan="1">−1.01</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-MLO-3</td>
<td align="left" rowspan="1" colspan="1">−7.46</td>
<td align="left" rowspan="1" colspan="1">−6.27</td>
<td align="left" rowspan="1" colspan="1">−10.03</td>
<td align="left" rowspan="1" colspan="1">−1.47</td>
<td align="left" rowspan="1" colspan="1">−0.47</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-CC-1</td>
<td align="left" rowspan="1" colspan="1">−6.06</td>
<td align="left" rowspan="1" colspan="1">−10.07</td>
<td align="left" rowspan="1" colspan="1">−4.95</td>
<td align="left" rowspan="1" colspan="1">−0.25</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">1.24</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-CC-2</td>
<td align="left" rowspan="1" colspan="1">−6.92</td>
<td align="left" rowspan="1" colspan="1">−5.74</td>
<td align="left" rowspan="1" colspan="1">−5.78</td>
<td align="left" rowspan="1" colspan="1">−0.99</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">0.50</td>
<td align="left" rowspan="1" colspan="1">−0.75</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">DDSM-CC-3</td>
<td align="left" rowspan="1" colspan="1">−7.38</td>
<td align="left" rowspan="1" colspan="1">−6.18</td>
<td align="left" rowspan="1" colspan="1">−6.22</td>
<td align="left" rowspan="1" colspan="1">−1.38</td>
<td align="left" rowspan="1" colspan="1">−0.37</td>
<td align="left" rowspan="1" colspan="1">0.10</td>
<td align="left" rowspan="1" colspan="1">−1.14</td>
<td align="left" rowspan="1" colspan="1">−0.40</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt104"><label/><p>Comparison of ROC curves.</p></fn><fn id="nt105"><label>a</label><p>1,2 and 3 refer to the number of features used in the classification.</p></fn><fn id="nt106"><label>b</label><p>the t-statistic was calculated using the method described by Delong and colleagues (20). Values less than1.96 indicate no significant difference in the comparison.</p></fn></table-wrap-foot></table-wrap>
<p>At 100% sensitivity, for DDSM MLO with a three feature classifier, 64.3% specificity was obtained. In other words 173 normal images may be removed from the set of 339 images.</p>
</sec></sec></sec><sec id="s4">
<title>Discussion</title>
<p>The ability of features derived from a discrete cosine transform (DCT) of mammograms to distinguish normal from suspicious breast images was tested in three datasets.</p>
<p>The algorithms were adjusted to get the best possible accuracy for MIAS (sensitivity of 100% and a specificity of 19.0%). When the DDSM MLO set was introduced, using the exact same algorithm, there was a substantially better performance (sensitivity of 100% and a specificity of 64.3%). Since the DDSM subset used here was only slightly larger than the MIAS, size probably did not have a significant impact. However, the datasets were qualitatively different. In the MIAS set, 60 of the 95 suspicious images were benign, whereas in the DDSM set only 5 of the 70 suspicious images were benign. Furthermore, all five of those benign findings were contralateral to a malignant image. In a separate experiment a new data set will be created to determine if the benign findings rate degrades the separation of normal from suspicious images.</p>
<p>Choosing the best classifier is often an arbitrary exercise <xref ref-type="bibr" rid="pone.0091015-Dromain1">[5]</xref>. Here, since a false negative might have severe health repercussions, features and classifiers with the highest sensitivities were chosen as “best”. Choosing classifiers with the highest sensitivity provided a consistent basis of comparison.</p>
<p>In this study neither the KNN nor the naive Bayesian classifiers emerged as superior under all conditions. However, the naive Bayesian classifier had some favorable characteristics. For example, as an eager learner, it had a more efficient operational phase. Since all that needed to be taken from the training phase were two histograms per feature, storage requirements were low. In addition, computational requirements for classification were low. The k-nearest neighbor classifier on the other hand required the feature values and classifications for all images in the training set to be saved, requiring more storage. Classification of each new image required comparison to every image in the training set before votes could be tabulated.</p>
<p>The naive Bayesian classifier is also quite flexible. The threshold of what to consider normal and what to consider suspicious can be changed without having to retrain the classifier. This allows the selection of how much emphasis to place on sensitivity and how much to trade off for increased specificity. An adjustable KNN classifier could be developed by changing the weighting assigned to suspicious and normal neighbor votes. As seen for the prior adjusted results though, this produces some odd behavior in the classifier depending on the number of neighbors used (<xref ref-type="fig" rid="pone-0091015-g001">Figures 1</xref>–<xref ref-type="fig" rid="pone-0091015-g003">3</xref>).</p>
<p>The classifiers used no more than three features. Despite this small feature vector size, the results were still quite accurate. Using such a small number of features ensured that over training would not be an issue. The consistent high performance of these features for different data sets and different classification algorithms suggests that the high classification rates are due more to the features themselves than to the classifiers or to random chance.</p>
<p>The high sensitivity attained using the DCT generated feature set means that one of the classifiers developed in this project could be used in series with other computer aided detection methods to increase overall accuracy <xref ref-type="bibr" rid="pone.0091015-Oliver1">[31]</xref>. Using a classifier with near 100% sensitivity, such as the one developed in this project, before applying a second independent classifier may boost the overall accuracy. At 100% sensitivity, no suspicious images are lost, while some (64% in the case of naive Bayesian classification of DDSM MLO) of the normal images can be removed to a separate low priority processing queue. In the high priority queue, the second classifier is given a smaller group of images that are more likely to be suspicious.</p>
<p>It appears that the DCT feature based classifiers performance is in the useful range <xref ref-type="bibr" rid="pone.0091015-Sickles1">[10]</xref>. Sickles and colleagues have provided reference values to compare the performance of mammographic stations <xref ref-type="bibr" rid="pone.0091015-Sickles1">[10]</xref>. If we assume that their published PPV mean values have a normal distribution, the performance of the KNN and Bayesian classifiers here is significantly better than these benchmarks.</p>
<p>This classifiers had two outputs, one that contained only normal images and the other contained normal and suspicious images. The algorithm allows selection of a sensitivity threshold. Disease prevalence in output one can be zero or can be detuned to allow false negatives. In the first instance, all of the suspicious images are in output two. If this output was referred to a mammographer the performance obtained may approximate that described by Evans and colleagues <xref ref-type="bibr" rid="pone.0091015-Evans1">[14]</xref>. They claim that interpretation performance improves when disease incidence increases. At the very least, triaging the exams into high an low priority streams may reduce reader fatigue, a factor thought to contribute to false negative findings<xref ref-type="bibr" rid="pone.0091015-TaylorPhillips1">[13]</xref>. Investigations are underway to determine the extent of enrichment possible in a contemporary clinical setting and if that enrichment results in a lower false negative rate.</p>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0091015-Pisano1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Pisano ED, Cole E, Hemminger BM, Muller K, Shumak R, <etal>et al</etal>.. (2001) Accuracy of digital mammography vs. screen-film mammography in a diagnostic mammography population. Iwdm 2000: 5th International Workshop on Digital Mammography: 504–511.</mixed-citation>
</ref>
<ref id="pone.0091015-The1"><label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">The Breast Cancer Surveillance Consortium (2005) NCI-funded Breast Cancer Surveillance Consortium co-operative agreement (U01CA63740 UC, U01CA86082, U01CA63736, U01CA70013, U01CA69976, U01CA63731, U01CA70040). Available: <ext-link ext-link-type="uri" xlink:href="http://breastscreening.cancer.gov/data/benchmarks/screening/2009/tableSensSpec.html" xlink:type="simple">http://breastscreening.cancer.gov/data/benchmarks/screening/2009/tableSensSpec.html</ext-link>. Accessed 2013 Aug 27.</mixed-citation>
</ref>
<ref id="pone.0091015-SmithBindman1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith-Bindman</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Chu</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Miglioretti</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Quale</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rosenberg</surname><given-names>RD</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Physician predictors of mammographic accuracy</article-title>. <source>Journal of the National Cancer Institute</source> <volume>97</volume>: <fpage>358</fpage>–<lpage>367</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Coldman1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coldman</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Major</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Doyle</surname><given-names>GP</given-names></name>, <name name-style="western"><surname>D'yachkova</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Phillips</surname><given-names>N</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Organized Breast Screening Programs in Canada: Effect of Radiologist Reading Volumes on Outcomes1</article-title>. <source>Radiology</source> <volume>238</volume>: <fpage>809</fpage>–<lpage>815</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Dromain1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dromain</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Boyer</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Ferre</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Canale</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Delaloge</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Computed-aided diagnosis (CAD) in the detection of breast cancer</article-title>. <source>European Journal of Radiology</source> <volume>82</volume>: <fpage>417</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Fenton1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fenton</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Abraham</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Taplin</surname><given-names>SH</given-names></name>, <name name-style="western"><surname>Geller</surname><given-names>BM</given-names></name>, <name name-style="western"><surname>Carney</surname><given-names>PA</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Effectiveness of computer-aided detection in community mammography practice</article-title>. <source>Journal of the National Cancer Institute</source> <volume>103</volume>: <fpage>1152</fpage>–<lpage>1161</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Fenton2"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fenton</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Taplin</surname><given-names>SH</given-names></name>, <name name-style="western"><surname>Carney</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Abraham</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Sickles</surname><given-names>EA</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Influence of computer-aided detection on performance of screening mammography</article-title>. <source>New England Journal of Medicine</source> <volume>356</volume>: <fpage>1399</fpage>–<lpage>1409</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Jiang1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Nishikawa</surname><given-names>RM</given-names></name>, <name name-style="western"><surname>Schmidt</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Metz</surname><given-names>CE</given-names></name> (<year>2006</year>) <article-title>Comparison of independent double readings and computer-aided diagnosis (CAD) for the diagnosis of breast calcifications</article-title>. <source>Acad Radiol</source> <volume>13</volume>: <fpage>84</fpage>–<lpage>94</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Gilbert1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilbert</surname><given-names>FJ</given-names></name>, <name name-style="western"><surname>Astley</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Gillan</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>Agbaje</surname><given-names>OF</given-names></name>, <name name-style="western"><surname>Wallis</surname><given-names>MG</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Single reading with computer-aided detection for screening mammography</article-title>. <source>N Engl J Med</source> <volume>359</volume>: <fpage>1675</fpage>–<lpage>1684</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Sickles1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sickles</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Miglioretti</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Ballard-Barbash</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Geller</surname><given-names>BM</given-names></name>, <name name-style="western"><surname>Leung</surname><given-names>JWT</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Performance benchmarks for diagnostic mammography</article-title>. <source>Radiology</source> <volume>235</volume>: <fpage>775</fpage>–<lpage>790</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Scott1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scott</surname><given-names>HJ</given-names></name>, <name name-style="western"><surname>Gale</surname><given-names>AG</given-names></name> (<year>2005</year>) <article-title>Breast Screening Technologists: when is a difficult case truly difficult and for whom?</article-title> <source>Medical Imaging 2005: Image Perception, Observer Performance, and Technology Assessment</source> <volume>5749</volume>: <fpage>557</fpage>–<lpage>565</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Bird1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bird</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Wallace</surname><given-names>TW</given-names></name>, <name name-style="western"><surname>Yankaskas</surname><given-names>BC</given-names></name> (<year>1992</year>) <article-title>Analysis of Cancers Missed at Screening Mammography</article-title>. <source>Radiology</source> <volume>184</volume>: <fpage>613</fpage>–<lpage>617</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-TaylorPhillips1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Taylor-Phillips S, Clarke A, Wheaton M, Kearins O, Wallis M (2012) Fatigue and performance in interpreting breast screening mammograms. Breast Cancer Research<volume>14</volume>..</mixed-citation>
</ref>
<ref id="pone.0091015-Evans1"><label>14</label>
<mixed-citation publication-type="other" xlink:type="simple">Evans KK, Birdwell RL, Wolfe JM (2013) If You Don't Find It Often, You Often Don't Find It: Why Some Cancers Are Missed in Breast Cancer Screening. Plos One <volume>8</volume>..</mixed-citation>
</ref>
<ref id="pone.0091015-Gur1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gur</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Rockette</surname><given-names>HE</given-names></name>, <name name-style="western"><surname>Armfield</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Blachar</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bogan</surname><given-names>JK</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Prevalence effect in a laboratory environment</article-title>. <source>Radiology</source> <volume>228</volume>: <fpage>10</fpage>–<lpage>14</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Gur2"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gur</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Bandos</surname><given-names>AI</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Hakim</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Hardesty</surname><given-names>LA</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>The “Laboratory” effect: Comparing radiologists' performance and variability during prospective clinical and laboratory mammography interpretations</article-title>. <source>Radiology</source> <volume>249</volume>: <fpage>47</fpage>–<lpage>53</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Wolfe1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolfe</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Van Wert</surname><given-names>MJ</given-names></name> (<year>2010</year>) <article-title>Varying Target Prevalence Reveals Two Dissociable Decision Criteria in Visual Search</article-title>. <source>Current Biology</source> <volume>20</volume>: <fpage>121</fpage>–<lpage>124</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Cupples1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cupples</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Cunningham</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Reynolds</surname><given-names>JC</given-names></name> (<year>2005</year>) <article-title>Impact of computer-aided detection in a regional screening mammography program</article-title>. <source>American Journal of Roentgenology</source> <volume>185</volume>: <fpage>944</fpage>–<lpage>950</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Azavedo1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Azavedo</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Zackrisson</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mejare</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Heibert Arnlind</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Is single reading with computer-aided detection (CAD) as good as double reading in mammography screening? A systematic review</article-title>. <source>BMC Med Imaging</source> <volume>12</volume>: <fpage>22</fpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Sato1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Sato M, Kawai M, Nishino Y, Shibuya D, Ohuchi N, <etal>et al</etal>.. (2012) Cost-effectiveness analysis for breast cancer screening: double reading versus single + CAD reading. Breast Cancer.</mixed-citation>
</ref>
<ref id="pone.0091015-Houssami1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Houssami</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Given-Wilson</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Ciatto</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Early detection of breast cancer: overview of the evidence on computer-aided detection in mammography screening</article-title>. <source>J Med Imaging Radiat Oncol</source> <volume>53</volume>: <fpage>171</fpage>–<lpage>176</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Houssami2"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Houssami</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Lord</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Ciatto</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Breast cancer screening: emerging role of new imaging techniques as adjuncts to mammography</article-title>. <source>Med J Aust</source> <volume>190</volume>: <fpage>493</fpage>–<lpage>497</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Gur3"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gur</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Stalder</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Hardesty</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Zheng</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Sumkin</surname><given-names>JH</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Computer-aided Detection Performance in Mammographic Examination of Masses: Assessment1</article-title>. <source>Radiology</source> <volume>233</volume>: <fpage>418</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Liu1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Babbs</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Delp</surname><given-names>EJ</given-names></name> (<year>2001</year>) <article-title>Multiresolution detection of spiculated lesions in digital mammograms</article-title>. <source>Ieee Transactions on Image Processing</source> <volume>10</volume>: <fpage>874</fpage>–<lpage>884</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Liu2"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Babbs</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Delp</surname><given-names>EJ</given-names></name> (<year>1998</year>) <article-title>Normal mammogram analysis and recognition</article-title>. <source>1998 International Conference on Image Processing - Proceedings, Vol</source> <volume>1</volume>: <fpage>727</fpage>–<lpage>731</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Kendall1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kendall</surname><given-names>EJ</given-names></name>, <name name-style="western"><surname>Barnett</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>Chytyk-Praznik</surname><given-names>K</given-names></name> (<year>2013</year>) <article-title>Automatic detection of anomalies in screening mammograms</article-title>. <source>BMC Med Imaging</source> <volume>13</volume>: <fpage>43</fpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Heath1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Heath M, Bowyer K, Kopans D, Kegelmeyer Jr P, Moore R, <etal>et al</etal>.. (1998) Current status of the digital database for screening mammography. Digital Mammography: Springer. pp. 457–460.</mixed-citation>
</ref>
<ref id="pone.0091015-Heath2"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Heath M, Bowyer K, Kopans D, Moore R, Kegelmeyer P, The digital database for screening mammography; 2000. pp. 212–218.</mixed-citation>
</ref>
<ref id="pone.0091015-Suckling1"><label>29</label>
<mixed-citation publication-type="other" xlink:type="simple">Suckling J, Parker J, Dance D, Astley S, Hutt I, <etal>et al</etal>.. (1994) The mammographic image analysis society digital mammogram database.</mixed-citation>
</ref>
<ref id="pone.0091015-Delong1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Delong</surname><given-names>ER</given-names></name>, <name name-style="western"><surname>Delong</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Clarkepearson</surname><given-names>DI</given-names></name> (<year>1988</year>) <article-title>Comparing the Areas under 2 or More Correlated Receiver Operating Characteristic Curves - a Nonparametric Approach</article-title>. <source>Biometrics</source> <volume>44</volume>: <fpage>837</fpage>–<lpage>845</lpage>.</mixed-citation>
</ref>
<ref id="pone.0091015-Oliver1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oliver</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Freixenet</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Marti</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Perez</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Pont</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>A review of automatic mass detection and segmentation in mammographic images</article-title>. <source>Medical Image Analysis</source> <volume>14</volume>: <fpage>87</fpage>–<lpage>110</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>