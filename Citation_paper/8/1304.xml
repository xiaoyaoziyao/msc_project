<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-01731</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004250</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Memory Storage Fidelity in the Hippocampal Circuit: The Role of Subregions and Input Statistics</article-title>
<alt-title alt-title-type="running-head">Memory Storage in the Hippocampal Circuit</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Neher</surname> <given-names>Torsten</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Cheng</surname> <given-names>Sen</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Wiskott</surname> <given-names>Laurenz</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>International Graduate School Neuroscience, Ruhr-University Bochum, Bochum, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Institute for Neural Computation, Ruhr-University Bochum, Bochum, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Mercator Research Group ‘Structure of Memory’, Department of Psychology, Ruhr-University Bochum, Bochum, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Treves</surname> <given-names>Alessandro</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>SISSA Intl Sch Adv Studies, ITALY</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: TN SC LW. Performed the experiments: TN. Analyzed the data: TN SC LW. Contributed reagents/materials/analysis tools: TN. Wrote the paper: TN SC LW.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">torsten.neher@ini.rub.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>5</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>8</day>
<month>5</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>5</issue>
<elocation-id>e1004250</elocation-id>
<history>
<date date-type="received">
<day>22</day>
<month>9</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>3</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Neher et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004250" xlink:type="simple"/>
<abstract>
<p>In the last decades a standard model regarding the function of the hippocampus in memory formation has been established and tested computationally. It has been argued that the CA3 region works as an auto-associative memory and that its recurrent fibers are the actual storing place of the memories. Furthermore, to work properly CA3 requires memory patterns that are mutually uncorrelated. It has been suggested that the dentate gyrus orthogonalizes the patterns before storage, a process known as pattern separation. In this study we review the model when random input patterns are presented for storage and investigate whether it is capable of storing patterns of more realistic entorhinal grid cell input. Surprisingly, we find that an auto-associative CA3 net is redundant for random inputs up to moderate noise levels and is only beneficial at high noise levels. When grid cell input is presented, auto-association is even harmful for memory performance at all levels. Furthermore, we find that Hebbian learning in the dentate gyrus does not support its function as a pattern separator. These findings challenge the standard framework and support an alternative view where the simpler EC-CA1-EC network is sufficient for memory storage.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>It is well known that the hippocampus, a mammalian brain region, has a crucial role in memory formation. Furthermore, it has a remarkable anatomical structure and can be divided into several subregions based on physiological properties. Over the last decades a widely accepted model has evolved suggesting individual roles for each subregion in memory storage. The central idea is that region CA3, with its remarkably many synapses that project into the region itself again, stores the memories within these synapses. In this model a memory is impressed onto the hippocampus by neuronal activation in the hippocampal input region. Recently it has been found that such activations have a certain regularity instead of being random as assumed in the standard model. Here we investigate how well the model performs when storing memories of regular inputs. We find that the proposed function of CA3 actually harms memory performance. Moreover, we show that this function is redundant even in the case of random inputs. These findings call the standard model into question and support an alternative view of how the hippocampus may store memories.</p>
</abstract>
<funding-group>
<funding-statement>This work was partly funded by a grant from the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) to LW (SFB 874, project B3) and to SC (SFB 874, project B2), and by a grant from the Stiftung Mercator to SC. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="1"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>The computational code which we apply to create the data is available at: <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://cns.mrg1.rub.de/index.php/software">http://cns.mrg1.rub.de/index.php/software</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The crucial role of the hippocampus in memory formation is well known. Patients with damage to the hippocampus and its nearby cortices have severe deficits in acquiring new episodic memory and in remembering events that happened shortly before the damage [<xref ref-type="bibr" rid="pcbi.1004250.ref001">1</xref>]. Impairments in memory formation can be observed in animals, too. For example, rats with a lesioned hippocampus cannot associate stimuli if there is a time delay between them [<xref ref-type="bibr" rid="pcbi.1004250.ref002">2</xref>].</p>
<p>Furthermore, the hippocampus has a remarkable anatomical structure. Based on anatomical and physiological properties it can be divided into the dentate gyrus (DG) with its huge number of small granule cells that show low activity [<xref ref-type="bibr" rid="pcbi.1004250.ref003">3</xref>] and the regions CA3 and CA1 consisting of a homogeneous set of pyramidal cells, where in CA3 one can find a striking number of recurrent connections. A further notable property is that the connections among the subregions is established largely in a feedforward manner [<xref ref-type="bibr" rid="pcbi.1004250.ref004">4</xref>].</p>
<p>The question that arises is, how does this peculiar anatomical structure serve memory formation? Over the years, a standard framework has evolved regarding hippocampal functioning and it has been tested with a number of computational models (for example by Rolls (1995) [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>]). The view is that the CA3 region functions as an auto-associative memory [<xref ref-type="bibr" rid="pcbi.1004250.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref009">9</xref>]. An auto-associative memory is a recurrent network that stores patterns in its feedback connections and can reconstruct these patterns when only a partial version of them is presented. Thus, the actual storing place are the recurrent connections and this idea could explain why there are so remarkably many in CA3.</p>
<p>An auto-associative memory can only store patterns that are not similar or mutually correlated [<xref ref-type="bibr" rid="pcbi.1004250.ref006">6</xref>]. By nature, however, the neural activation in the input region of the hippocampus, the entorhinal cortex (EC), is not uncorrelated [<xref ref-type="bibr" rid="pcbi.1004250.ref010">10</xref>]. Thus, it has been suggested that the DG performs pattern separation during the storage phase [<xref ref-type="bibr" rid="pcbi.1004250.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref009">9</xref>]. It decorrelates the patterns of the EC and projects the separated versions of the patterns to CA3 for storage. A large number of cells with low activity and the sparse projection of mossy fibers support pattern separation computationally [<xref ref-type="bibr" rid="pcbi.1004250.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref012">12</xref>]. Hence, this view explains the appearance of yet other prominent hippocampal characteristics. Finally, it has been proposed that the role of CA1 is to decode the highly transformed patterns in CA3 back to their original versions in the EC.</p>
<p>A number of cells in the medial entorhinal cortex (MEC), called grid cells, fire at places in the environment regularly distributed on a hexagonal grid [<xref ref-type="bibr" rid="pcbi.1004250.ref010">10</xref>]. The present study reviews the model by Rolls and we test whether it is capable of storing grid cell input patterns. To our surprise, we find that CA3 functioning as an auto-associative memory is not only redundant, but harmful for memory performance. We even find a redundancy for random inputs at low to moderate noise levels. Moreover, pattern separation through the DG does not occur by simply applying Hebbian learning.</p>
<p>Since it was recently suggested that the subnetwork EC-CA1-EC already performs pattern completion [<xref ref-type="bibr" rid="pcbi.1004250.ref013">13</xref>], we tested whether this simpler network is indeed sufficient for memory function.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec003">
<title>Model Architecture and Activation Function</title>
<p>The model consists of the subregions entorhinal cortex (EC), dentate gyrus (DG), CA3 and CA1. Cell numbers <italic>N</italic> in each region and numbers of connections one cell in a downstream region has with the upper region are summarized in <xref ref-type="fig" rid="pcbi.1004250.g001">Fig 1</xref>. Cell numbers and numbers of connections are derived from rat data [<xref ref-type="bibr" rid="pcbi.1004250.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref014">14</xref>] and scaled down by 100 and 10, respectively. Dividing the number of connections per cell by 100, too, would lead to CA3 cells that do not receive any input from the DG. On the other hand, leaving this number constant would result in triple connections among cell pairs in the network. Thus, we choose to scale by the square root of 100, which scales the total number of connections between two subregions by 100, too. Cells in our model have continuous firing rates with the exception of CA3 cells, which are binary, i.e., they either fire and have the value 1 or are silent and have the value 0. This is in line with Rolls (1995), where CA3 does not work well with continuous firing rates [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>].</p>
<fig id="pcbi.1004250.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Model overview.</title>
<p><bold>A</bold>: The four subregions EC, DG, CA3 and CA1 are modeled. <italic>a</italic> denotes the proportion of cells being active at any given time. Arrows indicate connectivity among regions. Black ones are random and fixed connections, green ones are plastic and adjusted during learning. The number next to the arrows show the number of connections one cell in the downstream region has with the up stream region. <bold>B-C</bold>: Distribution of spacings (<bold>B</bold>) and orientations (<bold>C</bold>) of the grid population in one environment. Colours indicate the modules. <bold>D-E</bold>: Four examples of grid cells (one from each module) (<bold>D</bold>) and two examples of LEC cells (<bold>E</bold>). The two rows show the firing map of the cells in two distinct environments.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g001"/>
</fig>
<p>A pattern <bold>p</bold> of neural activation, for example, <inline-formula id="pcbi.1004250.e001"><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mo>ℝ</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:math></inline-formula> in the EC triggers neural activity in a downstream region, e.g., in the DG, via the connections as follows: First, the activation <italic>h</italic><sub><italic>i</italic></sub> of the output cell <italic>i</italic> is calculated by the standard weighted sum of its inputs
<disp-formula id="pcbi.1004250.e002"><alternatives><graphic id="pcbi.1004250.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e002"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:munderover> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>w</italic><sub><italic>ij</italic></sub> is the strength of the connection from cell <italic>j</italic> to cell <italic>i</italic> and is defined as 0 whenever this connection is not existent.</p>
<p>To determine the firing of a cell a simple <italic>k</italic>-Winner-Take-All (WTA) mechanism is applied: After calculating the activation of all cells of that region, the <italic>k</italic> cells with the highest activation are either set to 1 or to <italic>h</italic><sub><italic>i</italic></sub> whenever they are continuous. The others are inhibited and set to 0. The number <italic>k</italic> is determined by the sparsity <italic>a</italic> of that region, i.e <italic>k</italic> = <italic>aN</italic>. For instance, the pattern of neural activity <inline-formula id="pcbi.1004250.e003"><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>∈</mml:mo> <mml:msubsup><mml:mo>ℝ</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>D</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:math></inline-formula> in the DG is
<disp-formula id="pcbi.1004250.e004"><alternatives><graphic id="pcbi.1004250.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e004"/><mml:math id="M4" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mi>h</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>h</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="4.pt"/><mml:mtext>is</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>among</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>the</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>k</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>highest</mml:mtext> <mml:mspace width="4.pt"/><mml:mo>{</mml:mo> <mml:msub><mml:mi>h</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>:</mml:mo> <mml:mn>1</mml:mn> <mml:mo>≤</mml:mo> <mml:mi>j</mml:mi> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>D</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>otherwise</mml:mtext> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
Thus, inhibitory cells are not modeled explicitly but rather through their effect on a population level [<xref ref-type="bibr" rid="pcbi.1004250.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref019">19</xref>].</p>
<p>In order to determine the sparsity <italic>a</italic> we first estimated the average number of cells being active in one environment by referring to several studies that count active cells by immediate early genes [<xref ref-type="bibr" rid="pcbi.1004250.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref023">23</xref>] or by electrophysiological recordings [<xref ref-type="bibr" rid="pcbi.1004250.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref025">25</xref>]. Individual reports are summarized in <xref ref-type="table" rid="pcbi.1004250.t001">Table 1</xref> and yield average activity levels of 2.9% in the DG, 22.7% in CA3 and 42.7% in CA1 across the enclosure. Second, for simplicity we assume that every active cell is a place cell and the proportion of the environment a place cell fires in is determined by its place field size times the number of fields the cell has. Using data from recordings within a 1m<sup>2</sup> apparatus [<xref ref-type="bibr" rid="pcbi.1004250.ref024">24</xref>, Supplementary Table 1], we obtain an average coverage of 14% of a CA3 cell, and 21% of a CA1 cell. A typical DG cell has 3–4 fields and a field size smaller than 900cm<sup>2</sup> (personal communication with Edvard Moser) which brings us to an estimation of 27% coverage. Multiplying the proportion of cells being active across the environment by the proportion of the environment one active cells fires leads to the activation level at one location given by <italic>a</italic> (see <xref ref-type="fig" rid="pcbi.1004250.g001">Fig 1</xref>). For the EC we calculated the average coverage of a grid cell to be 35% using data from Hafting et al. (2005) and assume that a grid cell is active in every environment [<xref ref-type="bibr" rid="pcbi.1004250.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref026">26</xref>]. This value is similar to the value obtained by the simulations from others [<xref ref-type="bibr" rid="pcbi.1004250.ref027">27</xref>].</p>
<table-wrap id="pcbi.1004250.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.t001</object-id>
<label>Table 1</label>
<caption>
<title>Overview of measured activity levels in hippocampal subregions.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004250.t001g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.t001"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Study</th>
<th align="left" rowspan="1" colspan="1">Method</th>
<th align="left" rowspan="1" colspan="1">Active cells %</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>DG</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref023">23</xref>] (<xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3</xref>)</td>
<td align="left" rowspan="1" colspan="1">IEG</td>
<td align="left" rowspan="1" colspan="1">3</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref022">22</xref>] (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5</xref>)</td>
<td align="left" rowspan="1" colspan="1">IEG</td>
<td align="left" rowspan="1" colspan="1">3–4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref021">21</xref>] (<xref ref-type="fig" rid="pcbi.1004250.g007">Fig 7</xref>)</td>
<td align="left" rowspan="1" colspan="1">IEG</td>
<td align="left" rowspan="1" colspan="1">2.2</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>CA3</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref020">20</xref>] (<xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3c</xref>)</td>
<td align="left" rowspan="1" colspan="1">IEG (Arc, Homer1)</td>
<td align="left" rowspan="1" colspan="1">18</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref024">24</xref>]</td>
<td align="left" rowspan="1" colspan="1">Electrophysiology</td>
<td align="left" rowspan="1" colspan="1">17–32</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref025">25</xref>]</td>
<td align="left" rowspan="1" colspan="1">Electrophysiology</td>
<td align="left" rowspan="1" colspan="1">26</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>CA1</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref020">20</xref>] (<xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3c</xref>)</td>
<td align="left" rowspan="1" colspan="1">IEG (Arc, Homer1)</td>
<td align="left" rowspan="1" colspan="1">35</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref024">24</xref>]</td>
<td align="left" rowspan="1" colspan="1">Electrophysiology</td>
<td align="left" rowspan="1" colspan="1">48–66</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">[<xref ref-type="bibr" rid="pcbi.1004250.ref025">25</xref>]</td>
<td align="left" rowspan="1" colspan="1">Electrophysiology</td>
<td align="left" rowspan="1" colspan="1">36</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001">
<p>IEG means immediate early genes</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec004">
<title>Learning Rules</title>
<p>To store patterns in the network the plastic weights among subregions (green arrows in <xref ref-type="fig" rid="pcbi.1004250.g001">Fig 1</xref>) are adjusted by three related Hebbian learning rules. Let <bold>C</bold> denote the connection matrix of two regions, i.e., <italic>c</italic><sub><italic>ij</italic></sub> = 1 if there is a connection from cell <italic>j</italic> to <italic>i</italic> and <italic>c</italic><sub><italic>ij</italic></sub> = 0 otherwise.</p>
<p>For the connections EC to CA3, CA3 to CA1, and CA1 to EC a rule for hetero-association is used. Let {<bold>p</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>} be the set of <italic>M</italic> input patterns and {<bold>q</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>} be the set of output patterns, then the connection strength is defined according to the so called Stent-Stinger rule [<xref ref-type="bibr" rid="pcbi.1004250.ref028">28</xref>]
<disp-formula id="pcbi.1004250.e005"><alternatives><graphic id="pcbi.1004250.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e005"/><mml:math id="M5" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where the connection from cell <italic>j</italic> to <italic>i</italic> is the sum over all patterns <italic>s</italic> of firing <inline-formula id="pcbi.1004250.e006"><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> of input cell <italic>j</italic> subtracted by its mean <inline-formula id="pcbi.1004250.e007"><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>‾</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> times the firing <inline-formula id="pcbi.1004250.e008"><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> of cell <italic>i</italic>. The factor <italic>c</italic><sub><italic>ij</italic></sub> assures that non-existing connections remain at zero weight.</p>
<p>For the synaptic weight matrix <bold>V</bold> of the recurrent weights in CA3 the co-variance rule is used [<xref ref-type="bibr" rid="pcbi.1004250.ref029">29</xref>] to learn an auto-association among a set of patterns {<bold>p</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>}
<disp-formula id="pcbi.1004250.e009"><alternatives><graphic id="pcbi.1004250.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e009"/><mml:math id="M9" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
By subtracting the mean the two learning rules model LTP and LTD. Furthermore the subtraction is essential for computational reasons (see for example [<xref ref-type="bibr" rid="pcbi.1004250.ref030">30</xref>, chapter 8.2]).</p>
<p>Finally, the connections from EC to DG are altered by a one shot competitive learning rule. Here, the current input pattern <bold>p</bold> first triggers a firing pattern <bold>q</bold> in the downstream region according to the equations above. Synapses are then changed by
<disp-formula id="pcbi.1004250.e010"><alternatives><graphic id="pcbi.1004250.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>o</mml:mi> <mml:mi>l</mml:mi> <mml:mi>d</mml:mi></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>q</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where <italic>γ</italic> is a constant learning rate. After applying <xref ref-type="disp-formula" rid="pcbi.1004250.e010">Eq (4)</xref> the Euclidean norm of vector <bold>w</bold><sub><italic>i</italic></sub> of incoming weights to cell <italic>i</italic> is normalized to one to assure that not always the same cells get activated. These rules are adopted from Rolls (1995) to keep the model as similar as possible to that one.</p>
<p>After hetero-association of {<bold>p</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>} with {<bold>q</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>} by applying <xref ref-type="disp-formula" rid="pcbi.1004250.e005">Eq (3)</xref> between some regions, given pattern <bold>p</bold><sup>(<italic>t</italic>)</sup> as the present input we can rewrite the activation <inline-formula id="pcbi.1004250.e011"><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> as
<disp-formula id="pcbi.1004250.e012"><alternatives><graphic id="pcbi.1004250.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e012"/><mml:math id="M12" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mspace width="0.166667em"/></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.166667em"/><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mspace width="0.166667em"/><mml:mover><mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>3</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mover> <mml:mspace width="0.166667em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mspace width="0.166667em"/></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mspace width="0.166667em"/><mml:mo>≈</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mspace width="0.166667em"/><mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mi>c</mml:mi> <mml:mspace width="0.166667em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>︸</mml:mo></mml:munder> <mml:msub><mml:mi>S</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:munder> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:munder> <mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mi>c</mml:mi> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>︸</mml:mo></mml:munder> <mml:msub><mml:mi>X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:munder> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>c</italic> is the proportion of cells one output cell is connected to in the input layer. Thus, we can write the activation of cell <italic>i</italic> as the sum of a signal term <italic>q</italic><sub><italic>i</italic></sub> <italic>S</italic><sub><italic>t</italic></sub> which stems from the proportion of the weights arising from the storage of pattern <bold>p</bold><sup>(<italic>t</italic>)</sup> and the crosstalk terms <italic>X</italic><sub>(<italic>i</italic>,<italic>s</italic>,<italic>t</italic>)</sub> which come from the contribution of the other stored patterns in which this cell was active [<xref ref-type="bibr" rid="pcbi.1004250.ref031">31</xref>]
<disp-formula id="pcbi.1004250.e013"><alternatives><graphic id="pcbi.1004250.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>h</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mtd> <mml:mtd><mml:mrow><mml:mo>≈</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:msub><mml:mi>S</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
Ideally, the activation is high if and only if the cell has fired in pattern <bold>q</bold><sup>(<italic>t</italic>)</sup>.</p>
</sec>
<sec id="sec005">
<title>Input</title>
<p>We perform simulations with random patterns and more realistic patterns that were generated by a grid cell code in the medial entorhinal cortex (MEC). For a randomly created pattern, cell activity <italic>h</italic><sub><italic>i</italic></sub> is sampled from a normal distribution with mean and variance equal to 1. All cells, but the <italic>k</italic> ones with the highest activation are set to zero, as in <xref ref-type="disp-formula" rid="pcbi.1004250.e004">Eq (2)</xref>. We store 252 patterns in both cases.</p>
<p>For the grid cell input we built a 1m by 1m virtual square environment. Each cell is equipped with a hexagonal grid of place fields with equal size. The peak firing rate of each field is drawn from a uniform distribution from 0.5 to 1.5. According to the findings of Stensola et al. (2012) we divided the grid cell population into four modules [<xref ref-type="bibr" rid="pcbi.1004250.ref032">32</xref>]. Cells belonging to the same module have similar grid spacing and orientation. The cell parameter are drawn from normal distributions with variances 8 cm and 3 degree, respectively. The mean spacings of the modules are 38.8, 48.4, 65 and 98.4 cm and are taken from [<xref ref-type="bibr" rid="pcbi.1004250.ref032">32</xref>, <xref ref-type="fig" rid="pcbi.1004250.g001">Fig 1D</xref>]. The mean orientations are 15, 30, 45 and 60 degrees. The resulting distribution of spacings and orientations of the population is illustrated in Fig <xref ref-type="fig" rid="pcbi.1004250.g001">1B</xref>–<xref ref-type="fig" rid="pcbi.1004250.g001">1C</xref>. As in Stensola et al. (2012) there are more cells in the modules with small spacings.</p>
<p>Activation of cell <italic>i</italic> at one location is determined by
<disp-formula id="pcbi.1004250.e014"><alternatives><graphic id="pcbi.1004250.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e014"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mfrac><mml:mi>d</mml:mi> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mi>l</mml:mi> <mml:mi>o</mml:mi> <mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>5</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>·</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>d</italic> is the Euclidean distance to the nearest field center <italic>j</italic> and <inline-formula id="pcbi.1004250.e015"><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>i</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the peak rate in that field and <italic>r</italic><sub><italic>i</italic></sub> is the radius. This way its activation is <inline-formula id="pcbi.1004250.e016"><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>i</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> at the center and <inline-formula id="pcbi.1004250.e017"><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>2</mml:mn> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>i</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> at the border of one field, which is motivated by the definition of a place field [<xref ref-type="bibr" rid="pcbi.1004250.ref010">10</xref>]. We measure the activity of all cells at 400 locations uniformly distributed throughout the space. At each location all cells but the <italic>k</italic> ones with the highest activation are set to zero as in <xref ref-type="disp-formula" rid="pcbi.1004250.e004">Eq (2)</xref>. For storage, 252 out of the 400 locations are chosen randomly and the corresponding population activities were considered as input patterns.</p>
<p>To study the influence of the lateral entorhinal cortex (LEC) we add input from LEC in some simulations. The activation map of one LEC cell is the summation of 30 place fields with random size at random locations. This is inspired by the findings of Deshmukh and Knierim (2011). They show that cells in the LEC tend to have several pseudo place fields that actually code for specific objects [<xref ref-type="bibr" rid="pcbi.1004250.ref033">33</xref>]. In Rennó-Costa (2010) LEC cells are modelled similarly. There, the cell’s activation map has specific active and non-active regions [<xref ref-type="bibr" rid="pcbi.1004250.ref015">15</xref>]. After defining the map in our model, we again set all LEC cells but the <italic>k</italic> ones with the highest activation in each location to zero as in <xref ref-type="disp-formula" rid="pcbi.1004250.e004">Eq (2)</xref>.</p>
<p>To study the effect of global remapping, input patterns from different environments are stored in some simulations. Here, each input cell has an activation map for each environment. For a grid cell, its activation map is computed by rotating and shifting its grid structure defined in the first environment, where the rotation angle and shifting vector is the same for the cells from the same module. This is inspired by the results of Fyhn et al. (2007), where they find a coherent remapping in cells recorded at the same location in the MEC [<xref ref-type="bibr" rid="pcbi.1004250.ref026">26</xref>]. For an LEC cell we define a completely new map for each environment in the same way as for the first map. Examples of input cells and their remapping are shown in Fig <xref ref-type="fig" rid="pcbi.1004250.g001">1D</xref>–<xref ref-type="fig" rid="pcbi.1004250.g001">1E</xref>.</p>
<p>For recall a noisy version of a stored pattern is created, which we call recall cue. For each noisy pattern a subset of cells is selected randomly to fire incorrectly by setting its rate to that of an arbitrary other cell in that pattern. The quality of the cue is controlled by the number of cells that fire incorrectly and is measured by the Pearson correlation between original pattern and the recall cue.</p>
</sec>
<sec id="sec006">
<title>Storage and Recall</title>
<p>Storing a pattern <bold>p</bold> of entorhinal activation in the network is done as follows. First, this pattern triggers neural activity in the DG which in turn triggers a pattern in the CA3 region via Eqs (<xref ref-type="disp-formula" rid="pcbi.1004250.e002">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004250.e004">2</xref>). Thus, during storage, activity in CA3 is only influenced by the mossy fiber input from the DG. The connections from EC to DG are altered by the competitive learning rule (<xref ref-type="disp-formula" rid="pcbi.1004250.e010">Eq (4)</xref>) for pattern separation. Hence, for the next pattern the connections are different as for the current pattern. Furthermore, <bold>p</bold> drives an activity pattern in CA1. Now, the pattern in CA3 is hetero-associated with <bold>p</bold> in EC, auto-associated in the recurrent connections in CA3, and hetero-associated with the pattern in CA1. Finally, the CA1 activity is hetero-associated with <bold>p</bold> in the EC.</p>
<p>After the storage of all patterns the network is presented a recall cue by setting entorhinal activity to a noisy version <inline-formula id="pcbi.1004250.e018"><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> of a previously stored pattern. This activity triggers a pattern <inline-formula id="pcbi.1004250.e019"><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>˜</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in CA3 directly via the previously learned weights from EC to CA3. The pattern then runs through 15 activation cycles of the auto-associative network in CA3 while leaving the input from the EC clamped (we have verified that after 15 cycles the results have converged). In more detail, for the <italic>t</italic>-th cycle the activation of CA3 cell <italic>i</italic> is
<disp-formula id="pcbi.1004250.e020"><alternatives><graphic id="pcbi.1004250.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e020"/><mml:math id="M20" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>α</mml:mi> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:munderover> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mi>β</mml:mi> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>C</mml:mi> <mml:mi>A</mml:mi> <mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:munderover> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mover accent="true"><mml:msub><mml:mi>q</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>α</italic> and <italic>β</italic> are constant factors set to 1 and 3 and <inline-formula id="pcbi.1004250.e021"><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>˜</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is determined by the k-WTA mechanism described in <xref ref-type="disp-formula" rid="pcbi.1004250.e004">Eq 2</xref>. Hence, during recall CA3 activity is dominated by the recurrent connections and the DG is not involved anymore. The resulting pattern <inline-formula id="pcbi.1004250.e022"><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>˜</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mn>15</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> triggers one in CA1, which in turn determines the output activity in the EC via the learned weights from CA3 to CA1 and CA1 to EC, respectively. In simulations without recurrent connections <inline-formula id="pcbi.1004250.e023"><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>˜</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> activates a pattern in CA1 immediately.</p>
</sec>
<sec id="sec007">
<title>Evaluation</title>
<p>Memory performance is determined by the network’s ability to perform pattern completion. In more detail, after storage, patterns are presented to the network again, but now in a corrupted version called recall cue. If the network’s output is more similar to the original pattern than its cue was, then the network has done some amount of recall. As a measure for similarity we use the Pearson correlation coefficient. For instance, the correlation between the originally stored pattern <bold>p</bold> in the EC and the reconstructed one <inline-formula id="pcbi.1004250.e024"><mml:math id="M24" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is defined as:
<disp-formula id="pcbi.1004250.e025"><alternatives><graphic id="pcbi.1004250.e025g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e025"/><mml:math id="M25" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>C</mml:mi> <mml:mi>o</mml:mi> <mml:mi>r</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mrow><mml:mo>∥</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>−</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>∥</mml:mo> <mml:mo>·</mml:mo> <mml:mo>∥</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1004250.e026"><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004250.e027"><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> are the means of <bold>p</bold> and <inline-formula id="pcbi.1004250.e028"><mml:math id="M28" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, respectively. The higher this correlation is, the more similar is the recalled pattern to the original one. Furthermore, we define the average correlation over all stored patterns {<bold>p</bold><sup>(<italic>s</italic>)</sup>:1 ≤ <italic>s</italic> ≤ <italic>M</italic>} as
<disp-formula id="pcbi.1004250.e029"><alternatives><graphic id="pcbi.1004250.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004250.e029"/><mml:math id="M29" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>C</mml:mi> <mml:mi>o</mml:mi> <mml:mi>r</mml:mi> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>M</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mi>C</mml:mi> <mml:mi>o</mml:mi> <mml:mi>r</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
We perform simulations where we alter the quality of the recall cue and we illustrate the memory performance by plotting <italic>Corr</italic><sub><italic>EC</italic></sub> over the quality of the cues, i.e. the average correlation the cues have with the original patterns. Measurements above the main diagonal show then that the output of the network is on average more similar to the stored patterns than the cues. Hence, the more the measurements are above the diagonal, the better is the performance. To investigate how much pattern completion each subregion contributes to the overall performance, we similarly define <italic>Corr</italic><sub><italic>CA</italic>3</sub> and <italic>Corr</italic><sub><italic>CA</italic>1</sub>.</p>
</sec>
<sec id="sec008">
<title>Different Networks</title>
<p>We compare the model to two alternatives. Firstly, to determine how effective the CA3 recurrent connections are, we perform simulations of a network without these connections. Here, the pattern <inline-formula id="pcbi.1004250.e030"><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">q</mml:mtext> <mml:mo>˜</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is directly transferred to CA1 during recall without undergoing the activation cycles of the auto-associative network in CA3. The result of these simulations are indicated by dashed lines throughout the figures.</p>
<p>Secondly, we investigate the ability of a minimal EC-CA1-EC model to store patterns. We performed simulations, in which during storage, activity in CA1 is triggered by the input from EC-CA3-CA1 pathway, without any plasticity in these connections. The CA1 patterns are then hetero-associated with the original input patterns in the connection weights EC-CA1 and CA1-EC, so in contrast to previous simulations the EC-CA1 connections are now plastic. During the recall phase, the recall cue is transferred to CA1 via the temporoammonic pathway and from there back to EC. The result of these simulations are indicated by magenta lines throughout the figures.</p>
<p>Besides outlined architecture, parameters do not change across simulations except in section ‘Comparison to the Model in Rolls (1995)’. All parameter changes there are described in the main text.</p>
</sec>
<sec id="sec009">
<title>Pattern Separation Index</title>
<p>To quantify the degree of pattern separation by the DG we plot the pairwise correlations of stored patterns in CA3 over the ones of the stored input patterns themselves and calculate the regression line between them. Whenever the line approximates the data well, then its slope is a good measure of how effective the DG separates the patterns. The flatter it is, the better is the separation. Thus, we refer to it as the pattern separation index.</p>
</sec>
</sec>
<sec id="sec010" sec-type="results">
<title>Results</title>
<sec id="sec011">
<title>Comparison to the Model in Rolls (1995)</title>
<p>In a series of studies, a hippocampal model for memory formation within the standard framework has been established and tested computationally [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>]. The main argument of this model is that CA3 equipped with many recurrent connections functions as an auto-associative network and is the crucial place for pattern completion. To test the theory, performance of simulations where those connections have been removed, has been compared to performance of the full network.</p>
<p>To reproduce the results of Rolls (1995) we performed a simulation of this model using the same parameters as in that study, including number of cells and connections and the sparseness parameter, and stored 100 random patterns. <xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2A</xref> shows the average correlation between stored patterns and the reconstructed ones in the EC vs. the cue quality. Since the curve is well above the diagonal the network as a whole performs pattern completion. Only when the cue quality becomes highly degraded, pattern completion starts to break down. The intermediate stages of the network, CA1 and CA3, while not as efficient as the entire network, perform pattern completion as well to a certain degree (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2A</xref>). To specifically test the role of the recurrent connections in CA3, we performed the same analysis without those recurrent connections. In this case, pattern completion in CA3 was abolished (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2A</xref>, dashed green line). However, as in the data of Rolls (1995), at the output level pattern completion was not affected. This has not been discussed and we will turn to this in more detail below. In conclusion, we reproduce the main results of the model (compare <xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2A</xref> with [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>, <xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3</xref> bottom]).</p>
<fig id="pcbi.1004250.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Analysis of the model by Rolls (1995).</title>
<p><bold>A</bold>: Recall performance in the model as proposed in [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>]. Different colors show mean correlation between reconstructed patterns and stored ones in different regions; dashed lines show performance in a simulation where the recurrent connections in CA3 were turned off. <bold>B</bold>: Histogram of CA1 cell firing during storage. When sparsity is 0.01 (magenta) each cell fires about one time. This grandmother-like coding is abandoned if sparsity is 0.1 (black). <bold>C</bold>: Recall performance in CA1 (red) and EC (blue) for sparsity 0.1 measured for the last 10 patterns stored (stars) and for the first 10 (diamonds). Abandoning the grandmother-like code leads to a breakdown in performance by forgetting previously stored patterns. <bold>D</bold>: Recall performance in EC when connectivity from CA1 to EC is not complete and sparsity in CA1 is 0.01 (diamonds). A grandmother-like code cannot reproduce the whole pattern if the connectivity is sparse. When CA3-CA1 is a hetero-association with sparsity 0.1 (stars) diluting the connectivity has a milder effect. <bold>E</bold>: Our model as described in text yields similar results as in <bold>A</bold>, but is biologically more plausible, we believe.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g002"/>
</fig>
<p>While most of the parameters in the Rolls’ model are consistent with the rat hippocampal anatomy, two clearly are not. Firstly, in the model CA1 the sparsity, i.e., the proportion of cells being active, <italic>a</italic><sub><italic>CA</italic>1</sub> = 1%, is much lower compared to the other regions, but the contrary is true in the real rat hippocampus [<xref ref-type="bibr" rid="pcbi.1004250.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref034">34</xref>] (and see sparsity estimates in <xref ref-type="sec" rid="sec002">Methods</xref>). This way, many CA1 cells only code for one pattern as shown in <xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2B</xref> and the pattern a cell codes for is burned into the weights of that cell, which is reflected in a high learning rate in CA1. However, it is unrealistic to assume such a coding scheme. Since it allows CA1 to store only <inline-formula id="pcbi.1004250.e031"><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>C</mml:mi> <mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> patterns, even when numbers of cells and connections are scaled up to realistic ones of several hundreds of thousands as in the rat. This sparse coding scheme is functional, since the recall performance breaks down when we abandon it by increasing the sparsity to 10% (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2C</xref>). In particular, patterns that are stored in the beginning of learning are overwritten by patterns that are stored later.</p>
<p>Secondly, full connectivity from CA1 to EC is assumed. This property is important, too. When the connectivity is diluted like between other regions, the low activity in CA1 is unable to trigger the whole original pattern in the EC (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2D</xref>, diamonds). In this case, given a pattern in CA1, due to its high sparsity there are a few cells in EC that do not get any activation from it. However, this high connectivity is biologically not plausible.</p>
<p>To improve on these two inconsistencies we propose that, during storage, CA1 is activated by the EC via the temporoammonic pathway, that has not been considered yet. Thus, rather than a competitive one shot learning, we suggest a hetero-association between CA3 and CA1 as between EC-CA3 and CA1-EC. Now, the network recalls well even when the connectivity is not complete and the sparsity in CA1 is not unreasonably high (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2D</xref>, stars). An alternative could be to keep the one shot learning and lower the sparsity and the learning rate. However, for simplicity we choose the former option.</p>
<p>Besides the changes in CA1, we scaled the model up and adjusted all parameters to more biological plausible ones (<xref ref-type="fig" rid="pcbi.1004250.g001">Fig 1A</xref>) and simplified the activation function to a k-WTA mechanism (see <xref ref-type="sec" rid="sec002">Methods</xref> for details). Overall, these changes did not alter the behaviour of the network (<xref ref-type="fig" rid="pcbi.1004250.g002">Fig 2E</xref>), although the presence of recurrence in CA3 now has a stronger effect on pattern completion at the output stage. Notice also, that the completion of the first hetero-association from EC to CA3 is much more effective. Due to a very sparse coding in Rolls’ EC (5%) and a sparse connectivity the signal cannot be transferred properly to CA3 during recall. This is not the case in our model, since here the sparsity in EC is 35%.</p>
<p>From now on, all simulations are performed with continuous input, thus the model is now as described in the Method Section.</p>
</sec>
<sec id="sec012">
<title>Pattern Separation in DG</title>
<p>The standard framework suggests that the role of the DG is to perform pattern separation [<xref ref-type="bibr" rid="pcbi.1004250.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref009">9</xref>]. This process transforms correlated patterns in the EC into more uncorrelated ones in CA3. This is a necessary operation, since a Hopfield-like auto-associative memory in CA3 would only be efficient in storing patterns that are nearly orthogonal to each other [<xref ref-type="bibr" rid="pcbi.1004250.ref035">35</xref>]. [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>] has suggested that pattern separation can be learned by a Hebbian competitive net, however, that has not been verified computationally. We therefore investigated whether DG is a good pattern separator and whether Hebbian learning enhances this function. We compared three different simulations. One with learning in the DG enabled, one where it is disabled, and one simulation, where we modeled the DG as a perfect pattern separator. In the last case, we removed the EC-DG-CA3 pathway and instead artificially set up a random uncorrelated code in CA3 for storage. Each set of simulations were performed with random input and more realistic grid cell input (see <xref ref-type="sec" rid="sec002">Methods</xref>).</p>
<p>As one might expect, with random input there are no great differences in performance between the three simulations (Fig <xref ref-type="fig" rid="pcbi.1004250.g003">3B</xref>–<xref ref-type="fig" rid="pcbi.1004250.g003">3D</xref>). Patterns in the EC input are already uncorrelated by construction. This low degree of correlation is then just transferred to CA3. Hebbian learning in connections between EC and DG is not able to remove any more correlation (<xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3A</xref>). Since the pairwise correlation in CA3 is not linearly dependent on the ones in EC (r value ranges from -0.01 to 0.12), the pattern separation index is not reliable here.</p>
<fig id="pcbi.1004250.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Pattern separation in the DG with random input.</title>
<p><bold>A</bold>: Pairwise correlation between stored patterns in CA3 as a function of pairwise correlation in EC with learning in DG (green), without (blue) and when the CA3 code is set up randomly (red). Regression lines are plotted, r values are shown in the upper left. <bold>B-D</bold>: Recall performance of the different simulations in CA3 (<bold>B</bold>), CA1 (<bold>C</bold>) and EC (<bold>D</bold>). Dashed lines are simulations where the recurrent connections in CA3 have been removed.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g003"/>
</fig>
<p>By contrast, with grid cell input from the EC, Hebbian learning has a strong effect on the network. One observation is the different firing behaviour of CA3 cells. Since each input pattern refers to one location in space, we can illustrate the firing of CA3 cells over all stored patterns plotted over the environment (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4A</xref>). Note that only 252 of the 400 locations can be occupied, as only 252 patterns were selected for storage. We observe that after learning, many cells in CA3 establish place fields. They fire around certain locations, but are silent elsewhere. This is in accordance to other work that have shown that Hebbian learning indeed transforms grid cell code into a place field representation [<xref ref-type="bibr" rid="pcbi.1004250.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref040">40</xref>]. Consequently, the probability a CA3 cell fires at location <italic>s</italic> given it fires at location <italic>t</italic> is significantly higher when the Euclidean distance between these locations is small than when they are far away (green line in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4I</xref>). When learning is disabled, a typical cell in CA3 fires scattered over the entire space and is more comparable to a CA3 cell that is created randomly, as in the third simulation. Hence, the probability it fires at <italic>s</italic> is no longer dependent on the distance to <italic>t</italic> in the random CA3 case (red curve in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4I</xref>). This dependency is weaker when the DG connections are static (blue curve). In particular, the dependency extends to a smaller radius.</p>
<fig id="pcbi.1004250.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Pattern separation in the DG with grid cell input.</title>
<p><bold>A</bold>: Firing of three typical CA3 cells across all stored patterns plotted over the environment. Colour code as in <xref ref-type="fig" rid="pcbi.1004250.g003">Fig 3</xref>. <bold>B</bold>: Pairwise correlation between stored patterns in CA3 as a function of pairwise correlation in EC. Number next to regression line show its slope, r-values are shown in the upper right. <bold>C-E</bold>: Recall performance of the different simulations in CA3 (<bold>C</bold>), CA1 (<bold>D</bold>) and EC (<bold>E</bold>). Dashed lines are simulations without recurrent connections in CA3. <bold>F</bold>: Distribution of activities during recall when a cell fires during storage (solid) or is silent during storage (dashed) in CA3 when noiseless cues are given. <italic>S</italic> = ⟨<italic>S</italic><sub><italic>t</italic></sub>⟩<sub><italic>t</italic></sub> indicates the average signal term in <xref ref-type="disp-formula" rid="pcbi.1004250.e013">Eq (5)</xref>. <bold>G</bold>: Distribution of crosstalk terms of cells that fire (solid) and are silent during storage (dashed). <bold>H</bold>: Average overlap of two pattens <bold>p</bold><sup>(<italic>s</italic>)</sup> and <bold>p</bold><sup>(<italic>t</italic>)</sup> in the EC plotted over the distance of <italic>s</italic> and <italic>t</italic>. <bold>I</bold>: Probability that a CA3 cell fires at a location s given it fires at t plotted over the Euclidean distance of s and t. Inset shows zoomed plot. <bold>J</bold>: Average Overlap of two pattens <bold>p</bold><sup>(<italic>s</italic>)</sup> and <bold>p</bold><sup>(<italic>t</italic>)</sup> in the EC plotted over the probability a cell fires at <italic>s</italic> given it fires at <italic>t</italic>. <bold>K</bold>: Probability a cell fires at s, given it is silent at t. Inset shows zoomed plot. <bold>L</bold>: Same as <bold>F</bold> but in CA1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g004"/>
</fig>
<p>More interestingly, we find that Hebbian learning does not support pattern separation. To the contrary, we have measured the pairwise correlation between all stored patterns in CA3 and in EC and we have found that some patterns are highly similar in CA3 (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4B</xref>) when learning is enabled. This is a direct consequence of the established place-field-like code in CA3. Patterns referring to close locations are very similar. Without learning, we do not see patterns of such high correlation, since CA3 cells are not as spatially selective as before. This is in line with the lower pattern separation index of the static DG (0.15) compared to the plastic one (0.28). In the simulation where the DG is modeled as a perfect separator the correlation between two patterns is distributed around zero and no high correlations are found by definition.</p>
<p>In simulations without recurrent connections, the consequence of a place-field-like code in CA3 is a better recall performance in CA3 compared to the other scenarios, but a worse one at the output level in the EC (Fig <xref ref-type="fig" rid="pcbi.1004250.g004">4C</xref>–<xref ref-type="fig" rid="pcbi.1004250.g004">4E</xref>, dashed lines). To investigate the reason for the improvement in CA3 in this simulation, we looked at the activity distributions of cells during recall with a noiseless cue. We distinguished between activities of cells that should fire given the present recall cue and those of cells that should be silent. To no surprise, we find that the mean of the former is much higher. With plasticity in the DG the two distributions have very little overlap (green curves in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4F</xref>). Thus, it is very rare that a cell that should be silent receives more activation than a cell that should be active. Hence, very few mistakes are made. In contrast, if the CA3 code is random, these distributions overlap more and false behaviour occurs more often.</p>
<p>What is the origin of this effect? In <xref ref-type="disp-formula" rid="pcbi.1004250.e013">Eq (5)</xref> we expressed the activation of cell <italic>i</italic> given the noiseless recall cue <bold>p</bold><sup>(<italic>t</italic>)</sup> as the sum of the signal <italic>S</italic><sub><italic>t</italic></sub> and the crosstalk terms. In the random case, the activations of cells that should be silent are distributed around 0. Here, in each activation the signal term vanishes (because <inline-formula id="pcbi.1004250.e032"><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) and it is only influenced by the sum of crosstalk terms. For the activations of cells that should fire, the signal term does not vanish (because <inline-formula id="pcbi.1004250.e033"><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) and the distribution is shifted to the right by the average signal <italic>S</italic> = ⟨<italic>S</italic><sub><italic>t</italic></sub>⟩<sub><italic>t</italic></sub> while its shape is preserved (we find that the variance of <italic>S</italic> is negligible). Hence, the sums of crosstalk terms are not dependent on whether a cell fired during storage or not.</p>
<p>In contrast, in a place-field-like code these distributions are not just shifted by <italic>S</italic>. Here, crosstalk terms tend to be larger, when a cell is supposed to fire (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4G</xref>). Note that each crosstalk term <italic>X</italic><sub>(<italic>i</italic>,<italic>s</italic>,<italic>t</italic>)</sub> is proportional to <inline-formula id="pcbi.1004250.e034"><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, the firing of cell <italic>i</italic> at location <italic>s</italic>, times the overlap <inline-formula id="pcbi.1004250.e035"><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mtext mathvariant="bold">p</mml:mtext> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of the input pattern at location <italic>s</italic> with the cue. Suppose cell <italic>i</italic> has fired at <italic>t</italic>, as seen in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4I</xref>, <inline-formula id="pcbi.1004250.e036"><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is more likely to be non zero when location <italic>s</italic> is nearby location <italic>t</italic>. Additionally, due the spatial character of the grid cell input, the overlap is highly dependent on the distance, too, and is maximal when the locations are close by (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4H</xref>). Thus, the more likely <inline-formula id="pcbi.1004250.e037"><mml:math id="M37" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the higher is the overlap as shown in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4J</xref> (green dots). This is not true when cell <italic>i</italic> has been silent at <italic>t</italic> (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4K</xref>). Here, the cell is less likely to fire at nearby locations and hence crosstalk terms with a large overlap factor do vanish at least as often as others. Therefore, crosstalks are greater in cells that should be active than in cells that should not. This explains the higher activation of cells that should be active and the better performance.</p>
<p>When learning is disabled the probability of <inline-formula id="pcbi.1004250.e038"><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is less dependent on the distance of <italic>s</italic> and <italic>t</italic>. Hence, the relation of the overlap with <inline-formula id="pcbi.1004250.e039"><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is less pronounced (blue dots in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4J</xref>). Consequently, this relation disappears in a random CA3 code, since here a CA3 cell fires entirely independently on the distance (red dots in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4J</xref>).</p>
<p>The advantage in performance when learning is enabled, however, is already gone at the CA1 stage (dashed lines in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4D</xref>). Due to the high similarity of some patterns in CA3, some crosstalk terms in CA1 become very large. The consequence is a high variance of the sum of crosstalks and hence wider distributions of activities of cells that should be active and of those that should not. This results in a high overlap between these two distributions, thus many errors are made (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4L</xref>).</p>
<p>Without Hebbian learning in the DG and in the simulation where the DG is a perfect separator, we do not see this high variance because of the lack of patterns that are highly similar. Here, the distributions are sharper resulting in less overlap and fewer mistakes (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4L</xref>).</p>
<p>Furthermore, the recall correlations in CA3 without recurrent connections are very low, in particular when the CA3 patterns are created randomly (red dashed line in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4C</xref>). This requires an explanation.</p>
<p>Even though the 252 patterns stored in CA3 are orthogonal and span a high dimensional space, due to the high correlations in the grid input, the learned EC-CA3 weights, span a much lower dimensional space. When CA3 patterns are projected into this low-dimensional subspace, the correlation between recalled and stored patterns are high, i.e., the EC-CA3 hetero-association works in principle. However, when assessing the retrieval quality, we compare the retrieved to the stored pattern in the larger dimensional space of CA3 patterns. Since the EC-CA3 weights span a low-dimensional space, they cannot address the higher dimensional space and, therefore, the correlations between stored and recalled patterns are low, and the dashed red line in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4C</xref> is far below the diagonal.</p>
<p>The recurrent collaterals in CA3 are doing their job well in the random CA3 case since the solid red line is well above the dashed one in <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4C</xref>. However, the solid red line is still barely above the diagonal for low to moderate cue quality and well below for high cue quality, because the auto-associative net cannot entirely overcome the limitation of the EC-CA3 projections. As in the network without recurrent connections, when patterns are projected onto the low-dimensional subspace, recall performance would be much better. That information about the stored input patterns is preserved in CA3, despite the low retrieval correlations, is evident when examining the later stages of hippocampal processing, in CA1 (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4D</xref>) and EC output (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4E</xref>). There, the retrieval performance is quite high for random CA3 patterns. The fact that it is better than for the static or plastic DG case confirms that auto-associative networks perform best for uncorrelated (CA3) patterns.</p>
<p>For the static and plastic DG case, we find that without recurrent connections performance is better than for random CA3 patterns (<xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4C</xref>, green and blue dashed lines lie above red dashed line) and that the difference between recurrent and no recurrent connections is less pronounced (compare respective solid to dashed lines). These findings lend further support to our explanation for the retrieval correlations for random CA3 patterns. When DG is static or plastic, the pattern in CA3 is driven to a certain extend by the EC input (via DG) and thus is correlated with it. Therefore, the mismatch between the dimensionality of the CA3 patterns and that of the EC inputs is lower and, as a result, the retrieval correlations in CA3 are higher. However, the correlations between stored CA3 patterns reduce the ability of the CA3 recurrent network to perform pattern completion, which hurts retrieval performance in the downstream layers (Fig <xref ref-type="fig" rid="pcbi.1004250.g004">4D</xref> and <xref ref-type="fig" rid="pcbi.1004250.g004">4E</xref>).</p>
<p>To summarize, Hebbian plasticity does not enhance pattern separation as suggested in [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>]. When grid input is given, it has even the contrary effect and hence harms memory performance. Moreover, we find that a static DG performs decent pattern separation. Therefore, in the following analysis learning in the DG is disabled.</p>
</sec>
<sec id="sec013">
<title>Pattern Completion in CA3</title>
<p>To test the hypothesis that CA3 functions as an auto-associative memory, we compared a simulation of the complete network with one, where we disabled the recurrent connections. Once again, we perform this comparison for random and grid cell inputs.</p>
<p>When random inputs are presented, we indeed find the recurrent connections performing a fair amount of pattern completion in CA3 (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5A</xref>) as also found by [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>]. At the output stage in the EC, however, the recurrent connections in CA3 are only beneficial when cues are highly degraded. Both simulations with and without recurrent CA3 connections perform equally well for strong to moderate cue qualities (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5B</xref>). Thus, in these cases the hetero-associative steps EC-CA3, CA3-CA1 and CA1-EC are already sufficient for pattern completion.</p>
<fig id="pcbi.1004250.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Recall performance of the model with random input.</title>
<p>Performance in CA3 (left column) and in EC (right column). <bold>A-B</bold>: Recall performance in CA3 and EC; dashed lines are simulations without recurrent connections. <bold>C-D</bold>: Proportion of correctly retrieved cues. Left side in inset of <bold>C</bold> illustrates that the cue (star) is retrieved correctly. The reconstruction is most correlated with corresponding stored pattern (star) compared to the other stored pattern (moon and sun). Right side shows when cue is confused with another stored pattern. Here the reconstruction is more correlated with the sun than with the star. Coloured bars explain code in <bold>E-H</bold>. <bold>E-F</bold>: Histogram of pairwise correlations between reconstructed pattern and corresponding stored pattern (cyan, blue) and between reconstructed pattern and another stored pattern (red). Blue indicate the cases when the correlation between the reconstructed pattern and the stored pattern is not maximal. Star marks mean of the distribution of the correlation between the reconstructed pattern and the stored pattern. The histogram is calculated at the cue quality indicated by the red rhombus in <bold>A-D</bold>. <bold>G-H</bold>: Same as <bold>E-F</bold> but with recurrent connections enabled.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g005"/>
</fig>
<p>One can argue that a good recall performance does not only include a high correlation between reconstructed and original pattern, but also require that the recalled pattern is more similar to the original one than to any other one. To investigate this, we compared the correlation between a reconstructed pattern and its original stored version with the correlations between this reconstructed pattern and all other stored patterns. If the pattern is remembered correctly, the former correlation should be larger than all of the latter ones. Otherwise, the recall cue has been reconstructed closer to a wrong pattern and hence it has been confused by the network as another stored pattern (see inset of <xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5C</xref> for illustration). We find that the simulations using the recurrent connections do confuse patterns more often when cue qualities are poor than do simulations without recurrent connections (Fig <xref ref-type="fig" rid="pcbi.1004250.g005">5C</xref>–<xref ref-type="fig" rid="pcbi.1004250.g005">5D</xref>). At moderate to high cue qualities, the performance is equal with and without recurrent network.</p>
<p>In more detail, the mean of the distribution of correlations between the reconstructed patterns and their original version is increased by the recurrent connections, which is good. However, at the same time, this distribution becomes wider and even bimodal. Thus, it begins to intersect with the distribution of correlations between the reconstructed patterns and all other stored pattern. Consequently, it starts to confuse reconstructed patterns with the other stored ones (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5G</xref>). This confusion cannot be solved at later stages and the correlation between these patterns and their originals stays low till the output stage (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5H</xref>). The result is a bimodal distribution of correctly remembered patterns with high correlation and false recalled ones with correlation around 0. When the recurrent connections are disabled, the distribution of correlations in the EC stays unimodal with a lower mean but fewer patterns are confused (<xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5F</xref>).</p>
<p>To summarize, for moderate to good cue qualities, the computation of the recurrent connections is completely redundant, since the pattern completion is also performed by the inevitable decoding pathway over CA1. For weak cues, the recurrent connections do help recall, but this advantage comes at the price of a higher confusion rate.</p>
<p>We also tested how effective the pattern completion by the recurrent connections is in the grid cell input scenario. We observe that having these connections helps in CA3 only marginally, but at the price of a significantly higher confusion rate (Fig <xref ref-type="fig" rid="pcbi.1004250.g006">6A</xref>–<xref ref-type="fig" rid="pcbi.1004250.g006">6H</xref>). More importantly, at the output level in EC the recurrent connections become a deficiency for the model and the performance is worse. Additionally, the higher confusion rate is still apparent. Thus, the recurrent connections are not only redundant but even harmful for memory performance for all cue qualities.</p>
<fig id="pcbi.1004250.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Recall performance of the model with grid input.</title>
<p>Effect of recurrent connections when grid cell input is given. Plotting conventions as in <xref ref-type="fig" rid="pcbi.1004250.g005">Fig 5</xref>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g006"/>
</fig>
</sec>
<sec id="sec014">
<title>Recall by the EC-CA1-EC Pathway</title>
<p>An alternative proposal is that pattern completion is performed by the pathway EC-CA1-EC [<xref ref-type="bibr" rid="pcbi.1004250.ref013">13</xref>]. Our data shows that recurrence in CA3 is redundant and that three hetero-associations are sufficient for completion. We investigated, whether the two associations EC-CA1-EC are sufficient for pattern completion as well. The results are shown in <xref ref-type="fig" rid="pcbi.1004250.g007">Fig 7</xref>.</p>
<fig id="pcbi.1004250.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Comparison of the complete model with the simpler EC-CA1-EC model.</title>
<p>Performance of the complete model (green and blue) and of the simpler EC-CA1-EC model (magenta) when random input is given (<bold>A-D</bold>) and grid input is given (<bold>E-H</bold>). <bold>A</bold>: Recall performance in CA3 (complete model) and CA1 (simpler model). <bold>B</bold>: Performance in EC. <bold>C-D</bold>: Proportion of correctly retrieved patterns in CA3/CA1 (<bold>C</bold>) and EC (<bold>D</bold>), respectively; dashed lines are simulations without recurrent connections. <bold>E-H</bold>: Same as left column, but with grid cell input.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g007"/>
</fig>
<p>When input patterns are created randomly, the simpler model confuses fewer patterns (Fig <xref ref-type="fig" rid="pcbi.1004250.g007">7C</xref>–<xref ref-type="fig" rid="pcbi.1004250.g007">7D</xref>), but performance in terms of correlation is worse than with the complete network (Fig <xref ref-type="fig" rid="pcbi.1004250.g007">7A</xref>–<xref ref-type="fig" rid="pcbi.1004250.g007">7B</xref>). It seems that in this scenario two steps are not sufficient to reconstruct the whole pattern. Interestingly, in the more realistic grid cell input scenario, the two steps in the alternative model are slightly more effective in pattern completion than the complete network (Fig <xref ref-type="fig" rid="pcbi.1004250.g007">7E</xref>–<xref ref-type="fig" rid="pcbi.1004250.g007">7F</xref>). Moreover, the former confuses far fewer patterns than the latter (Fig <xref ref-type="fig" rid="pcbi.1004250.g007">7G</xref>–<xref ref-type="fig" rid="pcbi.1004250.g007">7H</xref>).</p>
<p>We wondered whether scaling factors effect the model. Thus, we performed simulations as in <xref ref-type="fig" rid="pcbi.1004250.g007">Fig 7</xref> where we scaled down the number of neurons by only 20 rather than by 100. We stored 252 ⋅ 5 patterns while leaving all other parameters constant. In particular, the number of synapses is still scaled by 10. We find no qualitative differences between the simulations indicating that our results do not change when numbers of cells and synapses approach the realistic ones.</p>
</sec>
<sec id="sec015">
<title>LEC Input and Different Environments</title>
<p>Up to now we have considered only input to the hippocampus that originates from the medial part of the entorhinal cortex. Studies have shown that substantial part of hippocampal input comes from the lateral entorhinal cortex (LEC). In contrary to the grid cells, neurons in LEC fire only weakly spatially modulated [<xref ref-type="bibr" rid="pcbi.1004250.ref041">41</xref>] and rather respond to individual objects [<xref ref-type="bibr" rid="pcbi.1004250.ref033">33</xref>]. How do the networks behave under the influence of such input? Since the proportion of LEC input relative to MEC input is not clear, we parametrized it and performed simulations with different proportions of LEC cells. We find that the recall correlations in EC are not affected much by adding LEC input (<xref ref-type="fig" rid="pcbi.1004250.g008">Fig 8A</xref>). When input comes only from LEC the networks confuse patterns more often. Because of the pseudo place field code in LEC, nearby patterns are highly correlated and the radius to which this extends is slightly larger than in the grid cell code ((compare <xref ref-type="fig" rid="pcbi.1004250.g008">Fig 8G</xref> with <xref ref-type="fig" rid="pcbi.1004250.g004">Fig 4B</xref>)). Consequently, the number of high correlated patterns is higher which results in a higher confusion as well as in a slightly less effective pattern separation.</p>
<fig id="pcbi.1004250.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004250.g008</object-id>
<label>Fig 8</label>
<caption>
<title>LEC input and multiple environments.</title>
<p>Results of simulations with additional LEC input (<bold>A-C</bold>) and with input from multiple environments (<bold>D-F</bold>). First row (<bold>A, D</bold>) shows the recall correlation in EC averaged over all cue strengths, second row (<bold>B, E</bold>) shows averaged proportion of correctly retrieved patterns and last row (<bold>C, F</bold>) shows pattern separation index. <bold>G</bold>: Pairwise correlation between stored patterns in CA3 as a function of pairwise correlation in EC in a simulation with only LEC inputs. Euclidean distance (in m) of the pair is indicated by the colour of disk according to the colourbar. Black line is the regression line with slope s (separation index) and r value shown in the upper left. <bold>H-I</bold>: Same as (<bold>G</bold>) in a simulation with only MEC input originating from nine different environments. <bold>H</bold> shows all pairs where both patterns come from the same map, <bold>I</bold> show all pairs where the patterns come from different maps.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004250.g008"/>
</fig>
<p>Fyhn et al. (2007) found that when a rat is exposed to a new environment the grid cells remap, i.e. their grid pattern rotates and shifts coherently while the spatial frequency remains roughly stable [<xref ref-type="bibr" rid="pcbi.1004250.ref026">26</xref>]. We investigated how well the networks can store patterns of activity originating from different environments rather than from just one. We find that by increasing the number of maps, the recall correlations and the proportion of correctly retrieved patterns of the networks with and without recurrent connections become almost equal, where the EC-CA1-EC network remains the best in both measures (Fig <xref ref-type="fig" rid="pcbi.1004250.g008">8D</xref>–<xref ref-type="fig" rid="pcbi.1004250.g008">8E</xref>).</p>
<p>As argued above, already a small number of moderately correlated patterns in CA3 degrades the auto-association and the subsequent hetero-association with CA1. Given just one map, correlation appears only in patterns that are nearby. We wondered, whether this is still true comparing patterns from different environments. In Fig <xref ref-type="fig" rid="pcbi.1004250.g008">8H</xref>–<xref ref-type="fig" rid="pcbi.1004250.g008">8I</xref> we see the pairwise correlations of stored patterns in CA3 over the ones in the input in a simulation where we store patterns from nine different environments. Comparing patterns that originate from the same map, only those that are up to 5 cm apart have a high correlation above 0.6 and these are the only pairs, that remain to have moderate correlations left in CA3(<xref ref-type="fig" rid="pcbi.1004250.g008">Fig 8H</xref>). Many pairs, that are not nearby, have a fair correlation in the input but are almost uncorrelated after pattern separation through the DG. This can be observed for pairs where each pattern is from a different environment, too(<xref ref-type="fig" rid="pcbi.1004250.g008">Fig 8I</xref>). Many of them are moderately correlated in the input, but no longer in CA3. The remapping of the grids does not orthogonalizes the activities in the EC. Nevertheless, after pattern separation by the DG the patterns become almost uncorrelated in CA3.</p>
<p>To conclude, when patterns are stored from several environments, the relative number of pattern pairs that are nearby and from the same environment decreases and with it the number of pairs with remaining correlation in CA3. This benefits in particular the recurrent network and it performs as well as the network without recurrent connections. Nevertheless, the EC-CA1-EC network performance is best in all scenarios.</p>
</sec>
</sec>
<sec id="sec016" sec-type="conclusions">
<title>Discussion</title>
<p>In the last decades, a view has evolved about how the peculiar anatomic structure of the hippocampus serves memory formation. It has been postulated that the CA3 region with its many recurrent connections functions as an attractor network performing pattern completion when degraded input is given [<xref ref-type="bibr" rid="pcbi.1004250.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref011">11</xref>]. Thus, it is believed that CA3 is the actual storing place. Complex mathematical analysis show that the memory capacity of such a network is sufficient, when the activity in the region is sparse enough [<xref ref-type="bibr" rid="pcbi.1004250.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref042">42</xref>]. However, a decorrelation among the stored patterns is crucial and all the analysis supposes that. It is believed that the DG removes all correlations from the input patterns of the EC and performs the so called pattern separation. This is supported by a sparse coding, by strong and sparse synapses from DG to CA3 [<xref ref-type="bibr" rid="pcbi.1004250.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref011">11</xref>], and by Hebbian plasticity from EC to DG during storage [<xref ref-type="bibr" rid="pcbi.1004250.ref005">5</xref>].</p>
<p>The present study challenges this view and shows several weaknesses of it. Firstly, in the mathematical analysis of the standard framework only an isolated CA3 network has been considered and the inevitable decoding pathway via CA1 has been neglected. We show that this pathway is capable of reconstructing the memory even when the recurrent connections in CA3 are removed. This makes the assigned auto-associative function of CA3 redundant for low to moderate noise levels. Interestingly, by arguing for CA3 being an attractor network, Treves and Rolls (1991) compared the ability of pattern completion of an auto-associative network with that of subsequent hetero-associative networks [<xref ref-type="bibr" rid="pcbi.1004250.ref042">42</xref>]. They conclude that when the sparsity of the activity approaches zero, the performance of a single auto-associative memory reaches nearly that of several hetero-associations, while at the same time fewer neuronal components are needed. However, in the standard model these components have to be present to perform encoding and decoding, turning this argument against the proposed function of CA3.</p>
<p>Secondly, simple Hebbian plasticity in the DG as proposed by Rolls (1995) does not support pattern separation. To the contrary. We have shown that due to this plasticity the grid cell code in the EC is mapped into a place field like code in CA3. This is in line with other work, that investigate the transformation from grid cells to place cells [<xref ref-type="bibr" rid="pcbi.1004250.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004250.ref040">40</xref>] by Hebbian learning. In this code, patterns from nearby locations happen to be highly correlated, which is the opposite of what a pattern separator should do. Thus, a competitive net is not a good candidate to orthogonalize patterns for grid cell input. What is not modeled here, is adult neurogenesis in the DG [<xref ref-type="bibr" rid="pcbi.1004250.ref043">43</xref>]. This additional plasticity might support pattern separation in contrast to Hebbian learning alone. Weisz and Argibay (2009) studied the effects of neurogenesis in the standard model and they find advantages in memory performance, but they only considered the case of random inputs [<xref ref-type="bibr" rid="pcbi.1004250.ref044">44</xref>]. However, alternative hypotheses for adult neurogenesis exist (e.g [<xref ref-type="bibr" rid="pcbi.1004250.ref018">18</xref>]). We show that by having random and fixed connections the DG performs quite well as a pattern separator. Only for very highly correlated patterns in the input, there remains some amount of correlation in these patterns after applying the separator. Despite the significant reduction, this amount is still enough to degrade the auto-associative CA3. Thus, to make the standard model work, a separator is needed that functions perfectly. However, assuming it exists, the benefit of a recurrent CA3 net would still be small compared to the EC-CA1-EC model if applied to grid cell input.</p>
<p>Thirdly, a further challenging argument against an auto-associative function of CA3 is the fact that the actual representations in the mammalian CA3 are far from uncorrelated. The vast majority of active pyramidal cells are place cells [<xref ref-type="bibr" rid="pcbi.1004250.ref045">45</xref>], thus activity patterns are correlated by nature. Storing such patterns of continuous place cell activity that occur in one environment in an auto-associative network leads to a continuous attractor or so called chart [<xref ref-type="bibr" rid="pcbi.1004250.ref046">46</xref>]. Every point in this chart refers to the neural representation of one location in the environment. A degraded input is then attracted towards a point on the chart and the network is indeed able to diminish the noise orthogonal to the attractor. However, it has been observed that many points are not stable [<xref ref-type="bibr" rid="pcbi.1004250.ref047">47</xref>] and drift along the attractor until they reach a fix point [<xref ref-type="bibr" rid="pcbi.1004250.ref048">48</xref>]. This means that many finally retrieved patterns are representations of the wrong location. Since we store correlated patterns in the auto-associative CA3 net, a continuous attractor is also formed in the present model. It can store a large number of patterns drawn from the grid map moderately well, however, drifting occurs in the recall. This drifting is already reduced, since the CA3 representations are binary rather than continuous [<xref ref-type="bibr" rid="pcbi.1004250.ref049">49</xref>], but still apparent as reflected by the high confusion rate of patterns when using the recurrent connections in CA3 (see <xref ref-type="fig" rid="pcbi.1004250.g006">Fig 6C</xref>). Papp et al.(2007) state that the drift may be much slower than pattern completion and hence storage of locations is still possible [<xref ref-type="bibr" rid="pcbi.1004250.ref049">49</xref>]. In other words, pattern completion is already done in the first update cycles in the attractor network. This is in agreement with our results. By viewing each hetero-associative step as one update cycle, pattern completion is performed by the three associative networks without loosing accuracy caused by the drift and the auto-associative function in CA3 becomes redundant.</p>
<p>Finally, given the structured grid cell input in the EC, the simpler network EC-CA1-EC is already sufficient for storage and pattern completion. Additionally, it confuses memories less often than the complete network does. This frees the recurrent CA3 connections to perform other functions. For instance, Levy (1996) suggested that CA3 associates its present activity with activity occurring in the past [<xref ref-type="bibr" rid="pcbi.1004250.ref050">50</xref>]. In this way, sequences of activities are stored which can explain the hippocampal involvement in tasks like trace conditioning or configural learning problems. A further alternative to an attractor net in CA3 has been suggested by Cheng (2013). Here, it is assumed that the recurrent CA3 network is not plastic, but rather creates intrinsic sequences which are then associated with temporal sequences of patterns in the EC [<xref ref-type="bibr" rid="pcbi.1004250.ref013">13</xref>]. We do not model temporal aspects here, but our study shows that because of the redundancy of CA3 as an auto-associative net, it very likely fulfils some other function. Similarly, the minimal model does not require plasticity in the synapses projecting from EC to CA3 nor in the Schaffer Collaterals, where plasticity has been found [<xref ref-type="bibr" rid="pcbi.1004250.ref051">51</xref>]. Hence, the plasticity could serve another function leaving the pattern completion in the model unaffected.</p>
<p>Experimental studies reported evidence for CA3 being an auto-association memory. For example, Gold and Kesner (2005) show that rats with lesioned CA3 are impaired in remembering a location when parts of the spatial cues are removed [<xref ref-type="bibr" rid="pcbi.1004250.ref052">52</xref>]. Another study obtains similar results when plasticity in CA3 synapses is corrupted in knock-out mice [<xref ref-type="bibr" rid="pcbi.1004250.ref053">53</xref>]. The authors conclude that CA3 is crucial for spatial pattern completion. In our opinion this is not convincing. If the actual storing place of the memory is CA3 then lesioning it or removing plasticity should give equivalent results as lesioning the entire hippocampus [<xref ref-type="bibr" rid="pcbi.1004250.ref013">13</xref>]. This is not the case, since in both studies animals behave normally in full cue conditions, but animals with hippocampal lesions are clearly impaired [<xref ref-type="bibr" rid="pcbi.1004250.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref055">55</xref>]. An alternative interpretation for the experimental observations could be that the animals rely more on the integration of self motion cues in conditions when external cues are poor. This is in line with others who assign a path integration function to CA3 [<xref ref-type="bibr" rid="pcbi.1004250.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref056">56</xref>]. If spatial information provided by the external cues is sufficient, spatial recognition can be performed by CA1 alone [<xref ref-type="bibr" rid="pcbi.1004250.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1004250.ref058">58</xref>].</p>
<p>Our work illustrates how essential it is to consider the whole hippocampal loop while investigating individual functional roles of the subregions.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004250.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Milner</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Corkin</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Teuber</surname> <given-names>J</given-names></name> (<year>1968</year>) <article-title>Further analysis of the hippocampal amnesic syndrome: A 14-year follow-up study of HM</article-title>. <source>Neuropsychologia</source> <volume>6</volume>: <fpage>215</fpage>–<lpage>234</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0028-3932(68)90021-3" xlink:type="simple">10.1016/0028-3932(68)90021-3</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Gluck</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Myers</surname> <given-names>CE</given-names></name> (<year>2001</year>) <source>Gateway to memory</source>. <publisher-loc>Cambridge, MA, USA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Leutgeb</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name> (<year>2007</year>) <article-title>Pattern separation in the dentate gyrus and CA3 of the hippocampus</article-title>. <source>Science</source> <volume>315</volume>: <fpage>961</fpage>–<lpage>966</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1135801" xlink:type="simple">10.1126/science.1135801</ext-link></comment> <object-id pub-id-type="pmid">17303747</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Amaral</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Ishizuka</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Claiborne</surname> <given-names>BJ</given-names></name> (<year>1990</year>) <article-title>Neurons, numbers and the hippocampal network</article-title>. <source>Progress in Brain Research</source> <volume>83</volume>: <fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0079-6123(08)61237-6" xlink:type="simple">10.1016/S0079-6123(08)61237-6</ext-link></comment> <object-id pub-id-type="pmid">2203093</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name> (<year>1995</year>) <article-title>A model of the operation of the hippocampus and enthorhinal cortex in memory</article-title>. <source>International Journal of Neural Systems</source> <volume>6</volume>: <fpage>51</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Marr</surname> <given-names>D</given-names></name> (<year>1971</year>) <article-title>Simple memory: a theory for archicortex</article-title>. <source>Philosophical Transactions of the Royal Society of London, Series B</source> <volume>262</volume>: <fpage>23</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.1971.0078" xlink:type="simple">10.1098/rstb.1971.0078</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Morris</surname> <given-names>RGM</given-names></name> (<year>1987</year>) <article-title>Hippocampal synaptic enhancement and information storage within a distributed memory system</article-title>. <source>Trends in Neurosciences</source> <volume>10</volume>: <fpage>408</fpage>–<lpage>415</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0166-2236(87)90011-7" xlink:type="simple">10.1016/0166-2236(87)90011-7</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name> (<year>1994</year>) <article-title>Computational analysis of the role of the hippocampus in memory</article-title>. <source>Hippocampus</source> <volume>4</volume>: <fpage>374</fpage>–<lpage>391</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.450040319" xlink:type="simple">10.1002/hipo.450040319</ext-link></comment> <object-id pub-id-type="pmid">7842058</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name> (<year>1994</year>) <article-title>Hippocampal conjunctive encoding, storage, and recall: avoiding a trade-off</article-title>. <source>Hippocampus</source> <volume>4</volume>: <fpage>661</fpage>–<lpage>682</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.450040605" xlink:type="simple">10.1002/hipo.450040605</ext-link></comment> <object-id pub-id-type="pmid">7704110</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hafting</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Fyhn</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Molden</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name> (<year>2005</year>) <article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>. <source>Nature</source> <volume>436</volume>: <fpage>801</fpage>–<lpage>806</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03721" xlink:type="simple">10.1038/nature03721</ext-link></comment> <object-id pub-id-type="pmid">15965463</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name> (<year>2007</year>) <article-title>An attractor network in the hippocampus: Theory and neurophysiology</article-title>. <source>Learning &amp; Memory</source> <volume>14</volume>: <fpage>714</fpage>–<lpage>731</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/lm.631207" xlink:type="simple">10.1101/lm.631207</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tashiro</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Witter</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name> (<year>2008</year>) <article-title>What is the mammalian dentate gyrus good for?</article-title> <source>Neuroscience</source> <volume>154</volume>: <fpage>1155</fpage>–<lpage>1172</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroscience.2008.04.073" xlink:type="simple">10.1016/j.neuroscience.2008.04.073</ext-link></comment> <object-id pub-id-type="pmid">18554812</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cheng</surname> <given-names>S</given-names></name> (<year>2013</year>) <article-title>The CRISP theory of hippocampal function in episodic memory</article-title>. <source>Frontiers in Neural Circuits</source> <volume>7</volume>: <fpage>88</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncir.2013.00088" xlink:type="simple">10.3389/fncir.2013.00088</ext-link></comment> <object-id pub-id-type="pmid">23653597</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Vassilis</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bruce</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Stuart</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Imre</surname> <given-names>V</given-names></name> (<year>2010</year>) <chapter-title>Hippocampal Microcircuits</chapter-title>. <source>A Computational Modeler’s Resource</source>. <publisher-name>Springer New York</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rennó-Costa</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lisman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Verschure</surname> <given-names>P</given-names></name> (<year>2010</year>) <article-title>The mechanism of rate remapping in the dentate gyrus</article-title>. <source>Neuron</source> <volume>68</volume>: <fpage>1051</fpage>–<lpage>1058</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.11.024" xlink:type="simple">10.1016/j.neuron.2010.11.024</ext-link></comment> <object-id pub-id-type="pmid">21172608</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name> (<year>2008</year>) <article-title>Representing where along with what information in a model of a cortical patch</article-title>. <source>PLoS Comput Biol</source> <volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000012" xlink:type="simple">10.1371/journal.pcbi.1000012</ext-link></comment> <object-id pub-id-type="pmid">18369416</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Moustafa</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Myers</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Gluck</surname> <given-names>MA</given-names></name> (<year>2009</year>) <article-title>A neurocomputational model of classical conditioning phenomena: A putative role for the hippocampal region in associative learning</article-title>. <source>Brain Research</source> <volume>1276</volume>: <fpage>180</fpage>–<lpage>195</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.brainres.2009.04.020" xlink:type="simple">10.1016/j.brainres.2009.04.020</ext-link></comment> <object-id pub-id-type="pmid">19379717</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Appleby</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Kempermann</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Wiskott</surname> <given-names>L</given-names></name> (<year>2011</year>) <article-title>The role of additive neurogenesis and synaptic plasticity in a hippocampal memory model with grid-cell like input</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1001063</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001063" xlink:type="simple">10.1371/journal.pcbi.1001063</ext-link></comment> <object-id pub-id-type="pmid">21298080</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Monaco</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>L</given-names></name> (<year>2011</year>) <article-title>Modular realignment of entorhinal grid cell activity as a basis for hippocampal remapping</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>9414</fpage>–<lpage>9425</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1433-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1433-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21697391</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Vazdarjanova</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Guzowski</surname> <given-names>JF</given-names></name> (<year>2004</year>) <article-title>Differences in hippocampal neuronal population responses to modifications of an environmental context: Evidence for distinct, yet complementary, functions of CA3 and CA1 ensembles</article-title>. <source>The Journal of Neuroscience</source> <volume>24</volume>: <fpage>6489</fpage>–<lpage>6496</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0350-04.2004" xlink:type="simple">10.1523/JNEUROSCI.0350-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15269259</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Alme</surname> <given-names>CB</given-names></name>, <name name-style="western"><surname>Buzzetti</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Marrone</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Chawla</surname> <given-names>MK</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Hippocampal granule cells opt for early retirement</article-title>. <source>Hippocampus</source> <volume>20</volume>: <fpage>1109</fpage>–<lpage>1123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.20810" xlink:type="simple">10.1002/hipo.20810</ext-link></comment> <object-id pub-id-type="pmid">20872737</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Marrone</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Satvat</surname> <given-names>E</given-names></name> (<year>2011</year>) <article-title>Increased pattern separation in the aged fascia dentata</article-title>. <source>Neurobiology of Aging</source> <volume>32</volume>: <fpage>2317.e23</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neurobiolaging.2010.03.021" xlink:type="simple">10.1016/j.neurobiolaging.2010.03.021</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Satvat</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Argraves</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Marrone</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Markus</surname> <given-names>EJ</given-names></name> (<year>2011</year>) <article-title>Changes in task demands alter the pattern of zif268 expression in the dentate gyrus</article-title>. <source>The Journal of Neuroscience</source> <volume>31</volume>: <fpage>7163</fpage>–<lpage>7167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0094-11.2011" xlink:type="simple">10.1523/JNEUROSCI.0094-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21562279</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name> (<year>2004</year>) <article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1</article-title>. <source>Science</source> <volume>305</volume>: <fpage>1295</fpage>–<lpage>1298</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1100265" xlink:type="simple">10.1126/science.1100265</ext-link></comment> <object-id pub-id-type="pmid">15272123</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lee</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Yoganarasimha</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Knierim</surname> <given-names>JJ</given-names></name> (<year>2004</year>) <article-title>Comparison of population coherence of place cells in hippocampal subfields CA1 and CA3</article-title>. <source>Nature</source> <volume>430</volume>: <fpage>456</fpage>–<lpage>459</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02739" xlink:type="simple">10.1038/nature02739</ext-link></comment> <object-id pub-id-type="pmid">15229614</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fyhn</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hafting</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name> (<year>2007</year>) <article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title>. <source>Nature</source> <volume>466</volume>: <fpage>190</fpage>–<lpage>194</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature05601" xlink:type="simple">10.1038/nature05601</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>de Almeida</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Idiart</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lisman</surname> <given-names>JE</given-names></name> (<year>2009</year>) <article-title>The input–output transformation of the hippocampal granule cells: From grid cells to place fields</article-title>. <source>The Journal of Neuroscience</source> <volume>29</volume>: <fpage>7504</fpage>–<lpage>7512</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.6048-08.2009" xlink:type="simple">10.1523/JNEUROSCI.6048-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19515918</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Stent</surname> <given-names>GS</given-names></name> (<year>1973</year>) <article-title>A physiological mechanism for Hebb’s postulate of learning</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>70</volume>: <fpage>997</fpage>–<lpage>1001</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.70.4.997" xlink:type="simple">10.1073/pnas.70.4.997</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name> (<year>1977</year>) <article-title>Storing covariance with nonlinearly interacting neurons</article-title>. <source>Journal of Mathematical Biology</source> <volume>4</volume>: <fpage>303</fpage>–<lpage>321</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00275079" xlink:type="simple">10.1007/BF00275079</ext-link></comment> <object-id pub-id-type="pmid">925522</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Amit</surname> <given-names>DJ</given-names></name> (<year>1989</year>) <source>Modeling Brain Function: The World of Attractor Neural Networks</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Willshaw</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>1990</year>) <article-title>Optimal plasticity from matrix memories: What goes up must come down</article-title>. <source>Neural Comput</source> <volume>2</volume>: <fpage>85</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1990.2.1.85" xlink:type="simple">10.1162/neco.1990.2.1.85</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Stensola</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Stensola</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Solstad</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Froland</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The entorhinal grid map is discretized</article-title>. <source>Nature</source> <volume>492</volume>: <fpage>72</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11649" xlink:type="simple">10.1038/nature11649</ext-link></comment> <object-id pub-id-type="pmid">23222610</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Deshmukh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Knierim</surname> <given-names>JJ</given-names></name> (<year>2011</year>) <article-title>Representation of nonspatial and spatial information in the lateral entorhinal cortex</article-title>. <source>Frontiers in Behavioral Neuroscience</source> <volume>5</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnbeh.2011.00069" xlink:type="simple">10.3389/fnbeh.2011.00069</ext-link></comment> <object-id pub-id-type="pmid">22065409</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Mizuseki</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Royer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diba</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Buzsáki</surname> <given-names>G</given-names></name> (<year>2012</year>) <article-title>Activity dynamics and behavioral correlates of CA3 and CA1 hippocampal pyramidal neurons</article-title>. <source>Hippocampus</source> <volume>22</volume>: <fpage>1659</fpage>–<lpage>1680</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.22002" xlink:type="simple">10.1002/hipo.22002</ext-link></comment> <object-id pub-id-type="pmid">22367959</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name> (<year>1982</year>) <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>79</volume>: <fpage>2554</fpage>–<lpage>2558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.79.8.2554" xlink:type="simple">10.1073/pnas.79.8.2554</ext-link></comment> <object-id pub-id-type="pmid">6953413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Stringer</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Elliot</surname> <given-names>T</given-names></name> (<year>2006</year>) <article-title>Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning</article-title>. <source>Network</source> <volume>17</volume>: <fpage>447</fpage>–<lpage>465</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09548980601064846" xlink:type="simple">10.1080/09548980601064846</ext-link></comment> <object-id pub-id-type="pmid">17162463</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Franzius</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vollgraf</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wiskott</surname> <given-names>L</given-names></name> (<year>2007</year>) <article-title>From grids to places</article-title>. <source>Journal Computational Neuroscience</source> <volume>22</volume>: <fpage>297</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-006-0013-7" xlink:type="simple">10.1007/s10827-006-0013-7</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Si</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name> (<year>2009</year>) <article-title>The role of competitive learning in the generation of DG fields from EC inputs</article-title>. <source>Cognitive Neurodynamics</source> <volume>3</volume>: <fpage>177</fpage>–<lpage>187</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11571-009-9079-z" xlink:type="simple">10.1007/s11571-009-9079-z</ext-link></comment> <object-id pub-id-type="pmid">19301148</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Savelli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Knierim</surname> <given-names>JJ</given-names></name> (<year>2010</year>) <article-title>Hebbian analysis of the transformation of medial entorhinal grid-cell inputs to hippocampal place fields</article-title>. <source>Journal of Neurophysiology</source> <volume>103</volume>: <fpage>3167</fpage>–<lpage>3183</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00932.2009" xlink:type="simple">10.1152/jn.00932.2009</ext-link></comment> <object-id pub-id-type="pmid">20357069</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cheng</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name> (<year>2011</year>) <article-title>The structure of networks that produce the transformation from grid cells to place cells</article-title>. <source>Neuroscience</source> <volume>197</volume>: <fpage>293</fpage>–<lpage>306</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroscience.2011.09.002" xlink:type="simple">10.1016/j.neuroscience.2011.09.002</ext-link></comment> <object-id pub-id-type="pmid">21963867</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hargreaves</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Knierim</surname> <given-names>JJ</given-names></name> (<year>2005</year>) <article-title>Major dissociation between medial and lateral entorhinal input to dorsal hippocampus</article-title>. <source>Science</source> <volume>308</volume>: <fpage>1792</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1110449" xlink:type="simple">10.1126/science.1110449</ext-link></comment> <object-id pub-id-type="pmid">15961670</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name> (<year>1991</year>) <article-title>What determines the capacity of autoassociative memories in the brain?</article-title> <source>Network: Computation in Neural Systems</source> <volume>2</volume>: <fpage>371</fpage>–<lpage>397</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X/2/4/004" xlink:type="simple">10.1088/0954-898X/2/4/004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gross</surname> <given-names>CG</given-names></name> (<year>2000</year>) <article-title>Neurogenesis in the adult brain: death of a dogma</article-title>. <source>Nature Reviews Neuroscience</source> <volume>1</volume>: <fpage>67</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35036235" xlink:type="simple">10.1038/35036235</ext-link></comment> <object-id pub-id-type="pmid">11252770</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Weisz</surname> <given-names>VI</given-names></name>, <name name-style="western"><surname>Argibay</surname> <given-names>PF</given-names></name> (<year>2009</year>) <article-title>A putative role for neurogenesis in neurocomputational terms: Inferences from a hippocampal model</article-title>. <source>Cognition</source> <volume>112</volume>: <fpage>229</fpage>–<lpage>240</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cognition.2009.05.001" xlink:type="simple">10.1016/j.cognition.2009.05.001</ext-link></comment> <object-id pub-id-type="pmid">19481201</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name> (<year>1976</year>) <article-title>Place units in the hippocampus of the freely moving rat</article-title>. <source>Experimental Neurology</source> <volume>51</volume>: <fpage>78</fpage>–<lpage>109</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0014-4886(76)90055-8" xlink:type="simple">10.1016/0014-4886(76)90055-8</ext-link></comment> <object-id pub-id-type="pmid">1261644</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Samsonovich</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name> (<year>1997</year>) <article-title>Path integration and cognitive mapping in a continuous attractor neural network model</article-title>. <source>The Journal of Neuroscience</source> <volume>17</volume>: <fpage>5900</fpage>–<lpage>5920</lpage>. <object-id pub-id-type="pmid">9221787</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name> (<year>1995</year>) <article-title>Associative memory and hippocampal place cells</article-title>. <source>International Journal of Neural Systems</source> <volume>6</volume>: <fpage>81</fpage>–<lpage>86</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cerasti</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name> (<year>2013</year>) <article-title>The spatial representations acquired in CA3 by self-organizing recurrent connections</article-title>. <source>Frontiers in Cellular Neuroscience</source> <volume>7</volume>: <fpage>112</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncel.2013.00112" xlink:type="simple">10.3389/fncel.2013.00112</ext-link></comment> <object-id pub-id-type="pmid">23882184</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Papp</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Witter</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name> (<year>2007</year>) <article-title>The CA3 network as a memory store for spatial representations</article-title>. <source>Learning &amp; Memory</source> <volume>14</volume>: <fpage>732</fpage>–<lpage>744</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/lm.687407" xlink:type="simple">10.1101/lm.687407</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Levy</surname> <given-names>WB</given-names></name> (<year>1996</year>) <article-title>A sequence predicting CA3 is a flexible associator that learns and uses context to solve hippocampal-like tasks</article-title>. <source>Hippocampus</source> <volume>6</volume>: <fpage>579</fpage>–<lpage>590</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1098-1063(1996)6:6%3C579::AID-HIPO3%3E3.0.CO;2-C" xlink:type="simple">10.1002/(SICI)1098-1063(1996)6:6%3C579::AID-HIPO3%3E3.0.CO;2-C</ext-link></comment> <object-id pub-id-type="pmid">9034847</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Buchanan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mellor</surname> <given-names>J</given-names></name> (<year>2010</year>) <article-title>The activity requirements for spike timing-dependent plasticity in the hippocampus</article-title>. <source>Frontiers in Synaptic Neuroscience</source> <volume>296</volume>: <fpage>2243</fpage>–<lpage>2246</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gold</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Kesner</surname> <given-names>RP</given-names></name> (<year>2005</year>) <article-title>The role of the CA3 subregion of the dorsal hippocampus in spatial pattern completion in the rat</article-title>. <source>Hippocampus</source> <volume>15</volume>: <fpage>808</fpage>–<lpage>814</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/hipo.20103" xlink:type="simple">10.1002/hipo.20103</ext-link></comment> <object-id pub-id-type="pmid">16010664</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nakazawa</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Quirk</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Chitwood</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yeckel</surname> <given-names>MF</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Requirement for hippocampal CA3 NMDA receptors in associative memory recall</article-title>. <source>Science</source> <volume>297</volume>: <fpage>211</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1071795" xlink:type="simple">10.1126/science.1071795</ext-link></comment> <object-id pub-id-type="pmid">12040087</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Morris</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Garrud</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Rawlins</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name> (<year>1982</year>) <article-title>Place navigation impaired in rats with hippocampal lesions</article-title>. <source>Nature</source> <volume>297</volume>: <fpage>681</fpage>–<lpage>683</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/297681a0" xlink:type="simple">10.1038/297681a0</ext-link></comment> <object-id pub-id-type="pmid">7088155</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gilbert</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Kesner</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>DeCoteau</surname> <given-names>WE</given-names></name> (<year>1998</year>) <article-title>Memory for spatial location: role of the hippocampus in mediating spatial pattern separation</article-title>. <source>The Journal of Neurosciences</source> <volume>18</volume>: <fpage>804</fpage>–<lpage>810</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004250.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Colgin</surname> <given-names>LL</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jezek</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Attractor-map versus autoassociation based attractor dynamics in the hippocampal network</article-title>. <source>Journal of Neurophysiology</source> <volume>104</volume>: <fpage>35</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00202.2010" xlink:type="simple">10.1152/jn.00202.2010</ext-link></comment> <object-id pub-id-type="pmid">20445029</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brun</surname> <given-names>VH</given-names></name>, <name name-style="western"><surname>Otnass</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Molden</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Steffenach</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Witter</surname> <given-names>MP</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Place cells and place recognition maintained by direct entorhinal-hippocampal circuitry</article-title>. <source>Science</source> <volume>296</volume>: <fpage>2243</fpage>–<lpage>2246</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1071089" xlink:type="simple">10.1126/science.1071089</ext-link></comment> <object-id pub-id-type="pmid">12077421</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004250.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Steffenach</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Sloviter</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name> (<year>2002</year>) <article-title>Impaired retention of spatial memory after transection of longitudinally oriented axons of hippocampal CA3 pyramidal cells</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>99</volume>: <fpage>3194</fpage>–<lpage>3198</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.042700999" xlink:type="simple">10.1073/pnas.042700999</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>