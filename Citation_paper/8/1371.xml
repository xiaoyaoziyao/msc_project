<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-11-00191</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0019109</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Neurophysiology</subject>
              <subj-group>
                <subject>Synapses</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Neural networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Computer modeling</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
          <subject>Computer Science</subject>
        </subj-group>
      </article-categories><title-group><article-title>Artificial Astrocytes Improve Neural Network Performance</article-title><alt-title alt-title-type="running-head">Artificial Astrocytes Improve Neural Networks</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Porto-Pazos</surname>
            <given-names>Ana B.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Veiguela</surname>
            <given-names>Noha</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Mesejo</surname>
            <given-names>Pablo</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Navarrete</surname>
            <given-names>Marta</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Alvarellos</surname>
            <given-names>Alberto</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Ibáñez</surname>
            <given-names>Oscar</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Pazos</surname>
            <given-names>Alejandro</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Araque</surname>
            <given-names>Alfonso</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Departamento de Tecnologías de la Información y las Comunicaciones, Facultad de Informática, Universidad de A Coruña, Campus de Elviña, A Coruña, Spain</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Instituto Cajal, Consejo Superior de Investigaciones Científicas, Madrid, Spain</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Amédée</surname>
            <given-names>Thierry</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Centre national de la recherche scientifique, University of Bordeaux, France</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">ana.portop@udc.es</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: ABP AP A. Araque MN. Performed the experiments: NV PM. Analyzed the data: ABP AP A. Araque. Contributed reagents/materials/analysis tools: A. Alvarellos OI. Wrote the paper: A. Araque. Designed the software for simulations: AP. Implemented the software used in analysis: NV PM.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>19</day>
        <month>4</month>
        <year>2011</year>
      </pub-date><volume>6</volume><issue>4</issue><elocation-id>e19109</elocation-id><history>
        <date date-type="received">
          <day>20</day>
          <month>12</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>17</day>
          <month>3</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Porto-Pazos et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Compelling evidence indicates the existence of bidirectional communication between astrocytes and neurons. Astrocytes, a type of glial cells classically considered to be passive supportive cells, have been recently demonstrated to be actively involved in the processing and regulation of synaptic information, suggesting that brain function arises from the activity of neuron-glia networks. However, the actual impact of astrocytes in neural network function is largely unknown and its application in artificial intelligence remains untested. We have investigated the consequences of including artificial astrocytes, which present the biologically defined properties involved in astrocyte-neuron communication, on artificial neural network performance. Using connectionist systems and evolutionary algorithms, we have compared the performance of artificial neural networks (NN) and artificial neuron-glia networks (NGN) to solve classification problems. We show that the degree of success of NGN is superior to NN. Analysis of performances of NN with different number of neurons or different architectures indicate that the effects of NGN cannot be accounted for an increased number of network elements, but rather they are specifically due to astrocytes. Furthermore, the relative efficacy of NGN vs. NN increases as the complexity of the network increases. These results indicate that artificial astrocytes improve neural network performance, and established the concept of Artificial Neuron-Glia Networks, which represents a novel concept in Artificial Intelligence with implications in computational science as well as in the understanding of brain function.</p>
      </abstract><funding-group><funding-statement>The work was supported by grants from Ministry of Science and Innovation of Spain (TIN2009-07707, BFU2010-15832, CSD2010-00045), Xunta de Galicia, Spain (REGICC 2009/58, 08SIN010105PR), CYTED (Ibero-NBIC Network 209RT0366), Cajal Blue Brain, Spain, and European Union (HEALTH-F2-2007-202167). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="8"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>In Artificial Intelligence, connectionist systems are based on networks of interconnected artificial neurons that emulate brain neuronal networks <xref ref-type="bibr" rid="pone.0019109-Hopfield1">[1]</xref>, <xref ref-type="bibr" rid="pone.0019109-McCulloch1">[2]</xref>. Astrocytes have recently emerged as cellular elements actively involved in the transfer and integration of information in the brain. Indeed, astrocytes receive, process and regulate synaptic information which had led to a new concept in neuroscience, i.e., that brain function results from the coordinated activity of astrocytes and neurons in neuron-glia networks <xref ref-type="bibr" rid="pone.0019109-Araque1">[3]</xref>–<xref ref-type="bibr" rid="pone.0019109-Volterra1">[7]</xref>. However, the design of artificial neuron-glia networks, where astrocytes exchange information with neurons and which are endowed with similar properties of astrocyte-neuron communication in biological systems, is still lacking. Based on our current knowledge of nervous system function, such novel design seems a logical step to be followed by future artificial intelligence. We therefore designed artificial neuron-glia networks and investigated the consequences of the presence of artificial astrocytes on the performance of artificial neural networks.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Artificial astrocytes improve neural network performance</title>
        <p>We used multilayer feed-forward artificial neural networks with 3 to 5 layers (including input and output layers). We compared the performance efficiency to solve problems of artificial pure neural networks and the corresponding artificial neuron-glia networks, which included astrocytes that sensed and modulated neuronal connections. Artificial astrocytes were designed to resemble the signaling properties of biological astrocytes, which respond to neurotransmitters released under high synaptic activity <xref ref-type="bibr" rid="pone.0019109-Perea1">[6]</xref>, <xref ref-type="bibr" rid="pone.0019109-Grosche1">[8]</xref>–<xref ref-type="bibr" rid="pone.0019109-Porter1">[11]</xref> and regulate neurotransmission in a larger temporal scale (i.e. hundreds of milliseconds and seconds) than fast neuronal and synaptic signaling (i.e. milliseconds) <xref ref-type="bibr" rid="pone.0019109-Perea1">[6]</xref>. Consequently, artificial astrocytes 1) were stimulated by highly active neuronal connections, and 2) regulated neuronal connections with slow temporal time course. Hence, 1) astrocytes were stimulated when the associated neuronal connections were active for at least n out of m iterations (n: 2 to 3; m: 4, 6, 8), and 2) considering the time unit as a single iteration, astrocytic effects lasted 4 to 8 iterations, and the neuronal connection weights gradually increased (25%) or decreased (50%) if the associated astrocyte was active or inactive, respectively. Present neuron-glial networks had an artificial astrocyte for each neuron, and each astrocyte only responds to the activity of the associated neuron and modulates the connections of that neuron with neurons of the next (adjacent) layer. For simplicity, spatial spread of the astrocyte signal to other neurons or communication between astrocytes were not considered (see <xref ref-type="sec" rid="s3">Discussion</xref>).</p>
        <p>Artificial networks were challenged to solve four classification problems (obtained from the University of California Irvine Machine Learning Repository <xref ref-type="bibr" rid="pone.0019109-Mertz1">[12]</xref>) with different characteristics and complexities defined by the number of input variables and output parameters: 1) In Heart Disease (HD) problem, networks detected the presence or absence of disease analyzing 13 parameters from 303 patients (i.e., they were fed with 13 inputs and provided a single binomial output); 2) In Breast Cancer (BC) problem, they predicted the presence of cancer from 9 properties from 699 patients (i.e., 9 inputs; a binomial output); 3) In Iris Flower (IF) problem, networks classified 150 flowers displaying 4 characteristics (width and length of petals and sepals) into 3 different species (i.e., 4 inputs; 3 possible outputs); 4) In the Ionosphere (IS) problem, networks defined “good” or “bad” radar signals according to the state of the ionosphere analyzing 34 characteristics of 351 radar signals (i.e., 34 inputs; a binomial output).</p>
        <p>NN were trained using genetic algorithms (GA) <xref ref-type="bibr" rid="pone.0019109-Holland1">[13]</xref>–<xref ref-type="bibr" rid="pone.0019109-Yao1">[15]</xref> and NGN were trained using a learning hybrid method combining GA and the neuron-glia algorithm (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). We quantified the following parameters: 1) Training and Test accuracies: the accuracies reached during training and test; 2) Steady Training and Test accuracies: the training and test accuracies, respectively, reached at the end of the process (60, 210, 16 and 240 minutes for HD, BC, IF and IS problems, respectively); 3) Training and Test times: the mean time at which 95% of the respective steady accuracy was reached.</p>
        <p>When solving the IS problem (<xref ref-type="fig" rid="pone-0019109-g001">Figure 1A</xref>), both training and test accuracies of the NN increased over time until reaching a maximum at the end of the processes (<xref ref-type="fig" rid="pone-0019109-g001">Figure 1B, 1C</xref>). Similar behaviours were observed for the other problems. A similar developmental profile of both parameters over time was observed in NGN (<xref ref-type="fig" rid="pone-0019109-g001">Figure 1B, 1C</xref>). However, striking differences in the parameters were shown by NN and NGN.</p>
        <fig id="pone-0019109-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0019109.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Artificial astrocytes enhance neural network performance.</title>
            <p>(<bold>A</bold>) Schematic drawing representing the design of artificial neural networks without (left) and with artificial astrocytes (red stars; right) designed to solve the Ionosphere (IS) problem. (<bold>B</bold>) Representative example (left) and mean training accuracy (n = 100) vs. time for the (NN) and (NGN) solving the IS problem. (<bold>C</bold>) Representative example (left) and mean test accuracy (n = 100) vs. time for the NN and NGN solving the IS problem. (<bold>D</bold>) Mean steady training and test accuracies (left and right, respectively; n = 100) of NN and NGN solving the four problems tested. (<bold>E</bold>) Mean training and test times (left and right, respectively; n = 100) of NN and NGN solving the four problems tested. *P&lt;0.05, **P&lt;0.01 and ***P&lt;0.001. Values represent mean ± S.E.M.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.g001" xlink:type="simple"/>
        </fig>
        <p>The steady training accuracies of NGN were higher than the respective NN in all problems (<xref ref-type="fig" rid="pone-0019109-g001">Figure 1D</xref>). The steady test accuracy of NGN was also higher than NN when solving IS and BC problems, whereas it was reduced for HD problem, or unchanged for IF problem. Both training and test times of NGN and NN, yet in some cases significantly different, had similar values (&lt;6 min) for HD, IF and BC problems (<xref ref-type="fig" rid="pone-0019109-g001">Figure 1E</xref>). In IS problem, which displayed long training and test times, both were shorter in NGN than in NN. These results indicate that astrocytes influenced the performance of the networks, without largely affecting or rather reducing their learning velocity. They also suggest that such influence depended on the network architecture and the problem tested.</p>
      </sec>
      <sec id="s2b">
        <title>The improvement of network performance is specifically due to artificial astrocytes</title>
        <p>Because the performance enhancement of NGN vs. NN might not be specifically due to astrocytes but to the presence of additional elements, we tested whether additional neurons in NN produced similar improvements. We analyzed the performances of NN with different architecture and number of neurons (<xref ref-type="fig" rid="pone-0019109-g002">Figure 2</xref>). We designed NN with 1, 2 or 3 hidden layers (NN1, NN2 and NN3) and with 44, 87 and 87 neurons (<xref ref-type="fig" rid="pone-0019109-g002">Figure 2A</xref>). In three problems (HD, IF and BC), no differences were found between the different NN (<xref ref-type="fig" rid="pone-0019109-g002">Figure 2B, 2C</xref>). In IS problem, accuracies were higher in NN2 and NN3 respect to NN1, but they were lower in NN3 than in NN2, which had the same number of neurons but different architectures, which is inconsistent with an improved performance as the number of neurons increase. Likewise, no trends were observed in training and test times (<xref ref-type="fig" rid="pone-0019109-g002">Figure 2D</xref>). These results indicate that NN performance did not correlate with the number of neurons or the architecture, suggesting that differences in NN and NGN performances cannot be accounted for an increased number of elements, but they are specifically due to astrocytes.</p>
        <fig id="pone-0019109-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0019109.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Neural network performance does not depend on the number of neurons or the architecture of the network.</title>
            <p>(<bold>A</bold>) Schematic drawing representing the design of three artificial neural networks with different number of neurons and different architectures. (<bold>B and C</bold>) Mean steady training and test accuracies, respectively (n = 100) of each NN for each problem tested. (<bold>D</bold>) Mean training and test times (left and right, respectively; n = 100) of each NN for each problem tested. *P&lt;0.05, **P&lt;0.01 and ***P&lt;0.001. Values represent mean ± S.E.M.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.g002" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2c">
        <title>Network performance improvement by artificial astrocytes increases as the network complexity increases</title>
        <p>We next investigated whether astrocyte effects depended on the network complexity. We used networks with different levels of complexity (defined by their different number of neurons, hidden layers and connections) and compared their performances with the corresponding NGN. To quantify NGN vs. NN performance, we defined performance index as the ratio between steady accuracies of NGN and the corresponding NN. First, we analyzed the impact of astrocytes on three networks with different hidden layers for each problem tested (<xref ref-type="fig" rid="pone-0019109-g003">Figure 3A</xref>). The steady test and training accuracies of NGN and the corresponding NN were different, and their relative values were also different among the three networks (for each problem tested) (<xref ref-type="fig" rid="pone-0019109-g003">Figure 3A</xref>). Then, to estimate the astrocyte effects irrespective of the problem, we pooled together the performance indexes of the four problems and plotted vs. the number of hidden layers (<xref ref-type="fig" rid="pone-0019109-g003">Figure 3B</xref>). Both training and test performance indexes increased as the number of hidden layers increased (<xref ref-type="fig" rid="pone-0019109-g003">Figure 3B</xref>), indicating that the impact of astrocytes increased as the complexity of the network increased.</p>
        <fig id="pone-0019109-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0019109.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Network performance improvement by artificial astrocytes increases as the network complexity increases.</title>
            <p>(<bold>A</bold>) Mean steady training and test accuracies (left and right, respectively; n = 100) of NN and NGN with 1, 2 or 3 hidden layers to solve the four problems tested. (<bold>B</bold>) Performance indexes (i.e., NGN values relative to NN values) of the training and test accuracies (left and right, respectively). Red symbols represent the corresponding averaged values (n = 16). *P&lt;0.05, **P&lt;0.01 and ***P&lt;0.001. Values represent mean ± S.E.M.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Relative network performance improvement by artificial astrocytes depends on the problem tested</title>
        <p>We next asked whether astrocyte effects depended on the problem (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4</xref>). In all cases (except IF problem, 1 hidden layer), the steady training accuracy and the performance index was increased in NGN vs. the respective NN, in all the problems and networks (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4A, 4B</xref>). However, the steady test accuracy of NGN vs. NN displayed more variability depending on the problem (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4A</xref>). To quantify the astrocyte impact irrespective of the network architecture, for each problem we pooled together the performance indexes of the three networks (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4B</xref>). While the relative training accuracy was higher for IF and IS problems, the relative test accuracy increased following the sequence HD-IF-BC-IS (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4B</xref>). This result indicates that the impact of astrocytes also depended on the problem tested.</p>
        <fig id="pone-0019109-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0019109.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Relative network performance improvement by artificial astrocytes depends on the problem tested.</title>
            <p>(<bold>A</bold>) Mean steady training and test accuracies (left and right, respectively; n = 100) of NN and NGN with 1, 2 or 3 hidden layers to solve the four problems tested. (<bold>B</bold>) Performance indexes (i.e., NGN values relative to NN values) of the training and test accuracies (left and right, respectively). Red symbols represent the corresponding averaged values (n = 12). (<bold>C</bold>) Mean performance indexes of the training and test accuracies (left and right, respectively; n = 100) for each problem tested when artificial astrocytes were stimulated by different patterns of neuronal connection activity. The notation n,m indicates that artificial astrocytes were stimulated when the associated neuronal connections were active for at least n out of m iterations. (<bold>D</bold>) Mean performance indexes of the training and test accuracies (left and right, respectively; n = 100) for each problem of NGN with non-selected (black bars) or with specifically selected neuron-glia interaction parameters (red bars). *P&lt;0.05, **P&lt;0.01 and ***P&lt;0.001. Values represent mean ± S.E.M.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.g004" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2e">
        <title>NGN performance improvement depends on intrinsic properties of astrocytes</title>
        <p>Above results were obtained using a constant paradigm of astrocytic activation, i.e., astrocytes were stimulated when the associated neuronal connections were active for at least 3 out of 6 iterations. To investigate if NGN performance improvement depended on intrinsic properties of astrocytes, we analyzed whether different patterns of astrocytic activation influenced the performance indexes. We defined two variables in the artificial neuron-glia interaction: 1) Astrocytic Sensitivity as the number of times the neuronal connection was required to be active to stimulate the associated astrocyte, i.e., 2,m is more sensitive than 3,m (being m = 4, 6 or 8); 2) Neuron-glia Connection Power as the number of iterations in which the neuronal connections are possibly active to stimulate the astrocyte (for example, if n,m = 3,6, at least 3 activations of the neuron had to occur during 6 consecutive iterations to stimulate the associated astrocyte), consequently, the strength is: n,8&gt;n,6&gt;n,4 (being n = 2 or 3) because the ability of a neuron to stimulate the associated astrocyte is higher for m = 8 than m = 6 and m = 4. <xref ref-type="fig" rid="pone-0019109-g004">Figure 4C</xref> shows that the relative performance of NGN vs. the corresponding NN is variable depending on the sensitivity and the neuron-glia connection power, and is different for each problem, indicating that the relative improvement of NGN vs. NN depends on intrinsic properties of the astrocytes, i.e., their sensitivity to neuronal connection activity and the strength of the neuron-glia connection.</p>
        <p>We finally investigated whether assigning specific values to the intrinsic properties of astrocytes and neuron-glia connections would further enhance the performance of NGN. We selected the best configuration of the neuron-glia interaction and compared it with the averaged non-selected configurations (<xref ref-type="fig" rid="pone-0019109-g004">Figure 4D</xref>). In all problems, the performance of the specifically designed NGN was enhanced vs. the corresponding NN (performance indexes &gt;1) as well as vs. the corresponding NGN with non-selected configuration.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Present results show that the performance of artificial networks is improved by artificial astrocytes, which is in agreement and support recent experimental findings that propose a direct involvement of astrocytes in brain information processing <xref ref-type="bibr" rid="pone.0019109-Araque1">[3]</xref>–<xref ref-type="bibr" rid="pone.0019109-Volterra1">[7]</xref>. The improvement provided by artificial astrocytes increases as the network complexity increases, which agrees with the gradual increase of the glia proportion observed in the phylogeny as the nervous system complexity increases <xref ref-type="bibr" rid="pone.0019109-Nedergaard1">[5]</xref>, <xref ref-type="bibr" rid="pone.0019109-RamnyCajal1">[16]</xref>. The specifically designed neuron-atrocyte properties provide a better network performance than indiscriminate properties, indicating that the interaction properties in these artificial tripartite synapses are relevant, which supports the notion that neuron-glia interaction in biological synapses represents a fine tuned communication <xref ref-type="bibr" rid="pone.0019109-Perea2">[10]</xref>.</p>
      <p>Several mechanisms and physiological consequences of astrocyte-neuron communication occur <xref ref-type="bibr" rid="pone.0019109-Perea1">[6]</xref>, <xref ref-type="bibr" rid="pone.0019109-Perea3">[17]</xref>. Under what conditions one specific modulatory effect takes place in a particular neural network remains unknown <xref ref-type="bibr" rid="pone.0019109-Perea3">[17]</xref>. For simplicity and as a first approximation to a complex problem, present work focused in modelling astrocyte-induced synaptic potentiation to investigate whether artificial astrocytes improve artificial neural network performance. Once this proof of concept is established, the development of future models of astrocyte-neuron interaction that incorporate the richness of biological interactions, e.g., astrocyte-induced synaptic depression, or depression and potentiation altogether, as well as spatial spread of the astrocyte signalling and astrocyte-astrocyte communication, are required to test whether they provide similar, or even better, improvements of neural network performances. Likewise, future work is necessary to investigate the impact of astrocytes in more complex neural networks that include e.g., inhibitory neurons and/or feed-back neuronal communication.</p>
      <p>In conclusion, the performance of artificial neural networks is improved when they include artificial astrocytes that are endowed with biologically-defined neuron-glia communication properties. Present results serve as foundation for the establishment of Artificial Neuron-Glia Networks, which represents a novel concept in Artificial Intelligence. Future developments of artificial neuron-glia networks will help to improve the efficacy of artificial networks as well as to better understand the role of astrocytes in brain function.</p>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Architecture and Parameters</title>
        <p><xref ref-type="table" rid="pone-0019109-t001">Table 1</xref> shows the NN architectures used. In NGN, every astrocyte was associated with the neuronal connections of each neuron (i.e. HD, 1 hidden layer architecture, NN: 13-4-1 vs NGN: 13(13)*-4(4)*-1, where (n)* refers to n astrocytes).</p>
        <table-wrap id="pone-0019109-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0019109.t001</object-id><label>Table 1</label><caption>
            <title>Architectures of NN used in each problem.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0019109-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.t001" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">One hidden layer</td>
                <td align="left" colspan="2" rowspan="1">Two hidden layers</td>
                <td align="left" colspan="2" rowspan="1">Three hidden layers</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1"><xref ref-type="fig" rid="pone-0019109-g002">Fig. 2</xref>, <xref ref-type="fig" rid="pone-0019109-g003">3</xref>, <xref ref-type="fig" rid="pone-0019109-g004">4</xref></td>
                <td align="left" colspan="1" rowspan="1"><xref ref-type="fig" rid="pone-0019109-g001">Fig. 1</xref>, <xref ref-type="fig" rid="pone-0019109-g003">3</xref>, <xref ref-type="fig" rid="pone-0019109-g004">4</xref></td>
                <td align="left" colspan="1" rowspan="1">
                  <xref ref-type="fig" rid="pone-0019109-g002">Fig. 2</xref>
                </td>
                <td align="left" colspan="1" rowspan="1"><xref ref-type="fig" rid="pone-0019109-g003">Fig. 3</xref>, <xref ref-type="fig" rid="pone-0019109-g004">4</xref></td>
                <td align="left" colspan="1" rowspan="1">
                  <xref ref-type="fig" rid="pone-0019109-g002">Fig. 2</xref>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Heart Disease</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">13-4-1</td>
                <td align="left" colspan="1" rowspan="1">13-4-3-1</td>
                <td align="left" colspan="1" rowspan="1">13-13-8-1</td>
                <td align="left" colspan="1" rowspan="1">13-5-4-3-1</td>
                <td align="left" colspan="1" rowspan="1">13-13-4-4-1</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Iris Flower</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">4-5-3</td>
                <td align="left" colspan="1" rowspan="1">4-5-7-3</td>
                <td align="left" colspan="1" rowspan="1">4-4-10-3</td>
                <td align="left" colspan="1" rowspan="1">4-7-5-7-3</td>
                <td align="left" colspan="1" rowspan="1">4-4-5-5-3</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Breast Cancer</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">9-7-1</td>
                <td align="left" colspan="1" rowspan="1">9-7-5-1</td>
                <td align="left" colspan="1" rowspan="1">9-9-14-1</td>
                <td align="left" colspan="1" rowspan="1">9-12-8-4-1</td>
                <td align="left" colspan="1" rowspan="1">9-9-7-7-1</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Ionosphere</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">34-9-1</td>
                <td align="left" colspan="1" rowspan="1">34-9-4-1</td>
                <td align="left" colspan="1" rowspan="1">34-34-18-1</td>
                <td align="left" colspan="1" rowspan="1">34-12-8-4-1</td>
                <td align="left" colspan="1" rowspan="1">34-34-9-9-1</td>
              </tr>
            </tbody>
          </table></alternatives></table-wrap>
        <p>The activation function was the hyperbolic tangent in all the layers, except in the output layer where the threshold function was used with a threshold value of 0.5 and an expected binary output.</p>
        <p>The same initial population of individuals was used for each problem and architecture. The population sizes were 150 individuals (except for HD problem that was 100). The following techniques were employed: the Montecarlo method for the selection of individuals; the Darwinian substitution method; a single crossover point; a crossover rate of 90%; and a mutation rate of 10%.</p>
        <p>The network architectures as well as GA parameters were selected for their simplicity <xref ref-type="bibr" rid="pone.0019109-Rabual1">[18]</xref> and to establish the same conditions for comparing NN and NGN.</p>
      </sec>
      <sec id="s4b">
        <title>Hybrid learning method</title>
        <p>We designed a new hybrid learning method for training the new NGN that searched for optimal connection weights in two phases. In one phase, the weight values were modified using rules based on neuron-glia communication properties <xref ref-type="bibr" rid="pone.0019109-Perea4">[19]</xref>. In the other phase, the weights were adjusted through GA.</p>
        <p>In the first learning phase, every individual (consisting of as many values as the connection weights exist in the NGN) of a population considered by the GA was modified as each training pattern passed on to the network, according to the activity of the neurons during the passage of that pattern. For each individual, every input pattern of the training set was presented to the network during m iterations (pattern cycle = m: 4, 6 or 8). These iterations modified the individual by applying an algorithm based on neuron-glia communication properties. This algorithm considered that the NGN had an artificial astrocyte for each neuron, and each neuron had an activity counter that begun with a value of zero and increased or decreased during each iteration in only one whole integer (+1 or −1) until it reached the Maximum (n) or Minimum (-n) Astrocytic Sensitivity. A neuronal connection ij connected neuron i with neuron j. A neuronal connection was considered active when the neuron i was active (according to its activation function). When the activity of a neuron reached its maximum value n, the astrocyte was activated and then increased 25% the weight of the neuronal connections with the neurons of the next (adjacent) layer. If a neuron that had reached this maximum value was once again activated, the value of n was maintained and the weights were increased another 25%. On the other hand, if the activity counter reached a value of –n, the astrocyte was not excited and the associated neuronal connection weights were decreased 50%. If a neuron had reached its minimum value and was not further activated, then the value of –n was maintained and the weights were further decreased. Therefore, the astrocytic effects were maintained and became gradually attenuated over time. The combinations (Astrocytic Sensitivity, Neuron-glia power connection: 2,4; 3,6; 2,6 y 3,8) were determined by trial-and-error, and allowed an upper limit of 3, 4, 5 or 6 astrocytic activations, respectively. Weight changes of 25% and 50% were chosen because they provided satisfactory results in the initial tests and they are in agreement with biological experimental observations, because being the increment lower than the decrement only neuronal connections with relatively high activity would remain reinforced <xref ref-type="bibr" rid="pone.0019109-Perea4">[19]</xref>.</p>
        <p>Throughout the training phase, after pattern cycle finished the associated error was calculated. After all the training patterns were passed, the mean square error (MSE) for each individual was calculated. This phase constitutes a non-supervised training since the modifications of the connection weights did not consider the error of the output, but rather took place at any time according to the activation of astrocytes.</p>
        <p>In the second learning phase, GA was applied to the individuals according to their MSE obtained in the first phase. The GA selected the new individuals with which the first and second phases were repeated until the pre-established stop-time was reached or no error was obtained.</p>
        <p>During the test phase, the input patterns were presented to the network according to the combinations (Astrocytic Sensitivity, Neuron-glia power connection) determined in the training phase.</p>
      </sec>
      <sec id="s4c">
        <title>Validation</title>
        <p>For each problem and for each architecture, the values for the comparison of each NN with its corresponding NGN were the average precisions obtained in 100 different test results. These 100 tests were performed once each network was trained with 10 disjointed sets of input patterns using the 5 iterations of 2-fold crossvalidation method <xref ref-type="bibr" rid="pone.0019109-Dietterich1">[20]</xref>, and additionally employing ten different populations of initial weights. The sets of input patterns were divided evenly into 50% training and 50% testing patterns. Wilcoxon test <xref ref-type="bibr" rid="pone.0019109-Wilcoxon1">[21]</xref> was used for statistics.</p>
        <p>The steady test accuracies were measured after a training period that was previously established for each problem and architecture. This time was the same for NN and NGN and was the execution time associated with 5,000 generations of the 2,4 combination. <xref ref-type="table" rid="pone-0019109-t002">Table 2</xref> shows the stop times during the training phase.</p>
        <table-wrap id="pone-0019109-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0019109.t002</object-id><label>Table 2</label><caption>
            <title>Stop times during the training phase (minutes).</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pone-0019109-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0019109.t002" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">
                  <italic>One hidden layer</italic>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <italic>Two hidden layers</italic>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <italic>Three hidden layers</italic>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Heart Disease</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">42</td>
                <td align="left" colspan="1" rowspan="1">60</td>
                <td align="left" colspan="1" rowspan="1">90</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Iris Flower</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">7</td>
                <td align="left" colspan="1" rowspan="1">16</td>
                <td align="left" colspan="1" rowspan="1">26</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Breast Cancer</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">180</td>
                <td align="left" colspan="1" rowspan="1">210</td>
                <td align="left" colspan="1" rowspan="1">360</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Ionosphere</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">210</td>
                <td align="left" colspan="1" rowspan="1">240</td>
                <td align="left" colspan="1" rowspan="1">360</td>
              </tr>
            </tbody>
          </table></alternatives></table-wrap>
        <p>The simulations were performed with Linux operating system in the FINISTERRAE and SVG supercomputers from CESGA <xref ref-type="bibr" rid="pone.0019109-CESGA1">[22]</xref>, Spain.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank J. Pazos, W. Buño and N. Ezquerra for helpful suggestions.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0019109-Hopfield1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group>             <year>1982</year>             <article-title>Neural networks and physical systems with emergent collective computational abilities.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>79</volume>             <fpage>2554</fpage>             <lpage>2558</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-McCulloch1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McCulloch</surname><given-names>WS</given-names></name><name name-style="western"><surname>Pitts</surname><given-names>W</given-names></name></person-group>             <year>1943</year>             <article-title>A logical calculus of ideas immanent in nervous activity. Bull. Math.</article-title>             <source>Biophys</source>             <volume>5</volume>             <fpage>115</fpage>             <lpage>133</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Araque1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Araque</surname><given-names>A</given-names></name><name name-style="western"><surname>Carmignoto</surname><given-names>G</given-names></name><name name-style="western"><surname>Haydon</surname><given-names>PG</given-names></name></person-group>             <year>2001</year>             <article-title>Dynamic signaling between neurons and glia.</article-title>             <source>Annu Rev Physiol</source>             <volume>63</volume>             <fpage>795</fpage>             <lpage>813</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Haydon1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haydon</surname><given-names>PG</given-names></name><name name-style="western"><surname>Carmignoto</surname><given-names>G</given-names></name></person-group>             <year>2006</year>             <article-title>Astrocyte control of synaptic transmission and neurovascular coupling.</article-title>             <source>Physiol Rev</source>             <volume>86</volume>             <fpage>1009</fpage>             <lpage>1031</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Nedergaard1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nedergaard</surname><given-names>M</given-names></name><name name-style="western"><surname>Ransom</surname><given-names>B</given-names></name><name name-style="western"><surname>Goldman</surname><given-names>SA</given-names></name></person-group>             <year>2003</year>             <article-title>New roles for astrocytes: Redefining the functional architecture of the brain.</article-title>             <source>Trends Neurosci</source>             <volume>26</volume>             <fpage>523</fpage>             <lpage>530</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Perea1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perea</surname><given-names>G</given-names></name><name name-style="western"><surname>Navarrete</surname><given-names>M</given-names></name><name name-style="western"><surname>Araque</surname><given-names>A</given-names></name></person-group>             <year>2009</year>             <article-title>Tripartite synapses: astrocytes process and control synaptic information.</article-title>             <source>Trends Neurosci</source>             <volume>32</volume>             <fpage>421</fpage>             <lpage>431</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Volterra1">
        <label>7</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Volterra</surname><given-names>A</given-names></name><name name-style="western"><surname>Bezzi</surname><given-names>P</given-names></name></person-group>             <year>2002</year>             <article-title>Release of transmitters fron glial cells.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Volterra</surname><given-names>A</given-names></name><name name-style="western"><surname>Magistretti</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Haydon</surname><given-names>PG</given-names></name></person-group>             <source>The Tripartite Synapse: Glia in Synaptic Transmission</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Oxford Univ. Press</publisher-name>             <fpage>164</fpage>             <lpage>184</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Grosche1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grosche</surname><given-names>J</given-names></name><etal/></person-group>             <year>1999</year>             <article-title>Microdomains for neuron-glia interaction: parallel fiber signaling to Bergmann glial cells.</article-title>             <source>Nat Neurosci</source>             <volume>2</volume>             <fpage>139</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Pasti1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pasti</surname><given-names>L</given-names></name><name name-style="western"><surname>Volterra</surname><given-names>A</given-names></name><name name-style="western"><surname>Pozzan</surname><given-names>T</given-names></name><name name-style="western"><surname>Carmignoto</surname><given-names>G</given-names></name></person-group>             <year>1997</year>             <article-title>Intracellular calcium oscillations in astrocytes: a highly plastic, bidirectional form of communication between neurons and astrocytes in situ.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>7817</fpage>             <lpage>7830</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Perea2">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perea</surname><given-names>G</given-names></name><name name-style="western"><surname>Araque</surname><given-names>A</given-names></name></person-group>             <year>2005</year>             <article-title>Properties of synaptically evoked astrocyte calcium signal reveal synaptic information processing by astrocytes.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>2192</fpage>             <lpage>2203</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Porter1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Porter</surname><given-names>JT</given-names></name><name name-style="western"><surname>McCarthy</surname><given-names>KD</given-names></name></person-group>             <year>1997</year>             <article-title>Astrocytic neurotransmitter receptors in situ and in vivo.</article-title>             <source>Prog Neurobiol</source>             <volume>51</volume>             <fpage>439</fpage>             <lpage>455</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Mertz1">
        <label>12</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mertz</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Murphy</surname><given-names>PM</given-names></name></person-group>             <year>2002</year>             <comment>University of California Irvine Machine Learning Repository (UCI), <ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/" xlink:type="simple">http://archive.ics.uci.edu/ml/</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pone.0019109-Holland1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Holland</surname><given-names>JH</given-names></name></person-group>             <year>1975</year>             <article-title>Adaptation in Natural and Artificial Systems.</article-title>             <publisher-loc>Ann Arbor, MI</publisher-loc>             <publisher-name>Univ. Michigan Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pone.0019109-Holland2">
        <label>14</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Holland</surname><given-names>JH</given-names></name></person-group>             <year>1987</year>             <article-title>Genetic algorithms and classifier systems: foundations and future directions.</article-title>             <publisher-name>Proc 2° Int Conf on Genetic Algorithms</publisher-name>             <fpage>82</fpage>             <lpage>89</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Yao1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yao</surname><given-names>X</given-names></name></person-group>             <year>1999</year>             <article-title>Evolving artificial neural networks. Proc.</article-title>             <source>IEEE</source>             <volume>87</volume>             <fpage>1423</fpage>             <lpage>1447</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-RamnyCajal1">
        <label>16</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ramón y Cajal</surname><given-names>S</given-names></name></person-group>             <year>1913</year>             <article-title>Contribución al conocimiento de la neuroglia del cerebro humano.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Moya</surname><given-names>Moya</given-names></name></person-group>             <publisher-loc>Madrid, Spain</publisher-loc>             <publisher-name>Trab Lab Invest Biol Univ, Vol XI</publisher-name>             <fpage>255</fpage>             <lpage>315</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Perea3">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perea</surname><given-names>G</given-names></name><name name-style="western"><surname>Araque</surname><given-names>A</given-names></name></person-group>             <year>2010</year>             <article-title>GLIA modulates synaptic transmission.</article-title>             <source>Brain Res Rev</source>             <volume>63</volume>             <fpage>93</fpage>             <lpage>102</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Rabual1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rabuñal</surname><given-names>JR</given-names></name><name name-style="western"><surname>Dorado</surname><given-names>J</given-names></name><name name-style="western"><surname>Pazos</surname><given-names>A</given-names></name><name name-style="western"><surname>Pereira</surname><given-names>J</given-names></name><name name-style="western"><surname>Rivero</surname><given-names>D</given-names></name></person-group>             <year>2004</year>             <article-title>A new approach to the extraction of ANN rules and to their generalization capacity through GP.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>1483</fpage>             <lpage>1524</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Perea4">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perea</surname><given-names>G</given-names></name><name name-style="western"><surname>Araque</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Astrocytes Potentiate Transmitter Release at Single Hippocampal Synapses.</article-title>             <source>Science</source>             <volume>317</volume>             <fpage>1083</fpage>             <lpage>1086</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Dietterich1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dietterich</surname><given-names>TG</given-names></name></person-group>             <year>1998</year>             <article-title>Approximate statistical tests for comparing supervised classification learning algorithms.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>1895</fpage>             <lpage>1924</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-Wilcoxon1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wilcoxon</surname><given-names>F</given-names></name></person-group>             <year>1945</year>             <article-title>Individual comparisons by ranking methods.</article-title>             <source>Biometrics</source>             <volume>1</volume>             <fpage>80</fpage>             <lpage>83</lpage>          </element-citation>
      </ref>
      <ref id="pone.0019109-CESGA1">
        <label>22</label>
        <element-citation publication-type="other" xlink:type="simple">             <collab xlink:type="simple">CESGA</collab>             <year>2010</year>             <comment>The computing equipment was provided by the Centro de SuperComputation de Galicia (CESGA), Spain. <ext-link ext-link-type="uri" xlink:href="http://www.cesga.es" xlink:type="simple">http://www.cesga.es</ext-link></comment>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>