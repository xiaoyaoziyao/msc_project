<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0200106</article-id>
<article-id pub-id-type="publisher-id">PONE-D-18-04706</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Reaction time</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Reaction time</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Computer networks</subject><subj-group><subject>Internet</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Mooney face stimuli for visual perception research</article-title>
<alt-title alt-title-type="running-head">Mooney face stimuli for perception research</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0661-8859</contrib-id>
<name name-style="western">
<surname>Schwiedrzik</surname>
<given-names>Caspar M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Melloni</surname>
<given-names>Lucia</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Schurger</surname>
<given-names>Aaron</given-names>
</name>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Neural Circuits and Cognition Lab, European Neuroscience Institute, Göttingen, Germany</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>University Medical Center Goettingen, Göttingen, Germany</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Neurosurgery, Columbia University, New York, New York, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Neuroscience Department, Max Planck Institute for Empirical Aesthetics, Frankfurt am Main, Germany</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>INSERM, Cognitive Neuroimaging Unit, Gif sur Yvette, France</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Commissariat à l’Energie Atomique, Direction des Sciences du Vivant, I2BM, NeuroSpin center, Gif sur Yvette, France</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sigman</surname>
<given-names>Mariano</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Universidad Torcuato Di Tella, ARGENTINA</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">c.schwiedrzik@eni-g.de</email> (CMS); <email xlink:type="simple">aaron.schurger@gmail.com</email> (AS)</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>6</day>
<month>7</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<year>2018</year>
</pub-date>
<volume>13</volume>
<issue>7</issue>
<elocation-id>e0200106</elocation-id>
<history>
<date date-type="received">
<day>12</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>6</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Schwiedrzik et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0200106"/>
<abstract>
<p>In 1957, Craig Mooney published a set of human face stimuli to study perceptual closure: the formation of a coherent percept on the basis of minimal visual information. Images of this type, now known as “Mooney faces”, are widely used in cognitive psychology and neuroscience because they offer a means of inducing variable perception with constant visuo-spatial characteristics (they are often not perceived as faces if viewed upside down). Mooney’s original set of 40 stimuli has been employed in several studies. However, it is often necessary to use a much larger stimulus set. We created a new set of over 500 Mooney faces and tested them on a cohort of human observers. We present the results of our tests here, and make the stimuli freely available via the internet. Our test results can be used to select subsets of the stimuli that are most suited for a given experimental purpose.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004412</institution-id>
<institution>Human Frontier Science Program</institution>
</institution-wrap>
</funding-source>
<award-id>LT001118/2012-L</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0661-8859</contrib-id>
<name name-style="western">
<surname>Schwiedrzik</surname>
<given-names>Caspar M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100010665</institution-id>
<institution>H2020 Marie Skłodowska-Curie Actions</institution>
</institution-wrap>
</funding-source>
<award-id>706519</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0661-8859</contrib-id>
<name name-style="western">
<surname>Schwiedrzik</surname>
<given-names>Caspar M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100011264</institution-id>
<institution>FP7 People: Marie-Curie Actions</institution>
</institution-wrap>
</funding-source>
<award-id>299372</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Melloni</surname>
<given-names>Lucia</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004189</institution-id>
<institution>Max-Planck-Gesellschaft</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Melloni</surname>
<given-names>Lucia</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100010663</institution-id>
<institution>H2020 European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>640626</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Schurger</surname>
<given-names>Aaron</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>CMS was supported by a Human Frontier Science Program (<ext-link ext-link-type="uri" xlink:href="http://www.hfsp.org" xlink:type="simple">http://www.hfsp.org</ext-link>) Long-Term Fellowship (LT001118/2012-L), and is currently funded by the European Union’s Horizon 2020 research and innovation programme (<ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/research/mariecurieactions" xlink:type="simple">https://ec.europa.eu/research/mariecurieactions</ext-link>) under the Marie Skłodowska-Curie grant agreement No. 706519. LM was supported by a Marie Curie International Outgoing Fellowship (<ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/research/mariecurieactions" xlink:type="simple">https://ec.europa.eu/research/mariecurieactions</ext-link>) within the 7th European Community Framework Programme (grant number 299372) and the Max Planck Society (<ext-link ext-link-type="uri" xlink:href="https://www.mpg.de" xlink:type="simple">https://www.mpg.de</ext-link>). AS was supported by an ERC Starting Grant (<ext-link ext-link-type="uri" xlink:href="https://erc.europa.eu/funding/starting-grants" xlink:type="simple">https://erc.europa.eu/funding/starting-grants</ext-link>) from the European Research Council (grant number 640626). Funding for publication charges was provided by the German Research Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de" xlink:type="simple">http://www.dfg.de</ext-link>) and the Open Access Publication Funds of the Göttingen University (<ext-link ext-link-type="uri" xlink:href="https://www.sub.uni-goettingen.de/en/electronic-publishing/open-access" xlink:type="simple">https://www.sub.uni-goettingen.de/en/electronic-publishing/open-access</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="11"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The full set of stimuli and the results of our behavioral tests, indexed by stimulus name, are freely available via the internet at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5783037" xlink:type="simple">https://doi.org/10.6084/m9.figshare.5783037</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>One of the hallmarks of vision is the ability to recognize objects on the basis of very little information. For example, a face that has only barely emerged from behind a shadow can often be immediately recognized, even though only a few patches of dark and light are available on the retina (<xref ref-type="fig" rid="pone.0200106.g001">Fig 1A</xref>). Missing detail is inferred and the object as a whole (the Gestalt) is perceived based only on a few visual “hints”. This process of visual completion based on prior perceptual knowledge is referred to as “perceptual closure”. In order to study visuo-perceptual closure in children [<xref ref-type="bibr" rid="pone.0200106.ref001">1</xref>], in the 1950’s cognitive psychologist Craig Mooney created a set of 40 human face stimuli, each defined by a few smooth rounded patches of black and white (<xref ref-type="fig" rid="pone.0200106.g001">Fig 1B</xref>). Such stimuli can take a few seconds to recognize at first [<xref ref-type="bibr" rid="pone.0200106.ref002">2</xref>], but once the face is perceived it is difficult for a normally-sighted human observer not to see the face from that moment onward [<xref ref-type="bibr" rid="pone.0200106.ref003">3</xref>]. When such a stimulus is presented upside-down it is often not recognized as a face, even if it is immediately recognized as a face when presented upright [<xref ref-type="bibr" rid="pone.0200106.ref004">4</xref>], revealing a hallmark of holistic face processing.</p>
<fig id="pone.0200106.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0200106.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Face and Mooney face stimuli.</title>
<p><bold>(A)</bold> This greyscale image is easily perceived as a face although most visual information is covered by shadows. <bold>(B)</bold> A typical “Mooney” face. <bold>(C)</bold> An extremely easy “Mooney” face, devoid of cast shadows.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0200106.g001" xlink:type="simple"/>
</fig>
<p>Images of this type, now commonly referred to as “Mooney faces”, have become widely used in cognitive psychology and neuroscience experiments because they offer a means of inducing variable perception with constant visuo-spatial characteristics in humans [<xref ref-type="bibr" rid="pone.0200106.ref005">5</xref>–<xref ref-type="bibr" rid="pone.0200106.ref008">8</xref>] and other animals [<xref ref-type="bibr" rid="pone.0200106.ref009">9</xref>–<xref ref-type="bibr" rid="pone.0200106.ref012">12</xref>]. Non-face objects, such as fruits, houses, and tools, can also be rendered in this way [<xref ref-type="bibr" rid="pone.0200106.ref011">11</xref>, <xref ref-type="bibr" rid="pone.0200106.ref013">13</xref>–<xref ref-type="bibr" rid="pone.0200106.ref015">15</xref>]. The stimuli are created by first blurring a grayscale image, and then increasing the contrast to 100%, so that only patches of black and white remain. For faces, it is important that the original photograph be taken from an oblique angle and in the presence of shadows, otherwise the resulting stimulus can be trivially easy to recognize (<xref ref-type="fig" rid="pone.0200106.g001">Fig 1C</xref>).</p>
<p>Mooney’s original set of 40 stimuli have been used in many studies to investigate closure and face perception, and deficits therein in neurological patients [<xref ref-type="bibr" rid="pone.0200106.ref016">16</xref>, <xref ref-type="bibr" rid="pone.0200106.ref017">17</xref>], as well as in psychiatric and neurodevelopmental disorders [<xref ref-type="bibr" rid="pone.0200106.ref018">18</xref>–<xref ref-type="bibr" rid="pone.0200106.ref021">21</xref>]. However, it is long known that the small set of Mooney’s original stimuli is quickly overlearned [<xref ref-type="bibr" rid="pone.0200106.ref022">22</xref>], preventing, e.g., longitudinal experiments. Furthermore, for many purposes it is necessary to employ a much larger set of stimuli, e.g., in psychophysical experiments were many trials need to be collected. In addition, it may be important to work with sets of stimuli that are approximately equated in terms of how readily they are recognized when presented upright and when presented inverted. In the past, researchers have resorted to creating their own stimuli [<xref ref-type="bibr" rid="pone.0200106.ref023">23</xref>–<xref ref-type="bibr" rid="pone.0200106.ref025">25</xref>], but this hampers comparisons between studies. Therefore, we created a large set of more than 500 Mooney face stimuli and tested them in healthy human observers using a face detection task. Each stimulus was presented twice, once upright and once inverted, and the subject was asked to indicate, on each trial, whether or not s/he had perceived a face. Scrambled versions of some of the images were included as explicit non-face control stimuli; half of the subjects were shown 50 scrambled images, and the other half 100 scrambled images. An infrared eye tracker was used to control for eye movements. We recorded subject’s responses and reaction times and subjected these and the images themselves to a battery of statistical tests, including a comparison of our stimuli to Craig Mooney’s original set of images. Our stimuli resemble Mooney’s originals in terms of overall difficulty and induce the typical face inversion effect when presented upside-down. They thus lend themselves well to the experimental study of perceptual closure and face perception. The full set of stimuli and the results of our behavioral tests, indexed by stimulus name, are freely available via the internet at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5783037" xlink:type="simple">https://doi.org/10.6084/m9.figshare.5783037</ext-link> [<xref ref-type="bibr" rid="pone.0200106.ref026">26</xref>].</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Subjects</title>
<p>A total of 20 subjects participated in this study (11 female, mean age 25.5 yrs, range 16–63 yrs, 15 right-handed, as assessed with the Edinburgh Inventory [<xref ref-type="bibr" rid="pone.0200106.ref027">27</xref>]). Subjects were pseudo-randomly assigned to two groups that were shown different numbers of catch trials (50 vs. 100 scrambled faces). One subject of each group was later excluded from analyses because they did not comply with task instructions (final <italic>n</italic> = 18). Because previous studies reported sex-differences in the perception of Mooney faces [<xref ref-type="bibr" rid="pone.0200106.ref028">28</xref>, <xref ref-type="bibr" rid="pone.0200106.ref029">29</xref>], we made sure that the female:male ratio was the same in both groups. All subjects had normal or corrected-to-normal vision, reported no history of neurological or psychiatric disease, and gave written informed consent before participation. Subjects received monetary compensation for their participation. All procedures were approved by The University Committee on Activities Involving Human Subjects at Columbia University.</p>
</sec>
<sec id="sec004">
<title>Stimuli</title>
<p>Stimuli were created from images taken from various sources on the internet. We primarily chose images that were taken from an oblique angle and had visible shadows, preferring “artistic” images over mugshots. They were scaled to 160×230 px size, converted to grey scale, smoothed with a 2 px Gaussian kernel, and then binarized at a threshold in Photoshop (Adobe Systems Inc.). Since there is no established threshold to create Mooney faces, the threshold was set by hand based on the subjective impression of the authors. To create scrambled versions of the images, contiguous regions in the images were selected and manually moved around to create distortions without creating sharp boundaries that are not present in the undistorted Mooney face. Subsequently, in pilot experiments, subjects were asked to identify scrambled images in which they still recognized faces. This process was iterated until the number of ‘face’ responses for scrambled images was minimized and subjects agreed in more than 85% of the images that there was ‘no face’.</p>
</sec>
<sec id="sec005">
<title>Procedures and task</title>
<p>For all experiments, stimuli were presented for 100 ms against a black background on a LCD computer screen (resolution 1600×1200 px, refresh rate 60 Hz), located at 74 cm distance. Stimulus dimensions (7×10 dva) matched previous studies using Mooney faces [<xref ref-type="bibr" rid="pone.0200106.ref018">18</xref>]. Subjects were instructed that they would be shown highly degraded pictures of faces and pictures not containing faces, and that they would have to decide on each trial whether the picture contained a face or not. Subjects used the index finger of their dominant hand to press ‘G’ on a standard computer keyboard for ‘face’, and their middle finger of the same hand to press ‘H’ for ‘no face’. Stimuli were presented in five blocks of 226 or 236 trials, respectively, depending on the number of catch trials (50 vs. 100). The number of upright/inverted/scrambled images was balanced across blocks. A red fixation dot was continuously present at the center of the screen. Stimulus display and response collection were controlled using Presentation software (Neurobehavioral Systems).</p>
</sec>
<sec id="sec006">
<title>Eye tracking</title>
<p>We used binocular video-based eye tracking at a sampling rate of 500 Hz (Eyelink 1000, SR Research) to assess fixation stability during the experiment in 14 of the subjects and to verify that subjects were looking at the stimuli during the task. A standard 9-point calibration routine was run at the beginning of the experiment as well as after each break.</p>
</sec>
<sec id="sec007">
<title>Data analyses</title>
<p>Data were analyzed in Matlab (The Mathworks) and SPSS (IBM Corp.). To assess face detection sensitivity, we calculated <italic>d’</italic> as a bias-free measure of face detection accuracy with the loglinear correction to avoid infinite <italic>z</italic>-scores [<xref ref-type="bibr" rid="pone.0200106.ref030">30</xref>]. For the analyses of reaction times, we excluded trials with reaction times shorter than 150 and longer than 2000 ms. The choice of cutoff did not affect the overall pattern of results. To assess inter-rater reliability and internal consistency, we calculated Fleiss’ Kappa [<xref ref-type="bibr" rid="pone.0200106.ref031">31</xref>] and Cronbach’s Alpha [<xref ref-type="bibr" rid="pone.0200106.ref032">32</xref>], respectively. Fixation stability was determined in a 2.5×2.5 dva window around the fixation dot for the time period from -150 to 150 ms around stimulus onset and averaged across both eyes.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<p>Subjects (<italic>n</italic> = 18) showed generally high Mooney face detection sensitivity, with an average <italic>d’</italic> of 1.19 (SD 0.30) across tasks (upright vs. inverted, upright vs. scrambled, inverted vs. scrambled) and subjects. A mixed repeated measures analysis of variance (rmANOVA) showed that performance did not depend upon how many scrambled images were shown (main effect group <italic>F</italic>(1,16) = 0.06, <italic>p</italic> = 0.79; task×group interaction <italic>F</italic>(2,32) = 0.06, <italic>p</italic> = 0.86, Greenhouse-Geisser corrected); hence, we report aggregate results across all participants. Subjects exhibited the highest face detection sensitivity when we compared behavior for upright faces versus scrambled faces (mean <italic>d’</italic> 1.78, SD 0.45), followed by upright versus inverted faces (mean <italic>d’</italic> 0.94, SD 0.26), followed by inverted versus scrambled faces (mean <italic>d’</italic> 0.83, SD 0.45).</p>
<p>It took subjects approximately 550 ms (SD 81.5 ms) on average to identify upright Mooney faces (<xref ref-type="fig" rid="pone.0200106.g002">Fig 2</xref>), which is slow compared to published reaction times of ~100 ms in speeded face detection with undegraded stimuli [<xref ref-type="bibr" rid="pone.0200106.ref033">33</xref>]. Subjects were generally fastest when they perceived a Mooney face, whether it was upright or not, compared to when they did not perceive a face (mean difference 29.8 ms, <italic>T</italic>(17) = 3.86, <italic>p</italic> = 0.001); the fastest reaction times were observed for upright faces perceived as such (all <italic>p</italic>&lt;0.0013, Bonferroni corrected). We also observed a typical face inversion effect, where subjects took longer to perceive inverted than upright Mooney faces (mean difference 38.9 ms, <italic>T</italic>(17) = 7.54, <italic>p</italic>&lt;0.001). Across stimuli, 16 of 18 subjects showed individually significant inversion effects (<italic>p</italic>&lt;0.05, Wilcoxon signed rank test). For scrambled images, reaction times were very slow (mean 619.6 ms, SD 73.5 ms) and did not differ between trials where subjects reported seeing a face and trials where subjects did not report seeing a face (mean difference 2.1 ms, <italic>T</italic>(17) = 0.11, <italic>p</italic> = 0.906).</p>
<fig id="pone.0200106.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0200106.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Reaction times.</title>
<p>Subjects were faster when they perceived a face then when they did not, both in the upright and in the inverted condition (mean difference 29.8 ms, <italic>T</italic>(17) = 3.86, <italic>p</italic> = 0.001). They also showed a typical face inversion effect, taking longer to perceive inverted than upright Mooney faces (mean difference 38.9 ms, <italic>T</italic>(17) = 7.54, <italic>p</italic>&lt;0.001). No reaction time differences between perceived and non-perceived scrambled images were observed (mean difference 2.1 ms, <italic>T</italic>(17) = 0.11, <italic>p</italic> = 0.906). Error bars reflect the standard error of the mean, corrected for between-subject variability [<xref ref-type="bibr" rid="pone.0200106.ref034">34</xref>, <xref ref-type="bibr" rid="pone.0200106.ref035">35</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0200106.g002" xlink:type="simple"/>
</fig>
<p>Fixation stability during stimulus presentation was generally high (all medians &gt;92%) and did not differ between conditions (no significant main effects or interactions for the factors stimulus (upright, inverted, scrambled) or percept (face, no face), rmANOVA, all <italic>p</italic>&gt;0.7, Greenhouse-Geisser corrected), as expected [<xref ref-type="bibr" rid="pone.0200106.ref036">36</xref>]. Thus, differences in fixation stability did not systematically drive ‘face’ vs. ‘no face’ responses.</p>
<p>Overall, our behavioral results show a typical pattern of performance with Mooney faces where face detection is comparatively slow but accurate, and face inversion further slows but does not fully eliminate face perception.</p>
<sec id="sec009">
<title>Item analyses</title>
<p>More than 90% of our new Mooney face stimuli were correctly recognized as a face by at least half of the subjects when presented upright, and all of the new upright Mooney faces were correctly identified as a face by at least two subjects (<xref ref-type="fig" rid="pone.0200106.g003">Fig 3</xref>). The most difficult new Mooney faces were recognized by only 2 of the 18 subjects. Overall, successful face recognition ranged from 11 to 100% of subjects per stimulus. For comparison, in the original set of Mooney faces, 86% of upright stimuli were recognized as a face by at least half of the subjects. The most difficult original Mooney face was recognized by 3 of the 18 subjects. The distributions of recognition per item did not differ significantly between ours and Craig Mooney’s original face images (Kolmogorov-Smirnov test, <italic>D</italic> = 0.18, <italic>p</italic> = 0.18). Internal consistency of our upright faces, i.e., the degree of correlation between individual images in terms of whether or not they were perceived as faces, was high (Cronbach’s <italic>α</italic> = 0.97), suggesting that they constitute a comparatively homogeneous pool of stimuli. In contrast, inter-rater reliability, i.e., the degree of agreement in recognizing an upright face as a face across subjects, was only ‘fair’ [<xref ref-type="bibr" rid="pone.0200106.ref037">37</xref>], albeit significant at <italic>κ</italic> = 0.21 (SE 0.003, <italic>Z</italic> = 59.2, <italic>p</italic>&lt;0.0001) for our stimulus set, compared to <italic>κ</italic> = 0.26 (SE 0.013, <italic>Z</italic> = 19.2, <italic>p</italic>&lt;0.0001) for the original stimulus set. This likely reflects inter-individual variability in face recognition and/or perceptual closure capabilities.</p>
<fig id="pone.0200106.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0200106.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Frequency of stimuli perceived as face, upright or inverted.</title>
<p>Most faces were correctly identified as faces by the majority of subjects when presented upright (green) both in our and in the original Mooney face set, but both stimulus sets also contain difficult stimuli that are only perceived as faces by a few subjects. Face inversion (blue) markedly reduced the number of ‘face’ responses. On the right are examples of easy and difficult Mooney faces from the upright and the inverted conditions, respectively. Original Mooney faces reprinted from [<xref ref-type="bibr" rid="pone.0200106.ref001">1</xref>] under a CC BY license, with permission from the Canadian Psychological Association Inc., original copyright 1957.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0200106.g003" xlink:type="simple"/>
</fig>
<p>When presented upside-down, only 67% of our new stimuli were recognized as faces by at least half of the subjects, ranging from 0 to 100% of subjects per stimulus (<xref ref-type="fig" rid="pone.0200106.g003">Fig 3</xref>). In the original Mooney face set, 44% of inverted images were recognized as faces, ranging from 11 to 89% of subjects per stimulus. Again, internal consistency of our stimulus set was high (Cronbach’s <italic>α</italic> = 0.98), while inter-rater reliability was only ‘slight’ [<xref ref-type="bibr" rid="pone.0200106.ref037">37</xref>], both for our (<italic>κ</italic> = 0.15, SE 0.003, <italic>Z</italic> = 41.8, <italic>p</italic>&lt;0.0001) and for the original stimulus set (<italic>κ</italic> = 0.11, SE 0.013, <italic>Z</italic> = 8.53, <italic>p</italic>&lt;0.0001).</p>
<p>Mooney faces are often used to investigate face inversion effects. Here, one can consider either face recognition or reaction times to determine whether inversion effects are present (<xref ref-type="fig" rid="pone.0200106.g004">Fig 4</xref>). Interestingly, the two types of inversion effects are only weakly correlated (number of subjects recognizing inverted Mooney face vs. median reaction time difference, <italic>r</italic> = 0.09, <italic>p</italic> = 0.03, Spearman rank correlation). When using face recognition as a criterion, 84 images were both recognized as a face when presented upright and not recognized as a face when inverted by at least half of the subjects in our new stimulus set, compared to 11 images in the original stimulus set. Inversion effects in reaction times were much more common, with an overall median of 69 ms (<xref ref-type="fig" rid="pone.0200106.g004">Fig 4</xref>). The largest per-image median inversion effect we observed was 259 ms in our stimulus set, and 278 ms in the original Mooney stimulus set. 396 of our stimuli were both recognized as a face when presented upright and showed an inversion effect in reaction times in at least half of the subjects, while this was the case for 22 images in the original stimulus set. In both stimulus sets, faces that were more easily recognized as faces when presented upright were also more likely to be recognized as such when presented upside-down (ours: <italic>r</italic> = 0.67, <italic>p</italic>&lt;0.001; original: <italic>r</italic> = 0.61, <italic>p</italic>&lt;0.001), and induced larger reaction time inversion effects (ours: <italic>r</italic> = 0.30, <italic>p</italic>&lt;0.001; original: <italic>r</italic> = 0.42, <italic>p</italic> = 0.01).</p>
<fig id="pone.0200106.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0200106.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Inversion effects.</title>
<p>Inversion effects were evident both when considering whether an inverted face was recognized as a face (red) and when considering reaction times (yellow), i.e., longer reaction times to inverted than to upright faces. The latter type of inversion effect was much more frequent than the former. Overall, inversion effects of reaction times showed a median effect of 66 ms in our new stimulus set, and 79 ms in the original Mooney stimulus set (black solid lines). The right shows the stimuli with the most reliable/largest inversion effects for face recognition and reaction times, respectively. Original Mooney faces reprinted from [<xref ref-type="bibr" rid="pone.0200106.ref001">1</xref>] under a CC BY license, with permission from the Canadian Psychological Association Inc., original copyright 1957.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0200106.g004" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec010" sec-type="conclusions">
<title>Discussion</title>
<p>We present a new, large set of Mooney face stimuli that cover a range of difficulty levels and induce typical inversion effects in face perception. The behavior we observe for our new stimuli generally resembles the behavior observed with the original but much smaller stimulus set developed by Craig Mooney in the 1950’s. Together, this suggests that vision researchers interested in face perception and/or perceptual closure can use our freely available stimulus set in situations where large numbers of stimuli are needed, e.g., to prevent learning effects, and/or when stimuli need to be pre-selected to reliably induce certain behavioral effects, e.g., inversion effects in reaction times. Furthermore, our data can provide a reference against which future studies can be compared, thus contributing to reproducibility.</p>
<p>In the past, many studies have relied on the original set of Mooney faces, which are also sorted by difficulty. However, in contrast to the face recognition task we used here, the original task was non-speeded sorting of paper cards into age and gender categories [<xref ref-type="bibr" rid="pone.0200106.ref001">1</xref>]. Stimulus difficulty is correlated between the original task and the more common face recognition task we used (<italic>r</italic> = 0.52, <italic>p</italic> = 0.001), similar to what has been observed for a spatial 3AFC task in a new online version of the Mooney test (<italic>r</italic> = 0.56) [<xref ref-type="bibr" rid="pone.0200106.ref029">29</xref>]. Given the rather weak correlation, it seems advisable to determine stimulus difficulty anew for each new task. However, the face recognition task we used here is likely to tap into more basic perceptual processes than age and gender categorization and thus constitutes a good starting point. We also find that face inversion has two partially distinct effects: slowing of reaction times, and attenuation of recognition abilities. While the former effect occurs for many Mooney face stimuli, including the original ones, the latter is much less frequent (<xref ref-type="fig" rid="pone.0200106.g004">Fig 4</xref>), which cautions against the untested use of inverted Mooney faces as non-face stimuli. An alternative is to use scrambled Mooney images which similarly preserve low-level stimulus features, as we did here.</p>
<p>Mooney faces have proven a highly effective stimulus for the investigation of face perception and perceptual closure abilities in development [<xref ref-type="bibr" rid="pone.0200106.ref038">38</xref>–<xref ref-type="bibr" rid="pone.0200106.ref040">40</xref>], disease [<xref ref-type="bibr" rid="pone.0200106.ref016">16</xref>–<xref ref-type="bibr" rid="pone.0200106.ref021">21</xref>], across cultures [<xref ref-type="bibr" rid="pone.0200106.ref041">41</xref>] and species [<xref ref-type="bibr" rid="pone.0200106.ref009">9</xref>–<xref ref-type="bibr" rid="pone.0200106.ref012">12</xref>], from basic vision [<xref ref-type="bibr" rid="pone.0200106.ref042">42</xref>] to aesthetic experience [<xref ref-type="bibr" rid="pone.0200106.ref043">43</xref>], as well as in computer vision [<xref ref-type="bibr" rid="pone.0200106.ref044">44</xref>]. Our new stimulus set, benchmarked against human observers, will serve as a valuable resource for future research.</p>
</sec>
</body>
<back>
<ack>
<p>We would like to thank Hakwan Lau for generously providing us with lab space and equipment, Jessica Zhang for her help in pre-testing the stimuli, and Ben Bernstein for help with data acquisition. Original Mooney faces in Figs <xref ref-type="fig" rid="pone.0200106.g003">3</xref> and <xref ref-type="fig" rid="pone.0200106.g004">4</xref> are from the Canadian Journal of Psychology, Volume 11, No. 4, <xref ref-type="fig" rid="pone.0200106.g001">Fig 1</xref>, pg# 220, Copyright 1957 by the Canadian Psychological Association Inc. Permission from the Canadian Psychological Association Inc. to reprint 6 images from <xref ref-type="fig" rid="pone.0200106.g001">Fig 1</xref>. CMS was supported by a Human Frontier Science Program (<ext-link ext-link-type="uri" xlink:href="http://www.hfsp.org/" xlink:type="simple">http://www.hfsp.org</ext-link>) Long-Term Fellowship (LT001118/2012-L), and is currently funded by the European Union’s Horizon 2020 research and innovation programme (<ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/research/mariecurieactions" xlink:type="simple">https://ec.europa.eu/research/mariecurieactions</ext-link>) under the Marie Skłodowska-Curie grant agreement No. 706519. LM was supported by a Marie Curie International Outgoing Fellowship (<ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/research/mariecurieactions" xlink:type="simple">https://ec.europa.eu/research/mariecurieactions</ext-link>) within the 7th European Community Framework Programme (grant number 299372) and the Max Planck Society (<ext-link ext-link-type="uri" xlink:href="https://www.mpg.de/" xlink:type="simple">https://www.mpg.de</ext-link>). AS was supported by an ERC Starting Grant (<ext-link ext-link-type="uri" xlink:href="https://erc.europa.eu/funding/starting-grants" xlink:type="simple">https://erc.europa.eu/funding/starting-grants</ext-link>) from the European Research Council (grant number 640626). Funding for publication charges was provided by the German Research Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/" xlink:type="simple">http://www.dfg.de</ext-link>) and the Open Access Publication Funds of the Göttingen University (<ext-link ext-link-type="uri" xlink:href="https://www.sub.uni-goettingen.de/en/electronic-publishing/open-access" xlink:type="simple">https://www.sub.uni-goettingen.de/en/electronic-publishing/open-access</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. The authors have declared that no competing interests exist.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0200106.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mooney</surname> <given-names>CM</given-names></name>. <article-title>Age in the development of closure ability in children</article-title>. <source>Can J Psychol</source>. <year>1957</year>;<volume>11</volume>(<issue>4</issue>):<fpage>219</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0083717" xlink:type="simple">10.1037/h0083717</ext-link></comment> <object-id pub-id-type="pmid">13489559</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramachandran</surname> <given-names>VS</given-names></name>, <name name-style="western"><surname>Armel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Foster</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Stoddard</surname> <given-names>R</given-names></name>. <article-title>Object recognition can drive motion perception</article-title>. <source>Nature</source>. <year>1998</year>;<volume>395</volume>(<issue>6705</issue>):<fpage>852</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/27573" xlink:type="simple">10.1038/27573</ext-link></comment> <object-id pub-id-type="pmid">9804417</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ludmer</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dudai</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>N</given-names></name>. <article-title>Uncovering camouflage: amygdala activation predicts long-term memory of induced perceptual insight</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>69</volume>(<issue>5</issue>):<fpage>1002</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.02.013" xlink:type="simple">10.1016/j.neuron.2011.02.013</ext-link></comment> <object-id pub-id-type="pmid">21382558</object-id>; PubMed Central PMCID: PMC3281502.</mixed-citation></ref>
<ref id="pone.0200106.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>George</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Jemel</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fiori</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Chaby</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Renault</surname> <given-names>B</given-names></name>. <article-title>Electrophysiological correlates of facial decision: insights from upright and upside-down Mooney-face perception</article-title>. <source>Brain Res Cogn Brain Res</source>. <year>2005</year>;<volume>24</volume>(<issue>3</issue>):<fpage>663</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cogbrainres.2005.03.017" xlink:type="simple">10.1016/j.cogbrainres.2005.03.017</ext-link></comment> <object-id pub-id-type="pmid">15890502</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Nakayama</surname> <given-names>K</given-names></name>. <article-title>The effect of face inversion on the human fusiform face area</article-title>. <source>Cognition</source>. <year>1998</year>;<volume>68</volume>(<issue>1</issue>):<fpage>B1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/s0010-0277(98)00035-3" xlink:type="simple">10.1016/s0010-0277(98)00035-3</ext-link></comment> <object-id pub-id-type="pmid">9775518</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodriguez</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Lachaux</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Martinerie</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Renault</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Varela</surname> <given-names>FJ</given-names></name>. <article-title>Perception's shadow: long-distance synchronization of human brain activity</article-title>. <source>Nature</source>. <year>1999</year>;<volume>397</volume>(<issue>6718</issue>):<fpage>430</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/17120" xlink:type="simple">10.1038/17120</ext-link></comment> <object-id pub-id-type="pmid">9989408</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsieh</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>Recognition alters the spatial pattern of FMRI activation in early retinotopic cortex</article-title>. <source>J Neurophysiol</source>. <year>2010</year>;<volume>103</volume>(<issue>3</issue>):<fpage>1501</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00812.2009" xlink:type="simple">10.1152/jn.00812.2009</ext-link></comment> <object-id pub-id-type="pmid">20071627</object-id>; PubMed Central PMCID: PMC3257064.</mixed-citation></ref>
<ref id="pone.0200106.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hegde</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kersten</surname> <given-names>D</given-names></name>. <article-title>A link between visual disambiguation and visual memory</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>(<issue>45</issue>):<fpage>15124</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4415-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4415-09.2010</ext-link></comment> <object-id pub-id-type="pmid">21068318</object-id>; PubMed Central PMCID: PMC3040725.</mixed-citation></ref>
<ref id="pone.0200106.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perrett</surname> <given-names>DI</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Potter</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Mistlin</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Head</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Milner</surname> <given-names>AD</given-names></name>, <etal>et al</etal>. <article-title>Neurones responsive to faces in the temporal cortex: studies of functional organization, sensitivity to identity and relation to perception</article-title>. <source>Hum Neurobiol</source>. <year>1984</year>;<volume>3</volume>(<issue>4</issue>):<fpage>197</fpage>–<lpage>208</lpage>. <object-id pub-id-type="pmid">6526706</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tovee</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Ramachandran</surname> <given-names>VS</given-names></name>. <article-title>Rapid visual learning in neurones of the primate temporal visual cortex</article-title>. <source>Neuroreport</source>. <year>1996</year>;<volume>7</volume>(<issue>15–17</issue>):<fpage>2757</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1097/00001756-199611040-00070" xlink:type="simple">10.1097/00001756-199611040-00070</ext-link></comment> <object-id pub-id-type="pmid">8981462</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Taubert</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Parr</surname> <given-names>LA</given-names></name>. <article-title>The perception of two-tone Mooney faces in chimpanzees (Pan troglodytes)</article-title>. <source>Cogn Neurosci</source>. <year>2012</year>;<volume>3</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/17588928.2011.578737" xlink:type="simple">10.1080/17588928.2011.578737</ext-link></comment> <object-id pub-id-type="pmid">22737182</object-id>; PubMed Central PMCID: PMC3377185.</mixed-citation></ref>
<ref id="pone.0200106.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moeller</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Crapse</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>. <article-title>The effect of face patch microstimulation on perception of faces and objects</article-title>. <source>Nat Neurosci</source>. <year>2017</year>;<volume>20</volume>(<issue>5</issue>):<fpage>743</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4527" xlink:type="simple">10.1038/nn.4527</ext-link></comment> <object-id pub-id-type="pmid">28288127</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Imamoglu</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kahnt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>. <article-title>Changes in functional connectivity support conscious object recognition</article-title>. <source>Neuroimage</source>. <year>2012</year>;<volume>63</volume>(<issue>4</issue>):<fpage>1909</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.07.056" xlink:type="simple">10.1016/j.neuroimage.2012.07.056</ext-link></comment> <object-id pub-id-type="pmid">22877578</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brodski-Guerniero</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Paasch</surname> <given-names>GF</given-names></name>, <name name-style="western"><surname>Wollstadt</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ozdemir</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Lizier</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Wibral</surname> <given-names>M</given-names></name>. <article-title>Information-theoretic evidence for predictive coding in the face-processing system</article-title>. <source>J Neurosci</source>. <year>2017</year>;<volume>37</volume>(<issue>34</issue>):<fpage>8273</fpage>–<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0614-17.2017" xlink:type="simple">10.1523/JNEUROSCI.0614-17.2017</ext-link></comment> <object-id pub-id-type="pmid">28751458</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Fink</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Booth</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Frackowiak</surname> <given-names>RS</given-names></name>, <etal>et al</etal>. <article-title>How the brain learns to see objects and faces in an impoverished context</article-title>. <source>Nature</source>. <year>1997</year>;<volume>389</volume>(<issue>6651</issue>):<fpage>596</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/39309" xlink:type="simple">10.1038/39309</ext-link></comment> <object-id pub-id-type="pmid">9335498</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wasserstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Barr</surname> <given-names>WB</given-names></name>, <name name-style="western"><surname>Zappulla</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rock</surname> <given-names>D</given-names></name>. <article-title>Facial closure: interrelationship with facial discrimination, other closure tests, and subjective contour illusions</article-title>. <source>Neuropsychologia</source>. <year>2004</year>;<volume>42</volume>(<issue>2</issue>):<fpage>158</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2003.07.003" xlink:type="simple">10.1016/j.neuropsychologia.2003.07.003</ext-link></comment> <object-id pub-id-type="pmid">14644102</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Busigny</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Joubert</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Felician</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Ceccaldi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name>. <article-title>Holistic perception of the individual face is specific and necessary: evidence from an extensive case study of acquired prosopagnosia</article-title>. <source>Neuropsychologia</source>. <year>2010</year>;<volume>48</volume>(<issue>14</issue>):<fpage>4057</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2010.09.017" xlink:type="simple">10.1016/j.neuropsychologia.2010.09.017</ext-link></comment> <object-id pub-id-type="pmid">20875437</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uhlhaas</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Haenschel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lindner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Maurer</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Dysfunctional long-range coordination of neural activity during Gestalt perception in schizophrenia</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>(<issue>31</issue>):<fpage>8168</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2002-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2002-06.2006</ext-link></comment> <object-id pub-id-type="pmid">16885230</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sun</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Grutzner</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bolte</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wibral</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tozman</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Schlitt</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Impaired gamma-band activity during perceptual organization in adults with autism spectrum disorders: evidence for dysfunctional network activity in frontal-posterior cortices</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>28</issue>):<fpage>9563</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1073-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1073-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22787042</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grutzner</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wibral</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Rivolta</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Maurer</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Deficits in high- (&gt;60 Hz) gamma-band oscillations during visual processing in schizophrenia</article-title>. <source>Front Hum Neurosci</source>. <year>2013</year>;<volume>7</volume>:<fpage>88</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2013.00088" xlink:type="simple">10.3389/fnhum.2013.00088</ext-link></comment> <object-id pub-id-type="pmid">23532620</object-id>; PubMed Central PMCID: PMC3607810.</mixed-citation></ref>
<ref id="pone.0200106.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rivolta</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Castellanos</surname> <given-names>NP</given-names></name>, <name name-style="western"><surname>Stawowsky</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Helbling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wibral</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grutzner</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Source-reconstruction of event-related fields reveals hyperfunction and hypofunction of cortical circuits in antipsychotic-naive, first-episode schizophrenia patients during Mooney face processing</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>17</issue>):<fpage>5909</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3752-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3752-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24760850</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mooney</surname> <given-names>CM</given-names></name>. <article-title>Closure with negative after-images under flickering light</article-title>. <source>Can J Psychol</source>. <year>1956</year>;<volume>10</volume>(<issue>4</issue>):<fpage>191</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0083671" xlink:type="simple">10.1037/h0083671</ext-link></comment> <object-id pub-id-type="pmid">13374609</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jemel</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Pisani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Calabria</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Crommelinck</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bruyer</surname> <given-names>R</given-names></name>. <article-title>Is the N170 for faces cognitively penetrable? Evidence from repetition priming of Mooney faces of familiar and unfamiliar persons</article-title>. <source>Brain Res Cogn Brain Res</source>. <year>2003</year>;<volume>17</volume>(<issue>2</issue>):<fpage>431</fpage>–<lpage>46</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/s0926-6410(03)00145-9" xlink:type="simple">10.1016/s0926-6410(03)00145-9</ext-link></comment> <object-id pub-id-type="pmid">12880913</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKeeff</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name>. <article-title>The timing of perceptual decisions for ambiguous face stimuli in the human ventral visual cortex</article-title>. <source>Cereb Cortex</source>. <year>2007</year>;<volume>17</volume>(<issue>3</issue>):<fpage>669</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhk015" xlink:type="simple">10.1093/cercor/bhk015</ext-link></comment> <object-id pub-id-type="pmid">16648454</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dricot</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Busigny</surname> <given-names>T</given-names></name>. <article-title>Holistic face categorization in higher order visual areas of the normal and prosopagnosic brain: toward a non-hierarchical view of face perception</article-title>. <source>Front Hum Neurosci</source>. <year>2011</year>;<volume>4</volume>:<fpage>225</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2010.00225" xlink:type="simple">10.3389/fnhum.2010.00225</ext-link></comment> <object-id pub-id-type="pmid">21267432</object-id>; PubMed Central PMCID: PMC3025660.</mixed-citation></ref>
<ref id="pone.0200106.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwiedrzik</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Melloni</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Schurger</surname> <given-names>A</given-names></name>. <article-title>Mooney face stimuli for visual perception research</article-title>. <source>Figshare</source> [Internet]. <year>2018</year>. Available from: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5783037" xlink:type="simple">https://doi.org/10.6084/m9.figshare.5783037</ext-link>.</mixed-citation></ref>
<ref id="pone.0200106.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oldfield</surname> <given-names>RC</given-names></name>. <article-title>The assessment and analysis of handedness: the Edinburgh inventory</article-title>. <source>Neuropsychologia</source>. <year>1971</year>;<volume>9</volume>(<issue>1</issue>):<fpage>97</fpage>–<lpage>113</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0028-3932(71)90067-4" xlink:type="simple">10.1016/0028-3932(71)90067-4</ext-link></comment> <object-id pub-id-type="pmid">5146491</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foreman</surname> <given-names>N</given-names></name>. <article-title>Correlates of performance on the Gollin and Mooney tests of visual closure</article-title>. <source>J Gen Psychol</source>. <year>1991</year>;<volume>118</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/00221309.1991.9711129" xlink:type="simple">10.1080/00221309.1991.9711129</ext-link></comment> <object-id pub-id-type="pmid">2037842</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verhallen</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Bosten</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Goodbourn</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Bargary</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lawrance-Owen</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Mollon</surname> <given-names>JD</given-names></name>. <article-title>An online version of the Mooney Face Test: phenotypic and genetic associations</article-title>. <source>Neuropsychologia</source>. <year>2014</year>;<volume>63</volume>:<fpage>19</fpage>–<lpage>25</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2014.08.011" xlink:type="simple">10.1016/j.neuropsychologia.2014.08.011</ext-link></comment> <object-id pub-id-type="pmid">25138019</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hautus</surname> <given-names>MJ</given-names></name>. <article-title>Corrections for extreme proportions and their biasing effects on estimated values of d'</article-title>. <source>Behav Res Meth Instrum Comput</source>. <year>1995</year>;<volume>27</volume>(<issue>1</issue>):<fpage>46</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03203619" xlink:type="simple">10.3758/BF03203619</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleiss</surname> <given-names>JL</given-names></name>. <article-title>Measuring nominal scale agreement among many raters</article-title>. <source>Psychol Bull</source>. <year>1971</year>;<volume>76</volume>(<issue>5</issue>):<fpage>378</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0031619" xlink:type="simple">10.1037/h0031619</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cronbach</surname> <given-names>LJ</given-names></name>. <article-title>Coefficient alpha and the internal structure of tests</article-title>. <source>Psychometrika</source>. <year>1951</year>;<volume>16</volume>(<issue>3</issue>):<fpage>297</fpage>–<lpage>334</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/bf02310555" xlink:type="simple">10.1007/bf02310555</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crouzet</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Kirchner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name>. <article-title>Fast saccades toward faces: face detection in just 100 ms</article-title>. <source>Journal of vision</source>. <year>2010</year>;<volume>10</volume>(<issue>4</issue>):<fpage>16</fpage> 1–7. Epub 2010/05/15. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/10.4.16" xlink:type="simple">10.1167/10.4.16</ext-link></comment> <object-id pub-id-type="pmid">20465335</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cousineau</surname> <given-names>D</given-names></name>. <article-title>Confidence intervals in within-subjects designs: a simpler solution to Loftus and Masson's method</article-title>. <source>Tutor Quant Methods Psychol</source>. <year>2005</year>;<volume>1</volume>(<issue>1</issue>):<fpage>42</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.20982/tqmp.01.1.p042" xlink:type="simple">10.20982/tqmp.01.1.p042</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morey</surname> <given-names>RD</given-names></name>. <article-title>Confidence intervals from normalized data: a correction to Cousineau (2005)</article-title>. <source>Tutor Quant Methods Psychol</source>. <year>2008</year>;<volume>4</volume>(<issue>2</issue>):<fpage>61</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.20982/tqmp.04.2.p061" xlink:type="simple">10.20982/tqmp.04.2.p061</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mooney</surname> <given-names>CM</given-names></name>. <article-title>Closure as affected by viewing time and multiple visual fixations</article-title>. <source>Can J Psychol</source>. <year>1957</year>;<volume>11</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0083687" xlink:type="simple">10.1037/h0083687</ext-link></comment> <object-id pub-id-type="pmid">13404563</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Landis</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>GG</given-names></name>. <article-title>The measurement of observer agreement for categorical data</article-title>. <source>Biometrics</source>. <year>1977</year>;<volume>33</volume>(<issue>1</issue>):<fpage>159</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/2529310" xlink:type="simple">10.2307/2529310</ext-link></comment> <object-id pub-id-type="pmid">843571</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leo</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Simion</surname> <given-names>F</given-names></name>. <article-title>Newborn's Mooney-face perception</article-title>. <source>Infancy</source>. <year>2009</year>;<volume>14</volume>(<issue>6</issue>):<fpage>641</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/15250000903264047" xlink:type="simple">10.1080/15250000903264047</ext-link></comment></mixed-citation></ref>
<ref id="pone.0200106.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uhlhaas</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Roux</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Haenschel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sireteanu</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rodriguez</surname> <given-names>E</given-names></name>. <article-title>The development of neural synchrony reflects late maturation and restructuring of functional networks in humans</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2009</year>;<volume>106</volume>(<issue>24</issue>):<fpage>9866</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0900390106" xlink:type="simple">10.1073/pnas.0900390106</ext-link></comment> <object-id pub-id-type="pmid">19478071</object-id>; PubMed Central PMCID: PMC2687997.</mixed-citation></ref>
<ref id="pone.0200106.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carbon</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Gruter</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gruter</surname> <given-names>T</given-names></name>. <article-title>Age-dependent face detection and face categorization performance</article-title>. <source>PLoS One</source>. <year>2013</year>;<volume>8</volume>(<issue>10</issue>):<fpage>e79164</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0079164" xlink:type="simple">10.1371/journal.pone.0079164</ext-link></comment> <object-id pub-id-type="pmid">24116236</object-id>; PubMed Central PMCID: PMC3792936.</mixed-citation></ref>
<ref id="pone.0200106.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yoon</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Witthoft</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Winawer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Everett</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Gibson</surname> <given-names>E</given-names></name>. <article-title>Cultural differences in perceptual reorganization in US and Piraha adults</article-title>. <source>PLoS One</source>. <year>2014</year>;<volume>9</volume>(<issue>11</issue>):<fpage>e110225</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0110225" xlink:type="simple">10.1371/journal.pone.0110225</ext-link></comment> <object-id pub-id-type="pmid">25411970</object-id>; PubMed Central PMCID: PMC4238998.</mixed-citation></ref>
<ref id="pone.0200106.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKone</surname> <given-names>E</given-names></name>. <article-title>Isolating the special component of face recognition: peripheral identification and a Mooney face</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>2004</year>;<volume>30</volume>(<issue>1</issue>):<fpage>181</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.30.1.181" xlink:type="simple">10.1037/0278-7393.30.1.181</ext-link></comment> <object-id pub-id-type="pmid">14736306</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Muth</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Carbon</surname> <given-names>CC</given-names></name>. <article-title>The aesthetic aha: on the pleasure of having insights into Gestalt</article-title>. <source>Acta Psychol (Amst)</source>. <year>2013</year>;<volume>144</volume>(<issue>1</issue>):<fpage>25</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.actpsy.2013.05.001" xlink:type="simple">10.1016/j.actpsy.2013.05.001</ext-link></comment> <object-id pub-id-type="pmid">23743342</object-id>.</mixed-citation></ref>
<ref id="pone.0200106.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kemelmacher-Shlizerman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Basri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nadler</surname> <given-names>B</given-names></name>. <article-title>3D shape reconstruction of Mooney faces</article-title>. <source>IEEE Comput Soc Conf Comput Vis Pattern Recogn</source>. <year>2008</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/CVPR.2008.4587769" xlink:type="simple">10.1109/CVPR.2008.4587769</ext-link></comment></mixed-citation></ref>
</ref-list>
</back>
</article>