<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02082</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004490</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Scalability of Asynchronous Networks Is Limited by One-to-One Mapping between Effective Connectivity and Correlations</article-title>
<alt-title alt-title-type="running-head">Limits to Network Scaling</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>van Albada</surname> <given-names>Sacha Jennifer</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Helias</surname> <given-names>Moritz</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Diesmann</surname> <given-names>Markus</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6) and JARA BRAIN Institute I, Jülich Research Centre, Jülich, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Psychiatry, Psychotherapy and Psychosomatics, Medical Faculty, RWTH Aachen University, Aachen, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Physics, Faculty 1, RWTH Aachen University, Aachen, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Latham</surname> <given-names>Peter E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University College London, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Analyzed the data: SJvA MH MD. Wrote the paper: SJvA MH MD. Conceived and designed the study: SJvA MH MD. Developed the theory: SJvA MH MD. Wrote the simulation and analysis code: SJvA MH. Performed the simulations: SJvA MH.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">s.van.albada@fz-juelich.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>9</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>1</day>
<month>9</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>9</issue>
<elocation-id>e1004490</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>11</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>5</day>
<month>8</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>van Albada et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004490" xlink:type="simple"/>
<abstract>
<p>Network models are routinely downscaled compared to nature in terms of numbers of nodes or edges because of a lack of computational resources, often without explicit mention of the limitations this entails. While reliable methods have long existed to adjust parameters such that the first-order statistics of network dynamics are conserved, here we show that limitations already arise if also second-order statistics are to be maintained. The temporal structure of pairwise averaged correlations in the activity of recurrent networks is determined by the effective population-level connectivity. We first show that in general the converse is also true and explicitly mention degenerate cases when this one-to-one relationship does not hold. The one-to-one correspondence between effective connectivity and the temporal structure of pairwise averaged correlations implies that network scalings should preserve the effective connectivity if pairwise averaged correlations are to be held constant. Changes in effective connectivity can even push a network from a linearly stable to an unstable, oscillatory regime and vice versa. On this basis, we derive conditions for the preservation of both mean population-averaged activities and pairwise averaged correlations under a change in numbers of neurons or synapses in the asynchronous regime typical of cortical networks. We find that mean activities and correlation structure can be maintained by an appropriate scaling of the synaptic weights, but only over a range of numbers of synapses that is limited by the variance of external inputs to the network. Our results therefore show that the reducibility of asynchronous networks is fundamentally limited.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Neural networks have two basic components: their structural elements (neurons and synapses), and the dynamics of these constituents. The so-called <italic>effective connectivity</italic> combines both components to yield a measure of the actual influence of physical connections. Previous work showed effective connectivity to determine <italic>correlations</italic>, which quantify the co-activation of different neurons. Conversely, methods for estimating network structure from correlations have been developed. We here extend the range of networks for which the mapping between effective connectivity and correlations can be shown to be one-to-one, and clarify the conditions under which this equivalence holds. These findings apply to a class of networks that is often used, with some variations, to model the activity of cerebral cortex. Since the numbers of neurons and synapses in real mammalian brains are vast, such models tend to be reduced in size for simulation purposes. However, our findings imply that if we wish to retain the original dynamics including correlations, effective connectivity needs to be unchanged, from which we derive scaling laws for synaptic strengths and external inputs, and fundamental limits on the reducibility of network size. The work points to the importance of considering networks with realistic numbers of neurons and synapses.</p>
</abstract>
<funding-group>
<funding-statement>We acknowledge funding by the Helmholtz Association: portfolio theme Supercomputing and Modeling for the Human Brain (SMHB) (MD) and Helmholtz young investigator’s group VH-NG-1028 (MH); and European Union Grants 269921 (BrainScaleS) (SJvA, MD) and 604102 (Human Brain Project, HBP) (MD). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="3"/>
<page-count count="37"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All data and simulation and analysis files are available from the Dryad database: <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://dx.doi.org/10.5061/dryad.2m85h">http://dx.doi.org/10.5061/dryad.2m85h</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>While many aspects of brain dynamics and function remain unexplored, the numbers of neurons and synapses in a given volume are well known, and as such constitute basic parameters that should be taken seriously. Despite rapid advances in neural network simulation technology and increased availability of computing resources [<xref ref-type="bibr" rid="pcbi.1004490.ref001">1</xref>], memory and time constraints still lead to neuronal networks being routinely downscaled both on traditional architectures [<xref ref-type="bibr" rid="pcbi.1004490.ref002">2</xref>] and in systems dedicated to neural network simulation [<xref ref-type="bibr" rid="pcbi.1004490.ref003">3</xref>]. As synapses outnumber neurons by a factor of 10<sup>3</sup> − 10<sup>5</sup>, these constitute the main constraint on network size. Computational capacity ranges from a few tens of millions of synapses on laptop or desktop computers, or on dedicated hardware when fully exploited [<xref ref-type="bibr" rid="pcbi.1004490.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref005">5</xref>], to 10<sup>12</sup> − 10<sup>13</sup> synapses on supercomputers [<xref ref-type="bibr" rid="pcbi.1004490.ref006">6</xref>]. This upper limit is still about two orders of magnitude below the full human brain, underlining the need for downscaling in computational modeling. In fact, any brain model that approximates a fraction of the recurrent connections as external inputs is in some sense downscaled: the missing interactions need to be absorbed into the network and input parameters in order to obtain the appropriate statistics. Unfortunately, the implications of such scaling are usually not investigated.</p>
<p>The opposite type of scaling, taking the infinite size limit, is sometimes used in order to simplify equations describing the network (<xref ref-type="fig" rid="pcbi.1004490.g001">Fig 1A</xref>). Although this can lead to valuable insights, real networks in the human brain often contain on the order of 10<sup>5</sup> − 10<sup>7</sup> neurons (<xref ref-type="fig" rid="pcbi.1004490.g001">Fig 1B</xref>), too few to simplify certain equations in the limit of infinite size. This is illustrated in <xref ref-type="fig" rid="pcbi.1004490.g001">Fig 1C</xref> using as an example the intrinsic contribution to correlations due to fluctuations generated within the network, and the extrinsic contribution due to common external inputs to different neurons in random networks. Although the intrinsic contribution falls off more rapidly than the extrinsic one, it is the main contribution up to large network sizes (around 10<sup>8</sup> for the given parameters). Therefore, taking the infinite size limit and neglecting the intrinsic contribution leads to the wrong conclusions: The small correlations in finite random networks cannot be explained by the network activity tracking the external drive [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>], but rather require the consideration of negative feedback [<xref ref-type="bibr" rid="pcbi.1004490.ref008">8</xref>] that suppresses intrinsically generated and externally imprinted fluctuations alike [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>].</p>
<fig id="pcbi.1004490.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Framework for neural network scaling.</title>
<p><bold>A</bold> Downscaling facilitates simulations, while taking the <italic>N</italic> → ∞ limit often affords analytical insight. <bold>B</bold> Relevant scales. The local cortical microcircuit containing roughly 10<sup>5</sup> neurons is the smallest network where the majority of the synapses (∼ 10<sup>4</sup> per neuron) can be represented using realistic connection probabilities (∼ 0.1). <bold>C</bold> Results for the <italic>N</italic> → ∞ limit may not apply even for large networks. In this example, analytically determined intrinsic and extrinsic contributions to correlations between excitatory neurons are shown. The extrinsic contribution to the correlation between two neurons arises due common external input, and the intrinsic contribution due to fluctuations generated within the network (cf. [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>] Eq 24). The intrinsic contribution falls off more rapidly than the extrinsic contribution, but nevertheless dominates up to large network sizes, here around 10<sup>8</sup>. The crosses indicate simulation results. Adapted from [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>] Fig 7. <bold>D</bold> Scaling transformations may be designed to preserve average single-neuron or pairwise statistics for selected quantities, population statistics, or a combination of these. When average single-neuron and pairwise properties are preserved, the downscaled network of size <italic>N</italic> behaves to second order like a subsample of the full network of size <italic>N</italic><sub>0</sub>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g001"/>
</fig>
<p>Taking the infinite size limit for analytical tractability and downscaling to make networks accessible by direct simulation are two separate problems. We concentrate in the remainder of this study on such downscaling, which is often performed not only in neuroscience [<xref ref-type="bibr" rid="pcbi.1004490.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref013">13</xref>] but also in other disciplines [<xref ref-type="bibr" rid="pcbi.1004490.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref017">17</xref>]. Neurons and synapses may either be subsampled or aggregated [<xref ref-type="bibr" rid="pcbi.1004490.ref018">18</xref>]; here we focus on the former. One intuitive way of scaling is to ensure that the statistics of particular quantities of interest in the downscaled network match those of a subsample of the same size from the full network (<xref ref-type="fig" rid="pcbi.1004490.g001">Fig 1D</xref>). Alternatively, it may sometimes be useful to preserve the statistics of population sums of certain quantities, for instance population fluctuations.</p>
<p>We here focus on the preservation of mean population-averaged activities and pairwise averaged correlations in the activity. We consider both the size and temporal structure of correlations, but not distributions of mean activities and correlations across the network. Means and correlations present themselves as natural quantities to consider, because they are the first- and second-order and as such the most basic measures of the dynamics. If it is already difficult to preserve these measures, it is even less likely that preserving higher-order statistics will be possible, in view of their higher dimensionality. However, other choices are possible, for instance maintaining total input instead of output spike rates [<xref ref-type="bibr" rid="pcbi.1004490.ref019">19</xref>].</p>
<p>Besides being the most basic dynamical characteristics, means and correlations of neural activity are biologically relevant. Mean firing rates are important in many theories of network function [<xref ref-type="bibr" rid="pcbi.1004490.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref021">21</xref>], and their relevance is supported by experimental results [<xref ref-type="bibr" rid="pcbi.1004490.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref023">23</xref>]. For instance, neurons exhibit orientation tuning of spike rate in the visual system [<xref ref-type="bibr" rid="pcbi.1004490.ref024">24</xref>] and directional tuning in the motor system [<xref ref-type="bibr" rid="pcbi.1004490.ref025">25</xref>], and sustained rates are implicated in the working memory function of the prefrontal cortex [<xref ref-type="bibr" rid="pcbi.1004490.ref022">22</xref>]. Firing rates have also been shown to be central to pattern learning and retrieval in highly connected recurrent neural networks [<xref ref-type="bibr" rid="pcbi.1004490.ref021">21</xref>]. Furthermore, mean firing rates distinguish between states of arousal and attention [<xref ref-type="bibr" rid="pcbi.1004490.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref027">27</xref>], and between healthy and disease conditions [<xref ref-type="bibr" rid="pcbi.1004490.ref028">28</xref>]. The relevance of correlations is similarly supported by a large number of findings. They are widely present; multi-unit recordings have revealed correlated neuronal activity in various animals and behavioral conditions [<xref ref-type="bibr" rid="pcbi.1004490.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref031">31</xref>]. Pairwise correlations were even shown to capture the bulk of the structure in the spiking activity of retinal and cultured cortical neurons [<xref ref-type="bibr" rid="pcbi.1004490.ref032">32</xref>]. They are also related to information processing and behavior. Synchronous spiking (corresponding to a narrow peak in the cross-correlogram) has for example been shown to occur in relation to behaviorally relevant events [<xref ref-type="bibr" rid="pcbi.1004490.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref035">35</xref>]. The relevance of correlations for information processing is further established by the fact that they can increase or decrease the signal-to-noise ratio of population signals [<xref ref-type="bibr" rid="pcbi.1004490.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref037">37</xref>]. Moreover, correlations are important in networks with spike-timing-dependent plasticity, since they affect the average change in synaptic strengths [<xref ref-type="bibr" rid="pcbi.1004490.ref038">38</xref>]. Correspondingly, for larger correlations, stronger depression is needed for an equilibrium state with asynchronous firing and a unimodal weight distribution to exist in balanced random networks [<xref ref-type="bibr" rid="pcbi.1004490.ref039">39</xref>]. The level of correlations in neuronal activity has furthermore been shown to affect the spatial range of local field potentials (LFPs) effectively sampled by extracellular electrodes [<xref ref-type="bibr" rid="pcbi.1004490.ref040">40</xref>]. More generally, mesoscopic and macroscopic measures like the LFP and fMRI depend on interneuronal correlations [<xref ref-type="bibr" rid="pcbi.1004490.ref041">41</xref>]. Considering the wide range of dynamical and information processing properties affected by mean activities and correlations, it is important that they are accurately modeled.</p>
<p>We allow the number of neurons <italic>N</italic> and the number of incoming synapses per neuron <italic>K</italic> (the in-degree) to be varied independently, generalizing the common type of scaling where the connection probability is held constant so that <italic>N</italic> and <italic>K</italic> change proportionally. It is well known that reducing the number of neurons in asynchronous networks increases correlation sizes in inverse proportion to the network size [<xref ref-type="bibr" rid="pcbi.1004490.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>]. However, the influence of the number of synapses on the correlations, including their temporal structure, is less studied. When reducing the number of synapses, one may attempt to recover aspects of the network dynamics by adjusting parameters such as the synaptic weights <italic>J</italic>, the external drive, or neurotransmitter release probabilities [<xref ref-type="bibr" rid="pcbi.1004490.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref019">19</xref>]. In the present work, spike transmission is treated as perfectly reliable. We only adjust the synaptic weights and a combination of the neuronal threshold and the mean and variance of the external drive to make up for changes in <italic>N</italic> and <italic>K</italic>.</p>
<p>A few suggestions have been made for adjusting synaptic weights to numbers of synapses. In the balanced random network model, the asynchronous irregular (AI) firing often observed in cortex is explained by a domination of inhibition which causes a mean membrane potential below spike threshold, and sufficiently large fluctuations that trigger spikes [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>]. In order to achieve such an AI state for a large range of network sizes, one choice is to ensure that input fluctuations remain similar in size, and adjust the threshold or a DC drive to maintain the mean distance to threshold. As fluctuations are proportional to <italic>J</italic><sup>2</sup> <italic>K</italic> for independent inputs, this suggests the scaling
<disp-formula id="pcbi.1004490.e001"><alternatives><graphic id="pcbi.1004490.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
proposed in [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>]. Since the mean input to a neuron is proportional to <italic>J</italic> <italic>K</italic>, <xref ref-type="disp-formula" rid="pcbi.1004490.e001">Eq (1)</xref> leads, all else being equal, to an increase of the population feedback with <inline-formula id="pcbi.1004490.e002"><alternatives><graphic id="pcbi.1004490.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e002"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, changing the correlation structure of the network, as illustrated in <xref ref-type="fig" rid="pcbi.1004490.g002">Fig 2</xref> for a simple network of inhibitory leaky integrate-and-fire neurons (note that in this example we fix the connection probability). This suggests the alternative [<xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>]
<disp-formula id="pcbi.1004490.e003"><alternatives><graphic id="pcbi.1004490.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
where now the variance of the external drive needs to be adjusted to maintain the total input variance onto neurons in the network.</p>
<fig id="pcbi.1004490.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Transforming synaptic strengths <italic>J</italic> with the square root of the number of incoming synapses per neuron <italic>K</italic> (the in-degree) upon scaling of network size <italic>N</italic> changes correlation structure when mean and variance of the input current are maintained.</title>
<p>A reference network of 10,000 inhibitory leaky integrate-and-fire neurons is scaled up to 50,000 neurons, fixing the connection probability and adjusting the external Poisson drive to keep the mean and variance of total (external plus internal) inputs fixed. Single-neuron parameters and connection probability are as in <xref ref-type="table" rid="pcbi.1004490.t002">Table 2</xref>. Delays are 1 ms, mean and standard deviation of total inputs are 15 mV and 10 mV, respectively, and the reference network has <italic>J</italic> = 0.1 mV. Each network is simulated for 50 s. <bold>A</bold> Onset of oscillations induced by scaling of network size <italic>N</italic>, visualized by changes in the poles <italic>z</italic> of the covariance function in the frequency domain. Re(<italic>z</italic>) determines the frequency of oscillations and Im(<italic>z</italic>) their damping, such that -Im(<italic>z</italic>) &gt; 0 means that small deviations from the fixed-point activity of the network grow with time [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e157">Eq (76)</xref>]. The transformation <inline-formula id="pcbi.1004490.e004"><alternatives><graphic id="pcbi.1004490.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e004"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> preserves the poles, while <inline-formula id="pcbi.1004490.e005"><alternatives><graphic id="pcbi.1004490.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e005"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> induces a Hopf bifurcation so that the scaled network is outside the linearly stable regime. <bold>B</bold> Covariance in the network where coupling strength <italic>J</italic> is scaled with the in-degree <italic>K</italic> matches that in the reference network, whereas large oscillations appear in the network scaled with <inline-formula id="pcbi.1004490.e006"><alternatives><graphic id="pcbi.1004490.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e006"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>. Colors as in <bold>A</bold>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g002"/>
</fig>
<p>For a given network size <italic>N</italic> and mean activity level, the size and temporal structure of pairwise averaged correlations are determined by the so-called <italic>effective connectivity</italic>, which quantifies the linear dependence of the activity of each target population on the activity of each source population. The effective connectivity is proportional to synaptic strength and the number of synapses a target neuron establishes with the source population, and additionally depends on the activity of the target neurons. Effective connectivity has previously been defined as “the experiment and time-dependent, simplest possible circuit diagram that would replicate the observed timing relationships between the recorded neurons” [<xref ref-type="bibr" rid="pcbi.1004490.ref047">47</xref>]. In our analysis we consider the stationary state, but at different times the network may be in a different state exhibiting a different effective connectivity. The definition of [<xref ref-type="bibr" rid="pcbi.1004490.ref047">47</xref>] highlights the fact that identical neural timing relationships can in principle occur in different physical circuits and vice versa. However, with a given model of interactions or coupling, the activity may allow a unique effective connectivity to be derived [<xref ref-type="bibr" rid="pcbi.1004490.ref048">48</xref>]. We define effective connectivity in a forward manner with knowledge of the physical connectivity as well as the form of interactions. We show in this study that with this model of interactions, and with independent external inputs, the activity indeed determines a unique effective connectivity, so that the forward and reverse definitions coincide. This complements the groundbreaking general insight of [<xref ref-type="bibr" rid="pcbi.1004490.ref047">47</xref>].</p>
<p>We consider networks of binary model neurons and networks of leaky integrate-and-fire (LIF) neurons with current-based synapses to investigate how and to what extent changes in network parameters can be used to preserve mean population-averaged activities and pairwise averaged correlations under reductions in the numbers of neurons and synapses. The parameters allowed to vary are the synaptic weights, neuronal thresholds, and the mean and variance of the external drive. We apply and extend the theory of correlations in randomly connected binary and LIF networks in the asynchronous regime developed in [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref051">51</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>], which explains the smallness and structure of correlations experimentally observed during spontaneous activity in cortex [<xref ref-type="bibr" rid="pcbi.1004490.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref055">55</xref>], and we compare analytical predictions of correlations with results from simulations. The results are organized as follows. In “<bold>Correlations uniquely determine effective connectivity: a simple example</bold>” we provide an intuitive example that illustrates why the effective connectivity uniquely determines correlation structure. In “<bold>Correlations uniquely determine effective connectivity: the general case</bold>” we show that this one-to-one relationship generalizes to networks of several populations apart from degenerate cases. In “<bold>Correlation-preserving scaling</bold>” we conclude that, in general, only scalings that preserve the effective connectivity, such as <italic>J</italic> ∝ 1/<italic>K</italic>, are able to preserve correlations. In “<bold>Limit to in-degree scaling</bold>” we identify the limits of the resulting scaling procedure, demonstrating the restricted scalability of asynchronous networks. “<bold>Robustness of correlation-preserving scaling</bold>” shows that the scaling <italic>J</italic> ∝ 1/<italic>K</italic> can preserve correlations, within the identified restrictive bounds, for different networks either adhering to or deviating from the assumptions of the analytical theory. “<bold>Zero-lag correlations in binary network</bold>” investigates how to maintain the instantaneous correlations in a binary network, while “<bold>Symmetric two-population spiking network</bold>” considers the degenerate case of a connectivity with special symmetries, in which correlations may be maintained under network scaling without preserving the effective connectivity. Preliminary results have been published in abstract form [<xref ref-type="bibr" rid="pcbi.1004490.ref056">56</xref>].</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Correlations uniquely determine effective connectivity: A simple example</title>
<p>In this section we give an intuitive one-dimensional example to show that effective connectivity determines the shapes of the average pairwise cross-covariances and vice versa. For the following, we first introduce a few basic quantities. Consider a binary or spiking network consisting of several excitatory and inhibitory populations with potentially source- and target-type-dependent connectivity. For the spiking networks, we assume leaky integrate-and-fire (LIF) dynamics with exponential synaptic currents. The dynamics of the binary and LIF networks are respectively introduced in “<bold>Binary network dynamics</bold>” and “<bold>Spiking network dynamics</bold>”. We assume irregular network activity, approximated as Poissonian for the spiking network, with population means <italic>ν</italic><sub><italic>α</italic></sub>. For the binary network, <italic>ν</italic> = ⟨<italic>n</italic>⟩ is the expectation value of the binary variable. For the spiking network, we absorb the membrane time constant into <italic>ν</italic>, defining <italic>ν</italic> = <italic>τ</italic><sub>m</sub> <italic>r</italic> where <italic>r</italic> is the firing rate of the population. The external drive can consist of both a DC component <italic>μ</italic><sub><italic>α</italic>,ext</sub> and fluctuations with variance <inline-formula id="pcbi.1004490.e007"><alternatives><graphic id="pcbi.1004490.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e007"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mtext mathvariant="normal">ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, provided either by Poisson spikes or by a Gaussian current. The working points of each population, characterized by mean <italic>μ</italic><sub><italic>α</italic></sub> and variance <inline-formula id="pcbi.1004490.e008"><alternatives><graphic id="pcbi.1004490.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e008"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>α</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> of the combined input from within and outside the network, are given by
<disp-formula id="pcbi.1004490.e009"><alternatives><graphic id="pcbi.1004490.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e009"/><mml:math id="M9" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>μ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>β</mml:mi></mml:munder> <mml:msub><mml:mi>J</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>K</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>β</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula> <disp-formula id="pcbi.1004490.e010"><alternatives><graphic id="pcbi.1004490.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>β</mml:mi></mml:munder> <mml:msubsup><mml:mi>J</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>K</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mi>β</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext> <mml:mo>.</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula> <disp-formula id="pcbi.1004490.e011"><alternatives><graphic id="pcbi.1004490.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e011"/><mml:math id="M11" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtext>with</mml:mtext></mml:mtd> <mml:mtd/><mml:mtd columnalign="left"><mml:mrow/></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mi>ϕ</mml:mi></mml:mtd> <mml:mtd><mml:mo>≡</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext> <mml:mspace width="0.222222em"/><mml:mtext>binary</mml:mtext></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mi>ν</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext> <mml:mspace width="0.222222em"/><mml:mtext>LIF</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>J</italic><sub><italic>αβ</italic></sub> is the synaptic strength from population <italic>β</italic> to population <italic>α</italic>, and <italic>K</italic><sub><italic>αβ</italic></sub> is the number of synapses per target neuron (the in-degree) for the corresponding projection (we use ≡ in the sense of “is defined as”). We call <inline-formula id="pcbi.1004490.e012"><alternatives><graphic id="pcbi.1004490.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e012"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mtext mathvariant="normal">ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> “external variance” in the following, and the remainder “internal variance”. The mean population activities are determined by <italic>μ</italic><sub><italic>α</italic></sub> and <italic>σ</italic><sub><italic>α</italic></sub> according to Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e095">39</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e139">67</xref>). Expressions for correlations in binary and LIF networks are given respectively in “<bold>First and second moments of activity in the binary network</bold>” and “<bold>First and second moments of activity in the spiking network</bold>”.</p>
<p>As a one-dimensional example, consider a binary network with a single population and vanishing transmission delays. The effective connectivity <bold>W</bold> is just a scalar, and the population-averaged autocovariance <bold>a</bold> and cross-covariance <bold>c</bold> are functions of the time lag Δ. We define the population-averaged effective connectivity as
<disp-formula id="pcbi.1004490.e013"><alternatives><graphic id="pcbi.1004490.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>W</mml:mi> <mml:mo>=</mml:mo> <mml:mi>w</mml:mi> <mml:mo>(</mml:mo> <mml:mi>J</mml:mi> <mml:mo>,</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>K</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>w</italic>(<italic>J</italic>, <italic>μ</italic>, <italic>σ</italic>) is an effective synaptic weight that depends on the mean <italic>μ</italic> [<xref ref-type="disp-formula" rid="pcbi.1004490.e009">Eq (3)</xref>] and the variance <italic>σ</italic><sup>2</sup> [<xref ref-type="disp-formula" rid="pcbi.1004490.e010">Eq (4)</xref>] of the input. For LIF networks, <italic>w</italic> = ∂<italic>r</italic><sub>target</sub>/∂<italic>r</italic><sub>source</sub> is defined via <xref ref-type="disp-formula" rid="pcbi.1004490.e141">Eq (68)</xref> and can be obtained as the derivative of <xref ref-type="disp-formula" rid="pcbi.1004490.e139">Eq (67)</xref>. Note that we treat the effective influence of individual inputs as independent. A more accurate definition of the population-level effective connectivity, beyond the scope of this paper, could be obtained by also considering combinations of inputs in the sense of a Volterra series [<xref ref-type="bibr" rid="pcbi.1004490.ref057">57</xref>]. When the dependence of <italic>w</italic> on <italic>J</italic> is linearized, the effective connectivity can be written as
<disp-formula id="pcbi.1004490.e014"><alternatives><graphic id="pcbi.1004490.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e014"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>W</mml:mi> <mml:mo>=</mml:mo> <mml:mi>S</mml:mi> <mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>J</mml:mi> <mml:mi>K</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where the susceptibility <italic>S</italic>(<italic>μ</italic>, <italic>σ</italic>) measures to linear order the effect of a unit input to a neuron on its outgoing activity. In our one-dimensional example, <italic>W</italic> quantifies the self-influence of an activity fluctuation back onto the population. Expressed in these measures, the differential equation for the covariance function [<xref ref-type="disp-formula" rid="pcbi.1004490.e111">Eq (52)</xref>] takes the form
<disp-formula id="pcbi.1004490.e015"><alternatives><graphic id="pcbi.1004490.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mi>τ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>W</mml:mi></mml:mrow></mml:mfrac> <mml:mfrac><mml:mi>d</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:mfrac> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>W</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>W</mml:mi></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>a</mml:mi> <mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
with initial condition [from <xref ref-type="disp-formula" rid="pcbi.1004490.e098">Eq (41)</xref>]
<disp-formula id="pcbi.1004490.e016"><alternatives><graphic id="pcbi.1004490.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e016"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>W</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>W</mml:mi> <mml:mi>a</mml:mi></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
which is solved by
<disp-formula id="pcbi.1004490.e017"><alternatives><graphic id="pcbi.1004490.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e017"/><mml:math id="M17" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>W</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>W</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:mi>N</mml:mi></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mo>Δ</mml:mo> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula> <xref ref-type="disp-formula" rid="pcbi.1004490.e017">Eq (10)</xref> shows that the effective connectivity <italic>W</italic> together with the time constant <italic>τ</italic> of the neuron (which we assume fixed under scaling) determines the temporal structure of the correlations. Furthermore, since a sum of exponentials cannot equal a sum of exponentials with a different set of exponents, the temporal structure of the correlations uniquely determines <italic>W</italic>. Hence we see that there is a one-to-one correspondence between <italic>W</italic> and the correlation structure if the time constant <italic>τ</italic> is fixed, which implies that preserving correlation structure under a reduction in the in-degrees <italic>K</italic> requires adjusting the effective synaptic weights <italic>w</italic>(<italic>J</italic>, <italic>μ</italic>, <italic>σ</italic>) such that the effective connectivity <italic>W</italic> is maintained. If, in addition, the mean activity ⟨<italic>n</italic>⟩ is kept constant this also fixes the variance <italic>a</italic> = ⟨<italic>n</italic>⟩(1 − ⟨<italic>n</italic>⟩). <xref ref-type="disp-formula" rid="pcbi.1004490.e017">Eq (10)</xref> shows that, under these circumstances with <italic>W</italic> and <italic>a</italic> fixed, correlation sizes are determined by <italic>N</italic>.</p>
</sec>
<sec id="sec004">
<title>Correlations uniquely determine effective connectivity: The general case</title>
<p>More generally, networks consist of several neural populations each with different dynamic properties and with population-dependent transmission delays dαβ. Since this setting does not introduce additional symmetries, intuitively the one-to-one relationship between the effective connectivity and the correlations should still hold. We here show that, under certain conditions, this is indeed the case.</p>
<p>Instead of considering the covariance matrix in the time domain, for population-dependent dynamic properties we find it convenient to stay in the frequency domain. The influence of a fluctuating input on the output of the neuron can to lowest order be described by the transfer function <italic>H</italic>(<italic>ω</italic>). This quantity measures the amplitude and phase of the modulation of the neuronal activity given that the neuron receives a small sinusoidal perturbation of frequency <italic>ω</italic> in its input. The transfer function depends on the mean <italic>μ</italic> [<xref ref-type="disp-formula" rid="pcbi.1004490.e009">Eq (3)</xref>] and the variance <italic>σ</italic><sup>2</sup> [<xref ref-type="disp-formula" rid="pcbi.1004490.e010">Eq (4)</xref>] of the input to the neuron. We here first consider LIF networks; in the Supporting Information we show how the results carry over to the binary model.</p>
<p>In “<bold>First and second moments of activity in the spiking network</bold>”, we give the covariance matrix including the autocovariances in the frequency domain, <inline-formula id="pcbi.1004490.e018"><alternatives><graphic id="pcbi.1004490.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e018"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>+</mml:mo> <mml:mtext mathvariant="bold">A</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, as
<disp-formula id="pcbi.1004490.e019"><alternatives><graphic id="pcbi.1004490.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e019"/><mml:math id="M19" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where <bold>M</bold> has elements <italic>H</italic><sub><italic>αβ</italic></sub>(<italic>ω</italic>)<italic>W</italic><sub><italic>αβ</italic></sub>. If <inline-formula id="pcbi.1004490.e020"><alternatives><graphic id="pcbi.1004490.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e020"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is invertible, we can expand the inverse of <xref ref-type="disp-formula" rid="pcbi.1004490.e019">Eq (11)</xref> to obtain
<disp-formula id="pcbi.1004490.e021"><alternatives><graphic id="pcbi.1004490.e021g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e021"/><mml:math id="M21" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>γ</mml:mi></mml:munder> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>γ</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>M</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>γ</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>M</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>[</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>β</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>β</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>γ</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>γ</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>γ</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
where we assumed the transfer function to have the form <inline-formula id="pcbi.1004490.e022"><alternatives><graphic id="pcbi.1004490.e022g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e022"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> which is often a good approximation for the LIF model [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>]. In the second step we distinguish terms that only contribute on the diagonal (<italic>α</italic> = <italic>β</italic>), those that only contribute off the diagonal (<italic>α</italic> ≠ <italic>β</italic>), and those that contribute in either case. For <italic>α</italic> = <italic>β</italic>, only the first and last terms contribute, and we get
<disp-formula id="pcbi.1004490.e023"><alternatives><graphic id="pcbi.1004490.e023g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e023"/><mml:math id="M23" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>-</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>A</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac> <mml:mo>(</mml:mo> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>γ</mml:mi></mml:munder> <mml:mfrac><mml:mrow><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>γ</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>ω</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>γ</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
If we want to preserve <inline-formula id="pcbi.1004490.e024"><alternatives><graphic id="pcbi.1004490.e024g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e024"/><mml:math id="M24" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, this fixes <italic>A</italic><sub><italic>α</italic></sub> and thereby also <italic>W</italic><sub><italic>αα</italic></sub>, since it multiplies terms with unique <italic>ω</italic>-dependence. For <italic>α</italic> ≠ <italic>β</italic>, we obtain
<disp-formula id="pcbi.1004490.e025"><alternatives><graphic id="pcbi.1004490.e025g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e025"/><mml:math id="M25" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>A</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>ω</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>A</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>ω</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>β</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>β</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>γ</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>ω</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>γ</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
With <italic>A</italic><sub><italic>α</italic></sub> fixed, this additionally fixes <italic>W</italic><sub><italic>αβ</italic></sub>, in view of the unique <italic>ω</italic>-dependence it multiplies.</p>
<p>Since <inline-formula id="pcbi.1004490.e026"><alternatives><graphic id="pcbi.1004490.e026g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e026"/><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>−</mml:mo> <mml:mtext mathvariant="bold">A</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula>, a constraint on <bold>A</bold> necessary for preserving <inline-formula id="pcbi.1004490.e027"><alternatives><graphic id="pcbi.1004490.e027g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e027"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> may not translate into the same constraint when we only require the cross-covariances <bold>C</bold>(<italic>ω</italic>) to be preserved. However, <bold>C</bold>(<italic>ω</italic>) and <inline-formula id="pcbi.1004490.e028"><alternatives><graphic id="pcbi.1004490.e028g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e028"/><mml:math id="M28" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> have identical <italic>ω</italic>-dependence, as they differ only by constants on the diagonal (approximating autocorrelations as delta functions in the time domain [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>]). To derive conditions for preserving <bold>C</bold>(<italic>ω</italic>), we therefore ignore the constraint on <bold>A</bold> but still require the <italic>ω</italic>-dependence to be unchanged. A potential transformation leaving the <italic>ω</italic>-dependent terms in both Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e023">13</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e025">14</xref>) unchanged is <italic>A</italic><sub><italic>α</italic></sub> → <italic>kA</italic><sub><italic>α</italic></sub>, <italic>W</italic><sub><italic>αβ</italic></sub> → <italic>kW</italic><sub><italic>αβ</italic></sub>, <italic>W</italic><sub><italic>αα</italic></sub> → <italic>kW</italic><sub><italic>αα</italic></sub>, but this only works if <italic>τ</italic><sub><italic>α</italic></sub> = <italic>τ</italic><sub><italic>γ</italic></sub>, <italic>d</italic><sub><italic>αα</italic></sub> − <italic>d</italic><sub><italic>αβ</italic></sub> = <italic>d</italic><sub><italic>γα</italic></sub> − <italic>d</italic><sub><italic>γβ</italic></sub> for some <italic>γ</italic>, and if the terms for the corresponding <italic>γ</italic> are also transformed to offset the change in <inline-formula id="pcbi.1004490.e029"><alternatives><graphic id="pcbi.1004490.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e029"/><mml:math id="M29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mi>A</mml:mi> <mml:mi>α</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; or if some of the entries of <bold>W</bold> vanish. The <italic>ω</italic>-dependence of <inline-formula id="pcbi.1004490.e030"><alternatives><graphic id="pcbi.1004490.e030g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e030"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> and <bold>C</bold> would otherwise change, showing that, at least in the absence of such symmetries in the delays or time constants, or zeros in the effective connectivity matrix (i.e., absent connections at the population level, or inactive populations), there is a one-to-one relationship between covariances and effective connectivity. Hence, preserving the covariances requires preserving <bold>A</bold> and <bold>W</bold> except in degenerate cases. Note that the autocovariances and hence the firing rates can be changed while affecting only the size but not the shape of the correlations, but that the correlation shapes determine <bold>W</bold>.</p>
<p>Even in case of identical transfer functions across populations, including in particular equal transmission delays and identical <italic>τ</italic>, the one-to-one correspondence between effective connectivity and correlations can be demonstrated except for a narrower set of degenerate cases. The argument for <italic>d</italic> = 0 proceeds in the time domain along the same lines as “<bold>Correlations uniquely determine effective connectivity: a simple example</bold>”, using the fact that for a population-independent transfer function, the correlations can be expressed in terms of the eigenvalues and eigenvectors of the effective connectivity matrix (cf. “<bold>First and second moments of activity in the binary network</bold>” and “<bold>First and second moments of activity in the spiking network</bold>”). For general delays, a derivation in the frequency domain can be used. Through these arguments, we show in the Supporting Information that the one-to-one correspondence holds at least if <bold>W</bold> is diagonalizable and has no eigenvalues that are zero or degenerate.</p>
</sec>
<sec id="sec005">
<title>Correlation-preserving scaling</title>
<p>If the working point (<italic>μ</italic>, <italic>σ</italic>) is maintained, the one-to-one correspondence between the effective connectivity and the correlations implies that requiring unchanged average covariances leaves no freedom for network scaling except for a possible trade-off between in-degrees and synaptic weights. In the linear approximation <italic>W</italic>(<italic>J</italic>, <italic>μ</italic>, <italic>σ</italic>) = <italic>S</italic>(<italic>μ</italic>, <italic>σ</italic>)<italic>JK</italic>, this trade-off is <italic>J</italic> ∝ 1/<italic>K</italic>.</p>
<p>When this scaling is implemented naively without adjusting the external drive to recover the original working point, the covariances change, as illustrated in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3B</xref> for a two-population binary network with parameters given in <xref ref-type="table" rid="pcbi.1004490.t001">Table 1</xref>. The results of <italic>J</italic> ∝ 1/<italic>K</italic> scaling with appropriate adjustment of the external drive are shown in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3C</xref>. The scaling shown in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3B</xref> also increases the mean activities (E: from 0.16 to 0.23, I: from 0.07 to 0.11), whereas that in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3C</xref> preserves them.</p>
<fig id="pcbi.1004490.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Correlations from theory and simulations for a two-population binary network with asymmetric connectivity.</title>
<p><bold>A</bold> Average pairwise cross-covariances from simulations (solid curves) and <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref> (dashed curves). <bold>B</bold> Naive scaling with <italic>J</italic> ∝ 1/<italic>K</italic> but without adjustment of the external drive changes the correlation structure. <bold>C</bold> With an appropriate adjustment of the external drive (<italic>σ</italic><sub>ex</sub> = 53.4, <italic>σ</italic><sub>ix</sub> = 17.7), scaling synaptic weights as <italic>J</italic> ∝ 1/<italic>K</italic> is able to preserve correlation structure as long as <italic>N</italic> and <italic>K</italic> are reduced by comparable factors. <bold>D</bold> The same holds for <inline-formula id="pcbi.1004490.e031"><alternatives><graphic id="pcbi.1004490.e031g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e031"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> (<italic>μ</italic><sub>ex</sub> = 43.3, <italic>μ</italic><sub>ix</sub> = 34.6, <italic>σ</italic><sub>ex</sub> = 46.2, <italic>σ</italic><sub>ix</sub> = 15.3), but the susceptibility <italic>S</italic> is increased by about 20% already for <italic>N</italic> = 0.75 <italic>N</italic><sub>0</sub> in this case. In <bold>B</bold>, <bold>C</bold>, and <bold>D</bold>, results of simulations are shown. The curves in <bold>C</bold> and <bold>D</bold> are identical because internal inputs, the standard deviation of the external drive, and the distance to threshold due to the DC component of the drive in <bold>D</bold> are exactly <inline-formula id="pcbi.1004490.e032"><alternatives><graphic id="pcbi.1004490.e032g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e032"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mfrac><mml:mi>K</mml:mi> <mml:msub><mml:mi>K</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> times those in <bold>C</bold>. Hence, identical realizations of the random numbers for the connectivity and the Gaussian external drive cause the total inputs to the neurons to exceed the threshold at exactly the same points in time in the two simulations. The simulated time is 30 s, and the population activity is sampled at a resolution of 0.3 ms.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g003"/>
</fig>
<table-wrap id="pcbi.1004490.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.t001</object-id>
<label>Table 1</label>
<caption>
<title>Parameters of the asymmetric binary network.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004490.t001g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.t001"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<tbody>
<tr>
<td align="center" rowspan="1" colspan="1">numbers of neurons</td>
<td align="center" rowspan="1" colspan="1"><italic>N</italic><sub>e</sub>, <italic>N</italic><sub>i</sub></td>
<td align="center" rowspan="1" colspan="1">5000, 5000</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">neuron time constant</td>
<td align="center" rowspan="1" colspan="1"><italic>τ</italic></td>
<td align="center" rowspan="1" colspan="1">10 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">threshold</td>
<td align="center" rowspan="1" colspan="1"><italic>θ</italic></td>
<td align="center" rowspan="1" colspan="1">0</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">connection probabilities</td>
<td align="center" rowspan="1" colspan="1"><italic>p</italic><sub>ee</sub>, <italic>p</italic><sub>ei</sub>, <italic>p</italic><sub>ie</sub>, <italic>p</italic><sub>ii</sub></td>
<td align="center" rowspan="1" colspan="1">0.1, 0.2, 0.3, 0.4</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">transmission delay</td>
<td align="center" rowspan="1" colspan="1"><italic>d</italic></td>
<td align="center" rowspan="1" colspan="1">0.1 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">synaptic weights</td>
<td align="center" rowspan="1" colspan="1"><italic>J</italic><sub>ee</sub>, <italic>J</italic><sub>ei</sub>, <italic>J</italic><sub>ie</sub>, <italic>J</italic><sub>ii</sub></td>
<td align="center" rowspan="1" colspan="1">3, −5, 3, −6</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">mean external drive</td>
<td align="center" rowspan="1" colspan="1"><italic>m</italic><sub>ex</sub>, <italic>m</italic><sub>ix</sub></td>
<td align="center" rowspan="1" colspan="1">50, 40</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">SD of external drive</td>
<td align="center" rowspan="1" colspan="1"><italic>σ</italic><sub>ex</sub>, <italic>σ</italic><sub>ix</sub></td>
<td align="center" rowspan="1" colspan="1">60, 50</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>If one relaxes the constraint on the working point while still requiring mean activities to be preserved, the network does have additional symmetries due to the fact that only some combination of <italic>μ</italic> and <italic>σ</italic> needs to be fixed, rather than each of these separately. This combination is more easily determined for binary than for LIF networks, for which the mean firing rates depend on <italic>μ</italic> and <italic>σ</italic> in a complex manner [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e139">Eq (67)</xref>]. When the derivative of the gain function is narrow (e.g., having zero width in the case of the Heaviside function used here) compared to the input distribution, the mean activities of binary networks depend only on (<italic>μ</italic> − <italic>θ</italic>)/<italic>σ</italic> [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>]. Changing <italic>σ</italic> while preserving (<italic>μ</italic> − <italic>θ</italic>)/<italic>σ</italic> leads for a Heaviside gain function to a new susceptibility <italic>S</italic>′ = (<italic>σ</italic>/<italic>σ</italic>′)<italic>S</italic> [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e100">Eq (43)</xref>]. For constant <italic>K</italic>, if the standard deviation of the external drive is changed proportionally to the internal standard deviation, we have <italic>σ</italic> ∝ <italic>J</italic> and thus <italic>J</italic>′ <italic>S</italic>′ = <italic>JS</italic>, implying an insensitivity of the covariances to the synaptic weights <italic>J</italic> [<xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>]. In particular, this symmetry applies in the absence of an external drive. When <italic>K</italic> is altered, this choice for adjusting the external drive causes the covariances to change. However, adjusting the external drive such that <italic>σ</italic>′/<italic>σ</italic> = (<italic>J</italic>′ <italic>K</italic>′)/(<italic>JK</italic>), the change in <italic>S</italic> is countered to preserve <bold>W</bold> and correlations. This is illustrated in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3D</xref> for <inline-formula id="pcbi.1004490.e033"><alternatives><graphic id="pcbi.1004490.e033g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e033"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, which is another natural choice, as it preserves the internal variance if one ignores the typically small contribution of the correlations to the input variance ([<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>] Fig 3D illustrates the smallness of this contribution for an example network). This is only one of a continuum of possible scalings preserving mean activities and covariances (within the bounds described in the following section) when the working point and hence the susceptibility are allowed to change.</p>
</sec>
<sec id="sec006">
<title>Limit to in-degree scaling</title>
<p>We now show that both the scaling <italic>J</italic> ∝ 1/<italic>K</italic> for LIF networks (for which we do not consider changes to the working point, as analytic expressions for countering these changes are intractable), and correlation-preserving scalings for binary networks (where we allow changes to the working point that preserve mean activities) are applicable only up to a limit that depends on the external variance.</p>
<p>For the binary network, assume a generic scaling <italic>K</italic>′ = <italic>κK</italic>, <italic>J</italic>′ = <italic>ιJ</italic> and a Heaviside gain function. We denote variances due to inputs from within the network and due to the external drive respectively by <inline-formula id="pcbi.1004490.e034"><alternatives><graphic id="pcbi.1004490.e034g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e034"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004490.e035"><alternatives><graphic id="pcbi.1004490.e035g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e035"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> The preservation of the mean activities implies <italic>S</italic>′ = (<italic>σ</italic>/<italic>σ</italic>′)<italic>S</italic> as above, where <inline-formula id="pcbi.1004490.e036"><alternatives><graphic id="pcbi.1004490.e036g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e036"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. To keep <italic>SJK</italic> fixed we thus require
<disp-formula id="pcbi.1004490.e037"><alternatives><graphic id="pcbi.1004490.e037g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e037"/><mml:math id="M37" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mspace width="0.166667em"/><mml:mo>′</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mspace width="0.166667em"/><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ι</mml:mi> <mml:mi>κ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mspace width="0.166667em"/><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>ι</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>κ</mml:mi> <mml:mo>[</mml:mo> <mml:mo>(</mml:mo> <mml:mi>κ</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>κ</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
where we have used <inline-formula id="pcbi.1004490.e038"><alternatives><graphic id="pcbi.1004490.e038g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e038"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>≈</mml:mo> <mml:mi>ι</mml:mi> <mml:msqrt><mml:mi>κ</mml:mi></mml:msqrt> <mml:msub><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> in the second line. For <italic>σ</italic><sub>ext</sub> = 0 this scaling only works for <italic>κ</italic> &gt; 1, i.e., increasing instead of decreasing the in-degrees. More generally, the limit to downscaling occurs when <inline-formula id="pcbi.1004490.e039"><alternatives><graphic id="pcbi.1004490.e039g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e039"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> or
<disp-formula id="pcbi.1004490.e040"><alternatives><graphic id="pcbi.1004490.e040g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e040"/><mml:math id="M40" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>κ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
independent of the scaling of the synaptic weights. Thus, larger external and smaller internal variance before scaling allow a greater reduction in the number of synapses. The in-degrees of the example network of <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3</xref> could be maximally reduced to 73%. Note that <italic>ι</italic> could in principle be chosen in a <italic>κ</italic>-dependent manner such that <inline-formula id="pcbi.1004490.e041"><alternatives><graphic id="pcbi.1004490.e041g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e041"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is fixed or increased instead of decreased upon downscaling, namely <inline-formula id="pcbi.1004490.e042"><alternatives><graphic id="pcbi.1004490.e042g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e042"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:mi>ι</mml:mi> <mml:mo>≥</mml:mo> <mml:msqrt><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msup><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>κ</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>κ</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>. However, <xref ref-type="disp-formula" rid="pcbi.1004490.e040">Eq (16)</xref> is still the limit beyond which this fails, as <italic>ι</italic> then diverges at that point.</p>
<p>Note that the limit to the in-degree scaling also implies a limit on the reduction in the number of neurons for which the scaling equations derived here allow the correlation structure to be preserved, as a greater reduction of <italic>N</italic> compared to <italic>K</italic> increases the number of common inputs neurons receive and thereby the deviation from the assumptions of the diffusion approximation. This is shown by the thin curves in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3C,3D</xref>.</p>
<p>Now consider correlation-preserving scaling of LIF networks. Reduced <italic>K</italic> with constant <italic>JK</italic> does not affect mean inputs [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e009">Eq (3)</xref>] but increases the internal variance according to <xref ref-type="disp-formula" rid="pcbi.1004490.e010">Eq (4)</xref>. To maintain the working point (<italic>μ</italic>, <italic>σ</italic>), it is therefore necessary to reduce the variance of the external drive. When the drive consists of excitatory Poisson input, one way of keeping the mean external drive constant while changing the variance is to add an inhibitory Poisson drive. With <italic>K</italic>′ = <italic>K</italic>/<italic>ι</italic> and <italic>J</italic>′ = <italic>ιJ</italic>, the change in internal variance is <inline-formula id="pcbi.1004490.e043"><alternatives><graphic id="pcbi.1004490.e043g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e043"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>ι</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004490.e044"><alternatives><graphic id="pcbi.1004490.e044g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e044"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">int</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the internal variance due to input currents in the full-scale model. This is canceled by an opposite change in <inline-formula id="pcbi.1004490.e045"><alternatives><graphic id="pcbi.1004490.e045g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e045"/><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> by choosing excitatory and inhibitory Poisson rates
<disp-formula id="pcbi.1004490.e046"><alternatives><graphic id="pcbi.1004490.e046g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e046"/><mml:math id="M46" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">e</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">e</mml:mi> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>ι</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msubsup><mml:mi>J</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula> <disp-formula id="pcbi.1004490.e047"><alternatives><graphic id="pcbi.1004490.e047g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e047"/><mml:math id="M47" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">i</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>ι</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msubsup><mml:mi>J</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
where <italic>r</italic><sub>e,0</sub> is the Poisson rate in the full-scale model, and the excitatory and inhibitory synapses have weights <italic>J</italic><sub>ext</sub> and −<italic>g</italic> <italic>J</italic><sub>ext</sub>, respectively. Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e046">17</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e047">18</xref>) match Eq (E.1) in [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>] except for the 1 + <italic>g</italic> in the denominator, which was there erroneously given as 1+<italic>g</italic><sup>2</sup>. Since downscaling <italic>K</italic> implies <italic>ι</italic> &gt; 1, it is seen that the required rate of the inhibitory inputs is negative. Therefore, this method only allows upscaling. An alternative is to use a balanced Poisson drive with weights <italic>J</italic><sub>ext</sub> and − <italic>J</italic><sub>ext</sub>, choosing the rate of both excitatory and inhibitory inputs to generate the desired variance, and adding a DC drive <italic>I</italic><sub>ext</sub> to recover the mean input,
<disp-formula id="pcbi.1004490.e048"><alternatives><graphic id="pcbi.1004490.e048g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e048"/><mml:math id="M48" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">e</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">i</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">e</mml:mi> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>ι</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>int</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msubsup><mml:mi>J</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula> <disp-formula id="pcbi.1004490.e049"><alternatives><graphic id="pcbi.1004490.e049g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e049"/><mml:math id="M49" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>I</mml:mi> <mml:mtext>ext</mml:mtext></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi mathvariant="normal">e</mml:mi> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:msub><mml:mi>J</mml:mi> <mml:mtext>ext</mml:mtext></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
In this manner, the network can be downscaled up to the point where the variance of the external drive vanishes. Substituting this condition into <xref ref-type="disp-formula" rid="pcbi.1004490.e037">Eq (15)</xref>, the same expression for the minimal in-degree scaling factor <xref ref-type="disp-formula" rid="pcbi.1004490.e040">Eq (16)</xref> is obtained as for the binary network.</p>
</sec>
<sec id="sec007">
<title>Robustness of correlation-preserving scaling</title>
<p>In this section, we show that the scaling <italic>J</italic> ∝ 1/<italic>K</italic>, which maintains the population-level feedback quantified by the effective connectivity, can preserve correlations (within the bounds given in “<bold>Limit to in-degree scaling</bold>”) under fairly general conditions. To this end, we consider two types of networks: 1. a multi-layer cortical microcircuit model with distributed in- and out-degrees and lognormally distributed synaptic strengths (cf. “<bold>Network structure and notation</bold>”); 2. a two-population LIF network with different mean firing rates (parameters in <xref ref-type="table" rid="pcbi.1004490.t002">Table 2</xref>). For both types of models, we contrast the scaling <italic>J</italic> ∝ 1/<italic>K</italic> with <inline-formula id="pcbi.1004490.e050"><alternatives><graphic id="pcbi.1004490.e050g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e050"/><mml:math id="M50" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, in each case maintaining the working point given by Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e009">3</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e010">4</xref>). <xref ref-type="fig" rid="pcbi.1004490.g004">Fig 4</xref> illustrates that the former closely preserves average pairwise cross-covariances in the cortical microcircuit model, whereas the latter changes both their size and temporal structure.</p>
<table-wrap id="pcbi.1004490.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.t002</object-id>
<label>Table 2</label>
<caption>
<title>Full-scale parameters of the two-population spiking networks used to demonstrate the robustness of <italic>J</italic> ∝ 1/<italic>K</italic> scaling to mean firing rates.</title>
<p>The two networks are distinguished by their external drives.</p>
</caption>
<alternatives>
<graphic id="pcbi.1004490.t002g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.t002"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<tbody>
<tr>
<td align="center" rowspan="1" colspan="1">number of excitatory neurons</td>
<td align="center" rowspan="1" colspan="1"><italic>N</italic></td>
<td align="center" rowspan="1" colspan="1">8000</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">relative inhibitory population size</td>
<td align="center" rowspan="1" colspan="1"><italic>γ</italic></td>
<td align="center" rowspan="1" colspan="1">0.25</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">membrane time constant</td>
<td align="center" rowspan="1" colspan="1"><italic>τ</italic><sub>m</sub></td>
<td align="center" rowspan="1" colspan="1">20 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">synaptic time constant</td>
<td align="center" rowspan="1" colspan="1"><italic>τ</italic><sub>s</sub></td>
<td align="center" rowspan="1" colspan="1">2 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">refractory period</td>
<td align="center" rowspan="1" colspan="1"><italic>τ</italic><sub>ref</sub></td>
<td align="center" rowspan="1" colspan="1">2 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">membrane resistance</td>
<td align="center" rowspan="1" colspan="1"><italic>R</italic><sub>m</sub></td>
<td align="center" rowspan="1" colspan="1">20 MΩ</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">resting and reset potential</td>
<td align="center" rowspan="1" colspan="1"><italic>V</italic><sub>r</sub></td>
<td align="center" rowspan="1" colspan="1">0 mV</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">threshold</td>
<td align="center" rowspan="1" colspan="1"><italic>θ</italic></td>
<td align="center" rowspan="1" colspan="1">15 mV</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">connection probability</td>
<td align="center" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="center" rowspan="1" colspan="1">0.1</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">transmission delay</td>
<td align="center" rowspan="1" colspan="1"><italic>d</italic></td>
<td align="center" rowspan="1" colspan="1">3 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">excitatory synaptic weight</td>
<td align="center" rowspan="1" colspan="1"><italic>J</italic></td>
<td align="center" rowspan="1" colspan="1">0.1 mV</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">relative inhibitory synaptic weight</td>
<td align="center" rowspan="1" colspan="1"><italic>g</italic></td>
<td align="center" rowspan="1" colspan="1">5</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">mean and standard deviation of external drive</td>
<td align="center" rowspan="1" colspan="1">(<italic>μ</italic><sub>ext</sub>, <italic>σ</italic><sub>ext</sub>)</td>
<td align="center" rowspan="1" colspan="1">(10 mV, 5 mV);</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1"/>
<td align="center" rowspan="1" colspan="1"/>
<td align="center" rowspan="1" colspan="1">(25 mV, 20 mV)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="pcbi.1004490.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Within the restrictive bounds imposed by <xref ref-type="disp-formula" rid="pcbi.1004490.e040">Eq (16)</xref>, preserving effective connectivity can preserve correlations also in a complex network.</title>
<p>Simulation results for the cortical microcircuit at full scale and with in-degrees reduced to 90%. Synaptic strengths are scaled as indicated, and the external drive is adjusted to restore the working point. Mean pairwise cross-covariances are shown for population 2/3E. Qualitatively identical results are obtained within and across other populations. The simulation duration is 30 s and covariances are determined with a resolution of 0.5 ms. To enable downscaling with <italic>J</italic> ∝ 1/<italic>K</italic>, the excitatory Poisson input of the original implementation of [<xref ref-type="bibr" rid="pcbi.1004490.ref058">58</xref>] is replaced by balanced inhibitory and excitatory Poisson input with a DC drive according to Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e048">19</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e049">20</xref>). <bold>A</bold> Scaling synaptic strengths as <inline-formula id="pcbi.1004490.e051"><alternatives><graphic id="pcbi.1004490.e051g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e051"/><mml:math id="M51" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> changes the mean covariance. Light green curve: stretching the covariance of the scaled network along the vertical axis to match the zero-lag correlation of the full-scale network shows that not only the size but also the temporal structure of the covariance is affected. <bold>B</bold> Scaling synaptic strengths as <italic>J</italic> ∝ 1/<italic>K</italic> closely preserves the covariance of the full-scale network. However, note that this scaling is only applicable down to the in-degree scaling factor given by <xref ref-type="disp-formula" rid="pcbi.1004490.e040">Eq (16)</xref>, which for this example is approximately 0.9.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g004"/>
</fig>
<p>
<xref ref-type="fig" rid="pcbi.1004490.g005">Fig 5</xref> demonstrates the robustness of <italic>J</italic> ∝ 1/<italic>K</italic> scaling to the firing rate of the network. In this example, both the full-scale network and the downscaled networks receive a balanced Poisson drive producing the desired variance, while the mean input is provided by a DC drive. By changing the parameters of the external drive, we create two networks each with irregular spiking but with widely different mean rates (3.3 spikes/s and 29.6 spikes/s). Downscaling only the number of synapses but not the number of neurons, both the temporal structure and the size of the correlations are closely preserved. Reducing the in-degrees and the number of neurons <italic>N</italic> by the same factor, the correlations are scaled by 1/<italic>N</italic>. Hence, the correlations of the full-scale network of size <italic>N</italic><sub>0</sub> can be estimated simply by multiplying those of the reduced network by <italic>N</italic>/<italic>N</italic><sub>0</sub>. In contrast, <inline-formula id="pcbi.1004490.e052"><alternatives><graphic id="pcbi.1004490.e052g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e052"/><mml:math id="M52" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> changes correlation sizes even when <italic>N</italic> is held constant, and combined scaling of <italic>N</italic> and <italic>K</italic> can therefore not simply be compensated for by the factor <italic>N</italic>/<italic>N</italic><sub>0</sub>. In the high-rate network, the spiking statistics of the neurons is non-Poissonian, as seen from the gap in the autocorrelations (insets in <xref ref-type="fig" rid="pcbi.1004490.g005">Fig 5B, 5D</xref>). Nevertheless, <italic>J</italic> ∝ 1/<italic>K</italic> preserves the correlations more closely than <inline-formula id="pcbi.1004490.e053"><alternatives><graphic id="pcbi.1004490.e053g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e053"/><mml:math id="M53" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, showing that the predicted scaling properties hold beyond the strict domain of validity of the underlying theory.</p>
<fig id="pcbi.1004490.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Scaling synaptic strengths as <italic>J</italic> ∝ 1/<italic>K</italic> can preserve correlations in networks with widely different firing rates.</title>
<p>Results of simulations of a LIF network consisting of one excitatory and one inhibitory population (<xref ref-type="table" rid="pcbi.1004490.t002">Table 2</xref>). Average cross-covariances are determined with a resolution of 0.1 ms and are shown for excitatory-inhibitory neuron pairs. Each network receives a balanced Poisson drive with excitatory and inhibitory rates both given by <inline-formula id="pcbi.1004490.e054"><alternatives><graphic id="pcbi.1004490.e054g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e054"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>/</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:mn>2</mml:mn> <mml:mspace width="0.167em"/><mml:msub><mml:mi>τ</mml:mi> <mml:mtext mathvariant="normal">m</mml:mtext></mml:msub> <mml:mspace width="0.167em"/><mml:msup><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004490.e055"><alternatives><graphic id="pcbi.1004490.e055g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e055"/><mml:math id="M55" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">ext</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is chosen to maintain the working point of the full-scale network. The synaptic strengths for the external drive are 0.1 mV and −0.1 mV for excitatory and inhibitory synapses, respectively. A DC drive with strength <italic>μ</italic><sub>ext</sub> is similarly adjusted to maintain the full-scale working point. All networks are simulated for 100 s. For each population, cross-covariances are computed as averages over all neuron pairs across two disjoint groups of 𝓝 × 1000 neurons, where 𝓝 is the scaling factor for the number of neurons (a given pair has one neuron in each group). Autocovariances are computed as averages over 100 neurons in each population. <bold>A</bold>, <bold>B</bold> Reducing in-degrees <italic>K</italic> to 50% while the number of neurons <italic>N</italic> is held constant, <italic>J</italic> ∝ 1/<italic>K</italic> closely preserves both the size and the shape of the covariances, while <inline-formula id="pcbi.1004490.e056"><alternatives><graphic id="pcbi.1004490.e056g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e056"/><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> diminishes their size. <bold>C</bold>, <bold>D</bold> Reducing both <italic>N</italic> and <italic>K</italic> to 50%, covariance sizes scale with 1/<italic>N</italic> for <italic>J</italic> ∝ 1/<italic>K</italic> but with a different factor for <inline-formula id="pcbi.1004490.e057"><alternatives><graphic id="pcbi.1004490.e057g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e057"/><mml:math id="M57" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>. Dashed curves represent theoretical predictions. The insets show mean autocovariances for time lags Δ ∈ (−30, 30) ms.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g005"/>
</fig>
</sec>
<sec id="sec008">
<title>Zero-lag correlations in binary network</title>
<p>Although it is not generally possible to keep mean activities and correlations invariant upon downscaling, transformations may be found when only one aspect of the correlations is important, such as their zero-lag values. We illustrate this using a simple, randomly connected binary network of <italic>N</italic> excitatory and <italic>γN</italic> inhibitory binary neurons, where each neuron receives <italic>K</italic> = <italic>pN</italic> excitatory and <italic>γK</italic> inhibitory inputs. The parameters are given in <xref ref-type="table" rid="pcbi.1004490.t003">Table 3</xref>. The linearized effective connectivity matrix for this example is
<disp-formula id="pcbi.1004490.e058"><alternatives><graphic id="pcbi.1004490.e058g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e058"/><mml:math id="M58" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>=</mml:mo> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>J</mml:mi> <mml:mi>K</mml:mi> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula></p>
<table-wrap id="pcbi.1004490.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.t003</object-id>
<label>Table 3</label>
<caption>
<title>Parameters of the symmetric binary network.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004490.t003g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.t003"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<tbody>
<tr>
<td align="center" rowspan="1" colspan="1">number of excitatory neurons</td>
<td align="center" rowspan="1" colspan="1"><italic>N</italic></td>
<td align="center" rowspan="1" colspan="1">1000</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">relative inhibitory population size</td>
<td align="center" rowspan="1" colspan="1"><italic>γ</italic></td>
<td align="center" rowspan="1" colspan="1">1</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">neuron time constant</td>
<td align="center" rowspan="1" colspan="1"><italic>τ</italic></td>
<td align="center" rowspan="1" colspan="1">10 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">threshold</td>
<td align="center" rowspan="1" colspan="1"><italic>θ</italic></td>
<td align="center" rowspan="1" colspan="1">−3</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">connection probability</td>
<td align="center" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="center" rowspan="1" colspan="1">0.2</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">transmission delay</td>
<td align="center" rowspan="1" colspan="1"><italic>d</italic></td>
<td align="center" rowspan="1" colspan="1">0.1 ms</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">excitatory synaptic weight</td>
<td align="center" rowspan="1" colspan="1"><italic>J</italic></td>
<td align="center" rowspan="1" colspan="1">
<inline-formula id="pcbi.1004490.e059">
<alternatives>
<graphic id="pcbi.1004490.e059g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e059"/>
<mml:math id="M59" display="inline" overflow="scroll">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>/</mml:mo>
<mml:msqrt>
<mml:mn>1000</mml:mn>
</mml:msqrt>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">relative inhibitory synaptic weight</td>
<td align="center" rowspan="1" colspan="1"><italic>g</italic></td>
<td align="center" rowspan="1" colspan="1">3</td>
</tr>
<tr>
<td align="center" rowspan="1" colspan="1">external drive</td>
<td align="center" rowspan="1" colspan="1"><italic>m</italic><sub>x</sub></td>
<td align="center" rowspan="1" colspan="1">0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>When the threshold <italic>θ</italic> is ≤ 0, the network is spontaneously active without external inputs. In the diffusion approximation and assuming stationarity, the mean zero-lag cross-covariances between pairs of neurons from each population can be estimated from <xref ref-type="disp-formula" rid="pcbi.1004490.e098">Eq (41)</xref> (see also [<xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>])
<disp-formula id="pcbi.1004490.e060"><alternatives><graphic id="pcbi.1004490.e060g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e060"/><mml:math id="M60" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>[</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mi>a</mml:mi></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula> <disp-formula id="pcbi.1004490.e061"><alternatives><graphic id="pcbi.1004490.e061g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e061"/><mml:math id="M61" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ei</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ie</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula>
where the subscripts e and i respectively denote excitatory and inhibitory populations. Moreover, <italic>W</italic><sub>e</sub> is the effective excitatory coupling,
<disp-formula id="pcbi.1004490.e062"><alternatives><graphic id="pcbi.1004490.e062g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e062"/><mml:math id="M62" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>J</mml:mi> <mml:mi>K</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula>
with <italic>S</italic> the susceptibility as defined in <xref ref-type="disp-formula" rid="pcbi.1004490.e100">Eq (43)</xref>. Furthermore, <italic>a</italic> is the variance of the single-neuron activity,
<disp-formula id="pcbi.1004490.e063"><alternatives><graphic id="pcbi.1004490.e063g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e063"/><mml:math id="M63" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>a</mml:mi> <mml:mo>=</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(24)</label></disp-formula>
which is identical for the excitatory and inhibitory populations. The mean input to each neuron is given by [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e009">Eq (3)</xref>],
<disp-formula id="pcbi.1004490.e064"><alternatives><graphic id="pcbi.1004490.e064g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e064"/><mml:math id="M64" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>μ</mml:mi> <mml:mo>=</mml:mo> <mml:mi>J</mml:mi> <mml:mi>K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula>
and, under the assumption of near-independence of the neurons, the variance of the inputs is well approximated by the sum of the variances from each sending neuron [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e010">Eq (4)</xref>],
<disp-formula id="pcbi.1004490.e065"><alternatives><graphic id="pcbi.1004490.e065g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e065"/><mml:math id="M65" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>g</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(26)</label></disp-formula>
Finally, the mean activity can be obtained from the self-consistency relation <xref ref-type="disp-formula" rid="pcbi.1004490.e095">Eq (39)</xref>.</p>
<p>
<xref ref-type="disp-formula" rid="pcbi.1004490.e061">Eq (22)</xref> shows that, when excitatory and inhibitory synaptic weights are scaled equally, the covariances scale with 1/<italic>N</italic> as long as the network feedback is strong (<italic>W</italic><sub>e</sub> ≫ 1), (for this argument, we assume that ⟨<italic>n</italic>⟩ is held constant, which may be achieved by adjusting a combination of <italic>θ</italic> and the external drive). Hence, conventional downscaling of population sizes tends to increase covariances.</p>
<p>We use <xref ref-type="disp-formula" rid="pcbi.1004490.e061">Eq (22)</xref> to perform a more sophisticated downscaling (cf. <xref ref-type="fig" rid="pcbi.1004490.g006">Fig 6</xref>). Let the new size of the excitatory population be <italic>N</italic>′. <xref ref-type="disp-formula" rid="pcbi.1004490.e061">Eq (22)</xref> shows that the covariances can only be preserved when a combination of <italic>W</italic><sub>e</sub>, <italic>γ</italic>, and <italic>g</italic> is adjusted. We take <italic>γ</italic> constant, and apply the transformation
<disp-formula id="pcbi.1004490.e066"><alternatives><graphic id="pcbi.1004490.e066g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e066"/><mml:math id="M66" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mo>→</mml:mo> <mml:mi>f</mml:mi> <mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mo>;</mml:mo> <mml:mspace width="0.277778em"/><mml:mi>g</mml:mi> <mml:mo>→</mml:mo> <mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(27)</label></disp-formula>
Solving <xref ref-type="disp-formula" rid="pcbi.1004490.e061">Eq (22)</xref> for <italic>f</italic> and <italic>g</italic>′ yields (cf. <xref ref-type="fig" rid="pcbi.1004490.g006">Fig 6B</xref>)
<disp-formula id="pcbi.1004490.e067"><alternatives><graphic id="pcbi.1004490.e067g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e067"/><mml:math id="M67" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mfrac><mml:mrow><mml:mi>a</mml:mi> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mi>γ</mml:mi> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mi mathvariant="normal">e</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:msup><mml:mi>N</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>γ</mml:mi> <mml:mn>4</mml:mn></mml:mfrac> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula> <disp-formula id="pcbi.1004490.e068"><alternatives><graphic id="pcbi.1004490.e068g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e068"/><mml:math id="M68" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:mi>a</mml:mi></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mfrac> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub></mml:mrow> <mml:mrow><mml:mi>γ</mml:mi> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ii</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:mi>a</mml:mi></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mfrac> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>ee</mml:mtext></mml:msub></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(29)</label></disp-formula>
The change in <italic>W</italic><sub>e</sub> can be captured by <italic>K</italic> → <italic>f</italic> <italic>K</italic> as long as the working point (<italic>μ</italic>, <italic>σ</italic>) is maintained. This intuitively corresponds to a redistribution of the synapses so that a fraction <italic>f</italic> comes from inside the network, and 1 − <italic>f</italic> from outside (cf. <xref ref-type="fig" rid="pcbi.1004490.g006">Fig 6A</xref>). However, the external drive does not have the same mean and variance as the internal inputs, since it needs to make up for the change in <italic>g</italic>. The external input can be modeled as a Gaussian noise with parameters
<disp-formula id="pcbi.1004490.e069"><alternatives><graphic id="pcbi.1004490.e069g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e069"/><mml:math id="M69" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>μ</mml:mi> <mml:mtext>ext</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi> <mml:mi>J</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>-</mml:mo> <mml:mi>f</mml:mi> <mml:mi>K</mml:mi> <mml:mi>J</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(30)</label></disp-formula> <disp-formula id="pcbi.1004490.e070"><alternatives><graphic id="pcbi.1004490.e070g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e070"/><mml:math id="M70" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi> <mml:msup><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>g</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:mi>f</mml:mi> <mml:mi>K</mml:mi> <mml:msup><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>g</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>a</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(31)</label></disp-formula>
independent for each neuron.</p>
<fig id="pcbi.1004490.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Binary network scaling that approximately preserves both mean activities and zero-lag covariances.</title>
<p><bold>A</bold> Increased covariances due to reduced network size can be countered by a change in the relative inhibitory synaptic weight combined with a redistribution of the synapses so that a fraction comes from outside the network. Adjusting a combination of the threshold and external drive restores the working point. <bold>B</bold> Scaling parameters versus relative network size for an example network. Since <italic>γ</italic> = 1 in this example, the scaling only works down to <italic>g</italic> = 1 (indicated by the horizontal and vertical dashed lines): Lower values of <italic>g</italic> only allow a silent or fully active network as steady states. <bold>C</bold>, <bold>E</bold> The mean activities are well preserved both by the conventional scaling in <xref ref-type="disp-formula" rid="pcbi.1004490.e001">Eq (1)</xref> with an appropriate adjustment of <italic>θ</italic> (panel <bold>C</bold>), and by the method proposed here (panel <bold>E</bold>). <bold>D</bold>, <bold>F</bold> Conventional scaling increases the magnitude of zero-lag covariances in simulated data (panel <bold>D</bold>), while the proposed method preserves them (panel <bold>F</bold>). Dark colors: full-scale network. Light colors: downscaled network. Crosses and dots indicate zero-lag correlations in the full-scale and downscaled networks, respectively.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g006"/>
</fig>
<p>An alternative is to perform the downscaling in two steps: First change the relative inhibitory weights according to <xref ref-type="disp-formula" rid="pcbi.1004490.e068">Eq (29)</xref> but keep the connection probability constant. The mean activity can be preserved by solving <xref ref-type="disp-formula" rid="pcbi.1004490.e095">Eq (39)</xref> for <italic>θ</italic>, but the covariances are changed. The second step, which restores the original covariances, then amounts to redistributing the synapses so that a fraction <inline-formula id="pcbi.1004490.e071"><alternatives><graphic id="pcbi.1004490.e071g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e071"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> comes from inside the network, and <inline-formula id="pcbi.1004490.e072"><alternatives><graphic id="pcbi.1004490.e072g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e072"/><mml:math id="M72" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> from outside, where the external (non-modeled) neurons have the same mean activity as those inside the network. This mean activity is negative, as the balanced regime implies stronger inhibition than excitation. Note that <inline-formula id="pcbi.1004490.e073"><alternatives><graphic id="pcbi.1004490.e073g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e073"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>≠</mml:mo> <mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, since <italic>W</italic><sub>e</sub> changes already in the first step.</p>
<p>The requirement that inhibition dominate excitation places a lower limit on the network size for which the scaling is effective. The reason is that <italic>g</italic> decreases with network size, so that a bifurcation occurs at <italic>g</italic> = 1/<italic>γ</italic>, beyond which the only steady states correspond to a silent network or a fully active one.</p>
</sec>
<sec id="sec009">
<title>Symmetric two-population spiking network</title>
<p>We have seen that the one-to-one relationship between effective connectivity and correlations does not hold in certain degenerate cases. Here we consider such a degenerate case and perform a scaling that preserves mean activities as well as both the size and the temporal structure of the correlations under reductions in both the number of neurons and the number of synapses. The network consists of one excitatory and one inhibitory population of LIF neurons with a population-independent connection probability and vanishing transmission delays. Due to the appearance of the eigenvalues in the numerator of the expression for the correlations in LIF networks [cf. Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e144">70</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e152">71</xref>)], such networks are subject to a reduced number of constraints when <bold>W</bold> has a zero eigenvalue, as this leaves a freedom to change the corresponding eigenvectors. Furthermore, identically vanishing delays greatly simplify the equations for the covariances.</p>
<p>The single-neuron and network parameters are as in <xref ref-type="table" rid="pcbi.1004490.t002">Table 2</xref> except that, here, <italic>N</italic> = 10,000, <italic>J</italic> = 0.2 mV, and the external drive is chosen such that the mean and standard deviation of the total input to each neuron are <italic>μ</italic> = 15 mV, <italic>σ</italic> = 10 mV. Furthermore, the delay is chosen equal to the simulation time step to approximate <italic>d</italic> = 0, which we assume here. The effective connectivity matrix for this network is
<disp-formula id="pcbi.1004490.e074"><alternatives><graphic id="pcbi.1004490.e074g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e074"/><mml:math id="M74" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>=</mml:mo> <mml:mi>w</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>K</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(32)</label></disp-formula>
where <italic>w</italic> = ∂<italic>r</italic><sub>target</sub>/∂<italic>r</italic><sub>source</sub> is the effective excitatory synaptic weight obtained as the derivative of <xref ref-type="disp-formula" rid="pcbi.1004490.e139">Eq (67)</xref>. Here, we take into account the dependence of <italic>w</italic> on <italic>J</italic> to quadratic order. The inhibitory weight is approximated as <italic>gw</italic> to allow an analytical expression for the relative inhibitory weight in the scaled network to be derived. The left and right eigenvectors are <inline-formula id="pcbi.1004490.e075"><alternatives><graphic id="pcbi.1004490.e075g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e075"/><mml:math id="M75" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">v</mml:mtext> <mml:mn>1</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.167em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mo>−</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mtd></mml:mtr></mml:mtable> <mml:mo stretchy="true">)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> <inline-formula id="pcbi.1004490.e076"><alternatives><graphic id="pcbi.1004490.e076g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e076"/><mml:math id="M76" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">u</mml:mtext> <mml:mn>1</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.167em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable> <mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> corresponding to eigenvalue <italic>L</italic> = <italic>w</italic> <italic>K</italic>(1 − <italic>γ</italic> <italic>g</italic>) and <inline-formula id="pcbi.1004490.e077"><alternatives><graphic id="pcbi.1004490.e077g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e077"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">v</mml:mtext> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.167em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable> <mml:mo stretchy="true">)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> <inline-formula id="pcbi.1004490.e078"><alternatives><graphic id="pcbi.1004490.e078g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e078"/><mml:math id="M78" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">u</mml:mtext> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.167em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable> <mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> corresponding to eigenvalue 0. The normalization is chosen such that the bi-orthogonality condition <xref ref-type="disp-formula" rid="pcbi.1004490.e104">Eq (47)</xref> is fulfilled.</p>
<p>A transformed connectivity matrix should have the same eigenvalues as <bold>W</bold>, and can thus be written as
<disp-formula id="pcbi.1004490.e079"><alternatives><graphic id="pcbi.1004490.e079g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e079"/><mml:math id="M79" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>c</mml:mi></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mi>b</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(33)</label></disp-formula> <disp-formula id="pcbi.1004490.e080"><alternatives><graphic id="pcbi.1004490.e080g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e080"/><mml:math id="M80" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>where</mml:mtext> <mml:mspace width="1.em"/><mml:mi>b</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>c</mml:mi></mml:mfrac> <mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>w</mml:mi> <mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(34)</label></disp-formula>
Denote the new population sizes by <italic>N</italic><sub>1</sub> and <italic>N</italic><sub>2</sub>. Equating the covariances before and after the transformation yields using <xref ref-type="disp-formula" rid="pcbi.1004490.e152">Eq (71)</xref> and <italic>A</italic><sup><italic>jk</italic></sup> = <bold>v</bold><sup><italic>jT</italic></sup> <bold>A</bold> <bold>v</bold><sup><italic>k</italic></sup> [cf. <xref ref-type="disp-formula" rid="pcbi.1004490.e106">Eq (49)</xref>],
<disp-formula id="pcbi.1004490.e081"><alternatives><graphic id="pcbi.1004490.e081g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e081"/><mml:math id="M81" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>g</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mi>N</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>g</mml:mi> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mi>N</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1.em"/><mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mfrac> <mml:mo>+</mml:mo> <mml:msup><mml:mi>b</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi> <mml:mi>c</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mi>c</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>c</mml:mi></mml:mtd> <mml:mtd><mml:msup><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>b</mml:mi> <mml:mi>c</mml:mi></mml:mfrac> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:mrow> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi> <mml:mi>c</mml:mi> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>b</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>b</mml:mi></mml:mfrac></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>c</mml:mi></mml:mtd> <mml:mtd><mml:mfrac><mml:mi>c</mml:mi> <mml:mi>b</mml:mi></mml:mfrac></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(35)</label></disp-formula>
In <xref ref-type="disp-formula" rid="pcbi.1004490.e081">Eq (35)</xref> we have assumed that the working points, and thus <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>2</sub>, are preserved, which may be achieved with an appropriate external drive as long as the corresponding variance remains positive. The four equations are simultaneously solved by
<disp-formula id="pcbi.1004490.e082"><alternatives><graphic id="pcbi.1004490.e082g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e082"/><mml:math id="M82" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>N</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mfrac><mml:mrow><mml:mi>N</mml:mi> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>w</mml:mi> <mml:mi>K</mml:mi> <mml:mi>g</mml:mi> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mi>K</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>[</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi> <mml:mi>K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>g</mml:mi> <mml:mi>w</mml:mi> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mi>w</mml:mi> <mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>L</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mrow><mml:mi>g</mml:mi> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mi>g</mml:mi> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mi>c</mml:mi></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(36)</label></disp-formula>
where <italic>w</italic>′ <italic>K</italic>′ may be chosen freely. Thus, the new connectivity matrix reads
<disp-formula id="pcbi.1004490.e083"><alternatives><graphic id="pcbi.1004490.e083g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e083"/><mml:math id="M83" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mi>w</mml:mi> <mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mi>w</mml:mi> <mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>g</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(37)</label></disp-formula>
which may also be cast into the form
<disp-formula id="pcbi.1004490.e084"><alternatives><graphic id="pcbi.1004490.e084g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e084"/><mml:math id="M84" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(38)</label></disp-formula>
where <italic>γ</italic>′ = <italic>N</italic><sub>2</sub>/<italic>N</italic><sub>1</sub> and <inline-formula id="pcbi.1004490.e085"><alternatives><graphic id="pcbi.1004490.e085g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e085"/><mml:math id="M85" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>g</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>−</mml:mo> <mml:mi>L</mml:mi></mml:mrow> <mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>K</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi>γ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>When the populations receive statistically identical external inputs, we have <italic>a</italic><sub>1</sub> = <italic>a</italic><sub>2</sub> = <italic>r</italic>, since the internal inputs are also equal. <xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7</xref> illustrates the network scaling for the choice <italic>w</italic>′ = <italic>w</italic>. Results are shown as a function of the relative size <italic>N</italic><sub>1</sub>/<italic>N</italic> of the excitatory population. External drive is provided at each network size to keep the mean and standard deviation of the total inputs to each neuron at the level indicated. The mean is supplied as a constant current input, while the variability is afforded by Poisson inputs according to Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e046">17</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e047">18</xref>) (<xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7D</xref>). It is seen that the transformations (<xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7B</xref>) are able to reduce both the total numbers of neurons and the total number of synapses (<xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7C</xref>) while approximately preserving covariance sizes and shapes (<xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7E,7F</xref>). Small fluctuations in the theoretical predictions in <xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7E</xref> are due to the discreteness of numbers of neurons and synapses, and deviations of the effective inhibitory weight from the linear approximation <italic>g</italic> <italic>w</italic>. The fact that the theoretical prediction in <xref ref-type="fig" rid="pcbi.1004490.g007">Fig 7F</xref> misses the small dips around <italic>t</italic> = 0 may be due to the approximation of the autocorrelations by delta functions, eliminating the relative refractoriness due to the reset. The numbers of neurons and synapses increase again below some <italic>N</italic><sub>1</sub>/<italic>N</italic>, and diverge as <italic>g</italic>′ becomes zero. This limits the scalability despite the additional freedom provided by the symmetry.</p>
<fig id="pcbi.1004490.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004490.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Spiking network scaling that approximately preserves mean firing rates and covariances.</title>
<p><bold>A</bold> Diagram illustrating the network and indicating the parameters that are adjusted. <bold>B</bold> Excitatory in-degrees <italic>K</italic>′, relative inhibitory synaptic weight <italic>g</italic>′, and relative number of inhibitory neurons <italic>γ</italic>′ versus scaling factor <italic>N</italic><sub>1</sub>/<italic>N</italic>. The dashed vertical line indicates the limit below which the scaling fails. <bold>C</bold> Total number of neurons <italic>N</italic><sub>total</sub> = (1+<italic>γ</italic>′)<italic>N</italic><sub>1</sub> and total number of synapses <italic>N</italic><sub>syn</sub> = (1+<italic>γ</italic>′)<sup>2</sup> <italic>K</italic>′ <italic>N</italic><sub>1</sub> versus scaling factor. <bold>D</bold> Rates of external excitatory and inhibitory Poisson inputs necessary for keeping firing rates constant. Average firing rates are between 23.1 and 23.5 spikes/s for both excitatory and inhibitory populations and all network sizes. <bold>E</bold> Integrated covariances, corresponding to zero-frequency components in the Fourier domain. Crosses: simulation results, dots: theoretical predictions. <bold>F</bold> Average covariance between excitatory-inhibitory neuron pairs for different network sizes. The dashed curve indicates the theoretical prediction for <italic>N</italic> = 10,000. Each network was simulated for 100 s.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.g007"/>
</fig>
</sec>
</sec>
<sec id="sec010" sec-type="conclusions">
<title>Discussion</title>
<p>By applying and extending the theory of correlations in asynchronous networks of binary and networks of leaky integrate-and-fire (LIF) neurons, our present work shows that the scalability of numbers of neurons and synapses is fundamentally limited if mean activities and pairwise averaged activity correlations are to be preserved. We analytically derive a limit on the reducibility of the number of incoming synapses per neuron, <italic>K</italic> (the in-degree), which depends on the variance of the external drive, and which indirectly restricts the scalability of the number of neurons. Within these restrictive bounds, we propose a scaling of the synaptic strengths <italic>J</italic> and the external drive with <italic>K</italic> that can preserve mean activities and the size and temporal structure of pairwise averaged correlations. Mean activities can be approximately preserved by maintaining the mean and variance of the total input currents to the neurons, also referred to as the <italic>working point</italic>. The temporal structure of pairwise averaged correlations depends on the <italic>effective connectivity</italic>, a measure of the effective influence of source populations on target populations determined both by the physical connectivity and the working point of the target neurons. When the dependence of the effective connectivity on the synaptic strengths <italic>J</italic> is linearized, it can be written as <italic>SJK</italic>, where <italic>S</italic> is the susceptibility of the target neurons (quantifying the change in output activity for a unit change in input). Scalings and analytical predictions of pairwise averaged correlations are tested using direct simulations of randomly connected networks of excitatory and inhibitory neurons.</p>
<p>Our most important findings are:
<list list-type="order"><list-item><p>The population-level effective connectivity matrix and pairwise averaged correlations are linked by a one-to-one mapping except in degenerate cases. Therefore, with few exceptions, any network scaling that preserves the correlations needs to preserve the effective connectivity.</p></list-item> <list-item><p>The most straightforward way of simultaneously preserving mean activities and pairwise averaged correlations is to change the synaptic strengths in inverse proportion to the in-degrees (<italic>J</italic> ∝ 1/<italic>K</italic>), and to adjust the variance of the external drive to make up for the change in variance of inputs from within the network. Other scalings, such as <inline-formula id="pcbi.1004490.e086"><alternatives><graphic id="pcbi.1004490.e086g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e086"/><mml:math id="M86" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, can in principle also preserve both mean activities and pairwise averaged correlations, but then change the working point (hence the neuronal susceptibility determining the strength of stimulus responses, and the degree to which the activity is mean- or fluctuation-driven), and are analytically intractable for LIF networks due to the complicated dependence of the firing rates and the impulse response on the mean and variance of the inputs.</p></list-item> <list-item><p>When downscaling the in-degrees <italic>K</italic> and scaling synaptic strengths as <italic>J</italic> ∝ 1/<italic>K</italic>, the variance of inputs from within the network increases, so that the variance of external inputs needs to be decreased to restore the working point. This is only possible up to the point where the variance of the external drive vanishes. The minimal in-degree scaling factor equals the ratio between the variance of inputs coming from within the network, and the total input variance due to both internal inputs and the external drive. The same limit to in-degree scaling holds more generally for scalings that simultaneously preserve mean activities and correlations. Thus, in the absence of a variable external drive, no downscaling is possible without changing mean activities, correlations, or both.</p></list-item> <list-item><p>Within the identified restrictive bounds, the scaling <italic>J</italic> ∝ 1/<italic>K</italic>, where the external variance is adjusted to maintain the working point, can preserve mean activities and pairwise averaged correlations also in asynchronous networks deviating from the assumptions of the analytical theory presented here. We show this robustness for an example network with distributed in- and out-degrees and distributed synaptic weights, and for a network with non-Poissonian spiking.</p></list-item> <list-item><p>For a sufficiently large change in in-degrees, a scaling that affects correlations can push the network from the linearly stable to an oscillatory regime or vice versa.</p></list-item> <list-item><p>Transformations derived using the diffusion approximation are able to closely preserve the relevant quantities (mean activities, correlation shapes and sizes) in simulated networks of binary and spiking neurons within the given bounds. Reducing the number of neurons only increases correlation magnitudes without affecting their structure in this approximation.However, strong deviations from the assumptions of the diffusion approximation can cause also correlation structure to change in simulated networks under scalings originally constructed to maintain correlation structure. This occurs for instance when a drastic reduction in network size is coupled with a less than proportional reduction in in-degrees, leading to large numbers of common inputs and increased synchrony. Thus, the scalability of the number of neurons with available analytical results is indirectly limited by the minimal in-degree scaling factor.</p></list-item></list></p>
<p>In conclusion, we have identified limits to the reducibility of neural networks, even when only considering first- and second-order statistical properties. Networks are inevitably irreducible in some sense, in that downscaled networks are clearly not identical to their full-scale counterparts. However, mean activity, a first-order macroscopic quantity, can usually be preserved. The present work makes it clear that non-reducibility already sets in at the second-order macroscopic level of correlations. This does not imply a general minimal size for network models to be valid, merely that each network in question needs to be studied near its natural size to verify results from any scaled versions.</p>
<p>Our analytical theory is based on the diffusion approximation, in which inputs are treated as Gaussian noise, valid in the asynchronous irregular regime when activities are sufficiently high and synaptic weights are small. Moreover, external inputs are taken to be independent across populations, and delays and time constants are assumed to be unchanged under scaling. A further assumption of the theory is that the dynamics is stationary and linearly stable.</p>
<p>The one-to-one correspondence between effective connectivity and correlations applies with a few exceptions. For non-identical populations with different impulse responses, an analysis in the frequency domain demonstrates the equivalence under the assumption that the correlation matrix is invertible. An argument that assumes a diagonalizable effective connectivity matrix extends the equivalence to identical populations apart from cases where the effective connectivity matrix has eigenvalues that are zero or degenerate.</p>
<p>The equivalence of correlations and effective connectivity ties in with efforts to infer structure from activity, not only in neuroscience [<xref ref-type="bibr" rid="pcbi.1004490.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref060">60</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref062">62</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref064">64</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref065">65</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref066">66</xref>] but also in other disciplines [<xref ref-type="bibr" rid="pcbi.1004490.ref067">67</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref068">68</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref069">69</xref>], as it implies that one should in principle be able to find the only—and therefore the real—effective connectivity that accounts for the correlations. Within the same framework as that used here, [<xref ref-type="bibr" rid="pcbi.1004490.ref065">65</xref>] shows that knowledge of the cross-spectrum at two distinct frequencies allows a unique reconstruction of the effective connectivity matrix by splitting the covariance matrix into symmetric and antisymmetric parts. The derivation considers a class of transfer functions (the Fourier transform of the neuronal impulse response) rather than any specific form, but the transfer function is taken to be unique, whereas the present work allows for differences between populations. Furthermore, we here present a more straightforward derivation of the equivalence, not focused on the practical aim of network reconstruction, and clarify the conditions under which reconstruction is possible.</p>
<p>In practice, using our results to infer structure from correlations may not be straightforward, due to both deviations from the assumptions of the theory and problems with measuring the relevant quantities. For instance, neural activity is often nonstationary [<xref ref-type="bibr" rid="pcbi.1004490.ref070">70</xref>], transfer functions are normally not measured directly, and correlations are imperfectly known due to measurement noise. Furthermore, inference of anatomical from functional connectivity (correlations) is often done based on functional magnetic resonance imaging (fMRI) measurements, which are sensitive only to very low frequencies and therefore only allow the symmetric part of the effective connectivity to be reliably determined [<xref ref-type="bibr" rid="pcbi.1004490.ref066">66</xref>]. The presence of unobserved populations providing correlated input to two or more observed populations can also hinder inference of network structure. Thus, high-resolution measurements (e.g., two-photon microscopy combined with optogenetics to record activity in a cell-type-specific manner [<xref ref-type="bibr" rid="pcbi.1004490.ref071">71</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref072">72</xref>]) of networks with controlled input (e.g., in brain slices) hold the most promise for network reconstruction from correlations.</p>
<p>The effects on correlation-based synaptic plasticity of scaling-related changes in correlations may be partly compensated for by adjusting the learning parameters. For instance, an increase in average correlation size with factor 1/<italic>N</italic> without a change in temporal shape may be to some extent countered by reducing the learning rate by the same factor. Changes in the temporal structure of the correlations are more difficult to compensate for. When learning is linear or slow, so that the learning function can be approximated as constant (independent of the weights), the mean drift in the synaptic weights is determined by the integral of the product of the correlations and the learning function [<xref ref-type="bibr" rid="pcbi.1004490.ref073">73</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref074">74</xref>]. Therefore, this mean drift may be kept constant under a change in correlation shapes by adjusting the learning function such that this product is preserved for all time lags. However, given that the expression for the correlations is a complicated function of the network parameters, the required adjustment of the learning function will also be complex. Moreover, the effects of this adjustment on precise patterns of weights are difficult to predict, since the distribution of correlations between neuron pairs may change under the proposed scalings, and this solution does not apply when learning is fast and weight-dependent.</p>
<p>The groundbreaking work of [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>] identified a dynamic balance between excitation and inhibition as a mechanism for the asynchronous irregular activity in cortex, and showed that <inline-formula id="pcbi.1004490.e087"><alternatives><graphic id="pcbi.1004490.e087g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e087"/><mml:math id="M87" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> can robustly lead to a balanced state in the limit <italic>N</italic> → ∞ for constant <italic>K</italic>/<italic>N</italic>. However, it is not necessary to scale synaptic weights as <inline-formula id="pcbi.1004490.e088"><alternatives><graphic id="pcbi.1004490.e088g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e088"/><mml:math id="M88" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> in order to obtain a balanced network state, even in the limit of infinite network size (and infinite <italic>K</italic>). For instance, <italic>J</italic> ∝ 1/<italic>K</italic> can retain balance in the infinite size limit in the sense that the sum of the excitatory and inhibitory inputs is small compared to each of these inputs separately. To retain irregular activity with this scaling one merely needs to ensure a variable external drive, as the internal variance vanishes for <italic>N</italic> → ∞. Moreover, in binary networks with neurons that have a Heaviside gain function (a hard threshold) identical across neurons, one does not even need a variable drive in order to stay in a balanced state [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>, p. 1360]. This can be seen from a simple example of a network of <italic>N</italic> excitatory and <italic>γN</italic> inhibitory neurons with random connectivity with probability <italic>p</italic>, where <italic>J</italic> = <italic>J</italic><sub>0</sub>/<italic>N</italic> &gt; 0 is the synaptic amplitude of an excitatory synapse, and −<italic>gJ</italic> the amplitude of an inhibitory synapse. The network may receive a DC drive, which we absorb into the threshold <italic>θ</italic>. The summed input to each cell is then <italic>μ</italic> = <italic>pNJ</italic>(1 − <italic>γg</italic>) <italic>n</italic>, where <italic>n</italic> ∈ [0, 1] is the mean activity in the network. For a balanced state to arise, the negative feedback must be sufficiently strong, so that the mean activity <italic>n</italic> settles on a level where the summed input is close to the threshold <italic>μ</italic> ≃ <italic>θ</italic>. This will always be achieved if <italic>pJ</italic><sub>0</sub>(1 − <italic>γg</italic>) &lt; <italic>θ</italic> &lt; 0: in a completely activated network (<italic>n</italic> = 1) the summed input is below threshold, and in a silent network (<italic>n</italic> = 0) the summed input is above threshold, hence the activity will settle close to the value <italic>n</italic> ≃ <italic>θ</italic>/[<italic>pJ</italic><sub>0</sub>(1 − <italic>γg</italic>)]. As the variance of the synaptic input decreases with network size, the latter estimate of the mean activity will become exact in the limit <italic>N</italic> → ∞. The underlying reason for both 1/<italic>K</italic> and <inline-formula id="pcbi.1004490.e089"><alternatives><graphic id="pcbi.1004490.e089g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e089"/><mml:math id="M89" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> scaling to lead to a qualitatively identical balanced state is the absence of a characteristic scale on which to measure the synaptic input: the threshold is hard. Only by introducing a characteristic scale, for example distributed values for the thresholds, the 1/<italic>K</italic> scaling with a DC drive will in the large <italic>N</italic> limit lead to a freezing of the balanced state due to the vanishing variance of the summed input, while with either <inline-formula id="pcbi.1004490.e090"><alternatives><graphic id="pcbi.1004490.e090g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e090"/><mml:math id="M90" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> scaling, or 1/<italic>K</italic> scaling with a fluctuating external drive, the balanced state is conserved.</p>
<p>In [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>], <inline-formula id="pcbi.1004490.e091"><alternatives><graphic id="pcbi.1004490.e091g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e091"/><mml:math id="M91" display="inline" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi> <mml:mo>∝</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> refers not only to a comparison between differently-sized networks, but also to the assumption that approximately <inline-formula id="pcbi.1004490.e092"><alternatives><graphic id="pcbi.1004490.e092g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e092"/><mml:math id="M92" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> excitatory synapses need to be active to reach spike threshold. However, this is also not a necessary condition for balance, which can arise for a wide range of synaptic strengths relative to threshold, as long as inhibition is sufficiently strong compared to excitation. As discussed in “<bold>Correlation-preserving scaling</bold>”, with appropriately chosen external drive, <italic>J</italic> even drops out of the mean-field theory for binary networks with a Heaviside gain function altogether [<xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>]. The difficulty in the interpretation of the [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>] results illustrates a more general point: The primary goal of scaling studies is to identify the mechanisms governing network dynamics. Nevertheless, these studies usually also specify requirements on the robustness of the mechanism, leading to scaling laws for network parameters that may be more restrictive than a description of the mechanism per se. An example is the robustness to strong synapses, defined such that activation of <inline-formula id="pcbi.1004490.e093"><alternatives><graphic id="pcbi.1004490.e093g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e093"/><mml:math id="M93" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> excitatory synapses suffices to reach threshold in the absence of an external drive [<xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>, p. 1324]. This scenario was considered in order to create a condition under which dynamic balance is clearly <italic>necessary</italic> for achieving asynchronous irregular activity in balanced random networks, since combined inputs would otherwise far exceed the threshold. However, dynamic balance can arise also with weak synapses, e.g., with strength ∼ 1/<italic>K</italic> of the distance to threshold. Without questioning the value of scaling studies, which can distill essential mechanisms and are sometimes possible where finite-size analytical descriptions are intractable, this shows that scaling laws need to be interpreted with care.</p>
<p>The issue of the interrelation between network size, synaptic strengths, numbers of synapses per neuron, and activity is embedded in the wider context of anatomical and physiological scaling laws observed experimentally. In homeostatic synaptic plasticity, synaptic strengths are adjusted in a manner that keeps the activity of the postsynaptic neurons within a certain operating range [<xref ref-type="bibr" rid="pcbi.1004490.ref075">75</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref076">76</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref077">77</xref>]. Since postsynaptic activity depends not only on the strength of inputs but also on their number, this may induce a correlation between synaptic strengths and in-degree. In line with this hypothesis, excitatory postsynaptic currents (EPSCs) at single synapses were found to be inversely related to the density of active synapses onto cultured hippocampal neurons [<xref ref-type="bibr" rid="pcbi.1004490.ref078">78</xref>], and the size of both miniature EPSCs and evoked EPSCs between neurons decreased with network size and with the number of synapses per neuron in patterned cultures [<xref ref-type="bibr" rid="pcbi.1004490.ref079">79</xref>], although contrasting results have also been reported [<xref ref-type="bibr" rid="pcbi.1004490.ref080">80</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref081">81</xref>]. In the development of a mammal, the neuronal network grows by orders of magnitude and is continuously modified. For instance, the amplitude of miniature EPSCs is reduced in a period of heightened synaptogenesis in rat primary visual cortex [<xref ref-type="bibr" rid="pcbi.1004490.ref082">82</xref>]. During such developmental processes, some functions are conserved and new functions emerge. This balance between stability and flexibility is an intriguing theoretical problem. Here, network scaling is deeply related to biological principles. Our results open up a new perspective for analyzing and interpreting such biological scaling laws.</p>
<p>Certainly, most network models will not fit neatly into the categories considered here, and detailed models often provide valuable insights regardless of whether they are scaled in a systematic manner. Nevertheless, it is usually possible to at least mention whether and how a particular model is scaled. When the results are not amenable to mathematical analysis, we suggest investigating through simulations of networks of different sizes how essential characteristics depend on numbers of neurons and synapses (the relevant characteristics depend on the model at hand, and do not necessarily include mean activities or correlations). Thus, while both the investigation of the infinity limit and the exploration of downscaled networks remain powerful methods of computational neuroscience, we argue for a more careful approach to network scaling than has hitherto been customary, making the type of scaling and its consequences explicit. Fortunately, in neuroscience full-scale simulations are now becoming routinely possible due to the technological advances of recent years.</p>
</sec>
<sec id="sec011" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec012">
<title>Software</title>
<p>We verify analytical results for networks of binary neurons and networks of spiking neurons using direct simulations performed with NEST [<xref ref-type="bibr" rid="pcbi.1004490.ref083">83</xref>] revisions 10711 and 11264 for the spiking networks and revision 11540 for the binary networks. For simulating the multi-layer microcircuit model, PyNN version 0.7.6 (revision 1312) [<xref ref-type="bibr" rid="pcbi.1004490.ref084">84</xref>] was used with NEST 2.6.0 as back end, single-threaded on 12 MPI processes on a high-performance cluster. All simulations have a time step of 0.1 ms. Spike times in the microcircuit model are constrained to the grid. The other spiking network simulations use precise spike timing [<xref ref-type="bibr" rid="pcbi.1004490.ref085">85</xref>]. In part, Sage was used for symbolic linear algebra [<xref ref-type="bibr" rid="pcbi.1004490.ref086">86</xref>]. Pre- and post-processing and numerical analysis were performed with Python.</p>
</sec>
<sec id="sec013">
<title>Network structure and notation</title>
<p>For both the binary and the spiking networks, we derive analytical results where both the number of populations <italic>N</italic><sub>pop</sub> and the population-level connectivity are arbitrary. Specific examples are given of networks with a single, inhibitory population, or with two populations (one excitatory, one inhibitory) with either population-specific or population-independent connectivities. In addition, we discuss a multi-layer spiking cortical microcircuit model consisting of 77,169 neurons with approximately 3 × 10<sup>8</sup> synapses, with eight populations (2/3E, 2/3I, 4E, 4I, 5E, 5I, 6E, 6I) and population-specific connection probabilities [<xref ref-type="bibr" rid="pcbi.1004490.ref058">58</xref>], slightly adjusted to enhance the asynchrony of the activity. The adjustments consist of replacing normally by lognormally distributed weights with the same mean and with coefficient of variation 3; and using 4.5 instead of 4 as the relative strength of synapses from 4I to 4E compared to excitatory synaptic strengths. Besides distributed synaptic strengths, the model has binomially distributed in- and out-degrees, and normally distributed delays (clipped at the simulation time step), thereby deviating from the assumptions of our analytic theory. It thus serves to evaluate the robustness of our analytical results to such deviations from the underlying assumptions.</p>
<p>In all cases, pairs of populations are randomly connected. In the binary and one- and two-population LIF network simulations, in-degrees are fixed and multiple directed connections between pairs of neurons (multapses) are disallowed. In the multi-layer microcircuit model, in-degrees are distributed and multapses are allowed. In case of population-specific connectivities, we denote the (unique or mean) in-degree for connections from population <italic>β</italic> to population <italic>α</italic> by <italic>K</italic><sub><italic>αβ</italic></sub>, and synaptic strengths by <italic>J</italic><sub><italic>αβ</italic></sub>. Population sizes are denoted by <italic>N</italic><sub><italic>α</italic></sub>. For the example networks with population-independent connection probability, we denote the size of the excitatory population by <italic>N</italic>, the in-degree from excitatory neurons by <italic>K</italic> = <italic>pN</italic>, and the size of the inhibitory relative to the excitatory population by <italic>γ</italic>, so that the inhibitory in-degree is <italic>γK</italic>. Synaptic strengths are also taken to only depend on the source population, and are written as <italic>J</italic> for excitatory and −<italic>gJ</italic> for inhibitory synapses.</p>
</sec>
<sec id="sec014">
<title>Binary network dynamics</title>
<p>We denote the activity of neuron <italic>j</italic> by <italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic>). The state <italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic>) of a binary neuron is either 0 or 1, where 1 indicates activity, 0 inactivity [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref087">87</xref>]. The state of the network of <italic>N</italic> such neurons is described by a binary vector <bold>n</bold> = (<italic>n</italic><sub>1</sub>, …, <italic>n</italic><sub><italic>N</italic></sub>) ∈ {0,1}<sup><italic>N</italic></sup>. We denote the mean activity by ⟨<italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub>, where the average ⟨⟩<sub><italic>t</italic></sub> is over time and realizations of the stochastic activity. The neuron model shows stochastic transitions (at random points in time) between the two states 0 and 1. In each infinitesimal interval [<italic>t</italic>, <italic>t</italic> + <italic>δt</italic>), each neuron in the network has the probability <inline-formula id="pcbi.1004490.e094"><alternatives><graphic id="pcbi.1004490.e094g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e094"/><mml:math id="M94" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> to be chosen for update [<xref ref-type="bibr" rid="pcbi.1004490.ref088">88</xref>], where <italic>τ</italic> is the time constant of the neuronal dynamics. We use an equivalent implementation in which the time points of update are drawn independently for all neurons. For a particular neuron, the sequence of update points has exponentially distributed intervals with mean duration <italic>τ</italic>, i.e., update times form a Poisson process with rate <italic>τ</italic><sup>−1</sup>. The stochastic update constitutes a source of noise in the system. Given that the <italic>j</italic>-th neuron is selected for update, the probability to end in the up state (<italic>n</italic><sub><italic>j</italic></sub> = 1) is determined by the gain function <italic>F</italic><sub><italic>j</italic></sub>(<bold>n</bold>(<italic>t</italic>)) = Θ(∑<sub><italic>k</italic></sub> <italic>J</italic><sub><italic>jk</italic></sub> <italic>n</italic><sub><italic>k</italic></sub>(<italic>t</italic>) − <italic>θ</italic>) which in general depends on the activity <bold>n</bold> of all other neurons. Here <italic>θ</italic> denotes the threshold of the neuron and Θ(<italic>x</italic>) the Heaviside function. The probability of ending in the down state (<italic>n</italic><sub><italic>j</italic></sub> = 0) is 1 − <italic>F</italic><sub><italic>j</italic></sub>(<bold>n</bold>). This model has been considered previously [<xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref087">87</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref089">89</xref>], and here we follow the notation introduced in [<xref ref-type="bibr" rid="pcbi.1004490.ref087">87</xref>] that we also employed in our earlier works. We skip details of the derivation here that are already contained in [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>].</p>
</sec>
<sec id="sec015">
<title>First and second moments of activity in the binary network</title>
<p>The combined distribution of large numbers of independent inputs can be approximated as a Gaussian 𝓝(<italic>μ</italic>, <italic>σ</italic><sup>2</sup>) by the central limit theorem. The arguments <italic>μ</italic> and <italic>σ</italic> are the mean and standard deviation of the synaptic input noise, together referred to as the working point [cf. Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e009">3</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e010">4</xref>)]. The stationary mean activity of a given population of neurons then obeys [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>]
<disp-formula id="pcbi.1004490.e095"><alternatives><graphic id="pcbi.1004490.e095g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e095"/><mml:math id="M95" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>n</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>F</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>⟩</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>≃</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:mo>Θ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>-</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mi>θ</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mtext>erfc</mml:mtext> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>θ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>(</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi mathvariant="bold">n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>σ</mml:mi> <mml:mo>(</mml:mo> <mml:mo>⟨</mml:mo> <mml:mi mathvariant="bold">n</mml:mi> <mml:mo>⟩</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(39)</label></disp-formula>
This equation needs to be solved self-consistently because ⟨<italic>n</italic>⟩ influences <italic>μ</italic>, <italic>σ</italic> through interactions within the population itself and with other populations.</p>
<p>When network activity is stationary, the covariance of the activities of a pair (<italic>j</italic>, <italic>k</italic>) of neurons is defined as <italic>c</italic><sub><italic>jk</italic></sub>(Δ) = ⟨<italic>δn</italic><sub><italic>j</italic></sub>(<italic>t</italic> + Δ)<italic>δn</italic><sub><italic>k</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub>, where <italic>δn</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = <italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic>) − ⟨<italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub> is the deviation of neuron <italic>j</italic>’s activity from expectation, and Δ is a time lag. Instead of the raw correlation ⟨<italic>n</italic><sub><italic>j</italic></sub>(<italic>t</italic> + Δ)<italic>n</italic><sub><italic>k</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub>, here and for the spiking networks we measure the covariance, i.e., the second centralized moment, which is also identical to the second cumulant. To derive analytical expressions for the covariances in binary networks in the asynchronous regime, we follow the theory developed in [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>]. We first consider the case of vanishing transmission delays <italic>d</italic> = 0 and then discuss networks with delays.</p>
<p>Let
<disp-formula id="pcbi.1004490.e096"><alternatives><graphic id="pcbi.1004490.e096g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e096"/><mml:math id="M96" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mspace width="0.277778em"/><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>β</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(40)</label></disp-formula>
be the covariance averaged over disjoint pairs of neurons in two (possibly identical) populations <italic>α</italic>, <italic>β</italic>, and <inline-formula id="pcbi.1004490.e097"><alternatives><graphic id="pcbi.1004490.e097g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e097"/><mml:math id="M97" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> the population-averaged single-neuron variance <italic>a</italic><sub><italic>j</italic></sub>(Δ) = ⟨<italic>δn</italic><sub><italic>j</italic></sub>(<italic>t</italic> + Δ)<italic>δn</italic><sub><italic>j</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub>. Note that for <italic>α</italic> = <italic>β</italic> there are only <italic>N</italic><sub><italic>α</italic></sub>(<italic>N</italic><sub><italic>α</italic></sub> − 1) disjoint pairs of neurons, so <italic>c</italic><sub><italic>αα</italic></sub> differs from the average pairwise cross-correlation by a factor (<italic>N</italic><sub><italic>α</italic></sub> − 1)/<italic>N</italic><sub><italic>α</italic></sub>, but we choose this definition because it slightly simplifies the population-level equations. For sufficiently weak synapses and sufficiently high firing rates, and when higher-order correlations can be neglected, a linearized equation relating these quantities can be derived for the case <italic>d</italic> = 0 ([<xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>] Eqs (9.14)–(9.16); [<xref ref-type="bibr" rid="pcbi.1004490.ref007">7</xref>] supplementary material Eq (36), [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>] Eq (10)),
<disp-formula id="pcbi.1004490.e098"><alternatives><graphic id="pcbi.1004490.e098g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e098"/><mml:math id="M98" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mn>2</mml:mn> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>γ</mml:mi></mml:munder> <mml:mo>(</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>γ</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>γ</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>γ</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mi>β</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(41)</label></disp-formula>
Here, we have assumed identical time constants across populations, and
<disp-formula id="pcbi.1004490.e099"><alternatives><graphic id="pcbi.1004490.e099g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e099"/><mml:math id="M99" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>J</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>K</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(42)</label></disp-formula>
is the linearized effective connectivity. The susceptibility <italic>S</italic> is defined as the slope of the gain function averaged over the noisy input to each neuron [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>], reducing for a Heaviside gain function to
<disp-formula id="pcbi.1004490.e100"><alternatives><graphic id="pcbi.1004490.e100g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e100"/><mml:math id="M100" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt> <mml:mi>σ</mml:mi></mml:mrow></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(43)</label></disp-formula></p>
<p>With the definitions
<disp-formula id="pcbi.1004490.e101"><alternatives><graphic id="pcbi.1004490.e101g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e101"/><mml:math id="M101" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>≡</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mspace width="0.277778em"/><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>β</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(44)</label></disp-formula> <disp-formula id="pcbi.1004490.e102"><alternatives><graphic id="pcbi.1004490.e102g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e102"/><mml:math id="M102" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>≡</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(45)</label></disp-formula> <xref ref-type="disp-formula" rid="pcbi.1004490.e098">Eq (41)</xref> is recognized as a continuous Lyapunov equation
<disp-formula id="pcbi.1004490.e103"><alternatives><graphic id="pcbi.1004490.e103g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e103"/><mml:math id="M103" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">P</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">P</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:mtext>diag</mml:mtext> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>a</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>≡</mml:mo> <mml:mn>2</mml:mn> <mml:mi mathvariant="bold">A</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(46)</label></disp-formula>
which can be solved using known methods. Let <bold>v</bold><sup><italic>j</italic></sup>,<bold>u</bold><sup><italic>k</italic></sup> be the left and right eigenvectors of <bold>W</bold>, with eigenvalues <italic>λ</italic><sub><italic>j</italic></sub> and <italic>λ</italic><sub><italic>k</italic></sub>, respectively. Choose the normalization such that the left and right eigenvectors are biorthogonal,
<disp-formula id="pcbi.1004490.e104"><alternatives><graphic id="pcbi.1004490.e104g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e104"/><mml:math id="M104" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(47)</label></disp-formula>
Then multiplying <xref ref-type="disp-formula" rid="pcbi.1004490.e103">Eq (46)</xref> from the left with <bold>v</bold><sup><italic>jT</italic></sup> and from the right with <bold>v</bold><sup><italic>k</italic></sup> yields
<disp-formula id="pcbi.1004490.e105"><alternatives><graphic id="pcbi.1004490.e105g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e105"/><mml:math id="M105" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(48)</label></disp-formula>
Define
<disp-formula id="pcbi.1004490.e106"><alternatives><graphic id="pcbi.1004490.e106g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e106"/><mml:math id="M106" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>m</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mo>≡</mml:mo> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">m</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(49)</label></disp-formula>
for <inline-formula id="pcbi.1004490.e107"><alternatives><graphic id="pcbi.1004490.e107g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e107"/><mml:math id="M107" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">m</mml:mtext> <mml:mo>=</mml:mo> <mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mtext mathvariant="bold">A</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula>. Then solving <xref ref-type="disp-formula" rid="pcbi.1004490.e105">Eq (48)</xref> for <inline-formula id="pcbi.1004490.e108"><alternatives><graphic id="pcbi.1004490.e108g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e108"/><mml:math id="M108" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> gives
<disp-formula id="pcbi.1004490.e109"><alternatives><graphic id="pcbi.1004490.e109g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e109"/><mml:math id="M109" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(50)</label></disp-formula>
as can be verified using <xref ref-type="disp-formula" rid="pcbi.1004490.e104">Eq (47)</xref>. This provides an approximation of the population-averaged zero-lag correlations, including contributions from both auto- and cross-correlations.</p>
<p>To determine the temporal structure of the population-averaged cross-correlations, we start from the single-neuron level, for which the correlations approximately obey ([<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>] Eq (29))
<disp-formula id="pcbi.1004490.e110"><alternatives><graphic id="pcbi.1004490.e110g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e110"/><mml:math id="M110" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mfrac><mml:mi>d</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:mfrac> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mspace width="2.em"/><mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(51)</label></disp-formula>
where <italic>w</italic><sub><italic>ij</italic></sub> is the neuron-level effective connectivity (<italic>w</italic><sub><italic>ij</italic></sub> = <italic>S</italic><sub><italic>i</italic></sub> <italic>J</italic><sub><italic>ij</italic></sub> if a connection exists and <italic>w</italic><sub><italic>ij</italic></sub> = 0 otherwise). This equation also holds on the diagonal, <italic>j</italic> = <italic>k</italic>. To obtain the population-level equation, we use Eqs (<xref ref-type="disp-formula" rid="pcbi.1004490.e096">40</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004490.e101">44</xref>) and count the numbers of connections, which yields a factor <italic>K</italic><sub><italic>αβ</italic></sub> for each projection. <xref ref-type="disp-formula" rid="pcbi.1004490.e110">Eq (51)</xref> then becomes
<disp-formula id="pcbi.1004490.e111"><alternatives><graphic id="pcbi.1004490.e111g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e111"/><mml:math id="M111" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mfrac><mml:mi>d</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:mfrac> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">P</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mspace width="2.em"/><mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(52)</label></disp-formula>
This step from the single-neuron to the population level constitutes an approximation when the out-degrees are distributed, but is exact for fixed out-degree [<xref ref-type="bibr" rid="pcbi.1004490.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>]. The correlations for Δ &lt; 0 are determined by <inline-formula id="pcbi.1004490.e112"><alternatives><graphic id="pcbi.1004490.e112g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e112"/><mml:math id="M112" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>‾</mml:mo></mml:mover> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>‾</mml:mo></mml:mover> <mml:mrow><mml:mi>β</mml:mi> <mml:mi>α</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. With the definition Eq (<xref ref-type="disp-formula" rid="pcbi.1004490.e106">49</xref>), Eq (<xref ref-type="disp-formula" rid="pcbi.1004490.e111">52</xref>) yields
<disp-formula id="pcbi.1004490.e113"><alternatives><graphic id="pcbi.1004490.e113g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e113"/><mml:math id="M113" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mfrac><mml:mi>d</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:mfrac> <mml:msup><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="2.em"/><mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(53)</label></disp-formula>
Using the initial condition for <inline-formula id="pcbi.1004490.e114"><alternatives><graphic id="pcbi.1004490.e114g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e114"/><mml:math id="M114" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> from <xref ref-type="disp-formula" rid="pcbi.1004490.e109">Eq (50)</xref> and multiplying <xref ref-type="disp-formula" rid="pcbi.1004490.e113">Eq (53)</xref> by <bold>u</bold><sup><italic>j</italic></sup> <bold>u</bold><sup><italic>kT</italic></sup>, summing over <italic>j</italic> and <italic>k</italic>, we obtain the solution
<disp-formula id="pcbi.1004490.e115"><alternatives><graphic id="pcbi.1004490.e115g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e115"/><mml:math id="M115" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(54)</label></disp-formula>
The shape of the autocovariances is well approximated by that for isolated neurons, <inline-formula id="pcbi.1004490.e116"><alternatives><graphic id="pcbi.1004490.e116g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e116"/><mml:math id="M116" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">A</mml:mtext> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mfrac><mml:mo>Δ</mml:mo> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, with corrections due to interactions being <italic>O</italic>(1/<italic>N</italic>) [<xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>]. Substituting this form in <xref ref-type="disp-formula" rid="pcbi.1004490.e115">Eq (54)</xref> leads to
<disp-formula id="pcbi.1004490.e117"><alternatives><graphic id="pcbi.1004490.e117g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e117"/><mml:math id="M117" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mo>Δ</mml:mo> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(55)</label></disp-formula>
equivalent to [<xref ref-type="bibr" rid="pcbi.1004490.ref042">42</xref>] Eq (6.20). Note that this equation still needs to be solved self-consistently, because the variance of the inputs to the neurons, which goes into <italic>S</italic>(<italic>μ</italic>, <italic>σ</italic>), depends on the correlations. However, correlations tend to contribute only a small fraction of the input variance in the asynchronous regime (cf. [<xref ref-type="bibr" rid="pcbi.1004490.ref009">9</xref>] Fig 3D). The accuracy of the result <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref> is illustrated in <xref ref-type="fig" rid="pcbi.1004490.g003">Fig 3A</xref> for a network with parameters given in <xref ref-type="table" rid="pcbi.1004490.t001">Table 1</xref> by comparison with a direct simulation. Note that the delays were not zero but equal to the simulation time step of 0.1 ms, sufficiently small for the correlations to be well approximated by <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref>.</p>
<p>Now consider arbitrary transmission delay <italic>d</italic> &gt; 0, and let both <italic>d</italic> and the input statistics be population-independent. This case is most easily approached from the Fourier domain, where the population-averaged covariances including autocovariances can be approximated as [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>]
<disp-formula id="pcbi.1004490.e118"><alternatives><graphic id="pcbi.1004490.e118g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e118"/><mml:math id="M118" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">W</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(56)</label></disp-formula>
Here, <italic>H</italic>(<italic>ω</italic>) is the transfer function
<disp-formula id="pcbi.1004490.e119"><alternatives><graphic id="pcbi.1004490.e119g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e119"/><mml:math id="M119" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mi>d</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(57)</label></disp-formula>
which is equal for all populations under the assumptions made. The transfer function is the Fourier transform of the impulse response, which is a jump followed by an exponential relaxation,
<disp-formula id="pcbi.1004490.e120"><alternatives><graphic id="pcbi.1004490.e120g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e120"/><mml:math id="M120" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>h</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Θ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(58)</label></disp-formula>
where Θ is the Heaviside step function.</p>
<p>For the case of population-independent <italic>H</italic>(<italic>ω</italic>), Fourier back transformation to the time domain is feasible, and was performed in [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>] for symmetric connectivity matrices. Here, we consider generic connectivity (insofar as consistent with equal <italic>H</italic>(<italic>ω</italic>)), and again use projection onto the eigenspaces of <bold>W</bold> to obtain a form similar to <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref>, i.e., insert the identity matrix
<disp-formula id="pcbi.1004490.e121"><alternatives><graphic id="pcbi.1004490.e121g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e121"/><mml:math id="M121" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(59)</label></disp-formula>
both on the left and on the right of <xref ref-type="disp-formula" rid="pcbi.1004490.e118">Eq (56)</xref>, and Fourier transform to obtain 
<disp-formula id="pcbi.1004490.e122"><alternatives><graphic id="pcbi.1004490.e122g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e122"/><mml:math id="M122" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:msub><mml:mi>f</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>with</mml:mtext> <mml:mspace width="0.277778em"/><mml:msub><mml:mi>f</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≡</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mspace width="0.166667em"/><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(60)</label></disp-formula>
In the third line of <xref ref-type="disp-formula" rid="pcbi.1004490.e122">Eq (60)</xref>, we used <italic>A</italic><sup><italic>jk</italic></sup> = <bold>v</bold><sup><italic>jT</italic></sup> <bold>A</bold> <bold>v</bold><sup><italic>k</italic></sup> and collected the frequency-dependent terms for clarity. The exponential <italic>e</italic><sup><italic>iω</italic>Δ</sup> does not have any poles, so the only poles stem from <italic>f</italic><sub><italic>jk</italic></sub>, which we denote by <italic>z</italic><sub><italic>l</italic></sub>(<italic>λ</italic><sub><italic>j</italic></sub>) and the corresponding residues by Res<sub><italic>j</italic>,<italic>k</italic></sub>[<italic>z</italic><sub><italic>l</italic></sub>(<italic>λ</italic><sub><italic>j</italic></sub>)]. We only need to consider Δ ≥ 0, since the solution for negative lags follows from <inline-formula id="pcbi.1004490.e123"><alternatives><graphic id="pcbi.1004490.e123g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e123"/><mml:math id="M123" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mi>T</mml:mi></mml:msup> <mml:mo stretchy="false">(</mml:mo> <mml:mo>−</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The equation can then be solved by contour integration over the upper half of the complex plane, as the integrand vanishes at <italic>ω</italic> → +<italic>i</italic>∞. Stability requires that the poles of the first term of <xref ref-type="disp-formula" rid="pcbi.1004490.e122">Eq (60)</xref> lie only in the upper half plane (note that the linear approximation we have employed only applies in the stable regime). The poles of the second term correspondingly lie in the lower half plane and hence need not be considered. For <italic>d</italic> &gt; 0, the locations of the poles are given by [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>] Eq (12),
<disp-formula id="pcbi.1004490.e124"><alternatives><graphic id="pcbi.1004490.e124g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e124"/><mml:math id="M124" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>d</mml:mi></mml:mfrac> <mml:msub><mml:mi>W</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mfrac><mml:mi>d</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mo>/</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(61)</label></disp-formula>
where <italic>W</italic><sub><italic>l</italic></sub> is the <italic>l</italic><sup>th</sup> of the infinitely many branches of the Lambert-W function defined by <italic>x</italic> = <italic>W</italic>(<italic>x</italic>)<italic>e</italic><sup><italic>W</italic>(<italic>x</italic>)</sup> [<xref ref-type="bibr" rid="pcbi.1004490.ref090">90</xref>]. For <italic>d</italic> = 0, the poles are <inline-formula id="pcbi.1004490.e125"><alternatives><graphic id="pcbi.1004490.e125g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e125"/><mml:math id="M125" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>−</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Using the residue theorem thus brings <xref ref-type="disp-formula" rid="pcbi.1004490.e122">Eq (60)</xref> into the form
<disp-formula id="pcbi.1004490.e126"><alternatives><graphic id="pcbi.1004490.e126g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e126"/><mml:math id="M126" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">c</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>l</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mtext>Res</mml:mtext> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>l</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi> <mml:mi>l</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>with</mml:mtext> <mml:mspace width="0.277778em"/><mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi> <mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≡</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mtext>Res</mml:mtext> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(62)</label></disp-formula>
where <italic>I</italic>(<italic>γ</italic>) = 1 is the winding number of the contour <italic>γ</italic> around the poles. To see that <xref ref-type="disp-formula" rid="pcbi.1004490.e126">Eq (62)</xref> reduces to <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref> when <italic>d</italic> = 0, substitute the poles in the upper half plane <inline-formula id="pcbi.1004490.e127"><alternatives><graphic id="pcbi.1004490.e127g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e127"/><mml:math id="M127" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>−</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> with residues [<italic>iτ</italic>(2 − <italic>λ</italic><sub><italic>j</italic></sub> − <italic>λ</italic><sub><italic>k</italic></sub>)]<sup>−1</sup> and note that <inline-formula id="pcbi.1004490.e128"><alternatives><graphic id="pcbi.1004490.e128g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e128"/><mml:math id="M128" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>−</mml:mo> <mml:mtext mathvariant="bold">A</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>When the input statistics and hence transfer functions are population-specific, <xref ref-type="disp-formula" rid="pcbi.1004490.e118">Eq (56)</xref> becomes
<disp-formula id="pcbi.1004490.e129"><alternatives><graphic id="pcbi.1004490.e129g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e129"/><mml:math id="M129" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(63)</label></disp-formula> <disp-formula id="pcbi.1004490.e130"><alternatives><graphic id="pcbi.1004490.e130g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e130"/><mml:math id="M130" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≡</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>diag</mml:mtext> <mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mo>{</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>a</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mi>ω</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>α</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>α</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>…</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>pop</mml:mtext></mml:msub></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(64)</label></disp-formula>
where <italic>M</italic><sub><italic>αβ</italic></sub>(<italic>ω</italic>) = <italic>H</italic><sub><italic>αβ</italic></sub>(<italic>ω</italic>)<italic>W</italic><sub><italic>αβ</italic></sub>.</p>
</sec>
<sec id="sec016">
<title>Spiking network dynamics</title>
<p>The spiking networks consist of single-compartment leaky integrate-and-fire neurons with exponential current-based synapses. The subthreshold dynamics of neuron <italic>i</italic> is given by
<disp-formula id="pcbi.1004490.e131"><alternatives><graphic id="pcbi.1004490.e131g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e131"/><mml:math id="M131" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>V</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>V</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">s</mml:mi></mml:msub> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>I</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>J</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(65)</label></disp-formula>
where we have set the resting potential to zero without loss of generality, and absorbed the membrane resistance into the synaptic current <italic>I</italic><sub><italic>i</italic></sub>, in line with previous works [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref091">91</xref>]. Bringing back the corresponding parameters, the dynamics reads
<disp-formula id="pcbi.1004490.e132"><alternatives><graphic id="pcbi.1004490.e132g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e132"/><mml:math id="M132" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>E</mml:mi> <mml:mi mathvariant="normal">L</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>I</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">s</mml:mi></mml:msub> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>I</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>I</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">s</mml:mi></mml:msub> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(66)</label></disp-formula>
Thus, our scaled synaptic amplitudes <italic>J</italic><sub><italic>ij</italic></sub> in terms of the amplitudes <inline-formula id="pcbi.1004490.e133"><alternatives><graphic id="pcbi.1004490.e133g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e133"/><mml:math id="M133" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> of the synaptic current due to a single spike are <inline-formula id="pcbi.1004490.e134"><alternatives><graphic id="pcbi.1004490.e134g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e134"/><mml:math id="M134" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mtext mathvariant="normal">m</mml:mtext></mml:msub> <mml:msub><mml:mi>τ</mml:mi> <mml:mtext mathvariant="normal">s</mml:mtext></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mtext mathvariant="normal">m</mml:mtext></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>J</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Here, <italic>τ</italic><sub>m</sub> and <italic>τ</italic><sub>s</sub> are membrane and synaptic time constants, <italic>E</italic><sub>L</sub> is the leak or resting potential, <italic>R</italic><sub>m</sub> is the membrane resistance, <italic>d</italic> is the transmission delay, <inline-formula id="pcbi.1004490.e135"><alternatives><graphic id="pcbi.1004490.e135g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e135"/><mml:math id="M135" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>I</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mtext mathvariant="normal">m</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the total synaptic current, and <inline-formula id="pcbi.1004490.e136"><alternatives><graphic id="pcbi.1004490.e136g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e136"/><mml:math id="M136" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:mi>δ</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>k</mml:mi> <mml:mi>j</mml:mi></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> are the incoming spike trains. When <italic>V</italic><sub><italic>i</italic></sub> reaches a threshold <italic>θ</italic>, a spike is assumed, and the membrane potential is clamped to a level <italic>V</italic><sub>r</sub> for a refractory period <italic>τ</italic><sub>ref</sub>. Threshold and reset potential in physical units are shifted by the leak potential (<inline-formula id="pcbi.1004490.e137"><alternatives><graphic id="pcbi.1004490.e137g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e137"/><mml:math id="M137" display="inline" overflow="scroll"><mml:mrow><mml:mi>θ</mml:mi> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>θ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:msub><mml:mi>E</mml:mi> <mml:mtext mathvariant="normal">L</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1004490.e138"><alternatives><graphic id="pcbi.1004490.e138g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e138"/><mml:math id="M138" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>V</mml:mi> <mml:mtext mathvariant="normal">r</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:msub><mml:mi>V</mml:mi> <mml:mtext mathvariant="normal">r</mml:mtext></mml:msub> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:msub><mml:mi>E</mml:mi> <mml:mtext mathvariant="normal">L</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), showing that the assumption <italic>E</italic><sub>L</sub> = 0 in <xref ref-type="disp-formula" rid="pcbi.1004490.e131">Eq (65)</xref> does not limit generality. The intrinsic dynamics of the neurons in the different populations are taken to be identical, so that population differences are only expressed in the couplings.</p>
</sec>
<sec id="sec017">
<title>First and second moments of activity in the spiking network</title>
<p>An approximation of the stationary mean firing rate of LIF networks with exponential current-based synapses was derived in [<xref ref-type="bibr" rid="pcbi.1004490.ref091">91</xref>],
<disp-formula id="pcbi.1004490.e139"><alternatives><graphic id="pcbi.1004490.e139g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e139"/><mml:math id="M139" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>r</mml:mi></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub> <mml:msqrt><mml:mi>π</mml:mi></mml:msqrt> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>V</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>α</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:msqrt><mml:mfrac><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">s</mml:mi></mml:msub> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:msqrt></mml:mrow> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>α</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:msqrt><mml:mfrac><mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">s</mml:mi></mml:msub> <mml:msub><mml:mi>τ</mml:mi> <mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:msubsup> <mml:mo>Ψ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>Ψ</mml:mo> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:msup><mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:msup> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mtext>erf</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mi>α</mml:mi></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mo>|</mml:mo> <mml:mi>ζ</mml:mi> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(67)</label></disp-formula>
where the summed synaptic input is characterized by a Gaussian noise with first moment <italic>μ</italic> and second moment <italic>σ</italic><sup>2</sup> based on the diffusion approximation, and <italic>ζ</italic> is the Riemann zeta function.</p>
<p>For the covariances, we follow and extend the theory developed in [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>], starting with the average influence of a single synapse. Assuming that the network is in the asynchronous state, and that synaptic amplitudes are small, the synaptic influences can be averaged around the mean activity <italic>r</italic><sub><italic>j</italic></sub> of each neuron <italic>j</italic>. These influences are characterized by linear response kernels <italic>h</italic><sub><italic>jk</italic></sub>(<italic>t</italic>, <italic>t</italic>′) defined as the derivative of the density of spikes of spike train <italic>s</italic><sub><italic>j</italic></sub>(<italic>t</italic>) of neuron <italic>j</italic> with respect to an incoming spike train <italic>s</italic><sub><italic>k</italic></sub>(<italic>t</italic>′), averaged over realizations of the remaining incoming spike trains <bold>s</bold>\<italic>s</italic><sub><italic>k</italic></sub> that act as noise. In the stationary state, the kernel only depends on the time difference <italic>t</italic> − <italic>t</italic>′, giving
<disp-formula id="pcbi.1004490.e140"><alternatives><graphic id="pcbi.1004490.e140g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e140"/><mml:math id="M140" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi> <mml:mo>\</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:munderover> <mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula> <disp-formula id="pcbi.1004490.e141"><alternatives><graphic id="pcbi.1004490.e141g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e141"/><mml:math id="M141" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:mfrac><mml:mrow><mml:mi>δ</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>δ</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi> <mml:mo>\</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>≡</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mi>h</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(68)</label></disp-formula>
where <italic>δs</italic><sub><italic>j</italic></sub> ≡ <italic>s</italic><sub><italic>j</italic></sub> − <italic>r</italic><sub><italic>j</italic></sub> is the <italic>j</italic>-th centralized (zero-mean) spike train. Here, <italic>w</italic><sub><italic>jk</italic></sub> is the integral of <italic>h</italic><sub><italic>jk</italic></sub>(<italic>t</italic> − <italic>t</italic>′), and <italic>h</italic>(<italic>t</italic> − <italic>t</italic>′) is a normalized function capturing its time dependence, which may be source- and target-specific. The dimensionless effective weights <italic>w</italic><sub><italic>jk</italic></sub> are determined nonlinearly by the synaptic strengths <italic>J</italic><sub><italic>jk</italic></sub>, the single-neuron parameters, and the working point (<italic>μ</italic><sub><italic>j</italic></sub>,<italic>σ</italic><sub><italic>j</italic></sub>) (cf. [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>] Eq (A.3) but note that <italic>β</italic> as given there has a spurious factor <italic>J</italic>). We approximate the impulse response by the form <xref ref-type="disp-formula" rid="pcbi.1004490.e120">Eq (58)</xref>, where <italic>τ</italic> is now an effective time constant depending on the working point (<italic>μ</italic><sub><italic>j</italic></sub>,<italic>σ</italic><sub><italic>j</italic></sub>) and the parameters of the target neurons. This form of the impulse response, corresponding to a low-pass filter, appears to be a good approximation in the noisy regime when the neuron fires irregularly. In the mean-driven regime (<italic>μ</italic> ≫ <italic>σ</italic>) the transfer function of the LIF neuron is known to exhibit resonant behavior with a peak close to its firing rate. In this regime a single exponential response kernel is expected to be a poor approximation (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004490.ref092">92</xref>] Fig 1). In general, the source population dependence of <xref ref-type="disp-formula" rid="pcbi.1004490.e120">Eq (58)</xref> comes in through the delay <italic>d</italic>, and the target population dependence through both <italic>τ</italic> and <italic>d</italic>.</p>
<p>As for binary networks with delays, the average pairwise covariance functions <italic>c</italic><sub><italic>ij</italic></sub>(Δ) ≡ ⟨<italic>δs</italic><sub><italic>i</italic></sub>(<italic>t</italic> + Δ)<italic>δs</italic><sub><italic>j</italic></sub>(<italic>t</italic>)⟩<sub><italic>t</italic></sub> are most conveniently derived starting from the frequency domain. In case of identical transfer functions for all populations, the matrix of average cross-covariances is given by [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>] Eq (16) minus the autocovariance contribution,
<disp-formula id="pcbi.1004490.e142"><alternatives><graphic id="pcbi.1004490.e142g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e142"/><mml:math id="M142" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">W</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">W</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">W</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mtext mathvariant="bold">WA</mml:mtext></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(69)</label></disp-formula>
Here, <bold>W</bold> contains the effective weights of single synapses from population <italic>β</italic> to population <italic>α</italic> times the corresponding in-degrees, <italic>w</italic><sub><italic>αβ</italic></sub> <italic>K</italic><sub><italic>αβ</italic></sub>; and <bold>A</bold> contains the population-averaged autocovariances, which we approximate as <inline-formula id="pcbi.1004490.e143"><alternatives><graphic id="pcbi.1004490.e143g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e143"/><mml:math id="M143" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>α</mml:mi> <mml:mi>β</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mi>r</mml:mi> <mml:mi>α</mml:mi></mml:msub> <mml:msub><mml:mi>N</mml:mi> <mml:mi>α</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, with <italic>r</italic><sub><italic>α</italic></sub> the mean firing rate, as also done in [<xref ref-type="bibr" rid="pcbi.1004490.ref045">45</xref>]. In [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>], <xref ref-type="disp-formula" rid="pcbi.1004490.e142">Eq (69)</xref> was written using a more general diagonal matrix instead of <bold>A</bold>, to help clarify close similarities between binary and LIF networks and Ornstein-Uhlenbeck processes or linear rate models; however, for LIF networks, this diagonal matrix corresponds precisely to the autocovariance matrix. We chose the form <xref ref-type="disp-formula" rid="pcbi.1004490.e142">Eq (69)</xref> because it separates terms that vanish at either <italic>ω</italic> → <italic>i</italic>∞ or <italic>ω</italic> → −<italic>i</italic>∞ depending on Δ. This facilitates Fourier back transformation, as contour integration with an appropriate contour can be used for each term.</p>
<p>To perform the Fourier back transformation, we apply the same method as used for the binary network. Let <bold>v</bold><sup><italic>j</italic></sup>,<bold>u</bold><sup><italic>j</italic></sup> be the left and right eigenvectors of the connectivity matrix <bold>W</bold>, and <italic>λ</italic><sub><italic>j</italic></sub> the corresponding eigenvalues. Insert ∑<sub><italic>j</italic></sub> <bold>u</bold><sup><italic>j</italic></sup> <bold>v</bold><sup><italic>jT</italic></sup> = 𝟙 into <xref ref-type="disp-formula" rid="pcbi.1004490.e142">Eq (69)</xref> on the left and right, and Fourier transform,
<disp-formula id="pcbi.1004490.e144"><alternatives><graphic id="pcbi.1004490.e144g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e144"/><mml:math id="M144" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mi mathvariant="bold">c</mml:mi> <mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi mathvariant="bold">C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>{</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="5pt"/><mml:mrow><mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="5pt"/><mml:mrow><mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>}</mml:mo> <mml:mi>d</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(70)</label></disp-formula>
As for the binary case, we only need to consider Δ ≥ 0, as the solution for Δ &lt; 0 is given by <bold>c</bold>(Δ) = <bold>c</bold><sup><italic>T</italic></sup>(−Δ). The contour can then be closed over the upper half plane, where the term containing only <italic>H</italic>(−<italic>ω</italic>) has no poles due to the stability condition. When Δ &lt; <italic>d</italic>, the contour for the term containing only <italic>H</italic>(<italic>ω</italic>) can also be closed in the lower half plane where it has no poles, so that the corresponding integral vanishes. Analogously, the integral of the term with only <italic>H</italic>(−<italic>ω</italic>) vanishes when 0 &gt; Δ &gt; −<italic>d</italic>. Therefore, the second and third terms represent ‘echoes’ of spikes arriving after one transmission delay [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>]. For Δ = 0 and <italic>d</italic> &gt; 0, only the first term contributes, and the contour can be closed in either half plane. As before, the poles are given by <xref ref-type="disp-formula" rid="pcbi.1004490.e124">Eq (61)</xref> for <italic>d</italic> &gt; 0, and by <inline-formula id="pcbi.1004490.e145"><alternatives><graphic id="pcbi.1004490.e145g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e145"/><mml:math id="M145" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>∓</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mrow><mml:mo stretchy="true">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for <italic>d</italic> = 0. The residue theorem yields a solution of the form <xref ref-type="disp-formula" rid="pcbi.1004490.e126">Eq (62)</xref>, the only difference being the precise form of the residues, and the fact that we here consider <bold>c</bold> as opposed to <inline-formula id="pcbi.1004490.e146"><alternatives><graphic id="pcbi.1004490.e146g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e146"/><mml:math id="M146" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">c</mml:mtext> <mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>In the absence of delays, an explicit solution can again be derived. For Δ &gt; 0, the poles inside the contour are <inline-formula id="pcbi.1004490.e147"><alternatives><graphic id="pcbi.1004490.e147g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e147"/><mml:math id="M147" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>−</mml:mo> <mml:mfrac><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> corresponding to the terms with <italic>H</italic>(<italic>ω</italic>)<sup>−1</sup>. The residue corresponding to <inline-formula id="pcbi.1004490.e148"><alternatives><graphic id="pcbi.1004490.e148g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e148"/><mml:math id="M148" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> is <inline-formula id="pcbi.1004490.e149"><alternatives><graphic id="pcbi.1004490.e149g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e149"/><mml:math id="M149" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, and the term <inline-formula id="pcbi.1004490.e150"><alternatives><graphic id="pcbi.1004490.e150g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e150"/><mml:math id="M150" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mi>H</mml:mi> <mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mo>−</mml:mo> <mml:mi>ω</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> is finite and evaluates at the pole to <inline-formula id="pcbi.1004490.e151"><alternatives><graphic id="pcbi.1004490.e151g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e151"/><mml:math id="M151" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>−</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Using <italic>A</italic><sup><italic>jk</italic></sup> = <bold>v</bold><sup><italic>jT</italic></sup> <bold>A</bold> <bold>v</bold><sup><italic>k</italic></sup> we get
<disp-formula id="pcbi.1004490.e152"><alternatives><graphic id="pcbi.1004490.e152g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e152"/><mml:math id="M152" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mfrac><mml:msup><mml:mi>A</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msup> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>j</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>Δ</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(71)</label></disp-formula>
which is reminiscent of but not identical to <xref ref-type="disp-formula" rid="pcbi.1004490.e117">Eq (55)</xref> for the binary network. Note that <xref ref-type="disp-formula" rid="pcbi.1004490.e152">Eq (71)</xref> for the LIF network corresponds to spike train covariances with the dimensionality of 1/<italic>t</italic><sup>2</sup> due to [<italic>A</italic><sup><italic>jk</italic></sup>] = [1/<italic>t</italic>] and the factor 1/<italic>τ</italic>, whereas the covariances for the binary network are dimensionless.</p>
<p>The population-specific generalization of <xref ref-type="disp-formula" rid="pcbi.1004490.e142">Eq (69)</xref> reads
<disp-formula id="pcbi.1004490.e153"><alternatives><graphic id="pcbi.1004490.e153g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e153"/><mml:math id="M153" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(72)</label></disp-formula>
where <bold>M</bold>(<italic>ω</italic>) has elements <italic>H</italic><sub><italic>αβ</italic></sub>(<italic>ω</italic>)<italic>K</italic><sub><italic>αβ</italic></sub> <italic>w</italic><sub><italic>αβ</italic></sub>, as before. The covariance matrix including autocovariances can be more simply written as
<disp-formula id="pcbi.1004490.e154"><alternatives><graphic id="pcbi.1004490.e154g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e154"/><mml:math id="M154" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo mathvariant="bold">𝟙</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(73)</label></disp-formula>
The only difference compared to the expression <xref ref-type="disp-formula" rid="pcbi.1004490.e129">Eq (63)</xref> for the binary network is the form of the diagonal matrix, here analogous to white output noise in a linear rate model, whereas the binary network resembles a linear rate model with white noise on the input side, which is passed through the transfer function before affecting the correlations [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>].</p>
</sec>
<sec id="sec018">
<title>Fluctuating rate equation and stability condition</title>
<p>An alternative description of the spiking dynamics can be obtained by considering a system of linear coupled rate equations that produces the same moments to second order as the spiking dynamics [<xref ref-type="bibr" rid="pcbi.1004490.ref053">53</xref>]. The convolution equation
<disp-formula id="pcbi.1004490.e155"><alternatives><graphic id="pcbi.1004490.e155g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e155"/><mml:math id="M155" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:mo>∫</mml:mo> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>h</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>y</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>with</mml:mtext> <mml:mspace width="4.pt"/></mml:mrow></mml:mtd> <mml:mtd/><mml:mtd columnalign="left"><mml:mrow/></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(74)</label></disp-formula>
with pairwise uncorrelated white noises <italic>x</italic><sub><italic>j</italic></sub> and the response kernel <italic>h</italic><sub><italic>jk</italic></sub> given by <xref ref-type="disp-formula" rid="pcbi.1004490.e141">Eq (68)</xref> can be shown to yield a cross-covariance matrix of the form <xref ref-type="disp-formula" rid="pcbi.1004490.e142">Eq (69)</xref> by considering the Fourier transform of <xref ref-type="disp-formula" rid="pcbi.1004490.e155">Eq (74)</xref>, written in matrix notation as
<disp-formula id="pcbi.1004490.e156"><alternatives><graphic id="pcbi.1004490.e156g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e156"/><mml:math id="M156" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>H</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mspace width="0.166667em"/><mml:mi mathvariant="bold">W</mml:mi> <mml:mspace width="0.166667em"/><mml:mi mathvariant="bold">Y</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(75)</label></disp-formula>
We can expand the latter equation into eigenmodes by multiplying from the left with the left-sided eigenvector <bold>v</bold><sup><italic>k</italic></sup> of <bold>W</bold> and by writing the general solution as a linear combination of right-sided eigenmodes <bold>Y</bold>(<italic>ω</italic>) = ∑<sub><italic>j</italic></sub> <italic>η</italic><sub><italic>j</italic></sub>(<italic>ω</italic>) <bold>u</bold><sup><italic>j</italic></sup> to obtain (with the bi-orthogonality relation <bold>v</bold><sup><italic>kT</italic></sup> <bold>u</bold><sup><italic>j</italic></sup> = <italic>δ</italic><sub><italic>kj</italic></sub>)
<disp-formula id="pcbi.1004490.e157"><alternatives><graphic id="pcbi.1004490.e157g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e157"/><mml:math id="M157" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>η</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>η</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>η</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(76)</label></disp-formula>
The latter equation shows that the same poles <italic>z</italic>(<italic>λ</italic><sub><italic>k</italic></sub>) that appear in the covariance function <xref ref-type="disp-formula" rid="pcbi.1004490.e144">Eq (70)</xref> also determine the evolution of the effective rate equation. Moreover, transforming <xref ref-type="disp-formula" rid="pcbi.1004490.e157">Eq (76)</xref> back to the time domain, we see with
<disp-formula id="pcbi.1004490.e158"><alternatives><graphic id="pcbi.1004490.e158g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004490.e158"/><mml:math id="M158" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>η</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mtext>poles</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>z</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:munder> <mml:mtext>Res</mml:mtext> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mi>z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mspace width="0.166667em"/><mml:mi>i</mml:mi> <mml:mi>z</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mspace width="0.166667em"/><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
that the eigenmodes have a time evolution determined by <italic>e</italic><sup><italic>iz</italic>(<italic>λ</italic><sub><italic>k</italic></sub>)<italic>t</italic></sup>. Hence the imaginary part of the pole <italic>z</italic>(<italic>λ</italic><sub><italic>k</italic></sub>) controls whether the mode is exponentially growing (Im(<italic>z</italic>) &lt; 0) or decaying (Im(<italic>z</italic>) &gt; 0), while the real part determines the oscillation frequency.</p>
</sec>
</sec>
<sec id="sec019">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004490.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004490.s001" mimetype="application/pdf" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Derivation of one-to-one relationship between effective connectivity and correlations for binary networks and networks consisting of populations with identical response properties.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004490.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>van Albada</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Kunkel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2014</year>) <chapter-title>Integrating brain structure and dynamics on supercomputers</chapter-title>. In: <name name-style="western"><surname>Grandinetti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lippert</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Petkov</surname> <given-names>N</given-names></name>, editors, <source>Brain-Inspired Computing</source>, <publisher-name>Springer</publisher-name>. pp. <fpage>22</fpage>–<lpage>32</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kunkel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Masumoto</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Igarashi</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Eppler</surname> <given-names>JM</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Supercomputers ready for use as discovery machines for neuroscience</article-title>. <source>Front Neuroinform</source> <volume>6</volume>: <fpage>26</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fninf.2012.00026" xlink:type="simple">10.3389/fninf.2012.00026</ext-link></comment> <object-id pub-id-type="pmid">23129998</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Khan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lester</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Plana</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Rast</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>X</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <chapter-title>SpiNNaker: mapping neural networks onto a massively-parallel chip multiprocessor</chapter-title>. In: <source>2008 International Joint Conference on Neural Networks (IJCNN 2008)</source>. <publisher-loc>Hong Kong</publisher-loc>: <publisher-name>IEEE Press</publisher-name>, pp. <fpage>2849</fpage>–<lpage>2856</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brüderle</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Petrovici</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vogginger</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ehrlich</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pfeil</surname> <given-names>T</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>A comprehensive workflow for general-purpose neural modeling with highly configurable neuromorphic hardware systems</article-title>. <source>Biol Cybern</source> <volume>104</volume>: <fpage>263</fpage>–<lpage>296</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-011-0435-9" xlink:type="simple">10.1007/s00422-011-0435-9</ext-link></comment> <object-id pub-id-type="pmid">21618053</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sharp</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Furber</surname> <given-names>S</given-names></name> (<year>2014</year>) <article-title>Real-time million-synapse simulation of rat barrel cortex</article-title>. <source>Front Neurosci</source> <volume>8</volume>: <fpage>131</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnins.2014.00131" xlink:type="simple">10.3389/fnins.2014.00131</ext-link></comment> <object-id pub-id-type="pmid">24910593</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kunkel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Eppler</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Masumoto</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Igarashi</surname> <given-names>J</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Spiking network simulation code for petascale computers</article-title>. <source>Frontiers in Neuroinformatics</source> <volume>8</volume>: <fpage>78</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fninf.2014.00078" xlink:type="simple">10.3389/fninf.2014.00078</ext-link></comment> <object-id pub-id-type="pmid">25346682</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Renart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>De La Rocha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bartho</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hollender</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Parga</surname> <given-names>N</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>The asynchronous state in cortical circuits</article-title>. <source>Science</source> <volume>327</volume>: <fpage>587</fpage>–<lpage>590</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1179850" xlink:type="simple">10.1126/science.1179850</ext-link></comment> <object-id pub-id-type="pmid">20110507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Einevoll</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Decorrelation of neural-network activity by inhibitory feedback</article-title>. <source>PLoS Comput Biol</source> <volume>8</volume>: <fpage>e1002596</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002596" xlink:type="simple">10.1371/journal.pcbi.1002596</ext-link></comment> <object-id pub-id-type="pmid">23133368</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2014</year>) <article-title>The correlation structure of local cortical networks intrinsically results from recurrent dynamics</article-title>. <source>PLoS Comput Biol</source> <volume>10</volume>: <fpage>e1003428</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003428" xlink:type="simple">10.1371/journal.pcbi.1003428</ext-link></comment> <object-id pub-id-type="pmid">24453955</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bower</surname> <given-names>JM</given-names></name> (<year>1992</year>) <article-title>Cortical oscillations and temporal interactions in a computer simulation of piriform cortex</article-title>. <source>J Neurophysiol</source> <volume>67</volume>: <fpage>981</fpage>–<lpage>995</lpage>. <object-id pub-id-type="pmid">1316954</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tsodyks</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name> (<year>1995</year>) <article-title>Rapid state switching in balanced cortical network models</article-title>. <source>Network: Comput Neural Systems</source> <volume>6</volume>: <fpage>111</fpage>–<lpage>124</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X/6/2/001" xlink:type="simple">10.1088/0954-898X/6/2/001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hill</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tononi</surname> <given-names>G</given-names></name> (<year>2005</year>) <article-title>Modeling sleep and wakefulness in the thalamocortical system</article-title>. <source>J Neurophysiol</source> <volume>93</volume>: <fpage>1671</fpage>–<lpage>1698</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00915.2004" xlink:type="simple">10.1152/jn.00915.2004</ext-link></comment> <object-id pub-id-type="pmid">15537811</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Edelman</surname> <given-names>GM</given-names></name> (<year>2008</year>) <article-title>Large-scale model of mammalian thalamocortical systems</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>105</volume>: <fpage>3593</fpage>–<lpage>3598</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0712231105" xlink:type="simple">10.1073/pnas.0712231105</ext-link></comment> <object-id pub-id-type="pmid">18292226</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Winslow</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Kimball</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Varghese</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>D</given-names></name> (<year>1993</year>) <article-title>Simulating cardiac sinus and atrial network dynamics on the connection machine</article-title>. <source>Physica D</source> <volume>64</volume>: <fpage>281</fpage>–<lpage>298</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(93)90260-8" xlink:type="simple">10.1016/0167-2789(93)90260-8</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Morris</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kretzschmar</surname> <given-names>M</given-names></name> (<year>1997</year>) <article-title>Concurrent partnerships and the spread of HIV</article-title>. <source>AIDS</source> <volume>11</volume>: <fpage>641</fpage>–<lpage>648</lpage>. <object-id pub-id-type="pmid">9108946</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ten Tusscher</surname> <given-names>KHWJ</given-names></name>, <name name-style="western"><surname>Panfilov</surname> <given-names>AV</given-names></name> (<year>2006</year>) <article-title>Cell model for efficient simulation of wave propagation in human ventricular tissue under normal and pathological conditions</article-title>. <source>Phys Med Biol</source> <volume>51</volume>: <fpage>6141</fpage>–<lpage>6156</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0031-9155/51/23/014" xlink:type="simple">10.1088/0031-9155/51/23/014</ext-link></comment> <object-id pub-id-type="pmid">17110776</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="other">Bisset KR, Chen J, Feng X, Kumar VSA (2009) EpiFast: a fast algorithm for large scale realistic epidemic simulations on distributed memory systems. In: Proceedings of the 23rd international conference on Supercomputing. pp. 430–439.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Crook</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bednar</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Berger</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cannon</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Davison</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Creating, documenting and sharing network models</article-title>. <source>Network: Comput Neural Systems</source> <volume>23</volume>: <fpage>131</fpage>–<lpage>149</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Amit</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name> (<year>1997</year>) <article-title>Dynamics of a recurrent network of spiking neurons before and following learning</article-title>. <source>Network: Comput Neural Syst</source> <volume>8</volume>: <fpage>373</fpage>–<lpage>404</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Amit</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name> (<year>1991</year>) <article-title>Quantitative study of attractor neural networks retrieving at low spike rates: II</article-title>. <source>low-rate retrieval in symmetric networks. Network: Comput Neural Systems</source> <volume>2</volume>: <fpage>275</fpage>–<lpage>294</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name> (<year>1992</year>) <article-title>Universality in neural networks: the importance of the ‘mean firing rate’</article-title>. <source>Biol Cybern</source> <volume>67</volume>: <fpage>195</fpage>–<lpage>205</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00204392" xlink:type="simple">10.1007/BF00204392</ext-link></comment> <object-id pub-id-type="pmid">1498186</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brody</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Hernandez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lemus</surname> <given-names>L</given-names></name> (<year>1999</year>) <article-title>Neuronal correlates of parametric working memory in the prefrontal cortex</article-title>. <source>Nature</source> <volume>399</volume>: <fpage>470</fpage>–<lpage>473</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/20939" xlink:type="simple">10.1038/20939</ext-link></comment> <object-id pub-id-type="pmid">10365959</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ahissar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sosnik</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Haidarliu</surname> <given-names>S</given-names></name> (<year>2000</year>) <article-title>Transformation from temporal to rate coding in somatosensory thalamocortical pathway</article-title>. <source>Nature</source> <volume>406</volume>: <fpage>302</fpage>–<lpage>306</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35018568" xlink:type="simple">10.1038/35018568</ext-link></comment> <object-id pub-id-type="pmid">10917531</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hubel</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname> <given-names>TN</given-names></name> (<year>1968</year>) <article-title>Receptive fields and functional architecture of monkey striate cortex</article-title>. <source>J Neurophysiol</source> <volume>195</volume>: <fpage>215</fpage>–<lpage>243</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Georgopoulos</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kettner</surname> <given-names>R</given-names></name> (<year>1986</year>) <article-title>Neuronal population coding of movement direction</article-title>. <source>Science</source> <volume>4771</volume>: <fpage>1416</fpage>–<lpage>1419</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.3749885" xlink:type="simple">10.1126/science.3749885</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Steriade</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Timofeev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Grenier</surname> <given-names>F</given-names></name> (<year>2001</year>) <article-title>Natural waking and sleep states: a view from inside neocortical neurons</article-title>. <source>J Neurophysiol</source> <volume>85</volume>: <fpage>1969</fpage>–<lpage>1985</lpage>. <object-id pub-id-type="pmid">11353014</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roelfsema</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>König</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name> (<year>1996</year>) <article-title>The role of neuronal synchronization in response selection: A biologically plausible theory of structured representations in the visual cortex</article-title>. <source>J Cogn Neurosci</source> <volume>8</volume>: <fpage>603</fpage>–<lpage>625</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.1996.8.6.603" xlink:type="simple">10.1162/jocn.1996.8.6.603</ext-link></comment> <object-id pub-id-type="pmid">23961987</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>van Albada</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>P</given-names></name> (<year>2009</year>) <article-title>Mean-field modeling of the basal ganglia-thalamocortical system</article-title>. <source>I: Firing rates in healthy and parkinsonian states. J Theor Biol</source> <volume>257</volume>: <fpage>642</fpage>–<lpage>663</lpage>. <object-id pub-id-type="pmid">19168074</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Perkel</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Gerstein</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>GP</given-names></name> (<year>1967</year>) <article-title>Neuronal spike trains and stochastic point processes</article-title>. <source>II. Simultaneous spike trains. Biophys J</source> <volume>7</volume>: <fpage>419</fpage>–<lpage>440</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0006-3495(67)86597-4" xlink:type="simple">10.1016/S0006-3495(67)86597-4</ext-link></comment> <object-id pub-id-type="pmid">4292792</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Aertsen</surname> <given-names>AMHJ</given-names></name>, <name name-style="western"><surname>Gerstein</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Habib</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Palm</surname> <given-names>G</given-names></name> (<year>1989</year>) <article-title>Dynamics of neuronal firing correlation: modulation of ‘effective connectivity’</article-title>. <source>J Neurophysiol</source> <volume>61</volume>: <fpage>900</fpage>–<lpage>917</lpage>. <object-id pub-id-type="pmid">2723733</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kilavik</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Roux</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ponce-Alvarez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Confais</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gruen</surname> <given-names>S</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Long-term modifications in motor cortical dynamics induced by intensive practice</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>12653</fpage>–<lpage>12663</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1554-09.2009" xlink:type="simple">10.1523/JNEUROSCI.1554-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19812340</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name> (<year>2006</year>) <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source> <volume>440</volume>: <fpage>1007</fpage>–<lpage>1012</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04701" xlink:type="simple">10.1038/nature04701</ext-link></comment> <object-id pub-id-type="pmid">16625187</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ito</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maldonado</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>Saccade-related modulations of neuronal excitability support synchrony of visually elicited spikes</article-title>. <source>Cereb Cortex</source> <volume>21</volume>: <fpage>2482</fpage>–<lpage>2497</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhr020" xlink:type="simple">10.1093/cercor/bhr020</ext-link></comment> <object-id pub-id-type="pmid">21459839</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Riehle</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name> (<year>1997</year>) <article-title>Spike synchronization and rate modulation differentially involved in motor cortical function</article-title>. <source>Science</source> <volume>278</volume>: <fpage>1950</fpage>–<lpage>1953</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.278.5345.1950" xlink:type="simple">10.1126/science.278.5345.1950</ext-link></comment> <object-id pub-id-type="pmid">9395398</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Vaadia</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Haalman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Abeles</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bergman</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Prut</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. (<year>1995</year>) <article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioural events</article-title>. <source>Nature</source> <volume>373</volume>: <fpage>515</fpage>–<lpage>518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/373515a0" xlink:type="simple">10.1038/373515a0</ext-link></comment> <object-id pub-id-type="pmid">7845462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Yoon</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kang</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shamir</surname> <given-names>M</given-names></name> (<year>2001</year>) <article-title>Population coding in neuronal systems with correlated noise</article-title>. <source>Phys Rev E</source> <volume>64</volume>: <fpage>51904</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.64.051904" xlink:type="simple">10.1103/PhysRevE.64.051904</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zohary</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name> (<year>1994</year>) <article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title>. <source>Nature</source> <volume>370</volume>: <fpage>140</fpage>–<lpage>143</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/370140a0" xlink:type="simple">10.1038/370140a0</ext-link></comment> <object-id pub-id-type="pmid">8022482</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Desai</surname> <given-names>NS</given-names></name> (<year>2003</year>) <article-title>Relating STDP to BCM</article-title>. <source>Neural Comput</source> <volume>15</volume>: <fpage>1511</fpage>–<lpage>1523</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976603321891783" xlink:type="simple">10.1162/089976603321891783</ext-link></comment> <object-id pub-id-type="pmid">12816564</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2007</year>) <article-title>Spike-timing dependent plasticity in balanced random networks</article-title>. <source>Neural Comput</source> <volume>19</volume>: <fpage>1437</fpage>–<lpage>1467</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2007.19.6.1437" xlink:type="simple">10.1162/neco.2007.19.6.1437</ext-link></comment> <object-id pub-id-type="pmid">17444756</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lindén</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Potjans</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Pettersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Modeling the spatial reach of the LFP</article-title>. <source>Neuron</source> <volume>72</volume>: <fpage>859</fpage>–<lpage>872</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.11.006" xlink:type="simple">10.1016/j.neuron.2011.11.006</ext-link></comment> <object-id pub-id-type="pmid">22153380</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nir</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Fisch</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Mukamel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gelbard-Sagiv</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Arieli</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Coupling between neuronal firing rate, gamma LFP, and BOLD fMRI is related to interneuronal correlations</article-title>. <source>Current Biology</source> <volume>17</volume>: <fpage>1275</fpage>–<lpage>1285</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2007.06.066" xlink:type="simple">10.1016/j.cub.2007.06.066</ext-link></comment> <object-id pub-id-type="pmid">17686438</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ginzburg</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name> (<year>1994</year>) <article-title>Theory of correlations in stochastic neural networks</article-title>. <source>Phys Rev E</source> <volume>50</volume>: <fpage>3171</fpage>–<lpage>3191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.50.3171" xlink:type="simple">10.1103/PhysRevE.50.3171</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>van Vreeswijk</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name> (<year>1998</year>) <article-title>Chaotic balanced state in a model of cortical circuits</article-title>. <source>Neural Comput</source> <volume>10</volume>: <fpage>1321</fpage>–<lpage>1371</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976698300017214" xlink:type="simple">10.1162/089976698300017214</ext-link></comment> <object-id pub-id-type="pmid">9698348</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name> (<year>2010</year>) <article-title>Cross-correlations in high-conductance states of a model cortical network</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>427</fpage>–<lpage>447</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2009.06-08-806" xlink:type="simple">10.1162/neco.2009.06-08-806</ext-link></comment> <object-id pub-id-type="pmid">19842988</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Echoes in correlated neural systems</article-title>. <source>New J Phys</source> <volume>15</volume>: <fpage>023002</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1367-2630/15/2/023002" xlink:type="simple">10.1088/1367-2630/15/2/023002</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Van Vreeswijk</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name> (<year>1998</year>) <article-title>Chaotic balanced state in a model of cortical circuits</article-title>. <source>Neural Comput</source> <volume>10</volume>: <fpage>1321</fpage>–<lpage>1371</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976698300017214" xlink:type="simple">10.1162/089976698300017214</ext-link></comment> <object-id pub-id-type="pmid">9698348</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="other">Aertsen A, Preißl H (1990) Dynamics of activity and connectivity in physiological neuronal networks. In: Schuster HG, editor, Nonlinear Dynamics and Neuronal Networks. VCH, Proceedings of the 63rd W. E. Heraeus Seminar Friedrichsdorf 1990, pp. 281–301.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2011</year>) <article-title>Functional and effective connectivity: a review</article-title>. <source>Brain Connectivity</source> <volume>1</volume>: <fpage>13</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1089/brain.2011.0008" xlink:type="simple">10.1089/brain.2011.0008</ext-link></comment> <object-id pub-id-type="pmid">22432952</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lindner</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Longtin</surname> <given-names>A</given-names></name> (<year>2005</year>) <article-title>Theory of oscillatory firing induced by spatially correlated noise and delayed inhibitory feedback</article-title>. <source>Phys Rev E</source> <volume>72</volume>: <fpage>061919</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.72.061919" xlink:type="simple">10.1103/PhysRevE.72.061919</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>How structure determines correlations in neuronal networks</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002059</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002059" xlink:type="simple">10.1371/journal.pcbi.1002059</ext-link></comment> <object-id pub-id-type="pmid">21625580</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Trousdale</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Josic</surname> <given-names>K</given-names></name> (<year>2012</year>) <article-title>Impact of network structure and cellular response on spike time correlations</article-title>. <source>PLoS Comput Biol</source> <volume>8</volume>: <fpage>e1002408</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002408" xlink:type="simple">10.1371/journal.pcbi.1002408</ext-link></comment> <object-id pub-id-type="pmid">22457608</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Grytskyy</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Invariance of covariances arises out of noise</article-title>. <source>AIP Conf Proc</source> <volume>1510</volume>: <fpage>258</fpage>–<lpage>262</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1063/1.4776531" xlink:type="simple">10.1063/1.4776531</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Grytskyy</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tetzlaff</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>A unified view on weakly correlated recurrent networks</article-title>. <source>Front Comput Neurosci</source> <volume>7</volume>: <fpage>131</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00131" xlink:type="simple">10.3389/fncom.2013.00131</ext-link></comment> <object-id pub-id-type="pmid">24151463</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Okun</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lampl</surname> <given-names>I</given-names></name> (<year>2008</year>) <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nature Neuroscience</source> <volume>11</volume>: <fpage>535</fpage>–<lpage>537</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2105" xlink:type="simple">10.1038/nn.2105</ext-link></comment> <object-id pub-id-type="pmid">18376400</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Graupner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>AD</given-names></name> (<year>2013</year>) <article-title>Synaptic input correlations leading to membrane potential decorrelation of spontaneous activity in cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>15075</fpage>–<lpage>15085</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0347-13.2013" xlink:type="simple">10.1523/JNEUROSCI.0347-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24048838</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>van Albada</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Schrader</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Influence of different types of downscaling on a cortical microcircuit model</article-title>. <source>BMC Neuroscience</source> <volume>14</volume>: <fpage>P112</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1471-2202-14-S1-P112" xlink:type="simple">10.1186/1471-2202-14-S1-P112</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="other">Bronstein IN, Semendjajew KA, Musiol G, Mühlig H (1999) Taschenbuch der Mathematik. Verlag Harri Deutsch, 4th edition.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Potjans</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2014</year>) <article-title>The cell-type specific cortical microcircuit: Relating structure and activity in a full-scale spiking network model</article-title>. <source>Cereb Cortex</source> <volume>24</volume>: <fpage>785</fpage>–<lpage>806</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhs358" xlink:type="simple">10.1093/cercor/bhs358</ext-link></comment> <object-id pub-id-type="pmid">23203991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref059">
<label>59</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kamiński</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ding</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Truccolo</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Bressler</surname> <given-names>SL</given-names></name> (<year>2001</year>) <article-title>Evaluating causal relations in neural systems: Granger causality, directed transfer function and statistical assessment of signicance</article-title>. <source>Biol Cybern</source> <volume>85</volume>: <fpage>145</fpage>–<lpage>157</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s004220000235" xlink:type="simple">10.1007/s004220000235</ext-link></comment> <object-id pub-id-type="pmid">11508777</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref060">
<label>60</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Harrison</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>W</given-names></name> (<year>2003</year>) <article-title>Dynamic causal modelling</article-title>. <source>NeuroImage</source> <volume>19</volume>: <fpage>1273</fpage>–<lpage>1302</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1053-8119(03)00202-7" xlink:type="simple">10.1016/S1053-8119(03)00202-7</ext-link></comment> <object-id pub-id-type="pmid">12948688</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref061">
<label>61</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nykamp</surname> <given-names>DQ</given-names></name> (<year>2007</year>) <article-title>A mathematical framework for inferring connectivity in probabilistic neuronal networks</article-title>. <source>Math Biosci</source> <volume>205</volume>: <fpage>204</fpage>–<lpage>251</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.mbs.2006.08.020" xlink:type="simple">10.1016/j.mbs.2006.08.020</ext-link></comment> <object-id pub-id-type="pmid">17070863</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref062">
<label>62</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Timme</surname> <given-names>M</given-names></name> (<year>2007</year>) <article-title>Revealing network connectivity from response dynamics</article-title>. <source>Phys Rev Lett</source> <volume>98</volume>: <fpage>224101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.98.224101" xlink:type="simple">10.1103/PhysRevLett.98.224101</ext-link></comment> <object-id pub-id-type="pmid">17677845</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref063">
<label>63</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name> (<year>2011</year>) <article-title>Mean field theory for nonequilibrium network reconstruction</article-title>. <source>Physical Review Letters</source> <volume>106</volume>: <fpage>048702</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.106.048702" xlink:type="simple">10.1103/PhysRevLett.106.048702</ext-link></comment> <object-id pub-id-type="pmid">21405370</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref064">
<label>64</label>
<mixed-citation xlink:type="simple" publication-type="other">Pernice V, Rotter S (2012) Reconstruction of connectivity in sparse neural networks from spike train covariances. Front Comput Neurosci Conference Abstract: Bernstein Conference 2012.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref065">
<label>65</label>
<mixed-citation xlink:type="simple" publication-type="other">Grytskyy D, Helias M, Diesmann M (2013) Reconstruction of network connectivity in the irregular firing regime. In: Proceedings 10th Göttingen Meeting of the German Neuroscience Society. pp. 1192–1193.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref066">
<label>66</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Robinson</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Sarkar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pandejee</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Henderson</surname> <given-names>JA</given-names></name> (<year>2014</year>) <article-title>Determination of effective brain connectivity from functional connectivity with application to resting state connectivities</article-title>. <source>Phys Rev E</source> <volume>90</volume>: <issue>012707</issue>:<fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref067">
<label>67</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>D’haeseleer</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Somogyi</surname> <given-names>R</given-names></name> (<year>2000</year>) <article-title>Genetic network inference: from co-expression clustering to reverse engineering</article-title>. <source>Bioinformatics</source> <volume>16</volume>: <fpage>707</fpage>–<lpage>726</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/16.8.707" xlink:type="simple">10.1093/bioinformatics/16.8.707</ext-link></comment> <object-id pub-id-type="pmid">11099257</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref068">
<label>68</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Steuer</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kurths</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fiehn</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Weckwerth</surname> <given-names>W</given-names></name> (<year>2003</year>) <article-title>Observing and interpreting correlations in metabolomic networks</article-title>. <source>Bioinformatics</source> <volume>19</volume>: <fpage>1019</fpage>–<lpage>1026</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btg120" xlink:type="simple">10.1093/bioinformatics/btg120</ext-link></comment> <object-id pub-id-type="pmid">12761066</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref069">
<label>69</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Psorakis</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Rezek</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Sheldon</surname> <given-names>BC</given-names></name> (<year>2012</year>) <article-title>Inferring social network structure in ecological systems from spatio-temporal data streams</article-title>. <source>J R Soc Interface</source>: <fpage>rsif20120223</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref070">
<label>70</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tyrcha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Marsili</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name> (<year>2013</year>) <article-title>The effect of nonstationarity on models inferred from neural data</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source> <volume>2013</volume>: <fpage>P03005</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03005" xlink:type="simple">10.1088/1742-5468/2013/03/P03005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref071">
<label>71</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Helmchen</surname> <given-names>F</given-names></name> (<year>2009</year>) <chapter-title>Two-photon functional imaging of neuronal activity</chapter-title>. In: <name name-style="western"><surname>Frostig</surname> <given-names>R</given-names></name>, editor, In <source>Vivo Optical Imaging of Brain Function</source>, <publisher-loc>Boca Raton (FL)</publisher-loc>: <publisher-name>CRC Press</publisher-name>, <comment>chapter 2</comment> <edition>2nd edition</edition>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref072">
<label>72</label>
<mixed-citation xlink:type="simple" publication-type="other">Akemann W, Sasaki M, Mutoh H, Imamura T, Honkura N, et al. (2013) Two-photon voltage imaging using a genetically encoded voltage indicator. Scientific Reports 3.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref073">
<label>73</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kempter</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>van Hemmen</surname> <given-names>JL</given-names></name> (<year>1999</year>) <article-title>Hebbian learning and spiking neurons</article-title>. <source>Phys Rev E</source> <volume>59</volume>: <fpage>4498</fpage>–<lpage>4514</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.59.4498" xlink:type="simple">10.1103/PhysRevE.59.4498</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref074">
<label>74</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kunkel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name> (<year>2011</year>) <article-title>Limits to the development of feed-forward structures in large recurrent neuronal networks</article-title>. <source>Front Comput Neurosci</source> <volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2010.00160" xlink:type="simple">10.3389/fncom.2010.00160</ext-link></comment> <object-id pub-id-type="pmid">21415913</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref075">
<label>75</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Turrigiano</surname> <given-names>GG</given-names></name> (<year>2008</year>) <article-title>The self-tuning neuron: synaptic scaling of excitatory synapses</article-title>. <source>Cell</source> <volume>135</volume>: <fpage>422</fpage>–<lpage>435</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cell.2008.10.008" xlink:type="simple">10.1016/j.cell.2008.10.008</ext-link></comment> <object-id pub-id-type="pmid">18984155</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref076">
<label>76</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Turrigiano</surname> <given-names>GG</given-names></name>, <name name-style="western"><surname>Leslie</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Desai</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Rutherford</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>SB</given-names></name> (<year>1998</year>) <article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons</article-title>. <source>Nature</source> <volume>391</volume>: <fpage>892</fpage>–<lpage>896</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/36103" xlink:type="simple">10.1038/36103</ext-link></comment> <object-id pub-id-type="pmid">9495341</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref077">
<label>77</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Burrone</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Murthy</surname> <given-names>VN</given-names></name> (<year>2003</year>) <article-title>Synaptic gain control and homeostasis</article-title>. <source>Curr Opin Neurobiol</source> <volume>13</volume>: <fpage>560</fpage>–<lpage>567</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2003.09.007" xlink:type="simple">10.1016/j.conb.2003.09.007</ext-link></comment> <object-id pub-id-type="pmid">14630218</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref078">
<label>78</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Liu</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Tsien</surname> <given-names>RW</given-names></name> (<year>1995</year>) <article-title>Properties of synaptic transmission at single hippocampal synaptic boutons</article-title>. <source>Nature</source> <volume>375</volume>: <fpage>404</fpage>–<lpage>408</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/375404a0" xlink:type="simple">10.1038/375404a0</ext-link></comment> <object-id pub-id-type="pmid">7760934</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref079">
<label>79</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wilson</surname> <given-names>NR</given-names></name>, <name name-style="western"><surname>Ty</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Ingber</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Sur</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>G</given-names></name> (<year>2007</year>) <article-title>Synaptic reorganization in scaled networks of controlled size</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>13581</fpage>–<lpage>13589</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3863-07.2007" xlink:type="simple">10.1523/JNEUROSCI.3863-07.2007</ext-link></comment> <object-id pub-id-type="pmid">18077670</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref080">
<label>80</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ivenshitz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Segal</surname> <given-names>M</given-names></name> (<year>2010</year>) <article-title>Neuronal density determines network connectivity and spontaneous activity in cultured hippocampus</article-title>. <source>J Neurophysiol</source> <volume>104</volume>: <fpage>1052</fpage>–<lpage>1060</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00914.2009" xlink:type="simple">10.1152/jn.00914.2009</ext-link></comment> <object-id pub-id-type="pmid">20554850</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref081">
<label>81</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Medalla</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Luebke</surname> <given-names>JI</given-names></name> (<year>2015</year>) <article-title>Diversity of glutamatergic synaptic strength in lateral prefrontal versus primary visual cortices in the rhesus monkey</article-title>. <source>J Neurosci</source> <volume>35</volume>: <fpage>112</fpage>–<lpage>127</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3426-14.2015" xlink:type="simple">10.1523/JNEUROSCI.3426-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25568107</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref082">
<label>82</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Desai</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Cudmore</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Turrigiano</surname> <given-names>GG</given-names></name> (<year>2002</year>) <article-title>Critical periods for experience-dependent synaptic scaling in visual cortex</article-title>. <source>Nat Neurosci</source> <volume>5</volume>: <fpage>783</fpage>–<lpage>789</lpage>. <object-id pub-id-type="pmid">12080341</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref083">
<label>83</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gewaltig</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2007</year>) <article-title>NEST (NEural Simulation Tool)</article-title>. <source>Scholarpedia</source> <volume>2</volume>: <fpage>1430</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.4249/scholarpedia.1430" xlink:type="simple">10.4249/scholarpedia.1430</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref084">
<label>84</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Davison</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Brüderle</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Eppler</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kremkow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>E</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>PyNN: a common interface for neuronal network simulators</article-title>. <source>Front Neuroinformatics</source> <volume>2</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.11.011.2008" xlink:type="simple">10.3389/neuro.11.011.2008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref085">
<label>85</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hanuschkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kunkel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Helias</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name> (<year>2010</year>) <article-title>A general and efficient method for incorporating precise spike times in globally time-driven simulations</article-title>. <source>Front Neuroinform</source> <volume>4</volume>: <fpage>113</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fninf.2010.00113" xlink:type="simple">10.3389/fninf.2010.00113</ext-link></comment> <object-id pub-id-type="pmid">21031031</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref086">
<label>86</label>
<mixed-citation xlink:type="simple" publication-type="other">Stein W, et al. (2013) Sage Mathematics Software (Version 5.9). The Sage Development Team. <monospace>http://www.sagemath.org</monospace>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref087">
<label>87</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Buice</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Chow</surname> <given-names>CC</given-names></name> (<year>2009</year>) <article-title>Systematic fluctuation expansion for neural network activity equations</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>377</fpage>–<lpage>426</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2009.02-09-960" xlink:type="simple">10.1162/neco.2009.02-09-960</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref088">
<label>88</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name> (<year>1982</year>) <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>79</volume>: <fpage>2554</fpage>–<lpage>2558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.79.8.2554" xlink:type="simple">10.1073/pnas.79.8.2554</ext-link></comment> <object-id pub-id-type="pmid">6953413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref089">
<label>89</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Krogh</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>RG</given-names></name> (<year>1991</year>) <source>Introduction to the Theory of Neural Computation</source>. <publisher-name>Perseus Books</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004490.ref090">
<label>90</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Corless</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Gonnet</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Hare</surname> <given-names>DEG</given-names></name>, <name name-style="western"><surname>Jeffrey</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Knuth</surname> <given-names>DE</given-names></name> (<year>1996</year>) <article-title>On the Lambert W function</article-title>. <source>Advances in Computational Mathematics</source> <volume>5</volume>: <fpage>329</fpage>–<lpage>359</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02124750" xlink:type="simple">10.1007/BF02124750</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref091">
<label>91</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fourcaud</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name> (<year>2002</year>) <article-title>Dynamics of the firing probability of noisy integrate-and-fire neurons</article-title>. <source>Neural Comput</source> <volume>14</volume>: <fpage>2057</fpage>–<lpage>2110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976602320264015" xlink:type="simple">10.1162/089976602320264015</ext-link></comment> <object-id pub-id-type="pmid">12184844</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004490.ref092">
<label>92</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Chance</surname> <given-names>FS</given-names></name>, <name name-style="western"><surname>Fourcaud</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name> (<year>2001</year>) <article-title>Effects of synaptic noise and filtering on the frequency response of spiking neurons</article-title>. <source>Phys Rev Lett</source> <volume>86</volume>: <fpage>2186</fpage>–<lpage>2189</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.86.2186" xlink:type="simple">10.1103/PhysRevLett.86.2186</ext-link></comment> <object-id pub-id-type="pmid">11289886</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>