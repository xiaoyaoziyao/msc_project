<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0204394</article-id>
<article-id pub-id-type="publisher-id">PONE-D-17-27675</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Survey research</subject><subj-group><subject>Questionnaires</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Survey research</subject><subj-group><subject>Surveys</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Computer networks</subject><subj-group><subject>Internet</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Clustering algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Clustering algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Age groups</subject><subj-group><subject>Young adults</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Survey research</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Electromagnetic radiation</subject><subj-group><subject>Light</subject><subj-group><subject>Ultraviolet radiation</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A hierarchical clustering approach to identify repeated enrollments in web survey data</article-title>
<alt-title alt-title-type="running-head">A hierarchical clustering approach to identify repeated enrollments in web survey data</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0445-8978</contrib-id>
<name name-style="western">
<surname>Handorf</surname>
<given-names>Elizabeth A.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Heckman</surname>
<given-names>Carolyn J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Darlow</surname>
<given-names>Susan</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Slifker</surname>
<given-names>Michael</given-names>
</name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ritterband</surname>
<given-names>Lee</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Biostatistics and Bioinformatics Facility, Fox Chase Cancer Center, Philadelphia, PA, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Medical Oncology, Rutgers Cancer Institute of New Jersey, New Brunswick, New Jersey, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>National Comprehensive Cancer Network, Fort Washington, PA, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Psychiatry and Neurobehavioral Sciences, University of Virginia, Charlottesville, VA, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Dinov</surname>
<given-names>Ivo D.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Michigan, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>LR is an equity holder of BeHealth Solutions, Inc, which developed the data management system and helped develop the intervention described in this paper. LR’s conflict of interest (COI) is being managed by a COI committee at the University of Virginia, in accordance with their respective conflict of interest policies. This does not alter our adherence to PLOS ONE policies on sharing data and materials.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">Elizabeth.Handorf@fccc.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>25</day>
<month>9</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<year>2018</year>
</pub-date>
<volume>13</volume>
<issue>9</issue>
<elocation-id>e0204394</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>9</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Handorf et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0204394"/>
<abstract>
<sec id="sec001">
<title>Introduction</title>
<p>Online surveys are a valuable tool for social science research, but the perceived anonymity provided by online administration may lead to problematic behaviors from study participants. Particularly, if a study offers incentives, some participants may attempt to enroll multiple times. We propose a method to identify clusters of non-independent enrollments in a web-based study, motivated by an analysis of survey data which tests the effectiveness of an online skin-cancer risk reduction program.</p>
</sec>
<sec id="sec002">
<title>Methods</title>
<p>To identify groups of enrollments, we used a hierarchical clustering algorithm based on the Euclidean distance matrix formed by participant responses to a series of Likert-type eligibility questions. We then systematically identified clusters that are unusual in terms of both size and similarity, by repeatedly simulating datasets from the empirical distribution of responses under the assumption of independent enrollments. By performing the clustering algorithm on the simulated datasets, we determined the distribution of cluster size and similarity under independence, which is then used to identify groups of outliers in the observed data. Next, we assessed 12 other quality indicators, including previously proposed and study-specific measures. We summarized the quality measures by cluster membership, and compared the cluster groupings to those found when using the quality indicators with latent class modeling.</p>
</sec>
<sec id="sec003">
<title>Results and conclusions</title>
<p>When we excluded the clustered enrollments and/or lower-quality latent classes from the analysis of study outcomes, the estimates of the intervention effect were larger. This demonstrates how including repeat or low quality participants can introduce bias into a web-based study. As much as is possible, web-based surveys should be designed to verify participant quality. Our method can be used to verify survey quality and identify problematic groups of enrollments when necessary.</p>
</sec>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01CA154928</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Heckman</surname>
<given-names>Carolyn J.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>T32CA009035</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Darlow</surname>
<given-names>Susan</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>P30CA006927</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0445-8978</contrib-id>
<name name-style="western">
<surname>Handorf</surname>
<given-names>Elizabeth A.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was funded by R01CA154928 (CH); T32CA009035 (SD); and P30CA006927 (Cancer Center Support Grant). The study sponsor had no role in study design; collection, analysis, or interpretation of data; writing the report; or the decision to submit the report for publication.</funding-statement>
</funding-group>
<counts>
<fig-count count="2"/>
<table-count count="3"/>
<page-count count="14"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec004" sec-type="intro">
<title>1. Introduction</title>
<p>Public health researchers are increasingly using internet-based surveys and interventions in their research. There are many benefits to web-based interventions, including the ability to personalize, to more easily create disseminable public health interventions, and to economically reach a large number of research participants. Additionally, with approximately 99% of U.S. young adults using the internet [<xref ref-type="bibr" rid="pone.0204394.ref001">1</xref>] and the evidence for the efficacy of internet interventions [<xref ref-type="bibr" rid="pone.0204394.ref002">2</xref>], the internet is an appropriate modality with which to reach young adults and to test public health interventions targeted at this population.</p>
<p>An issue unique to web-based surveys, particularly those with monetary incentives, is that participants may enroll multiple times to obtain the incentives. This phenomenon has been previously observed in internet survey research, such as a case study by Konstan et al [<xref ref-type="bibr" rid="pone.0204394.ref003">3</xref>], where through a combination of email addresses, payment records, IP addresses, and other quality indicators, the study team determined that 11% of their sample consisted of repeat responses, including 1 subject who enrolled 65 times.</p>
<p>Generally, any anonymous survey-based research (web-based or otherwise) may be subject to data quality issues beyond typical errors in self-reported data. Participants may not thoughtfully complete the questionnaire, a phenomenon termed “careless responding.” Meade and Craig developed a method to evaluate survey responses to identify participants with low-quality survey data [<xref ref-type="bibr" rid="pone.0204394.ref004">4</xref>]. They suggest quantifying response consistency, the presence of outliers, and response time, and using a latent class model to determine which subjects may have responded carelessly.</p>
<p>In this paper, we develop methods to systematically identify non-independent enrollments (i.e. a single individual enrolled in a study multiple times) when there is no way to confirm subjects’ identities. We provide a novel simulation-based method for identifying such participants via hierarchal clustering methods, and demonstrate how it can be used in the context of web-based surveys. We then compare our findings with other methods used to measure survey quality, and demonstrate how inclusion of clustered participants may change study findings.</p>
</sec>
<sec id="sec005">
<title>2. Identification of similar response patterns</title>
<sec id="sec006">
<title>2.1 Motivating study</title>
<p>This work was motivated by enrollment quality issues that arose during the conduct of a web-based interventional study, designed to change participant behaviors associated with risk of developing skin cancer. In this study, named UV4.me, the team developed the first web-based intervention to modify skin cancer risk and protective behaviors targeted specifically for young adults, which was informed by the Integrative Model for Behavioral Prediction (IM) [<xref ref-type="bibr" rid="pone.0204394.ref005">5</xref>]. The UV4.me intervention was targeted to young adults, personally tailored, and included interactive, multimedia, and goal-setting components. Study methods and interventions have been described previously [<xref ref-type="bibr" rid="pone.0204394.ref006">6</xref>]. Briefly, participants were recruited nationally online by a consumer research company, using their US consumer opinion panel and partnerships with other panels and online communities. Panelists were exposed to brief web banner ads about the study from which they could click to link to the study website. Once at the study website, interested candidates were asked to complete the Brief Skin Cancer Risk Assessment Tool (BRAT) [<xref ref-type="bibr" rid="pone.0204394.ref007">7</xref>], which was scored automatically. Eligible participants were 18–25 years old, had never had skin cancer, and were at moderate to high risk of developing skin cancer based on the BRAT [<xref ref-type="bibr" rid="pone.0204394.ref007">7</xref>]. In a national randomized controlled trial [<xref ref-type="bibr" rid="pone.0204394.ref006">6</xref>], the UV4.me intervention was found to be efficacious in significantly decreasing ultraviolet radiation exposure and increasing skin protection behaviors among young adults at risk of skin cancer. The effects of the intervention have been previously described in detail elsewhere [<xref ref-type="bibr" rid="pone.0204394.ref006">6</xref>, <xref ref-type="bibr" rid="pone.0204394.ref008">8</xref>]. This project was approved by Fox Chase Cancer Center's IRB, and electronic informed consent was obtained from all research participants.</p>
<p>During enrollment of subjects into the UV4.me study, the research team detected individuals who attempted to enroll in the study multiple times. Some re-enrollments were clear and could be manually removed, as when multiple enrollments used the same name or email address. Later in the study, based on email interactions with study participants, the team noticed a series of suspicious enrollments. These participants appeared to be coming from outside of the US, which would make them ineligible, but this could not be objectively confirmed. The participants used different email addresses and names for the enrollments; however, their responses to the screener questionnaire were unusually consistent. The team was unable to find a single unique identifier that could separate these problematic enrollments from valid participants; IP addresses, for example, were not available. We therefore sought to develop an objective criteria based on multiple factors by which we could exclude repeat enrollments. In our main analysis of intervention efficacy, we used clustering and latent class models in attempt to remove the most problematic enrollments [<xref ref-type="bibr" rid="pone.0204394.ref006">6</xref>]. In this work, we further develop these methods, and propose a novel simulation-based approach to objectively detect unusual clusters of enrollments.</p>
<p>Every subject interested in participating in the UV4.me study filled out the Eligibility Screener (ES) to determine whether they meet the study inclusion criteria. A key portion of the ES was the BRAT, a validated instrument which identifies subjects at high risk of developing skin cancer [<xref ref-type="bibr" rid="pone.0204394.ref007">7</xref>]. The eight Likert-type items on this scale are weighted according to the amount of risk that each characteristic conveys, and are summed to give a single aggregate risk score. In the UV4.me study, participants were eligible if they were at moderate to high risk of skin cancer with a total risk score of 27 or more (out of a possible 89). The items, their scoring, and the proportion of participants in the final eligible sample are given in supplementary <xref ref-type="supplementary-material" rid="pone.0204394.s001">S1 Table</xref>. Due to the large number of potential response patterns for the BRAT questionnaire, it provided an opportunity to identify unusually similar enrollments. In addition to the BRAT items, we also considered self-reported age. Further, as problematic subjects appeared to be clustered in time (Supplementary <xref ref-type="supplementary-material" rid="pone.0204394.s004">S1 Fig</xref>), we also considered order of enrollment. Other items in the ES, such as prior skin cancer diagnosis and state of residence in childhood were excluded due to sparseness or lack of variability.</p>
</sec>
<sec id="sec007" sec-type="materials|methods">
<title>2.2 Methods</title>
<sec id="sec008">
<title>2.2.1 Hierarchical clustering</title>
<p>We identified groups of similar enrollments from the 1,234 participants who met all study inclusion criteria by applying hierarchical clustering [<xref ref-type="bibr" rid="pone.0204394.ref009">9</xref>] to their responses on the ES. Hierarchical clustering is a common method for clustering high-dimensional data, which uses an agglomerative (“bottom-up”) approach based on a dissimilarity (e.g. distance) measure between each pair of observations. The algorithm begins with each observation in a different cluster and proceeds iteratively, joining the two most “similar” clusters at each step. Similarity can be defined in several ways, one common choice being complete linkage. Under this definition, the maximum dissimilarity between each pair of observations in the two candidate clusters is calculated. Therefore, the clusters which are joined minimize the maximum within-cluster distance. This value then becomes the “height” at which the two clusters merged, which can then be displayed using a dendrogram (see <xref ref-type="fig" rid="pone.0204394.g001">Fig 1</xref>), with height represented on the y-axis. Cluster membership can be defined by choosing a height threshold; any observations that are joined at a smaller value than the chosen height are considered to be in the same cluster. The choice of height therefore defines the number and membership of clusters.</p>
<fig id="pone.0204394.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0204394.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Dendrogram representing clustering of screener responses in participants who went on to complete the baseline questionnaire.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.g001" xlink:type="simple"/>
</fig>
<p>For the purposes of defining dissimilarity, we treated the ordinal Likert-type items as continuous. We constructed a Euclidean distance matrix using the eight fields in the ES, age, and enrollment order after standardizing the items to their corresponding standard deviation. This distance matrix formed the dissimilarity measures used by the hierarchical clustering algorithm. Formally, the distance between any two participants, <italic>i</italic> and <italic>j</italic>, was defined as
<disp-formula id="pone.0204394.e001">
<alternatives>
<graphic id="pone.0204394.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msqrt><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>x</italic><sub><italic>ik</italic></sub> and <italic>x</italic><sub><italic>jk</italic></sub> are the value of the <italic>k</italic><sup>th</sup> field observed for participants <italic>i</italic> and <italic>j</italic>, respectively, and <italic>σ</italic><sub><italic>k</italic></sub> is the standard deviation of the <italic>k</italic><sup>th</sup> field. We applied the hierarchical clustering algorithm with complete linkage to the resulting distance matrix <bold><italic>D</italic></bold>, consisting of all pairs of elements <italic>d</italic><sub><italic>ij</italic></sub>.</p>
<p>Cluster size was defined by the number of participants in a cluster at a given height. We measured within-cluster similarity using the average silhouette (sil) width. Sil width is a measure of similarity of an observation to others within its identified cluster, compared to those in the closest other cluster. For a given observation <italic>i</italic>, sil width is defined as
<disp-formula id="pone.0204394.e002">
<alternatives>
<graphic id="pone.0204394.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>[</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>a(i)</italic> is the average distance between observation <italic>i</italic> and the other observations in its own cluster, and <italic>b(i)</italic> is the average distance between observation <italic>i</italic> and all other observations in the closest other cluster [<xref ref-type="bibr" rid="pone.0204394.ref010">10</xref>]. Average Sil Width (<italic>ASW</italic>) of cluster <italic>k</italic> is the average of <italic>s(i)</italic> for all observations within that cluster. Larger values of <italic>ASW</italic> indicate better fit, and negative values may indicate that that the number of clusters (here defined by the specified height) is too small or too large.</p>
</sec>
<sec id="sec009">
<title>2.2.2 Simulating cluster characteristics under independence</title>
<p>Testing for evidence of clustering is challenging, and is often done empirically. Suzuki and Shimodaira [<xref ref-type="bibr" rid="pone.0204394.ref011">11</xref>] proposed a bootstrap based procedure for testing stability of clusters in genetic analyses, for example, in DNA microarrays. Unlike a typical bootstrap procedure, instead of resampling the observations (participants) the variables which are used to define distances are resampled instead, and the clustering algorithm is re-calculated with the updated distance matrix. In typical DNA experiments the number of variables is large, but in our application we only have 10 variables on which the clusters are defined, so we cannot reliably use this type of bootstrap resampling.</p>
<p>We therefore propose a simulation based approach, where we generate independent observations based on the empirical distribution of the variables of interest. The hierarchical clustering algorithm is then applied to the simulated dataset, and we summarize resulting clusters using relevant measures of size and similarity. This process is then repeated many times. As the simulated cluster is based on independent data, we can determine the distribution of its characteristics when no clustering is present, and determine if the observed dataset deviates substantially from the expected distribution under independence. Our approach is comparable to that described by Hennig et al. [<xref ref-type="bibr" rid="pone.0204394.ref012">12</xref>] for k-medoid clustering, a “top-down” clustering method where all observations are fit into a number of pre-specified clusters, <italic>k</italic>. However, their goal was to identify stable clusters encompassing the whole dataset, while our objective was to identify large, unusually similar groups of responses. Therefore, we considered both cluster size and within-cluster similarity, as quantified by <italic>ASW</italic>. Key to this approach is the simulation of the “null” distribution, from non-clustered, independent observations (Steps 2–3). For Likert-type items, we recommend using the GenOrd R package, or another comparable tool. This program allows the user to specify the observed marginal proportions of each ordinal category, and the observed correlation matrix [<xref ref-type="bibr" rid="pone.0204394.ref013">13</xref>]. It then simulates data from the multivariate normal distribution, and these continuous values are categorized based on quantiles of the normal distribution such that the simulated samples have the same proportions as the observed data. This program also applies a correction to the correlation matrix used to generate the multivariate normal data, so that when the simulated values are categorized as ordinal, the correlation matrix reflects that of the original ordinal data.</p>
<p>Because of the restriction imposed by requiring total score of ≥27 points, we could not directly use the marginal response rates to simulate observations based on the final sample of eligible individuals, as by chance, some simulated responses would not have been eligible for inclusion. Instead, we drew from the full distribution of all responses to the ES from all individuals in the acceptable age range without a personal history of cancer, and then applied the score restriction. Some participants who met the score restriction did not go on to complete the Baseline Questionnaire (BQ). We modeled the probability of completing the BQ in this population based on age and answers to the BRAT questionnaire using logistic regression. For each simulated sample, we estimated the probability that they would complete the BQ, and then used this estimate to randomly assign them as completing/not completing the BQ. We used rejection sampling (based on simulated scores and BQ completion indicators) until we obtained a sample of 1,234 simulated observations with valid scores. Enrollment order was then permuted, assuming that enrollment characteristics would be stable over time under independence. This procedure was repeated 1,000 times, and performed the hierarchical clustering algorithm on each of the simulated datasets.</p>
<p>To identify repeat enrollments, we wished to find clusters with unusual within-cluster similarity and large size. Small clusters tend to have wide variability in similarity measures (ranging from low to high similarity), while large clusters tend to have smaller within-cluster similarity. We therefore proposed the following measure Size and Sil Width (<italic>SSW</italic>) for each cluster <italic>c</italic> (out of all clusters <italic>C</italic>).
<disp-formula id="pone.0204394.e003">
<alternatives>
<graphic id="pone.0204394.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>N</italic> is the number of samples in the cluster, and <italic>ASW</italic> is the average sil width. As these measures are on different scales, we standardize them by dividing by the maximum observed values for all clusters, so that both components are equally important. This measure is highest for large, similar clusters. We then calculate this statistic for the simulated samples as
<disp-formula id="pone.0204394.e004">
<alternatives>
<graphic id="pone.0204394.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>N*</italic> and <italic>ASW*</italic> are the sizes and average sil widths of the clustered samples. We normalize them to the maximum sizes and sil widths of the original samples to maintain the same scale. We then compare the <italic>SSWs</italic> for the original dataset to distribution of <inline-formula id="pone.0204394.e005"><alternatives><graphic id="pone.0204394.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, the maximum <italic>SSW</italic>s observed in each of the simulated samples.</p>
</sec>
<sec id="sec010">
<title>2.2.3 Summary of algorithm</title>
<p>Below, we summarize the steps used to identify unusual clusters. R code for implementation of this procedure is available in the supplementary materials (<xref ref-type="supplementary-material" rid="pone.0204394.s007">S1 Code</xref>).</p>
<list list-type="order">
<list-item><p>Perform hierarchical clustering on original dataset (<bold><italic>X)</italic></bold> where the columns are the <italic>K</italic> variables used to define clusters, and the rows are the <italic>N</italic> samples.
<list list-type="alpha-lower">
<list-item><p>Calculate the Euclidean distance matrix <italic>D</italic>, were the elements of <italic>D</italic> are defined by <inline-formula id="pone.0204394.e006"><alternatives><graphic id="pone.0204394.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula> (Euclidean distance between every pair of individuals).</p></list-item>
<list-item><p>Run a hierarchical clustering analysis on <italic>D</italic>.</p></list-item>
<list-item><p>Apply several height thresholds to partition the samples into clusters.</p></list-item>
<list-item><p>Choose a height threshold which results in good fit (e.g. as measured by <italic>ASW</italic>).</p></list-item>
</list></p></list-item>
<list-item><p>Let <italic>V</italic><sub><bold><italic>i</italic></bold></sub> be the ith variable (column) in <bold><italic>X</italic>.</bold> Estimate the multivariable distribution <inline-formula id="pone.0204394.e007"><alternatives><graphic id="pone.0204394.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> assuming independence between samples (the “null” distribution).</p></list-item>
<list-item><p>Draw <italic>N</italic> independent samples, such that <bold><italic>V*</italic></bold> i.i.d. <inline-formula id="pone.0204394.e008"><alternatives><graphic id="pone.0204394.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, to create a simulated dataset <bold><italic>X*</italic></bold>.</p></list-item>
<list-item><p>Repeat the simulation procedure (step 3) <italic>M</italic> times.</p></list-item>
<list-item><p>Apply the hierarchical clustering procedure to the <italic>M</italic> simulated datasets (<bold><italic>X*</italic></bold>).
<list list-type="alpha-lower">
<list-item><p>Repeat step 1a-b for each <bold><italic>X*</italic></bold>.</p></list-item>
<list-item><p>Using the height threshold chosen in 1d, partition the <italic>N</italic> rows into clusters.</p></list-item>
</list></p></list-item>
<list-item><p>Compare the observed clusters found in step 1 to the simulated clusters from step 5.
<list list-type="alpha-lower">
<list-item><p>Quantify size and within-cluster similarity (<italic>SSW</italic>) of each cluster <italic>c</italic> found in step 1 (based on <bold><italic>X</italic></bold>).</p></list-item>
<list-item><p>For each of the <italic>M</italic> simulated clusters, find <inline-formula id="pone.0204394.e009"><alternatives><graphic id="pone.0204394.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>.</p></list-item>
<list-item><p>For each cluster <italic>c</italic> from the observed data, calculate <inline-formula id="pone.0204394.e010"><alternatives><graphic id="pone.0204394.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, the proportion of the times the observed <italic>SSW</italic> is greater than the maximum <italic>SSW</italic>s from each of the <italic>M</italic> simulations.</p></list-item>
</list></p></list-item>
</list>
<p>Note that steps 2–4 are similar to those proposed by Hennig et al. [<xref ref-type="bibr" rid="pone.0204394.ref012">12</xref>] to assess the properties of k-medoid clustering using a simulated “null” distribution. Our method mainly differs in steps 1, 5, and 6, as we need to evaluate the properties of each observed cluster, not overall fit.</p>
</sec>
</sec>
<sec id="sec011" sec-type="results">
<title>2.3 Results</title>
<p>Applying the hierarchical clustering approach described in Section 2.2.1, we created a dendrogram to illustrate the structure of the study data (<xref ref-type="fig" rid="pone.0204394.g001">Fig 1</xref>). A figure showing the structure of Euclidean pairwise distances is available in the supplementary files (<xref ref-type="supplementary-material" rid="pone.0204394.s004">S1 Fig</xref>).</p>
<p>Visual inspection of the dendrogram shows that there are two clusters which seem to have a large degree of similarity compared to the remainder of the population. The clusters are unusual in that they have especially low dissimilarity and large size. As cluster definition depended on height, we explored several thresholds: 4.5, 5.0, and 5.5. Based on the observed <italic>ASWs</italic>, we chose a height of 4.5, as <italic>ASWs</italic> were more often negative for the larger heights. We did not explore smaller height thresholds as we wished to split the dataset into the fewest possible number of clusters. This resulted in a set of 80 clusters, ranging in size from 1 to 65 participants per cluster, with <italic>ASWs</italic> ranging from -0.042 to 0.441.</p>
<p>The distribution of <italic>N</italic> versus <italic>ASW</italic> and <italic>SSW</italic> from the original data and a single simulated dataset are shown in <xref ref-type="fig" rid="pone.0204394.g002">Fig 2A</xref>. Gray points are from the simulated dataset and black points are from the original dataset. We note that most of the clusters in the observed data have similar characteristics to those of the simulated clusters; however, this method detected two outlying clusters, consisting of 65 and 49 participants each. After calculating the maximum observed <italic>SSWs</italic> from 1,000 simulated datasets, we found that these clusters had <italic>SSWs</italic> greater than 100% and 99.6% of the simulated values of <inline-formula id="pone.0204394.e011"><alternatives><graphic id="pone.0204394.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, respectively. The cluster with the next largest <italic>SSW</italic> only had values greater than 88.0% of the simulated values. (See <xref ref-type="fig" rid="pone.0204394.g002">Fig 2B</xref>) Although this method does not give a true p-value, it provides substantial evidence that these clusters would be unlikely to occur by chance if the data were truly independently distributed.</p>
<fig id="pone.0204394.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0204394.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p>(A) shows the distribution of the observed cluster sizes and sil widths (black) compared to the distribution of size and sil widths from one simulated sample. (B) shows the distribution of the maximum <italic>SSWs</italic> from each of 1,000 simulations, compared to the top three observed <italic>SSWs</italic> in the true data. The two outliers of interest are represented by an X through a circle in both plots.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.g002" xlink:type="simple"/>
</fig>
<sec id="sec012">
<title>2.3.1 Verification of algorithm</title>
<p>Next, we evaluated our method of identifying non-independent enrollments in two ways. First, we re-ran the algorithm including participants who were previously dropped for known issues (N = 257), including one participant who re-enrolled 53 times (detected by similar nonsense registration names, e.g. “asdf”). The clustering method identified an additional cluster (with 91 total enrollments), including 44 of the 53 enrollments from the known repeater (83%).</p>
<p>Second, we generated synthetic datasets where we introduced a true cluster (with correlated observations), and used our method to see if this known cluster could be identified. By repeating this many times, we evaluated the method’s false positive and false negative rates under different data-generating mechanisms. Due to the computational complexity of this procedure, we explored a limited number of scenarios, and used 100 synthetic datasets per scenario. Most observations in each synthetic dataset were generated independently, using the method described in Section 2.2.2. We also generated a much smaller clustered sample where the correlation matrix (<bold><italic>∑</italic></bold>) consisted of a series of blocks. The blocks along the diagonal, <bold><italic>S</italic></bold>, defined the correlation of items within an individual. We then defined the off-diagonal blocks to be <italic>r</italic><bold><italic>S</italic></bold>, where 0 ≤ <italic>r</italic> ≤1, which induced a correlation between individuals. R code and a supporting datafile are available in Supplementary files S2 Code and <xref ref-type="supplementary-material" rid="pone.0204394.s010">S1 File</xref>.</p>
<p>In the synthetic datasets, we specified the number of samples, vector of means and correlation matrices to reflect approximately what was present in the true dataset. We varied <italic>r</italic> to determine how the algorithm performs under varying degrees of correlation. For our base case, we used <italic>r</italic> = 0.8, anticipating that the clustered samples would be highly correlated (i.e. a cluster of repeated enrollments from one individual). We specified that if <inline-formula id="pone.0204394.e012"><alternatives><graphic id="pone.0204394.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0.95</mml:mn></mml:math></alternatives></inline-formula>, a cluster was considered to be unusual. The mean number of non-clustered individuals was 1296 and the mean number of individuals in the cluster was 59. The algorithm identified clustering in 74% of the synthetic datasets. When clustering was detected, 88.4% of the clustered samples were identified as unusual by the simulation-based algorithm, leading to an overall sensitivity of 65.4%. Specificity was excellent, with only 0.5% of non-clustered samples falsely identified as belonging to an unusual cluster (specificity = 99.5%). When we reduced the correlation to r = 0.6, sensitivity was 59.7% and specificity was 99.5%. Finally, we tested whether we could improve sensitivity by lowering the value of <inline-formula id="pone.0204394.e013"><alternatives><graphic id="pone.0204394.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0204394.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> to 0.8; which resulted in increased sensitivity of 70.7% with only a small decrease in specificity (99.4%). In our application, we considered high specificity to be critical, as we wanted to limit the number of true enrollments excluded from the analysis. This motivated our use of the 0.95 threshold; however, these results indicate that lower thresholds could be considered to improve sensitivity.</p>
</sec>
</sec>
</sec>
<sec id="sec013">
<title>3. Comparison with survey quality measures</title>
<sec id="sec014" sec-type="materials|methods">
<title>3.1 Methods</title>
<p>Use of self-reported data is the standard in psychology and behavioral science. However, in addition to the known issues of using self-reported data such as participant memory and study demand characteristics [<xref ref-type="bibr" rid="pone.0204394.ref014">14</xref>], survey participants may not complete questionnaires thoughtfully and carefully, which has been described as “careless responding”. [<xref ref-type="bibr" rid="pone.0204394.ref004">4</xref>] Meade and Craig proposed several metrics which, in combination, can be used to identify careless respondents. For our study, we performed a similar type of analysis to that proposed by Meade and Craig, which we adapted based on measures available for our study. We identified 12 relevant quality measures, which are described in detail in the supplementary files (<xref ref-type="supplementary-material" rid="pone.0204394.s002">S2 Table</xref>). We adapted five relevant metrics proposed by Meade and Craig, including time to complete the survey, three measures of response consistency/similarity, and patterned responding (repeated identical responses on the same page). We also incorporated seven other indicators of potential problems that were collected by the study team during enrollment and follow-up, including discrepancies between self-reported characteristics (e.g. skin color or gender) at different parts of the questionnaires and non-US phone numbers. Note that the variables used in the clustering procedure above were from the Eligibility Screener (ES), while the quality measures relied on data from the Baseline Questionnaire (BQ), and other measures collected during the enrollment/study process. Therefore, the quality variables were measured separately from variables used to identify clustering.</p>
<p>We performed latent class modeling based on the quality variables to identify underlying groups. Continuous measures were categorized into deciles, as some of the measures were highly skewed, and for ease of fitting a latent class model with mixed variable types. We fit models with two to four classes, and selected the three class model as it minimized the Bayesian Information Criterion (BIC). We then determined predicted class membership for each observation [<xref ref-type="bibr" rid="pone.0204394.ref015">15</xref>]. We also tried including an indicator for membership in one of the clusters as an additional variable in the latent class model; however, these models had worse overall fit as measured by the BIC. See supplementary materials (S) for R code.</p>
</sec>
<sec id="sec015" sec-type="results">
<title>3.2 Results</title>
<p>The relationship between latent class membership and cluster membership is shown in <xref ref-type="table" rid="pone.0204394.t001">Table 1</xref>. Interestingly, individuals from the two clusters were mainly fit in two separate classes. As the final latent class model did not include an indicator for cluster membership, or depend on any of the variables from the ES, this provides further evidence that these groups of unusual registrations were non-independent. <xref ref-type="table" rid="pone.0204394.t002">Table 2</xref> describes the quality measures, separately by cluster membership and by latent class membership.</p>
<table-wrap id="pone.0204394.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0204394.t001</object-id>
<label>Table 1</label> <caption><title>Cluster membership vs. latent class membership.</title></caption>
<alternatives>
<graphic id="pone.0204394.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" rowspan="2">Cluster Membership</th>
<th align="center" colspan="3">Latent Class Membership</th>
<th align="left"> </th>
</tr>
<tr>
<th align="right">Class 1</th>
<th align="right">Class 2</th>
<th align="right">Class 3</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Other<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
<td align="right">610</td>
<td align="right">406</td>
<td align="right">104</td>
<td align="right">1120</td>
</tr>
<tr>
<td align="left">Cluster #1</td>
<td align="right">7</td>
<td align="right">55</td>
<td align="right">3</td>
<td align="right">65</td>
</tr>
<tr>
<td align="left">Cluster #2</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">43</td>
<td align="right">49</td>
</tr>
<tr>
<td align="left">Total</td>
<td align="right">619</td>
<td align="right">465</td>
<td align="right">150</td>
<td align="right">1234</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>*“Other” denotes membership in one of the clusters not identified as usually large/similar</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pone.0204394.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0204394.t002</object-id>
<label>Table 2</label> <caption><title>Quality variables by cluster membership and predicted latent class.</title></caption>
<alternatives>
<graphic id="pone.0204394.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2">Quality variables</th>
<th align="center" rowspan="2" style="border-right:thick">Full sample</th>
<th align="center" colspan="3" style="border-right:thick">Cluster Membership</th>
<th align="center" colspan="3">Latent Class Membership</th>
</tr>
<tr>
<th align="center">Other<xref ref-type="table-fn" rid="t002fn002">*</xref></th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">1. Minutes to complete questionnaire (median)</td>
<td align="right" style="border-right:thick">21</td>
<td align="right">21</td>
<td align="right" style="background-color:#D9D9D9">14</td>
<td align="right" style="background-color:#D9D9D9;border-right:thick">935</td>
<td align="right">20</td>
<td align="right" style="background-color:#D9D9D9">15</td>
<td align="right" style="background-color:#D9D9D9">935</td>
</tr>
<tr>
<td align="left">2. Correlation of synonyms (mean)<break/><italic>within-person correlation of items with strongest overall correlation</italic></td>
<td align="right" style="border-right:thick">0.4</td>
<td align="right">0.39</td>
<td align="right" style="background-color:#D9D9D9">0.58</td>
<td align="right" style="background-color:#D9D9D9;border-right:thick">0.33</td>
<td align="right">0.28</td>
<td align="right" style="background-color:#D9D9D9">0.59</td>
<td align="right" style="background-color:#D9D9D9">0.33</td>
</tr>
<tr>
<td align="left">3. Even-odd item correlation (mean)<break/><italic>Correlation of even/odd items on unidimensional scales</italic></td>
<td align="right" style="border-right:thick">0.62</td>
<td align="right">0.61</td>
<td align="right" style="background-color:#D9D9D9">0.74</td>
<td align="right" style="border-right:thick">0.66</td>
<td align="right">0.60</td>
<td align="right">0.64</td>
<td align="right">0.62</td>
</tr>
<tr>
<td align="left">4. Distance from average (mean)<break/><italic>Euclidean distance between participant’s responses and population average responses</italic></td>
<td align="right" style="border-right:thick">15.64</td>
<td align="right">15.82</td>
<td align="right" style="background-color:#D9D9D9">12.85</td>
<td align="right" style="border-right:thick">15.33</td>
<td align="right">17.40</td>
<td align="right" style="background-color:#D9D9D9">13.45</td>
<td align="right">15.18</td>
</tr>
<tr>
<td align="left">5. Runs of identical responses (mean)<break/><italic>Average over pages with many items</italic></td>
<td align="right" style="border-right:thick">0.43</td>
<td align="right">0.44</td>
<td align="right">0.47</td>
<td align="right" style="background-color:#D9D9D9;border-right:thick">0.27</td>
<td align="right">0.43</td>
<td align="right">0.49</td>
<td align="right" style="background-color:#D9D9D9">0.27</td>
</tr>
<tr>
<td align="left">6. Inconsistent state/climate selection</td>
<td align="right" style="border-right:thick">15.0%</td>
<td align="right">12.9%</td>
<td align="right">16.9%</td>
<td align="right" style="background-color:#D9D9D9;border-right:thick">61.2%</td>
<td align="right">6.8%</td>
<td align="right">13.8%</td>
<td align="right" style="background-color:#D9D9D9">52.7%</td>
</tr>
<tr>
<td align="left">7. Non-US phone</td>
<td align="right" style="border-right:thick">16.0%</td>
<td align="right">15.3%</td>
<td align="right">13.9%</td>
<td align="right" style="background-color:#D9D9D9;border-right:thick">36.7%</td>
<td align="right">13.1%</td>
<td align="right">8.4%</td>
<td align="right" style="background-color:#D9D9D9">52.0%</td>
</tr>
<tr>
<td align="left">8. Wrong phone number</td>
<td align="right" style="border-right:thick">13.0%</td>
<td align="right">13.8%</td>
<td align="right">9.2%</td>
<td align="right" style="border-right:thick">2.0%</td>
<td align="right">8.9%</td>
<td align="right" style="background-color:#D9D9D9">22.4%</td>
<td align="right">1.3%</td>
</tr>
<tr>
<td align="left">9. Obviously fake name</td>
<td align="right" style="border-right:thick">6.8%</td>
<td align="right">6.8%</td>
<td align="right" style="background-color:#D9D9D9">12.3%</td>
<td align="right" style="border-right:thick">0.0%</td>
<td align="right">0.5%</td>
<td align="right" style="background-color:#D9D9D9">16.3%</td>
<td align="right">3.3%</td>
</tr>
<tr>
<td align="left">10. Nonsensical feedback<break/><italic>e</italic>.<italic>g</italic>. <italic>“dsadasdasd”</italic></td>
<td align="right" style="border-right:thick">2.8%</td>
<td align="right">2.0%</td>
<td align="right" style="background-color:#D9D9D9">20.0%</td>
<td align="right" style="border-right:thick">0.0%</td>
<td align="right">0.3%</td>
<td align="right" style="background-color:#D9D9D9">7.1%</td>
<td align="right">0.0%</td>
</tr>
<tr>
<td align="left">11. Discrepancies within questionnaire</td>
<td align="right" style="border-right:thick">4.3%</td>
<td align="right">3.8%</td>
<td align="right" style="background-color:#D9D9D9">16.9%</td>
<td align="right" style="border-right:thick">0.0%</td>
<td align="right">2.3%</td>
<td align="right" style="background-color:#D9D9D9">7.7%</td>
<td align="right">2.0%</td>
</tr>
<tr>
<td align="left">12. Other</td>
<td align="right" style="border-right:thick">9.3%</td>
<td align="right">9.7%</td>
<td align="right">6.2%</td>
<td align="right" style="border-right:thick">4.1%</td>
<td align="right">7.4%</td>
<td align="right" style="background-color:#D9D9D9">12.5%</td>
<td align="right">7.3%</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Note: Shading emphasizes unusual behavior patterns as measured by the quality indicators</p></fn>
<fn id="t002fn002"><p>*“Other” denotes membership in one of the clusters not identified as usually large/similar</p></fn>
</table-wrap-foot>
</table-wrap>
<p>From the observed values of the quality measures by cluster membership, we see that cluster 1 exhibits higher than average similarity (as quantified by items 2–4), with high correlation of synonyms (items with highest correlation across the whole sample), high correlation of even/odd numbered items in unidimensional scales, and overall responses very close to the mean response (as measured by Euclidean distance). They also completed the questionnaire in shorter times, had high rates of giving fake names, providing nonsensical feedback, and giving inconsistent answers about their characteristics (e.g. skin color or gender). Members of cluster 2 had different patterns of behavior. Their median completion time was very high (indicating that they left their sessions open for a long time before submitting), and their responses had low correlation of synonyms, short runs of identical responses, high rates of inconsistencies between state and climate region of the US, and high rates of giving a non-US phone number.</p>
<p>There was substantial overlap between class and cluster membership, and similarities in overall patterns of behavior. The majority of subjects in cluster 1 (55/65, or 85%) were grouped in latent class 2, although they made up only a small proportion of this class (with 465 total subjects). Likewise, the majority of subjects in cluster 2 were fitted into latent class 3 (43/49, or 88%). Cluster 2 made up a larger proportion of latent class 3, although they were still a minority of the total cluster membership (142 total subjects). It is interesting to see that many subjects who were not identified as members of one of the clusters had similar behavior patterns as the clustered subjects, as shown by the quality indicators in <xref ref-type="table" rid="pone.0204394.t002">Table 2</xref>.</p>
</sec>
</sec>
<sec id="sec016">
<title>4. Implications for study findings</title>
<p>The goal of the UV4.me intervention was to increase beneficial behaviors (skin protection) and decrease detrimental behaviors (ultraviolet radiation [UV] exposure) related to skin cancer. As described in prior work [<xref ref-type="bibr" rid="pone.0204394.ref006">6</xref>], we used linear regression models to identify the effect of the intervention versus the control condition (assessment only) at the time of the final questionnaire (12-weeks post enrollment). We accounted for within-subject correlation across the measurement times using robust sandwich variance estimates with Generalized Estimating Equations (GEE). The linear regression model included main effects for treatment and time (both categorical), and interactions between treatment and time. The model used an auto-regressive working correlation structure with clusters defined by patients [<xref ref-type="bibr" rid="pone.0204394.ref016">16</xref>]. See supplementary file <xref ref-type="supplementary-material" rid="pone.0204394.s009">S3 Code</xref> for R code to run these models.</p>
<p><xref ref-type="table" rid="pone.0204394.t003">Table 3</xref> shows the results in the full sample (N = 1,234), in the participants who were not members of one of the unusual clusters (N = 1,120), and in participants with predicted membership in the best quality latent class (Class 1, N = 622).</p>
<table-wrap id="pone.0204394.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0204394.t003</object-id>
<label>Table 3</label> <caption><title>Intervention effects on primary outcomes at 12 weeks, by cluster and latent class membership.</title></caption>
<alternatives>
<graphic id="pone.0204394.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">UV exposure outcome</th>
<th align="left">Effect</th>
<th align="left">SE</th>
<th align="center" colspan="2">95% CI</th>
<th align="left">P-val</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">    All participants</td>
<td align="right">-0.19</td>
<td align="right">0.054</td>
<td align="right">-0.30</td>
<td align="right">-0.09</td>
<td align="right">0.0003</td>
</tr>
<tr>
<td align="left">    Only non-clustered participants</td>
<td align="right">-0.24</td>
<td align="right">0.058</td>
<td align="right">-0.36</td>
<td align="right">-0.13</td>
<td align="right">&lt;0.0001</td>
</tr>
<tr>
<td align="left">    Only members of latent class 1</td>
<td align="right">-0.31</td>
<td align="right">0.081</td>
<td align="right">-0.47</td>
<td align="right">-0.15</td>
<td align="right">0.0001</td>
</tr>
<tr>
<td align="left"><bold>Skin protection outcome</bold></td>
<td align="left"><bold>Effect</bold></td>
<td align="left"><bold>SE</bold></td>
<td align="center" colspan="2"><bold>95% CI</bold></td>
<td align="left"><bold>P-val</bold></td>
</tr>
<tr>
<td align="left">    All participants</td>
<td align="right">0.31</td>
<td align="right">0.081</td>
<td align="right">0.15</td>
<td align="right">0.47</td>
<td align="right">0.0001</td>
</tr>
<tr>
<td align="left">    Only non-clustered participants</td>
<td align="right">0.32</td>
<td align="right">0.085</td>
<td align="right">0.16</td>
<td align="right">0.49</td>
<td align="right">0.0001</td>
</tr>
<tr>
<td align="left">    Only members of latent class 1</td>
<td align="right">0.58</td>
<td align="right">0.116</td>
<td align="right">0.35</td>
<td align="right">0.81</td>
<td align="right">&lt;0.0001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Although the intervention had a statistically significant effect regardless of the exclusions, the strength of the effect varied. The effect on exposure was substantively stronger when we removed the 114 participants clustered based on their screener responses, although the effect on protection outcomes was largely unchanged. For both outcomes, the intervention effect was much larger in the subgroup of participants in latent class 1 (best quality class); however, using only this subgroup excludes almost half of otherwise eligible participants, leading to concerns about generalizability.</p>
</sec>
<sec id="sec017" sec-type="conclusions">
<title>5. Conclusions</title>
<p>In this work, we proposed a method to identify groups of non-independent study participants, as might result from a single individual repeatedly enrolling in a web-based study. Unlike other procedures based on clustering algorithms [<xref ref-type="bibr" rid="pone.0204394.ref010">10</xref>, <xref ref-type="bibr" rid="pone.0204394.ref011">11</xref>], our method is designed to separate non-independent clusters from a mixed population of clustered and non-clustered data, and can be used when the number of variables which defines distance between pairs of observations is small.</p>
<p>One limitation of the procedure we used to identify clusters is that distribution of the test statistic generated via simulation assumed independence. This study recruited participants using web advertisements and participant referrals, which could lead to some dependence between subjects. Nevertheless, the clustering procedure successfully revealed unusual groups of participants with characteristics not easily explained by modest sources of within-group correlations. Another limitation of this method is that it can only identify large clusters of non-independent enrollments; however, it is most important to be able to detect large groups of repeated enrollments as these are most likely to cause substantial changes in study results. Finally, our method of cluster identification demonstrated excellent specificity; however, further development is needed to improve sensitivity. Future work should determine whether an optimal threshold for identifying unusual clusters can be found, or if modifying the specification of the hierarchical clustering algorithm (i.e. distance metrics and linkage) can improve sensitivity while maintaining specificity.</p>
<p>We compared our results to an adapted version of the method used to identify careless respondents proposed by Meade and Craig [<xref ref-type="bibr" rid="pone.0204394.ref004">4</xref>]. In our application, that approach lacked specificity needed to identify careless responders; however, we were not able to directly replicate all their measures. Although we followed the principles outlined in their method, we could not directly use some of the proposed measures, such as proposed “bogus items” (questions with answers which were obviously wrong). We instead included our own study specific quality measures. Further, due to the discrete nature of some of our measures, we fit latent class models instead of using latent profile analysis. This may have led to some of the differences between our results and those described in the example given in the original paper. Only about half of our samples were fit into the “best quality” cluster, whereas in Meade and Craig’s application, almost 90% of samples were in a single class.</p>
<p>We recommend that all web-based studies are designed with the ability to verify data quality in mind. Kramer and colleagues provide a set of recommendations to decrease enrollment of otherwise ineligible participants [<xref ref-type="bibr" rid="pone.0204394.ref017">17</xref>]. Ideally, sufficient information would be gathered to identify repeat enrollments automatically during the course of the study, not manually or in a post-hoc analysis. As much as is practical, researchers should use metrics that uniquely identify individuals. In the current study, we were not able to obtain information on IP addresses or other unique identifiers. However, such methods are not infallible, as a determined individual can use software to circumvent such identifiers (for example, by varying their IP address) [<xref ref-type="bibr" rid="pone.0204394.ref018">18</xref>]. Further, for socially sensitive topics, researchers may opt not to collect potentially identifying information for the privacy of participants and to minimize the risk of accidental disclosure of participant data. Our clustering method should be used in conjunction with other best practices to look for evidence of repeat enrollments, and potentially exclude problematic subjects.</p>
</sec>
<sec id="sec018">
<title>Supporting information</title>
<supplementary-material id="pone.0204394.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s001" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Table of screening questions from the BRAT scale.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s002" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s002" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Quality measures in detail.</title>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s003" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Data dictionary (for <xref ref-type="supplementary-material" rid="pone.0204394.s005">S1</xref> and <xref ref-type="supplementary-material" rid="pone.0204394.s006">S2</xref> Datasets).</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s004" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Euclidean distance matrix based on screener responses.</title>
<p>Red indicates small pairwise distances, blue indicates large distances.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s005" mimetype="text/csv" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s005" xlink:type="simple">
<label>S1 Dataset</label>
<caption>
<title>Data used in clustering analysis.</title>
<p>(CSV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s006" mimetype="text/csv" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s006" xlink:type="simple">
<label>S2 Dataset</label>
<caption>
<title>Data used in quality and outcome evaluation.</title>
<p>(CSV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s007" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s007" xlink:type="simple">
<label>S1 Code</label>
<caption>
<title>R code to implement analysis in section 2 (cluster identification).</title>
<p>(R)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s008" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s008" xlink:type="simple">
<label>S2 Code</label>
<caption>
<title>R code to implement sensitivity and specificity analysis in section 2.3.1.</title>
<p>(R)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s009" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s009" xlink:type="simple">
<label>S3 Code</label>
<caption>
<title>R code to implement analysis in sections 3–4 (response quality, effect on outcomes).</title>
<p>(R)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0204394.s010" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0204394.s010" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>Supporting RData file for <xref ref-type="supplementary-material" rid="pone.0204394.s008">S2 Code</xref>.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Teja Munshi for her assistance with data management.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0204394.ref001"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Pew Research Internet Project, Health fact sheet 2017 [cited 2017 April 24]. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pewinternet.org/fact-sheet/internet-broadband/" xlink:type="simple">http://www.pewinternet.org/fact-sheet/internet-broadband/</ext-link>.</mixed-citation></ref>
<ref id="pone.0204394.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tate</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Finkelstein</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Khavjou</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Gustafson</surname> <given-names>A</given-names></name>. <article-title>Cost effectiveness of internet interventions: review and recommendations</article-title>. <source>Annals of Behavioral Medicine</source>. <year>2009</year>;<volume>38</volume>(<issue>1</issue>):<fpage>40</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s12160-009-9131-6" xlink:type="simple">10.1007/s12160-009-9131-6</ext-link></comment> <object-id pub-id-type="pmid">19834778</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Konstan</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Simon Rosser</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Stanton</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Edwards</surname> <given-names>WM</given-names></name>. <article-title>The story of subject naught: A cautionary but optimistic tale of Internet survey research</article-title>. <source>Journal of Computer‐Mediated Communication</source>. <year>2005</year>;<volume>10</volume>(<issue>2</issue>):00-.</mixed-citation></ref>
<ref id="pone.0204394.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meade</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Craig</surname> <given-names>SB</given-names></name>. <article-title>Identifying careless responses in survey data</article-title>. <source>Psychological methods</source>. <year>2012</year>;<volume>17</volume>(<issue>3</issue>):<fpage>437</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0028085" xlink:type="simple">10.1037/a0028085</ext-link></comment> <object-id pub-id-type="pmid">22506584</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fishbein</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hennessy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yzer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Douglas</surname> <given-names>J</given-names></name>. <article-title>Can we explain why some people do and some people do not act on their intentions?</article-title> <source>Psychology, health &amp; medicine</source>. <year>2003</year>;<volume>8</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="pone.0204394.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heckman</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Darlow</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Ritterband</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Handorf</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Manne</surname> <given-names>SL</given-names></name>. <article-title>Efficacy of an Intervention to Alter Skin Cancer Risk Behaviors in Young Adults</article-title>. <source>American journal of preventive medicine</source>. <year>2016</year>;<volume>51</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>11</lpage>. Epub 2016/01/27. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.amepre.2015.11.008" xlink:type="simple">10.1016/j.amepre.2015.11.008</ext-link></comment> <object-id pub-id-type="pmid">26810358</object-id>; PubMed Central PMCID: PMCPMC4914462.</mixed-citation></ref>
<ref id="pone.0204394.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glanz</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schoenfeld</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Weinstock</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Layi</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Kidd</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shigaki</surname> <given-names>DM</given-names></name>. <article-title>Development and reliability of a brief skin cancer risk assessment tool</article-title>. <source>Cancer detection and prevention</source>. <year>2003</year>;<volume>27</volume>(<issue>4</issue>):<fpage>311</fpage>–<lpage>5</lpage>. <object-id pub-id-type="pmid">12893080</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heckman</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Handorf</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Darlow</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Ritterband</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Manne</surname> <given-names>SL</given-names></name>. <article-title>An Online Skin Cancer Risk-Reduction Intervention for Young Adults: Mechanisms of Effects</article-title>. <source>Health psychology: official journal of the Division of Health Psychology, American Psychological Association</source>. <year>2016</year>. Epub 2016/11/08. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/hea0000420" xlink:type="simple">10.1037/hea0000420</ext-link></comment> <object-id pub-id-type="pmid">27819460</object-id>.</mixed-citation></ref>
<ref id="pone.0204394.ref009"><label>9</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>James</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Witten</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <source>An introduction to statistical learning</source>: <publisher-name>Springer</publisher-name>; <year>2013</year>.</mixed-citation></ref>
<ref id="pone.0204394.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sugar</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>James</surname> <given-names>GM</given-names></name>. <article-title>Finding the number of clusters in a dataset: An information-theoretic approach</article-title>. <source>Journal of the American Statistical Association</source>. <year>2003</year>;<volume>98</volume>(<issue>463</issue>):<fpage>750</fpage>–<lpage>63</lpage>.</mixed-citation></ref>
<ref id="pone.0204394.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Suzuki</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shimodaira</surname> <given-names>H</given-names></name>. <article-title>Pvclust: an R package for assessing the uncertainty in hierarchical clustering</article-title>. <source>Bioinformatics</source>. <year>2006</year>;<volume>22</volume>(<issue>12</issue>):<fpage>1540</fpage>–<lpage>2</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btl117" xlink:type="simple">10.1093/bioinformatics/btl117</ext-link></comment> <object-id pub-id-type="pmid">16595560</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hennig</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Liao</surname> <given-names>TF</given-names></name>. <article-title>How to find an appropriate clustering for mixed‐type variables with application to socio‐economic stratification</article-title>. <source>Journal of the Royal Statistical Society: Series C (Applied Statistics)</source>. <year>2013</year>;<volume>62</volume>(<issue>3</issue>):<fpage>309</fpage>–<lpage>69</lpage>.</mixed-citation></ref>
<ref id="pone.0204394.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrari</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Barbiero</surname> <given-names>A</given-names></name>. <article-title>Simulating ordinal data</article-title>. <source>Multivariate Behavioral Research</source>. <year>2012</year>;<volume>47</volume>(<issue>4</issue>):<fpage>566</fpage>–<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/00273171.2012.692630" xlink:type="simple">10.1080/00273171.2012.692630</ext-link></comment> <object-id pub-id-type="pmid">26777670</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newell</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Girgis</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sanson-Fisher</surname> <given-names>RW</given-names></name>, <name name-style="western"><surname>Savolainen</surname> <given-names>NJ</given-names></name>. <article-title>The accuracy of self-reported health behaviors and risk factors relating to cancer and cardiovascular disease in the general population: a critical review</article-title>. <source>American journal of preventive medicine</source>. <year>1999</year>;<volume>17</volume>(<issue>3</issue>):<fpage>211</fpage>–<lpage>29</lpage>. <object-id pub-id-type="pmid">10987638</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linzer</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Lewis</surname> <given-names>JB</given-names></name>. <article-title>poLCA: An R package for polytomous variable latent class analysis</article-title>. <source>Journal of Statistical Software</source>. <year>2011</year>;<volume>42</volume>(<issue>10</issue>):<fpage>1</fpage>–<lpage>29</lpage>.</mixed-citation></ref>
<ref id="pone.0204394.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liang</surname> <given-names>K-Y</given-names></name>, <name name-style="western"><surname>Zeger</surname> <given-names>SL</given-names></name>. <article-title>Longitudinal data analysis using generalized linear models</article-title>. <source>Biometrika</source>. <year>1986</year>;<volume>73</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>22</lpage>.</mixed-citation></ref>
<ref id="pone.0204394.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kramer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Coster</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Helmuth</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hermos</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rosenbloom</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Strategies to address participant misrepresentation for eligibility in Web‐based research</article-title>. <source>International journal of methods in psychiatric research</source>. <year>2014</year>;<volume>23</volume>(<issue>1</issue>):<fpage>120</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/mpr.1415" xlink:type="simple">10.1002/mpr.1415</ext-link></comment> <object-id pub-id-type="pmid">24431134</object-id></mixed-citation></ref>
<ref id="pone.0204394.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bowen</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Daniel</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Baird</surname> <given-names>GL</given-names></name>. <article-title>Identifying multiple submissions in Internet research: preserving data integrity</article-title>. <source>AIDS and Behavior</source>. <year>2008</year>;<volume>12</volume>(<issue>6</issue>):<fpage>964</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10461-007-9352-2" xlink:type="simple">10.1007/s10461-007-9352-2</ext-link></comment> <object-id pub-id-type="pmid">18240015</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>