<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-12-28631</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0080278</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories>
<title-group>
<article-title>Quantifying Reproducibility in Computational Biology: The Case of the Tuberculosis Drugome</article-title>
<alt-title alt-title-type="running-head">Measuring Reproducibility in Computational Biology</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Garijo</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kinnings</surname><given-names>Sarah</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Xie</surname><given-names>Li</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Xie</surname><given-names>Lei</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Zhang</surname><given-names>Yinliang</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bourne</surname><given-names>Philip E.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gil</surname><given-names>Yolanda</given-names></name><xref ref-type="aff" rid="aff6"><sup>6</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Ontology Engineering Group, Facultad de Informática, Universidad Politécnica de Madrid, Madrid, Spain</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Chemistry and Biochemistry, University of California San Diego, La Jolla, California, United States of America</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Skaggs School of Pharmacy and Pharmaceutical Sciences, University of California San Diego, La Jolla, California, United States of America</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Department of Computer Science, Hunter College, The City University of New York, New York, New York, United States of America</addr-line></aff>
<aff id="aff5"><label>5</label><addr-line>School of Life Sciences, University of Science and Technology of China, Hefei, Anhui, China</addr-line></aff>
<aff id="aff6"><label>6</label><addr-line>Information Sciences Institute and Department of Computer Science, University of Southern California, Los Angeles, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Ouzounis</surname><given-names>Christos A.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>The Centre for Research and Technology, Hellas, Greece</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">pbourne@ucsd.edu</email> (PEB); <email xlink:type="simple">gil@isi.edu</email> (YG)</corresp>
<fn fn-type="conflict"><p>The research presented here has been sponsored partly by Elsevier Labs. This does not alter the authors' adherence to all the PLOS ONE policies on sharing data and materials.</p></fn>
<fn fn-type="con"><p>Performed the experiments: DG. Analyzed the data: DG YG. Wrote the paper: DG YG PB. Designed and performed the TB-Drugome experiment: SK Li Xie Lei Xie PB. Tested the automated workflow and reported feedback: YZ. Contributed to the manuscript writting with feedback: SK Li Xie Lei Xie.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>27</day><month>11</month><year>2013</year></pub-date>
<volume>8</volume>
<issue>11</issue>
<elocation-id>e80278</elocation-id>
<history>
<date date-type="received"><day>18</day><month>9</month><year>2012</year></date>
<date date-type="accepted"><day>10</day><month>10</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Garijo et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/3.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>How easy is it to reproduce the results found in a typical computational biology paper? Either through experience or intuition the reader will already know that the answer is with difficulty or not at all. In this paper we attempt to quantify this difficulty by reproducing a previously published paper for different classes of users (ranging from users with little expertise to domain experts) and suggest ways in which the situation might be improved. Quantification is achieved by estimating the time required to reproduce each of the steps in the method described in the original paper and make them part of an explicit workflow that reproduces the original results. Reproducing the method took several months of effort, and required using new versions and new software that posed challenges to reconstructing and validating the results. The quantification leads to “reproducibility maps” that reveal that novice researchers would only be able to reproduce a few of the steps in the method, and that only expert researchers with advance knowledge of the domain would be able to reproduce the method in its entirety. The workflow itself is published as an online resource together with supporting software and data. The paper concludes with a brief discussion of the complexities of requiring reproducibility in terms of cost versus benefit, and a desiderata with our observations and guidelines for improving reproducibility. This has implications not only in reproducing the work of others from published papers, but reproducing work from one’s own laboratory.</p>
</abstract>
<funding-group><funding-statement>This research is sponsored by Elsevier Labs, the National Science Foundation with award number IIS-0948429, the Air Force Office of Scientific Research with award number FA9550-11-1-0104, internal funds from the University of Southern California's Information Sciences Institute and from the University of California, San Diego, and by a Formación de Profesorado Universitario grant from the Spanish Ministry of Science and Innovation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="11"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Computation is now an integral part of the biological sciences either applied as a technique or as a science in its own right - bioinformatics. As a technique, software becomes an instrument to analyze data and uncover new biological insights. By reading the published article describing these insights, another researcher hopes to understand what computations were carried out, replicate the software apparatus originally used and reproduce the experiment. This is rarely the case without significant effort, and sometimes impossible without asking the original authors. In short, reproducibility in computational biology is aspired to, but rarely achieved. This is unfortunate since the quantitative nature of the science makes reproducibility more obtainable than in cases where experiments are qualitative and hard to describe explicitly.</p>
<p>An intriguing possibility where potential quantification exists is to extend articles through the inclusion of scientific workflows that represent computations carried out to obtain the published results, thereby capturing data analysis methods explicitly <xref ref-type="bibr" rid="pone.0080278-Bourne1">[1]</xref>. This would make scientific results more reproducible because articles would have not only a textual description of the computational process described in the article but also a workflow that, as a computational artifact, could be analyzed and re-run automatically. Consequently, workflows can make scientists more productive because they capture complex methods in an easy to use accessible manner <xref ref-type="bibr" rid="pone.0080278-Gil1">[2]</xref>–<xref ref-type="bibr" rid="pone.0080278-Taylor1">[3]</xref>.</p>
<p>The goal of this article is, by applying a workflow to an existing computational analysis <xref ref-type="bibr" rid="pone.0080278-Kinnings1">[4]</xref>, to describe and quantify the effort involved in reproducing the published computational method and to articulate guidelines for authors that would facilitate reproducibility and reuse. Quantification is achieved by assigning a reproducibility score that exposes the cost of omitting important information from the published paper that then caused problems in creating the workflow. Beyond this no case is made for the value of workflows which is well described elsewhere <xref ref-type="bibr" rid="pone.0080278-Taylor1">[3]</xref>.</p>
<sec id="s1a">
<title>Related Work</title>
<p>As stated, scientific articles describe computational methods informally, as the computational aspects of the method may not be the main focus of the article. We acknowledge that in computer science the method may be described formally and any limitations, it could be argued, reside with the editors and reviewers. However, in the domain of computational biology, which is the focus here, we believe methods to be, for the most part, described informally as formalizations are not typically favored by authors or enforced by reviewers.</p>
<p>Computational methods are often complex and hard to explain in textual form with the given space limitations of many articles. As a result, reproducing methods often requires significant effort from others to reproduce and reuse. Studies have shown that reproducibility is not achievable from the article itself, even when datasets are published <xref ref-type="bibr" rid="pone.0080278-Bell1">[5]</xref>–<xref ref-type="bibr" rid="pone.0080278-Hothorn1">[7]</xref>. The reproducibility process can be so costly that it has been referred to as “forensic” research <xref ref-type="bibr" rid="pone.0080278-Baggerly1">[8]</xref>. Lack of reproducibility also affects the review process and as a result retractions of publications occur more often than is desirable <xref ref-type="bibr" rid="pone.0080278-Decullier1">[9]</xref>. A recent editorial proposed tracking the “retraction index” of scientific journals to indicate the proportion of published articles that are later found problematic <xref ref-type="bibr" rid="pone.0080278-Fang1">[10]</xref>. Publishers themselves are asking the community to end “black box” science that cannot be easily reproduced <xref ref-type="bibr" rid="pone.0080278-NatureEditorialIlluminatingtheBlack1">[11]</xref>. Pharmaceutical companies report abandoning efforts to reproduce research that seemed initially promising and worth investigating after substantial investments <xref ref-type="bibr" rid="pone.0080278-Naik1">[12]</xref>.</p>
<p>Computational reproducibility is a relatively modern concept. The Stanford Exploration Project led by Jon Claerbout published an electronic book containing a dissertation and other articles from their geosciences lab <xref ref-type="bibr" rid="pone.0080278-Claerbout1">[13]</xref>. Papers are accompanied by zipped files with the software that could be used to reproduce the results, and a methodology was developed to create and manage all these objects that continue today with the Madagascar software <xref ref-type="bibr" rid="pone.0080278-Schwab1">[14]</xref>. Advocates of reproducibility have sprung up over the years in many disciplines, from signal processing <xref ref-type="bibr" rid="pone.0080278-Vandewalle1">[15]</xref> to psychology <xref ref-type="bibr" rid="pone.0080278-Spies1">[16]</xref>. Organized community efforts include reproducibility tracks at conferences <xref ref-type="bibr" rid="pone.0080278-Manolescu1">[17]</xref>–<xref ref-type="bibr" rid="pone.0080278-Wilson1">[19]</xref>, reproducibility editors in journals <xref ref-type="bibr" rid="pone.0080278-Diggle1">[20]</xref>, and numerous community workshops and forums (e.g., <xref ref-type="bibr" rid="pone.0080278-Beyond1">[21]</xref>, <xref ref-type="bibr" rid="pone.0080278-Bourne2">[22]</xref>). Active research in this area is addressing a range of topics including copyright <xref ref-type="bibr" rid="pone.0080278-Stodden1">[23]</xref>, privacy <xref ref-type="bibr" rid="pone.0080278-Baker1">[24]</xref>, social <xref ref-type="bibr" rid="pone.0080278-Yong1">[25]</xref> and validation issues <xref ref-type="bibr" rid="pone.0080278-Guo1">[26]</xref>.</p>
<p>Scientific publications could be extended so that they incorporate computational workflows, as many already include data <xref ref-type="bibr" rid="pone.0080278-Bourne1">[1]</xref>. Without access to the source codes for the papers, reproducibility has been shown elusive <xref ref-type="bibr" rid="pone.0080278-Hothorn1">[7]</xref>. This would make scientific results more easily reproducible because articles would have not just a textual description of the computational process used but also a workflow that, as a computational artifact, could be inspected and automatically re-executed. Some systems exist that augment publications with scripts or workflows, such as Weaver for Latex <xref ref-type="bibr" rid="pone.0080278-Leisch1">[27]</xref>–<xref ref-type="bibr" rid="pone.0080278-Falcon1">[28]</xref> and GenePattern for MS Word <xref ref-type="bibr" rid="pone.0080278-Mesirov1">[29]</xref>. Many scientific workflow systems now include the ability to publish provenance records <xref ref-type="bibr" rid="pone.0080278-Moreau1">[30]</xref>–<xref ref-type="bibr" rid="pone.0080278-Simmhan1">[31]</xref>. The Open Provenance Model was developed by the scientific workflow community and is extensively used for this purpose <xref ref-type="bibr" rid="pone.0080278-Moreau2">[32]</xref>. Here we make a contribution to the on-going discussion of reproducibility by attempting to quantify what reproducibility implies.</p>
</sec></sec><sec id="s2">
<title>Methods and Analysis</title>
<sec id="s2a">
<title>Quantifying Reproducibility</title>
<p>We focus on an article that describes a method that lends itself to workflow representation, since others can, in principle, use the same exact procedures <xref ref-type="bibr" rid="pone.0080278-Kinnings1">[4]</xref>. The article describes a computational pipeline that, as applied, maps all putative FDA and European drugs to possible protein receptors within a given proteome; Mycobacterium tuberculosis (TB) in the paper under study. Mapping is limited to the accessible structural proteome of experimental structures and high quality homology models. Mapping is performed using a binding site comparison algorithm which compares the binding site of the drug bound to a primary protein receptor to potential binding sites found on every available protein in a given proteome. Docking of the drug to the off-target protein is used to further validate the predicted binding. The study uses data from the RCSB Protein Data Bank (PDB <xref ref-type="bibr" rid="pone.0080278-Berman1">[33]</xref>) and Modbase <xref ref-type="bibr" rid="pone.0080278-Pieper1">[34]</xref>. The resultant “drugome” established multiple receptors to which a given drug can bind and multiple drugs that could bind to a given receptor. As such it is a putative map of possible drug repositioning strategies in treating a given condition caused by a pathogen. Although the article focuses on Mycobacterium tuberculosis (TB), according to the article’s abstract:</p>
<p>“… the methodology may be applied to other pathogens of interest with results improving as more of their structural proteomes are determined through the continued efforts of structural biology/genomics.”</p>
<p>That is, the methodology is likely to be repeated for other organisms and/or repeated in the same organism as more drugs become available and/or more of the structural proteome becomes available. The original work did not use a workflow system; instead the computational steps were run separately and manually. The original work was done over a period of two years, with different authors having different degrees of participation in the design and the programming aspects of the study. There is a TB Drugome project site where many details about the work can be found <xref ref-type="bibr" rid="pone.0080278-TBDrugome1">[35]</xref>.</p>
<p>The original article was used to challenge participants at the first <italic>Beyond the PDF</italic> workshop <xref ref-type="bibr" rid="pone.0080278-Beyond1">[21]</xref>. The workshop attracted participants interested in bettering the communication and comprehension of science. The challenge was to apply the tools they had developed to illustrate their value on a given piece of science to which, as far as possible, all lab notes, raw data, software, drafts of the paper etc. where made available. The work described here is one outcome of these efforts and is aimed at addressing the questions: What can we gain from the process of workflow creation and what does it tell us about reproducibility?</p>
<p>The rest of this paper describes our attempt to answer these questions. Many details of the analysis and how progress was made in reproducing the method are available on the project site <xref ref-type="bibr" rid="pone.0080278-Wings1">[36]</xref>. Also <xref ref-type="supplementary-material" rid="pone.0080278.s001">Supplement S1</xref> includes a more detailed analysis and the thought processes that occurred.</p>
</sec><sec id="s2b">
<title>Methodology</title>
<p>The workflow was reproduced as a joint effort between computer scientists and the original authors of the article. Although some of the authors of the paper had moved to other research groups (notably Kinnings, its first author), they were still available to answer questions and provide software scripts and data as needed.</p>
<p>We present a detailed analysis of the issues that came up in reproducing three major parts of the methods section in the original paper. These three parts were originally fully automated. Other steps of the method, notably the initial steps to obtain the data and the final steps for visualization and presentation, were manually done and not considered as part of the workflow presented here.</p>
<p>We describe how each of the three method subsections was implemented as a workflow. Each computational step corresponds to an execution of an existing tool or a script written by the paper authors. We were able to recreate the workflow in the Wings workflow system <xref ref-type="bibr" rid="pone.0080278-Gil2">[37]</xref>–<xref ref-type="bibr" rid="pone.0080278-Wings2">[39]</xref> to make sure it was executable and reproduced the original results reported in the paper. Hence, the workflow explicitly represents the method that the authors meant to convey in the original text, that is, the process by which software and data are used to achieve the published result.</p>
<p>Based on this explicit computational workflow, we present an analysis of the reproducibility of each subsection. We considered reproducibility by researchers of four types:</p>
<list list-type="order"><list-item>
<p><bold>REP-AUTHOR</bold>, is a researcher who did the original work and who may need to reproduce the method to update or extend the results published. It is assumed that the authors have enough backup materials to answer any questions that arise in reconstructing the method. In practice, some authors may be students that move away from the lab and their materials and notes may or may not be available, confounding reproducibility <xref ref-type="bibr" rid="pone.0080278-Veretnik1">[40]</xref>.</p>
</list-item><list-item>
<p><bold>REP-EXPERT</bold> is a researcher familiar with the research area. These researchers could reproduce the method even if the methods section of the paper is incomplete and ambiguous. They can use their knowledge of the domain, the software tools and the process to make very complex inferences from the text and reconstruct the method. However, there may be some non-trivial inferences that require significant effort.</p>
</list-item><list-item>
<p><bold>REP-NOVICE</bold> is a researcher with basic bioinformatics expertise. They may be asked to use the method with new data, but are only able to make limited inferences based on analyzing the text and software tools. For them reproducibility can be very costly since it may involve a lot of trial and error, or perhaps additional research. In some cases reproducibility may become impossible.</p>
</list-item><list-item>
<p><bold>REP-MINIMAL</bold> is a researcher with no expertise in bioinformatics. They need some programming skills to assemble the software necessary to run the different steps of the method. They represent researchers from other areas of science with minimal knowledge about biology, students, and even entrepreneurial citizen scientists (e.g., <xref ref-type="bibr" rid="pone.0080278-Rocca1">[41]</xref>). Unless the steps of the method are explicitly stated, they would not be able to reproduce the results.</p>
</list-item></list>
<p>In our work, we did not ask experts to reproduce the method, so we only have three categories of researcher rather than four. We used the following approach:</p>
<list list-type="bullet"><list-item>
<p><bold>REP-MINIMAL</bold> - The computer scientists in the team read the article and formulated the initial workflows. They have minimal background knowledge in biology.</p>
</list-item><list-item>
<p><bold>REP-NOVICE</bold> - The computer scientists subsequently consulted the documentation on the software tools mentioned in the article to try to infer how the data were being processed by each of the steps of the method. Based on this, they refined their initial workflows.</p>
</list-item><list-item>
<p><bold>REP-AUTHOR</bold> - Lastly the computer scientists approached the original paper authors to ask specific questions, resolve execution failures and errors and consult concerning the validity of the results for each step. They created the final workflow based on these conversations with the authors.</p>
</list-item></list>
<p>We analyzed each of the workflow steps in terms of: whether the existence of the step itself was clear to the reproducers, whether the software that was used to run the step was clear to the reproducers, and whether their inputs and outputs were clear. For example, the existence of a step to compare ligand binding sites is mentioned in the text of the original paper, and the fact that it was carried out using the SMAP software <xref ref-type="bibr" rid="pone.0080278-Xie1">[42]</xref> is also explicit in the text, so those would be things that the REP-MINIMAL reproducers were able to figure out. The use of a p-value as an input was not mentioned in the text and cannot be easily inferred unless the researcher reproducing the method becomes familiar with the software, so REP-NOVICE reproducers were able to figure out this parameter.</p>
<p>For this analysis, we assigned a reproducibility score to each aspect of the workflow for each of these reproducer categories. A score of 1 in a category means that, in our assessment, a prototypical researcher of that category would be able to figure out the item. A score of 0 means that they would not be likely to figure it out without help from experts.</p>
<p>Based on these scores, we designed a reproducibility map, where the reproducibility of each computational step was highlighted to determine how far each category of researcher could go in reproducing a given workflow fragment.</p>
<p>Finally, we report on the effort involved in creating the workflow, measured as the time spent on various aspects of the work involved in reproducing the method described in the original article.</p>
</sec><sec id="s2c">
<title>Conceptual Overview of the Method and Final Workflow</title>
<p>An interesting result of our initial discussions of the method was a collaborative diagram that indicated each of the steps in the method and how data were generated and used by each step. This diagram, shown in <xref ref-type="fig" rid="pone-0080278-g001">Figure 1</xref>, makes the steps of the method more explicit and adds useful information to the text in the methods section. It also shows where the data in the tables of the article fit into the method.</p>
<fig id="pone-0080278-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.g001</object-id><label>Figure 1</label><caption>
<title>A high-level dataflow diagram of the TB drugome method.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.g001" position="float" xlink:type="simple"/></fig>
<p>In essence, the bulk of the results in the paper are obtained through three major steps:</p>
<list list-type="order"><list-item>
<p><italic>Comparison of ligand binding sites</italic>, which compares the putative binding sites of solved protein structures and homology models (obtained from queries to the PDB and other sources) against the binding sites from protein structures where approved drugs are bound. This step used the SMAP software <xref ref-type="bibr" rid="pone.0080278-Xie1">[42]</xref>.</p>
</list-item><list-item>
<p><italic>Comparison of protein structures</italic>, optimizing their alignment as well as reporting on the statistical significance of the structural similarity. This step used the FATCAT software <xref ref-type="bibr" rid="pone.0080278-Prlic1">[43]</xref> and is in essence a filtering step to remove structures which have overall global similarity and hence likely to be in the same protein family, since we are interested in similar binding sites found in otherwise dissimilar proteins.</p>
</list-item><list-item>
<p><italic>Molecular docking</italic>, to predict the binding and affinity of the proteins and drug molecules. This step used the eHits software <xref ref-type="bibr" rid="pone.0080278-Ravitz1">[44]</xref>.</p>
</list-item></list>
<p><bold>Based on our experience, authors should be encouraged to publish such high-level flow diagrams as a normal part of the materials and methods section of a paper.</bold> The diagrams provide a high level overview of the method, highlights major steps, and offer a roadmap for reproducibility.</p>
<p>The final workflow with the four steps that reproduced the method is shown in <xref ref-type="fig" rid="pone-0080278-g002">Figure 2</xref>. We highlight the first three major subsections of the method. In order to validate the new results, we used the same inputs (drug binding sites, solved structures, and homology models) as in the original work. However, these inputs point to external data sources (like the PDB) where the data are stored. These third-party data sources had been updated, and therefore the workflow execution produced slightly different results than the results reported in the original article. A detailed comparison of the original results and the results of the new workflow is provided in <xref ref-type="supplementary-material" rid="pone.0080278.s001">Supplement S1</xref>.</p>
<fig id="pone-0080278-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.g002</object-id><label>Figure 2</label><caption>
<title>The reproduced TB Drugome workflow with the different subsections highlighted.</title>
<p>(1) Comparison of ligand binding sites using SMAP; (2) protein structure comparison using FATCAT; (3) docking using Autodock Vina; and (4) graph network creation (visualization). We focus on the reproducibility of sections 1-3 here.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.g002" position="float" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>Reproducibility Analysis</title>
<p>We now analyze each of the subsections of the method as described in the original paper, discussing the difficulties encountered in reproducing the method, highlighting recommendations to improve reproducibility, and show reproducibility scores for each step of the final workflow. An extended analysis of each subsection of the method is available in <xref ref-type="supplementary-material" rid="pone.0080278.s001">Supplement S1</xref>, detailing the evolution of each sub-workflow in order to achieve the final result.</p>
<p><bold>Comparison of ligand binding sites.</bold> The initial workflow design used a single step to compare the three items: the binding sites of experimental structures, the binding sites of the homology models, and the binding sites of the proteins to which drugs were bound. Examining the SMAP software and associated scripts revealed that comparison occurred in two steps: one to compare the experimental binding sites with the drug binding sites, and one to compare the homology model binding sites with the drug binding sites.</p>
<p>To clarify how the outputs of both SMAP invocations were combined, the authors provided the script that invoked the SMAP software. This revealed a new step for sorting the results. In addition, there was an additional step where the results below a given p-value were filtered out.</p>
<p>The SMAP software has several configuration parameters. Without the author’s configuration files, default values of the parameters were used not knowing if the workflow would produce questionable results. That is, it is not clear whether without the same parameter settings the original method would be reproduced and similar results would be obtained. For these reasons, the original configuration files were obtained from the authors. <bold>This suggests that it would be good practice for authors to publish not just a description of the software used and the data used in the original experiment, but also the configuration files used.</bold></p>
<p>It also became clear that the data published as tables in the original article were not the direct input to the SMAP software, and some transformations would be required in order to use these data in the workflow. <bold>We recommend that when data is published in formats that make it more readable, the actual data that is input for software to run also be made available.</bold></p>
<p>Another issue concerned the constant evolution of the software tools that are used for the method steps. In our case, the SMAP software had evolved since the publication of the original paper. As with many software tools used in biology, SMAP is an active research effort and its functionality continues to improve. When the workflow was reproduced there was a new version of SMAP that had the same basic functionality, but produced slightly different results. Under normal research circumstances, it is not critical that the workflow reproduce the exact execution results, but that the conclusions drawn from those results still hold. An interesting result would be if the workflow was run again with a newer more powerful tool and there were additional findings over and above the original publication. The same can be said for new and more comprehensive sources of input data. <bold>The possibility of easily re-running and checking the method periodically with new versions of software tools and/or data that might lead to additional findings may entice researchers to keep their methods more readily reproducible.</bold></p>
<p><bold>Global comparison of protein structures.</bold> Inspecting the scripts used by the authors revealed two steps for this subsection not mentioned in the original article. The first step generates a list of significant comparisons, which is used in the second step to remove significantly similar pairs of global structures from the FATCAT output. An expert in the domain would infer the need for these steps from the published article – only one structure from a set with similar global structures is needed to reach the appropriate conclusions. The article mentions the use of a threshold of 0.05, but this value did not appear in any parameter file. The FATCAT documentation mentions that 0.05 is a default value used to filter results, so this threshold did not have to be reflected in the workflow since it was fixed by the software – hard for a novice to know. Thus the workflow for this subsection could not be recreated just from the article alone, but required the scripts from the authors. Authors should be encouraged to publish any software and parameter files that were written by them and that became part of the method, because public domain software tools are only part of the software required to reproduce the method.</p>
<p>An important issue regarding reproducibility came up in this subsection of the workflow. Although the method was reproduced with all of the necessary steps, the execution of the FATCAT step failed. The reason for the failure was that some of the PDB (protein) ids used in the input list had been superseded by newer structures in the PDB. Therefore, an additional component was added to check availability and replace any obsolete protein with its superseded version. This issue will not be unusual in reproducibility. Many experiments rely upon third party data sources that change constantly. Consequently, it is to be expected that these sources may not always be available and that the results that they return for the same given query may not always be the same. In our case, the changes in the PDB were addressed by adding a step that updated the older IDs with the new ones. <bold>This suggests that some published results that depend on third party data sources may not always be reproducible exactly, so it would be good practice to publish all intermediate data from the experiment so that the method followed can be examined when re-execution is not possible. An alternative is that data archives provide access to their contents for each version.</bold></p>
<p><bold>Docking.</bold> The raw interaction network resulting from the first subsection of the method (comparison of ligand binding sites) was assumed to be the input for docking. It turns out that although the input for docking is data produced by SMAP, it is not the raw interaction network that it outputs. Instead, it is data that SMAP places in an “alignment” folder - only expert users would be aware of this.</p>
<p>The original article refers to adding cofactors to relevant proteins prior to docking, which could be interpreted to be a step prior to docking. As it turns out, there is no explicit step for handling the cofactors since this is handled by manually editing the appropriate PDB file. Again, only expert users would be aware of this.</p>
<p>Examination of the author’s scripts revealed some additional steps: calculating the clip files, which are used for obtaining the ideal ligands before docking. Clip files are mentioned in the article as containing the aligned drug molecules, so it would seem to a non-expert that the aligned molecules would be the output of the initial alignment steps of the overall method.</p>
<p>A major issue with this portion of the workflow is that the docking software used for the original article was no longer used in the laboratory. It is proprietary software, and its license had expired, so alternative software (AutodockVina) with similar functionality has been adopted since the original article was published. Some of the ligands were not recognized by this software, so a transformation step had to be added to the workflow to make Autodock Vina work correctly.</p>
<p>There are reasons why authors use proprietary software, for example, ease of use, support, robustness, visualization and data types supported. However, the authors could replicate the method before publication using open source tools, which would facilitate reproducibility by others. <bold>The use of open source software instead of proprietary software facilitates the reproduction of the software steps originally used by the authors, and should be the preferred mode of publication of methods and workflows.</bold></p>
</sec><sec id="s2e">
<title>Reproducibility Maps</title>
<p>We present reproducibility maps created as a summary of the reproducibility scores for all the major steps in the workflow. <xref ref-type="fig" rid="pone-0080278-g003">Figure 3</xref> shows the reproducibility maps for each of the subsections, summarizing the reproducibility scores assigned to each step. For each section of the method, we show a progression of steps from left to right, noting on the right hand side the category of reproducer represented (MINIMAL, NOVICE, and AUTHOR). A step is shown in red if it was not reproducible by that category of user, and green if it were.</p>
<fig id="pone-0080278-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.g003</object-id><label>Figure 3</label><caption>
<title>Reproducibility maps of the three major subsections of the workflow.</title>
<p>A step is shown in red if it was not reproducible by that category of user, and green if it were.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.g003" position="float" xlink:type="simple"/></fig>
<p>Our observation was that a researcher with minimal knowledge of the domain would only be able to reproduce one of the fourteen steps in the workflow. A novice researcher would be able to reproduce seven of the fourteen steps: the six steps to compare ligand binding sites, only one of the four steps to compare the protein structures, and none of the steps for docking. For docking, our conclusion was that only expert researchers with advanced knowledge of the domain would be able to reproduce the steps. The original software was no longer available, and advanced expertise was required to identify equivalent software to replace it, and to write the software necessary to make it work as needed. Expert researchers would be able to reproduce the method, as the original article combined with the data and software published in the site would be sufficient to infer any missing information. A detailed rationale for the scores can be found in the <italic>reproducibility scores</italic> subsection of <xref ref-type="supplementary-material" rid="pone.0080278.s001">Supplement S1</xref>.</p>
<p>Regarding the results, we checked that the output of the workflow included all the drugs exposed in the original work (plus new findings). The ranking of drugs in the results of the workflow is almost the same as the original, although the number of connections found for each drug is significantly higher in the results of the workflow. A possible reason is changes in the version of the software tools and updates to the external databases where the structures are stored. A detailed comparison can be seen in the <italic>original results versus results from the workflow</italic> subsection of <xref ref-type="supplementary-material" rid="pone.0080278.s001">Supplement S1</xref>.</p>
</sec><sec id="s2f">
<title>Productivity and Effort</title>
<p>We kept detailed records in a wiki of the effort involved in reproducing the method throughout the project. These records are publicly available from <xref ref-type="bibr" rid="pone.0080278-Wings1">[36]</xref>.</p>
<p>We estimated the overall time to reproduce the method as 280 hours for a novice with minimal expertise in bioinformatics. The effort included analyzing the paper and the original author’s web site and additional materials (data, scripts, configuration files) to understand the details of the method, locating and preparing the codes, finding appropriate parameter settings, implementing the workflows, asking questions to the authors when necessary, and validating the workflows. It should be noted that the authors of the original experiment were available to answer questions (notably Kinnings, the first author). These questions were related to missing configuration parameters, documentation for the proper invocation of the tools, and validation of the outcome of the intermediate steps. <xref ref-type="table" rid="pone-0080278-t001">Table 1</xref> estimates the time required to reproduce the method and is broken down by major tasks according to our records.</p>
<table-wrap id="pone-0080278-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.t001</object-id><label>Table 1</label><caption>
<title>Time to reproduce the method.</title>
</caption><alternatives><graphic id="pone-0080278-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Tasks</td>
<td align="left" rowspan="1" colspan="1">Time (hours)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Familiarization with workflow and running software</td>
<td align="left" rowspan="1" colspan="1">160</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">SMAP steps</td>
<td align="left" rowspan="1" colspan="1">32</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">SMAP result sorter steps</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Merger steps</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Get significant results</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">FATCAT URL checker</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">FATCAT step</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Remove significant pairs</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Create clip files</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Create ideal ligands</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Ideal ligand checker</td>
<td align="left" rowspan="1" colspan="1">8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Autodock Vina</td>
<td align="left" rowspan="1" colspan="1">16</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Data visualization steps</td>
<td align="left" rowspan="1" colspan="1">16</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">TOTAL</td>
<td align="left" rowspan="1" colspan="1">280 hours</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap></sec><sec id="s2g">
<title>Publishing the Reproduced Workflow</title>
<p>Now that we had invested significant effort in reproducing the workflow, our goal was to maximize its reusability.</p>
<p>First, the executed workflow was published using the Open Provenance Model <xref ref-type="bibr" rid="pone.0080278-Moreau2">[32]</xref>. This model is used by many workflow systems, so it increases the workflow reusability because it can be imported into other systems depending on the preference of the particular research group. We also publish the workflow provenance using the PROV ontology <xref ref-type="bibr" rid="pone.0080278-Lebo1">[45]</xref>, a recent standard for provenance from the W3C <xref ref-type="bibr" rid="pone.0080278-W3C1">[46]</xref>. This makes the published workflow independent of the workflow system used to create it.</p>
<p>Second, we published an abstract workflow that complements it. The abstract workflow describes the steps in a manner that is independent of the software used to implement them. For this we used an extension of the Open Provenance Model called OPMW <xref ref-type="bibr" rid="pone.0080278-OPMW1">[47]</xref> that includes new terms to describe abstract steps.</p>
<p>Third, we published the workflow and all of its constituents (including input and output data, software and scripts for the steps) as Linked Data <xref ref-type="bibr" rid="pone.0080278-Brickley1">[48]</xref>, which means that each constituent of the workflow can be accessed by its URI through HTTP, and its properties are described using W3C RDF standards <xref ref-type="bibr" rid="pone.0080278-Heath1">[49]</xref>. This means that the published workflow is accessible over the Web, in a way that does not require figuring out how to access institutional catalogs or file systems.</p>
<p>With this maximally open form of publication of the workflow, the effort that we invested in reproducing the workflow does not have to be incurred by others. Each step and its inputs and outputs are explicitly and separately represented as well as linked to the workflow. The software for each step is available as well, as are the intermediate and final results.</p>
<p>The effort involved in creating a workflow is negligible compared with the time to implement the computational method. Implementing the computational method typically takes months, and involves activities such as finding software packages that implement some of the steps, figuring out how to set up the software (e.g., setting up parameters) to suit the data, and writing new code to reformat the data to fit those packages. Once this is all done, creating the workflow can be done in a few hours, and can be as simple as wrapping each step so it can be invoked as a software component and expressing the dataflow among the components. Learning to create simple workflows requires only a few hours, more advanced capabilities clearly require additional time investment (e.g., running workflows in a cluster, depositing results in a catalog, or expressing a complex control flow). Similarly, publishing workflows takes no effort at all since the workflow system takes care of the publication.</p>
<p>Technical details on how the workflow is published can be found in <xref ref-type="bibr" rid="pone.0080278-Garijo1">[50]</xref>. The OWL ontologies for OPM and PROV that express all the underlying RDF properties can be browsed from <xref ref-type="bibr" rid="pone.0080278-Garijo2">[51]</xref>. All the materials related to the workflow and its execution results have been published online <xref ref-type="bibr" rid="pone.0080278-Wings1">[36]</xref>. Additionally, input and output datasets have been associated to DOIs and uploaded to a persistent data sharing repository <xref ref-type="bibr" rid="pone.0080278-FigShare1">[52]</xref>.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>Reproducibility is considered a cornerstone of the scientific method and yet rarely is scientific research reproducible without significant effort, if at all <xref ref-type="bibr" rid="pone.0080278-Bell1">[5]</xref>-<xref ref-type="bibr" rid="pone.0080278-Hothorn1">[7]</xref>. Authors submitting papers know this; as do those reading the papers and trying to reproduce the experiment. For computational work like that described here, where data, methods, and control parameters are all explicitly defined there is less of an excuse for not making the work reproducible. Note that making the software available or accessible through a webserver, while commendable, is not the same as making the work reproducible. Workflows, which define the scientific process as well as all the components, provide the tools for improved reproducibility. While workflows are commonly used for highly repetitive tasks, they are less used for earlier stage research. Whether this is a result of shortcomings in the tools or insufficient emphasis on the need to make work reproducible requires further consideration. This then raises the further issue of whether the emphasis itself is justified. Do we really care if work is <italic>exactly</italic> reproducible? This generally only becomes important if some variation of the original work cannot be reproduced at all, then the original work is fully scrutinized. This speaks to a need for better quantification of what is really needed to improve productivity in science. When, as is the case here, the experiment is conducted completely <italic>in silico</italic>, the opportunity to accurately capture what has transpired becomes a relatively straightforward task (i.e., there is a relatively favorable cost:benefit ratio) and raises the question as to whether the community of computational biologists should do better. What does doing better imply?</p>
<p>We believe it is rare that work is purposely made irreproducible; rather the system of peer review speaks to reproducibility but is cursory in demanding it. The scientific reward is in publishing another paper, not making your current paper more reproducible. Tools help, but changes in policy are also needed. It will be a brave publisher indeed that demands that workflows be deposited with the paper. Publishing after all is a business and if one publisher demands workflows, authors are more likely to publish elsewhere than go to the trouble. Journals are beginning to provide guidelines for reproducibility and minimum requirements for method descriptions <xref ref-type="bibr" rid="pone.0080278-Nature1">[53]</xref>–<xref ref-type="bibr" rid="pone.0080278-Nature2">[54]</xref>. There is already a concept of “data publication,” where datasets are described and receive a unique identifier and a publication. Similarly, there should be a concept of “workflow publication.” There is no explicit credit for publishing software packages, and many people do it. The credit comes indirectly from acknowledgement by the community that the software is useful. Perhaps publishing end-to-end methods as workflows would bring similar reputation. For this to work, authors must be recognized and credited by other researchers reusing their workflow. We posit that the authors of the original method need not be the ones publishing the workflow. Third parties interested in reproducing the method could publish the workflow once reproduced, and get credit not for the method but for the workflow as a reusable software instrument. In one sense this is no different than taking other scientists data and developing a database that extends the use of these data to a wider community. It is a value-added service worthy of attention through publication.</p>
<p>Federal mandates similar to those emerging around shared data could also be put in place for reproducibility too. In the end, funding for science ultimately comes from taxes from the public, and we need to be responsible in making science as efficient and productive as possible. Many government agencies already require data to be published and shared with other researchers. Workflows should follow the same path. The recent emphasis on open availability of research products resulting from public funds <xref ref-type="bibr" rid="pone.0080278-Obama1">[55]</xref>–<xref ref-type="bibr" rid="pone.0080278-Holdren1">[56]</xref> will eventually include the publication of software and the methods (workflows). This will likely be sometime coming as the easier issue of meaningful data provision is not fully understood and solved yet. Notwithstanding, if this remains a difficult issue on a global scale we can make progress in our own laboratories.</p>
<p>A new researcher coming to almost any laboratory and picking up tools used by previous laboratory members can likely testify to what is described in this paper. If we are to accelerate scientific discovery we must surely do better both within a laboratory and beyond. This is particularly important in an era of interdisciplinary science where we often wish to apply methods that we are not experts in. Some would argue that irreproducibility in the laboratory is part of the learning process; we would argue yes, but with so much to learn that is more relevant to discovery we should do better now that we have tools to assist us.</p>
<p>Or should we? Reproducibility aside, is there indeed a favorable cost:benefit ratio in using workflows with respect to productivity? There is a dearth of literature that addresses this question. Rather the value of the workflow is assumed and different workflow systems on different computer architectures are analyzed for their relative performance. At best the question can be addressed by work habits. We must be careful as such work habits could be mandated, in a large company say, rather than by choice, which would be the case in an independent research laboratory. Creating workflows results in overhead for exploratory research, where many paths are discarded. However, once created a workflow can be reused many times. This makes them ideal for repetitive procedures such as might be found in aspects of the pharmaceutical industry. Pharmaceutical companies use workflows for computational experiments <xref ref-type="bibr" rid="pone.0080278-Pipeline1">[57]</xref>. This means there must be a business case for workflows in terms of saving time and effort and/or facilitating quality control. Taking an independent computational biology laboratory, as is the case for this study, it is fair to say that workflows are making inroads into daily work habits. These inroads are still localized to specific subareas of study – Galaxy <xref ref-type="bibr" rid="pone.0080278-Goecks1">[58]</xref> for high-throughput genomic sequence analysis; KNIME <xref ref-type="bibr" rid="pone.0080278-Knime1">[59]</xref> for high-throughput drug screening, and so on, but with that nucleation and with new applications being added by an open source-minded community, adoption is increasing. Adoption would assume a favorable cost:benefit ratio in that use of a workflow system provides increased productivity over not using such a system. This is a cost measured in time rather than money since most academic laboratories in computational biology would use free open source workflow systems. Finally, when articles cannot be easily reproduced the authors are often contacted to clarify or describe additional details. This requires effort that might as well have been invested in writing the article more precisely in the first place.</p>
<p>Workflows can also be seen as an important tool to make the research in a lab more rigorous. Analyses must be captured so they can be inspected by others and errors detected as easily as possible. For example, writing code to transform data makes the transformation inspectable, while using a spreadsheet to do the task makes it much harder to verify that it was done correctly. Ensuring consistency and reproducibility requires more effort without workflows. In our own laboratory we find that the workflow can act as a reference such that new users can more quickly familiarize themselves with the various applications than would be the case without the benefit of the workflow organization, but then choose to go on and run applications outside of the workflow system. As the workflow systems themselves continue to be easier to use and more intuitive we anticipate that more work will be done within the workflow system itself, presumably improving productivity.</p>
<p>For the practitioner, what are the pluses and minuses of workflow use today? An obvious minus is the time required to establish the workflow itself. In some sense this is analogous to documenting a procedure to run a set of software programs. But in most cases once codes are prepared for publication little additional effort is required to include them in a workflow. The advantage of a workflow is that capturing the steps themselves defines the procedure and it can be re-run, in principle, without any further effort. We say “in principle” since as this work has shown workflows decay – the tools available change, the licenses to those tools change, remote data accessibility changes etc. Virtual machines offer the promise of capturing the complete executable environment for future use, however they introduce other issues <xref ref-type="bibr" rid="pone.0080278-Guo1">[26]</xref>. For example, virtual machines often act as black boxes that allow repeating the experiment verbatim, but do not allow for any changes to the computational execution pipeline, limiting its reproducibility. Furthermore, virtual machines cannot store external dynamic databases accessed at runtime (like the PDB in our work) due to their size. These databases are commonly used for experiments in computational biology.</p>
<p>All taken together, it may be that we are at this tipping point of broad workflow adoption and it will be interesting to review workflow use by the computational biology community two or more years from now.</p>
</sec><sec id="s4">
<title>Conclusions</title>
<p>We conclude by summarizing the main observations resulting from our work, leading to desiderata for reproducibility shown in <xref ref-type="table" rid="pone-0080278-t002">Table 2</xref>, and a set of guidelines for authors shown in <xref ref-type="table" rid="pone-0080278-t003">Table 3</xref>. We have restrained from making too many absolute conclusions from a single instance of applying a workflow to a scientific method. It would be interesting to carry out similar studies in other domains and compare findings.</p>
<table-wrap id="pone-0080278-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.t002</object-id><label>Table 2</label><caption>
<title>Observations and desiderata for reproducibility.</title>
</caption><alternatives><graphic id="pone-0080278-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Observation</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">·We found that important computational steps were either missing or ambiguous. <bold>The paper should make clear all computational steps needed by a novice user.</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">·Software is often used with carefully selected parameter settings and configurations. <bold>It would be good practice for authors to publish not just a description of the software and data used, but also to publish any parameter settings and configuration files used.</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">·The possibility of re-running the method periodically with new versions of software tools leading to new findings might help entice researchers to keep their methods readily reproducible.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">·Published results that depend on third party data sources may not always be accessible and may make the experiments run by the original authors irreproducible. <bold>Where practical, authors should publish all intermediate data from the experiment so that the method they followed can be examined when direct re-execution is not possible.</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">·To implement some steps of their methods, authors often use proprietary software or software that is not widely available. <bold>The use of open source software facilitates the reproduction of the software steps originally used by the authors, and should be the preferred mode of publication for authors of methods and workflows.</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">·Although many methods are implemented by using public domain software tools, they often contain additional steps that were implemented by the authors. <bold>To facilitate reproducibility, authors should publish any software written by them and that became part of the method.</bold></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><table-wrap id="pone-0080278-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0080278.t003</object-id><label>Table 3</label><caption>
<title>Reproducibility Guidelines for Authors.</title>
</caption><alternatives><graphic id="pone-0080278-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0080278.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Guideline</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1. <bold>Input data:</bold> Provide the original datasets used in the experiment reported in the paper</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2. <bold>Dataflow Diagram:</bold> Provide a diagram that represents a dataflow of the computational steps. The nodes in the graph should be computational steps, which include invocations of software tools, scripts and other software that were written, and any additional data manipulations that were carried out manually. The links in the graph specify the dataflow, which indicates what the input data for each step are and links to other steps that may have generated the data.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3. <bold>Software:</bold> Prefer open software tools that are appropriately documented. Specify the software tools used mentioning versions and download dates. For any scripts or other software that were written, provide the code itself or at least “pseudo-code” (i.e., an informal version of the code that is language-independent)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4. <bold>Configurations:</bold> Provide the values of any parameters and configuration files used</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5. <bold>Intermediate data:</bold> Provide key intermediate data that resulted from important steps and that would help others determine whether they reproduced the method correctly</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pone.0080278.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pone.0080278.s001" position="float" xlink:type="simple"><label>Supplement S1</label><caption>
<p><bold>A detailed account of the Reproducibility of the TB Drugome Method.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0080278-Bourne1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bourne</surname><given-names>PE</given-names></name> (<year>2010</year>) <article-title>What Do I Want from the Publisher of the Future?</article-title> <source>PLoS Comput Biol</source> <volume>6(5)</volume>: <fpage>e1000787</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000787" xlink:type="simple">10.1371/journal.pcbi.1000787</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Gil1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gil</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Deelman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ellisman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fahringer</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fox</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Examining the Challenges of Scientific Workflows, IEEE Computer</article-title>, <volume>vol. 40</volume>, <issue>no. 12</issue>, pp. <fpage>24</fpage>–<lpage>32</lpage>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/MC.2007.421" xlink:type="simple">http://dx.doi.org/10.1109/MC.2007.421</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Taylor1"><label>3</label>
<mixed-citation publication-type="other" xlink:type="simple">Taylor IJ, Deelman E, Gannon DB, Shields M (Eds.) (2007) Workflows for e-Science. Scientific Workflows for Grids, 1st Edition., XXII, 530 p. 181 illus.</mixed-citation>
</ref>
<ref id="pone.0080278-Kinnings1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kinnings</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Fung</surname><given-names>KH</given-names></name>, <name name-style="western"><surname>Jackson</surname><given-names>RM</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>The Mycobacterium tuberculosis Drugome and Its Polypharmacological Implications</article-title>. <source>PLoS Comput Biol</source> <volume>6(11)</volume>: <fpage>e1000976</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000976" xlink:type="simple">10.1371/journal.pcbi.1000976</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Bell1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AW</given-names></name>, <name name-style="western"><surname>Deutsch</surname><given-names>EW</given-names></name>, <name name-style="western"><surname>Au</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Kearney</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Beavis</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>A HUPO test sample study reveals common problems in mass spectrometry–based proteomics</article-title>. <source>Nature Methods</source> <volume>6(6)</volume>: <fpage>423</fpage>–<lpage>30</lpage> <comment>Doi: doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nmeth.1333" xlink:type="simple">10.1038/nmeth.1333</ext-link>. Available from <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nmeth/journal/v6/n6/full/nmeth.1333.html" xlink:type="simple">http://www.nature.com/nmeth/journal/v6/n6/full/nmeth.1333.html</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Ioannidis1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Allison</surname><given-names>DB</given-names></name>, <name name-style="western"><surname>Ball</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Coulibaly</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Cui</surname><given-names>X</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Repeatability of Published Microarray Gene Expression Analyses</article-title>. <source>Nature Genetics</source> <volume>41(2)</volume>: <fpage>149</fpage>–<lpage>55</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ng.295" xlink:type="simple">10.1038/ng.295</ext-link>. Available from <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/ng/journal/v41/n2/full/ng.295.html" xlink:type="simple">http://www.nature.com/ng/journal/v41/n2/full/ng.295.html</ext-link>.</comment></mixed-citation>
</ref>
<ref id="pone.0080278-Hothorn1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hothorn</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Leisch</surname><given-names>F</given-names></name> (<year>2011</year>). <article-title>Case Studies in Reproducibility</article-title>. <source>Briefings in Bioinformatics</source>, <volume>12</volume><supplement>(3)</supplement>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bib/bbq084" xlink:type="simple">10.1093/bib/bbq084</ext-link>. Available: <ext-link ext-link-type="uri" xlink:href="http://bib.oxfordjournals.org/content/12/3/288" xlink:type="simple">http://bib.oxfordjournals.org/content/12/3/288</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Baggerly1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baggerly</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Coombes</surname><given-names>KR</given-names></name> (<year>2009</year>) <article-title>Deriving Chemosensitivity from Cell Lines: Forensic Bioinformatics and Reproducible Research in High-Throughput Biology</article-title>. <source>Annals of Applied Statistics</source>, <volume>3</volume><supplement>(4)</supplement> <fpage>1309</fpage>–<lpage>1334</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/09-AOAS291" xlink:type="simple">10.1214/09-AOAS291</ext-link>. Available from <ext-link ext-link-type="uri" xlink:href="http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aoas/1267453942" xlink:type="simple">http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aoas/1267453942</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-Decullier1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Decullier</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Huot</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Samson</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Maisonneuve</surname><given-names>H</given-names></name> (<year>2013</year>) <article-title>Visibility of retractions: a cross-sectional one-year study</article-title>. <source>BMC Research Notes</source> <volume>6</volume>: <fpage>238</fpage>.</mixed-citation>
</ref>
<ref id="pone.0080278-Fang1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fang</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Casadevall</surname><given-names>A</given-names></name> (<year>2011</year>). <article-title>Retracted Science and the retracted index</article-title>. <source>Infection and Immunity</source>. <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1128/IAI.05661-11" xlink:type="simple">10.1128/IAI.05661-11</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0080278-NatureEditorialIlluminatingtheBlack1"><label>11</label>
<mixed-citation publication-type="other" xlink:type="simple">Nature Editorial. Illuminating the Black Box (2006). Nature, 442(7098). Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nature/journal/v442/n7098/full/442001a.html" xlink:type="simple">http://www.nature.com/nature/journal/v442/n7098/full/442001a.html</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Naik1"><label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">Naik G (2011) Scientists' Elusive Goal: Reproducing Study Results. The Wall Street Journal Website. Available: <ext-link ext-link-type="uri" xlink:href="http://online.wsj.com/news/articles/SB10001424052970203764804577059841672541590" xlink:type="simple">http://online.wsj.com/news/articles/SB10001424052970203764804577059841672541590</ext-link> Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Claerbout1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Claerbout J, Karrenbach M (1992). Electronic documents give reproducible research a new meaning. 62nd Annual International Meeting of the Society of Exploration Geophysics., Expanded Abstracts, 92: Society of Exploration Geophysics, 601–604. Available from <ext-link ext-link-type="uri" xlink:href="http://sepwww.stanford.edu/doku.php?id=sep:research:reproducible:seg92" xlink:type="simple">http://sepwww.stanford.edu/doku.php?id=sep:research:reproducible:seg92</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Schwab1"><label>14</label>
<mixed-citation publication-type="other" xlink:type="simple">Schwab M, Karrenbach N, Claerbout J (2000). Making Scientific computations reproducible. Computing in Science &amp; Engineering, 2(6), pp.61–67. Available from <ext-link ext-link-type="uri" xlink:href="http://sep.stanford.edu/lib/exe/fetch.php?id=sep%3Aresearch%3Areproducible&amp;cache=cache&amp;media=sep:research:reproducible:cip.pdf" xlink:type="simple">http://sep.stanford.edu/lib/exe/fetch.php?id=sep%3Aresearch%3Areproducible&amp;cache=cache&amp;media=sep:research:reproducible:cip.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Vandewalle1"><label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">Vandewalle P, Kovačević J, Vetterli M (2009) What, why and how of reproducible research in signal processing. IEEE Signal Processing 26(3) pp. 37–47. doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/MSP.2009.932122" xlink:type="simple">http://dx.doi.org/10.1109/MSP.2009.932122</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Spies1"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Spies J, Nosek BA, Bartmess E, Lai C, Galak  J  et al. The reproducibility of psychological science. Report of the Open Science Collaboration. Available: <ext-link ext-link-type="uri" xlink:href="http://openscienceframework.org/reproducibility/" xlink:type="simple">http://openscienceframework.org/reproducibility/</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Manolescu1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Manolescu I, Afanasiev L, Arion A, Dittrich J, Manegold S <etal>et al</etal>. (2008). The repeatability experiment of SIGMOD 2008 ACM SIGMOD Record 37(1). Available from <ext-link ext-link-type="uri" xlink:href="http://portal.acm.org/citation.cfm?id=1374780.1374791&amp;coll=&amp;dl=&amp;idx=J689" xlink:type="simple">http://portal.acm.org/citation.cfm?id=1374780.1374791&amp;coll=&amp;dl=&amp;idx=J689</ext-link>∂ = newsletter&amp;WantType = Newsletters&amp;title = ACM%20SIGMOD%20Recor.</mixed-citation>
</ref>
<ref id="pone.0080278-Bonnet1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bonnet</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Manegold</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bjørling</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cao</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Gonzalez</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Repeatability and workability evaluation of SIGMOD 2011</article-title>. <source>SIGMOD Record</source> <volume>40(2)</volume>: <fpage>45</fpage>–<lpage>48</lpage>.</mixed-citation>
</ref>
<ref id="pone.0080278-Wilson1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Wilson ML, Mackay W, Hovy E, Chi MS, Bernstein JN (2012). RepliCHI SIG – from a panel to a new submission venue for replication. ACM SIGCHI. DOI: 10.1145/2212360.2212419.</mixed-citation>
</ref>
<ref id="pone.0080278-Diggle1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Diggle PJ, Zeger SL (2009) Reproducible research and Biostatistics. Biostatistics 10(3).</mixed-citation>
</ref>
<ref id="pone.0080278-Beyond1"><label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">Beyond the PDF website. Available: <ext-link ext-link-type="uri" xlink:href="http://sites.google.com/site/beyondthepdf" xlink:type="simple">http://sites.google.com/site/beyondthepdf</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Bourne2"><label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Bourne PE, Clark T, Dale R Waard A, Herman I <etal>et al</etal>. (2013) “Improving Future Research Communication and e-Scholarship”. The FORCE 11 Manifesto. Available: <ext-link ext-link-type="uri" xlink:href="http://www.force11.org/white_paper" xlink:type="simple">http://www.force11.org/white_paper</ext-link>. Accessed 2013 October 23.</mixed-citation>
</ref>
<ref id="pone.0080278-Stodden1"><label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Stodden V (2009). The Legal Framework for Reproducible Research in the Sciences: Licensing and Copyright. IEEE Computing in Science and Engineering, 11(1).</mixed-citation>
</ref>
<ref id="pone.0080278-Baker1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Baker SG, Drake AK, Pinsky P, Parnes HL, Kramer BS (2010) Transparency and reproducibility in data analysis: the Prostate Cancer Prevention Trial. Biostatistics, 11(3).</mixed-citation>
</ref>
<ref id="pone.0080278-Yong1"><label>25</label>
<mixed-citation publication-type="other" xlink:type="simple">Yong E (2012) Replication studies: Bad copy. Nature <volume>485</volume>: , 298–300. doi:10.1038/485298a.</mixed-citation>
</ref>
<ref id="pone.0080278-Guo1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Guo PJ (2012) CDE: A Tool For Creating Portable Experimental Software Packages. Computing in Science and Engineering: Special Issue on Software for Reproducible Computational Science, 14(4) pp. 32–35.</mixed-citation>
</ref>
<ref id="pone.0080278-Leisch1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Leisch F (2002) Sweave: Dynamic Generation of Statistical Reports Using Literate Data Analysis. Proceedings of Computational Statistics. In Härdle W, Rönz B (editors). Compstat, Proceedings in Computational Statistics. pp. 575–580. doi: 10.1007/978-3-642-57489-4_89</mixed-citation>
</ref>
<ref id="pone.0080278-Falcon1"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Falcon S (2007) Caching code chunks in dynamic documents: The weaver package. Computational Statistics, (24)2. Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/content/55411257n1473414/" xlink:type="simple">http://www.springerlink.com/content/55411257n1473414/</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Mesirov1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mesirov</surname><given-names>JP</given-names></name> (<year>2010</year>) <article-title>Accessible Reproducible Research</article-title>. <source>Science</source> <volume>327</volume>: <fpage>415</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/cgi/rapidpdf/327/5964/415?ijkey=WzYHd6g6IBNeQ&amp;keytype=ref&amp;siteid=sci" xlink:type="simple">http://www.sciencemag.org/cgi/rapidpdf/327/5964/415?ijkey=WzYHd6g6IBNeQ&amp;keytype=ref&amp;siteid=sci</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Moreau1"><label>30</label>
<mixed-citation publication-type="other" xlink:type="simple">Moreau L, Ludaescher B (editors) (2008). Special Issue on “The First Provenance Challenge,” Concurrency and Computation: Practice and Experience, 20(5).</mixed-citation>
</ref>
<ref id="pone.0080278-Simmhan1"><label>31</label>
<mixed-citation publication-type="other" xlink:type="simple">Simmhan Y, Groth P, Moreau L (Eds) (2011). Special Issue on The third provenance challenge on using the open provenance model for interoperability. Future Generation Computer Systems, 27(6).</mixed-citation>
</ref>
<ref id="pone.0080278-Moreau2"><label>32</label>
<mixed-citation publication-type="other" xlink:type="simple">Moreau L, Clifford B, Freire J, Futrelle J, Gil Y <etal>et al</etal>.. (2011) The Open Provenance Model Core Specification (v1.1). Future Generation Computer Systems, 27(6). Preprint available from <ext-link ext-link-type="uri" xlink:href="http://www.bibbase.org/cache/www.isi.edu__7Egil_publications.bib/moreau-etal-fgcs11.html" xlink:type="simple">http://www.bibbase.org/cache/www.isi.edu__7Egil_publications.bib/moreau-etal-fgcs11.html</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Berman1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat TN <etal>et al</etal>. (2000). The Protein Data Bank. Nucleic Acid Research 2000 28(1), 235–242. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC102472/?tool=pubmed" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC102472/?tool=pubmed</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Pieper1"><label>34</label>
<mixed-citation publication-type="other" xlink:type="simple">Pieper U, Webb BM, Barkan DY, Schneidman-Duhovny D, Schlessinger A, <etal>et al</etal>.. (2011). MODBASE, a database of annotated comparative protein structure models and associated resources. Nucleic Acids Research 32(Database issue):D217–22. Available from: <ext-link ext-link-type="uri" xlink:href="http://salilab.org/pdf/Pieper_NucleicAcidsRes_2010.pdf" xlink:type="simple">http://salilab.org/pdf/Pieper_NucleicAcidsRes_2010.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-TBDrugome1"><label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">TB-Drugome website. Available: <ext-link ext-link-type="uri" xlink:href="http://funsite.sdsc.edu/drugome/TB" xlink:type="simple">http://funsite.sdsc.edu/drugome/TB</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Wings1"><label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">Wings Drugome website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.wings-workflows.org/drugome" xlink:type="simple">http://www.wings-workflows.org/drugome</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Gil2"><label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Gil Y, Gonzalez-Calero PA, Kim J, Moody J, Ratnakar V (2011). A Semantic Framework for Automatic Generation of Computational Workflows Using Distributed Data and Component Catalogs. Journal of Experimental and Theoretical Artificial Intelligence, 23(4).</mixed-citation>
</ref>
<ref id="pone.0080278-Gil3"><label>38</label>
<mixed-citation publication-type="other" xlink:type="simple">Gil Y, Ratnakar V, Kim J, Gonzalez-Calero PA, Groth P <etal>et al</etal>. (2011). Wings: Intelligent Workflow-Based Design of Computational Experiments. IEEE Intelligent Systems, 26(1).</mixed-citation>
</ref>
<ref id="pone.0080278-Wings2"><label>39</label>
<mixed-citation publication-type="other" xlink:type="simple">Wings workflow management system website. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.wings-workflows.org" xlink:type="simple">http://www.wings-workflows.org</ext-link>. Accessed on October 15, 2013.</mixed-citation>
</ref>
<ref id="pone.0080278-Veretnik1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Veretnik</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Fink</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Bourne</surname><given-names>PE</given-names></name> (<year>2008</year>) <article-title>Computational Biology Resources Lack Persistence and Usability. </article-title>. <source>PLoS Comp. Biol</source>. <volume>4(7)</volume>: <fpage>e1000136</fpage>.</mixed-citation>
</ref>
<ref id="pone.0080278-Rocca1"><label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Rocca RA, Magoon G, Reynolds DF, Krahn T, Tilroe VO <etal>et al</etal>.. (2012) Discovery of Western European R1b1a2 Y Chromosome Variants in 1000 Genomes Project Data: An Online Community Approach. PLoS ONE 7(7).</mixed-citation>
</ref>
<ref id="pone.0080278-Xie1"><label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Xie L, Bourne PE (2008) Detecting Evolutionary Linkages Across Fold and Functional Space with Sequence Order Independent Profile-profile Alignments. Proc. Nat. Acad. Sci. (USA), 105(14) 5441–5446.</mixed-citation>
</ref>
<ref id="pone.0080278-Prlic1"><label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Prlic A, Bliven S, Rose PW, Bluhm WF, Bizon C <etal>et al</etal>. (2010) Precalculated Protein Structure Alignments at the RCSB PDB website. Bioinformatics, doi: 10.1093/bioinformatics/btq572. Available: <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/content/early/2010/10/10/bioinformatics.btq572.abstract.html?ijkey=zAIg7fpd9Bhgni4&amp;keytype=ref" xlink:type="simple">http://bioinformatics.oxfordjournals.org/content/early/2010/10/10/bioinformatics.btq572.abstract.html?ijkey=zAIg7fpd9Bhgni4&amp;keytype=ref</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Ravitz1"><label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Ravitz O, Zsoldos Z, Simon A (2011). Improving molecular docking through eHiTS' tunable scoring function. Journal of ComputerAided Molecular Design. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/22076470" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/22076470</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Lebo1"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Lebo T, Sahoo S, McGuinness D, Belhajjame K, Corsar D <etal>et al</etal>. (2013). PROV-O: The PROV Ontology. W3C Recommendation. Available: <ext-link ext-link-type="uri" xlink:href="http://www.w3.org/TR/prov-o/" xlink:type="simple">http://www.w3.org/TR/prov-o/</ext-link>. Accessed 2013 October 23.</mixed-citation>
</ref>
<ref id="pone.0080278-W3C1"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">W3C Provenance Working Group website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.w3.org/2011/prov/wiki/Main_Page" xlink:type="simple">http://www.w3.org/2011/prov/wiki/Main_Page</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-OPMW1"><label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">OPMW Website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.opmw.org" xlink:type="simple">http://www.opmw.org</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Brickley1"><label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Brickley D, Guha RV (2004). RDF Vocabulary Description Language 1.0: RDF Schema. World Wide Web Consortium. Available from <ext-link ext-link-type="uri" xlink:href="http://www.w3.org/TR/rdf-schema" xlink:type="simple">http://www.w3.org/TR/rdf-schema</ext-link>. Accessed on October 23, 2013.</mixed-citation>
</ref>
<ref id="pone.0080278-Heath1"><label>49</label>
<mixed-citation publication-type="book" xlink:type="simple">Heath T, Bizer C (2011). Linked Data: Evolving the Web into a Global Data Space. Morgan and Claypool Publishers, Synthesis Lectures on the Semantic Web. 136 p.</mixed-citation>
</ref>
<ref id="pone.0080278-Garijo1"><label>50</label>
<mixed-citation publication-type="other" xlink:type="simple">Garijo D, Gil Y (2011). A New Approach for Publishing Workflows: Abstractions, Standards, and Linked Data. Proceedings of the Sixth Workshop on Workflows in Support of Large-Scale Science (WORKS'11), held in conjunction with SC 2011, Seattle, Washington. pp. 47–56 doi: 10.1145/2110497.2110504, <ext-link ext-link-type="uri" xlink:href="http://doi.acm.org/10.1145/2110497.2110504" xlink:type="simple">http://doi.acm.org/10.1145/2110497.2110504</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0080278-Garijo2"><label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Garijo D, Gil Y (2011). The OPMW ontology specification. Available: <ext-link ext-link-type="uri" xlink:href="http://www.opmw.org/ontology/" xlink:type="simple">http://www.opmw.org/ontology/</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-FigShare1"><label>52</label>
<mixed-citation publication-type="other" xlink:type="simple">FigShare data repository. Available: <ext-link ext-link-type="uri" xlink:href="http://figshare.com/" xlink:type="simple">http://figshare.com/</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Nature1"><label>53</label>
<mixed-citation publication-type="other" xlink:type="simple">Nature Methods (2013). Enhancing reproducibility., 10, 367. doi:10.1038/nmeth.2471.</mixed-citation>
</ref>
<ref id="pone.0080278-Nature2"><label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">Nature Website(2013). Reporting Checklist for Life Sciences Articles, Nature. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/authors/policies/checklist.pdf" xlink:type="simple">http://www.nature.com/authors/policies/checklist.pdf</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Obama1"><label>55</label>
<mixed-citation publication-type="other" xlink:type="simple">Obama B (2013). Making Open and Machine Readable the New Default for Government Information. Executive Order, The White House. Available: <ext-link ext-link-type="uri" xlink:href="http://www.whitehouse.gov/the-press-office/2013/05/09/executive-order-making-open-and-machine-readable-new-default-government" xlink:type="simple">http://www.whitehouse.gov/the-press-office/2013/05/09/executive-order-making-open-and-machine-readable-new-default-government</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Holdren1"><label>56</label>
<mixed-citation publication-type="other" xlink:type="simple">Holdren J (2013). Increasing Public Access to the Results of Scientific Research. Memorandum of the US Office of Science and Technology. Available: <ext-link ext-link-type="uri" xlink:href="https://petitions.whitehouse.gov/response/increasing-public-access-results-scientific-research" xlink:type="simple">https://petitions.whitehouse.gov/response/increasing-public-access-results-scientific-research</ext-link>. Accessed 2013 October 23.</mixed-citation>
</ref>
<ref id="pone.0080278-Pipeline1"><label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">Pipeline Pilot website. Available: <ext-link ext-link-type="uri" xlink:href="http://accelrys.com/products/pipeline-pilot" xlink:type="simple">http://accelrys.com/products/pipeline-pilot</ext-link>. Accessed 2013 October 15.</mixed-citation>
</ref>
<ref id="pone.0080278-Goecks1"><label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Goecks J, Nekrutenko A, Taylor J, Galaxy Team (2010) Galaxy: A comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biology 11 (8). doi:10.1186/gb-2010-11-8-r86.</mixed-citation>
</ref>
<ref id="pone.0080278-Knime1"><label>59</label>
<mixed-citation publication-type="other" xlink:type="simple">Knime Website. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.knime.org" xlink:type="simple">http://www.knime.org</ext-link>. Accessed on October 15, 2013.</mixed-citation>
</ref>
</ref-list></back>
</article>