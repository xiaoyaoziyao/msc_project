<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0152330</article-id>
<article-id pub-id-type="publisher-id">PONE-D-15-33451</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject><subj-group><subject>Normal distribution</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Experimental design</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychometrics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychometrics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Arithmetic</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical data</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Markov models</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Missing Data Approach to Correct for Direct and Indirect Range Restrictions with a Dichotomous Criterion: A Simulation Study</article-title>
<alt-title alt-title-type="running-head">A Missing Data Approach to Correct for Range Restrictions</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Pfaffel</surname>
<given-names>Andreas</given-names>
</name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kollmayer</surname>
<given-names>Marlene</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schober</surname>
<given-names>Barbara</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Spiel</surname>
<given-names>Christiane</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Applied Psychology: Work, Education, Economy, Faculty of Psychology, University of Vienna, Vienna, Austria</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Gluud</surname>
<given-names>Lise Lotte</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Hvidovre Hospital, DENMARK</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: AP MK BS CS. Performed the experiments: AP MK BS CS. Analyzed the data: AP MK BS CS. Wrote the paper: AP MK BS CS.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">andreas.pfaffel@univie.ac.at</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>28</day>
<month>3</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<year>2016</year>
</pub-date>
<volume>11</volume>
<issue>3</issue>
<elocation-id>e0152330</elocation-id>
<history>
<date date-type="received">
<day>30</day>
<month>7</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>3</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Pfaffel et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0152330"/>
<abstract>
<p>A recurring methodological problem in the evaluation of the predictive validity of selection methods is that the values of the criterion variable are available for selected applicants only. This so-called range restriction problem causes biased population estimates. Correction methods for direct and indirect range restriction scenarios have widely studied for continuous criterion variables but not for dichotomous ones. The few existing approaches are inapplicable because they do not consider the unknown base rate of success. Hence, there is a lack of scientific research on suitable correction methods and the systematic analysis of their accuracies in the cases of a naturally or artificially dichotomous criterion. We aim to overcome this deficiency by viewing the range restriction problem as a missing data mechanism. We used multiple imputation by chained equations to generate complete criterion data before estimating the predictive validity and the base rate of success. Monte Carlo simulations were conducted to investigate the accuracy of the proposed correction in dependence of selection ratio, predictive validity, and base rate of success in an experimental design. In addition, we compared our proposed missing data approach with Thorndike’s well-known correction formulas that have only been used in the case of continuous criterion variables so far. The results show that the missing data approach is more accurate in estimating the predictive validity than Thorndike’s correction formulas. The accuracy of our proposed correction increases as the selection ratio and the correlation between predictor and criterion increase. Furthermore, the missing data approach provides a valid estimate of the unknown base rate of success. On the basis of our findings, we argue for the use of multiple imputation by chained equations in the evaluation of the predictive validity of selection methods when the criterion is dichotomous.</p>
</abstract>
<funding-group>
<funding-statement>This article was supported by the Open Access Publishing Fund of the University of Vienna.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="5"/>
<page-count count="21"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A recurring methodological problem in the evaluation of the predictive validity of selection methods is that the values of the criterion variable are available only for selected applicants. This loss of criterion data for non-selected applicants is an inherent effect of selection and is known as the <italic>range restriction problem</italic> [<xref ref-type="bibr" rid="pone.0152330.ref001">1</xref>–<xref ref-type="bibr" rid="pone.0152330.ref005">5</xref>]. The problem occurs, for example, in the evaluation of an admission test in higher education, because data on academic success are only available for applicants who are admitted to the program. As an effect of the selection, the sample of selected applicants is not random and therefore not representative of the applicant population. Consequently, the observed sample correlation is a biased estimate of the population correlation, i.e. of the predictive validity. The correlation between a predictor <italic>X</italic> and a criterion <italic>Y</italic> obtained from the (available) range restricted dataset (i.e., the selected sample) underestimates the correlation we would obtain from the (not available) unrestricted dataset. Hence, this biased sample correlation has to be corrected to provide a more valid population estimate.</p>
<p>Correction methods for the range restriction problem have been widely studied for continuous criterion variables [<xref ref-type="bibr" rid="pone.0152330.ref005">5</xref>–<xref ref-type="bibr" rid="pone.0152330.ref017">17</xref>]. However, sociological, medical, and psychological research often deal with dichotomous criterion variables [<xref ref-type="bibr" rid="pone.0152330.ref018">18</xref>,<xref ref-type="bibr" rid="pone.0152330.ref019">19</xref>]. Dichotomous variables are characterized by a division of the individuals of a sample or population into two groups. The division can be based on either a qualitative or a quantitative characteristic. In the former case, the dichotomous variable is labelled as natural, and in the latter case as artificial [<xref ref-type="bibr" rid="pone.0152330.ref020">20</xref>]. For example, in higher education, the graduation status of a student is naturally dichotomous (‘graduated’ versus ‘not graduated’). An artificially dichotomous variable is one that has a continuous underlying scale, but has been dichotomized (e.g., ‘high performers’ versus ‘low performers’). The few existing approaches [<xref ref-type="bibr" rid="pone.0152330.ref021">21</xref>,<xref ref-type="bibr" rid="pone.0152330.ref022">22</xref>] to correct the biased correlation in the case of a dichotomous criterion are inapplicable because they require information about the base rate of success, i.e. the proportion of successful individuals in the unrestricted dataset. However, this information is typically not available. Thus, there is a lack in scientific research on suitable correction methods and their accuracies when the criterion variable is dichotomous.</p>
<p>In the present paper, we aim to overcome this deficiency by viewing the range restriction problem as a missing data mechanism [<xref ref-type="bibr" rid="pone.0152330.ref014">14</xref>,<xref ref-type="bibr" rid="pone.0152330.ref023">23</xref>]. As there is comprehensive literature on dealing with missing data, we can draw on a variety of techniques and research results. This potential is a great advantage of this approach, which has not yet been used to correct for range restriction with a dichotomous criterion variable [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>–<xref ref-type="bibr" rid="pone.0152330.ref026">26</xref>]. We apply this approach to the two most common selection scenarios in personnel selection and higher education [<xref ref-type="bibr" rid="pone.0152330.ref027">27</xref>]: the <italic>direct range restriction</italic> (DRR) scenario and the <italic>indirect range restriction</italic> (IRR) scenario. In a DRR scenario, selection is based directly on the predictor variable <italic>X</italic>, whereas in an IRR scenario, selection is based on another variable <italic>Z</italic>.</p>
<p>First of all, we describe the loss of data in the two selection scenarios DRR and IRR, show which data are used for the correction, and give a brief introduction to Thorndike’s well-known and widely used correction formulas in the case of a continuous criterion variable. Next, we provide a brief overview of methods for handling missing data and demonstrate that the proposed approach, <italic>multiple imputation by chained equations</italic>, is suitable for correcting for range restriction in both scenarios involving a dichotomous criterion. Then, we emphasize the critical role of the base rate of success, which has not been taken into account in previous approaches. Our proposed missing data approach generates complete data from which the base rate of success as well as the unbiased predictive validity can be obtained. Finally, we investigate the accuracy of the proposed correction by conducting Monte Carlo simulations, which allow for a comparison of the corrected parameters and the unbiased parameters (predictive validity and base rate of success) in an experimental design.</p>
<sec id="sec002">
<title>Direct and indirect range restriction</title>
<p>The most straightforward selection scenario is the direct range restriction (DRR) scenario, or explicit selection, which is commonly referred to as Thorndike’s Case 2 [<xref ref-type="bibr" rid="pone.0152330.ref004">4</xref>,<xref ref-type="bibr" rid="pone.0152330.ref005">5</xref>]. In a DRR scenario, selection is based directly on the predictor variable <italic>X</italic> and occurs top down. The idea is that applicants with a higher value of <italic>X</italic> are more suitable, and thus more likely to have a higher value in <italic>Y</italic>. As selection is based on values of <italic>X</italic>, the range of <italic>X</italic> is restricted in the selected sample. For this reason, this methodological problem is called the range restriction problem. The variable <italic>X</italic> can be either a score in a single-selection method (e.g., a psychometric test), or a composite score derived from several selection methods (e.g., a psychometric test and a quantitative interview). For example, in higher education in Austria, prospective students of medicine are selected based solely on an entrance examination [<xref ref-type="bibr" rid="pone.0152330.ref028">28</xref>–<xref ref-type="bibr" rid="pone.0152330.ref030">30</xref>]. In the case of DRR, values of <italic>X</italic> are available for all applicants, whereas values of <italic>Y</italic> are only available for selected applicants.</p>
<p>The indirect range restriction scenario (IRR) occurs when applicants are selected on the basis of another variable <italic>Z</italic>, which is usually correlated with <italic>X</italic>, <italic>Y</italic>, or both. The IRR scenario or incidental selection is commonly referred to as Thorndike’s Case 3 [<xref ref-type="bibr" rid="pone.0152330.ref004">4</xref>,<xref ref-type="bibr" rid="pone.0152330.ref005">5</xref>]. Although selection is based on <italic>Z</italic>, the predictive validity of <italic>X</italic> remains of interest. Suppose a selection procedure consists of a psychometric test and a quantitative interview, and we want to assess the predictive validity of the psychometric test, the predictor <italic>X</italic>. For selection, we use the composite score <italic>Z</italic> derived from both selection methods. Organizations often use a composite score for selection and need to know the predictive validity of a single selection method in order to increase the predictive validity of the whole selection procedure (e.g., by removing or weighting a particular selection method). In the case of IRR, values of <italic>X</italic> and <italic>Z</italic> are available for all applicants, whereas values of <italic>Y</italic> are available for selected applicants only.</p>
<p>The amount of data loss depends on the selection ratio (SR), which is defined as the ratio of available places to the number of applicants. The SR ranges between 0 and 1, or between 0% and 100%. For example, if 200 study places are available and 500 applicants apply for them, the SR is 200 divided by 500 or 40%. The top 40% of applicants will be selected and 60% will be unselected. Hence, in this case we have missing values in the criterion variable <italic>Y</italic> for 60% of the applicants, but no missing values in <italic>X</italic> or <italic>Z</italic>. <xref ref-type="fig" rid="pone.0152330.g001">Fig 1</xref> shows the missing data pattern for a SR of 40% in the cases of DRR and IRR.</p>
<fig id="pone.0152330.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Missing data patterns under range restriction.</title>
<p><bold>(a)</bold> Direct range restriction scenario (selection on <italic>X</italic>), and <bold>(b)</bold> indirect range restriction scenario (selection on <italic>Z</italic>). The shaded areas in <italic>Y</italic> represent the location of the missing values in the dataset.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g001" xlink:type="simple"/>
</fig>
<p>In both scenarios, the observed sample correlation between <italic>X</italic> and <italic>Y</italic> is smaller than the correlation we would obtain from the unrestricted dataset, i.e. the predictive validity of the selection method is underestimated. To overcome this problem in the case of a continuous criterion variable, Thorndike [<xref ref-type="bibr" rid="pone.0152330.ref005">5</xref>] presented formulas to correct the Pearson correlation coefficient for DRR and IRR. The goal of these correction formulas is to estimate the correlation in the unrestricted dataset, which is the best estimate available of the population correlation, based on the correlation obtained from the restricted dataset. Correction formulas are commonly applied in predictive validity studies of large-scale testing programs, such as the Graduate Record Examination (GRE) [<xref ref-type="bibr" rid="pone.0152330.ref031">31</xref>,<xref ref-type="bibr" rid="pone.0152330.ref032">32</xref>], the Scholastic Aptitude Test (SAT) [<xref ref-type="bibr" rid="pone.0152330.ref033">33</xref>,<xref ref-type="bibr" rid="pone.0152330.ref034">34</xref>], and the Graduate Management Admission Test (GMAT) [<xref ref-type="bibr" rid="pone.0152330.ref035">35</xref>]. Correction formulas are also applied in other fields, e.g. in predicting job performance [<xref ref-type="bibr" rid="pone.0152330.ref036">36</xref>], and in evaluating the selection of pilot candidates in the US Air Force [<xref ref-type="bibr" rid="pone.0152330.ref037">37</xref>].</p>
<p>The formula for correcting for direct range restriction (DRR) presented by Thorndike is:
<disp-formula id="pone.0152330.e001">
<alternatives>
<graphic id="pone.0152330.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>S</mml:mtext><mml:mi>X</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mtext>s</mml:mtext><mml:mi>X</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>S</mml:mtext><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mtext>s</mml:mtext><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where ρ<sub><italic>XY</italic></sub> is the true or unrestricted correlation coefficient, <italic>r</italic><sub><italic>XY</italic></sub> is the biased Pearson correlation coefficient obtained from the restricted dataset, and <italic>s</italic><sub><italic>X</italic></sub> and <italic>S</italic><sub><italic>X</italic></sub> are the standard deviations of <italic>X</italic> for the restricted and the unrestricted datasets [<xref ref-type="bibr" rid="pone.0152330.ref004">4</xref>]. The formula for correcting for indirect range restriction (IRR) is:
<disp-formula id="pone.0152330.e002">
<alternatives>
<graphic id="pone.0152330.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>Z</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>Z</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>Z</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo> </mml:mo><mml:mo>⋅</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>Z</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <italic>r</italic><sub><italic>XY</italic></sub>, <italic>r</italic><sub><italic>ZX</italic></sub>, and <italic>r</italic><sub><italic>ZY</italic></sub> are the uncorrected Pearson correlation coefficients obtained from the restricted dataset, and <italic>s</italic><sub><italic>Z</italic></sub> and <italic>S</italic><sub><italic>Z</italic></sub> are the standard deviations of variable <italic>Z</italic> for the restricted and the unrestricted dataset [<xref ref-type="bibr" rid="pone.0152330.ref004">4</xref>]. The core term in both correction formulas is the ratio of the standard deviations of the selection variable (<italic>X</italic> or <italic>Z</italic>).</p>
<p>The two formulas require that the assumption of linearity between <italic>X</italic> and <italic>Y</italic> as well as the assumption of homoscedasticity hold. In psychometric literature, it is well documented that corrected correlations are less biased than uncorrected correlations, even over a wide range of assumption violations [<xref ref-type="bibr" rid="pone.0152330.ref009">9</xref>,<xref ref-type="bibr" rid="pone.0152330.ref017">17</xref>,<xref ref-type="bibr" rid="pone.0152330.ref038">38</xref>,<xref ref-type="bibr" rid="pone.0152330.ref039">39</xref>]. Correcting for range restriction is recognized as professional practice because the corrected correlation coefficient is generally the best estimate of the population validity coefficient [<xref ref-type="bibr" rid="pone.0152330.ref040">40</xref>]. In general, the accuracy of the correction increases as the selection ratio increases and as the predictive validity increases [<xref ref-type="bibr" rid="pone.0152330.ref041">41</xref>]. Whereas Thorndike’s correction formulas have been widely studied for continuous criterion variables, they have not been studied for dichotomous ones. Therefore, we investigate how usable Thorndike’s correction formulas are in the case of a dichotomous criterion variable. Furthermore, we propose an approach based on state of the art methods for dealing with missing values that has not yet been applied in predictive validity studies [<xref ref-type="bibr" rid="pone.0152330.ref023">23</xref>].</p>
</sec>
<sec id="sec003">
<title>Range restriction as a missing data mechanism</title>
<p>First, we give a brief overview of missing data mechanisms to locate the range restriction problem in this line of research. Afterwards, we introduce different methods of handling missing data and propose an approach for handling missing values in dichotomous dependent variables. One advantage of viewing the range restriction as a missing data mechanism is that we can draw on a variety of techniques and research results in dealing with missing data [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref025">25</xref>,<xref ref-type="bibr" rid="pone.0152330.ref042">42</xref>]. However, this approach is seldom used with range restriction problems [<xref ref-type="bibr" rid="pone.0152330.ref014">14</xref>].</p>
<p>Rubin [<xref ref-type="bibr" rid="pone.0152330.ref043">43</xref>] describes three mechanisms essential as assumptions in dealing with missing values. These three mechanisms describe how the probability of a missing value relates to the data [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>]: (1) Missing completely at random (MCAR) means the probability of missing data on <italic>Y</italic> is unrelated to other measured variables and is unrelated to the values of <italic>Y</italic> itself; (2) Missing at random (MAR) means the probability of missing data on <italic>Y</italic> is related to some other measured variable (or variables) in the analysis model but not to the values of <italic>Y</italic> itself; and (3) Missing not at random (MNAR) means the probability of missing data on <italic>Y</italic> is related to the values of <italic>Y</italic> itself, even after controlling for other variables. We consider both selection scenarios to be MAR, because the probability of missing values on <italic>Y</italic> depends either on <italic>X</italic> in the case of DRR, or on <italic>Z</italic> in the case of IRR, and not on values of <italic>Y</italic> itself. In other words, there is no relationship between the probability of missing values on <italic>Y</italic> and the values of <italic>Y</italic> after partialling out other variables. In the case of a MAR mechanism, we can estimate the missing values based on the observed values [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>].</p>
<p>Over the past few decades, methodologists have proposed different techniques for dealing with missing data. Many of these approaches have enjoyed widespread use, but several of them, like listwise or pairwise deletion and single imputation techniques (e.g., arithmetic mean imputation, single regression imputation, and single EM imputation) are no longer considered to be state of the art, because they have potentially serious drawbacks [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>]. Listwise and pairwise deletion require an MCAR mechanism, and produce biased parameter estimates with MAR and MNAR data. Deletion of incomplete cases can reduce the statistical power dramatically, even when the data are MCAR. Single imputation techniques also produce biased parameter estimates with MAR data and attenuate standard errors. Single regression imputation and single EM imputation overestimate correlations and attenuate variances and covariances, even when the data are MCAR, because they impute the data with perfectly correlated scores [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref044">44</xref>]. In a single regression imputation, all imputed values fall directly on the regression line and therefore lack variability. In contrast, arithmetic mean imputation attenuates correlations. Consequently, single imputation techniques are not suitable for many reasons, especially with regard to estimating correlation coefficients.</p>
<p>The two approaches that methodologists currently regard as state of the art [<xref ref-type="bibr" rid="pone.0152330.ref025">25</xref>,<xref ref-type="bibr" rid="pone.0152330.ref026">26</xref>] are (1) full information maximum likelihood (FIML), and (2) multiple imputation (MI). Neither of these approaches suffers from the problems mentioned for deletion of incomplete cases and single imputation techniques. The FIML approach estimates the most plausible parameters of a statistical model given the data. In other words, the goal is to identify the population parameter values with the highest probability of producing the data of a certain sample. The population parameter values are estimated with iterative optimization algorithms (e.g., expectation maximization algorithm). For a detailed description of likelihood-based approaches, see Little and Rubin [<xref ref-type="bibr" rid="pone.0152330.ref025">25</xref>], or for a less technical description see Enders [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>].</p>
<p>The second state of the art approach to handle missing data problems is multiple imputation (MI) [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref025">25</xref>,<xref ref-type="bibr" rid="pone.0152330.ref045">45</xref>]. A multiple imputation analysis consists of three distinct steps: the imputation phase, the analysis phase, and the pooling phase. The imputation phase creates several complete datasets (e.g., <italic>m</italic> = 20 imputations) based on one dataset with missing values. Each of these complete datasets contains different plausible estimates of the missing values, but identical values for the observed data. In the analysis phase, data can be analyzed with conventional statistical methods, but the analysis has to be performed <italic>m</italic> times, once for each complete dataset. The goal of the pooling phase is to combine the <italic>m</italic> parameter estimates into a single set of parameter estimates. The pooled parameter estimate is simply the arithmetic average of the <italic>m</italic> estimates from the analysis phase [<xref ref-type="bibr" rid="pone.0152330.ref046">46</xref>]. Analyzing multiple datasets and pooling the results sounds laborious, but modern MI software packages automate this procedure.</p>
<p>FIML und MI make the same assumptions (MAR and multivariate normality), have similar statistical properties, and frequently produce equivalent results [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref042">42</xref>]. Despite making the same assumptions, the two approaches differ in their mathematical background: The mathematical background of FIML is maximum likelihood estimation, whereas MI is based on Bayesian estimation. Therefore, there are important differences between the two approaches. While FIML maximizes the likelihood function to estimate the parameters without replacing missing values, MI replaces the missing values before estimating the parameters from the complete datasets. In contrast to FIML, MI effectively separates the imputation and the analysis phase. This may yield to different parameter estimates between the two approaches. Typically, in MI the imputation model includes many variables of the dataset, whereas the analysis model includes a subset of these variables.</p>
<p>Real data often do not conform to the modeling assumption of multivariate normality. Real data might be skewed, not negative, or bimodal, to name just a few deviations from normality. This mismatch between the distribution of the observed and imputed data may adversely affect the estimates of interest. MI generally tends to be robust against violations of normality [<xref ref-type="bibr" rid="pone.0152330.ref045">45</xref>,<xref ref-type="bibr" rid="pone.0152330.ref047">47</xref>,<xref ref-type="bibr" rid="pone.0152330.ref048">48</xref>]. Deviations from the normal distribution have a small effect on estimates that rely on the center of the distribution, like mean or regression coefficients, but may have significant effects on variances. Demirtas et al. [<xref ref-type="bibr" rid="pone.0152330.ref048">48</xref>] found that MI performs accurately with regard to the mean structure of skewed or multimodal distributions in large samples (n = 400), even for 75% missing values.</p>
<p>In the present study, we have to handle missing values in a dichotomous dependent variable. In light of this, we want to give a conceptual overview of Bayesian multiple imputation using logistic regression, which is considered to handle dichotomous variables most efficiently. Imputation of incomplete dichotomous variables is possible under the broad class of generalized linear models (GLM) [<xref ref-type="bibr" rid="pone.0152330.ref049">49</xref>]. The logistic regression models the probability that <italic>Y</italic><sub><italic>i</italic></sub> = 1 given <italic>X</italic><sub><italic>i</italic></sub> and model parameter vector <italic>β</italic> as [<xref ref-type="bibr" rid="pone.0152330.ref045">45</xref>]:
<disp-formula id="pone.0152330.e003">
<alternatives>
<graphic id="pone.0152330.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>The general idea is to estimate the probability model on the subset of the observed data (i.e., the restricted sample), and to impute the missing values with plausible values according to the fitted probabilities. For example, a probability of .80 means that <italic>Y</italic><sub><italic>i</italic></sub> has a chance of 80% of becoming 1 and a 20% chance of becoming 0. For a large number of imputations, the percentage of datasets in which <italic>Y</italic><sub><italic>i</italic></sub> = 1 tends towards 80%. The Bayesian method draws <italic>β</italic> from its respective posterior distributions. The posterior distribution contains the variability of <italic>β</italic> that needs to be incorporated into the imputations. In Bayesian statistics, Markov chain Monte Carlo (MCMC) methods are used to find the posterior distribution of the parameters. MCMC algorithms draw samples from probability distributions based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a very large number of steps is then used as a sample of the desired distribution. The quality of this sample increases with the number of steps. For a mathematical description of the Bayesian logistic regression imputation model, see Rubin [<xref ref-type="bibr" rid="pone.0152330.ref046">46</xref>].</p>
<p>Currently, MI is generally accepted as the best method for dealing with incomplete data in many fields [<xref ref-type="bibr" rid="pone.0152330.ref045">45</xref>]. Therefore, we suggest using multiple imputation by chained equations (MICE) to correct for range restriction in cases of DRR and IRR when the criterion variable is dichotomous. The proposed missing data approach first replaces the missing values of the criterion variable <italic>Y</italic> and generates several complete (unrestricted) datasets. Then, the correlation coefficient can be calculated based on these complete datasets.</p>
</sec>
<sec id="sec004">
<title>The critical role of the base rate of success</title>
<p>A very important factor to be considered when correcting for range restriction with a dichotomous criterion is the base rate of success (BR) [<xref ref-type="bibr" rid="pone.0152330.ref021">21</xref>]. The BR is the percentage of individuals who would be successful on the criterion if there were no selection. The BR is calculated by dividing the number of successful individuals by the number of applicants, and ranges between 0 and 1, or between 0% and 100%. The BR contains unbiased information about the proportions of cases in the categories <italic>p</italic> (<italic>Y</italic> = 0; not successful) and <italic>q</italic> (<italic>Y</italic> = 1; successful) of a dichotomous criterion variable. For example, if all applicants are admitted to a study program and 60% of them complete this study program successfully, the BR is .6, or 60%.</p>
<p>Unfortunately, in the case of selection, the BR is unknown, as we cannot obtain the percentage of unselected applicants able to succeed on the criterion. We can only obtain the <italic>success rate</italic> of the selected sample, which is the number of successful individuals divided by the number of selected applicants. The success rate, however, is a biased estimator for the BR. Assuming a selection method determines the most suitable applicants, we will obtain a success rate which is higher than the BR.</p>
<p>Next, we will show how the two proportions <italic>p</italic> and <italic>q</italic> constituting the BR affect the magnitude of the correlation coefficient between a continuous variable <italic>X</italic> and a dichotomous variable <italic>Y</italic> [<xref ref-type="bibr" rid="pone.0152330.ref050">50</xref>,<xref ref-type="bibr" rid="pone.0152330.ref051">51</xref>]. Two correlation coefficients can be distinguished depending on whether the dichotomous variable is based on a qualitative or on a quantitative characteristic. In the former case, the dichotomous variable is labelled as natural, and in the latter case as artificial [<xref ref-type="bibr" rid="pone.0152330.ref020">20</xref>]. For a naturally dichotomous variable, the point-biserial correlation coefficient ρ<sub>pb</sub> is used [<xref ref-type="bibr" rid="pone.0152330.ref050">50</xref>,<xref ref-type="bibr" rid="pone.0152330.ref051">51</xref>]:
<disp-formula id="pone.0152330.e004">
<alternatives>
<graphic id="pone.0152330.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msqrt><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msqrt></mml:mrow><mml:mrow><mml:msub><mml:mo>σ</mml:mo><mml:mi>X</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>M</italic><sub>1</sub> and <italic>M</italic><sub>0</sub> are the mean values of the continuous variable <italic>X</italic> for the group ‘not successful’ (<italic>Y</italic> = 0) and the group ‘successful’ (<italic>Y</italic> = 1), and σ<sub><italic>X</italic></sub> is the standard deviation of <italic>X</italic>. <italic>p</italic> and <italic>q</italic> = 1 − <italic>p</italic> represent the proportions of the two groups ‘not successful’ and ‘successful’. ρ<sub>pb</sub> ranges between -1 and +1. Normality of <italic>X</italic> is an assumption for significance testing, but not for calculating ρ<sub>pb</sub>.</p>
<p>An artificially dichotomous variable is created whenever the values of a continuous variable are divided into two groups at a specific cut-off point. For example, student performance is measured on a continuous scale, and students are divided into ‘low’ and ‘high’ performers on the basis of their performance. In this case, a biserial correlation coefficient ρ<sub>b</sub> is the more appropriate calculation. In the case of an artificially dichotomous variable, ρ<sub>pb</sub> systematically underestimates the Pearson correlation coefficient which would have been obtained before dichotomization [<xref ref-type="bibr" rid="pone.0152330.ref041">41</xref>]. ρ<sub>b</sub> is related to ρ<sub>pb</sub> as shown in <xref ref-type="fig" rid="pone.0152330.g005">Formula 5</xref>:
<disp-formula id="pone.0152330.e005">
<alternatives>
<graphic id="pone.0152330.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:msub><mml:mo>ρ</mml:mo><mml:mtext>b</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msqrt><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msqrt></mml:mrow><mml:mi>h</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where <italic>h</italic> is the ordinate of the standard normal distribution at the point at which the cut for the dichotomization was made.</p>
<p>Both ρ<sub>pb</sub> and ρ<sub>b</sub> depend on the proportions <italic>p</italic> and <italic>q</italic>. As <italic>p</italic> and <italic>q</italic> become more extreme (e.g., .1 and .9), the correlation coefficient becomes smaller. Different values of the BR and the success rate result in different values of the correlation coefficients. Hence, <italic>p</italic> and <italic>q</italic> as obtained from the restricted dataset are different from the <italic>p</italic> and <italic>q</italic> we would obtain from the unrestricted dataset. Therefore, using the success rate to estimate the predictive validity results in biased correlation coefficients.</p>
<p>Two approaches have been proposed so far to assess the predictive validity of a selection method when the criterion variable is dichotomous. However, both approaches assume that the BR is known (e.g., from the literature), or should be assumed. The first approach is to apply the Taylor-Russell tables for a dichotomous criterion variable [<xref ref-type="bibr" rid="pone.0152330.ref021">21</xref>]. These tables indicate values of ρ<sub>pb</sub> for the combination of the SR, the success rate, and the BR. The value for ρ<sub>pb</sub> can only be taken from the tables if the values for the other three parameters are known. While the SR and the success rate are typically known, the BR is not and must be assumed. The second approach focuses on the effect size Cohen’s <italic>d</italic> as a measure of the predictive validity in the case of a naturally dichotomous variable, and offers correction formulas for DRR and IRR [<xref ref-type="bibr" rid="pone.0152330.ref022">22</xref>]. The formulas correct the biased effect size <italic>d</italic> (obtained from the selected sample) into an unbiased <italic>d</italic> using the ratio of the unrestricted standard deviation to the restricted standard deviation, as known from Thorndike’s correction formulas. Both formulas to calculate the unbiased <italic>d</italic> require the BR, which must be known or assumed. However, assuming the BR is an arbitrary approach, and different assumptions of the BR result in different values of the predictive validity, i.e. different values of the correlation coefficients.</p>
<p>So far, the scientific literature does not provide any correction method for situations in which the BR is unknown. However, when correcting for range restriction with a dichotomous criterion, both the biased success rate and the biased correlation have to be considered. The proposed missing data approach allows for this, as it generates complete datasets from which the BR as well as the unrestricted correlation can be obtained. Therefore, the proposed approach provides an empirical estimation for both the correlation coefficients and the BR based on the selected sample.</p>
</sec>
<sec id="sec005">
<title>Purposes of this Study</title>
<p>Correction methods for range restriction have been studied almost exclusively for continuous criterion variables. Therefore, the aim of the present study was to give empirical evidence in an experimental design on correcting for direct range restriction (DRR) and indirect range restriction (IRR) when the criterion variable is dichotomous.</p>
<p>The first purpose is to compare the two approaches (1) multiple imputation by chained equations (MICE), and (2) Thorndike’s correction formulas (Formulas <xref ref-type="disp-formula" rid="pone.0152330.e001">1</xref> &amp; <xref ref-type="disp-formula" rid="pone.0152330.e002">2</xref>) with regard to the accuracy of the correction of the biased sample correlations.</p>
<p>The second purpose is to investigate the effect of a weak, moderate, and strong relationship between predictor and criterion on the accuracy of the correction of the biased sample correlations with multiple imputation by chained equations. Studies investigating Thorndike’s correction formulas have shown that the accuracy of the correction increases as the correlation between predictor and criterion increases.</p>
<p>The third purpose is to investigate the accuracy of the correction of the biased BR with multiple imputation by chained equations. Previous approaches are less useful when the criterion variable is dichotomous because they do not consider that the success rate is a biased estimate for the unknown BR. However, the proposed missing data approach allows us to estimate the BR.</p>
<p>The fourth purpose of this study is to investigate the effect of the strength of the correlation between <italic>Z</italic> and <italic>X</italic> on the accuracy of the correction with multiple imputation by chained equations in an IRR scenario.</p>
</sec>
</sec>
<sec id="sec006" sec-type="materials|methods">
<title>Method</title>
<sec id="sec007">
<title>Procedure</title>
<p>We conducted Monte Carlo simulations to investigate the two correction approaches: a) Thorndike’s correction formulas, and b) multiple imputation by chained equations (MICE) in an experimental design using the program R Statistics [<xref ref-type="bibr" rid="pone.0152330.ref052">52</xref>]. We wrote four R scripts (see <xref ref-type="supplementary-material" rid="pone.0152330.s005">S1</xref>–<xref ref-type="supplementary-material" rid="pone.0152330.s008">S4</xref> Rscripts) in order to conduct the Monte Carlo simulations for the following four conditions: 1. DRR with an artificially dichotomous criterion variable; 2. DRR with a naturally dichotomous criterion variable; 3. IRR with an artificially dichotomous criterion variable; and 4. IRR with a naturally dichotomous criterion variable. The Monte Carlo simulations were conducted with 5,000 iterations for each condition. The procedure for the Monte Carlo simulation consisted of the following steps.</p>
<sec id="sec008">
<title>Step 1—Data simulation</title>
<p>We generated 5,000 unrestricted multivariate datasets (sample size <italic>N</italic> = 500) for each condition by varying the correlation coefficient between <italic>X</italic> and <italic>Y</italic> from .10 to .90 and the base rate of success (BR) from 10% to 90%. In the case of IRR, there was a third variable <italic>Z</italic>, meaning that we varied not only the correlation coefficient between <italic>X</italic> and <italic>Y</italic> but also the correlations between <italic>Z</italic> and <italic>X</italic>, and Z and <italic>Y</italic> from .10 to .90.</p>
</sec>
<sec id="sec009">
<title>Step 2—Selection</title>
<p>We simulated the selection for nine levels of the selection ratio (SR) ranging from 10% to 90% with step width 10% (which corresponded to missing values in <italic>Y</italic> from 90% to 10%). This yielded 5000 * 9 = 45000 restricted datasets. In the case of DRR, datasets were sorted in descending order by <italic>X</italic>; in the case of IRR, in descending order by <italic>Z</italic>. We selected those cases with the highest values in <italic>X</italic> (DRR), and with the highest values in <italic>Z</italic> (IRR). The percentage of selected cases depended on the SR. Values of <italic>Y</italic> for non-selected cases were deleted (i.e., converted into missing values). The range restricted or selected samples created in this way were saved into new datasets and were used for applying the correction.</p>
</sec>
<sec id="sec010">
<title>Step 3—Correction</title>
<p>Both approaches were applied to the range restricted datasets. In the first approach, Thorndike’s correction formulas for DRR (<xref ref-type="disp-formula" rid="pone.0152330.e001">Eq 1</xref>) and IRR (<xref ref-type="disp-formula" rid="pone.0152330.e002">Eq 2</xref>) were used to calculate the estimate of the correlation coefficient between predictor <italic>X</italic> and criterion <italic>Y</italic>. In the second approach, we used multiple imputation by chained equations to generate <italic>m</italic> = 20 imputed datasets (see subsection Imputation of the missing values). For each imputed dataset, we calculated the correlation coefficient between <italic>X</italic> and <italic>Y</italic>, and the BR. The MI analysis pools the <italic>m</italic> = 20 estimates into a single point estimate. Rubin [<xref ref-type="bibr" rid="pone.0152330.ref046">46</xref>] showed that the multiple imputation point estimate is the arithmetic mean of the <italic>m</italic> estimates.</p>
</sec>
<sec id="sec011">
<title>Step 4—Analysis of parameter estimates</title>
<p>In order to analyse the accuracy of the correction, we compared the parameter estimates of both approaches with the true parameters obtained from the unrestricted dataset. All estimates of the parameters are denoted with the accent symbol hat, where <inline-formula id="pone.0152330.e006"><alternatives><graphic id="pone.0152330.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient and <inline-formula id="pone.0152330.e007"><alternatives><graphic id="pone.0152330.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient. We calculated the residual of each parameter estimate. For example, the residual for the point-biserial correlation coefficient was <inline-formula id="pone.0152330.e008"><alternatives><graphic id="pone.0152330.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, where ρ<sub>pb</sub> was the true unrestricted correlation coefficient.</p>
<p>When running Monte Carlo simulations, extreme conditions typically cause problems in statistical analysis. Consequently, marginal conditions have to be defined. The logistic regression could not be applied when <italic>Y</italic> was constant. This was particularly likely to be the case when the BR and the correlation between <italic>X</italic> and <italic>Y</italic> were high and the SR was small. Therefore, a minimum variance in <italic>Y</italic>, or a minimum number of observations with <italic>Y</italic> = 1 (or <italic>Y</italic> = 0) was a necessary precondition for a valid estimate. We determined that a minimum of five observations in the two categories (‘successful’ and ‘not successful’) was a sufficient number of observations in the restricted dataset. This minimum number of observations was based on the rule of thumb in chi-square statistics for contingency tables. Therefore, we excluded samples that did not meet this prerequisite.</p>
</sec>
</sec>
<sec id="sec012">
<title>Data simulation</title>
<p>We simulated multivariate data for two kinds of dichotomous criterion variables: a) an artificially dichotomous variable, and b) a naturally dichotomous variable. Both kinds of dichotomous criterion variables were simulated for a DRR and an IRR scenario. Purpose 1 was to compare the accuracy of the two approaches (Thorndike and MICE) for all possible combinations influencing the accuracy (ρ<sub><italic>XY</italic></sub>, ρ<sub>ZX</sub>, ρ<sub><italic>ZY</italic></sub>, BR, SR). Therefore, we generated the data using uniform random values for the correlation coefficients, and for the BR, both varied continuously from .1 to .9. The continuous variation of the factors facilitated the subsequent calculation of estimates aggregated over all factors and factor levels. On the basis of these aggregated estimates, the comparison of the two approaches can be displayed more clearly than based a large number of factor combinations.</p>
<p>a) We generated a bivariate standard normal distribution (DRR) or a trivariate standard normal distribution (IRR) using the <monospace>mvrnorm()</monospace> function of the MASS package [<xref ref-type="bibr" rid="pone.0152330.ref053">53</xref>]. <xref ref-type="table" rid="pone.0152330.t001">Table 1</xref> shows the design of the intercorrelation matrix for the DRR and IRR scenarios. In order to create an artificially dichotomous criterion variable <italic>Y</italic>, we dichotomized one of the standard normally distributed variables at a specific cut-off point. The cut-off point corresponded to the BR, which represented the number of ‘successful’ and ‘not successful’ individuals. Values higher than the cut-off point were coded as 1 (‘successful’); all other values were coded as 0 (‘not successful’). For example, a cut-off point at zero (= mean of the standard normal distribution) represented a BR of 50% (<italic>p</italic> = <italic>q</italic> = .50).</p>
<table-wrap id="pone.0152330.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.t001</object-id>
<label>Table 1</label> <caption><title>Design of the intercorrelation matrix of the correlation coefficients for direct range restriction (DRR) and indirect range restriction (IRR).</title></caption>
<alternatives>
<graphic id="pone.0152330.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="3">DRR</th>
<th align="center" colspan="4">IRR</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"/>
<td align="center"><italic>X</italic></td>
<td align="center"><italic>Y</italic></td>
<td align="center"/>
<td align="center"><italic>X</italic></td>
<td align="center"><italic>Y</italic></td>
<td align="center"><italic>Z</italic></td>
</tr>
<tr>
<td align="center"><italic>X</italic></td>
<td align="center">1</td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
<td align="center"><italic>X</italic></td>
<td align="center">1</td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
<td align="center"><italic>r</italic></td>
</tr>
<tr>
<td align="center"><italic>Y</italic></td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
<td align="center">1</td>
<td align="center"><italic>Y</italic></td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
<td align="center">1</td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
</tr>
<tr>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"><italic>Z</italic></td>
<td align="center"><italic>r</italic></td>
<td align="center"><italic>r</italic><sub>b</sub>/<italic>r</italic><sub>pb</sub></td>
<td align="center">1</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p><italic>X</italic> is the predictor variable; <italic>Y</italic> is the dichotomous criterion variable; <italic>Z</italic> is the selection variable in the case of IRR; <italic>r</italic><sub>b</sub> is the biserial correlation coefficient; <italic>r</italic><sub>pb</sub> is the point-biserial correlation coefficient; <italic>r</italic> is the Pearson correlation coefficient.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>b) In the case of a naturally dichotomous criterion, we simulated multivariate data based on a dichotomous variable (<italic>Y</italic>) and (for <italic>X</italic> and <italic>Z</italic>) a mixture of two univariate normal distributions, one normal distribution for each of the two criterion groups. This kind of data was used to develop the Taylor-Russell tables for a dichotomous criterion variable [<xref ref-type="bibr" rid="pone.0152330.ref021">21</xref>]. We followed this approach to be consistent with the literature on evaluating the predictive validity of a selection method when the criterion is dichotomous. First, we generated <italic>Y</italic> with the proportions of ‘successful’ and ‘not successful’ individuals based on the BR. Second, we generated two normally distributed variables (<italic>X</italic><sub>0</sub> and <italic>X</italic><sub>1</sub>; one for each criterion group) with standard deviations of 1, and a mean difference M<sub>1</sub> − M<sub>0</sub>. The mixture of <italic>X</italic><sub>0</sub> and <italic>X</italic><sub>1</sub> was the distribution of the continuous variable <italic>X</italic>. The mean difference is related to the amount of the point-biserial correlation coefficient ρ<sub>pb</sub>. The higher the mean difference, the higher ρ<sub>pb</sub> (for constant BR, and constant standard deviations of <italic>X</italic><sub>0</sub> and <italic>X</italic><sub>1</sub>). For example, when <italic>X</italic><sub>0</sub> and <italic>X</italic><sub>1</sub> are normally distributed with standard deviations of 1, the mean difference is 1.5, and the BR is 50%. In this example, the standard deviation of <italic>X</italic> is 1.25, resulting in a point-biserial correlation coefficient <inline-formula id="pone.0152330.e009"><alternatives><graphic id="pone.0152330.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msub><mml:mo>ρ</mml:mo><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn><mml:mo>⋅</mml:mo><mml:msqrt><mml:mrow><mml:mn>.25</mml:mn></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>1.25</mml:mn><mml:mo>=</mml:mo><mml:mn>.60</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> (see <xref ref-type="disp-formula" rid="pone.0152330.e004">Eq 4</xref>). For details on how to calculate σ<sub><italic>X</italic></sub> for a mixture of two normal distributions in an analytical way, see Cohen [<xref ref-type="bibr" rid="pone.0152330.ref054">54</xref>]. With this procedure, the data simulation was completed for the DRR scenario. For the IRR scenario, we added the third variable <italic>Z</italic> in the same way as <italic>X</italic>, where <italic>Z</italic> was correlated with <italic>X</italic> and with <italic>Y</italic>. Li and colleagues also used this three-variable design in their Monte Carlo simulations to estimate the bootstrapped standard error of the Pearson correlation coefficient of Thorndike’s correction formula for IRR [<xref ref-type="bibr" rid="pone.0152330.ref007">7</xref>].</p>
</sec>
<sec id="sec013">
<title>Imputation of the missing values</title>
<p>We used the R package <italic>MICE</italic> (multivariate imputation by chained equations; version 2.22 [<xref ref-type="bibr" rid="pone.0152330.ref055">55</xref>]) to implement multiple imputation using fully conditional specification. The MICE package supports multivariate imputations of continuous data, binary data, unordered categorical data, and ordered categorical data. The algorithm imputed an incomplete variable by generating plausible values given other variables in the dataset. For the imputation of the dichotomous criterion variable, we used a Bayesian logistic regression implemented using the elementary imputation method <monospace>logreg()</monospace> of the MICE package. The imputation method <monospace>logreg()</monospace> was used with default specifications for the prior distributions and the Markov Chain Monte Carlo simulation (MCMC). Conventional wisdom suggests that multiple imputation analysis requires about <italic>m</italic> = 5 imputations [<xref ref-type="bibr" rid="pone.0152330.ref046">46</xref>,<xref ref-type="bibr" rid="pone.0152330.ref047">47</xref>]. This number of imputations was derived solely by considering the relative efficiency [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref046">46</xref>]. Contrary to this conventional wisdom, simulation studies show that only analyses based on <italic>m</italic> = 20 imputations yield comparable power to a maximum likelihood analysis and are therefore sufficient for many situations [<xref ref-type="bibr" rid="pone.0152330.ref024">24</xref>,<xref ref-type="bibr" rid="pone.0152330.ref042">42</xref>].</p>
<p>In our simulation study, we investigated samples with a rate of missing values up to 90% (corresponding to a SR of 10%). Therefore, we conducted a preliminary study to investigate the impact of the number of imputations on the accuracy of the parameter estimation dependent on the rate of missing values. We conducted Monte Carlo simulations using <italic>m</italic> = 5, 20, and 50 imputations for samples with rates of missing values of 70%, 50%, and 30% (<italic>N</italic> = 500). <xref ref-type="table" rid="pone.0152330.t002">Table 2</xref> shows the results of the preliminary study that <italic>m</italic> = 20 imputations provided a more accurate estimate than only <italic>m</italic> = 5 imputations. However, increasing the number of imputations beyond 20 provided no relevant improvement in the accuracy of the estimates. Therefore, we used <italic>m</italic> = 20 imputations in each simulation.</p>
<table-wrap id="pone.0152330.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.t002</object-id>
<label>Table 2</label> <caption><title>Results of the preliminary study: Root mean square errors of the correlation estimates using <italic>m</italic> = 5, 20, and 50 imputations for 70%, 50%, and 30% missing values (DRR scenario, <italic>N</italic> = 500, 1000 iterations).</title></caption>
<alternatives>
<graphic id="pone.0152330.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center"/>
<th align="justify" colspan="3"><inline-formula id="pone.0152330.e010"><alternatives><graphic id="pone.0152330.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="justify" colspan="3"><inline-formula id="pone.0152330.e011"><alternatives><graphic id="pone.0152330.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><italic>m</italic></td>
<td align="center">70%</td>
<td align="center">50%</td>
<td align="center">30%</td>
<td align="center">70%</td>
<td align="center">50%</td>
<td align="center">30%</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">.163</td>
<td align="center">.118</td>
<td align="center">.075</td>
<td align="center">.112</td>
<td align="center">.082</td>
<td align="center">.049</td>
</tr>
<tr>
<td align="center">20</td>
<td align="center">.161 (-.002)</td>
<td align="center">.106 (-.012)</td>
<td align="center">.067 (-.008)</td>
<td align="center">.105 (-.007)</td>
<td align="center">.073 (-.009)</td>
<td align="center">.044 (-.005)</td>
</tr>
<tr>
<td align="center">50</td>
<td align="center">.158 (-.003)</td>
<td align="center">.104 (-.002)</td>
<td align="center">.070 (.003)</td>
<td align="center">.106 (.001)</td>
<td align="center">.070 (-.003)</td>
<td align="center">.042 (-.002)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p><inline-formula id="pone.0152330.e012"><alternatives><graphic id="pone.0152330.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient, <inline-formula id="pone.0152330.e013"><alternatives><graphic id="pone.0152330.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient, <italic>m</italic> is the number of imputations. Values in brackets show the change in the RMSE as a result of the additional imputations.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec014">
<title>Analysis of parameter estimates</title>
<p>For our purpose of investigating the accuracy of the correction methods, we calculated the residual of each parameter estimate (Step 4 of the procedure). Accuracy is defined as the closeness of the estimated value to the true value of the parameter being estimated [<xref ref-type="bibr" rid="pone.0152330.ref056">56</xref>]. If the residual of a parameter estimate is close to zero, a correction method provides a very good estimation of the true parameter obtained from the unrestricted dataset. The concept of accuracy encompasses both precision (random error) and trueness (bias or systematic error), and therefore provides important quantitative information about the goodness of the correction. We used the root mean square error (RMSE) as a measure of precision, and the mean error (ME) as a measure of trueness. Let <inline-formula id="pone.0152330.e014"><alternatives><graphic id="pone.0152330.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> be the parameter estimate and <italic>θ</italic> the true parameter, then the
<disp-formula id="pone.0152330.e015">
<alternatives>
<graphic id="pone.0152330.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e015" xlink:type="simple"/>
<mml:math display="block" id="M15"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
and the
<disp-formula id="pone.0152330.e016">
<alternatives>
<graphic id="pone.0152330.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e016" xlink:type="simple"/>
<mml:math display="block" id="M16"><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
</alternatives>
<label>(7)</label>
</disp-formula></p>
<p>The RMSE provides information about the probability that a correction is close to the true value. A small RMSE represents a small random error, i.e. a correction with high precision. The ME is the sample arithmetic mean of the residuals. An estimate is biased if the ME is different from zero. A positive ME represents an overestimation, and a negative ME represents an underestimation of the true parameter value.</p>
<p>We used <italic>F</italic>-ratio tests to compare Thorndike’s correction formulas with our proposed missing data approach in terms of the precision of the two estimates <inline-formula id="pone.0152330.e017"><alternatives><graphic id="pone.0152330.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e018"><alternatives><graphic id="pone.0152330.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. The <italic>F</italic>-ratio compares the mean square errors (MSEs), i.e. the variances of the residuals of the two approaches. For example, an <italic>F</italic>-ratio of 1 means that both correction methods have equal precision, while an <italic>F</italic>-ratio of 2 means that one correction method is twice as precise as the other one.</p>
<p>In order to investigate the effect of the strength of the relationship between predictor <italic>X</italic> and criterion <italic>Y</italic> (Purpose 2) and between selection variable <italic>Z</italic> and predictor <italic>X</italic> (Purpose 4) on the accuracy of the correction with multiple imputation by chained equations, we partitioned the true correlation coefficients obtained from the unrestricted dataset into three levels: a weak relationship (from .10 to &lt; .40), a moderate relationship (from .40 to &lt; .70), and a strong relationship (from .70 to .90). We compared the RMSEs of these three levels in order to demonstrate how the strength of the relationship between predictor and criterion affected the precision of the estimation.</p>
</sec>
</sec>
<sec id="sec015" sec-type="results">
<title>Results</title>
<p>Figs <xref ref-type="fig" rid="pone.0152330.g002">2</xref>–<xref ref-type="fig" rid="pone.0152330.g006">6</xref> show the root mean square errors (RMSEs) of the estimated parameters in dependence of the selection ratio (SR). As an overall effect, the accuracy (trueness and precision) of all estimates gradually improved as the SR increased from .1 to .9, i.e. as the loss of criterion data decreased from 90% to 10%. For each purpose, except Purpose 4 that explicitly refers to an IRR scenario, we first display the results for the DRR scenario and then the results for the IRR scenario.</p>
<fig id="pone.0152330.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Direct range restriction (DRR): Root mean square error (RMSE) of the estimates of the predictive validity (<inline-formula id="pone.0152330.e019"><alternatives><graphic id="pone.0152330.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e020"><alternatives><graphic id="pone.0152330.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>).</title>
<p><bold><inline-formula id="pone.0152330.e021"><alternatives><graphic id="pone.0152330.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></bold> is the estimate of the biserial correlation coefficient for an artificially dichotomous criterion variable, and <inline-formula id="pone.0152330.e022"><alternatives><graphic id="pone.0152330.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient for a naturally dichotomous criterion variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g002" xlink:type="simple"/>
</fig>
<fig id="pone.0152330.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Indirect range restriction (IRR): Root mean square error (RMSE) of the estimates of the predictive validity (<inline-formula id="pone.0152330.e023"><alternatives><graphic id="pone.0152330.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e024"><alternatives><graphic id="pone.0152330.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>).</title>
<p><inline-formula id="pone.0152330.e025"><alternatives><graphic id="pone.0152330.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient for an artificially dichotomous criterion variable, and <inline-formula id="pone.0152330.e026"><alternatives><graphic id="pone.0152330.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient for a naturally dichotomous criterion variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g003" xlink:type="simple"/>
</fig>
<fig id="pone.0152330.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Direct range restriction (DRR): Effects of a weak, moderate, and strong predictive validity on the root mean square error (RMSE) of the estimates of the predictive validity (<inline-formula id="pone.0152330.e027"><alternatives><graphic id="pone.0152330.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e028"><alternatives><graphic id="pone.0152330.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>).</title>
<p><inline-formula id="pone.0152330.e029"><alternatives><graphic id="pone.0152330.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient for an artificially dichotomous criterion variable, and <inline-formula id="pone.0152330.e030"><alternatives><graphic id="pone.0152330.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient for a naturally dichotomous criterion variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g004" xlink:type="simple"/>
</fig>
<fig id="pone.0152330.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Indirect range restriction (IRR): Effects of a weak, moderate, and strong predictive validity on the root mean square error (RMSE) of the estimates of the predictive validity (<inline-formula id="pone.0152330.e031"><alternatives><graphic id="pone.0152330.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e032"><alternatives><graphic id="pone.0152330.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>).</title>
<p><bold><inline-formula id="pone.0152330.e033"><alternatives><graphic id="pone.0152330.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></bold> is the estimate of the biserial correlation coefficient for an artificially dichotomous criterion variable, and <inline-formula id="pone.0152330.e034"><alternatives><graphic id="pone.0152330.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient for a naturally dichotomous criterion variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g005" xlink:type="simple"/>
</fig>
<fig id="pone.0152330.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Indirect range restriction (IRR): Effects of a weak, moderate, and strong relationship between predictor <italic>X</italic> and selection variable <italic>Z</italic> on the root mean square error (RMSE) of the estimates of the predictive validity (<inline-formula id="pone.0152330.e035"><alternatives><graphic id="pone.0152330.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e036"><alternatives><graphic id="pone.0152330.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>).</title>
<p><inline-formula id="pone.0152330.e037"><alternatives><graphic id="pone.0152330.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient for an artificially dichotomous criterion variable, and <inline-formula id="pone.0152330.e038"><alternatives><graphic id="pone.0152330.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the point-biserial correlation coefficient for a naturally dichotomous criterion variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.g006" xlink:type="simple"/>
</fig>
<sec id="sec016">
<title>Purpose 1—Comparison of the two approaches</title>
<p>The first purpose was to compare the correction with multiple imputation by chained equations (MICE) with Thorndike’s correction formulas with regard to the accuracy of the correlation estimates.</p>
<p><italic>DRR scenario</italic>: <xref ref-type="table" rid="pone.0152330.t003">Table 3</xref> summarizes the mean errors (MEs) as a measure of the trueness of the predictive validity. The results show that both approaches underestimate the unrestricted correlation at SR of .1 (90% missing values). The underestimation at SR = .1 is larger when correcting with MICE than when correcting with Thorndike’s formula (MICE about -.10; Thorndike about -.05). For SRs beyond .2, the estimates for both kinds of criterion variables are less biased when correcting with MICE. Next, we compared the RMSEs of <inline-formula id="pone.0152330.e039"><alternatives><graphic id="pone.0152330.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (naturally dichotomous criterion variable) and <inline-formula id="pone.0152330.e040"><alternatives><graphic id="pone.0152330.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (artificially dichotomous criterion variable) when correcting with MICE and with Thorndike’s correction formula for DRR (<xref ref-type="disp-formula" rid="pone.0152330.e001">Eq 1</xref>). In the case of <inline-formula id="pone.0152330.e041"><alternatives><graphic id="pone.0152330.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, the <italic>F</italic>-ratios range from 1.14 to 2.25 (all <italic>p</italic>s &lt; .001), except at SR = .3 and SR = .4 (<italic>F</italic>-ratios 1.03 and 1.00). In the case of <inline-formula id="pone.0152330.e042"><alternatives><graphic id="pone.0152330.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, the <italic>F</italic>-ratios range from 2.08 to 10.3 (all <italic>p</italic>s &lt; .001), as shown in <xref ref-type="table" rid="pone.0152330.t004">Table 4</xref>. Thus, the correction with MICE is more precise than the correction with Thorndike’s formula (<xref ref-type="disp-formula" rid="pone.0152330.e001">Eq 1</xref>) for both kinds of dichotomous criterion variables. The difference in the extent of precision between the two approaches is higher for a naturally dichotomous criterion variable than for an artificially dichotomous criterion variable. <xref ref-type="fig" rid="pone.0152330.g002">Fig 2</xref> shows the RMSEs of both correlation estimates (<inline-formula id="pone.0152330.e043"><alternatives><graphic id="pone.0152330.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub><mml:mtext> </mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e044"><alternatives><graphic id="pone.0152330.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) for our proposed correction with multiple imputation by chained equations (MICE) and for the correction with Thorndike’s formula (<xref ref-type="disp-formula" rid="pone.0152330.e001">Eq 1</xref>).</p>
<table-wrap id="pone.0152330.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.t003</object-id>
<label>Table 3</label> <caption><title>Mean errors (ME) of the correlation estimates.</title></caption>
<alternatives>
<graphic id="pone.0152330.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left"/>
<th align="center" colspan="9">Selection ratio (SR)</th>
</tr>
<tr>
<th align="center"/>
<th align="left"/>
<th align="center">.1</th>
<th align="center">.2</th>
<th align="center">.3</th>
<th align="center">.4</th>
<th align="center">.5</th>
<th align="center">.6</th>
<th align="center">.7</th>
<th align="center">.8</th>
<th align="center">.9</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="2"><bold>DRR, artificially dichotomous</bold></td>
<td align="left">MICE</td>
<td align="char" char=".">-.12</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">Thorndike</td>
<td align="char" char=".">-.06</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>DRR, naturally dichotomous</bold></td>
<td align="left">MICE</td>
<td align="char" char=".">-.09</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">Thorndike</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.05</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>IRR, artificially dichotomous</bold></td>
<td align="left">MICE</td>
<td align="char" char=".">-.08</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">Thorndike</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>IRR, naturally dichotomous</bold></td>
<td align="left">MICE</td>
<td align="char" char=".">-.07</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">Thorndike</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.04</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.03</td>
<td align="char" char=".">-.02</td>
<td align="char" char=".">-.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p><inline-formula id="pone.0152330.e045"><alternatives><graphic id="pone.0152330.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub><mml:mtext> </mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient, <inline-formula id="pone.0152330.e046"><alternatives><graphic id="pone.0152330.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate point-biserial correlation coefficient.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pone.0152330.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.t004</object-id>
<label>Table 4</label> <caption><title><italic>F</italic>-ratio of the correlation estimates when correcting with multiple imputation by chained equations and Thorndike’s formulas.</title></caption>
<alternatives>
<graphic id="pone.0152330.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2"/>
<th align="center" colspan="9">Selection ratio (SR)</th>
</tr>
<tr>
<th align="center">.1</th>
<th align="center">.2</th>
<th align="center">.3</th>
<th align="center">.4</th>
<th align="center">.5</th>
<th align="center">.6</th>
<th align="center">.7</th>
<th align="center">.8</th>
<th align="center">.9</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><bold>DRR, artificially dichotomous</bold></td>
<td align="char" char=".">2.23**</td>
<td align="char" char=".">1.23**</td>
<td align="char" char=".">1.03</td>
<td align="char" char=".">1.00</td>
<td align="char" char=".">1.14**</td>
<td align="char" char=".">1.27**</td>
<td align="char" char=".">1.66**</td>
<td align="char" char=".">1.95**</td>
<td align="char" char=".">2.25**</td>
</tr>
<tr>
<td align="left"><bold>DRR, naturally dichotomous</bold></td>
<td align="char" char=".">3.46**</td>
<td align="char" char=".">2.08**</td>
<td align="char" char=".">2.25**</td>
<td align="char" char=".">2.87**</td>
<td align="char" char=".">4.24**</td>
<td align="char" char=".">5.22**</td>
<td align="char" char=".">6.71**</td>
<td align="char" char=".">9.19**</td>
<td align="char" char=".">10.3**</td>
</tr>
<tr>
<td align="left"><bold>IRR, artificially dichotomous</bold></td>
<td align="char" char=".">1.72**</td>
<td align="char" char=".">1.46**</td>
<td align="char" char=".">1.34**</td>
<td align="char" char=".">1.42**</td>
<td align="char" char=".">1.48**</td>
<td align="char" char=".">1.69**</td>
<td align="char" char=".">1.95**</td>
<td align="char" char=".">2.40**</td>
<td align="char" char=".">2.72**</td>
</tr>
<tr>
<td align="left"><bold>IRR, naturally dichotomous</bold></td>
<td align="char" char=".">2.41**</td>
<td align="char" char=".">2.68**</td>
<td align="char" char=".">3.62**</td>
<td align="char" char=".">5.02**</td>
<td align="char" char=".">6.76**</td>
<td align="char" char=".">8.29**</td>
<td align="char" char=".">10.4**</td>
<td align="char" char=".">12.4**</td>
<td align="char" char=".">12.3**</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001"><p><inline-formula id="pone.0152330.e047"><alternatives><graphic id="pone.0152330.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate of the biserial correlation coefficient, <inline-formula id="pone.0152330.e048"><alternatives><graphic id="pone.0152330.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the estimate point-biserial correlation coefficient, <italic>F</italic>-ratio is calculated by the mean square error (MSE) of the estimate using Thorndike’s formula divided by the MSE of the estimate using MICE, ** <italic>p</italic> &lt; .001.</p></fn>
</table-wrap-foot>
</table-wrap>
<p><italic>IRR scenario</italic>: As shown in <xref ref-type="table" rid="pone.0152330.t003">Table 3</xref>, MICE underestimates the unrestricted correlation for both kinds of criterion variables at SR = .1. However, this bias tends to be smaller for the IRR scenario than for the DRR scenario. With regard to the precision of the estimates, <xref ref-type="fig" rid="pone.0152330.g003">Fig 3</xref> shows that the correlation estimates are more precise for our proposed correction with MICE than for the correction with Thorndike’s formula. The course of the lines is similar to the DRR scenario. The differences in the RMSEs between MICE and Thorndike’s formula are larger for <inline-formula id="pone.0152330.e049"><alternatives><graphic id="pone.0152330.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> than for <inline-formula id="pone.0152330.e050"><alternatives><graphic id="pone.0152330.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, as shown in <xref ref-type="table" rid="pone.0152330.t004">Table 4</xref>. The <italic>F</italic>-ratios for <inline-formula id="pone.0152330.e051"><alternatives><graphic id="pone.0152330.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> range from 1.34 to 2.72 (all <italic>p</italic>s &lt; .001), and for <inline-formula id="pone.0152330.e052"><alternatives><graphic id="pone.0152330.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> from 2.41 to 12.4 (all <italic>p</italic>s &lt; .001).</p>
</sec>
<sec id="sec017">
<title>Purpose 2—The effect of the strength of the relationship (X, Y)</title>
<p>The second purpose was to investigate the effect of the strength of the relationship between predictor <italic>X</italic> and criterion <italic>Y</italic> on the accuracy of the correction with MICE. Therefore, we investigated the effect of a weak, moderate, and strong relationship between <italic>X</italic> and <italic>Y</italic> on the precision of the correction with MICE.</p>
<p><italic>DRR scenario</italic>: <xref ref-type="fig" rid="pone.0152330.g004">Fig 4</xref> shows that the precision of <inline-formula id="pone.0152330.e053"><alternatives><graphic id="pone.0152330.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0152330.e054"><alternatives><graphic id="pone.0152330.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>b</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> increases (RMSEs decrease) when the strength of the correlation in the unrestricted dataset increases. In <xref ref-type="fig" rid="pone.0152330.g004">Fig 4</xref>, we excluded the value of <inline-formula id="pone.0152330.e055"><alternatives><graphic id="pone.0152330.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>pb</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> for the condition of SR = .1 combined with a strong relationship between <italic>X</italic> and <italic>Y</italic>, because for this case only three restricted datasets met the prerequisite.</p>
<p><italic>IRR scenario</italic>: Similar to the DRR scenario, the precision of the estimated correlation coefficient for naturally and artificially dichotomous criterion variables increases when the strength of the relationship between <italic>X</italic> and <italic>Y</italic> increases, as shown in <xref ref-type="fig" rid="pone.0152330.g005">Fig 5</xref>.</p>
</sec>
<sec id="sec018">
<title>Purpose 3—Correcting the biased base rate of success (BR)</title>
<p>The third purpose was to investigate the accuracy of the correction of the biased BR with MICE. <xref ref-type="table" rid="pone.0152330.t005">Table 5</xref> summarizes the MEs and the RMSEs of the estimate of the base rate of success (<inline-formula id="pone.0152330.e056"><alternatives><graphic id="pone.0152330.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>) for the two scenarios and both kinds of criterion variables.</p>
<table-wrap id="pone.0152330.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0152330.t005</object-id>
<label>Table 5</label> <caption><title>Accuracy of the estimate of the base rate of success when correcting via multiple imputation by chained equations (MICE).</title></caption>
<alternatives>
<graphic id="pone.0152330.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.t005" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left"/>
<th align="center" colspan="9">Selection ratio (SR)</th>
</tr>
<tr>
<th align="left"/>
<th align="left"/>
<th align="center">.1</th>
<th align="center">.2</th>
<th align="center">.3</th>
<th align="center">.4</th>
<th align="center">.5</th>
<th align="center">.6</th>
<th align="center">.7</th>
<th align="center">.8</th>
<th align="center">.9</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="2"><bold>DRR, artificially dichotomous</bold></td>
<td align="left">ME</td>
<td align="char" char=".">.07</td>
<td align="char" char=".">.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">RMSE</td>
<td align="char" char=".">.157</td>
<td align="char" char=".">.120</td>
<td align="char" char=".">.090</td>
<td align="char" char=".">.066</td>
<td align="char" char=".">.047</td>
<td align="char" char=".">.034</td>
<td align="char" char=".">.022</td>
<td align="char" char=".">.014</td>
<td align="char" char=".">.007</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>DRR, naturally dichotomous</bold></td>
<td align="left">ME</td>
<td align="char" char=".">.07</td>
<td align="char" char=".">.02</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">RMSE</td>
<td align="char" char=".">.154</td>
<td align="char" char=".">.111</td>
<td align="char" char=".">.081</td>
<td align="char" char=".">.059</td>
<td align="char" char=".">.040</td>
<td align="char" char=".">.028</td>
<td align="char" char=".">.018</td>
<td align="char" char=".">.011</td>
<td align="char" char=".">.005</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>IRR, artificially dichotomous</bold></td>
<td align="left">ME</td>
<td align="char" char=".">.07</td>
<td align="char" char=".">.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">RMSE</td>
<td align="char" char=".">.151</td>
<td align="char" char=".">.113</td>
<td align="char" char=".">.084</td>
<td align="char" char=".">.061</td>
<td align="char" char=".">.045</td>
<td align="char" char=".">.031</td>
<td align="char" char=".">.020</td>
<td align="char" char=".">.012</td>
<td align="char" char=".">.006</td>
</tr>
<tr>
<td align="left" rowspan="2"><bold>IRR, naturally dichotomous</bold></td>
<td align="left">ME</td>
<td align="char" char=".">.08</td>
<td align="char" char=".">.02</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
<td align="char" char=".">&lt;.01</td>
</tr>
<tr>
<td align="left">RMSE</td>
<td align="char" char=".">.142</td>
<td align="char" char=".">.108</td>
<td align="char" char=".">.078</td>
<td align="char" char=".">.054</td>
<td align="char" char=".">.037</td>
<td align="char" char=".">.026</td>
<td align="char" char=".">.016</td>
<td align="char" char=".">.010</td>
<td align="char" char=".">.005</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001"><p>DRR is the direct range restriction, IRR is the indirect range restriction, ME is the mean error, and RMSE is the root mean square error.</p></fn>
</table-wrap-foot>
</table-wrap>
<p><italic>DRR scenario</italic>: The mean errors in <xref ref-type="table" rid="pone.0152330.t005">Table 5</xref> show an overestimation of the base rate of success (+.07) at an SR of .1 for both kinds of criterion variables. This effect is contrary to the correlation estimates, which underestimate the unrestricted correlation. For SRs beyond .2, the estimates are not biased. In the same manner as for the estimation of the correlation coefficients, the RMSEs of <inline-formula id="pone.0152330.e057"><alternatives><graphic id="pone.0152330.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> decreases as the selection ratio increases (from .157 to .007 for an artificially dichotomous criterion variable and from .154 to .005 for a naturally dichotomous one).</p>
<p><italic>IRR scenario</italic>: The results for the IRR scenario are similar to the DRR scenario. The MEs show an overestimation of the base rate of success only at an SR of .1 and the precision of <inline-formula id="pone.0152330.e058"><alternatives><graphic id="pone.0152330.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0152330.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>B</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> increases as the selection ratio decreases.</p>
</sec>
<sec id="sec019">
<title>Purpose 4—The effect of the strength of the relationship (<italic>Z</italic>, <italic>X</italic>)</title>
<p>The fourth purpose of this study was to investigate the effect of the strength of the relationship between <italic>Z</italic> and <italic>X</italic> on the accuracy of the correction with MICE in an IRR scenario. Therefore, we investigated the effect of a weak, moderate, and strong relationship between the selection variable <italic>Z</italic> and the predictor variable <italic>X</italic> on the precision of the correction with MICE. The results in <xref ref-type="fig" rid="pone.0152330.g006">Fig 6</xref> show that the precision of the estimates increases (RMSEs decrease) when the relationship between <italic>Z</italic> and <italic>X</italic> decreases.</p>
</sec>
</sec>
<sec id="sec020" sec-type="conclusions">
<title>Discussion</title>
<p>A recurring methodological problem in the evaluation of the predictive validity of selection methods is the loss of data for the criterion variable. This so-called range restriction problem results in biased population estimates because the observed sample (the selected sample) is not representative of the population of interest (the applicant population). Hence, these biased estimates have to be corrected. However, researchers have almost exclusively focused on correction in the case of a continuous criterion variable. Therefore, our aim was to propose an approach for correcting for range restriction when the criterion variable is dichotomous. We applied this approach to the two most common selection scenarios in personnel selection and higher education: a direct range restriction scenario (DRR) and an indirect range restriction scenario (IRR). We investigated two kinds of dichotomous criterion variables: artificially and naturally dichotomous criterion variables.</p>
<p>The proposed approach correcting for range restriction is to view the selection as a missing data mechanism. We used multiple imputation by chained equations (MICE), which is a state-of-the-art method for dealing with missing data. We pointed out the importance of the unknown base rate of success, which has to be considered when correcting for range restriction in the case of a dichotomous criterion. The proposed approach corrects for range restriction by replacing the missing values of the criterion variable before estimating the predictive validity and the BR at the same time.</p>
<p>We investigated the accuracy of the proposed correction by conducting Monte Carlo simulations, which allowed us to compare the parameter estimates with the true parameters in an experimental design. In the present simulation study, we varied several factors (correlations, base rate of success, and selection ratio) over a wide range in order to examine the accuracy of the correction for a variety of possible datasets.</p>
<p>We compared our proposed missing data approach with Thorndike's formulas (established for a continuous criterion) in terms of the accuracy of the parameter estimates. The Monte Carlo simulations show that our proposed approach performs effectively in both the DRR scenario and the IRR scenario. The correction of the biased predictive validity with MICE is more precise than the correction with Thorndike’s formulas. Furthermore, we were able to show that the missing data approach provides a valid estimate of the base rate of success that has not been considered in the scientific literature. On the basis of our findings, we argue for the use of multiple imputation by chained equations in the evaluation of the predictive validity of selection methods when the criterion is dichotomous. To our knowledge, the proposed correction for range restriction using multiple imputation by chained equations is the first approach that provides a proper correction for the biased predictive validity when the criterion variable is dichotomous. The missing data approach facilitates the correction of the biased correlation coefficient as well as of the unknown base rate of success.</p>
<p>Some limitations of our study should be mentioned that open the field for further research. In the simulation study, we used a small data matrix of two variables in the DRR scenario and of three variables in the IRR scenario [<xref ref-type="bibr" rid="pone.0152330.ref007">7</xref>]. As in simulation studies, it is often difficult to generate multivariate random correlated datasets, especially for multivariate non-normal distributions. Further research should examine the effect of a data matrix with more variables on the accuracy of the correction. In the present study, we investigated the accuracy of the correction for one sample size. However, one important research question with regard to the multiple imputation by chained equations approach is how small the total sample size as well as the restricted sample size can be for a precise and unbiased correction. We recommend investigating these limitations in further studies.</p>
<p>The IRR scenario assumes that the selection variable <italic>Z</italic> is measured. In this case, the missing data mechanism is MAR (ignorable selection process, [<xref ref-type="bibr" rid="pone.0152330.ref003">3</xref>]), and therefore we can use a multiple imputation technique. However, in cases of incidental selections, <italic>Z</italic> is sometimes either partially measured or unmeasured. For example, this is the case when selection is based on an unquantified subjective judgment, or in the case of self-selection, when individuals remove themselves from a sample for reasons that are not measured. In such cases, the missing data mechanism is missing not at random (MNAR, non-ignorable selection process). In statistics, this methodological problem is known as sample selection bias [<xref ref-type="bibr" rid="pone.0152330.ref003">3</xref>]. Traditional range restriction corrections yield unsatisfactory estimates of <italic>r</italic><sub><italic>XY</italic></sub> when the selection process is non-ignorable [<xref ref-type="bibr" rid="pone.0152330.ref003">3</xref>,<xref ref-type="bibr" rid="pone.0152330.ref039">39</xref>]. A correction procedure for selection bias for a continuous dependent variable has been developed in the field of economics [<xref ref-type="bibr" rid="pone.0152330.ref057">57</xref>,<xref ref-type="bibr" rid="pone.0152330.ref058">58</xref>]. Muthén and Hsu [<xref ref-type="bibr" rid="pone.0152330.ref059">59</xref>] presented a latent variable model. In cases of non-ignorable selection, further studies should examine the accuracy of this latent variable model for a dichotomous criterion using weighted least squares means and variance adjusted (WLSMV). As another approach, MICE can also be used to correct for MNAR data [<xref ref-type="bibr" rid="pone.0152330.ref055">55</xref>].</p>
<p>Some recommendations for practitioners and organizations can be derived from our research. Sometimes, test data from applicants who were not selected are discarded are not available in later validity studies. However, discarding applicants’ test data leads to a needless loss of information regarding the predictive validity of selection methods. Therefore, we recommend that organizations store the data in an anonymized form for future evaluations of the predictive validity. Although our approach is applicable for data with up to 90% missing values, we urge caution in the interpretation of the estimates when missing values exceed 70%.</p>
<p>In summary, the results from the simulation study show that the proposed correction with multiple imputation by chained equations is effective in correcting for DRR and IRR scenarios when the criterion variable is dichotomous. Therefore, the approach presented in this paper seems to be promising in terms of overcoming recurring range restriction problems in the evaluation of the predictive validity of selection methods.</p>
</sec>
<sec id="sec021">
<title>Supporting Information</title>
<supplementary-material id="pone.0152330.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s001" xlink:type="simple">
<label>S1 Data</label>
<caption>
<title>Direct range restriction—artificially dichotomous criterion variable.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s002" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s002" xlink:type="simple">
<label>S2 Data</label>
<caption>
<title>Direct range restriction—naturally dichotomous criterion variable.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s003" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s003" xlink:type="simple">
<label>S3 Data</label>
<caption>
<title>Indirect range restriction—artificially dichotomous criterion variable.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s004" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s004" xlink:type="simple">
<label>S4 Data</label>
<caption>
<title>Indirect range restriction—naturally dichotomous criterion variable.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s005" xlink:type="simple">
<label>S1 Rscript</label>
<caption>
<title>Direct range restriction—artificially dichotomous criterion variable.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s006" xlink:type="simple">
<label>S2 Rscript</label>
<caption>
<title>Direct range restriction—naturally dichotomous criterion variable.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s007" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s007" xlink:type="simple">
<label>S3 Rscript</label>
<caption>
<title>Indirect range restriction—artificially dichotomous criterion variable.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0152330.s008" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0152330.s008" xlink:type="simple">
<label>S4 Rscript</label>
<caption>
<title>Indirect range restriction—naturally dichotomous criterion variable.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pone.0152330.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alexander</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>GV</given-names></name>, <name name-style="western"><surname>Alliger</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Carson</surname> <given-names>KP</given-names></name>. <article-title>Towards a general model of non-random sampling and the impact on population correlation: Generalizations of Berkson’s Fallacy and restriction of range</article-title>. <source>Br J Math Stat Psychol</source>. <year>1986</year>;<volume>39</volume>: <fpage>90</fpage>–<lpage>105</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.2044-8317.1986.tb00849.x" xlink:type="simple">10.1111/j.2044-8317.1986.tb00849.x</ext-link></comment> <object-id pub-id-type="pmid">3768267</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berk</surname> <given-names>RA</given-names></name>. <article-title>An introduction to sample selection bias in sociological data</article-title>. <source>Am Sociol Rev</source>. <year>1983</year>;<volume>48</volume>: <fpage>386</fpage>–<lpage>398</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/2095230" xlink:type="simple">10.2307/2095230</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gross</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>McGanney</surname> <given-names>ML</given-names></name>. <article-title>The restriction of range problem and nonignorable selection processes</article-title>. <source>J Appl Psychol</source>. <year>1987</year>;<volume>72</volume>: <fpage>604</fpage>–<lpage>610</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.72.4.604" xlink:type="simple">10.1037/0021-9010.72.4.604</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sackett</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>. <article-title>Correction for range restriction: An expanded typology</article-title>. <source>J Appl Psychol</source>. <year>2000</year>;<volume>85</volume>: <fpage>112</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.85.1.112" xlink:type="simple">10.1037/0021-9010.85.1.112</ext-link></comment> <object-id pub-id-type="pmid">10740961</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref005"><label>5</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Thorndike</surname> <given-names>RL</given-names></name>. <source>Personnel selection: Test and measurement techniques</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1949</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chan</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>DW-L</given-names></name>. <article-title>Bootstrap standard error and confidence intervals for the correlation corrected for range restriction: A simulation study</article-title>. <source>Psychol Methods</source>. <year>2004</year>;<volume>9</volume>: <fpage>369</fpage>–<lpage>385</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/1082-989X.9.3.369" xlink:type="simple">10.1037/1082-989X.9.3.369</ext-link></comment> <object-id pub-id-type="pmid">15355154</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>Y</given-names></name>. <article-title>Bootstrap standard error and confidence intervals for the correlations corrected for indirect range restriction</article-title>. <source>Br J Math Stat Psychol</source>. <year>2011</year>;<volume>64</volume>: <fpage>367</fpage>–<lpage>387</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1348/2044-8317.002007" xlink:type="simple">10.1348/2044-8317.002007</ext-link></comment> <object-id pub-id-type="pmid">21973092</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duan</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dunlap</surname> <given-names>WP</given-names></name>. <article-title>The accuracy of different methods for estimating the standard error of correlations corrected for range restriction</article-title>. <source>Educ Psychol Meas</source>. <year>1997</year>;<volume>57</volume>: <fpage>254</fpage>–<lpage>265</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0013164497057002005" xlink:type="simple">10.1177/0013164497057002005</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linn</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Harnisch</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Dunbar</surname> <given-names>SB</given-names></name>. <article-title>Corrections for range restriction: An empirical investigation of conditions resulting in conservative corrections</article-title>. <source>J Appl Psychol</source>. <year>1981</year>;<volume>66</volume>: <fpage>655</fpage>–<lpage>663</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.66.6.655" xlink:type="simple">http://dx.doi.org/10.1037/0021-9010.66.6.655</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref010"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Lord FM, Novick MR, Birnbaum A. Statistical theories of mental test scores. 1968; Available: <ext-link ext-link-type="uri" xlink:href="http://doi.apa.org/psycinfo/1968-35040-000" xlink:type="simple">http://doi.apa.org/psycinfo/1968-35040-000</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Millsap</surname> <given-names>RE</given-names></name>. <article-title>Sampling variance in the correlation coefficient under range restriction: A Monte Carlo study</article-title>. <source>J Appl Psychol</source>. <year>1989</year>;<volume>74</volume>: <fpage>456</fpage>–<lpage>461</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.74.3.456" xlink:type="simple">10.1037/0021-9010.74.3.456</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ree</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Carretta</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Earles</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Albert</surname> <given-names>W</given-names></name>. <article-title>Sign changes when correcting for range restriction: A note on Pearson’s and Lawley’s selection formulas</article-title>. <source>J Appl Psychol</source>. <year>1994</year>;<volume>79</volume>: <fpage>298</fpage>–<lpage>301</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.79.2.298" xlink:type="simple">10.1037/0021-9010.79.2.298</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidt</surname> <given-names>FL</given-names></name>, <name name-style="western"><surname>Oh</surname> <given-names>I-S</given-names></name>, <name name-style="western"><surname>Le</surname> <given-names>H</given-names></name>. <article-title>Increasing the accuracy of corrections for range restriction: Implications for selection procedure validities and other research results</article-title>. <source>Pers Psychol</source>. <year>2006</year>;<volume>59</volume>: <fpage>281</fpage>–<lpage>305</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1744-6570.2006.00065.x" xlink:type="simple">10.1111/j.1744-6570.2006.00065.x</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wiberg</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sundström</surname> <given-names>A</given-names></name>. <article-title>A comparison of two approaches to correction of restriction of range in correlation analysis</article-title>. <source>Pract Assess Res Eval</source>. <year>2009</year>;<volume>14</volume>: <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pone.0152330.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolfe</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Held</surname> <given-names>JD</given-names></name>. <article-title>Standard errors of multivariate range-corrected validities</article-title>. <source>Mil Psychol</source>. <year>2010</year>;<volume>22</volume>: <fpage>356</fpage>.</mixed-citation></ref>
<ref id="pone.0152330.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zimmerman</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>RH</given-names></name>. <article-title>Restriction of range and correlation in outlier-prone distributions</article-title>. <source>Appl Psychol Meas</source>. <year>2000</year>;<volume>24</volume>: <fpage>267</fpage>–<lpage>280</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/01466210022031741" xlink:type="simple">10.1177/01466210022031741</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linn</surname> <given-names>RL</given-names></name>. <article-title>Pearson selection formulas: Implications for studies of predictive bias and estimates of educational effects in selected samples</article-title>. <source>J Educ Meas</source>. <year>1983</year>;<volume>20</volume>: <fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1745-3984.1983.tb00185.x" xlink:type="simple">10.1111/j.1745-3984.1983.tb00185.x</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cleary</surname> <given-names>PD</given-names></name>, <name name-style="western"><surname>Angel</surname> <given-names>R</given-names></name>. <article-title>The analysis of relationships involving dichotomous dependent variables</article-title>. <source>J Health Soc Behav</source>. <year>1984</year>; <fpage>334</fpage>–<lpage>348</lpage>. <object-id pub-id-type="pmid">6501841</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peng</surname> <given-names>C-YJ</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Ingersoll</surname> <given-names>GM</given-names></name>. <article-title>An introduction to logistic regression analysis and reporting</article-title>. <source>J Educ Res</source>. <year>2002</year>;<volume>96</volume>: <fpage>3</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/00220670209598786" xlink:type="simple">10.1080/00220670209598786</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ulrich</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wirtz</surname> <given-names>M</given-names></name>. <article-title>On the correlation of a naturally and an artificially dichotomized variable</article-title>. <source>Br J Math Stat Psychol</source>. <year>2004</year>;<volume>57</volume>: <fpage>235</fpage>–<lpage>251</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1348/0007110042307203" xlink:type="simple">10.1348/0007110042307203</ext-link></comment> <object-id pub-id-type="pmid">15511306</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abrahams</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Alf</surname> <given-names>EF</given-names></name>, <name name-style="western"><surname>Wolfe</surname> <given-names>JJ</given-names></name>. <article-title>Taylor-Russell tables for dichotomous criterion variables</article-title>. <source>J Appl Psychol</source>. <year>1971</year>;<volume>55</volume>: <fpage>449</fpage>–<lpage>457</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/h0031761" xlink:type="simple">10.1037/h0031761</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bobko</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Roth</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Bobko</surname> <given-names>C</given-names></name>. <article-title>Correcting the effect size of d for range restriction and unreliability</article-title>. <source>Organ Res Methods</source>. <year>2001</year>;<volume>4</volume>: <fpage>46</fpage>–<lpage>61</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/109442810141003" xlink:type="simple">10.1177/109442810141003</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mendoza</surname> <given-names>JL</given-names></name>. <article-title>Fisher transformations for correlations corrected for selection and missing data</article-title>. <source>Psychometrika</source>. <year>1993</year>;<volume>58</volume>: <fpage>601</fpage>–<lpage>615</lpage>.</mixed-citation></ref>
<ref id="pone.0152330.ref024"><label>24</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Enders</surname> <given-names>CK</given-names></name>. <source>Applied missing data analysis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>; <year>2010</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref025"><label>25</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Little</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <source>Statistical analysis with missing data</source>. <edition>2nd ed</edition>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2002</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schafer</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>JW</given-names></name>. <article-title>Missing data: Our view of the state of the art</article-title>. <source>Psychol Methods</source>. <year>2002</year>;<volume>7</volume>: <fpage>147</fpage>–<lpage>177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/1082-989X.7.2.147" xlink:type="simple">10.1037/1082-989X.7.2.147</ext-link></comment> <object-id pub-id-type="pmid">12090408</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hunter</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>FL</given-names></name>, <name name-style="western"><surname>Le</surname> <given-names>H</given-names></name>. <article-title>Implications of direct and indirect range restriction for meta-analysis methods and findings</article-title>. <source>J Appl Psychol</source>. <year>2006</year>;<volume>91</volume>: <fpage>594</fpage>–<lpage>612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.91.3.594" xlink:type="simple">10.1037/0021-9010.91.3.594</ext-link></comment> <object-id pub-id-type="pmid">16737357</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref028"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">University of Vienna. Aufnahmeverfahren [Admission procedures] [Internet]. 2015 Accessed: 15 April 2015. Available: <ext-link ext-link-type="uri" xlink:href="https://aufnahmeverfahren.univie.ac.at/en/home/" xlink:type="simple">https://aufnahmeverfahren.univie.ac.at/en/home/</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref029"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Medical University of Vienna. MedAT—Aufnahmeverfahren Medizin [MedAT—admission test medicine] [Internet]. 2015 Accessed: 15 April 2015. Available: <ext-link ext-link-type="uri" xlink:href="http://www.medizinstudieren.at/" xlink:type="simple">http://www.medizinstudieren.at/</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref030"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Medical University of Vienna. Zulassung [Admission] [Internet]. 2015 Accessed: 5 April 2015. Available: <ext-link ext-link-type="uri" xlink:href="http://www.meduniwien.ac.at/homepage/content/studium-lehre/zulassung-administratives/zulassung-zum-studium/diplomstudien-human-und-zahnmedizin/zulassung/" xlink:type="simple">http://www.meduniwien.ac.at/homepage/content/studium-lehre/zulassung-administratives/zulassung-zum-studium/diplomstudien-human-und-zahnmedizin/zulassung/</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chernyshenko</surname> <given-names>OS</given-names></name>, <name name-style="western"><surname>Ones</surname> <given-names>DS</given-names></name>. <article-title>How selective are psychology graduate programs? The effect of the selection ratio on GRE score validity</article-title>. <source>Educ Psychol Meas</source>. <year>1999</year>;<volume>59</volume>: <fpage>951</fpage>–<lpage>961</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/00131649921970279" xlink:type="simple">10.1177/00131649921970279</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Powers</surname> <given-names>DE</given-names></name>. <article-title>Validity of Graduate Record Examinations (GRE) general test scores for admissions to colleges of veterinary medicine</article-title>. <source>J Appl Psychol</source>. <year>2004</year>;<volume>89</volume>: <fpage>208</fpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.89.2.208" xlink:type="simple">http://dx.doi.org/10.1037/0021-9010.89.2.208</ext-link> <object-id pub-id-type="pmid">15065970</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref033"><label>33</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kobrin</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Patterson</surname> <given-names>BF</given-names></name>, <name name-style="western"><surname>Shaw</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Mattern</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Barbuti</surname> <given-names>SM</given-names></name>. <source>Validity of the SAT<sup>®</sup> for predicting First-Year College Grade Point Average [Internet]</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>The College Board</publisher-name>; <year>2008</year> p. <fpage>16</fpage>. Report No.: 2008–5. Available: <ext-link ext-link-type="uri" xlink:href="https://professionals.collegeboard.com/profdownload/Validity_of_the_SAT_for_Predicting_First_Year_College_Grade_Point_Average.pdf" xlink:type="simple">https://professionals.collegeboard.com/profdownload/Validity_of_the_SAT_for_Predicting_First_Year_College_Grade_Point_Average.pdf</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weitzman</surname> <given-names>RA</given-names></name>. <article-title>The prediction of college achivement by the scholastic aptitude test and the high school record</article-title>. <source>J Educ Meas</source>. <year>2005</year>;<volume>19</volume>: <fpage>179</fpage>–<lpage>191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1745-3984.1982.tb00126.x" xlink:type="simple">10.1111/j.1745-3984.1982.tb00126.x</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sireci</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Talento-Miller</surname> <given-names>E</given-names></name>. <article-title>Evaluating the predictive validity of Graduate Management Admission test scores</article-title>. <source>Educ Psychol Meas</source>. <year>2006</year>;<volume>66</volume>: <fpage>305</fpage>–<lpage>317</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0013164405282455" xlink:type="simple">10.1177/0013164405282455</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>SjöBerg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>SjöBerg</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Näswall</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Sverke</surname> <given-names>M</given-names></name>. <article-title>Using individual differences to predict job performance: Correcting for direct and indirect restriction of range</article-title>. <source>Scand J Psychol</source>. <year>2012</year>;<volume>53</volume>: <fpage>368</fpage>–<lpage>373</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1467-9450.2012.00956.x" xlink:type="simple">10.1111/j.1467-9450.2012.00956.x</ext-link></comment> <object-id pub-id-type="pmid">22612634</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carretta</surname> <given-names>TR</given-names></name>. <article-title>Pilot Candidate Selection Method</article-title>. <source>Aviat Psychol Appl Hum Factors</source>. <year>2011</year>;<volume>1</volume>: <fpage>3</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1027/2192-0923/a00002" xlink:type="simple">10.1027/2192-0923/a00002</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holmes</surname> <given-names>DJ</given-names></name>. <article-title>The robustness of the usual correction for restriction in range due to explicit selection</article-title>. <source>Psychometrika</source>. <year>1990</year>;<volume>55</volume>: <fpage>19</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02294740" xlink:type="simple">10.1007/BF02294740</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gross</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Fleischman</surname> <given-names>L</given-names></name>. <article-title>Restriction of range corrections when both distribution and selection assumptions are violated</article-title>. <source>Appl Psychol Meas</source>. <year>1983</year>;<volume>7</volume>: <fpage>227</fpage>–<lpage>237</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/014662168300700210" xlink:type="simple">10.1177/014662168300700210</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref040"><label>40</label><mixed-citation publication-type="book" xlink:type="simple"><collab>Society for Industrial Organizational Psychology (SIOP)</collab>. <source>Principles for the validation and use of personnel selection procedures [Internet]</source>. <edition>4th ed</edition>. <publisher-loc>Bowling Green, OH</publisher-loc>: <publisher-name>Society for Industrial Organizational Psychology (SIOP)</publisher-name>; <year>2003</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.siop.org/_Principles/principles.pdf" xlink:type="simple">http://www.siop.org/_Principles/principles.pdf</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raju</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Brand</surname> <given-names>PA</given-names></name>. <article-title>Determining the significance of correlations corrected for unreliability and range restriction</article-title>. <source>Appl Psychol Meas</source>. <year>2003</year>;<volume>27</volume>: <fpage>52</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0146621602239476" xlink:type="simple">10.1177/0146621602239476</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graham</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Olchowski</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Gilreath</surname> <given-names>TD</given-names></name>. <article-title>How many imputations are really needed? Some practical clarifications of multiple imputation theory</article-title>. <source>Prev Sci</source>. <year>2007</year>;<volume>8</volume>: <fpage>206</fpage>–<lpage>213</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11121-007-0070-9" xlink:type="simple">10.1007/s11121-007-0070-9</ext-link></comment> <object-id pub-id-type="pmid">17549635</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Inference and missing data</article-title>. <source>Biometrika</source>. <year>1976</year>;<volume>63</volume>: <fpage>581</fpage>–<lpage>592</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/63.3.581" xlink:type="simple">10.1093/biomet/63.3.581</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Von Hippel</surname> <given-names>PT</given-names></name>. <article-title>Biases in SPSS 12.0 Missing Value Analysis</article-title>. <source>Am Stat</source>. <year>2004</year>;<volume>58</volume>: <fpage>160</fpage>–<lpage>164</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1198/0003130043204" xlink:type="simple">10.1198/0003130043204</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref045"><label>45</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Van Buuren</surname> <given-names>S</given-names></name>. <source>Flexible Imputation of Missing Data</source>. <publisher-name>CRC Press</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref046"><label>46</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <source>Multiple imputation for nonresponse in surveys</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2004</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref047"><label>47</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Schafer</surname> <given-names>JL</given-names></name>. <source>Analysis of incomplete multivariate data</source>. <edition>1st ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Chapman and Hall/CRC Press</publisher-name>; <year>1997</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Demirtas</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Freels</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Yucel</surname> <given-names>RM</given-names></name>. <article-title>Plausibility of multivariate normality assumption when multiply imputing non-Gaussian continuous outcomes: a simulation assessment</article-title>. <source>J Stat Comput Simul</source>. <year>2008</year>;<volume>78</volume>: <fpage>69</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/10629360600903866" xlink:type="simple">10.1080/10629360600903866</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref049"><label>49</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>McCullagh</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Nelder</surname> <given-names>JA</given-names></name>. <source>Generalized linear models</source>. <edition>2nd ed</edition>. <publisher-name>CRC Press</publisher-name>; <year>1989</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kemery</surname> <given-names>ER</given-names></name>, <name name-style="western"><surname>Dunlap</surname> <given-names>WP</given-names></name>, <name name-style="western"><surname>Griffeth</surname> <given-names>RW</given-names></name>. <article-title>Correction for variance restriction in point-biserial correlations</article-title>. <source>J Appl Psychol</source>. <year>1988</year>;<volume>73</volume>: <fpage>688</fpage>–<lpage>691</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0021-9010.73.4.688" xlink:type="simple">10.1037/0021-9010.73.4.688</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>MacCallum</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Preacher</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Rucker</surname> <given-names>DD</given-names></name>. <article-title>On the practice of dichotomization of quantitative variables</article-title>. <source>Psychol Methods</source>. <year>2002</year>;<volume>7</volume>: <fpage>19</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037//1082-989X.7.1.19" xlink:type="simple">10.1037//1082-989X.7.1.19</ext-link></comment> <object-id pub-id-type="pmid">11928888</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref052"><label>52</label><mixed-citation publication-type="book" xlink:type="simple"><collab>R Core Team</collab>. <source>A language and environment for statistical computing [Internet]</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name>; <year>2014</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/" xlink:type="simple">http://www.R-project.org/</ext-link></mixed-citation></ref>
<ref id="pone.0152330.ref053"><label>53</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Venables</surname> <given-names>WN</given-names></name>, <name name-style="western"><surname>Ripley</surname> <given-names>BD</given-names></name>. <source>Modern applied statistics with S</source>. <edition>4th ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2002</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>AC</given-names></name>. <article-title>Estimation in mixtures of two normal distributions</article-title>. <source>Technometrics</source>. <year>1967</year>;<volume>9</volume>: <fpage>15</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/1266315" xlink:type="simple">10.2307/1266315</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Buuren</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Groothuis-Oudshoorn</surname> <given-names>K</given-names></name>. <article-title>MICE: Multivariate imputation by chained equations in R</article-title>. <source>J Stat Softw</source>. <year>2011</year>;<volume>45</volume>. Available: <ext-link ext-link-type="uri" xlink:href="http://doc.utwente.nl/78938/" xlink:type="simple">http://doc.utwente.nl/78938/</ext-link> <object-id pub-id-type="pmid">22289957</object-id></mixed-citation></ref>
<ref id="pone.0152330.ref056"><label>56</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Ayyub</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>McCuen</surname> <given-names>RH</given-names></name>. <source>Probability, statistics, and reliability for engineers and scientists</source>. <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>CRC press</publisher-name>; <year>2011</year>.</mixed-citation></ref>
<ref id="pone.0152330.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heckman</surname> <given-names>JJ</given-names></name>. <article-title>Sample selection bias as a specification error</article-title>. <source>Econom J Econom Soc</source>. <year>1979</year>;<volume>47</volume>: <fpage>153</fpage>–<lpage>161</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/1912352" xlink:type="simple">10.2307/1912352</ext-link></comment></mixed-citation></ref>
<ref id="pone.0152330.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heckman</surname> <given-names>JJ</given-names></name>. <article-title>The common structure of statistical models of truncation, sample selection, and limited dependent variables, and a simple estimator for such models</article-title>. <source>Ann Econ Soc Meas</source>. <year>1976</year>;<volume>5</volume>: <fpage>475</fpage>–<lpage>492</lpage>.</mixed-citation></ref>
<ref id="pone.0152330.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Muthén</surname> <given-names>BO</given-names></name>, <name name-style="western"><surname>Hsu</surname> <given-names>J-WY</given-names></name>. <article-title>Selection and predictive validity with latent variable structures†</article-title>. <source>Br J Math Stat Psychol</source>. <year>1993</year>;<volume>46</volume>: <fpage>255</fpage>–<lpage>271</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>