<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-14-47509</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0122205</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>How Feeling Betrayed Affects Cooperation</article-title>
<alt-title alt-title-type="running-head">How Feeling Betrayed Affects Cooperation</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Ramazi</surname> <given-names>Pouria</given-names></name>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hessel</surname> <given-names>Jop</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Cao</surname> <given-names>Ming</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>ENgineering and TEchnology institute Groningen (ENTEG), Faculty of Mathematics and Natural Sciences, University of Groningen, Groningen, The Netherlands</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Xia</surname> <given-names>Cheng-Yi</given-names></name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Tianjin University of Technology, CHINA</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Wrote the paper: PR JH MC.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">p.ramazi@rug.nl</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>29</day>
<month>4</month>
<year>2015</year>
</pub-date>
<volume>10</volume>
<issue>4</issue>
<elocation-id>e0122205</elocation-id>
<history>
<date date-type="received">
<day>22</day>
<month>10</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>2</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Ramazi et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0122205" xlink:type="simple"/>
<abstract>
<p>For a population of interacting self-interested agents, we study how the average cooperation level is affected by some individuals' feelings of being betrayed and guilt. We quantify these feelings as adjusted payoffs in asymmetric games, where for different emotions, the payoff matrix takes the structure of that of either a prisoner's dilemma or a snowdrift game. Then we analyze the evolution of cooperation in a well-mixed population of agents, each of whom is associated with such a payoff matrix. At each time-step, an agent is randomly chosen from the population to update her strategy based on the myopic best-response update rule. According to the simulations, decreasing the feeling of being betrayed in a portion of agents does not necessarily increase the level of cooperation in the population. However, this resistance of the population against low-betrayal-level agents is effective only up to some extend that is explicitly determined by the payoff matrices and the number of agents associated with these matrices. Two other models are also considered where the betrayal factor of an agent fluctuates as a function of the number of cooperators and defectors that she encounters. Unstable behaviors are observed for the level of cooperation in these cases; however, we show that one can tune the parameters in the function to make the whole population become cooperative or defective.</p>
</abstract>
<funding-group>
<funding-statement>The work was supported in part by the European Research Council (ERC-StG-307207) and the EU INTERREG program under the auspices of the SMARTBOT project. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="15"/>
<table-count count="7"/>
<page-count count="29"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>For years, scientists have tried to close the gap between what theoretical game theory predicts and the actual outcome in game theoretic experiments with humans. Classical models in game theory, such as the model of Axelrod [<xref ref-type="bibr" rid="pone.0122205.ref001">1</xref>], predict that defection will be the dominant strategy where the <italic>prisoner’s dilemma (PD)</italic> game is played in a population of rational players. However, cooperative behaviour often does appear in real-life situations, as many social experiments with the prisoner’s dilemma and other public goods games have shown [<xref ref-type="bibr" rid="pone.0122205.ref002">2</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref003">3</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref004">4</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref005">5</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref006">6</xref>]. Previous research has proposed different mechanisms for the promotion of cooperation, e.g., inferring reputation [<xref ref-type="bibr" rid="pone.0122205.ref007">7</xref>], incorporating costly punishment [<xref ref-type="bibr" rid="pone.0122205.ref008">8</xref>], iterating the games [<xref ref-type="bibr" rid="pone.0122205.ref009">9</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref010">10</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref011">11</xref>], using multiplayer games [<xref ref-type="bibr" rid="pone.0122205.ref012">12</xref>], incorporating an interaction network [<xref ref-type="bibr" rid="pone.0122205.ref013">13</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref014">14</xref>], considering multilayer networks [<xref ref-type="bibr" rid="pone.0122205.ref015">15</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref016">16</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref017">17</xref>], considering the individual payoff weighting [<xref ref-type="bibr" rid="pone.0122205.ref018">18</xref>] and integrating the maximal neighbor’s payoff into the fitness in a network game [<xref ref-type="bibr" rid="pone.0122205.ref019">19</xref>]. In addition, several researchers have addressed an important issue that the payoffs stated in the payoff matrix of a game are not necessarily the only payoffs that a player perceives. Often, feelings like guilt and shame play a major role in decision-making in games as found by C. Boone et al [<xref ref-type="bibr" rid="pone.0122205.ref020">20</xref>], Matsumoto et al. [<xref ref-type="bibr" rid="pone.0122205.ref021">21</xref>] and Tabibnia [<xref ref-type="bibr" rid="pone.0122205.ref022">22</xref>], and the actions of players are influenced by emotions. One of the triggers that cause these feelings is that an opponent or the player herself deviates from a social norm [<xref ref-type="bibr" rid="pone.0122205.ref023">23</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref024">24</xref>].</p>
<p>In this article we investigate the effects of including these emotions in the game setups. We extend some of the work of Roger Waldeck [<xref ref-type="bibr" rid="pone.0122205.ref025">25</xref>] where it is assumed that players abide by a commonly known norm and the feeling of <italic>guilt</italic> is introduced in a PD game. An agent experiences the feeling of guilt when she defects while her opponent cooperated. One could also imagine that the opposite could happen, i.e., the player cooperates but now the opponent deviates from the social norm to defect. This would cause the player to feel betrayed. We extend the work of Waldeck by introducing both feelings of guilt and betrayal in a general 2 × 2 two-player game. Based on the feelings the general game can become either a prisoner’s dilemma or a <italic>snowdrift (SD)</italic> game, two well-known games in the field of game theory [<xref ref-type="bibr" rid="pone.0122205.ref026">26</xref>]. We consider the snowdrift game because of its nice property that under the evolutionary dynamics determined by the replicator dynamics [<xref ref-type="bibr" rid="pone.0122205.ref027">27</xref>] and the best response update rule [<xref ref-type="bibr" rid="pone.0122205.ref028">28</xref>], the final population state is in general irrelevant to the initial population state in a group of agents playing the snowdrift game. Such a property is also observed in evolutionary prisoner’s dilemma games, but is less interesting since the final state corresponds to purely defectors. This independence of the initial population state in evolutionary PD and SD games helps us to scrutinize the effects of other factors such as the emotional feelings on the final population state without worrying about the effect of the initial population.</p>
<p>Since we take into consideration emotions, which typically differ for each individual, we use <italic>asymmetric games</italic> to better resemble real-life situations. Different setups have been suggested for studying heterogeneous populations [<xref ref-type="bibr" rid="pone.0122205.ref029">29</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref030">30</xref>]. Moreover, the model in [<xref ref-type="bibr" rid="pone.0122205.ref025">25</xref>] already incorporates asymmetry by considering different levels of guilt among the individuals. We introduce asymmetry in a slightly different way but the concept remains the same. We assign the players with different ‘levels’ of emotions and thereby we create different types of players. We use an agent-based modeling approach to simulate the effects of adding different types of agents in a population. In the computations we assume that the agents in this framework have a <italic>bounded rationality</italic>, i.e., they get some information from the rest of the population and use this to ‘reason’ what would be the next best-move in the game.</p>
<p>We assign agents to have a pure strategy to either cooperate or defect. At each time-step, a randomly chosen agent gets to know the number of the agents who have cooperated (or defected) at the previous time-step, and then updates her strategy accordingly. An interpretation of such a population game is to randomly choose an agent at each time-step to play with all other agents, and then update her strategy accordingly. This interaction can be considered as a special case of the <italic>round-robin tournament</italic>[<xref ref-type="bibr" rid="pone.0122205.ref028">28</xref>] [<xref ref-type="bibr" rid="pone.0122205.ref031">31</xref>] where each agent plays with all other agents. It is assumed that the players in this context are <italic>utility-maximizing</italic> and therefore update their strategies based on their payoff matrices. They update according to the <italic>myopic best response rule</italic>[<xref ref-type="bibr" rid="pone.0122205.ref028">28</xref>], which means that each agent updates by choosing the best reply to the average population in the previous time-step. In other words, based on the last-played strategies in the population, an agent determines the probability of meeting a cooperator (including herself), and calculates her strategy accordingly. This is different from the <italic>imitative update rule</italic>[<xref ref-type="bibr" rid="pone.0122205.ref032">32</xref>] where each agent updates to the strategy of her neighbor with the highest payoff in the last (few) round(s).</p>
</sec>
<sec id="sec002">
<title>Framework</title>
<sec id="sec003">
<title>A game with betrayal and guilt</title>
<p>In this article, we consider 2 × 2, asymmetric, two-player games. Each game involves a row-player and a column-player both of whom having the option to cooperate (C) or to defect (D).</p>
<p>Consider the following general form of 2 × 2 payoff matrices [<xref ref-type="bibr" rid="pone.0122205.ref001">1</xref>] for the row player:
<disp-formula id="pone.0122205.e001"><alternatives><graphic id="pone.0122205.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>π</mml:mi> <mml:mo>=</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mspace width="3.33333pt"/></mml:mtd> <mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd> <mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mtd> <mml:mtd><mml:mrow><mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mi>R</mml:mi></mml:mtd> <mml:mtd><mml:mi>S</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>T</mml:mi></mml:mtd> <mml:mtd><mml:mi>P</mml:mi></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
We call the payoff matrix a <italic>Prisoner’s Dilemma (PD)</italic> payoff matrix if the following condition holds
<disp-formula id="pone.0122205.e002"><alternatives><graphic id="pone.0122205.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e002"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>P</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>S</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
The two inequalities <italic>T</italic> &gt; <italic>R</italic> and <italic>P</italic> &gt; <italic>S</italic> guarantee defection to be a better choice compared to cooperation. The inequality <italic>R</italic> &gt; <italic>P</italic> is to assign mutual cooperation with a higher profit comparing to mutual defection. In addition to the PD case, we call the payoff matrix (<xref ref-type="disp-formula" rid="pone.0122205.e001">Eq 1</xref>) a <italic>Snow Drift (SD)</italic> payoff matrix if the following condition holds
<disp-formula id="pone.0122205.e003"><alternatives><graphic id="pone.0122205.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>S</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>P</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Similarly, here the inequalities <italic>T</italic> &gt; <italic>R</italic> and <italic>S</italic> &gt; <italic>P</italic> determine the choice of strategy of the row player, which makes cooperation a better choice when the opponent defects and defection a better choice when the opponent cooperates; the inequality <italic>R</italic> &gt; <italic>S</italic> advances mutual cooperation over mutual defection.</p>
<p>Another widely used notation for a 2 × 2 snowdrift payoff matrix, which we adopt throughout this paper, is
<disp-formula id="pone.0122205.e004"><alternatives><graphic id="pone.0122205.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e004"/><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mi>D</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>r</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>r</italic> is the <italic>reward</italic> for cooperation and <italic>c</italic> is the <italic>cost</italic> of cooperation. The payoffs of the above payoff matrix represent the <italic>raw payoffs</italic> of the row player [<xref ref-type="bibr" rid="pone.0122205.ref033">33</xref>] and are the “real,” non-emotional payoffs of the game, e.g., the money that one earns out of the game. We call the payoff matrix constructed of only raw payoffs, the <italic>raw-payoff matrix</italic>.</p>
<p>One can also include some <italic>emotional payoffs</italic> in the raw-payoff matrix. The emotional payoffs are those that are not officially stated but do play a major role in decision-making, e.g., the <italic>feeling of guilt</italic> one may have after defecting an opponent who has cooperated. We assume that there is a <italic>social norm</italic> that everybody should adhere to, which is to cooperate [<xref ref-type="bibr" rid="pone.0122205.ref034">34</xref>]. In [<xref ref-type="bibr" rid="pone.0122205.ref025">25</xref>], the feeling of guilt has been stated as an emotion that is perceived when an individual does not adhere to a social norm that all players agreed on. Because players are concerned with not only their own payoffs but also the (fair) distribution of payoffs for others, a player experiences guilt or shame for deviating from the social norm. We also call the feeling of guilt, the <italic>guilt factor</italic> or in short <italic>guilt</italic> and denote it by <italic>g</italic>.</p>
<p>In addition, what we add to this framework is another emotional payoff for the <italic>feeling of being betrayed</italic> which we also call the <italic>betrayal factor</italic> or in short the <italic>betrayal</italic> denoted by <italic>b</italic>. Feeling betrayed is an emotion that is experienced after the opponent breaches a socially accepted norm, i.e., your opponent violates your trust on him. Now since in the setting of this article, cooperation is set as the social norm, we state that a player experiences the feeling of being betrayed when her opponent deviates from the social norm by defecting while the player herself chose to cooperate. Note that here the values of <italic>b</italic>, <italic>g</italic>, <italic>r</italic> and <italic>c</italic> are considered to be positive unless otherwise mentioned.</p>
<p>We integrate the betrayal <italic>b</italic> and the guilt <italic>g</italic> into the raw-payoff matrix and obtain
<disp-formula id="pone.0122205.e005"><alternatives><graphic id="pone.0122205.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e005"/><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mi>D</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>g</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
To explain why <italic>b</italic> and <italic>g</italic> are positioned in the payoff matrix in the way that is stated above, we use the notion of <italic>strategy profile</italic> defined as the couple (<italic>k</italic><sub><italic>i</italic></sub>, <italic>k</italic><sub><italic>j</italic></sub>) where <italic>k</italic><sub><italic>i</italic></sub> and <italic>k</italic><sub><italic>j</italic></sub> are the pure strategies that the row-player <italic>i</italic> and column-player <italic>j</italic> have chosen, respectively. For example, when both players cooperate, the strategy profile is denoted as (<italic>C</italic>, <italic>C</italic>). We add the variables with a negative sign (since they have a negative effect on the payoffs) to the payoff matrix at the location that corresponds to the strategy profile that they are perceived. This means that −<italic>g</italic> is added to the bottom left corner which corresponds to the strategy profile (<italic>D</italic>, <italic>C</italic>) where the row-player defects and the column-player cooperates. On the other hand, −<italic>b</italic> is added to the top-right corner of the payoff matrix corresponding to the strategy profile (<italic>C</italic>, <italic>D</italic>), when the row-player cooperates and the column-player defects.</p>
<p>We set the following constraints on the entries of <italic>A</italic>:
<disp-formula id="pone.0122205.e006"><alternatives><graphic id="pone.0122205.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e006"/><mml:math id="M6" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>c</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mn>2</mml:mn> <mml:mi>g</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula> <disp-formula id="pone.0122205.e007"><alternatives><graphic id="pone.0122205.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>b</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>c</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>2</mml:mn> <mml:mi>r</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
<p>Comparing <italic>A</italic> with the general-form payoff matrix <italic>π</italic>, one can easily see that inequality (<xref ref-type="disp-formula" rid="pone.0122205.e006">Eq 5</xref>) satisfies the inequality <italic>T</italic> &gt; <italic>R</italic> and (<xref ref-type="disp-formula" rid="pone.0122205.e007">Eq 6</xref>) satisfies <italic>R</italic> &gt; <italic>S</italic>, <italic>P</italic>. Now if the inequality <italic>b</italic> &gt; <italic>r</italic> − <italic>c</italic> in <italic>A</italic> or correspondingly <italic>P</italic> &gt; <italic>S</italic> in <italic>π</italic> holds, the payoff matrix becomes a PD payoff matrix. On the other hand, if the inequality <italic>r</italic> − <italic>c</italic> &gt; <italic>b</italic> in <italic>A</italic> or correspondingly <italic>S</italic> &gt; <italic>P</italic> in <italic>π</italic> holds, the payoff matrix becomes an SD payoff matrix. In other words, the magnitude of <italic>b</italic> with respect to <italic>c</italic> determines the type of <italic>A</italic>.</p>
<p>The payoffs in the payoff-matrix <italic>A</italic> are called the <italic>all-in payoffs</italic> of the row player which are her “all-things-considered” payoffs [<xref ref-type="bibr" rid="pone.0122205.ref033">33</xref>]. The all-in payoffs include officially stated payoffs, such as money, as well as the non-officially stated payoffs, such as the feeling of guilt. We call such a payoff matrix, i.e., constructed of all-in payoffs, the <italic>all-in-payoff matrix</italic>. According to the structure of the all-in payoff-matrix <italic>A</italic>, defection is no longer the best choice for a person with a great feeling of guilt, <italic>g</italic>, even when her opponent is cooperating and her raw-payoff matrix is a PD one. On the other hand, cooperation is not the best strategy for a person with a great feeling of being betrayed, <italic>b</italic>, even when her opponent is defecting and her corresponding raw-payoff matrix is an SD one. So in this sense, one can consider the all-in-payoff matrix to be a more “realistic” payoff matrix compared with the raw-payoff matrix.</p>
</sec>
<sec id="sec004">
<title>Types of agents</title>
<p>We consider <italic>n</italic> agents. Each agent <italic>i</italic> is assigned with a payoff matrix <italic>A</italic><sub><italic>i</italic></sub> of the same structure of <italic>A</italic> in (<xref ref-type="disp-formula" rid="pone.0122205.e005">Eq 4</xref>); to be more precise, <italic>A</italic><sub><italic>i</italic></sub> is defined by
<disp-formula id="pone.0122205.e008"><alternatives><graphic id="pone.0122205.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e008"/><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mi>D</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where <italic>g</italic><sub><italic>i</italic></sub> and <italic>b</italic><sub><italic>i</italic></sub> are the guilt and betrayal of agent <italic>i</italic>, respectively and inequalities (<xref ref-type="disp-formula" rid="pone.0122205.e006">Eq 5</xref>) and (<xref ref-type="disp-formula" rid="pone.0122205.e007">Eq 6</xref>) hold when <italic>b</italic> and <italic>g</italic> are replaced by <italic>b</italic><sub><italic>i</italic></sub> and <italic>g</italic><sub><italic>i</italic></sub>, respectively.</p>
<p>Let <italic>n</italic><sub><italic>l</italic></sub> be a non-negative integer. Based on the parameters of <italic>A</italic><sub><italic>i</italic></sub>, each agent belongs to one of the following <italic>n</italic><sub><italic>l</italic></sub> + 1 types:</p>
<p><bold><bold>PD</bold> type:</bold> The payoff matrix assigned to an agent <italic>i</italic> belonging to this type has the following property
<disp-formula id="pone.0122205.e009"><alternatives><graphic id="pone.0122205.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e009"/><mml:math id="M9" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Comparing this payoff matrix with <italic>π</italic>, we know that the inequality <italic>P</italic> &gt; <italic>S</italic> holds in this case. Hence, <italic>A</italic><sub><italic>i</italic></sub> is a PD payoff matrix in this case.</p>
<p><bold><bold>SD</bold><sub><italic>l</italic></sub> type</bold> (<italic>l</italic> = 1,…, <italic>n</italic><sub><italic>l</italic></sub>): The payoff matrix assigned to an agent <italic>i</italic> belonging to this type has the following properties:
<disp-formula id="pone.0122205.e010"><alternatives><graphic id="pone.0122205.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:msub><mml:mi>b</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
Comparing this payoff matrix with <italic>π</italic>, we know that the inequality <italic>S</italic> &gt; <italic>P</italic> holds in this case. Hence, <italic>A</italic><sub><italic>i</italic></sub> is an SD payoff matrix in this case.</p>
<p>We simply call a <italic>PD</italic>-type agent a <italic>PD</italic> agent, and an <italic>SD</italic><sub><italic>l</italic></sub>-type agent an <italic>SD</italic><sub><italic>l</italic></sub> agent. In general, by an <italic><italic>SD</italic> agent</italic> we mean an agent belonging to one of the <italic>SD</italic><sub><italic>l</italic></sub> types. The type of an agent affects her choice of strategy against her opponent. As an illustration, for a <italic>PD</italic> agent it is always better to defect regardless of her opponent’s strategy.</p>
</sec>
<sec id="sec005">
<title>Strategy space and best-response</title>
<p>Denote the probability of a player <italic>i</italic> cooperating to be <italic>x</italic><sub><italic>i</italic></sub>. Then the <italic>mixed strategy</italic> for player <italic>i</italic> which is the probability distribution over her set of pure strategies <italic>C</italic> and <italic>D</italic>, is defined by
<disp-formula id="pone.0122205.e011"><alternatives><graphic id="pone.0122205.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e011"/><mml:math id="M11" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
The <italic>utility function</italic> of player <italic>i</italic> when playing against player <italic>j</italic> is defined by
<disp-formula id="pone.0122205.e012"><alternatives><graphic id="pone.0122205.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e012"/><mml:math id="M12" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="0.222222em"/><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
which according to (<xref ref-type="disp-formula" rid="pone.0122205.e008">Eq 7</xref>) can be written into
<disp-formula id="pone.0122205.e013"><alternatives><graphic id="pone.0122205.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>Define <inline-formula id="pone.0122205.e014"><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the <italic>pure-strategy best-reply correspondence</italic> for player <italic>i</italic> to a strategy <italic>s</italic><sub><italic>j</italic></sub>, as the set of pure strategies <italic>k</italic> ∈ {<italic>C</italic>, <italic>D</italic>} such that no other pure strategy gives her a higher payoff against <italic>s</italic><sub><italic>j</italic></sub> (this definition is in consistent with that in [<xref ref-type="bibr" rid="pone.0122205.ref035">35</xref>]):
<disp-formula id="pone.0122205.e015"><alternatives><graphic id="pone.0122205.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>C</mml:mi> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>:</mml:mo> <mml:mspace width="4pt"/><mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≥</mml:mo> <mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1.em"/><mml:mo>∀</mml:mo> <mml:mi>x</mml:mi> <mml:mo>∈</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>C</mml:mi> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Note that there might be more than one best reply for player <italic>i</italic> to a strategy <italic>s</italic><sub><italic>j</italic></sub>.</p>
<p>In order to calculate the pure-strategy best-reply correspondence, we have to find the pure strategy <italic>k</italic> such that <italic>u</italic><sub><italic>i</italic></sub>(<italic>k</italic>, <italic>s</italic><sub><italic>j</italic></sub>) is maximized. From the definition of <italic>u</italic><sub><italic>i</italic></sub>(⋅,⋅), this is equivalent to player <italic>i</italic> choosing the maximum row of the multiplication <italic>A</italic><sub><italic>i</italic></sub> <italic>s</italic><sub><italic>j</italic></sub>:
<disp-formula id="pone.0122205.e016"><alternatives><graphic id="pone.0122205.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e016"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="true"><mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac></mml:mstyle> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
Player <italic>i</italic> as a row player has to choose that pure strategy corresponding to the maximum entry of the final vector on the right-hand side in (<xref ref-type="disp-formula" rid="pone.0122205.e016">Eq 10</xref>) in order to play her best response. Since Comparing the two entries of that vector <inline-formula id="pone.0122205.e017"><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="true"><mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac></mml:mstyle> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mo>−</mml:mo> <mml:mi>c</mml:mi> <mml:mo>−</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and (<italic>r</italic> − <italic>g</italic><sub><italic>i</italic></sub>)<italic>x</italic><sub><italic>j</italic></sub> is equivalent to compare <inline-formula id="pone.0122205.e018"><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="true"><mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac></mml:mstyle> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>r</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic>c</italic> + <italic>b</italic><sub><italic>i</italic></sub> − <italic>r</italic>, we know that the pure-strategy best-reply correspondence of player <italic>i</italic> is
<disp-formula id="pone.0122205.e019"><alternatives><graphic id="pone.0122205.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e019"/><mml:math id="M19" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>C</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>C</mml:mi> <mml:mspace width="4pt"/><mml:mtext>or</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>D</mml:mi></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mi>D</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
</sec>
<sec id="sec006">
<title>Equilibrium point</title>
<p>Define the <italic>equilibrium point of an <italic>SD</italic><sub><italic>l</italic></sub> agent</italic> with the payoff matrix <italic>A</italic><sub><italic>i</italic></sub> in the general form of <italic>π</italic> in (<xref ref-type="disp-formula" rid="pone.0122205.e001">Eq 1</xref>) to be
<disp-formula id="pone.0122205.e020"><alternatives><graphic id="pone.0122205.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e020"/><mml:math id="M20" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>S</mml:mi> <mml:mo>-</mml:mo> <mml:mi>P</mml:mi></mml:mrow> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>+</mml:mo> <mml:mi>S</mml:mi> <mml:mo>-</mml:mo> <mml:mi>R</mml:mi> <mml:mo>-</mml:mo> <mml:mi>P</mml:mi></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
The equilibrium point has the property that an <italic>SD</italic><sub><italic>l</italic></sub> agent’s best response to an opponent with the cooperation probability lower than (resp. higher than) <inline-formula id="pone.0122205.e021"><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is to cooperate (resp. defect). This property will be used later in the analysis.</p>
<p><bold>Remark 1</bold> <italic>The point</italic> <inline-formula id="pone.0122205.e022"><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> <italic>is the evolutionary stable strategy of the symmetric game with the snow-drift payoff matrix π. Moreover, the strategy profile</italic> <inline-formula id="pone.0122205.e023"><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>l</mml:mi></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> <italic>is the evolutionary stable equilibrium and hence the Nash equilibrium of such a game.</italic></p>
</sec>
<sec id="sec007">
<title>Population Game</title>
<p>Consider a population of <italic>n</italic> agents, each of whom belongs to one of the <italic>n</italic><sub><italic>l</italic></sub> + 1 types explained in subsection 1. For such a population, we define a <italic>population game</italic> as follows. The strategy of each agent is initialized to be either cooperation or defection. Then, at each time-step <italic>t</italic>, an agent <italic>i</italic> is randomly chosen from the whole population to update her strategy. The agent gets to know the ratio of cooperators in the population at <italic>t</italic> − 1, including herself in case her strategy was <italic>C</italic> at <italic>t</italic> − 1. This ratio is denoted by <italic>x</italic><sub><italic>C</italic></sub>(<italic>t</italic> − 1) and is the same as the probability of a randomly chosen agent from the population at time <italic>t</italic> − 1 being a cooperator. Then agent <italic>i</italic> updates her strategy according to the <italic>myopic best response (update) rule</italic> [<xref ref-type="bibr" rid="pone.0122205.ref028">28</xref>] where a small randomness is added: With the probability 0.98, agent <italic>i</italic> updates her strategy to her pure-strategy best-reply correspondence against [<italic>x</italic><sub><italic>C</italic></sub>(<italic>t</italic> − 1), 1 − <italic>x</italic><sub><italic>C</italic></sub>(<italic>t</italic> − 1)]<sup><italic>T</italic></sup>, and the probability 0.02 she randomly chooses from cooperation and defection. In case her pure-strategy best-reply correspondence was either to cooperate or to defect, i.e., both <italic>C</italic> and <italic>D</italic> result in the same payoff, she will keep her pure strategy at time <italic>t</italic> − 1.</p>
<p>Let <italic>p</italic><sub><italic>i</italic></sub>(<italic>t</italic>) denote the pure strategy of agent <italic>i</italic> at the time-step <italic>t</italic>. Also let Θ denote the 2-dimensional simplex, which is the convex combination of the two unit-vectors [1, 0]<sup><italic>T</italic></sup> and [0, 1]<sup><italic>T</italic></sup>. Following the definition of best reply correspondence, we define the <italic>i</italic>th player’s <italic>pure-strategy best-reply function</italic> <italic>β</italic><sub><italic>i</italic></sub>:Θ × ℝ → {<italic>C</italic>, <italic>D</italic>} at time <italic>t</italic> to be
<disp-formula id="pone.0122205.e024"><alternatives><graphic id="pone.0122205.e024g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e024"/><mml:math id="M24" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>β</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>C</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mi>D</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
Although for the case of <inline-formula id="pone.0122205.e025"><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>r</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> becoming equal to <italic>c</italic> + <italic>b</italic><sub><italic>i</italic></sub> − <italic>r</italic>, any strategy that player <italic>i</italic> chooses is a best response, we limit her to play her pure strategy at the previous time-step, <italic>p</italic><sub><italic>i</italic></sub>(<italic>t</italic> − 1), in this case. The players in this context are confined to pure strategies; hence, we also call the pure-strategy best-reply function the <italic>best reply</italic> or <italic>best response</italic>.</p>
<p>Now the population game can be summarized as follows.
<list list-type="bullet"><list-item><p>Each agent is initially programed to a pure strategy: <italic>C</italic> or <italic>D</italic>.</p></list-item> <list-item><p>At each time-step <italic>t</italic>, an agent <italic>i</italic> is randomly chosen from the population to update her strategy.</p></list-item> <list-item><p>Agent <italic>i</italic> updates her strategy to <inline-formula id="pone.0122205.e026"><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>β</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> with the probability 0.98 and chooses a random strategy from the set {<italic>C</italic>, <italic>D</italic>} with the probability 0.02.</p></list-item></list></p>
<p><bold>Remark 2</bold> <italic>The fact that an agent i updates her strategy to β<sub>i</sub>(x<sub>C</sub>(t − 1), t) is equivalent to the situation when an agent i updates her strategy to the best reply against a randomly chosen agent from the population including herself. The strategy [x<sub>C</sub>(t − 1) 1 − x<sub>C</sub>(t − 1)]<sup>T</sup> can be considered as the “average population’s strategy” at time t − 1. Hence, agent i is updating her strategy to the best response against the average population at the previous time-step.</italic></p>
</sec>
</sec>
<sec id="sec008">
<title>Multiple types of agents in a population</title>
<p>After introducing the feeling of being betrayed and how it can be implemented in the payoff matrix of an agent, now we are interested in studying how the betrayal factor affects the evolution of the strategies of different agents in a population under the best-response update rule. In this section, a population of different types of agents having different betrayals, whose strategies evolve according to the best-response update rule, is investigated through simulations. The goal is to understand the effects of the betrayal factors assigned to the agents on the final level of cooperation in the population. We start with a population including only two different types and then, populations involving three types are taken into account. Lastly, we draw some conclusions for a setting where the population consists of a large, finite number of types of agents.</p>
<sec id="sec009">
<title>Two types of agents</title>
<p>A population of 100 agents belonging to one of the two types <italic>PD</italic> or <italic>SD</italic><sub>1</sub> is studied. The following values are used for the parameters in the corresponding payoff matrices of the types of agents, <italic>A</italic><sub><italic>i</italic></sub>s:
<disp-formula id="pone.0122205.e027"><alternatives><graphic id="pone.0122205.e027g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e027"/><mml:math id="M27" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>5</mml:mn> <mml:mo>,</mml:mo> <mml:mspace width="4pt"/><mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mspace width="4pt"/><mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mspace width="2.em"/><mml:mo>∀</mml:mo> <mml:mi>i</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>5</mml:mn> <mml:mspace width="1.em"/><mml:mtext>when</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>agent</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>i</mml:mi> <mml:mspace width="4.pt"/><mml:mtext>is</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>a</mml:mtext> <mml:mspace width="4.pt"/><mml:mrow><mml:mi>P</mml:mi> <mml:mi>D</mml:mi></mml:mrow> <mml:mspace width="4.pt"/><mml:mtext>type</mml:mtext> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>3</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mspace width="1.em"/><mml:mtext>when</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>agent</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>i</mml:mi> <mml:mspace width="4.pt"/><mml:mtext>is</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>an</mml:mtext> <mml:mspace width="4.pt"/><mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mspace width="4.pt"/><mml:mtext>type,</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>i.e.,</mml:mtext> <mml:mspace width="4.pt"/><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>3</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
With these agents, we do simulations in MATLAB considering different compositions of the types. In each simulation, a fixed mixture of <italic>PD</italic> and <italic>SD</italic><sub>1</sub> agents play the population game explained in Subsection 1, for 1000 iterations. The initial number of cooperators is set to 20. Then the ratio of cooperators with respect to the number of iterations is plotted. To see the average outcome, an average of 20 simulations are depicted in the figures.</p>
<p>The results when having 25 <italic>SD</italic><sub>1</sub> agents and 75 <italic>PD</italic> agents are shown in <xref ref-type="fig" rid="pone.0122205.g001">Fig 1</xref>. The figure shows that the total number of cooperators in the population quickly converges to the number of <italic>SD</italic><sub>1</sub> agents. In order to understand the behavior of the agents described above, we need to examine the best response of each type, which is done by studying the all-in-payoff matrix of the different types of agents. The all-in payoff matrices of the two types of agents are:
<disp-formula id="pone.0122205.e028"><alternatives><graphic id="pone.0122205.e028g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e028"/><mml:math id="M28" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mi>D</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>4.5</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>5</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula> <disp-formula id="pone.0122205.e029"><alternatives><graphic id="pone.0122205.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e029"/><mml:math id="M29" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>C</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>4.5</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>5</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula>
From the <italic>PD</italic> payoff matrix it can be seen that pure defection is the best option, i.e., no matter what the opponent’s strategy is, it is always best for the agent to defect. Correspondingly, one may say that defection is an equilibrium for <italic>PD</italic> agents. For the <italic>SD</italic><sub>1</sub> type payoff matrix, there is no pure equilibrium. Indeed, for <italic>SD</italic><sub>1</sub> agents it is most beneficial that one part of the population cooperates and the other part defects. To calculate how many cooperators and defectors are optimal for a particular <italic>SD</italic><sub>1</sub> agent, we use <xref ref-type="disp-formula" rid="pone.0122205.e020">Eq (11)</xref> to derive the mixed strategy equilibrium point: <inline-formula id="pone.0122205.e030"><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>S</mml:mi> <mml:mo>−</mml:mo> <mml:mi>P</mml:mi></mml:mrow> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>+</mml:mo> <mml:mi>S</mml:mi> <mml:mo>−</mml:mo> <mml:mi>R</mml:mi> <mml:mo>−</mml:mo> <mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. Replacing <italic>T</italic>, <italic>S</italic>, <italic>R</italic> and <italic>P</italic> by the values from the payoff matrix of the <italic>SD</italic><sub>1</sub> agents, <italic>A</italic><sub><italic>SD</italic><sub>1</sub></sub>, results in <inline-formula id="pone.0122205.e031"><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>. This implies that an <italic>SD</italic><sub>1</sub> agent “strives” for a population with 50% cooperators. In other words, an <italic>SD</italic><sub>1</sub> agent tries to modify her strategy in such a way that the ratio of cooperators in the population approaches this equilibrium point, <inline-formula id="pone.0122205.e032"><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. Therefore, an <italic>SD</italic><sub>1</sub> agent will defect when the ratio of cooperators in the population is greater than <inline-formula id="pone.0122205.e033"><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and will cooperate when the ratio of cooperators has not yet reached the equilibrium point.</p>
<fig id="pone.0122205.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Percentage of cooperators when there are 75 <italic>PD</italic> and 25 <italic>SD</italic> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g001"/>
</fig>
<p>Now consider <xref ref-type="fig" rid="pone.0122205.g001">Fig 1</xref> again. There are 75 <italic>PD</italic> agents in the corresponding population who always defect after a while, i.e., after when they have gotten the chance to update their initial strategies. For the <italic>SD</italic><sub>1</sub> agents on the other hand, it is most profitable to have a ratio of <inline-formula id="pone.0122205.e034"><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> cooperators in the whole population. In other words, <italic>SD</italic><sub>1</sub> agents aim to make the total number of cooperators in the population 50 and the total number of defectors also 50. However, the <italic>PD</italic> agents have already occupied 75 agents of the population, and they all defect. So there are only 25 spots left to cooperate. Hence, the best the <italic>SD</italic><sub>1</sub> agents can do is that all of them cooperate in order to get as close as possible to their ideal equilibrium point which happens with 50 cooperators. Hence, all <italic>SD</italic><sub>1</sub> agents will cooperate in the final state while all the <italic>PD</italic> agents defect. In other words, all the agents with the lower level of the betrayal factor (<italic>SD</italic><sub>1</sub>s) cooperate and all the agents with the higher level of the betrayal factor (<italic>PD</italic>s) defect in the final state. The number of cooperators and defectors for each type of agents in the final state are provided in <xref ref-type="table" rid="pone.0122205.t001">Table 1</xref> where <italic>n</italic><sub><italic>C</italic></sub> and <italic>n</italic><sub><italic>D</italic></sub> are the number of cooperators and defectors, respectively.</p>
<table-wrap id="pone.0122205.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t001</object-id>
<label>Table 1</label>
<caption>
<title>Agents’ strategies when there are 75 <italic>PD</italic> and 25 <italic>SD</italic><sub>1</sub> agents.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t001g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t001"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Type</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of cooperators</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of defectors</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Total number</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>PD</italic></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">75</td>
<td align="left" rowspan="1" colspan="1">75</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic></td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">25</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Total</bold></td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">75</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>One may guess that the number of the agents with the lower betrayal factor always determines the total number of cooperators in the final state of the population game. However, <xref ref-type="fig" rid="pone.0122205.g002">Fig 2</xref> shows that such a conjecture is wrong. The figure shows the changes in the ratio of cooperators in the population when having 75 <italic>SD</italic><sub>1</sub> agents and 25 <italic>PD</italic> agents. As can be seen, the total number of cooperators in the population does not become equal to the number of <italic>SD</italic><sub>1</sub> agents in this case, but converges to a lower number, 50 (see <xref ref-type="table" rid="pone.0122205.t002">Table 2</xref>). In this case, the number of <italic>SD</italic><sub>1</sub> agents, 75, is enough to provide the number of cooperators required for the equilibrium point <inline-formula id="pone.0122205.e035"><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>. Hence, even though all the <italic>PD</italic> agents defect in the final state here as well as in the previous case, 50 of the <italic>SD</italic><sub>1</sub> agents cooperate, and the rest join the <italic>PD</italic> agents by defecting in order to make the total number of cooperators in the population equal to that of the equilibrium point <inline-formula id="pone.0122205.e036"><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. In this case, agents with a lower level of the betrayal factor are able to balance the strategies of the agents in the population in order to reach their desired number of cooperators. This is simply because the number of agents that feel less betrayed is greater than the required number of cooperators at the equilibrium point of these agents.</p>
<fig id="pone.0122205.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Percentage of cooperators when there are 25 <italic>PD</italic> and 75 <italic>SD</italic><sub>1</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g002"/>
</fig>
<table-wrap id="pone.0122205.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t002</object-id>
<label>Table 2</label>
<caption>
<title>Agents’ strategies when there are 25 <italic>PD</italic> and 75 <italic>SD</italic><sub>1</sub> agents.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t002g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t002"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Type</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of cooperators</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of defectors</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Total number</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>PD</italic></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">25</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic></td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">25</td>
<td align="left" rowspan="1" colspan="1">75</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Total</bold></td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In order to show that the initial number of cooperators does not affect the final number of cooperators, we add <xref ref-type="fig" rid="pone.0122205.g003">Fig 3</xref> where the population starts with different numbers of cooperators. As can be seen, no matter what the initial strategies of the agents are, and hence, how great the initial ratio of cooperators in the population is, the total number of cooperators in the population converges to the same value.</p>
<fig id="pone.0122205.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Percentage of cooperators when there are 25 <italic>PD</italic> and 75 <italic>SD</italic><sub>1</sub> agents.</title>
<p>Four different initial numbers of cooperators are examined.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g003"/>
</fig>
<p>Now to further investigate how the number of agents having a lower value of betrayal factor, i.e., the <italic>SD</italic><sub>1</sub> types, affects the final level of cooperation in the population, we conduct 101 different simulations as follows: One simulation where all of the 100 agents are <italic>PD</italic> type, one where one agent is an <italic>SD</italic><sub>1</sub> type and the rest are <italic>PD</italic> type, one where two of the agents are <italic>SD</italic><sub>1</sub> and the rest are <italic>PD</italic>, and so on until where all of the 100 agents are <italic>SD</italic><sub>1</sub> type. In each simulation, the number of cooperators in the population is averaged from iteration number 700 to 1000. Consider this to be the <italic>steady state</italic> for this combination of <italic>SD</italic> and <italic>PD</italic> agents. The resulting steady states of each of these 101 simulations are depicted in <xref ref-type="fig" rid="pone.0122205.g004">Fig 4</xref>.</p>
<fig id="pone.0122205.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Percentage of cooperators when there are different portions of <italic>SD</italic><sub>1</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g004"/>
</fig>
<p>As can be seen, the ratio of cooperators starts from zero and grows constantly as the ratio of <italic>SD</italic><sub>1</sub> agents increases. At the equilibrium point of the <italic>SD</italic><sub>1</sub> agents, i.e., <inline-formula id="pone.0122205.e037"><mml:math id="M37" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, this growth stops and the curve stays at a fixed percentage of cooperators while the number of <italic>SD</italic><sub>1</sub> agents continues to increase. The reason for this phenomenon lies in what we saw in the previous examples. Based upon the payoff matrix of the <italic>PD</italic> agents, we know full defection is always the best strategy for the <italic>PD</italic> agents. This implies that all of the <italic>PD</italic> agents will defect after they get the chance to update for the first time. This explains why the curve starts from the origin: When the population is completely made of <italic>PD</italic> agents, there will be no cooperators in the steady state. Moreover, because of the defection of all <italic>PD</italic> agents, the portion of cooperators in the population depends solely upon the portion of <italic>SD</italic><sub>1</sub> agents. Therefore, there is a linear relation in the graph between the portion of <italic>SD</italic><sub>1</sub> agents and the level of cooperation for portions of <italic>SD</italic><sub>1</sub> agents lower than <inline-formula id="pone.0122205.e038"><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. In other words, up to <inline-formula id="pone.0122205.e039"><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> the percentage of <italic>SD</italic><sub>1</sub> agents in the population is so low that it is beneficial for all of the <italic>SD</italic><sub>1</sub> agents to cooperate. Beyond this equilibrium, however, it is no longer beneficial for every <italic>SD</italic><sub>1</sub> agent to cooperate and some will start to defect so that the equilibrium point is maintained.</p>
<p>To conclude, in a population with two different types of agents there is a critical point for the number of agents with a lower betrayal factor. While the number of agents with the lower betrayal factor is smaller than that critical point, they all prefer to cooperate and raise the average level of cooperation. However, after the number of agents that feel less betrayed passes that critical point, their selfishness steps in and does not allow more cooperation to appear in the population.</p>
</sec>
<sec id="sec010">
<title>Three types of agents</title>
<p>Continuing with the previous subsection, we now add yet another type of agents to the population who again have an <italic>SD</italic> payoff matrix, but not exactly as the previous ones. This is done because we are interested in knowing how two conflicting equilibria of different <italic>SD</italic> agents will resolve. Adding another <italic>PD</italic> type of agents would not change much because the equilibrium of all <italic>PD</italic> agents is pure defection, which would be similar to adding more <italic>PD</italic> agents of the same type.</p>
<p>We run the simulations with the same settings as before. The same payoff matrices for the <italic>PD</italic> and <italic>SD</italic><sub>1</sub> agents are used and for the new type of agents, i.e., the <italic>SD</italic><sub>2</sub> agents, we set <italic>b</italic><sub><italic>i</italic></sub> = 2.5. The all-in-payoff matrix of every <italic>SD</italic><sub>2</sub> agent then becomes:
<disp-formula id="pone.0122205.e040"><alternatives><graphic id="pone.0122205.e040g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e040"/><mml:math id="M40" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mn>4.5</mml:mn><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1.5</mml:mn><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>5</mml:mn><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="2pt"/><mml:mspace width="2pt"/></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="2pt"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula>
Based on this payoff matrix, the equilibrium point for an <italic>SD</italic><sub>2</sub> agent is <inline-formula id="pone.0122205.e041"><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula> which is the desired ratio of cooperators in the population for the <italic>SD</italic><sub>2</sub> agents.</p>
<p>We examine the behaviour of each of the types of agents in the population in a similar procedure to Section <bold>Two types of agents</bold>. Recall that for the <italic>PD</italic> and <italic>SD</italic><sub>1</sub> agents, the desired equilibria implied 0 and 50 cooperators respectively. Firstly, we consider a case where the population consists of 60 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 20 <italic>SD</italic><sub>2</sub> agents. The percentage of cooperators with respect to the time-steps is plotted in <xref ref-type="fig" rid="pone.0122205.g005">Fig 5</xref>. In this situation the <italic>PD</italic> agents will still be defecting. On the other hand, the <italic>SD</italic> agents will cooperate because the sum of both types of <italic>SD</italic> agents is lower than the lowest equilibrium of the two types of agents. This means that for both <italic>SD</italic> agents the equilibrium is not yet reached and the best strategy to approach this equilibrium is for them to cooperate. The results at the final state are summarized in <xref ref-type="table" rid="pone.0122205.t003">Table 3</xref>.</p>
<fig id="pone.0122205.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Percentage of cooperators when there are 60 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 20 <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g005"/>
</fig>
<table-wrap id="pone.0122205.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t003</object-id>
<label>Table 3</label>
<caption>
<title>Agents’ strategies when there are 60 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 20 <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t003g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t003"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Type</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of cooperators</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of defectors</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Total number</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>PD</italic></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">60</td>
<td align="left" rowspan="1" colspan="1">60</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">20</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">20</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Total</bold></td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">60</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The situation changes when the total number of potential cooperators in the population, i.e., <italic>SD</italic> agents, rises above 50 which is the equilibrium point of the <italic>SD</italic><sub>1</sub> agents. Then, some of the <italic>SD</italic><sub>1</sub> agents, who have the medium level of the betrayal factor among the three available types of agents in the population will start to defect to maintain their equilibrium, <inline-formula id="pone.0122205.e042"><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula>, as mentioned before. We summarize the behaviour of the agents in <xref ref-type="table" rid="pone.0122205.t004">Table 4</xref>, where we consider a population with 40 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 40 <italic>SD</italic><sub>2</sub> agents.</p>
<table-wrap id="pone.0122205.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t004</object-id>
<label>Table 4</label>
<caption>
<title>Agents’ strategies when there are 40 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 40 <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t004g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t004"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Type</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of cooperators</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of defectors</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Total number</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>PD</italic></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">40</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">20</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">40</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">40</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Total</bold></td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">50</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In <xref ref-type="table" rid="pone.0122205.t004">Table 4</xref>, one can see that 10 <italic>SD</italic><sub>1</sub> agents defect to maintain the equilibrium of 50 cooperators. All of the <italic>SD</italic><sub>2</sub> agents, who have the lowest level of the betrayal factor, cooperate because they want the population to reach 75 cooperators in the population.</p>
<p>This process is continued until all of the <italic>SD</italic><sub>1</sub> agents defect and they can no longer maintain their equilibrium. In other words, if the number of <italic>SD</italic><sub>2</sub> agents becomes more than 50, also the ratio of cooperators in the population will grow beyond that of <inline-formula id="pone.0122205.e043"><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula> as can be seen in <xref ref-type="table" rid="pone.0122205.t005">Table 5</xref>.</p>
<table-wrap id="pone.0122205.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t005</object-id>
<label>Table 5</label>
<caption>
<title>Agents’ strategies when there are 29 <italic>PD</italic>, 20 <italic>SD</italic><sub>1</sub> and 51 <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t005g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t005"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Type</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of cooperators</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Number of defectors</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Total number</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>PD</italic></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">29</td>
<td align="left" rowspan="1" colspan="1">29</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">20</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>SD</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">51</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">51</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Total</bold></td>
<td align="left" rowspan="1" colspan="1">51</td>
<td align="left" rowspan="1" colspan="1">49</td>
<td align="left" rowspan="1" colspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>As for the case of two types of agents we can plot all of the steady states for the different combinations of <italic>PD</italic>, <italic>SD</italic><sub>1</sub> and <italic>SD</italic><sub>2</sub> agents in one figure. For example, <xref ref-type="fig" rid="pone.0122205.g006">Fig 6</xref> shows the steady states of the percentage of cooperators for different combinations of <italic>SD</italic><sub>2</sub> and <italic>PD</italic> agents who have the lowest and highest levels of the feeling of being betrayed, while having the number of <italic>SD</italic><sub>1</sub> agents fixed to 20. The figure includes the cases of the previous tables. As can be seen, in the absence of the <italic>SD</italic><sub>2</sub> agents, all <italic>SD</italic><sub>1</sub> agents, who now are the type with the least betrayal factor in the population, cooperate in the final state. That is why the curve starts from 20 percentage cooperation in the steady state. By the introduction of some even more cooperative type of agents, i.e., <italic>SD</italic><sub>2</sub>s, the total number of cooperators in the long run increases, but only up to some level where the selfishness of the agents with the medium feeling of being betrayed, i.e., <italic>SD</italic><sub>1</sub>s, rises and tries to maintain the level of cooperation at their own desired level. However, after a while, by further increasing the number of the agents that have the least feeling of being betrayed, i.e., <italic>SD</italic><sub>2</sub>s, the agents with the medium level of the betrayal factor, i.e., <italic>SD</italic><sub>1</sub>s, can no longer balance the total number of cooperators. Then the average cooperation level in the population rises by the increments in the number of the agents with the lowest feeling of being betrayed, but limits off at the point where the selfishness of this even very unselfish group shows up.</p>
<fig id="pone.0122205.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Percentage of cooperators when there are 20 <italic>SD</italic><sub>1</sub> and varying <italic>PD</italic> and <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g006"/>
</fig>
<p>Another scenario is plotted in <xref ref-type="fig" rid="pone.0122205.g007">Fig 7</xref> where there are 40 <italic>SD</italic><sub>1</sub> agents and the number of <italic>PD</italic> and <italic>SD</italic><sub>2</sub> agents vary in the <italic>x</italic>-axis. As can be seen, the number of <italic>SD</italic><sub>1</sub> agents, i.e., the number of the agents with the medium betrayal factor, is so big that they do not allow the most cooperative type that has the lowest level of the feeling of being betrayed, i.e., <italic>SD</italic><sub>2</sub>, to reach its equilibrium even when <italic>SD</italic><sub>2</sub> agents have their highest possible portion of the population.</p>
<fig id="pone.0122205.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Percentage of cooperators when there are 40 <italic>SD</italic><sub>1</sub> and varying <italic>PD</italic> and <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g007"/>
</fig>
<sec id="sec011">
<title>A comprehensive 3D plot of the results</title>
<p>One may plot the steady states of the percentage of cooperators for all different combinations of <italic>PD</italic>, <italic>SD</italic><sub>1</sub> and <italic>SD</italic><sub>2</sub> agents in one figure. This results in the 3D plotting of <xref ref-type="fig" rid="pone.0122205.g008">Fig 8</xref>. Each point in <xref ref-type="fig" rid="pone.0122205.g008">Fig 8</xref> is a representation of the steady state of a population with a certain number of <italic>PD</italic>, <italic>SD</italic><sub>1</sub> and <italic>SD</italic><sub>2</sub> agents. Note that the curves in <xref ref-type="fig" rid="pone.0122205.g007">Fig 7</xref> and <xref ref-type="fig" rid="pone.0122205.g006">Fig 6</xref> are two vertical slices of this 3D figure. One can distinguish two horizontal areas and two sloped areas in <xref ref-type="fig" rid="pone.0122205.g008">Fig 8</xref>. In the large horizontal area of the figure, marked with blue lines and denoted by <inline-formula id="pone.0122205.e044"><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, all of the steady states are equal to the equilibrium of the <italic>SD</italic><sub>1</sub> agents. There, the <italic>SD</italic><sub>1</sub> agents have been able to maintain their desired level of cooperators by modifying their strategy accordingly. The same holds for the smaller horizontal area denoted by <inline-formula id="pone.0122205.e045"><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> where the <italic>SD</italic><sub>2</sub> agents have maintained their equilibrium.</p>
<fig id="pone.0122205.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Percentage of cooperators when there are different portions of <italic>SD</italic><sub>1</sub> and <italic>SD</italic><sub>2</sub> agents.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g008"/>
</fig>
<p>In the sloped areas, the steady state of the population lies between two equilibria. In the main sloped area, coloured blue to yellow, the number of <italic>SD</italic> agents is relatively low and therefore the steady states lay between <inline-formula id="pone.0122205.e046"><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>D</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="pone.0122205.e047"><mml:math id="M47" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>. The points in the sloped area in red obviously lay between the equilibrium points of both of the SD agents, <inline-formula id="pone.0122205.e048"><mml:math id="M48" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="pone.0122205.e049"><mml:math id="M49" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
<p>We can explain the occurrence of these flat areas in the figure by looking at the equilibrium points of each of these types of agents. Each type of agent has a certain equilibrium point in terms of the ratio of cooperators in the population. For the <italic>PD</italic> agents this is zero, as mentioned before, because it is always most beneficial to defect according to their payoff matrices. Naturally, a <italic>PD</italic> agent which carries the highest level of the feeling of being betrayed among the agents, receives the greatest payoff when defecting while her opponent cooperates. This behaviour is called <italic>free-riding</italic>: Enjoying the contributions of others while not paying any of the costs. This is not the case for <italic>SD</italic> agents who have lower levels of the feeling of being betrayed. They receive the highest payoffs when the portion of cooperators in the population is optimally divided in two parts for this particular type of <italic>SD</italic> agents. Consequently, in a population with different types of <italic>SD</italic> agents these equilibria are conflicting. Each agent will strive to maintain or approach its own equilibrium point by modifying her strategy in such a way that the portion of cooperators approaches her equilibrium point which is of course determined by her betrayal factor.</p>
<p>For example, with the current settings, the <italic>SD</italic><sub>1</sub> agents will strive for an equilibrium of 50 cooperators. Up to this equilibrium, each <italic>SD</italic><sub>1</sub> agent will cooperate, as well as the <italic>SD</italic><sub>2</sub> agents, whose equilibrium point is even greater. This explains the main sloped-area, colored blue to yellow. However, above this point of 50 cooperators, the <italic>SD</italic><sub>1</sub> agents will start to defect to ‘neutralise’ the behaviour of others and maintain this equilibrium point. This illustrates the rectangular-shaped horizontal area. <italic>SD</italic><sub>2</sub> agents who feel the lowest level of being betrayed, will still be cooperating because they want an equilibrium with a higher ratio of cooperators. This continues until all of the <italic>SD</italic><sub>1</sub> agents defect and all <italic>SD</italic><sub>2</sub> agents cooperate. Then the number of <italic>SD</italic><sub>2</sub> agents is enough to reach the number of cooperators at their equilibrium point <inline-formula id="pone.0122205.e050"><mml:math id="M50" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mrow><mml:mi>S</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. This explains the sloped area in red. Afterwards, the selfishness of the <italic>SD</italic><sub>2</sub> agents forces them to balance the number of cooperators and defectors in the population to maintain their equilibrium while all <italic>PD</italic> and <italic>SD</italic><sub>1</sub> agents are defecting. This explains the triangle-shaped horizontal area on the top.</p>
<p>In short, based on the simulations, increasing the number of low-betrayal-level agents does not necessarily increase the average cooperation level in the population. Indeed, it depends on how the betrayal factor is distributed among the agents. For example, if the number of low-betrayal-level agents is big enough so that the average level of cooperation is already affected by these agents, then increasing the number of low-betrayal-level agents almost always increases the average cooperation level. On the other hand, if the number of low-betrayal-level agents is small compared to that of the high-betrayal-level agents so that the average level of cooperation is totally determined by high-betrayal-level agents, then almost always, increasing the number of low-betrayal-level agents does not change the average cooperation level. The reason is that high-betrayal-level agents will compensate this addition by defecting. However, this resistance of the high-betrayal-level agents is only up to some level. In other words, if we keep increasing the number of low-betrayal-level agents, after some point, finally the cooperation level starts to increase. This is because even though all of the high-betrayal-level agents will defect, their population size is limited and cannot compensate a large number of cooperators in the population.</p>
</sec>
</sec>
<sec id="sec012">
<title>Large number of different types of agents</title>
<p>After simulating with 2 and 3 different types of agents in a population, we find that different equilibria can be attained in a population with multiple types of agents by changing the number of agents of a certain type. We extend this work by studying a population with a large but finite number of different types by using a <italic>normal distribution</italic> of the betrayal factor <italic>b</italic><sub><italic>i</italic></sub> over the agents. Different mean (<italic>μ</italic>) and variance (<italic>σ</italic>) values are used for this normal distribution to see the impact of these factors.</p>
<p>In general, to be able to predict the number of cooperators in the steady state, one can use the previous analysis of the behaviour of different types of agents:
<list list-type="bullet"><list-item><p>All of the agents want to reach and maintain their equilibrium by adapting their strategy accordingly.</p></list-item> <list-item><p>All of the <italic>PD</italic> agents always defect in the steady state.</p></list-item></list>
From the previous simulations we know that the number of cooperators in the steady state is mainly determined by the equilibrium point of a certain type of agents. We use the average equilibrium point of all of the agents in the population to predict the ratio of cooperators in the final state. The results of the simulations with a normally distributed <italic>b</italic><sub><italic>i</italic></sub> are compared with the values of the average equilibrium and are stated in <xref ref-type="table" rid="pone.0122205.t006">Table 6</xref>.</p>
<table-wrap id="pone.0122205.t006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t006</object-id>
<label>Table 6</label>
<caption>
<title>Results for 100 different types of agents for several settings with normally distributed <italic>b</italic><sub><italic>i</italic></sub>.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t006g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t006"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>a</bold></th>
<th align="left" rowspan="1" colspan="1"><bold><italic>μ</italic></bold></th>
<th align="left" rowspan="1" colspan="1"><bold><italic>σ</italic></bold></th>
<th align="left" rowspan="1" colspan="1"><bold>average b</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>long-term ratio of cooperators from simulation</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>long-term ratio of cooperators from calculation</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>difference</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">1,4</td>
<td align="left" rowspan="1" colspan="1">0,8429</td>
<td align="left" rowspan="1" colspan="1">0,838709677</td>
<td align="left" rowspan="1" colspan="1">-0,004190323</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">1,133</td>
<td align="left" rowspan="1" colspan="1">0,8522</td>
<td align="left" rowspan="1" colspan="1">0,851499851</td>
<td align="left" rowspan="1" colspan="1">-0,000700149</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1,08</td>
<td align="left" rowspan="1" colspan="1">0,8521</td>
<td align="left" rowspan="1" colspan="1">0,85380117</td>
<td align="left" rowspan="1" colspan="1">0,00170117</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">2,4</td>
<td align="left" rowspan="1" colspan="1">0,7814</td>
<td align="left" rowspan="1" colspan="1">0,761904762</td>
<td align="left" rowspan="1" colspan="1">-0,019495238</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">2,133</td>
<td align="left" rowspan="1" colspan="1">0,7923</td>
<td align="left" rowspan="1" colspan="1">0,788762146</td>
<td align="left" rowspan="1" colspan="1">-0,003537854</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">2,08</td>
<td align="left" rowspan="1" colspan="1">0,7922</td>
<td align="left" rowspan="1" colspan="1">0,79338843</td>
<td align="left" rowspan="1" colspan="1">0,00118843</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">3,4</td>
<td align="left" rowspan="1" colspan="1">0,6452</td>
<td align="left" rowspan="1" colspan="1">0,545454545</td>
<td align="left" rowspan="1" colspan="1">-0,099745455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">3,144</td>
<td align="left" rowspan="1" colspan="1">0,6417</td>
<td align="left" rowspan="1" colspan="1">0,631268437</td>
<td align="left" rowspan="1" colspan="1">-0,010431563</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3,08</td>
<td align="left" rowspan="1" colspan="1">0,6521</td>
<td align="left" rowspan="1" colspan="1">0,647887324</td>
<td align="left" rowspan="1" colspan="1">-0,004212676</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">4,4</td>
<td align="left" rowspan="1" colspan="1">0,0072</td>
<td align="left" rowspan="1" colspan="1">-4</td>
<td align="left" rowspan="1" colspan="1">-4,0072</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">4,133</td>
<td align="left" rowspan="1" colspan="1">0,008</td>
<td align="left" rowspan="1" colspan="1">-0,36239782</td>
<td align="left" rowspan="1" colspan="1">-0,37039782</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">4,08</td>
<td align="left" rowspan="1" colspan="1">0,0141</td>
<td align="left" rowspan="1" colspan="1">-0,19047619</td>
<td align="left" rowspan="1" colspan="1">-0,20457619</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">5,4</td>
<td align="left" rowspan="1" colspan="1">0,0058</td>
<td align="left" rowspan="1" colspan="1">1,555555556</td>
<td align="left" rowspan="1" colspan="1">1,549755556</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">5,133</td>
<td align="left" rowspan="1" colspan="1">0,0067</td>
<td align="left" rowspan="1" colspan="1">1,789889415</td>
<td align="left" rowspan="1" colspan="1">1,783189415</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">5,08</td>
<td align="left" rowspan="1" colspan="1">0,0083</td>
<td align="left" rowspan="1" colspan="1">1,862068966</td>
<td align="left" rowspan="1" colspan="1">1,853768966</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">10,4</td>
<td align="left" rowspan="1" colspan="1">0,011</td>
<td align="left" rowspan="1" colspan="1">1,084745763</td>
<td align="left" rowspan="1" colspan="1">1,073745763</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>From the table one can conclude that the ratio of cooperators in the population at the steady state tends to the equilibrium of the “average” type of agents. Furthermore, the results show that the bigger the variance and therefore the less clear the average agent type, the more difference there is between the expected number of cooperators in the steady state and the realized steady state situation. This implies that if there is a clear majority in the population, then the overall number of cooperators would tend to the equilibrium point of that majority.</p>
<p>To test this hypothesis, we repeated the simulation with a finite number of different agent types with <italic>b</italic><sub><italic>i</italic></sub> being <italic>uniformly distributed</italic>. The motivation is that there is still a clear average; however, there are as many agents with an ‘extreme’ value as there are around the average. Therefore, there is no majority that can determine the number of cooperators in the steady state. The results of these experiments (see <xref ref-type="table" rid="pone.0122205.t007">Table 7</xref>) show that for populations with no clear majority of agents of a certain type, the current method does not provide an appropriate approximation of the number of cooperators in the steady state.</p>
<table-wrap id="pone.0122205.t007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.t007</object-id>
<label>Table 7</label>
<caption>
<title>Results for 100 different types of agents for several settings with uniformly distributed <italic>b</italic><sub><italic>i</italic></sub>.</title>
</caption>
<alternatives>
<graphic id="pone.0122205.t007g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.t007"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>min</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>max</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>avg</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>long-term ratio of cooperators from simulation</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>long-term ratio of cooperators from calculation</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>difference</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">1,1</td>
<td align="left" rowspan="1" colspan="1">0,6</td>
<td align="left" rowspan="1" colspan="1">0,8589</td>
<td align="left" rowspan="1" colspan="1">0,871794872</td>
<td align="left" rowspan="1" colspan="1">0,012894872</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">2,1</td>
<td align="left" rowspan="1" colspan="1">1,1</td>
<td align="left" rowspan="1" colspan="1">0,8188</td>
<td align="left" rowspan="1" colspan="1">0,852941176</td>
<td align="left" rowspan="1" colspan="1">0,034141176</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">3,1</td>
<td align="left" rowspan="1" colspan="1">1,6</td>
<td align="left" rowspan="1" colspan="1">0,7615</td>
<td align="left" rowspan="1" colspan="1">0,827586207</td>
<td align="left" rowspan="1" colspan="1">0,066086207</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">4,1</td>
<td align="left" rowspan="1" colspan="1">2,1</td>
<td align="left" rowspan="1" colspan="1">0,6959</td>
<td align="left" rowspan="1" colspan="1">0,791666667</td>
<td align="left" rowspan="1" colspan="1">0,095766667</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">5,1</td>
<td align="left" rowspan="1" colspan="1">2,6</td>
<td align="left" rowspan="1" colspan="1">0,6184</td>
<td align="left" rowspan="1" colspan="1">0,736842105</td>
<td align="left" rowspan="1" colspan="1">0,118442105</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">6,1</td>
<td align="left" rowspan="1" colspan="1">3,1</td>
<td align="left" rowspan="1" colspan="1">0,5542</td>
<td align="left" rowspan="1" colspan="1">0,642857143</td>
<td align="left" rowspan="1" colspan="1">0,088657143</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">7,1</td>
<td align="left" rowspan="1" colspan="1">3,6</td>
<td align="left" rowspan="1" colspan="1">0,4884</td>
<td align="left" rowspan="1" colspan="1">0,444444444</td>
<td align="left" rowspan="1" colspan="1">-0,043955556</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">8,1</td>
<td align="left" rowspan="1" colspan="1">4,1</td>
<td align="left" rowspan="1" colspan="1">0,4408</td>
<td align="left" rowspan="1" colspan="1">-0,25</td>
<td align="left" rowspan="1" colspan="1">-0,6908</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">9,1</td>
<td align="left" rowspan="1" colspan="1">4,6</td>
<td align="left" rowspan="1" colspan="1">0,4029</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">5,5971</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">0,1</td>
<td align="left" rowspan="1" colspan="1">10,1</td>
<td align="left" rowspan="1" colspan="1">5,1</td>
<td align="left" rowspan="1" colspan="1">0,3715</td>
<td align="left" rowspan="1" colspan="1">1,833333333</td>
<td align="left" rowspan="1" colspan="1">1,461833333</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec013">
<title>Expected ratio of cooperators in the stationary state</title>
<p>It is also possible to estimate the ratio of cooperators in the steady state using the distribution of the betrayal factor in the population. We aim to find the equilibrium point of the population game explained in subsection 1 when the distribution of <italic>b</italic><sub><italic>i</italic></sub> over the agents is known and the rest of the parameters in the payoff matrix <italic>A</italic><sub><italic>i</italic></sub> are the same for all of the agents. We neglect the 0.02 chance that the randomly chosen agent updates to a random strategy. Define the function <italic>a</italic>:[0,1) → ℝ to be
<disp-formula id="pone.0122205.e051"><alternatives><graphic id="pone.0122205.e051g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e051"/><mml:math id="M51" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>a</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mo>(</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo> <mml:mi>x</mml:mi> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mi>c</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Then according to (<xref ref-type="disp-formula" rid="pone.0122205.e024">Eq 12</xref>), the best response function can be written as
<disp-formula id="pone.0122205.e052"><alternatives><graphic id="pone.0122205.e052g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e052"/><mml:math id="M52" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>β</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>C</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mi>a</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mi>D</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mi>a</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
Based on the above equality, the probability of some agent <italic>i</italic> cooperating, <italic>x</italic><sub><italic>i</italic></sub>, equals the probability of <italic>b</italic><sub><italic>i</italic></sub> being less than <italic>a</italic>(<italic>x</italic><sub><italic>j</italic></sub>) when <italic>x</italic><sub><italic>j</italic></sub> ≠ 1:
<disp-formula id="pone.0122205.e053"><alternatives><graphic id="pone.0122205.e053g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e053"/><mml:math id="M53" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="normal">Pr</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&lt;</mml:mo> <mml:mi>a</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
When <italic>x</italic><sub><italic>j</italic></sub> = 1, we have that <italic>x</italic><sub><italic>i</italic></sub> = 0 which is the case when one player cooperates and the other defects. Now let <italic>F</italic><sub><italic>b</italic></sub>(⋅) denote the <italic>cumulative distribution function</italic> of the agents’ betrayal factors. Then <xref ref-type="disp-formula" rid="pone.0122205.e053">Eq (17)</xref> can be written as
<disp-formula id="pone.0122205.e054"><alternatives><graphic id="pone.0122205.e054g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e054"/><mml:math id="M54" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>F</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula></p>
<p>Now consider the population game in the stationary state, i.e., when an agent no longer changes her strategy when being chosen to update. Denote the expected proportion of cooperators in the stationary state by <italic>x</italic><sub><italic>C</italic></sub>. By definition, <italic>x</italic><sub><italic>C</italic></sub> equals the probability that in the stationary state, the strategy of a randomly chosen agent is <italic>C</italic>. Since the agents are at the stationary state, <italic>x</italic><sub><italic>C</italic></sub> equals the probability that a randomly chosen agent cooperates. On the other hand, according to (<xref ref-type="disp-formula" rid="pone.0122205.e054">Eq 18</xref>), the probability of a random agent cooperating equals the probability of her betrayal being less than <italic>a</italic>(<italic>x</italic><sub><italic>j</italic></sub>) when <italic>x</italic><sub><italic>j</italic></sub> ≠ 1. Note that <italic>x</italic><sub><italic>j</italic></sub> is the chance that the opponent cooperates; however, the opponent is also randomly chosen (which may be the agent herself). Hence, <italic>x</italic><sub><italic>j</italic></sub> = <italic>x</italic><sub><italic>C</italic></sub>. Therefore, (<xref ref-type="disp-formula" rid="pone.0122205.e054">Eq 18</xref>) becomes
<disp-formula id="pone.0122205.e055"><alternatives><graphic id="pone.0122205.e055g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e055"/><mml:math id="M55" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>F</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
When <italic>x</italic><sub><italic>j</italic></sub> = 1, we have that <italic>x</italic><sub><italic>C</italic></sub> = 1 implying that all of the agents in the population are cooperators, which almost never happens since the steady state for the <italic>PD</italic> and <italic>SD</italic> types is to have all and some portion of the population to defect, respectively. So in general, the ratio of cooperators in the population game in the steady state can be approximated by (<xref ref-type="disp-formula" rid="pone.0122205.e055">Eq 19</xref>).</p>
</sec>
</sec>
<sec id="sec014">
<title>Varying emotions</title>
<p>Up to now, we have considered a simplified version of emotions by including a fixed number, the betrayal factor, in the payoff matrix of the agents. In reality, emotions fluctuate over time. In experiments with social dilemmas such as the <italic>PD</italic> game and other public goods games, it is observed [<xref ref-type="bibr" rid="pone.0122205.ref036">36</xref>] that people often start out cooperative but after a few disappointments will start to behave less cooperatively. This gives rise to the suggestion that the factor <italic>b</italic> should not be fixed but a function of the number of encounters with a defector, namely the <italic>disappointments</italic>.</p>
<p>In order to model such a varying feeling of being betrayed, we define a <italic>varying emotion game</italic> similar to the population game defined previously in Subsection 1 as follows. Consider a population of <italic>n</italic> agents, to each of which the payoff matrix <italic>A</italic><sub><italic>i</italic></sub> defined in (<xref ref-type="disp-formula" rid="pone.0122205.e008">Eq 7</xref>) fulfilling the conditions (<xref ref-type="disp-formula" rid="pone.0122205.e006">Eq 5</xref>) and (<xref ref-type="disp-formula" rid="pone.0122205.e007">Eq 6</xref>) is assigned. Moreover, agents meet and play a game to be explained later. We assume that each agent has a memory that can store the number of times she has encountered a cooperator, <italic>n</italic><sub><italic>C</italic></sub>, and the number of times she has encountered a defector, <italic>n</italic><sub><italic>D</italic></sub>. The varying emotion game for such a population is defined to be the same as a population game with the following extra steps:
<list list-type="bullet"><list-item><p>After the chosen agent <italic>i</italic> updated her strategy, another agent <italic>j</italic> is randomly chosen from the population.</p></list-item> <list-item><p>Agent <italic>i</italic> as a row player plays a 2 × 2 asymmetric game against agent <italic>j</italic> as the column player where the payoff matrices <italic>A</italic><sub><italic>i</italic></sub> and <inline-formula id="pone.0122205.e056"><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>A</mml:mi> <mml:mi>j</mml:mi> <mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> correspond to the column and row players, respectively.</p></list-item> <list-item><p>Agent <italic>i</italic> updates her betrayal factor using a function <italic>b</italic>:ℝ<sup>2</sup> → ℝ as
<disp-formula id="pone.0122205.e057"><alternatives><graphic id="pone.0122205.e057g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e057"/><mml:math id="M57" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>b</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p></list-item></list>
Note that the betrayal factor <italic>b</italic><sub><italic>i</italic></sub> affects the agent’s benefits perceived from cooperation and her willingness to cooperate. Consequently, the agent chooses to update based on the probability that she will meet a cooperator next time and her willingness to cooperate for the next round.</p>
<p>One of the simplest functions one can imagine for <italic>b</italic> is a linear function of <italic>n</italic><sub><italic>D</italic></sub>:
<disp-formula id="pone.0122205.e058"><alternatives><graphic id="pone.0122205.e058g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e058"/><mml:math id="M58" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>b</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
for some real parameter <italic>a</italic><sub>1</sub> and a positive <italic>a</italic><sub>2</sub>. In this case, the betrayal would be a strictly decreasing function, which means that the probability that the corresponding agent will cooperate after many encounters with defectors tends to zero. One problem with such a function is that the betrayal of the agent gets affected equally after meeting a defector for the first time or for several times. However, in ‘reality’ it is more probable that the first negative encounter really touches an agent’s feelings, but after a while, the agent numbs and gets used to being defected upon and will start to defect as well. So it would be more realistic to choose a negative exponential function for <italic>b</italic>:
<disp-formula id="pone.0122205.e059"><alternatives><graphic id="pone.0122205.e059g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e059"/><mml:math id="M59" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>b</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>2</sub> are positive. Now the first encounters with a defector have a large negative effect; however, as <italic>n</italic><sub><italic>D</italic></sub> increases further, that is to meet more defectors, the magnitude of <italic>b</italic> slowly tends to zero. The exponential curve of <italic>b</italic> for parameters <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>2</sub> set to 1 is depicted in <xref ref-type="fig" rid="pone.0122205.g009">Fig 9</xref>. The main problem with such an exponential function is that no matter how many times an agent encounters a cooperator, her betrayal increases, and hence, her willingness to cooperate decreases by increments in meeting defectors. Based on the fact that someone’s willingness to cooperate can both grow and diminish over time, we modify the above function to capture the effect of meeting cooperators as in the following
<disp-formula id="pone.0122205.e060"><alternatives><graphic id="pone.0122205.e060g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pone.0122205.e060"/><mml:math id="M60" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>b</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>a</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>C</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
As emotions fade over time and are put in perspective as an agent gains experience, we moderate the emotions by the total number of games that the agent has played, <italic>n</italic><sub><italic>C</italic></sub> + <italic>n</italic><sub><italic>D</italic></sub>. The effect of each of the encounters can be enlarged or diminished by the variables <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub>.</p>
<fig id="pone.0122205.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g009</object-id>
<label>Fig 9</label>
<caption>
<title>The exponential decay of b(1,1).</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g009"/>
</fig>
<p>Now, with such a varying betrayal for each of the agents, we simulate the varying emotion game for a population of 100 agents, with the parameters <italic>r</italic> = 5, <italic>c</italic> = 1 and <italic>g</italic><sub><italic>i</italic></sub> = 0 in the payoff matrix <italic>A</italic><sub><italic>i</italic></sub> and for all <italic>i</italic>. The evolution of the percentage of cooperators for different initial number of cooperators is shown in Figs <xref ref-type="fig" rid="pone.0122205.g010">10</xref> and <xref ref-type="fig" rid="pone.0122205.g011">11</xref>.</p>
<fig id="pone.0122205.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Percentage of cooperators with respect to time for 4 different initial conditions for 5 runs and 1000 iterations per simulation with the initial number of cooperators set to 20 (yellow), 40 (blue), 60 (green) and 80 (cyan) with <italic>a</italic><sub>1</sub> = <italic>a</italic><sub>2</sub> = <italic>a</italic><sub>3</sub> = 1 and when <italic>r</italic> = 5, <italic>c</italic> = 1 and <italic>g</italic><sub><italic>i</italic></sub> = 0.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g010"/>
</fig>
<fig id="pone.0122205.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Percentage of cooperators with respect to time for 2 different initial conditions for 5 runs and 2000 iterations per simulation with the initial number of cooperators set to 20 (blue) and 50 (magenta) with <italic>a</italic><sub>1</sub> = 100 and <italic>a</italic><sub>2</sub>, <italic>a</italic><sub>3</sub> = 1 and when <italic>r</italic> = 5, <italic>c</italic> = 1 and <italic>g</italic><sub><italic>i</italic></sub> = 0.</title>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g011"/>
</fig>
<p>As can be seen from <xref ref-type="fig" rid="pone.0122205.g010">Fig 10</xref>, for the case of <italic>a</italic><sub>1</sub> = <italic>a</italic><sub>2</sub> = <italic>a</italic><sub>3</sub> = 1, for different initial numbers of cooperators in the population, the number of cooperators converges to approximately 40 in the steady state. However, for the case of <italic>a</italic><sub>1</sub> = 100 and <italic>a</italic><sub>2</sub>, <italic>a</italic><sub>3</sub> = 1, there is a strong influence of the initial conditions as can be seen in <xref ref-type="fig" rid="pone.0122205.g011">Fig 11</xref>. For values greater than or equal to 50 percent initial cooperators, the population almost always converges to full cooperation in the long run. For values smaller than 50 percent initial cooperators, the number of cooperators converges to the same value 40 as before.</p>
<sec id="sec015">
<title>Emotion-based decision-making</title>
<p>Until now, the assumption was made that all of the players know what percentage of the population has played cooperation in the previous round. This could be a reasonable assumption in a controlled game setting or in small groups where the behaviour of everybody is visible to everyone. However, in large groups it is unlikely that every player can make a good estimation of the probability of meeting a cooperator in the next round. Therefore, to be thorough, also some simulations are made where agents only update their strategies based upon their willingness to cooperate or put differently, on the amount of cooperators and defectors they met during the course of the game. The agents solely base their strategies, i.e., to cooperate or to defect, upon whether their willingness to cooperate is above or below a certain fixed level, 1 in this case, respectively. The willingness to cooperate is determined by the negative of the function <italic>b</italic> in (<xref ref-type="disp-formula" rid="pone.0122205.e060">Eq 20</xref>). Hence, each agent cooperates if her <italic>b</italic> is greater than 1 and defects if her <italic>b</italic> is less than 1.</p>
<p>For the simulations, first all of the variables <italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub> are kept to 1 and the strategies of half of the agents which are randomly chosen are initially set to cooperation, and the rest to defection. Note that <italic>a</italic><sub>1</sub> = <italic>a</italic><sub>2</sub> implies that the absolute size of the effect of meeting a cooperator or a defector are considered to be equal for each agent. The corresponding results can be found in <xref ref-type="fig" rid="pone.0122205.g012">Fig 12</xref>.</p>
<fig id="pone.0122205.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Different outcomes for the same initial conditions when the betrayal factors of the agents change by the function <italic>b</italic>(.) in (<xref ref-type="disp-formula" rid="pone.0122205.e060">Eq 20</xref>) and also when the agents do not update their strategies, but instead cooperate when <italic>b</italic> &lt; 1 and defect when <italic>b</italic> &gt; 1.</title>
<p><italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub> are all set to 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g012"/>
</fig>
<p>As can be seen, for the same initial number of cooperators, two completely different outcomes can happen in the final state: <italic>Full defection</italic>, i.e., a population of all defectors or <italic>full cooperation</italic>, i.e., a population of all cooperators. This implies that the sequence of the chosen agents to update their strategies plays an important role in this case. When the number of initial cooperators is higher than 50, the steady state almost always tends to full cooperation and vice versa.</p>
<p>It is also possible to turn the population to full defection or full cooperation almost independent of the initial number of cooperators by tuning the parameters <italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub>. In Figs <xref ref-type="fig" rid="pone.0122205.g013">13</xref>–<xref ref-type="fig" rid="pone.0122205.g015">15</xref>, each of the variables <italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub> are varied in turn to see what their respective effects on the levels of cooperation are. From the figures one can see that large values of <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>3</sub> will lead to full cooperation and larger values of <italic>a</italic><sub>2</sub> will lead to full defection. This knowledge can be used to tune the model once experimental data from social experiments are known.</p>
<fig id="pone.0122205.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Percentage of cooperators with respect to the number of iterations when the betrayal factors of the agents change according to the function <italic>b</italic>(.) in (<xref ref-type="disp-formula" rid="pone.0122205.e060">Eq 20</xref>) and also when the agents do not update their strategies, but instead cooperate when <italic>b</italic> &lt; 1 and defect when <italic>b</italic> &gt; 1.</title>
<p>Four different situations are shown after 5 runs and 2000 iterations per simulation with <italic>a</italic><sub>1</sub> set to 0.5 (yellow), 1 (green), 1.5 (blue) and 2 (red), <italic>a</italic><sub>2</sub> and <italic>a</italic><sub>3</sub> both set to 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g013"/>
</fig>
<fig id="pone.0122205.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Percentage of cooperators with respect to the number of iterations when the betrayal factors of the agents change by the function <italic>b</italic>(.) in (<xref ref-type="disp-formula" rid="pone.0122205.e060">Eq 20</xref>) and also when the agents do not update their strategies, but instead cooperate when <italic>b</italic> &lt; 1 and defect when <italic>b</italic> &gt; 1.</title>
<p>Four different situations are shown after 5 runs and 2000 iterations per simulation with <italic>a</italic><sub>2</sub> set to 0.5 (yellow), 1 (green), 1.5 (blue) and 2 (red), <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>3</sub> both set to 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g014"/>
</fig>
<fig id="pone.0122205.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0122205.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Percentage of cooperators with respect to the number of iterations when the betrayal factors of the agents change by the function <italic>b</italic>(.) in (<xref ref-type="disp-formula" rid="pone.0122205.e060">Eq 20</xref>) and also when the agents do not update their strategies, but instead cooperate when <italic>b</italic> &lt; 1 and defect when <italic>b</italic> &gt; 1.</title>
<p>Four different situations are shown after 5 runs and 2000 iterations per simulation with <italic>a</italic><sub>3</sub> set to 0.5 (yellow), 1 (green), 1.5 (blue) and 2 (red), <italic>a</italic><sub>1</sub> and <italic>a</italic><sub>2</sub> both set to 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pone.0122205.g015"/>
</fig>
</sec>
</sec>
<sec id="sec016">
<title>Concluding remarks</title>
<p>The results of this paper help to understand the behavior of a population of individuals with different emotions participating in asymmetric games. We introduce a payoff for the feeling of being betrayed and incorporate it with another emotional payoff, guilt, in a 2 × 2 payoff matrix. According to the emotions of each agent, such a payoff matrix is assigned to her which has the structure of the payoff matrix of either a snowdrift or a prisoner’s dilemma game. For large values of the feeling of being betrayed, the payoff matrix takes the structure of a PD payoff matrix while for smaller values it can take the structure of an SD payoff matrix. This makes defection the best response for an agent having a great feeling of being betrayed while for others it depends on the strategy of the opponent. We study the evolution of cooperation in a population of 100 agents, each of which updates her strategy according to the myopic best response update rule.</p>
<p>The evolution is simulated with different types of agents, each of whom has a different betrayal factor. We find that different equilibria can be attained in the population by changing the number of agents having a certain betrayal factor. The simulation results support the claim that decreasing the feeling of being betrayed in a portion of agents, does not necessarily increase the level of cooperation in the population. In other words, there are some states, at which the population becomes robust to agents with a lower level of feeling betrayed. Hence, replacing some of the high-betrayal-level agents in the population with some low-betrayal-level agents, does not change the total number of cooperators in the population. However, this resistance of the population against agents with a low level of the feeling of being betrayed is only up to some point. That is where the number of the agents in the population with a lower level of the betrayal factor reaches the number of cooperators at the symmetric Nash equilibrium of a 2 × 2 symmetric game with the same payoff matrix assigned to the low-betrayal-level agents. After that point, the average cooperation-level in the population is raised by the replacement of some high-level-betrayal agents with some low-betrayal-level ones. However, by further increasing the number of these low-betrayal-level type of agents in the population, the selfishness of these even highly cooperative agents will force them to start to defect. They defect in order to maintain the total level of cooperation in the population at their desired level. In the future, we are interested in investigating the evolution of cooperation under the same conditions but when the imitative update rule is used by the agents.</p>
<p>We also propose two other models where the betrayal factor of an agent fluctuates as a function of the number of times she encounters a cooperator and the number of times she encounters a defector. In the first model, the agents update their strategies as before. In this case the population exhibits a more unstable behavior comparing to the previous cases. However, for the same initial strategies, different runs result in almost the same final state of the ratio of cooperators. In the second model, the agents update their strategies based on the number of encounters. In this case, an unstable behavior is observed. Starting from the same ratio of cooperators in the population, the ratio of cooperators can converge to different final states. We have however discussed how to lead the population to the state of all cooperators or all defectors by tunning the parameters in the function just mentioned.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Dr. Jacob Dijkstra for making us aware of [<xref ref-type="bibr" rid="pone.0122205.ref025">25</xref>] and his suggestions to reinterpret the results in the paper by reshaping payoff matrices of games.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0122205.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Axelrod</surname> <given-names>RM</given-names></name>. <source>The Evolution of Cooperation</source>. <source>Basic Books</source>; <year>1984</year>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Andreoni</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>JH</given-names></name>. <article-title>Rational cooperation in the finitely repeated prisoner’s dilemma: Experimental evidence</article-title>. <source>Econ J (London)</source>. <year>1993</year>; <fpage>570</fpage>–<lpage>585</lpage>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Colman</surname> <given-names>AM</given-names></name>. <source>Game Theory and Its Applications in the Social and Biological Sciences</source>. <publisher-name>Psychology Press</publisher-name>; <year>1995</year>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fischbacher</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Gächter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>. <article-title>Are people conditionally cooperative? Evidence from a public goods experiment</article-title>. <source>Econ Lett</source>. <year>2001</year>; <volume>71</volume>: <fpage>397</fpage>–<lpage>404</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0165-1765(01)00394-9" xlink:type="simple">10.1016/S0165-1765(01)00394-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gächter</surname> <given-names>S</given-names></name>. <article-title>Altruistic punishment in humans</article-title>. <source>Nature</source>. <year>2002</year>; <volume>415</volume>: <fpage>137</fpage>–<lpage>140</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/415137a" xlink:type="simple">10.1038/415137a</ext-link></comment> <object-id pub-id-type="pmid">11805825</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brosig</surname> <given-names>J</given-names></name>. <article-title>Identifying cooperative behavior: some experimental results in a prisoner’s dilemma game</article-title>. <source>J Econ Behav Organ</source>. <year>2002</year>; <volume>47</volume>: <fpage>275</fpage>–<lpage>290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-2681(01)00211-6" xlink:type="simple">10.1016/S0167-2681(01)00211-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Yin</surname> <given-names>ZY</given-names></name>, <name name-style="western"><surname>Xia</surname> <given-names>CY</given-names></name>. <article-title>Inferring reputation promotes the evolution of cooperation in spatial social dilemma games</article-title>. <source>PLoS One</source>. <year>2012</year>; <volume>7</volume>: <fpage>e40218</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0040218" xlink:type="simple">10.1371/journal.pone.0040218</ext-link></comment> <object-id pub-id-type="pmid">22808120</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chan</surname> <given-names>NW</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Tey</surname> <given-names>SK</given-names></name>, <name name-style="western"><surname>Yap</surname> <given-names>YJ</given-names></name>, <name name-style="western"><surname>Hui</surname> <given-names>P</given-names></name>. <article-title>Evolutionary snowdrift game incorporating costly punishment in structured populations</article-title>. <source>Physica A</source>. <year>2013</year>; <volume>392</volume>: <fpage>168</fpage>–<lpage>176</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.physa.2012.07.078" xlink:type="simple">10.1016/j.physa.2012.07.078</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="other">Trivers RL. The evolution of reciprocal altruism. Q Rev Biol. 1971; 35–57.</mixed-citation>
</ref>
<ref id="pone.0122205.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="other">Wang C, Wu B, Cao M, Xie G. Modified snowdrift games for multi-robot water polo matches. Proc IEEE Chinese Conf Decis Control. 2012; 164–169.</mixed-citation>
</ref>
<ref id="pone.0122205.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="other">Ramazi P, Cao M. Stability analysis for replicator dynamics of evolutionary snowdrift games. Proc IEEE Conf Decis Control. 2014; 4515–4520.</mixed-citation>
</ref>
<ref id="pone.0122205.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Roth</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Kagel</surname> <given-names>JH</given-names></name>. <source>Handbook of Experimental Economics</source>. <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>; <year>1995</year>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nowak</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>May</surname> <given-names>RM</given-names></name>. <article-title>Evolutionary games and spatial chaos</article-title>. <source>Nature</source> <year>1992</year>; <volume>359</volume>: <fpage>826</fpage>–<lpage>829</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/359826a0" xlink:type="simple">10.1038/359826a0</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="other">Riehl, J, Cao, M. Towards control of evolutionary games on networks. Proc IEEE Conf Decis Control. 2014; 2877–2882.</mixed-citation>
</ref>
<ref id="pone.0122205.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jin</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Xia</surname> <given-names>CY</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>. <article-title>Spontaneous symmetry breaking in interdependent networked game</article-title>. <source>Sci Rep</source>. <year>2014</year>; <volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/srep04095" xlink:type="simple">10.1038/srep04095</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Perc</surname> <given-names>M</given-names></name>. <article-title>Degree mixing in multilayer networks impedes the evolution of cooperation</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>. <year>2014</year>; <volume>89</volume>: <fpage>052813</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.89.052813" xlink:type="simple">10.1103/PhysRevE.89.052813</ext-link></comment> <object-id pub-id-type="pmid">25353850</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boccaletti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bianconi</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Criado</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Del Genio</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Gómez-Gardeñes</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Romance</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>The structure and dynamics of multilayer networks</article-title>. <source>Phys Rep</source>. <year>2014</year>; <volume>544</volume>: <fpage>1</fpage>–<lpage>122</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.physrep.2014.07.001" xlink:type="simple">10.1016/j.physrep.2014.07.001</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Xia</surname> <given-names>CY</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>ZQ</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>J</given-names></name>. <article-title>Evaluating fitness by integrating the highest payoff within the neighborhood promotes cooperation in social dilemmas</article-title>. <source>Physica A</source>. <year>2012</year>; <volume>391</volume>: <fpage>6440</fpage>–<lpage>6447</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.physa.2012.07.065" xlink:type="simple">10.1016/j.physa.2012.07.065</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zhang</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Ning</surname> <given-names>HY</given-names></name>, <name name-style="western"><surname>Yin</surname> <given-names>ZY</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>JQ</given-names></name>, <etal>et al</etal>. <article-title>A novel snowdrift game model with edge weighting mechanism on the square lattice</article-title>, <source>Front Phys</source>. <year>2012</year>; <volume>7</volume>: <fpage>366</fpage>–<lpage>372</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11467-011-0208-x" xlink:type="simple">10.1007/s11467-011-0208-x</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boone</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>De-Brabander</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Van-Witteloostuijn</surname> <given-names>A</given-names></name>. <article-title>The impact of personality on behavior in five prisoner’s dilemma games</article-title>. <source>J Econ Psychol</source>. <year>1999</year>; <volume>20</volume>: <fpage>343</fpage>–<lpage>377</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-4870(99)00012-4" xlink:type="simple">10.1016/S0167-4870(99)00012-4</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Matsumoto</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Haan</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Yabrove</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Theodorou</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Carney</surname> <given-names>CC</given-names></name>. <article-title>Preschoolers’ moral actions and emotions in prisoner’s dilemma</article-title>. <source>Dev Psychol</source>. <year>1986</year>; <volume>22</volume>: <fpage>663</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0012-1649.22.5.663" xlink:type="simple">10.1037/0012-1649.22.5.663</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tabibnia</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Satpute</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Lieberman</surname> <given-names>MD</given-names></name>. <article-title>The sunny side of fairness preference for fairness activates reward circuitry (and disregarding unfairness activates self-control circuitry)</article-title>. <source>Psychol Sci</source>. <year>2008</year>;<volume>19</volume>: <fpage>339</fpage>–<lpage>347</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1467-9280.2008.02091.x" xlink:type="simple">10.1111/j.1467-9280.2008.02091.x</ext-link></comment> <object-id pub-id-type="pmid">18399886</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bowles</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gintis</surname> <given-names>H</given-names></name>. <article-title>Social capital and community governance</article-title>. <source>Econ J (London)</source>. <year>2002</year>;<volume>112</volume>: <fpage>F419</fpage>–<lpage>F436</lpage>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Winter</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rauhut</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Helbing</surname> <given-names>D</given-names></name>. <article-title>How norms can generate conflict: An experiment on the failure of cooperative micro-motives on the macro-level</article-title>. <source>Soc Forces</source>. <year>2012</year>; <volume>90</volume>: <fpage>919</fpage>–<lpage>946</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/sf/sor028" xlink:type="simple">10.1093/sf/sor028</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Waldeck</surname> <given-names>R</given-names></name>. <article-title>Segregated cooperation</article-title>. <source>J Artif Soc Soc Simul</source>. <year>2013</year>; <volume>16</volume>: <fpage>14</fpage>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hauert</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Doebeli</surname> <given-names>M</given-names></name>. <article-title>Spatial structure often inhibits the evolution of cooperation in the snowdrift game</article-title>. <source>Nature</source>. <year>2004</year>; <volume>428</volume>: <fpage>643</fpage>–<lpage>646</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02360" xlink:type="simple">10.1038/nature02360</ext-link></comment> <object-id pub-id-type="pmid">15074318</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schuster</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Sigmund</surname> <given-names>K</given-names></name>. <article-title>Replicator dynamics</article-title>. <source>J Theor Biol</source>. <year>1983</year>; <volume>100</volume>: <fpage>533</fpage>–<lpage>538</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0022-5193(83)90445-9" xlink:type="simple">10.1016/0022-5193(83)90445-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Alós-Ferrer</surname> <given-names>C</given-names></name>. <article-title>Finite population dynamics and mixed equilibria</article-title>. <source>Int Game Theor Rev</source>. <year>2003</year>; <volume>5</volume>: <fpage>263</fpage>–<lpage>290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1142/S0219198903001057" xlink:type="simple">10.1142/S0219198903001057</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Du</surname> <given-names>WB</given-names></name>, <name name-style="western"><surname>Cao</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>WX</given-names></name>. <article-title>Asymmetric cost in snowdrift game on scale-free networks</article-title>. <source>Europhys Lett</source>. <year>2009</year>; <volume>87</volume>: <fpage>60004</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1209/0295-5075/87/60004" xlink:type="simple">10.1209/0295-5075/87/60004</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Dijkstra</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Van-Assen</surname> <given-names>MA</given-names></name>. <article-title>Network public goods with asymmetric information about cooperation preferences and network degree</article-title>. <source>Soc Networks</source>. <year>2013</year>; <volume>35</volume>: <fpage>573</fpage>–<lpage>582</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.socnet.2013.08.005" xlink:type="simple">10.1016/j.socnet.2013.08.005</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kandori</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rob</surname> <given-names>R</given-names></name>. <article-title>Evolution of equilibria in the long run: A general theory and applications</article-title>. <source>J Econ Theory</source>, <year>1995</year>; <volume>65</volume>: <fpage>383</fpage>–<lpage>414</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1006/jeth.1995.1014" xlink:type="simple">10.1006/jeth.1995.1014</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roca</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Cuesta</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Sánchez</surname> <given-names>A</given-names></name>. <article-title>Promotion of cooperation on networks? the myopic best response case</article-title>. <source>Eur Phys J B</source>. <year>2009</year>; <volume>71</volume>: <fpage>587</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1140/epjb/e2009-00189-0" xlink:type="simple">10.1140/epjb/e2009-00189-0</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0122205.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Cook</surname> <given-names>K</given-names></name>. <source>Trust in Society</source>. <publisher-name>Russell Sage Foundation</publisher-name>; <year>2001</year>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Fischbacher</surname> <given-names>U</given-names></name>. <article-title>The nature of human altruism</article-title>. <source>Nature</source> <year>2003</year>; <volume>425</volume>: <fpage>785</fpage>–<lpage>791</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02043" xlink:type="simple">10.1038/nature02043</ext-link></comment> <object-id pub-id-type="pmid">14574401</object-id></mixed-citation>
</ref>
<ref id="pone.0122205.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Weibull</surname> <given-names>JW</given-names></name>. <chapter-title>Evolutionary Game Theory</chapter-title>. <source>MIT press</source>; <year>1997</year>.</mixed-citation>
</ref>
<ref id="pone.0122205.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cooper</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>DeJong</surname> <given-names>DV</given-names></name>, <name name-style="western"><surname>Forsythe</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>TW</given-names></name>. <article-title>Cooperation without reputation: experimental evidence from prisoner’s dilemma games</article-title>. <source>Games Econ Behav</source>. <year>1996</year>; <volume>12</volume>: <fpage>187</fpage>–<lpage>218</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>