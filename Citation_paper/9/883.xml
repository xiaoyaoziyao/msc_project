<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0215052</article-id>
<article-id pub-id-type="publisher-id">PONE-D-18-22718</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Science policy</subject><subj-group><subject>Research integrity</subject><subj-group><subject>Publication ethics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Metaanalysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Metaanalysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Systematic reviews</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Mental health and psychiatry</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Publication bias examined in meta-analyses from psychology and medicine: A meta-meta-analysis</article-title>
<alt-title alt-title-type="running-head">Studying publication bias in a meta-meta-analysis</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6187-0665</contrib-id>
<name name-style="western">
<surname>van Aert</surname>
<given-names>Robbie C. M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Wicherts</surname>
<given-names>Jelte M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>van Assen</surname>
<given-names>Marcel A. L. M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Methodology and Statistics, Tilburg University, Tilburg, the Netherlands</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Sociology, Utrecht University, Utrecht, the Netherlands</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Macleod</surname>
<given-names>Malcolm R.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Edinburgh, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>I have read the journal's policy and the authors of this manuscript have the following competing interests: Jelte M. Wicherts is a PLOS ONE Editorial Board member. This does not alter the authors’ adherence to PLOS ONE Editorial policies and criteria.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">R.C.M.vanAert@tilburguniversity.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>12</day>
<month>4</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<year>2019</year>
</pub-date>
<volume>14</volume>
<issue>4</issue>
<elocation-id>e0215052</elocation-id>
<history>
<date date-type="received">
<day>1</day>
<month>8</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>3</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>van Aert et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0215052"/>
<abstract>
<p>Publication bias is a substantial problem for the credibility of research in general and of meta-analyses in particular, as it yields overestimated effects and may suggest the existence of non-existing effects. Although there is consensus that publication bias exists, how strongly it affects different scientific literatures is currently less well-known. We examined evidence of publication bias in a large-scale data set of primary studies that were included in 83 meta-analyses published in Psychological Bulletin (representing meta-analyses from psychology) and 499 systematic reviews from the Cochrane Database of Systematic Reviews (CDSR; representing meta-analyses from medicine). Publication bias was assessed on all homogeneous subsets (3.8% of all subsets of meta-analyses published in Psychological Bulletin) of primary studies included in meta-analyses, because publication bias methods do not have good statistical properties if the true effect size is heterogeneous. Publication bias tests did not reveal evidence for bias in the homogeneous subsets. Overestimation was minimal but statistically significant, providing evidence of publication bias that appeared to be similar in both fields. However, a Monte-Carlo simulation study revealed that the creation of homogeneous subsets resulted in challenging conditions for publication bias methods since the number of effect sizes in a subset was rather small (median number of effect sizes equaled 6). Our findings are in line with, in its most extreme case, publication bias ranging from no bias until only 5% statistically nonsignificant effect sizes being published. These and other findings, in combination with the small percentages of statistically significant primary effect sizes (28.9% and 18.9% for subsets published in Psychological Bulletin and CDSR), led to the conclusion that evidence for publication bias in the studied homogeneous subsets is weak, but suggestive of mild publication bias in both psychology and medicine.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003246</institution-id>
<institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution>
</institution-wrap>
</funding-source>
<award-id>406-13-050</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6187-0665</contrib-id>
<name name-style="western">
<surname>van Aert</surname>
<given-names>Robbie C. M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Berkeley Initiative for Transparency in the Social Sciences and the Laura and John Arnold Foundation</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6187-0665</contrib-id>
<name name-style="western">
<surname>van Aert</surname>
<given-names>Robbie C. M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>The European Research Council</institution>
</funding-source>
<award-id>726361 (IMPROVE)</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Wicherts</surname>
<given-names>Jelte M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>RvA received Grant number: 406-13-050 from The Netherlands Organization for Scientific Research (NWO), URL funder website: <ext-link ext-link-type="uri" xlink:href="http://www.nwo.nl" xlink:type="simple">www.nwo.nl</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. RvA also received funding from Berkeley Initiative for Transparency in the Social Sciences and the Laura and John Arnold Foundation, URL funder website: <ext-link ext-link-type="uri" xlink:href="http://www.bitss.org" xlink:type="simple">www.bitss.org</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. JW received Grant number: 726361 (IMPROVE) fromThe European Research Council, URL funder website: <ext-link ext-link-type="uri" xlink:href="http://www.erc.europa.eu" xlink:type="simple">www.erc.europa.eu</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="8"/>
<page-count count="32"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data of the meta-analyses are available via <ext-link ext-link-type="uri" xlink:href="https://osf.io/dc9e8/" xlink:type="simple">https://osf.io/dc9e8/</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://osf.io/3gbfk/" xlink:type="simple">https://osf.io/3gbfk/</ext-link> for the meta-analyses obtained from Psychological Bulletin and the Cochrane Database of Systematic Reviews, respectively. The vast majority of data for the primary studies of the meta-analyses published in Psychological Bulletin is available via <ext-link ext-link-type="uri" xlink:href="https://osf.io/tqvue/" xlink:type="simple">https://osf.io/tqvue/</ext-link> (i.e., data of 86.7% of the included meta-analyses), because these data were reported in the published meta-analysis. If data of the primary studies was not included in the published meta-analysis, the authors sent an email to the corresponding author of the meta-analysis to request for these data. They sent a reminder to the corresponding author if he/she did not respond within two weeks. The authors are not allowed to share data of primary studies of the included meta-analyses (i.e., data of 13.3% of the included meta-analyses) if these data were obtained after contacting the corresponding author. The authors of this study promised to not share these data with others which was often a requirement by the corresponding author before he/she was willing to share the data. Nevertheless, they decided to also include data from these meta-analyses in this study at the expense of not being able to share these data to base their conclusions on the largest number of meta-analyses. The authors believe that authors of these meta-analyses will also be willing to share data with other researchers since they were also willing to share the data with them. A list with references of these meta-analyses are provided in a supporting information file (<xref ref-type="supplementary-material" rid="pone.0215052.s014">S1 File</xref>). Due to copyright restrictions, the authors are not allowed to share the data of the primary studies for the systematic reviews from the Cochrane Database of Systematic Reviews. However, they provide R code (<ext-link ext-link-type="uri" xlink:href="https://osf.io/x6yca/" xlink:type="simple">https://osf.io/x6yca/</ext-link>) that can be used in combination with the Cochrane scraper (<ext-link ext-link-type="uri" xlink:href="https://github.com/DASpringate/Cochrane_scraper" xlink:type="simple">https://github.com/DASpringate/Cochrane_scraper</ext-link>) to web scrape the same systematic reviews as they included in this study. This enables other researchers to get the same data from the primary studies as the authors used in this study.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Meta-analysis is the standard technique for synthesizing different studies on the same topic, and is defined as “the statistical analysis of a large collection of analysis results from individual studies for the purpose of integrating the findings” [<xref ref-type="bibr" rid="pone.0215052.ref001">1</xref>]. One of the greatest threats to the validity of meta-analytic results is publication bias, meaning that the publication of studies depends on the direction and statistical significance of the results [<xref ref-type="bibr" rid="pone.0215052.ref002">2</xref>]. Publication bias generally leads to effect sizes being overestimated and the dissemination of false-positive results (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref003">3</xref>, <xref ref-type="bibr" rid="pone.0215052.ref004">4</xref>]). Hence, publication bias results in false impressions about the magnitude and existence of an effect [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>] and is considered one of the key problems in contemporary science [<xref ref-type="bibr" rid="pone.0215052.ref006">6</xref>].</p>
<p>Indications for the presence of publication bias are present in various research fields. The main hypothesis tested in the psychology and psychiatry literature is statistically significant in approximately 90% of the cases[<xref ref-type="bibr" rid="pone.0215052.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0215052.ref008">8</xref>], which is not in line with the on average low statistical power of about 50% or less in, for instance, psychology [<xref ref-type="bibr" rid="pone.0215052.ref009">9</xref>, <xref ref-type="bibr" rid="pone.0215052.ref010">10</xref>] and may be caused by publication bias. Franco, Malhotra, and Simonovits [<xref ref-type="bibr" rid="pone.0215052.ref011">11</xref>] examined publication bias in studies that received a grant within the social sciences and found that 64.6% of the studies where most or all results did not support the alternative hypotheses was not written up compared to 4.4% of the studies where most or all the alternative hypotheses were supported (cf. [<xref ref-type="bibr" rid="pone.0215052.ref012">12</xref>, <xref ref-type="bibr" rid="pone.0215052.ref013">13</xref>]). In a highly similar project within the psychological literature, Franco, Malhotra, and Simonovits [<xref ref-type="bibr" rid="pone.0215052.ref014">14</xref>] showed that 70% of the included outcomes in a study were not reported, and that this selective reporting depended on statistical significance of the outcomes. Although these findings suggest that publication bias is present in numerous research fields, mixed results were observed when analyzing the distribution of <italic>p-</italic>values [<xref ref-type="bibr" rid="pone.0215052.ref015">15</xref>–<xref ref-type="bibr" rid="pone.0215052.ref021">21</xref>] where a difference between <italic>p</italic>-values just above and below α = .05 may be interpreted as evidence for publication bias.</p>
<p>Compared to the social sciences, more attention has been paid to publication bias in medicine [<xref ref-type="bibr" rid="pone.0215052.ref022">22</xref>]. Medicine has a longer history in registering clinical trials before conducting the research (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0215052.ref024">24</xref>]). As of 2007, the US Food and Drug Administration Act (FDA) even requires US researchers to make the results of different types of clinical trials publicly available independent of whether the results have been published or not [<xref ref-type="bibr" rid="pone.0215052.ref025">25</xref>]. With registers like <italic>clinicaltrials</italic>.<italic>gov</italic>, it is easier for meta-analysts to search for unpublished research, and to include it in their meta-analysis. Furthermore, it is straightforward to study publication bias by comparing the reported results in registers with the reported results in publications. Studies comparing the reported results in registers and publications show that statistically significant outcomes are more likely to be reported, and clinical trials with statistically significant results have a higher probability of getting published [<xref ref-type="bibr" rid="pone.0215052.ref026">26</xref>–<xref ref-type="bibr" rid="pone.0215052.ref028">28</xref>].</p>
<p>A number of methods exist to test for publication bias in a meta-analysis and to estimate a meta-analytic effect size corrected for publication bias. However, publication bias is often not routinely assessed in meta-analyses [<xref ref-type="bibr" rid="pone.0215052.ref029">29</xref>–<xref ref-type="bibr" rid="pone.0215052.ref031">31</xref>] or analyzed with suboptimal methods that lack statistical power to detect it [<xref ref-type="bibr" rid="pone.0215052.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0215052.ref033">33</xref>]. It has been suggested to reexamine publication bias in published meta-analyses [<xref ref-type="bibr" rid="pone.0215052.ref030">30</xref>, <xref ref-type="bibr" rid="pone.0215052.ref034">34</xref>] by applying recently developed methods to better understand the severity and prevalence of publication bias in different fields. These novel methods have better statistical properties than existing publication bias tests and methods developed earlier to correct effect sizes for publication bias. Moreover, several authors have recommended to not rely on a single method for examining publication bias in a meta-analysis, but rather to use and report a set of different publication bias methods [<xref ref-type="bibr" rid="pone.0215052.ref035">35</xref>, <xref ref-type="bibr" rid="pone.0215052.ref036">36</xref>]. This so-called triangulation should take into account that some methods do not perform well in some conditions and that none of the publication bias methods outperforms all the other methods under each and every condition; one method can signal publication bias in a meta-analysis whereas another one does not. Using a set of methods to assess the prevalence and severity of publication bias may yield a more balanced conclusion.</p>
<p>We set out to answer three research questions in this paper. The first research question concerned the prevalence of publication bias: “What is the prevalence of publication bias within published meta-analyses in psychological and medical research?” (1a), and “Is publication bias more prevalent in psychology than in medicine after controlling for the number of studies in a meta-analysis?” (1b). Medicine was selected to be compared to psychology, because more attention has been paid to publication bias in general [<xref ref-type="bibr" rid="pone.0215052.ref022">22</xref>] and study registration in particular (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0215052.ref024">24</xref>]) within medicine. We also evaluated the amount of agreement between different publication bias methods. In the second research question, we examined whether effect size estimates of traditional meta-analysis and corrected for publication bias by the <italic>p-</italic>uniform method can be predicted by characteristics of a meta-analysis: “What are predictors of the meta-analytic estimates of traditional meta-analysis and <italic>p</italic>-uniform?”. Our third research question also consisted of two parts and is about overestimation of effect size caused by publication bias: “How much is effect size overestimated by publication bias in meta-analyses in psychology and medical research?” (3a), and “What are predictors of the overestimation in effect size caused by publication bias in meta-analyses in psychology and medical research?” (3b). The aim of this paper is to shed light on the prevalence of publication bias and the overestimation that it causes by answering the above stated research questions. As we focus on homogeneous (subsets of) meta-analyses (i.e., with no or small heterogeneity), we examine these questions for the population of homogeneous subsets. A large-scale dataset will be used containing 83 meta-analyses published in the psychological literature and 499 systematic reviews in the medical literature making this paper a thorough and extensive assessment of publication bias in psychological and medical research.</p>
<p>The hypotheses as well as our planned analyses were preregistered (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/8y5ep/" xlink:type="simple">https://osf.io/8y5ep/</ext-link>) meaning that hypotheses, analysis plan, and code of the data analyses were specified in detail before the data were analyzed. Some additional analyses were conducted that were not included in the pre-analysis plan. We will explicate which analyses were exploratory when describing these analyses and their results. The paper continues by providing an overview of publication bias methods. Next, we describe the criteria for a meta-analysis to be included in our study. Then we describe how the data of meta-analyses were extracted and analyzed, and list our hypotheses. Subsequently, we provide the results of our analyses and conclude with a discussion.</p>
</sec>
<sec id="sec002">
<title>Publication bias methods</title>
<p>Methods for examining publication bias can be divided into two groups: methods that assess or test the presence of publication bias, and methods that estimate effect sizes corrected for publication bias. Methods that correct effect sizes for publication bias usually also provide a confidence interval and test the null hypothesis of no effect corrected for publication bias. <xref ref-type="table" rid="pone.0215052.t001">Table 1</xref> summarizes the methods together with their characteristics and recommendations on when to use each method. The last column of the table lists whether the method is included in our analyses. Readers that are not interested in the details regarding the publication bias methods can focus on the summary in <xref ref-type="table" rid="pone.0215052.t001">Table 1</xref>.</p>
<table-wrap id="pone.0215052.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t001</object-id>
<label>Table 1</label> <caption><title>Summary of publication bias methods to assess publication bias and estimate effect sizes corrected for publication bias.</title> <p>The penultimate column lists principal references of the different methods and the final column indicates whether a method is included in the analyses of this paper.</p></caption>
<alternatives>
<graphic id="pone.0215052.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left">Method</th>
<th align="left">Description</th>
<th align="left">Characteristics/Recommendations</th>
<th align="left">Included in analyses</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="3"><bold>Assessing publication bias</bold></td>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left">Fail-safe <italic>N</italic></td>
<td align="left">Estimates number of effect sizes in the file-drawer</td>
<td align="left">Method is discouraged to be used, because it, for instance, assumes that all nonsignificant effect sizes are equal to zero and focuses on statistical instead of practical significance [<xref ref-type="bibr" rid="pone.0215052.ref039">39</xref>, <xref ref-type="bibr" rid="pone.0215052.ref040">40</xref>].</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Funnel plot</td>
<td align="left">Graphical representation of small-study effects where funnel plot asymmetry is an indicator of small-study effects</td>
<td align="left">Publication bias is not the only cause of funnel plot asymmetry [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>]. Eyeballing a funnel plot for asymmetry is subjective [<xref ref-type="bibr" rid="pone.0215052.ref046">46</xref>], so recommendation is to use a statistical test (i.e., Egger’s [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>] or rank-correlation test [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>]).</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Egger’s and rank-correlation test</td>
<td align="left">Statistical tests for testing funnel plot symmetry</td>
<td align="left">Publication bias is not the only cause of funnel plot asymmetry [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>]. Methods are recommended to be applied when there are 10 or more effect sizes [<xref ref-type="bibr" rid="pone.0215052.ref048">48</xref>] otherwise the methods have low statistical power [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>, <xref ref-type="bibr" rid="pone.0215052.ref049">49</xref>].</td>
<td align="left">Yes</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Test of Excess Significance</td>
<td align="left">Computes whether observed and expected number of statistically significant results are in agreement</td>
<td align="left">Do not apply the method in case of heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>]. Method is known to be conservative [<xref ref-type="bibr" rid="pone.0215052.ref051">51</xref>].</td>
<td align="left">Yes</td>
</tr>
<tr>
<td align="left"/>
<td align="left"><italic>p-</italic>uniform’s publication bias test</td>
<td align="left">Examines whether statistically significant <italic>p</italic>-values are uniformly distributed at the estimate of the fixed-effect model</td>
<td align="left">Method does not use information of nonsignificant effect sizes and, assumes homogeneous true effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>].</td>
<td align="left">Yes</td>
</tr>
<tr>
<td align="left" colspan="3"><bold>Correcting effect size for publication bias</bold></td>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left">Trim and fill method</td>
<td align="left">Method corrects for funnel plot asymmetry by trimming most extreme effect sizes and filling these effect sizes to obtain funnel plot symmetry</td>
<td align="left">Method is discouraged to be used because it falsely imputes effect sizes when none are missing and other methods have shown to outperform trim and fill [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>, <xref ref-type="bibr" rid="pone.0215052.ref054">54</xref>]. Moreover, funnel plot asymmetry is not only caused by publication bias [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>], and the method does also not perform well if heterogeneity in true effect size is present [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref055">55</xref>].</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"/>
<td align="left">PET-PEESE</td>
<td align="left">Extension of Egger’s test where the corrected estimate is the intercept of a regression line fitted through the effect sizes in a funnel plot</td>
<td align="left">Method becomes biased if it is based on less than 10 effect sizes, the between-study variance in true effect size is large, and the sample size of primary studies included in a meta-analysis is rather similar [<xref ref-type="bibr" rid="pone.0215052.ref056">56</xref>–<xref ref-type="bibr" rid="pone.0215052.ref059">59</xref>].</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"/>
<td align="left"><italic>p</italic>-uniform/<italic>p</italic>-curve</td>
<td align="left">Estimate is the effect size for which the distribution of conditional <italic>p</italic>-values is uniformly distributed</td>
<td align="left">Method does not use information of nonsignificant effect sizes and assumes homogeneous true effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>, <xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>].</td>
<td align="left">Yes</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Selection model approach</td>
<td align="left">Method makes assumptions on the distribution of effect sizes (effect size model) and mechanism of observing effect sizes (selection model). Estimation is performed by combining these two models.</td>
<td align="left">User has to make sophisticated assumptions and choices [<xref ref-type="bibr" rid="pone.0215052.ref039">39</xref>]. Large number of effect sizes (more than 100) are needed to avoid convergence problems [<xref ref-type="bibr" rid="pone.0215052.ref055">55</xref>, <xref ref-type="bibr" rid="pone.0215052.ref060">60</xref>], but recent research showed that convergence problems of the approach by Iyengar and Greenhouse [<xref ref-type="bibr" rid="pone.0215052.ref061">61</xref>, <xref ref-type="bibr" rid="pone.0215052.ref062">62</xref>] were only severe if there was no or extreme publication bias in combination with no or a small amount of heterogeneity in true effect size.</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"/>
<td align="left">10% most precise effect sizes</td>
<td align="left">Only the 10% most precise effect sizes are used for estimation with a random-effects model</td>
<td align="left">90% of the available effect sizes is discarded and bias in estimates increases as a function of heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref063">63</xref>].</td>
<td align="left">Yes</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec003">
<title>Assessing or testing publication bias</title>
<p>The most often used method for assessing publication bias is fail-safe <italic>N</italic> [<xref ref-type="bibr" rid="pone.0215052.ref034">34</xref>, <xref ref-type="bibr" rid="pone.0215052.ref037">37</xref>]. This method estimates how many effect sizes with a zero effect size have to be added to a meta-analysis for changing a statistically significant summary effect size in a meta-analysis to a nonsignificant result [<xref ref-type="bibr" rid="pone.0215052.ref038">38</xref>]. Applying the method is discouraged, because it makes the unrealistic assumption that all nonsignificant effect sizes are equal to zero, does not take study sample size into account, and focuses on statistical significance and not on the magnitude of an effect that is of substantial importance [<xref ref-type="bibr" rid="pone.0215052.ref039">39</xref>, <xref ref-type="bibr" rid="pone.0215052.ref040">40</xref>].</p>
<p>Another popular method is the funnel plot [<xref ref-type="bibr" rid="pone.0215052.ref041">41</xref>]. In a funnel plot, the effect size estimates of the included studies in a meta-analysis are presented on the <italic>x-</italic>axis and some measure of the effect sizes’ precision is displayed on the <italic>y-</italic>axis. The left panel in <xref ref-type="fig" rid="pone.0215052.g001">Fig 1</xref> shows a funnel plot for a meta-analysis in the systematic review by Jürgens and Graudal [<xref ref-type="bibr" rid="pone.0215052.ref042">42</xref>] studying the effect of sodium intake on different health outcomes. Solid circles in the funnel plot indicate studies’ Hedges’ <italic>g</italic> effect sizes (<italic>y</italic>-axis) and their standard errors (<italic>x</italic>-axis). A funnel plot illustrates whether small-study effects are present. That is, whether there is a relationship between effect size and its precision. The funnel plot should be symmetric and resemble an inverted funnel in the absence of small-study effects, whereas a gap in the funnel indicates that small-study effects exist. Publication bias is one of the causes of small-study effects [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>], but funnel plot asymmetry is often interpreted as evidence for publication bias in a meta-analysis. Small-study effects can also be caused by, for instance, researchers basing their sample size on statistical power analyses in combination with heterogeneity in true effect size (see supplemental materials of [<xref ref-type="bibr" rid="pone.0215052.ref044">44</xref>] and [<xref ref-type="bibr" rid="pone.0215052.ref045">45</xref>]). In this case, larger true effect sizes are associated with studies using smaller sample sizes, resulting in funnel plot asymmetry.</p>
<fig id="pone.0215052.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Funnel plot showing the relationship between the observed effect size (Hedges’ <italic>g</italic>; solid circles) and its standard error in a meta-analysis by Jürgens and Graudal [<xref ref-type="bibr" rid="pone.0215052.ref042">42</xref>] on the effect of sodium intake on Noradrenaline (left panel).</title>
<p>The funnel plot in the right panel also includes the Hedges’ <italic>g</italic> effect sizes that are imputed by the trim and fill method (open circles).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.g001" xlink:type="simple"/>
</fig>
<p>Evaluating whether small-study effects exist by eyeballing a funnel plot is rather subjective [<xref ref-type="bibr" rid="pone.0215052.ref046">46</xref>]. Hence, Egger’s regression test [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>] and the rank-correlation test [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>] were developed to test whether small-study effects are present in a meta-analysis. Egger’s regression test uses linear regression with the observed effect sizes as dependent variable and a measure of primary studies’ precision as predictor. Evidence for small-study effects is obtained if the slope of this regression line is significantly different from zero. The rank-correlation test computes the rank correlation (Kendall’s τ) between the study’s effect sizes and their precision to test for small-study effects. Drawback of these two tests is that statistical power to detect publication bias is low especially if there are few effect sizes in a meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>, <xref ref-type="bibr" rid="pone.0215052.ref049">49</xref>]. Hence, these methods are recommended to be only applied to meta-analyses with ten or more effect sizes [<xref ref-type="bibr" rid="pone.0215052.ref048">48</xref>].</p>
<p>The test of excess significance (TES) compares the number of statistically significant effect sizes in a meta-analysis with the expected number of statistically significant effect sizes [<xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>]. The expected number of statistically significant effect sizes is computed by summing the statistical power of each primary study in a meta-analysis. More statistically significant results than expected indicate that some effect sizes are (possibly because of publication bias) missing from the meta-analysis. Ioannidis and Trikalinos [<xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>] recommend to not apply the method if heterogeneity in true effect size is present. Moreover, the TES is known to be conservative [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref051">51</xref>].</p>
<p>Another more recently developed method for examining publication bias is the <italic>p</italic>-uniform method [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. This method is based on the statistical principle that the distribution of <italic>p-</italic>values at the true effect size is uniform. For example, the distribution of <italic>p-</italic>values under the null hypothesis is uniform. Since in the presence of publication bias not all statistically nonsignificant effect sizes get published, <italic>p-</italic>uniform discards nonsignificant effect sizes and computes <italic>p-</italic>values conditional on being statistically significant. These conditional <italic>p</italic>-values should be uniformly distributed at the (fixed-effect) meta-analytic effect size estimate based on the significant and nonsignificant effect sizes, and deviations from the uniform distribution signals publication bias. <italic>P-</italic>uniform’s publication bias test was compared to the TES in a Monte-Carlo simulation study [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>], and statistical power of <italic>p</italic>-uniform was in general larger than the TES except for conditions with a true effect size of zero in combination with statistically nonsignificant studies included in a meta-analysis. This simulation study also showed that Type-I error rate of <italic>p</italic>-uniform’s publication bias test was too low if the true effect size was of medium size. Limitations of <italic>p</italic>-uniform’s publication bias test are that it assumes that the true effect size is homogeneous (which is not very common, see for instance [<xref ref-type="bibr" rid="pone.0215052.ref064">64</xref>–<xref ref-type="bibr" rid="pone.0215052.ref066">66</xref>]), and that the method may inefficiently use the available information by discarding statistically nonsignificant effect sizes in a meta-analysis.</p>
</sec>
<sec id="sec004">
<title>Correcting effect sizes for publication bias</title>
<p>Publication bias tests provide evidence about the presence of publication bias in a meta-analysis. However, statistical power of publication bias tests is often low in practice [<xref ref-type="bibr" rid="pone.0215052.ref054">54</xref>], because the number of effect sizes in a meta-analysis is often small. For instance, the median number of effect sizes in meta-analyses published in the Cochrane Database of Systematic Reviews was equal to 3 [<xref ref-type="bibr" rid="pone.0215052.ref067">67</xref>, <xref ref-type="bibr" rid="pone.0215052.ref068">68</xref>]. Furthermore, the magnitude of the effect after correcting for publication bias is more of interest from the perspective of an applied researcher.</p>
<p>The most popular method to correct for publication bias in a meta-analysis is trim and fill [<xref ref-type="bibr" rid="pone.0215052.ref069">69</xref>, <xref ref-type="bibr" rid="pone.0215052.ref070">70</xref>]. This method corrects for funnel plot asymmetry by trimming the most extreme effect sizes from one side of the funnel plot and filling these effect sizes in the other side of the funnel plot to obtain funnel plot symmetry. The corrected effect size estimate is obtained by computing the meta-analytic estimate based on the observed and imputed effect sizes. Trim and fill can also be used to create a confidence interval and test the null hypothesis of no effect after adjusting for funnel plot asymmetry. The procedure of trim and fill is illustrated in the right panel of <xref ref-type="fig" rid="pone.0215052.g001">Fig 1</xref>. The most extreme effect sizes from the right-hand side of the funnel plot are trimmed and imputed in the left-hand side of the funnel plot (open circles in the right panel of <xref ref-type="fig" rid="pone.0215052.g001">Fig 1</xref>). A drawback of trim and fill, which it shares with other methods based on the funnel plot, is that it corrects for small-study effects that are not necessarily caused by publication bias. Furthermore, the method cannot accurately correct for publication bias when the true effect size is heterogeneous (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref055">55</xref>]). Simulation studies have also shown that results of trim and fill cannot be trusted because it incorrectly adds studies when none are missing [<xref ref-type="bibr" rid="pone.0215052.ref055">55</xref>, <xref ref-type="bibr" rid="pone.0215052.ref071">71</xref>, <xref ref-type="bibr" rid="pone.0215052.ref072">72</xref>]. Hence, trim and fill is discouraged because of its misleading results [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>, <xref ref-type="bibr" rid="pone.0215052.ref054">54</xref>].</p>
<p>The PET-PEESE method [<xref ref-type="bibr" rid="pone.0215052.ref065">65</xref>] is an extension of Egger’s regression test to estimate an effect size in a meta-analysis corrected for small-study effects. PET-PEESE is based on a regression analysis where the observed effect sizes are regressed on their standard errors by means of a weighted least squares regression with the inverse of the effect sizes’ sampling variances as weights. If the intercept is not significantly different from zero, the estimate of the intercept is interpreted as the effect size estimate corrected for publication bias. The estimate of the intercept reflects the effect size estimate in a study with a standard error of zero (i.e., a study with an infinite sample size). However, this estimator is biased if the intercept is significantly different from zero [<xref ref-type="bibr" rid="pone.0215052.ref065">65</xref>]. Hence, in case the intercept is significantly different from zero, the intercept of another weighted least squares regression analysis (with the inverse sampling variances as weights) is interpreted as the effect size estimate. In this regression analysis, the observed effect sizes are regressed on their sampling variances. Simulation studies have shown that PET-PEESE substantially reduced the overestimation caused by small-study effects [<xref ref-type="bibr" rid="pone.0215052.ref065">65</xref>]. However, PET-PEESE becomes biased when less than 10 effect sizes are included in a meta-analysis, the between-study variance in true effect size is large, and the sample size of primary studies included in a meta-analysis is rather similar [<xref ref-type="bibr" rid="pone.0215052.ref056">56</xref>–<xref ref-type="bibr" rid="pone.0215052.ref059">59</xref>].</p>
<p>The <italic>p-</italic>uniform method can also be used for estimating effect size (and a confidence interval) and testing the null hypothesis of no effect corrected for publication bias. <italic>P-</italic>uniform’s effect size estimate is equal to the effect size for which the <italic>p-</italic>values conditional on being statistically significant are uniformly distributed. A similar method that uses the distribution of conditional <italic>p</italic>-values for estimating effect size in the presence of publication bias is <italic>p</italic>-curve [<xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>]. This method is similar to the <italic>p</italic>-uniform method, but differs in implementation (for a description of the difference between the two methods see [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]). A limitation of <italic>p</italic>-uniform and <italic>p</italic>-curve is that effect sizes are overestimated in the presence of heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. Especially if the heterogeneity in true effect size is more than moderate (<italic>I</italic><sup>2</sup> &gt; 50%; more than half of the total variance in effect size is caused by heterogeneity) both methods overestimate the effect size, and their results should be interpreted as a sensitivity analysis. Another limitation of both methods is that they are not efficient if many nonsignificant effect sizes exist. Such results are discarded by the methods, yielding imprecise estimates and wide confidence intervals of <italic>p-</italic>uniform (<italic>p-</italic>curve does not estimate a confidence interval). <italic>P-</italic>uniform and <italic>p-</italic>curve both outperformed trim and fill in simulation studies [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>].</p>
<p>A selection model approach [<xref ref-type="bibr" rid="pone.0215052.ref045">45</xref>] can also be used for estimating effect size corrected for publication bias. A selection model makes assumptions on the distribution of effect sizes (i.e., effect size model) and the mechanism that determines which studies are selected (for publication) and hence observed (i.e., selection model). The effect size estimate (and confidence interval) corrected for publication bias is obtained by combining the effect size and selection model. Many different selection model approaches exist (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref073">73</xref>–<xref ref-type="bibr" rid="pone.0215052.ref078">78</xref>]). Some approaches estimate the selection model [<xref ref-type="bibr" rid="pone.0215052.ref074">74</xref>, <xref ref-type="bibr" rid="pone.0215052.ref077">77</xref>] whereas others assume a known selection model [<xref ref-type="bibr" rid="pone.0215052.ref079">79</xref>]. A recently proposed selection model approach [<xref ref-type="bibr" rid="pone.0215052.ref080">80</xref>] estimates effect size corrected for publication bias by using Bayesian model averaging over multiple selection models. Selection model approaches are hardly used in practice, because it requires sophisticated assumptions and choices [<xref ref-type="bibr" rid="pone.0215052.ref039">39</xref>] and a large number of effect sizes (more than 100) to avoid convergence problems [<xref ref-type="bibr" rid="pone.0215052.ref055">55</xref>, <xref ref-type="bibr" rid="pone.0215052.ref060">60</xref>]. However, two recent simulation studies [<xref ref-type="bibr" rid="pone.0215052.ref061">61</xref>, <xref ref-type="bibr" rid="pone.0215052.ref062">62</xref>] were conducted that included the three-parameter selection model approach by Iyengar and Greenhouse [<xref ref-type="bibr" rid="pone.0215052.ref074">74</xref>, <xref ref-type="bibr" rid="pone.0215052.ref081">81</xref>] and showed that convergence problems of this approach were only severe for conditions that included only 10 studies, or conditions wherein publication bias was extreme.</p>
<p>Stanley, Jarrel, and Doucouliagos [<xref ref-type="bibr" rid="pone.0215052.ref063">63</xref>] proposed to correct for publication bias in the effect size estimate by computing the unweighted mean of the 10% most precise observed effect sizes, or the single most precise study in case of less than ten effect sizes. The rationale underlying only using the 10% most precise observed effect sizes is that these primary study’s effect sizes are less affected by publication bias than the 90% less precise discarded effect sizes. We propose to not combine the 10% most precise observed effect sizes with an unweighted mean, but with a random-effects model to take differences in primary study’s sampling variances and heterogeneity in true effect size into account. A disadvantage of this method is that it is not efficient leading to imprecise estimates and wider confidence intervals than estimation based on all effect sizes since up to 90% of the data is discarded. Moreover, bias in the method’s estimates increases as a function of the heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref063">63</xref>].</p>
</sec>
</sec>
<sec id="sec005" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec006">
<title>Data</title>
<p>A large-scale data set was created with meta-analyses published between 2004 and 2014 in Psychological Bulletin and in the Cochrane Library to study the extent and prevalence of publication bias in psychology and medicine. Psychological Bulletin was selected to represent meta-analyses in psychology, because this journal publishes many meta-analyses on a variety of topics from psychology. Meta-analyses published in the Cochrane Database of Systematic Reviews (CDSR) of the Cochrane Library were used to represent medicine. This database is a collection of peer-reviewed systematic reviews conducted in the field of medicine.</p>
<p>A first requirement for the inclusion of a meta-analysis was that either fixed-effect or random-effects meta-analysis had to be used in the meta-analysis (i.e., no other meta-analytic methods as, for instance, meta-analytic structural equation modelling or multilevel meta-analysis). Another requirement was that sufficient information in the meta-analysis had to be available to compute the primary study’s standardized effect size and its sampling variance. The same effect size measure (e.g., correlation and standardized mean difference) as in the original meta-analysis was used to compute the primary study’s effect size and its sampling variance. Formulas as described in [<xref ref-type="bibr" rid="pone.0215052.ref082">82</xref>], [<xref ref-type="bibr" rid="pone.0215052.ref083">83</xref>], and [<xref ref-type="bibr" rid="pone.0215052.ref084">84</xref>] were used for computing the standardized effect sizes and their sampling variances. For each included primary study, we extracted information on effect size and sampling variance, as well as information on all categorical moderator variables. Based on these moderators, we created homogeneous subsets of effect sizes. That is, a homogeneous subset consisted of the effect sizes that had the same scores on all the extracted moderators. Consequently, each meta-analysis could contain more than one subset of effect sizes if multiple homogeneous subsets were extracted based on the included moderators.</p>
<p>We only included subsets with less than moderate heterogeneity (<italic>I</italic><sup>2</sup>&lt;50%) [<xref ref-type="bibr" rid="pone.0215052.ref085">85</xref>], because none of the publication bias methods has desirable statistical properties under extreme heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. This implied that the population that we study is the homogeneous subsets of meta-analyses that were published in the psychological and medical literature. Drawbacks of examining heterogeneity in true effect size with the <italic>I</italic><sup>2</sup>-statistic are that its value heavily depends on the sample size of the primary studies in case of heterogeneity [<xref ref-type="bibr" rid="pone.0215052.ref086">86</xref>] and the statistic is imprecise in case of a small number of primary studies in a meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref087">87</xref>, <xref ref-type="bibr" rid="pone.0215052.ref088">88</xref>]. However, the <italic>I</italic><sup>2</sup>-statistic enables comparison across meta-analyses that used different effect size measures which is not possible by comparing estimates of the between-study variance (<italic>τ</italic><sup>2</sup>) in true effect size of meta-analyses. Different effect size measures were sometimes used within a meta-analysis. This may cause heterogeneity in a meta-analysis, so the type of effect size measure was also used for creating homogeneous subsets. Publication bias tests have low statistical power (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>, <xref ref-type="bibr" rid="pone.0215052.ref089">89</xref>]) if the number of effect sizes in a meta-analysis is small. Hence, another criterion for including a subset in the analyses was that a subset should contain at least five effect sizes.</p>
<p>We searched within the journal Psychological Bulletin for meta-analyses published between 2004 and 2014 by using the search terms “meta-analy*” and <italic>not</italic> “comment”, “note”, “correction”, and “reply” in the article’s title. This search resulted in 137 meta-analyses that were published between 2004 and 2014 and that were eligible for inclusion. A flowchart is presented in <xref ref-type="fig" rid="pone.0215052.g002">Fig 2</xref> describing the data extraction for the meta-analyses published in Psychological Bulletin. Eighty-three meta-analyses met the inclusion criteria and could be included since the data were available in the paper or were obtained by emailing the corresponding author. Data of these meta-analyses were extracted by hand and resulted in 9,568 subsets. Data from a random sample of 10% of the included meta-analyses was extracted a second time by a different researcher to verify the procedure of extracting data. Four additional subsets were excluded after verifying the data, because these subsets were heterogeneous instead of homogeneous. After excluding subsets with less than five effect sizes and heterogeneous subsets, a total number of 366 subsets from 83 meta-analyses were available for the analyses.</p>
<fig id="pone.0215052.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Flowchart illustrating the extraction procedure of data from meta-analyses published in Psychological Bulletin between 2004 and 2014.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.g002" xlink:type="simple"/>
</fig>
<p>Data of all systematic reviews in the CDSR are stored online in a standardized format, and data of these reviews can therefore be extracted by an automated procedure. We used the Cochrane scraper developed by Springate and Kontopantelis [<xref ref-type="bibr" rid="pone.0215052.ref090">90</xref>] to automatically extract data from systematic reviews. The total number of meta-analyses in the CDSR is larger than in Psychological Bulletin, so we drew a simple random sample without replacement of systematic reviews from the CDSR to represent meta-analyses published in medicine. Each systematic review in the database has an identification number. We sampled identification numbers, extracted subsets from the sampled systematic review, and included a subset in our study if (i) <italic>I</italic><sup>2</sup>&lt;50%, (ii) the number of effect sizes in a subset was at least five, and (iii) the subset was independent of previous included subsets (i.e., no overlap between effect sizes in different subsets). We continued sampling systematic reviews and extracting subsets till the same number of eligible subsets for inclusion were obtained as extracted from Psychological Bulletin (366). Data and/or descriptions of the data of the meta-analyses are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/9jqht/" xlink:type="simple">https://osf.io/9jqht/</ext-link>. The next section describes how the research questions were answered, and how the variables were measured.</p>
</sec>
<sec id="sec007">
<title>Analysis</title>
<sec id="sec008">
<title>Prevalence of publication bias</title>
<p>The prevalence of publication bias in homogeneous subsets from meta-analyses in the psychological and medical literature was examined to answer research question 1 by using the methods listed in the last column of <xref ref-type="table" rid="pone.0215052.t001">Table 1</xref>. Egger’s test and the rank-correlation test were used in the analyses to test for funnel plot asymmetry instead of eyeballing a funnel plot. <italic>P-</italic>uniform’s publication bias test can be applied to observed effect sizes in a subset that are either significantly smaller or larger than zero. Hence, <italic>p</italic>-uniform was applied to negative or positive statistically significant effect sizes in a subset depending on where the majority of statistically significant effect sizes was observed (using a two-tailed hypothesis test with α = .05). The estimator based on the Irwin-Hall distribution was used for <italic>p</italic>-uniform, because this estimator seemed to have the best statistical properties and provides a confidence interval [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. Publication bias tests have low statistical power, so we followed a recommendation by Egger and colleagues [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>] to conduct two-tailed hypothesis tests with α = .1 for all methods. Unintentionally, one-tailed <italic>p</italic>-values of <italic>p</italic>-uniform’s publication bias test were computed in the preregistered R code for subsets of CDSR instead of the intended two-tailed <italic>p-</italic>values. Since two-tailed <italic>p-</italic>values were computed for all the other publication bias tests, we corrected the pre-registered R code such that two-tailed <italic>p-</italic>values were also computed for <italic>p</italic>-uniform’s publication bias test.</p>
<p>We answered research question 1a about the prevalence of publication bias in meta-analyses published in Psychological Bulletin and CDSR by counting how often each method rejects the null hypothesis of no publication bias. Agreement among the publication bias tests was examined by computing Loevinger’s <italic>H</italic> values [<xref ref-type="bibr" rid="pone.0215052.ref091">91</xref>] for each combination of two methods. Loevinger’s <italic>H</italic> is a statistic to quantify the association between two dichotomous variables (i.e., statistically significant or not). The maximum value of Loevinger <italic>H</italic> is 1 indicating a perfect association where the minimum value depends on characteristics of the data. For subsets with no statistically significant effect sizes, <italic>p-</italic>uniform could not be applied, so we computed the association between the results of <italic>p-</italic>uniform and other methods only for subsets with statistically significant effect sizes.</p>
<p>We studied whether publication bias was more prevalent in homogeneous subsets from Psychological Bulletin and CDSR (research question 1b) by conducting for each publication bias test a logistic regression with as dependent variable whether a publication bias test was statistically significant or not and as predictor a dummy variable indicating whether a subset was obtained from Psychological Bulletin or CDSR (reference category). The number of effect sizes in a subset (or statistically significant effect sizes for <italic>p</italic>-uniform) was included as control variable, because statistical power of publication bias tests depends on the number of effect sizes in a subset and the number of effect sizes in subsets from meta-analyses published in Psychological Bulletin and CDSR were expected to differ. We hypothesized that publication bias would be more severe in subsets from Psychological Bulletin than CDSR after controlling for the number of effect sizes in a subset (or number of statistically significant effect sizes for <italic>p</italic>-uniform). This relationship was expected because medical researchers have been longer aware of the consequences of publication bias whereas broad awareness of publication bias recently originated in psychology. One-tailed hypothesis tests with α = .05 were used for answering research question 1b. As a sensitivity analysis, we also conducted for each publication bias test a multilevel logistic regression where we take into account that the subsets were nested in the meta-analyses. This analysis was not specified in the pre-analysis plan.</p>
</sec>
<sec id="sec009">
<title>Predicting effect size estimation</title>
<p>Characteristics of subsets were used to predict the estimates of random-effects meta-analysis and estimates of <italic>p-</italic>uniform in research question 2. All effect sizes and their sampling variances were transformed to Cohen’s <italic>d</italic> to enable interpretation of the results by using the formulas in section 12.5 of [<xref ref-type="bibr" rid="pone.0215052.ref082">82</xref>]. If Cohen’s <italic>d</italic> and their sampling variances could not be computed based on the available information, Hedges’ <italic>g</italic> was used as an approximation of Cohen’s <italic>d</italic> (6.4% of all subsets).</p>
<p>Random-effects meta-analysis was used to estimate the effect size rather than fixed-effect meta-analysis. Random-effects meta-analysis assumes that there is no single fixed true effect underlying each effect size [<xref ref-type="bibr" rid="pone.0215052.ref092">92</xref>], and was preferred over fixed-effect meta-analysis because a small amount of heterogeneity in true effect size could be present in the subsets. The Paule-Mandel estimator [<xref ref-type="bibr" rid="pone.0215052.ref093">93</xref>] was used in random-effects meta-analysis for estimating the amount of between-study variance in true effect size since this estimator has the best statistical properties in most situations [<xref ref-type="bibr" rid="pone.0215052.ref094">94</xref>, <xref ref-type="bibr" rid="pone.0215052.ref095">95</xref>]. Effect sizes corrected for publication bias were estimated with <italic>p</italic>-uniform and based on the 10% most precise observed effect sizes (see last column of <xref ref-type="table" rid="pone.0215052.t001">Table 1</xref>). Estimation based on the 10% most precise observed effect sizes was included as an exploratory analysis to examine whether estimates of <italic>p-</italic>uniform were in line with another method to correct effect sizes for publication bias. If the number of observed effect sizes in a subset was smaller than ten, the most precise estimate was interpreted as estimate of the 10% most precise observed effect sizes. For applying <italic>p</italic>-uniform, the estimator based on the Irwin-Hall distribution was used, and two-tailed hypothesis tests in the primary studies were conducted with α = .05. The underlying true effect size in a subset can be either positive or negative. Hence, the dependent variables of these analyses were the absolute values of the estimates of random-effects meta-analysis and <italic>p</italic>-uniform.</p>
<p>Selection model approaches and PET-PEESE methods were not incorporated in the analyses, because the number of effect sizes included in meta-analyses in medicine is often too small for these methods. Selection model approaches suffer from convergence problems when applied to data with these characteristics (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref060">60</xref>, <xref ref-type="bibr" rid="pone.0215052.ref061">61</xref>]), and PET-PEESE is not recommended to be used since it yields unreliable results if there are less than 10 observed effect sizes [<xref ref-type="bibr" rid="pone.0215052.ref056">56</xref>]. <italic>P-</italic>uniform was preferred over trim and fill and <italic>p-</italic>curve, because applying trim and fill is discouraged [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref053">53</xref>, <xref ref-type="bibr" rid="pone.0215052.ref054">54</xref>] and <italic>p</italic>-curve is not able to estimate a confidence interval around its effect size estimate.</p>
<p>Two weighted least squares (WLS) regressions were performed with as dependent variables the absolute values of the effect size estimates of either random-effects meta-analysis or <italic>p</italic>-uniform. Since we meta-analyze the effect sizes estimated with meta-analysis methods, we refer to these analyses as meta-meta-regressions. The inverse of the variance of a random-effects model was selected as weights in both meta-meta-regressions, because it is a function of both the sample size of the primary studies and the number of effect sizes in a subset. <italic>P-</italic>uniform can only be applied to subsets with statistically significant effect sizes, so the meta-meta-regression with the effect size estimates of <italic>p</italic>-uniform as dependent variable was only based on these subsets.</p>
<p>Four predictors were included in the meta-meta regressions. The predictors and the hypothesized relationships are listed in the first two columns of <xref ref-type="table" rid="pone.0215052.t002">Table 2</xref>. The meta-meta-analytic effect size estimate was expected to be larger in subsets from Psychological Bulletin, because publication bias was expected to be more severe in psychology than medicine. No relationship was hypothesized between the <italic>I</italic><sup>2</sup>-statistic and the meta-analytic effect size estimate, because heterogeneity can be either over- or underestimated depending on the extent of publication bias [<xref ref-type="bibr" rid="pone.0215052.ref096">96</xref>, <xref ref-type="bibr" rid="pone.0215052.ref097">97</xref>]. Primary studies’ precision in a subset was operationalized by computing the harmonic mean of the primary studies’ standard error. A negative relationship was expected between primary studies’ precision and the meta-analytic estimate, because less precise effect size estimates (i.e., larger standard errors) were expected to be accompanied with more bias and hence larger meta-analytic effect size estimates. The number of effect sizes in a subset was included to control for differences in the number of studies in a meta-analysis.</p>
<table-wrap id="pone.0215052.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t002</object-id>
<label>Table 2</label> <caption><title>Hypotheses between predictors and effect size estimate based on random-effects model, <italic>p-</italic>uniform, and overestimation in effect size when comparing estimate of the random-effects model with <italic>p</italic>-uniform (<italic>Y</italic>).</title></caption>
<alternatives>
<graphic id="pone.0215052.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="center" colspan="3">Hypotheses</th>
</tr>
<tr>
<th align="left">Predictor</th>
<th align="center">Random-effects model</th>
<th align="center"><italic>p-</italic>uniform</th>
<th align="center">Overestimation (<italic>Y</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Discipline</td>
<td align="left">Larger estimates in subsets from Psychological Bulletin</td>
<td align="left">No specific expectation</td>
<td align="left">Overestimation more severe in Psychological Bulletin</td>
</tr>
<tr>
<td align="left"><italic>I</italic><sup>2</sup>-statistic</td>
<td align="left">No relationship</td>
<td align="left">Positive relationship</td>
<td align="left">Negative relationship</td>
</tr>
<tr>
<td align="left">Primary studies’ precision</td>
<td align="left">Negative relationship</td>
<td align="left">No relationship</td>
<td align="left">Negative relationship</td>
</tr>
<tr>
<td align="left">Proportion of significant effect sizes</td>
<td align="left">Predictor not included</td>
<td align="left">No specific expectation</td>
<td align="left">No specific expectation</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The hypotheses concerning the effects in the meta-meta regression on <italic>p</italic>-uniform’s estimates are presented in the third column of <xref ref-type="table" rid="pone.0215052.t002">Table 2</xref>. No hypothesis was specified for the effect of discipline since <italic>p</italic>-uniform is supposed to correct for possible differences between both disciplines in effect sizes due to publication bias. We expected a positive relationship with the <italic>I</italic><sup>2</sup>-statistic, because <italic>p</italic>-uniform overestimates the true effect size in the presence of heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. No specific relationship was predicted with primary studies’ precision as <italic>p</italic>-uniform is supposed to correct for publication bias. A specific relationship was also not hypothesized for the effect of the proportion of statistically significant effect sizes in a subset. Many statistically significant effect sizes in a subset suggest that the studied effect size is large, sample size of the primary studies are large, or there was severe publication bias in combination with many conducted (but not published) primary studies. These partly opposing effects might have canceled each other out or there can be a positive or negative relationship. The number of effect sizes in a subset was again included as control variable.</p>
<p>The effect size estimate of <italic>p</italic>-uniform can become extremely positive or negative if there are multiple <italic>p</italic>-values just below the α-level [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. These outliers may affect the results of the meta-meta-regression with <italic>p</italic>-uniform’s estimate as dependent variable. Hence, we used quantile regression [<xref ref-type="bibr" rid="pone.0215052.ref098">98</xref>] as a sensitivity analysis, because this procedure is less influenced by outliers in the dependent variable. In quantile regression, the predictors were regressed on the median of the estimates of <italic>p</italic>-uniform. Moreover, we also conducted another meta-meta-regression as a sensitivity analysis where we added a random effect to take into account that the subsets were nested in meta-analyses. Both sensitivity analyses were exploratory analyses that were not specified in the pre-analysis plan.</p>
</sec>
<sec id="sec010">
<title>Overestimation of effect size</title>
<p>Estimates of random-effects meta-analysis and <italic>p</italic>-uniform obtained for answering research question 2 were used to examine the overestimation caused by publication bias. As an exploratory analysis, overestimation was also studied by comparing estimates of random-effects meta-analysis with those of 10% most precise observed effect sizes. It is possible that especially estimates of the meta-analysis and <italic>p</italic>-uniform have opposite signs (i.e., negative estimate of <italic>p</italic>-uniform and positive meta-analytic estimate or the other way around). An effect size estimate of <italic>p-</italic>uniform in the opposite direction than the meta-analytic estimate is often unrealistic, because this suggests that, for instance, a negative true effect size results in multiple positive observed effect sizes. Effect size estimates in opposing directions by meta-analysis and <italic>p-</italic>uniform may be caused by many <italic>p-</italic>values just below the α-level [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. Hence, <italic>p</italic>-uniform’s estimate was set equal to zero in these situations. Setting <italic>p-</italic>uniform’s estimate to zero when its sign is opposite to that of random-effects meta-analysis is in line with the recommendation in [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. We did not set estimates based on the 10% most precise observed effect sizes to zero, because this estimator will not yield unrealistic estimates in the opposite direction than random-effects meta-analysis in the absence of heterogeneity. Such an estimate in the opposite direction based on the 10% most precise observed effect sizes is also unlikely to occur. The most precise observed effect sizes get the largest weight in a random-effects meta-analysis and the sign of these precise observed effect sizes is for the vast majority of cases in line with the sign of the random-effects meta-analysis.</p>
<p>A new variable <italic>Y</italic> was created to reflect the overestimation of random-effects meta-analysis when compared with <italic>p</italic>-uniform and the 10% most precise observed effect sizes. Such a <italic>Y</italic>-variable was created for both methods that correct effect size estimates for publication bias. If the meta-analytic estimate was larger than zero, <italic>Y</italic> = MA-corrected where “MA” is the meta-analytic estimate and “corrected” is the estimate of either <italic>p</italic>-uniform or the 10% most precise observed effect sizes. If the meta-analytic estimate was smaller than zero, <italic>Y</italic> = -MA+corrected. Variable <italic>Y</italic> was zero if the estimates of the random-effects meta-analysis and an estimate corrected for publication bias were the same, positive if a corrected effect size estimate was closer to zero than the meta-analytic estimate (if they originally had the same sign), and negative if a corrected estimate was farther away from zero than the meta-analytic estimate (if they originally had the same sign). The <italic>Y</italic> variable based on <italic>p-</italic>uniform was computed for each subset with statistically significant effect sizes. We computed the mean, median, and a 95% confidence interval by using a normal approximation and estimated standard error equal to the standard deviation of <italic>Y</italic> divided by the square root of the number of homogeneous subsets. These estimates and 95% confidence intervals were computed for subsets from Psychological Bulletin and CDSR in order to gather insight in the amount of overestimation in effect size (research question 3a).</p>
<p>To answer research question 3b, we carried out meta-meta regressions on <italic>Y</italic> based on <italic>p-u</italic>niform with the inverse of the variance of the random-effects meta-analytic estimate as weights. We used the predictors that we also included in research question 2. The hypothesized relationships are summarized in the fourth column of <xref ref-type="table" rid="pone.0215052.t002">Table 2</xref>. A larger value on <italic>Y</italic> was expected for subsets from Psychological Bulletin than CDSR, because overestimation was expected to be more severe in psychology than in medicine. We hypothesized a negative relation between the <italic>I</italic><sup>2</sup>-statistic and <italic>Y</italic>, because <italic>p-</italic>uniform overestimates the effect size in the presence of heterogeneity in true effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. Primary studies’ precision was hypothesized to be negatively related to <italic>Y</italic>, because overestimation of the meta-analytic estimate was expected to decrease as a function of primary studies’ precision. We had no specific expectations on the relationships between the number of effect sizes in a subset and the proportion of statistically significant effect sizes in a subset. Although a positive effect of this proportion on the meta-analytic effect size estimate was expected, the effect of the proportion on <italic>p</italic>-uniform’s estimate was unclear. We included the number of effect sizes in a subset in the meta-meta-regression as a control variable.</p>
<p>Estimates of <italic>p-</italic>uniform that were in the opposite direction than traditional meta-analysis were set equal to zero before computing the <italic>Y</italic>-variable. This may have affected the results of the meta-meta-regression since the dependent variable <italic>Y</italic> did not follow a normal distribution. Hence, quantile regression [<xref ref-type="bibr" rid="pone.0215052.ref098">98</xref>] was used as sensitivity analysis with the median of <italic>Y</italic> as dependent variable instead of the mean of <italic>Y</italic> in the meta-meta regression. We also conducted another meta-meta-regression as a sensitivity analysis where a random effect was included to take into account that the subsets were nested in meta-analyses. Both sensitivity analyses were exploratory analyses that were not specified in the pre-analysis plan.</p>
</sec>
<sec id="sec011">
<title>Monte-Carlo simulation study</title>
<p>Following up on the comments of a reviewer we examined the statistical properties of our preregistered analyses by means of a Monte-Carlo simulation study. More specifically, we examined the statistical power of publication bias tests and properties of effect size estimation based on the 10% most precise observed effect sizes, both as a function of publication bias and true effect size. As the analysis based on the 10% most precise estimates does not make any assumptions about the publication process (like the publication bias methods, including <italic>p</italic>-uniform), we consider this analysis to provide additional valuable information about the extent of publication bias in the psychology and medicine literature.</p>
<p>Cohen’s <italic>d</italic> effect sizes were simulated under the fixed-effect meta-analysis model using the number of observed effect sizes and their standard errors of the homogeneous subsets included in our large-scale dataset. That is, effect sizes were simulated from a normal distribution with mean μ and variance equal to the ‘observed’ squared standard errors of each homogeneous subset. Publication bias was introduced by always including statistically significant effect sizes where significance was determined based on a one-tailed test with α = .025 to resemble common practice to test a two-tailed hypothesis with α = .05 and only report results in the predicted direction. All generated nonsignificant effect sizes had a probability equal to 1-<italic>pub</italic> to be included. For each effect size in the homogeneous subset, the observed effect size was simulated until it was ‘published’; as a result the simulated homogeneous subset had the same properties (number of studies, standard errors of the studies but not the effect sizes and their corresponding <italic>p-</italic>values) as the observed homogeneous subset.</p>
<p>The publication bias tests (see <xref ref-type="table" rid="pone.0215052.t001">Table 1</xref> for the included methods) and methods to correct effect size for publication bias (<italic>p</italic>-uniform and meta-analysis based on the 10% most precise observed effect sizes) were applied to data of each generated homogeneous subset. We examined Type-I error rate and statistical power of the publication bias tests using the same α-level (i.e., 0.1) as for testing for publication bias in the homogeneous subsets. We also assessed the overestimation of the random-effects model with the Paule-Mandel estimator [<xref ref-type="bibr" rid="pone.0215052.ref093">93</xref>] for the between-study variance when compared with the 10% most precise observed effect sizes by computing the earlier introduced <italic>Y</italic>-variable.</p>
<p>Data of homogeneous subsets were simulated for characteristics of all 732 homogeneous subsets and repeated 1,000 times. Values for μ were selected to reflect no (μ = 0), small (μ = 0.2), and medium (μ = 0.5) effect regarding the guidelines by Cohen [<xref ref-type="bibr" rid="pone.0215052.ref099">99</xref>]. Publication bias (<italic>pub</italic>) was varied from 0, 0.25, 0.5, 0.75, 0.85, 0.95, and 1, with <italic>pub</italic> = 0 implying no publication bias and 1 extreme publication bias. The Monte-Carlo simulation study was programmed in R [<xref ref-type="bibr" rid="pone.0215052.ref100">100</xref>] and the packages “metafor” [<xref ref-type="bibr" rid="pone.0215052.ref101">101</xref>], “puniform” [<xref ref-type="bibr" rid="pone.0215052.ref102">102</xref>], and “parallel” [<xref ref-type="bibr" rid="pone.0215052.ref100">100</xref>] were used (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/efkn9/" xlink:type="simple">https://osf.io/efkn9/</ext-link> for R code of the simulation study).</p>
</sec>
</sec>
</sec>
<sec id="sec012" sec-type="results">
<title>Results</title>
<sec id="sec013">
<title>Descriptive statistics</title>
<p>The total number of included homogeneous subsets was 732 (366 representing Psychological Bulletin and 366 representing CDSR). <xref ref-type="table" rid="pone.0215052.t003">Table 3</xref> shows descriptive results (number of effect sizes, percentage of statistically significant effect sizes, primary study sample sizes, and positive and negative meta-analytic effect size estimates) of applying random-effects meta-analysis, <italic>p</italic>-uniform, and random-effects meta-analysis based on the 10% most precise observed effect sizes.</p>
<table-wrap id="pone.0215052.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t003</object-id>
<label>Table 3</label> <caption><title>Percentage of statistically significant effect size estimates, median number of effect sizes and median of average sample size per homogeneous subset, and mean and median of effect size estimates when the subsets were analyzed with random-effects meta-analysis, <italic>p</italic>-uniform, and random-effects meta-analysis based on the 10% most precise observed effect sizes.</title></caption>
<alternatives>
<graphic id="pone.0215052.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left"/>
<th align="left"/>
<th align="left">RE meta-analysis</th>
<th align="left"><italic>p</italic>-uniform</th>
<th align="left">10% most precise</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="3"><bold>Psychological Bulletin</bold><break/><bold>28.9% statistically significant</bold></td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Median (IQR) number of effect sizes</td>
<td align="left">6 (5;9)</td>
<td align="left">1 (0;4)</td>
<td align="left">1 (1;1)</td>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Median (IQR) sample size</td>
<td align="left">97.8 (52.4;173.2)</td>
<td align="left">109 (56.5;206.2)</td>
<td align="left">207.3 (100;466)</td>
</tr>
<tr>
<td align="left"/>
<td align="left" colspan="2"><underline>Positive RE meta-analysis estimates:</underline><break/>67.2% of homogeneous subsets</td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Mean, median, [min.;max.], (SD) of estimates</td>
<td align="left">0.332, 0.279, [0;1.456] (0.264)</td>
<td align="left">-0.168, 0.372,<break/>[-21.584;1.295] (2.367)</td>
<td align="left">0.283, 0.22,<break/>[-0.629;1.34] (0.289)</td>
</tr>
<tr>
<td align="left"/>
<td align="left" colspan="2"><underline>Negative RE meta-analysis estimates:</underline><break/>32% of homogeneous subsets</td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Mean, median, [min.;max.], (SD) of estimates</td>
<td align="left">-0.216, -0.123,<break/>[-1.057;-0.002] (0.231)</td>
<td align="left">-0.041, -0.214,<break/>[-5.166;13.845] (1.84)</td>
<td align="left">-0.228, -0.204,<break/>[-0.972;0.181] (0.247)</td>
</tr>
<tr>
<td align="left" colspan="3"><bold>CDSR</bold><break/><bold>18.9% statistically significant</bold></td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Median (IQR) number of effect sizes</td>
<td align="left">6 (5;8)</td>
<td align="left">1 (0;2)</td>
<td align="left">1 (1;1)</td>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Median (IQR) sample size</td>
<td align="left">126.6 (68.3;223.3)</td>
<td align="left">123.3 (71.9;283.5)</td>
<td align="left">207 (101.2;443)</td>
</tr>
<tr>
<td align="left"/>
<td align="left" colspan="2"><underline>Positive RE meta-analysis estimates:</underline><break/>45.1% of homogeneous subsets</td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Mean, median, [min.;max.], (SD) of estimates</td>
<td align="left">0.304, 0.215, [0.001;1.833] (0.311)</td>
<td align="left">-1.049, 0.323,<break/>[-60.85;1.771] (6.978)</td>
<td align="left">0.284, 0.201,<break/>[-0.709;1.757] (0.366)</td>
</tr>
<tr>
<td align="left"/>
<td align="left" colspan="2"><underline>Negative RE meta-analysis estimates:</underline><break/>54.9% of homogeneous subsets</td>
<td align="left"/>
<td align="left"/>
<td align="left"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="left">Mean, median, [min.;max.], (SD) of estimates</td>
<td align="left">-0.267, -0.19,<break/>[-1.343;0] (0.253)</td>
<td align="left">1.51, -0.239,<break/>[-1.581;163.53] (15.064)</td>
<td align="left">-0.214, -0.182,<break/>[-1.205;0.644] (0.286)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>RE meta-analysis is random-effects meta-analysis, IQR is the interquartile range, min. is the minimum value, max. is the maximum value, SD is the standard deviation, and CDSR is Cochrane Database of Systematic Reviews. The percentages of homogeneous subsets with positive and negative RE meta-analysis estimates do not sum to 100%, because the estimates of three homogeneous subsets obtained from the meta-analysis by Else-Quest and colleagues [<xref ref-type="bibr" rid="pone.0215052.ref103">103</xref>] were equal to zero. These authors set effect sizes to zero if the effect size could not have been extracted from a primary study but was reported as not statistically significant.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>The percentage of effect sizes (across all homogeneous subsets) that was statistically significant was 28.9% and 18.9% in Psychological Bulletin and CDSR, respectively. These percentages were lower than those based on the excluded heterogeneous subsets (44.2% and 28.9%, respectively). The number of effect sizes in subsets was similar in Psychological Bulletin and CDSR. The majority of subsets contained less than 10 effect sizes (third quartile 9 for Psychological Bulletin and 8 for CDSR) meaning that the characteristics of the subsets were very tough for publication bias methods. Statistical power of publication bias is low in these conditions [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>, <xref ref-type="bibr" rid="pone.0215052.ref049">49</xref>] and effect size estimates corrected for publication bias are imprecise [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. The number of statistically significant effect sizes in the subsets based on a two-tailed hypothesis test with α = .05 was also small (listed in column with results of <italic>p</italic>-uniform). The median number of statistically significant effect sizes in the subsets was 1 for both Psychological Bulletin and CDSR. Moreover, 267 (73%) of the subsets from Psychological Bulletin and 214 (58.5%) of the subsets from CDSR contained at least one statistically significant effect size; hence 27% and 41.5% of subsets did not contain a single statistically significant effect size. Consequently, <italic>p</italic>-uniform could only be applied to 481 (65.7%) of the subsets. Of these subsets 180 (37.4%) included only one statistically significant effect size, so the characteristics of the subsets were very challenging for <italic>p</italic>-uniform. However, methods based on similar methodology as <italic>p-</italic>uniform to, for instance, compare an original study and replication and to determine the required sample size in a power analysis showed that one or two effect sizes can be sufficient for accurate estimation of effect size [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref104">104</xref>–<xref ref-type="bibr" rid="pone.0215052.ref106">106</xref>]. The median and interquartile range of the 10% most precise effect size estimates were all equal to one, and estimates of this method were for 676 (92.3%) subsets based on only one effect size.</p>
<p>The median of the average sample size per subset was slightly larger for CDSR (126.6) than for Psychological Bulletin (97.8). The interquartile range of average sample size within subsets from CDSR (68.3; 223.3) was also larger than for subsets from Psychological Bulletin (52.4;173.2). Psychological Bulletin and CDSR showed small differences in the median and interquartile range of the average sample size in subsets if computed based on only the statistically significant effect sizes (<italic>p-</italic>uniform) or the 10% most precise effect size estimates.</p>
<p>Results of estimating effect size in subsets with random-effects meta-analysis, <italic>p</italic>-uniform, and random-effects meta-analysis based on the 10% most precise observed effect sizes (exploratory analysis) are also included in <xref ref-type="table" rid="pone.0215052.t003">Table 3</xref>. To increase interpretability of the results, estimates were grouped depending on whether the effect size estimate of random-effects meta-analysis was positive or negative. The mean and median of the effect size estimates of random-effects meta-analysis and those based on the 10% most precise observed effect sizes were highly similar (difference at most 0.053). However, estimates of <italic>p</italic>-uniform deviated from the other two methods, because <italic>p</italic>-uniform’s estimates were in some subsets very positive or negative (i.e., 4 estimates were larger than 10 and 7 estimates were smaller than -10) due to <italic>p</italic>-values of the primary study’s effect sizes close to the α-level. Consequently, the standard deviation and range of the estimates of <italic>p</italic>-uniform were larger than of random-effects meta-analysis and based on the 10% most precise observed effect sizes.</p>
</sec>
<sec id="sec014">
<title>Prevalence of publication bias</title>
<p><xref ref-type="table" rid="pone.0215052.t004">Table 4</xref> shows the results of applying Egger’s regression test, the rank-correlation test, <italic>p</italic>-uniform’s publication bias test, and the TES to examine the prevalence of publication bias in the meta-analyses. The panels in <xref ref-type="table" rid="pone.0215052.t004">Table 4</xref> illustrate how often each publication bias test was statistically significant (marginal frequencies and percentages) and also the agreement among the methods (joint frequencies). Agreement among the methods was quantified by means of Loevinger’s <italic>H</italic> (bottom-right cell of each panel).</p>
<table-wrap id="pone.0215052.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t004</object-id>
<label>Table 4</label> <caption><title>Results of applying Egger’s regression test, rank-correlation test, <italic>p</italic>-uniform’s publication bias test, and test of excess significance (TES) to examine the prevalence of publication bias in meta-analyses from Psychological Bulletin and Cochrane Database of Systematic Reviews.</title></caption>
<alternatives>
<graphic id="pone.0215052.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left"/>
<th align="center" colspan="2">Rank-correlation</th>
<th align="left"/>
<th align="left"/>
<th align="left"/>
<th align="center" colspan="2"><italic>p</italic>-uniform</th>
<th align="left"/>
</tr>
<tr>
<th align="left"/>
<th align="left"/>
<th align="center">Not sig.</th>
<th align="center">Sig.</th>
<th align="center"/>
<th align="left"/>
<th align="left"/>
<th align="center">Not sig.</th>
<th align="center">Sig.</th>
<th align="center"/>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="2">Egger</td>
<td align="left">Not sig.</td>
<td align="center">600</td>
<td align="center">35</td>
<td align="center">635; 87.1%</td>
<td align="center" rowspan="2">Egger</td>
<td align="left">Not sig.</td>
<td align="center">354</td>
<td align="center">34</td>
<td align="center">388; 83.3%</td>
</tr>
<tr>
<td align="left">Sig.</td>
<td align="center">51</td>
<td align="center">43</td>
<td align="center">94; 12.9%</td>
<td align="left">Sig.</td>
<td align="center">70</td>
<td align="center">8</td>
<td align="center">78; 16.7%</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Total</td>
<td align="center">651; 89.3%</td>
<td align="center">78; 10.7%</td>
<td align="center"><italic>H</italic> = .485</td>
<td align="left"/>
<td align="left">Total</td>
<td align="center">424; 91%</td>
<td align="center">42; 9%</td>
<td align="center"><italic>H</italic> = .028</td>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="center" colspan="2">TES</td>
<td align="center"/>
<td align="left"/>
<td align="left"/>
<td align="center" colspan="2"><italic>p</italic>-uniform</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="center">Not sig.</td>
<td align="center">Sig.</td>
<td align="center"/>
<td align="left"/>
<td align="left"/>
<td align="center">Not sig.</td>
<td align="center">Sig.</td>
<td align="center"/>
</tr>
<tr>
<td align="center" rowspan="2">Egger</td>
<td align="left">Not sig.</td>
<td align="center">609</td>
<td align="center">29</td>
<td align="center">638; 87.2%</td>
<td align="center" rowspan="2">Rank-corr.</td>
<td align="left">Not sig.</td>
<td align="center">377</td>
<td align="center">34</td>
<td align="center">411; 88.2%</td>
</tr>
<tr>
<td align="left">Sig.</td>
<td align="center">83</td>
<td align="center">11</td>
<td align="center">94; 12.8%</td>
<td align="left">Sig.</td>
<td align="center">47</td>
<td align="center">8</td>
<td align="center">55; 11.8%</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Total</td>
<td align="center">692; 94.5%</td>
<td align="center">40; 5.5%</td>
<td align="center"><italic>H</italic> = .168</td>
<td align="left"/>
<td align="left">Total</td>
<td align="center">424; 91%</td>
<td align="center">42; 9%</td>
<td align="center"><italic>H</italic> = .082</td>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="center" colspan="2">TES</td>
<td align="center"/>
<td align="left"/>
<td align="left"/>
<td align="center" colspan="2">TES</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="left"/>
<td align="center">Not sig.</td>
<td align="center">Sig.</td>
<td align="center"/>
<td align="left"/>
<td align="left"/>
<td align="center">Not sig.</td>
<td align="center">Sig.</td>
<td align="center"/>
</tr>
<tr>
<td align="center" rowspan="2">Rank-corr.</td>
<td align="left">Not sig.</td>
<td align="center">620</td>
<td align="center">31</td>
<td align="center">651; 89.3%</td>
<td align="center" rowspan="2"><italic>p</italic>-uniform</td>
<td align="left">Not sig.</td>
<td align="center">393</td>
<td align="center">31</td>
<td align="center">424; 91%</td>
</tr>
<tr>
<td align="left">Sig.</td>
<td align="center">69</td>
<td align="center">9</td>
<td align="center">78; 10.7%</td>
<td align="left">Sig.</td>
<td align="center">33</td>
<td align="center">9</td>
<td align="center">42; 9%</td>
</tr>
<tr>
<td align="left"/>
<td align="left">Total</td>
<td align="center">689; 94.5%</td>
<td align="center">40; 5.5%</td>
<td align="center"><italic>H</italic> = .132</td>
<td align="left"/>
<td align="left">Total</td>
<td align="center">426; 91.4%</td>
<td align="center">40; 8.6%</td>
<td align="center"><italic>H</italic> = .148</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001"><p><italic>H</italic> denotes Loevinger’s <italic>H</italic> to describe the association between two methods. The rank-correlation could not be applied to all 732 subsets, because there was no variation in the observed effect sizes in three subsets. All these subsets were part of the meta-analysis by Else-Quest and colleagues [<xref ref-type="bibr" rid="pone.0215052.ref103">103</xref>] who set effect sizes to zero if the effect size could not have been extracted from a primary study but was reported as not statistically significant.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Publication bias was detected in at most 94 subsets (12.9%) by Egger’s regression test. The TES and rank-correlation test were statistically significant in 40 (5.5%) and 78 (10.7%) subsets, respectively. In the subsets with at least one statistically significant effect size, <italic>p</italic>-uniform’s publication bias test detected publication bias in 42 subsets (9%), which was more than TES (40; 8.6%) and less than both the rank-correlation test (55; 11.8%) and Egger’s regression test (78; 16.7%). Since the estimated prevalence values are close to 10%, which equals the significance threshold of each test, we conclude there is at best weak evidence of publication bias on the basis of publication bias tests. Associations among the methods were low (<italic>H &lt;</italic> .168), except for the association between Egger’s regression test and the rank-correlation test (<italic>H</italic> = .485).</p>
<p>To answer research question 1b we examined whether publication bias was more prevalent in subsets from Psychological Bulletin than CDSR. Publication bias was detected in 13.4% (Egger’s test), 12.8% (rank-correlation test), 11.4% (<italic>p-</italic>uniform), 6.6% (TES) of the subsets from Psychological Bulletin and in 12.2% (Egger’s test), 8.5% (rank-correlation test), 5.9% (<italic>p</italic>-uniform), and 4.4% (TES) of the subsets from CDSR. When testing for differences in publication bias we controlled for the number of effect sizes (or for <italic>p-</italic>uniform statistically significant effect sizes) in a meta-analysis. Publication bias was more prevalent in subsets from Psychological Bulletin if the results of <italic>p</italic>-uniform were used as dependent variable (odds ratio = 2.226, <italic>z</italic> = 2.217, one-tailed <italic>p</italic>-value <italic>=</italic> .014), but not for Egger’s regression test (odds ratio = 1.024, <italic>z</italic> = 0.106, one-tailed <italic>p</italic>-value <italic>=</italic> .458), rank-correlation test (odds ratio = 1.491, <italic>z =</italic> 1.613, one-tailed <italic>p</italic>-value <italic>=</italic> .054), and TES (odds ratio = 1.344, <italic>z</italic> = 0.871, one-tailed <italic>p</italic>-value <italic>=</italic> .192). Tables with the results of these logistic regression analyses are reported in <xref ref-type="supplementary-material" rid="pone.0215052.s001">S1</xref>–<xref ref-type="supplementary-material" rid="pone.0215052.s004">S4</xref> Tables. Note, however, that if we control for the number of tests performed (i.e., 4) by means of the Bonferoni correction (<italic>p</italic> = .005 &lt; .05/4 = .0125), the result of <italic>p</italic>-uniform was no longer statistically significant.</p>
<p>We also conducted multilevel logistic regression analyses to take into account that the subsets were nested in meta-analyses. The intraclass correlation can be used to assess to what extent the subsets within a meta-analysis were related to each other. These intraclass correlations were 14.9%, 25.6%, 0%, and 0% for Egger’s test, the rank-correlation test, <italic>p-</italic>uniform, and TES, respectively. Taking into account the nested structure hardly affected the parameter estimates and did not change the statistical inference (see <xref ref-type="supplementary-material" rid="pone.0215052.s005">S5</xref>–<xref ref-type="supplementary-material" rid="pone.0215052.s008">S8</xref> Tables). All in all, we conclude that evidence of publication bias was weak at best and that we found no evidence of a difference in the extent of publication bias existed between subsets from Psychological Bulletin and CDSR.</p>
</sec>
<sec id="sec015">
<title>Predicting effect size estimation</title>
<p>To answer research question 2, absolute values of the effect size estimates of random-effects meta-analysis and <italic>p</italic>-uniform were predicted based on characteristics of the subsets. One-tailed hypothesis tests were used in case of a directional hypothesis (see <xref ref-type="table" rid="pone.0215052.t002">Table 2</xref> for a summary of our hypotheses). <xref ref-type="table" rid="pone.0215052.t005">Table 5</xref> presents the results of the meta-meta-regression on the absolute value of the effect size estimates of random-effect meta-analysis. The variables in the model explained 15.2% of the variance in the estimates of random-effects meta-analysis (<italic>R</italic><sup>2</sup> = 0.152; <italic>F</italic>(4,727) = 32.6, <italic>p</italic> &lt; .001). The absolute value of the meta-analytic estimate was 0.056 larger for subsets from Psychological Bulletin compared to CDSR, and this effect was statistically significant and in line with our hypothesis (<italic>t</italic>(727) = 3.888, <italic>p</italic> &lt; .001, one-tailed). The <italic>I</italic><sup>2</sup>-statistic had an unexpected positive association with the absolute value of the meta-analytic estimate (B = 0.002, <italic>t</italic>(727) = 3.927, <italic>p</italic> &lt; .001, two-tailed). The harmonic mean of the standard error had, as expected, a positive effect (B = 0.776, <italic>t</italic>(727) = 10.685, <italic>p</italic> &lt; .001, one-tailed). The intraclass coefficient that was obtained with the sensitivity analysis where a random effect was included to take into account that the subsets were nested in meta-analyses was equal to 1.1%. The results of this sensitivity analysis are shown in <xref ref-type="supplementary-material" rid="pone.0215052.s009">S9 Table</xref> and were highly similar to the results of the analyses where the hierarchical structure was not taken into account.</p>
<table-wrap id="pone.0215052.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t005</object-id>
<label>Table 5</label> <caption><title>Results of meta-meta regression on the absolute value of the random-effects meta-analysis effect size estimate with predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), and number of effect sizes in a subset.</title></caption>
<alternatives>
<graphic id="pone.0215052.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t005" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left">B (SE)</th>
<th align="left"><italic>t-</italic>value (<italic>p</italic>-value)</th>
<th align="left">95% CI</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Intercept</td>
<td align="left">0.035 (0.018)</td>
<td align="left">1.924 (.055)</td>
<td align="left">-0.001;0.07</td>
</tr>
<tr>
<td align="left">Discipline</td>
<td align="left">0.056 (0.014)</td>
<td align="left">3.888 (&lt; .001)</td>
<td align="left">0.028;0.084</td>
</tr>
<tr>
<td align="left"><italic>I</italic><sup>2</sup>-statistic</td>
<td align="left">0.002 (0.0004)</td>
<td align="left">3.927 (&lt; .001)</td>
<td align="left">0.001;0.002</td>
</tr>
<tr>
<td align="left">Standard error</td>
<td align="left">0.776 (0.073)</td>
<td align="left">10.685 (&lt; .001)</td>
<td align="left">0.633;0.918</td>
</tr>
<tr>
<td align="left">Number of effect sizes</td>
<td align="left">-0.002 (0.0005)</td>
<td align="left">-4.910 (&lt; .001)</td>
<td align="left">-0.003;-0.001</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001"><p>CDSR is the reference category for discipline. <italic>p-</italic>values for discipline and harmonic mean of the standard error are one-tailed whereas the other <italic>p-</italic>values are two-tailed. CI = Wald-based confidence interval.</p></fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="table" rid="pone.0215052.t006">Table 6</xref> shows the results of meta-meta regressions on the absolute value of <italic>p-</italic>uniform’s estimate as the dependent variable. The proportion explained variance in <italic>p</italic>-uniform’s estimate was <italic>R</italic><sup>2</sup> = .014 (<italic>F</italic>(5,475) = 1.377, <italic>p</italic> = .231). None of the predictors was statistically significant. The results of the sensitivity analysis where a random effect was included to take into account that the subsets were nested in meta-analyses were highly similar (see <xref ref-type="supplementary-material" rid="pone.0215052.s010">S10 Table</xref>). This was no surprise as the intraclass correlation was estimated as 0%. Quantile regression was used as sensitivity analysis to examine whether the results were distorted by extreme effect size estimates of <italic>p</italic>-uniform (see <xref ref-type="supplementary-material" rid="pone.0215052.s011">S11 Table</xref>). The results of the predictors discipline and <italic>I</italic><sup><italic>2</italic></sup>-statistic were also not statistically significant in the quantile regression. The association of the harmonic mean of the standard error was lower in the quantile regression but statistically significant (B = 2.021, <italic>t</italic>(475) = 7.969, <italic>p</italic> &lt; .001, two-tailed) and the predictor “proportion of statistically significant effect sizes” was statistically significant (B = 0.196, <italic>t</italic>(475) = 2.353, <italic>p</italic> = .019, two-tailed).</p>
<table-wrap id="pone.0215052.t006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t006</object-id>
<label>Table 6</label> <caption><title>Results of meta-meta-regression on the absolute value of <italic>p-</italic>uniform’s effect size estimate with predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</title></caption>
<alternatives>
<graphic id="pone.0215052.t006g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t006" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left">B (SE)</th>
<th align="left"><italic>t-</italic>value (<italic>p</italic>-value)</th>
<th align="left">95% CI</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Intercept</td>
<td align="left">0.77 (0.689)</td>
<td align="left">1.118 (0.264)</td>
<td align="left">-0.584;2.124</td>
</tr>
<tr>
<td align="left">Discipline</td>
<td align="left">0.001 (0.497)</td>
<td align="left">0.001 (0.999)</td>
<td align="left">-0.975;0.976</td>
</tr>
<tr>
<td align="left"><italic>I</italic><sup>2</sup>-statistic</td>
<td align="left">0.013 (0.014)</td>
<td align="left">0.939 (0.174)</td>
<td align="left">-0.014;0.039</td>
</tr>
<tr>
<td align="left">Standard error</td>
<td align="left">3.767 (2.587)</td>
<td align="left">1.456 (0.146)</td>
<td align="left">-1.316;8.851</td>
</tr>
<tr>
<td align="left">Prop. sig. effect sizes</td>
<td align="left">-1.287 (0.797)</td>
<td align="left">-1.615 (0.107)</td>
<td align="left">-2.853;0.279</td>
</tr>
<tr>
<td align="left">Number of effect sizes</td>
<td align="left">-0.02 (0.015)</td>
<td align="left">-1.363 (0.173)</td>
<td align="left">-0.049;0.009</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t006fn001"><p>CDSR is the reference category for discipline. <italic>p-</italic>value for the <italic>I</italic><sup>2</sup>-statistic is one-tailed whereas the other <italic>p-</italic>values are two-tailed. CI = Wald-based confidence interval.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec016">
<title>Overestimation of effect size</title>
<p><xref ref-type="table" rid="pone.0215052.t007">Table 7</xref> shows descriptive statistics and 95% confidence intervals of the <italic>Y</italic>-variables comparing estimates of random-effects meta-analysis with <italic>p-</italic>uniform (first two columns) and the 10% most precise observed effect sizes (last two columns). Results of <italic>p</italic>-uniform suggest that possible overestimation because of publication bias was at most minimal for subsets from Psychological Bulletin: mean = -0.007, 95% CI = (-0.056;0.043), and median = 0.019. Overestimation for subsets from CDSR was larger but still small, and statistically significant (mean = 0.042, 95% CI = (0.002;0.083), median = 0.051). The overestimation based on the 10% most precise observed effect sizes was also small (<italic>d</italic>&lt;0.04) and statistically significant for subsets from Psychological Bulletin (mean = 0.030, 95% CI = (0.011;0.048), median = 0.024) and CDSR (mean = 0.038, 95% CI = (0.016;0.061), median = 0.023). The slight overestimations provide indirect evidence of publication bias that appears to be similar in both fields (research question 3a).</p>
<table-wrap id="pone.0215052.t007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t007</object-id>
<label>Table 7</label> <caption><title>Mean, standard deviation (SD), 95% confidence interval (CI), and median of the <italic>Y</italic> variable computed with <italic>p</italic>-uniform and the 10% most precise observed effect sizes.</title></caption>
<alternatives>
<graphic id="pone.0215052.t007g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t007" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center"/>
<th align="center" colspan="2"><italic>p-</italic>uniform</th>
<th align="center" colspan="2">10% most precise</th>
</tr>
<tr>
<th align="center"/>
<th align="center">Psy. Bull.</th>
<th align="center">CDSR</th>
<th align="center">Psy. Bull.</th>
<th align="center">CDSR</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Mean (SD)</td>
<td align="left">-0.007 (0.412)</td>
<td align="left">0.042 (0.305)</td>
<td align="left">0.030 (0.181)</td>
<td align="left">0.038 (0.220)</td>
</tr>
<tr>
<td align="left">(95% CI)</td>
<td align="left">(-0.056;0.043)</td>
<td align="left">(0.002;0.083)</td>
<td align="left">(0.011;0.048)</td>
<td align="left">(0.016;0.061)</td>
</tr>
<tr>
<td align="left">Median</td>
<td align="left">0.019</td>
<td align="left">0.051</td>
<td align="left">0.024</td>
<td align="left">0.023</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t007fn001"><p>Results are reported for homogeneous subsets of meta-analyses published in Psychological Bulletin (Psy. Bull.) and Cochrane Database of Systematic Reviews (CDSR).</p></fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="table" rid="pone.0215052.t008">Table 8</xref> presents the results of the meta-meta regression on <italic>Y</italic> to answer research question 3b on predictors of the overestimation in effect size caused by publication bias. The predictors explained 11.8% of the variance of <italic>Y</italic> (<italic>F</italic>(5,475) = 12.76, <italic>p</italic> &lt; .001). The effect size in subsets from Psychological Bulletin was not significantly larger than from CDSR (B = -0.040, <italic>t</italic>(475) = -1.651, <italic>p</italic> = .951, one-tailed). We found a negative effect of the <italic>I</italic><sup>2</sup>-statistic on <italic>Y</italic> (B = -0.004, <italic>t</italic>(475) = -5.338, <italic>p</italic> &lt; .001, one-tailed). The hypothesized relationship between the harmonic mean of the standard error and <italic>Y</italic> was not statistically significant (B = 0.172, <italic>t</italic>(475) = 1.371, <italic>p =</italic> .086, one-tailed). The proportion of statistically significant effect sizes in a subset was positively associated with <italic>Y</italic> (B = 0.182, <italic>t</italic>(475) = 4.713, <italic>p</italic> &lt; .001, two-tailed).</p>
<table-wrap id="pone.0215052.t008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.t008</object-id>
<label>Table 8</label> <caption><title>Results of meta-meta-regression on the effect size overestimation in random-effects meta-analysis when compared to <italic>p-</italic>uniform (<italic>Y</italic>) and predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</title></caption>
<alternatives>
<graphic id="pone.0215052.t008g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.t008" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left">B (SE)</th>
<th align="left"><italic>t-</italic>value (<italic>p</italic>-value)</th>
<th align="left">95% CI</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Intercept</td>
<td align="left">-0.017 (0.033)</td>
<td align="left">-0.517 (.605)</td>
<td align="left">-0.083;0.048</td>
</tr>
<tr>
<td align="left">Discipline</td>
<td align="left">-0.04 (0.024)</td>
<td align="left">-1.651 (.951)</td>
<td align="left">-0.087;0.008</td>
</tr>
<tr>
<td align="left"><italic>I</italic><sup>2</sup>-statistic</td>
<td align="left">-0.004 (0.001)</td>
<td align="left">-5.338 (&lt; .001)</td>
<td align="left">-0.005;-0.002</td>
</tr>
<tr>
<td align="left">Standard error</td>
<td align="left">0.172 (0.126)</td>
<td align="left">1.371 (.086)</td>
<td align="left">-0.074;0.419</td>
</tr>
<tr>
<td align="left">Prop. sig. effect sizes</td>
<td align="left">0.182 (0.039)</td>
<td align="left">4.713 (&lt; .001)</td>
<td align="left">0.106;0.258</td>
</tr>
<tr>
<td align="left">Number of effect sizes</td>
<td align="left">-0.001 (0.001)</td>
<td align="left">-2.064 (.04)</td>
<td align="left">-0.003;-0.0001</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t008fn001"><p>CDSR is the reference category for discipline. <italic>p-</italic>values for discipline, the <italic>I</italic><sup>2</sup>-statistic, and the harmonic mean of the standard error are one-tailed whereas the other <italic>p-</italic>values are two-tailed. CI = Wald-based confidence interval.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>The results of the sensitivity analysis where a random effect was included to take into account that subsets were nested in meta-analyses were highly similar (see <xref ref-type="supplementary-material" rid="pone.0215052.s012">S12 Table</xref>). Again, this was no surprise as the intraclass correlation coefficient was estimated as practically 0 (0.04%). Quantile regression with the median of <italic>Y</italic> as dependent variable was conducted to examine whether the results of the meta-meta-regression were affected by truncating the estimate of <italic>p</italic>-uniform to zero (see <xref ref-type="supplementary-material" rid="pone.0215052.s013">S13 Table</xref>). This truncation occurred in 136 subsets before computing <italic>Y</italic>. The predictor discipline was not statistically significant in the quantile regression. In contrast to the results of the meta-meta-regression, the effects of the <italic>I</italic><sup>2</sup>-statistic (B = -0.0003, <italic>t</italic>(475) = -0.2, <italic>p</italic> = .579, one-tailed) and proportion of statistically significant effect size in a subset (B = -0.002, <italic>t</italic>(475) = -1.53, <italic>p</italic> = .127, two-tailed) were no longer statistically significant, whereas the predictor harmonic mean of the standard error was statistically significant (B = 0.279, <italic>t</italic>(475) = 1.889, <italic>p</italic> = .03, one-tailed).</p>
</sec>
<sec id="sec017">
<title>Monte-Carlo simulation study</title>
<p><xref ref-type="fig" rid="pone.0215052.g003">Fig 3</xref> shows the average Type-I error rate and the average statistical power across all 732 data sets of the rank-correlation test (open bullets), Egger’s test (triangles), the TES (diamonds), and <italic>p</italic>-uniform’s publication bias test (solid bullets) as a function of publication bias (<italic>pub</italic>) and average true effect size (μ). Average statistical power of all methods increased as a function of <italic>pub</italic> and decreased as a function of μ. None of the publication bias tests achieved an average statistical power larger than 0.5 if <italic>pub</italic> ≤ 0.95, and average statistical power did not exceed 0.2 for <italic>pub</italic> ≤ 0.75 for any true effect size examined.</p>
<fig id="pone.0215052.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Type-I error rate and statistical power of the rank-correlation test (open bullets), Egger’s test (triangles), test of excess significance (TES; diamonds), and <italic>p</italic>-uniform’s publication bias test (solid bullets) in the Monte-Carlo simulation study.</title>
<p><italic>pub</italic> and μ are the extent of publication bias and the average true effect size, respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.g003" xlink:type="simple"/>
</fig>
<p>Our Monte-Carlo simulation study confirms the low statistical power of the publication bias tests to detect publication bias in the small homogeneous subsets examined in this study. The results of the simulations also indicate that the observed proportions of statistically significant publication bias tests for the homogeneous subsets could have occurred for a large range of values for <italic>pub</italic>. The observed proportions of statistically significant results for each publication bias test (ranging from 0.055 to 0.167) are in line with publication bias varying from <italic>pub</italic> = 0 to <italic>pub</italic> = 0.95 for μ = 0 and 0.2 and <italic>pub</italic> = 0.85 for μ = 0.5. This means that, even in our large data set with 732 subsets, the proportion of statistically significant results of publication bias tests does not provide much information on the presence of publication bias in homogeneous subsets of meta-analyses as published in Psychological Bulletin and CDSR.</p>
<p><xref ref-type="fig" rid="pone.0215052.g004">Fig 4</xref> illustrates the overestimation of effect size caused by publication bias for no (μ = 0; open bullets), small (μ = 0.2; triangles), and medium (μ = 0.5; diamonds) average true effects. We computed the mean of the <italic>Y</italic>-variable for each simulated homogeneous subset based on characteristics of subsets from meta-analyses published in Psychological Bulletin (left panel) and CDSR (right panel). The solid horizontal lines and dashed horizontal lines in <xref ref-type="fig" rid="pone.0215052.g004">Fig 4</xref> refer to the mean and 95% confidence interval around this mean of the <italic>Y</italic>-variable observed in the homogeneous subsets (see <xref ref-type="table" rid="pone.0215052.t007">Table 7</xref>). A larger value for <italic>Y</italic> refers to a larger overestimation by the random-effects model when compared with the 10% most precise observed effect sizes. Overestimation of effect size increased as a function of <italic>pub</italic>, but it was small for moderate publication bias (<italic>pub</italic> = 0.5) or even quite strong publication bias (<italic>pub</italic> &lt; .85) for a zero true effect size.</p>
<fig id="pone.0215052.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0215052.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Overestimation (<italic>Y</italic>) of the random-effects model when compared with the 10% most precise observed effect sizes for simulated data based on characteristics of subsets from meta-analyses published in Psychological Bulletin (left panel) and Cochrane Database of Systematic Reviews (CDSR; right panel).</title>
<p><italic>pub</italic> refers to the extent of publication bias and open bullets, triangles, and diamonds indicate no, small, and medium average true effect size. The solid line indicates the mean of the <italic>Y</italic>-variable observed in the homogeneous subsets and the dashed lines are the upper and lower bound of a 95% confidence interval (CI) around the mean of the <italic>Y</italic>-variable.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.g004" xlink:type="simple"/>
</fig>
<p>The overestimation observed in the homogeneous subsets is in line with a large range of values for <italic>pub</italic>. For homogeneous subsets of meta-analyses published in Psychological Bulletin (left panel), the lower and upper bound of the 95% confidence intervals could be observed in combination with <italic>pub</italic> &gt; 0.25 and &lt; 0.95 for μ = 0, <italic>pub</italic> &gt; 0.5 and &lt; 0.95 for μ = 0.2, and <italic>pub</italic> &gt; 0.25 and &lt; 0.85 for μ = 0.5. The same holds for the subsets of meta-analyses from CDSR where the 95% confidence intervals could be observed when <italic>pub</italic> &gt; 0 and &lt; 0.95 for μ = 0, <italic>pub</italic> &gt; 0.5 and &lt; 0.95 for μ = 0.2, and <italic>pub</italic> &gt; 0.25 and &lt; 0.85 for μ = 0.5. Note, however, we should be careful with overinterpreting the results depicted in <xref ref-type="fig" rid="pone.0215052.g004">Fig 4</xref> as estimated overestimation quite strongly depends on the assumed true effects, and we do not know the distribution of true effect size for the included homogeneous subsets. Nonetheless, we believe our Monte-Carlo simulation study revealed that the results in our study are in line with a wide range of publication bias, albeit not with scenarios where statistically nonsignificant effect sizes hardly ever get published. Specifically, our empirical results suggest at least mild publication bias as estimated overestimation was often not in the observed overestimation’s CI for <italic>pub</italic> ≤ 0.25 (<xref ref-type="fig" rid="pone.0215052.g004">Fig 4</xref>).</p>
</sec>
</sec>
<sec id="sec018" sec-type="conclusions">
<title>Conclusion and discussion</title>
<p>Publication bias is a major threat to the validity of meta-analyses. It results in overestimated effect sizes in primary studies which in turn also biases the meta-analytic results (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref003">3</xref>, <xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>]). Indications for the presence of publication bias have been observed in many research fields (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0215052.ref008">8</xref>, <xref ref-type="bibr" rid="pone.0215052.ref011">11</xref>, <xref ref-type="bibr" rid="pone.0215052.ref014">14</xref>]), and different methods were developed to examine publication bias in a meta-analysis (for an overview see [<xref ref-type="bibr" rid="pone.0215052.ref002">2</xref>]). We studied the prevalence of publication bias and the overestimation caused by it in a large number of meta-analyses published in Psychological Bulletin and CDSR by applying publication bias methods to homogeneous subsets of these meta-analyses. Homogeneous subsets were created, because publication bias methods have poor statistical properties if the true effect size is heterogeneous [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. The prevalence of publication bias was studied by means of Egger’s test [<xref ref-type="bibr" rid="pone.0215052.ref043">43</xref>], the rank-correlation test [<xref ref-type="bibr" rid="pone.0215052.ref047">47</xref>], TES [<xref ref-type="bibr" rid="pone.0215052.ref050">50</xref>], and <italic>p</italic>-uniform’s publication bias test [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>]. We used <italic>p</italic>-uniform and a meta-analysis based on the 10% most precise effect size estimates of a meta-analysis to estimate the effect size corrected for publication bias. The statistical properties of our preregistered analyses were also examined by means of a Monte-Carlo simulation study. Our paper is different from previous work [<xref ref-type="bibr" rid="pone.0215052.ref015">15</xref>–<xref ref-type="bibr" rid="pone.0215052.ref021">21</xref>] that studied the presence of questionable research practices and publication bias based on the distribution of <italic>p-</italic>values, because we did not analyze the distribution of <italic>p</italic>-values of studies published in a whole research field.</p>
<p>The results of our paper are not in line with previous research showing rather strong indications for publication bias in numerous research fields (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0215052.ref008">8</xref>, <xref ref-type="bibr" rid="pone.0215052.ref011">11</xref>, <xref ref-type="bibr" rid="pone.0215052.ref014">14</xref>]) and revealing the presence of small-study effects in another meta-meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref107">107</xref>]. The best illustration of the diverging results of previous research and our study is that many (subsets of) meta-analyses did not contain a single statistically significant effect size (41.5% in CDSR and 27% in Psychological Bulletin), and only a minority of observed primary effect sizes was statistically significant (18.9% in CDSR and 28.9% in Psychological Bulletin). Although the percentage of statistically significant findings was slightly higher before excluding heterogeneous subsets (28.9% in CDSR and 44.2% in Psychological Bulletin), these percentages are substantially lower than the percentage of times the main hypothesis of a paper was deemed to be supported according to previous research. For example, approximately 90% of these hypotheses were statistically significant in the psychology and psychiatry [<xref ref-type="bibr" rid="pone.0215052.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0215052.ref008">8</xref>] and clinical medicine literature [<xref ref-type="bibr" rid="pone.0215052.ref108">108</xref>]. To put the percentages of statistically significant effect sizes in perspective, imagine that only 25% of all effects examined in a field have a nonzero true effect size and that statistical power equals 0.5 for a one-tailed hypothesis test with α = .025 to resemble researchers conducting a two-tailed test and reporting only the results in the predicted direction. Then 18.9% and 28.9% significant effects imply that 72% and 41.3% of nonsignificant effects get published, respectively (<italic>pub</italic> equals 0.28 and 0.587). Assuming higher prevalence of nonzero true effects, higher power, or assuming <italic>p</italic>-hacking implies <italic>less</italic> publication bias than calculated here. Thus, these numbers alone imply that if publication bias exists in homogeneous (subsets of) meta-analyses in psychology and medicine, then statistically nonsignificant effects still have a nonzero probability of getting published.</p>
<p>Only weak evidence for the prevalence of publication bias was observed in our large-scale data set of homogeneous subsets of primary studies. No evidence of bias was obtained using the publication bias tests. Overestimation was minimal but statistically significant (except for subsets from Psychological Bulletin in combination with <italic>p</italic>-uniform as estimator), providing evidence of publication bias that appeared to be similar in both fields. The simulation study (not preregistered) showed that the publication bias tests were only reasonably powered to detect extreme publication bias where all statistically nonsignificant effect sizes remain unpublished. No evidence for this extreme publication bias was present in our large data set. It also showed that the observed overestimation in the large data set was consistent with a wide range of relatively mild publication bias scenarios (but not with a scenario with extreme publication bias). Based on these findings in combination with the small percentages of statistically significant effect sizes in psychology and medicine, we conclude that evidence for publication bias in the studied homogeneous subsets is weak, but suggestive of mild publication bias in both disciplines.</p>
<p>A meta-meta-regression on the random-effects meta-analytic estimates revealed, in line with the hypothesis, a negative association of primary studies’ precision with a meta-analytic estimate. Since only weak evidence for publication bias was observed, this association was most likely mainly caused by differences in sample sizes between research fields. For instance, if researchers use statistical power analysis to determine the sample size of their study or if researchers in fields characterized by lower effect sizes use larger sample sizes by habit, larger true effect sizes will be associated with studies using smaller sample sizes (see supplemental materials of [<xref ref-type="bibr" rid="pone.0215052.ref044">44</xref>] and [<xref ref-type="bibr" rid="pone.0215052.ref045">45</xref>]).</p>
<p>The same predictors used for predicting the random-effects meta-analytic effect size estimate were also used in a meta-meta-regression on <italic>p</italic>-uniform’s estimate. None of the predictors statistically significantly predicted <italic>p</italic>-uniform’s effect size estimate. This was in line with our hypothesis on the relationship with primary studies’ precision, but in contrast to the expected positive relationship between the <italic>I</italic><sup>2</sup>-statistic and <italic>p</italic>-uniform’s effect size estimate. The absence of such a positive relationship indicates that <italic>p</italic>-uniform did not overestimate the effect size in the presence of heterogeneity in true effect size. The initially unexpected positive association between the meta-analytic estimate and <italic>I</italic><sup>2</sup>-statistic is in line with two very recent studies on multi-lab replication [<xref ref-type="bibr" rid="pone.0215052.ref109">109</xref>, <xref ref-type="bibr" rid="pone.0215052.ref110">110</xref>], which showed absence of an effect in combination with homogeneous effect size, and heterogeneous effect sizes only in combination with some nonzero average effect size. The explained variance in the meta-meta-regression with <italic>p</italic>-uniform’s estimate as dependent variable (1.4%) was substantially lower than with the estimate of random-effects meta-analysis as dependent variable (67.6%). This difference in explained variance was mainly caused by the large variance in <italic>p</italic>-uniform’s effect size estimates across homogeneous subsets. The variance in these estimates was large, because estimates of <italic>p</italic>-uniform were based on a smaller subset of (statistically significant) effect sizes and were sometimes extremely positive or negative caused by observed effect sizes with <italic>p</italic>-values just below the α-level.</p>
<p>The different publication bias methods were not always in agreement with each other, which is caused by the absence of clear publication biases in the meta-analytic homogeneous subsets. An exception was the association between the results of Egger’s test and the rank-correlation test, but this association was expected since both methods are very similar in methodology (i.e., testing for publication bias by examining the relationship between observed effect size and some measure of its precision). Substantial differences were also observed among the two methods that we used to correct effect size estimates for publication bias (i.e., <italic>p</italic>-uniform and the 10% most precise observed effect size estimates). Effect size estimates based on the 10% most precise observed effect sizes were close to estimates of the random-effects meta-analysis whereas estimates of <italic>p</italic>-uniform were imprecise and sometimes very different from random-effects meta-analysis and the 10% most precise observed effect sizes. This suggests that <italic>p-</italic>uniform overcorrected for publication bias because of a small number of observed effect sizes in homogeneous subsets combined with <italic>p</italic>-values of primary studies being close to the α-level, because estimates based on the 10% most precise observed effect sizes are expected to be closer to <italic>p</italic>-uniform’s estimates in case of publication bias.</p>
<p>Our weak evidence of publication bias is at odds with meta-meta-analyses that found evidence for the presence of small-study effects (i.e., [<xref ref-type="bibr" rid="pone.0215052.ref107">107</xref>, <xref ref-type="bibr" rid="pone.0215052.ref111">111</xref>]). One possible explanation for this disparity is that we created homogeneous subsets of primary studies in this paper. Small-study effects can be caused by heterogeneity in true effect size, so eliminating this heterogeneity by creating homogeneous subsets may have led to not observing small-study effects. Publication bias could, however, have gone undetected due to a variety of reasons. First, publication bias is less of an issue if the relationship of interest in a meta-analysis was not the main focus of the primary studies. Statistical significance of the main result in a primary study probably determines whether a result gets published, rather than whether a secondary outcome or supplementary result is significant. For instance, a meta-analysis might be about gender differences where data is extracted from studies that used gender only as a control variable. Second, meta-analysts included many unpublished studies in their meta-analyses, which might have decreased the severity and detectability of publication bias in our selected meta-analyses. Third, questionable research practices may have also decreased the detectability of publication bias in the meta-analyses, because questionable research practices may bias the effect size estimates of meta-analysis methods in any direction [<xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>]. However, we do not believe that questionable research practices played a major role in the subsets in our paper, as relatively few effect sizes were statistically significant. The weak evidence for publication bias may be also caused by the challenging characteristics of the homogeneous subsets. Our Monte-Carlo simulation study revealed that publication bias tests did not achieve reasonable statistical power to detect moderate publication bias, and overestimation of effect size only became apparent in conditions where at most 1 out of 4 statistically nonsignificant effect size was included in a meta-analysis (<italic>pub</italic> ≥ 0.75).</p>
<p>Our focus on homogeneous (subsets of) meta-analyses limits the generalizability of our findings, because our conclusions can only straightforwardly be generalized to the population of subsets of primary studies of meta-analyses without evidence for medium or higher heterogeneity. However, limiting our population was necessary because publication bias methods’ statistical properties deteriorate if heterogeneity in true effect size is moderate or large. Determining whether primary studies in a subset were homogeneous or not was based on the <italic>I</italic><sup>2</sup>-statistic. Homogeneous subsets that belong to the population under study can readily be identified in a meta-analysis, because the <italic>I</italic><sup>2</sup>-statistic is now almost always reported in a meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref112">112</xref>] and routinely included in any Cochrane systematic review [<xref ref-type="bibr" rid="pone.0215052.ref087">87</xref>]. Another option for assessing the heterogeneity in true effect size is the <italic>Q-</italic>test for homogeneity [<xref ref-type="bibr" rid="pone.0215052.ref113">113</xref>], but this hypothesis test suffers from (too) low statistical power if a small number of primary studies are included in the meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref085">85</xref>, <xref ref-type="bibr" rid="pone.0215052.ref114">114</xref>, <xref ref-type="bibr" rid="pone.0215052.ref115">115</xref>]. However, drawbacks of the <italic>I</italic><sup>2</sup>-statistic are that it heavily depends on the sample size of the primary studies [<xref ref-type="bibr" rid="pone.0215052.ref086">86</xref>] and the statistic is imprecise in case of a small number of primary studies in a meta-analysis [<xref ref-type="bibr" rid="pone.0215052.ref087">87</xref>, <xref ref-type="bibr" rid="pone.0215052.ref088">88</xref>]. As a consequence, we may have wrongly included subsets that were heterogeneous and excluded subsets that were homogeneous. Moreover, our selection of homogeneous subsets could have led to the exclusion of subsets with severe publication bias. Imagine a subset with a number of statistically significant effect sizes that were published in a field with considerable publication bias, and a few statistically nonsignificant effect sizes that were obtained from unpublished research. The inclusion of the effect sizes from the unpublished research may cause heterogeneity in true effect size, and therefore a subset with potentially severe publication bias was excluded from our study.</p>
<p>Although no convincing evidence for publication bias was observed in our study, we agree with others (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref034">34</xref>, <xref ref-type="bibr" rid="pone.0215052.ref060">60</xref>, <xref ref-type="bibr" rid="pone.0215052.ref116">116</xref>]) that publication bias should be routinely assessed in every meta-analysis. Moreover, a set of publication bias methods is recommended to be applied and reported in each meta-analysis, because each method assesses publication bias in a different way and one method might detect or correct for publication bias in a meta-analysis whereas another method might not [<xref ref-type="bibr" rid="pone.0215052.ref035">35</xref>, <xref ref-type="bibr" rid="pone.0215052.ref036">36</xref>]. Future research should focus on developing publication bias methods that are able to examine publication bias in meta-analyses with heterogeneous true effect size, because effect size estimators that correct for publication bias are often biased in these conditions (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref005">5</xref>, <xref ref-type="bibr" rid="pone.0215052.ref052">52</xref>, <xref ref-type="bibr" rid="pone.0215052.ref061">61</xref>, <xref ref-type="bibr" rid="pone.0215052.ref062">62</xref>]). However, <italic>p-</italic>uniform was recently extended such that it can also deal with heterogeneous true effect size [<xref ref-type="bibr" rid="pone.0215052.ref106">106</xref>]. Other promising developments are the recently increased attention for selection model approaches (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref061">61</xref>, <xref ref-type="bibr" rid="pone.0215052.ref062">62</xref>, <xref ref-type="bibr" rid="pone.0215052.ref106">106</xref>, <xref ref-type="bibr" rid="pone.0215052.ref117">117</xref>]) and the development of a Bayesian method to correct for publication bias [<xref ref-type="bibr" rid="pone.0215052.ref080">80</xref>]. Albeit meta-analysts will greatly benefit from improved methods to assess publication bias, attention should also be paid to registering studies to make unpublished research readily accessible (e.g., [<xref ref-type="bibr" rid="pone.0215052.ref118">118</xref>]). Such a register enables meta-analysts to also include unpublished research in their meta-analysis and will improve the validity of meta-analytic results.</p>
</sec>
<sec id="sec019">
<title>Supporting information</title>
<supplementary-material id="pone.0215052.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s001" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Results of logistic regression predicting statistical significance of Egger’s regression test with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s002" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Results of logistic regression predicting statistical significance of rank-correlation test with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s003" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Results of logistic regression predicting statistical significance of <italic>p-</italic>uniform’s publication bias test with discipline and control variable number of statistically significant effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s004" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s004" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>Results of logistic regression predicting statistical significance of test of excess significance with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s005" xlink:type="simple">
<label>S5 Table</label>
<caption>
<title>Results of multilevel logistic regression predicting statistical significance of Egger’s regression test with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s006" xlink:type="simple">
<label>S6 Table</label>
<caption>
<title>Results of multilevel logistic regression predicting statistical significance of rank-correlation test with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s007" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s007" xlink:type="simple">
<label>S7 Table</label>
<caption>
<title>Results of multilevel logistic regression predicting statistical significance of <italic>p-</italic>uniform’s publication bias test with discipline and control variable number of statistically significant effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s008" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s008" xlink:type="simple">
<label>S8 Table</label>
<caption>
<title>Results of multilevel logistic regression predicting statistical significance of test of excess significance with discipline and control variable number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s009" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s009" xlink:type="simple">
<label>S9 Table</label>
<caption>
<title>Results of meta-meta regression with a random effect to take into account that the subsets were nested in meta-analyses.</title>
<p>The dependent variable is the absolute value of the random-effects meta-analysis effect size estimate with predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s010" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s010" xlink:type="simple">
<label>S10 Table</label>
<caption>
<title>Results of meta-meta regression with a random effect to take into account that the subsets were nested in meta-analyses.</title>
<p>The dependent variable is the absolute value of <italic>p-</italic>uniform’s effect size estimate with predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s011" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s011" xlink:type="simple">
<label>S11 Table</label>
<caption>
<title>Results of quantile regression with the median of <italic>p-</italic>uniform’s effect size estimates and predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s012" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s012" xlink:type="simple">
<label>S12 Table</label>
<caption>
<title>Results of meta-meta-regression with a random effect to take into account that the subsets were nested in meta-analyses.</title>
<p>The dependent variable is the effect size overestimation in random-effects meta-analysis when compared to <italic>p-</italic>uniform (<italic>Y</italic>) and predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s013" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s013" xlink:type="simple">
<label>S13 Table</label>
<caption>
<title>Results of quantile regression with the median of effect size overestimation in random-effects meta-analysis when compared to <italic>p-</italic>uniform (<italic>Y</italic>) and predictors discipline, <italic>I</italic><sup>2</sup>-statistic, harmonic mean of the standard error (standard error), proportion of statistically significant effect sizes in a subset (Prop. sig. effect sizes), and number of effect sizes in a subset.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0215052.s014" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pone.0215052.s014" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>List of references of meta-analyses where the data of the primary studies were obtained after contacting the corresponding author.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pone.0215052.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glass</surname> <given-names>GV</given-names></name>. <article-title>Primary, secondary, and meta-analysis of research</article-title>. <source>Educational Researcher</source>. <year>1976</year>;<volume>5</volume>(<issue>10</issue>):<fpage>3</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref002"><label>2</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>. <chapter-title>Publication bias in meta-analysis</chapter-title>. In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment and adjustments</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2005</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lane</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Dunlap</surname> <given-names>WP</given-names></name>. <article-title>Estimating effect size: Bias resulting from the significance criterion in editorial decisions.</article-title> <source>British Journal of Mathematical &amp; Statistical Psychology</source>. <year>1978</year>;<volume>31</volume>:<fpage>107</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nuijten</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>, <name name-style="western"><surname>Veldkamp</surname> <given-names>CLS</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>. <article-title>The replication paradox: Combining studies can decrease accuracy of effect size estimates</article-title>. <source>Review of General Psychology</source>. <year>2015</year>;<volume>19</volume>(<issue>2</issue>):<fpage>172</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/gpr0000034" xlink:type="simple">10.1037/gpr0000034</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>, <name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>. <article-title>Meta-analysis using effect size distributions of only statistically significant studies</article-title>. <source>Psychological Methods</source>. <year>2015</year>;<volume>20</volume>(<issue>3</issue>):<fpage>293</fpage>–<lpage>309</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/met0000025" xlink:type="simple">10.1037/met0000025</ext-link></comment> <object-id pub-id-type="pmid">25401773</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouter</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Tijdink</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Axelsen</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Martinson</surname> <given-names>BC</given-names></name>, <name name-style="western"><surname>ter Riet</surname> <given-names>G</given-names></name>. <article-title>Ranking major and minor research misbehaviors: results from a survey among participants of four World Conferences on Research Integrity</article-title>. <source>Research Integrity and Peer Review</source>. <year>2016</year>;<volume>1</volume>(<issue>1</issue>). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s41073-016-0024-5" xlink:type="simple">https://doi.org/10.1186/s41073-016-0024-5</ext-link>.</mixed-citation></ref>
<ref id="pone.0215052.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterling</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Rosenbaum</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Weinkam</surname> <given-names>JJ</given-names></name>. <article-title>Publication decisions revisited: The effect of the outcome of statistical tests on the decision to publish and vice versa</article-title>. <source>The American Statistician</source>. <year>1995</year>;<volume>49</volume>(<issue>1</issue>):<fpage>108</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/2684823" xlink:type="simple">10.2307/2684823</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D.</given-names></name> <article-title>Negative results are disappearing from most disciplines and countries</article-title>. <source>Scientometrics</source>. <year>2012</year>;<volume>90</volume>(<issue>3</issue>):<fpage>891</fpage>–<lpage>904</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11192-011-0494-7" xlink:type="simple">10.1007/s11192-011-0494-7</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bakker</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>van Dijk</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>. <article-title>The rules of the game called psychological science</article-title>. <source>Perspectives on Psychological Science</source>. <year>2012</year>;<volume>7</volume>(<issue>6</issue>):<fpage>543</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1745691612459060" xlink:type="simple">10.1177/1745691612459060</ext-link></comment> <object-id pub-id-type="pmid">26168111</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>J.</given-names></name> <article-title>Things I have learned (so far).</article-title> <source>American Psychologist</source>. <year>1990</year>;<volume>45</volume>(<issue>12</issue>):<fpage>1304</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franco</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Malhotra</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Simonovits</surname> <given-names>G</given-names></name>. <article-title>Publication bias in the social sciences: Unlocking the file drawer</article-title>. <source>Science</source>. <year>2014</year>;<volume>345</volume>(<issue>6203</issue>):<fpage>1502</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1255484" xlink:type="simple">10.1126/science.1255484</ext-link></comment> <object-id pub-id-type="pmid">25170047</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cooper</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>DeNeve</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Charlton</surname> <given-names>K</given-names></name>. <article-title>Finding the missing science: The fate of studies submitted for review by a human subjects committee</article-title>. <source>Psychological Methods</source>. <year>1997</year>;<volume>2</volume>(<issue>4</issue>):<fpage>447</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/1082-989X.2.4.447" xlink:type="simple">10.1037/1082-989X.2.4.447</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coursol</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>EE</given-names></name>. <article-title>Effect of positive findings on submission and acceptance rates: A note on meta-analysis bias. Professional Psychology</article-title>: <source>Research and Practice</source>. <year>1986</year>;<volume>17</volume>(<issue>2</issue>):<fpage>136</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0735-7028.17.2.136" xlink:type="simple">10.1037/0735-7028.17.2.136</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franco</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Simonovits</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Malhotra</surname> <given-names>N</given-names></name>. <article-title>Underreporting in psychology experiments: Evidence from a study registry</article-title>. <source>Social Psychological and Personality Science</source>. <year>2016</year>;<volume>7</volume>(<issue>1</issue>):<fpage>8</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1948550615598377" xlink:type="simple">10.1177/1948550615598377</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jager</surname> <given-names>LR</given-names></name>, <name name-style="western"><surname>Leek</surname> <given-names>JT</given-names></name>. <article-title>An estimate of the science-wise false discovery rate and application to the top medical literature.</article-title> <source>Biostatistics</source>. <year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biostatistics/kxt007" xlink:type="simple">10.1093/biostatistics/kxt007</ext-link></comment> <object-id pub-id-type="pmid">24068246</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Head</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Holman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lanfear</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kahn</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Jennions</surname> <given-names>MD</given-names></name>. <article-title>The extent and consequences of p-hacking in science</article-title>. <source>PLoS Biology</source>. <year>2015</year>;<volume>13</volume>(<issue>3</issue>):<fpage>e1002106</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002106" xlink:type="simple">10.1371/journal.pbio.1002106</ext-link></comment> <object-id pub-id-type="pmid">25768323</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartgerink</surname> <given-names>CHJ</given-names></name>, <name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>Nuijten</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>Distributions of p-values smaller than .05 in psychology: What is going on?</article-title> <source>PeerJ.</source> <year>2015</year>;<volume>4</volume>:<fpage>e1935</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.1935" xlink:type="simple">https://doi.org/10.7717/peerj.1935</ext-link>.</mixed-citation></ref>
<ref id="pone.0215052.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartgerink</surname> <given-names>CHJ</given-names></name>. <collab>Reanalyzing Head</collab> <etal>et al</etal>. (2015): <article-title>Investigating the robustness of widespread p-hacking</article-title>. <source>PeerJ</source>. <year>2017</year>;<volume>5</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.3068" xlink:type="simple">10.7717/peerj.3068</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brodeur</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Le</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sangnier</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zylberberg</surname> <given-names>Y</given-names></name>. <article-title>Star Wars: The empirics strike back.</article-title> <source>American Economic Journal: Applied Economics</source>. <year>2016</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1257/app.20150044" xlink:type="simple">10.1257/app.20150044</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krawczyk</surname> <given-names>M.</given-names></name> <article-title>The search for significance: A few peculiarities in the distribution of p values in experimental psychology literature</article-title>. <source>PLOS ONE</source>. <year>2015</year>;<volume>10</volume>(<issue>6</issue>):<fpage>e0127872</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0127872" xlink:type="simple">10.1371/journal.pone.0127872</ext-link></comment> <object-id pub-id-type="pmid">26061881</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Auspurg</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Hinz</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Schneck</surname> <given-names>A</given-names></name>. <article-title>Ausmaß und Risikofaktoren des Publication Bias in der deutschen Soziologie</article-title>. <source>KZfSS Kölner Zeitschrift für Soziologie und Sozialpsychologie</source>. <year>2014</year>;<volume>66</volume>(<issue>4</issue>):<fpage>549</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11577-014-0284-3" xlink:type="simple">10.1007/s11577-014-0284-3</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopewell</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mallet</surname> <given-names>S</given-names></name>. <article-title>Grey literature and systematic reviews</article-title>. In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment and adjustments</source><year>2005</year>. p. <fpage>99</fpage>–<lpage>110</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dickersin</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chalmers</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Sacks</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>H</given-names></name>. <article-title>Publication bias and clinical trials</article-title>. <source>Controlled Clinical Trials</source>. <year>1987</year>;<volume>8</volume>(<issue>4</issue>):<fpage>343</fpage>–<lpage>53</lpage>. <object-id pub-id-type="pmid">3442991</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Handler</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Crowell</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Keil</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Weaver</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Platts-Mills</surname> <given-names>TF</given-names></name>. <article-title>Non-publication of large randomized clinical trials: Cross sectional analysis</article-title>. <source>British Medical Journal</source>. <year>2013</year>;<volume>347</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/bmj.f6104" xlink:type="simple">10.1136/bmj.f6104</ext-link></comment> <object-id pub-id-type="pmid">24169943</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref025"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">United States Code (2007) US Public Law 110–85: Food and Drug Administration Amendments Act 2007. <ext-link ext-link-type="uri" xlink:href="http://frwebgate.access.gpo.gov/cgi-bin/getdoc.cgi?dbname=110_cong_public_laws&amp;docid=f:publ085.110.pdf" xlink:type="simple">http://frwebgate.access.gpo.gov/cgi-bin/getdoc.cgi?dbname=110_cong_public_laws&amp;docid=f:publ085.110.pdf</ext-link>.</mixed-citation></ref>
<ref id="pone.0215052.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dwan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Arnaiz</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>A-W</given-names></name>, <name name-style="western"><surname>Cronin</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Systematic review of the empirical evidence of study publication bias and outcome reporting bias.</article-title> <source>PLoS ONE</source>. <year>2008</year>;<volume>3</volume>(<issue>8</issue>):<fpage>e3081</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0003081" xlink:type="simple">10.1371/journal.pone.0003081</ext-link></comment> <object-id pub-id-type="pmid">18769481</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kirkham</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Dwan</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Gamble</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dodd</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Smyth</surname> <given-names>R</given-names></name>, <etal>et al</etal>. <article-title>The impact of outcome reporting bias in randomised controlled trials on a cohort of systematic reviews</article-title>. <source>BMJ</source>. <year>2010</year>;<volume>340</volume>(<issue>c365</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/bmj.c365" xlink:type="simple">10.1136/bmj.c365</ext-link></comment> <object-id pub-id-type="pmid">20156912</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Parekh</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hooper</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Loke</surname> <given-names>YK</given-names></name>, <name name-style="western"><surname>Ryder</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <etal>et al</etal>. <article-title>Dissemination and publication of research findings: An updated review of related biases</article-title>. <source>Health Technology Assessment</source>. <year>2010</year>;<volume>14</volume>(<issue>8</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3310/hta14080" xlink:type="simple">10.3310/hta14080</ext-link></comment> <object-id pub-id-type="pmid">20181324</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aguinis</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Dalton</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Bosco</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Pierce</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Dalton</surname> <given-names>CM</given-names></name>. <article-title>Meta-analytic choices and judgment calls: Implications for theory building and testing, obtained effect sizes, and scholarly impact</article-title>. <source>Journal of Management</source>. <year>2010</year>;<volume>37</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>38</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0149206310377113" xlink:type="simple">10.1177/0149206310377113</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Banks</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Kepes</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>KP</given-names></name>. <article-title>Publication bias: The antagonist of meta-analytic reviews and effective policymaking</article-title>. <source>Educational Evaluation and Policy Analysis</source>. <year>2012</year>;<volume>34</volume>(<issue>3</issue>):<fpage>259</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3102/0162373712446144" xlink:type="simple">10.3102/0162373712446144</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aytug</surname> <given-names>ZG</given-names></name>, <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>MC</given-names></name>. <article-title>Revealed or concealed? Transparency of procedures, decisions, and judgment calls in meta-analyses</article-title>. <source>Organizational Research Methods</source>. <year>2012</year>;<volume>15</volume>(<issue>1</issue>):<fpage>103</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1094428111403495" xlink:type="simple">10.1177/1094428111403495</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Trikalinos</surname> <given-names>TA</given-names></name>. <article-title>The appropriateness of asymmetry tests for publication bias in meta-analyses: A large survey</article-title>. <source>Canadian Medical Association Journal</source>. <year>2007</year>;<volume>176</volume>(<issue>8</issue>):<fpage>1091</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1503/cmaj.060410" xlink:type="simple">10.1503/cmaj.060410</ext-link></comment> <object-id pub-id-type="pmid">17420491</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JPA</given-names></name>. <article-title>Why most discovered true associations are inflated</article-title>. <source>Epidemiology</source>. <year>2008</year>;<volume>19</volume>(<issue>5</issue>):<fpage>640</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1097/EDE.0b013e31818131e7" xlink:type="simple">10.1097/EDE.0b013e31818131e7</ext-link></comment> ISI:000258712000001. <object-id pub-id-type="pmid">18633328</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Banks</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Kepes</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>McDaniel</surname> <given-names>MA</given-names></name>. <article-title>Publication bias: A call for improved meta-analytic practice in the organizational sciences</article-title>. <source>International Journal of Selection and Assessment</source>. <year>2012</year>;<volume>20</volume>(<issue>2</issue>):<fpage>182</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1468-2389.2012.00591" xlink:type="simple">10.1111/j.1468-2389.2012.00591</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kepes</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>McDaniel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Whetzel</surname> <given-names>DL</given-names></name>. <article-title>Publication bias in the organizational sciences</article-title>. <source>Organizational Research Methods</source>. <year>2012</year>;<volume>15</volume>(<issue>4</issue>):<fpage>624</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1094428112452760" xlink:type="simple">10.1177/1094428112452760</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coburn</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Vevea</surname> <given-names>JL</given-names></name>. <article-title>Publication bias as a function of study characteristics</article-title>. <source>Psychological methods</source>. <year>2015</year>;<volume>20</volume>(<issue>3</issue>):<fpage>310</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/met0000046" xlink:type="simple">10.1037/met0000046</ext-link></comment> <object-id pub-id-type="pmid">26348731</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferguson</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Brannick</surname> <given-names>MT</given-names></name>. <article-title>Publication bias in psychological science: Prevalence, methods for identifying and controlling, and implications for the use of meta-analyses</article-title>. <source>Psychological Methods</source>. <year>2012</year>;<volume>17</volume>(<issue>1</issue>):<fpage>120</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0024445" xlink:type="simple">10.1037/a0024445</ext-link></comment> <object-id pub-id-type="pmid">21787082</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosenthal</surname> <given-names>R.</given-names></name> <article-title>The file drawer problem and tolerance for null results</article-title>. <source>Psychological Bulletin</source>. <year>1979</year>;<volume>86</volume>(<issue>3</issue>):<fpage>638</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref039"><label>39</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JPT</given-names></name>, <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>. <chapter-title>Introduction to meta-analysis</chapter-title>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>John Wiley &amp; Sons, Ltd</publisher-name>.; <year>2009</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref040"><label>40</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Becker</surname> <given-names>BJ</given-names></name>. <chapter-title>Failsafe N or file-drawer number</chapter-title>. In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment and adjustments</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2005</year>. p. <fpage>111</fpage>–<lpage>25</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref041"><label>41</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Light</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Pillemer</surname> <given-names>DB</given-names></name>. <chapter-title>Summing up: The science of reviewing research</chapter-title>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>; <year>1984</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jürgens</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Graudal</surname> <given-names>NA</given-names></name>. <article-title>Effects of low sodium diet versus high sodium diet on blood pressure, renin, aldosterone, catecholamines, cholesterols, and triglyceride</article-title>. <source>Cochrane Database of Systematic Reviews</source>. <year>2004</year>;(<issue>1</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/14651858.CD004022.pub2" xlink:type="simple">10.1002/14651858.CD004022.pub2</ext-link></comment> CD004022. <object-id pub-id-type="pmid">14974053</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Egger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Minder</surname> <given-names>C</given-names></name>. <article-title>Bias in meta-analysis detected by a simple, graphical test</article-title>. <source>British Medical Journal</source>. <year>1997</year>;<volume>315</volume>:<fpage>629</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">9310563</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><collab>Open Science Collaboration</collab>. <article-title>Estimating the reproducibility of psychological science</article-title>. <source>Science</source>. <year>2015</year>;<volume>349</volume>(<issue>6251</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.aac4716" xlink:type="simple">10.1126/science.aac4716</ext-link></comment> <object-id pub-id-type="pmid">26315443</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref045"><label>45</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Vevea</surname> <given-names>JL</given-names></name>. <chapter-title>Selection method approaches</chapter-title>. In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment, and adjustments</source>. <publisher-loc>Chichester: UK</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2005</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Terrin</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Schmid</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>J</given-names></name>. <article-title>In an empirical evaluation of the funnel plot, researchers could not visually identify publication bias</article-title>. <source>Journal of Clinical Epidemiology</source>. <year>2005</year>;<volume>58</volume>(<issue>9</issue>):<fpage>894</fpage>–<lpage>901</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jclinepi.2005.01.006" xlink:type="simple">10.1016/j.jclinepi.2005.01.006</ext-link></comment> <object-id pub-id-type="pmid">16085192</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begg</surname> <given-names>CB</given-names></name>, <name name-style="western"><surname>Mazumdar</surname> <given-names>M</given-names></name>. <article-title>Operating characteristics of a rank correlation test for publication bias</article-title>. <source>Biometrics</source>. <year>1994</year>;<volume>50</volume>(<issue>4</issue>):<fpage>1088</fpage>–<lpage>101</lpage>. <object-id pub-id-type="pmid">7786990</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterne</surname> <given-names>JAC</given-names></name>, <name name-style="western"><surname>Harbord</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Terrin</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials</article-title>. <source>British Medical Journal</source>. <year>2011</year>;<volume>343</volume>(<issue>7818</issue>):<fpage>1</fpage>–<lpage>8</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1136/bmj.d4002" xlink:type="simple">http://dx.doi.org/10.1136/bmj.d4002</ext-link>.</mixed-citation></ref>
<ref id="pone.0215052.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterne</surname> <given-names>JAC</given-names></name>, <name name-style="western"><surname>Gavaghan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Egger</surname> <given-names>M</given-names></name>. <article-title>Publication and related bias in meta-analysis: Power of statistical tests and prevalence in the literature</article-title>. <source>Journal of Clinical Epidemiology</source>. <year>2000</year>;<volume>53</volume>(<issue>11</issue>):<fpage>1119</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0895-4356(00)00242-0" xlink:type="simple">10.1016/S0895-4356(00)00242-0</ext-link></comment> <object-id pub-id-type="pmid">11106885</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Trikalinos</surname> <given-names>TA</given-names></name>. <article-title>An exploratory test for an excess of significant findings</article-title>. <source>Clinical Trials</source>. <year>2007</year>;<volume>4</volume>(<issue>3</issue>):<fpage>245</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1740774507079441" xlink:type="simple">10.1177/1740774507079441</ext-link></comment> <object-id pub-id-type="pmid">17715249</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Replication</surname> <given-names>Francis G.</given-names></name>, <article-title>statistical consistency, and publication bias</article-title>. <source>Journal of Mathematical Psychology</source>. <year>2013</year>;<volume>57</volume>(<issue>5</issue>):<fpage>153</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jmp.2013.02.003" xlink:type="simple">10.1016/j.jmp.2013.02.003</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>Conducting meta-analyses on p-values: Reservations and recommendations for applying p-uniform and p-curve</article-title>. <source>Perspectives on Psychological Science</source>. <year>2016</year>;<volume>11</volume>(<issue>5</issue>):<fpage>713</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1745691616650874" xlink:type="simple">10.1177/1745691616650874</ext-link></comment> <object-id pub-id-type="pmid">27694466</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Simmons</surname> <given-names>JP</given-names></name>. <article-title>P-curve and effect size: Correcting for publication bias using only significant results</article-title>. <source>Perspectives on Psychological Science</source>. <year>2014</year>;<volume>9</volume>(<issue>6</issue>):<fpage>666</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1745691614553988" xlink:type="simple">10.1177/1745691614553988</ext-link></comment> <object-id pub-id-type="pmid">26186117</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moreno</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Ades</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Stanley</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Abrams</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>JL</given-names></name>, <etal>et al</etal>. <article-title>Assessment of regression-based methods to adjust for publication bias through a comprehensive simulation study</article-title>. <source>BMC Medical Research Methodology</source>. <year>2009</year>;<volume>9</volume>(<issue>2</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1471-2288-9-2" xlink:type="simple">10.1186/1471-2288-9-2</ext-link></comment> <object-id pub-id-type="pmid">19138428</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Terrin</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Schmid</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Olkin</surname> <given-names>I</given-names></name>. <article-title>Adjusting for publication bias in the presence of heterogeneity</article-title>. <source>Statistics in Medicine</source>. <year>2003</year>;<volume>22</volume>(<issue>13</issue>):<fpage>2113</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.1461" xlink:type="simple">10.1002/sim.1461</ext-link></comment> <object-id pub-id-type="pmid">12820277</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Doucouliagos</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Finding the power to reduce publication bias</article-title>. <source>Statistics in Medicine</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.7228" xlink:type="simple">10.1002/sim.7228</ext-link></comment> <object-id pub-id-type="pmid">28127782</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname> <given-names>TD</given-names></name>. <article-title>Limitations of PET-PEESE and other meta-analysis methods</article-title>. <source>Social Psychological and Personality Science</source>. <year>2017</year>;<volume>8</volume>(<issue>5</issue>):<fpage>581</fpage>–<lpage>91</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1948550617693062" xlink:type="simple">10.1177/1948550617693062</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reed</surname> <given-names>WR</given-names></name>. <article-title>A Monte Carlo analysis of alternative meta-analysis estimators in the presence of publication bias</article-title>. <source>Economics: The Open-Access, Open-Assessment E-Journal</source>. <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5018/economics-ejournal.ja.2015-30" xlink:type="simple">10.5018/economics-ejournal.ja.2015-30</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alinaghi</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Reed</surname> <given-names>WR</given-names></name>. <article-title>Meta‐analysis and publication bias: How well does the FAT‐PET‐PEESE procedure work?</article-title> <source>Research Synthesis Methods</source>. <year>2018</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/jrsm.1298" xlink:type="simple">10.1002/jrsm.1298</ext-link></comment> <object-id pub-id-type="pmid">29532634</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Gillett</surname> <given-names>R</given-names></name>. <article-title>How to do a meta-analysis</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>. <year>2010</year>;<volume>63</volume>(<issue>3</issue>):<fpage>665</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1348/000711010X502733" xlink:type="simple">10.1348/000711010X502733</ext-link></comment> <object-id pub-id-type="pmid">20497626</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carter</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Schönbrodt</surname> <given-names>FD</given-names></name>, <name name-style="western"><surname>Gervais</surname> <given-names>WM</given-names></name>, <name name-style="western"><surname>Hilgard</surname> <given-names>J</given-names></name>. <source>Correcting for bias in psychology: A comparison of meta-analytic methods</source>. <year>2018</year>. Available from osf.io/preprints/psyarxiv/9h3nu</mixed-citation></ref>
<ref id="pone.0215052.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McShane</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Böckenholt</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Hansen</surname> <given-names>KT</given-names></name>. <article-title>Adjusting for publication bias in meta-analysis: An evaluation of selection methods and some cautionary notes</article-title>. <source>Perspectives on Psychological Science</source>. <year>2016</year>;<volume>11</volume>(<issue>5</issue>):<fpage>730</fpage>–<lpage>49</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1745691616662243" xlink:type="simple">10.1177/1745691616662243</ext-link></comment> <object-id pub-id-type="pmid">27694467</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Jarrell</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Doucouliagos</surname> <given-names>H</given-names></name>. <article-title>Could it be better to discard 90% of the data? A statistical paradox</article-title>. <source>The American Statistician</source>. <year>2010</year>;<volume>64</volume>(<issue>1</issue>):<fpage>70</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1198/tast.2009.08205" xlink:type="simple">10.1198/tast.2009.08205</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Trikalinos</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Zintzaras</surname> <given-names>E</given-names></name>. <article-title>Extreme between-study homogeneity in meta-analyses could offer useful insights</article-title>. <source>Journal of Clinical Epidemiology</source>. <year>2006</year>;<volume>59</volume>(<issue>10</issue>):<fpage>1023</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jclinepi.2006.02.013" xlink:type="simple">10.1016/j.jclinepi.2006.02.013</ext-link></comment> <object-id pub-id-type="pmid">16980141</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stanley</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Doucouliagos</surname> <given-names>H</given-names></name>. <article-title>Meta-regression approximations to reduce publication selection bias.</article-title> <source>Research Synthesis Methods</source>. <year>2014</year>;<volume>5</volume>(<issue>1</issue>):<fpage>60</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/jrsm.1095" xlink:type="simple">10.1002/jrsm.1095</ext-link></comment> <object-id pub-id-type="pmid">26054026</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Higgins</surname> <given-names>JPT</given-names></name>. <article-title>Commentary: Heterogeneity in meta-analysis should be expected and appropriately quantified</article-title>. <source>International Journal of Epidemiology</source>. <year>2008</year>;<volume>37</volume>(<issue>5</issue>):<fpage>1158</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/ije/dyn204" xlink:type="simple">10.1093/ije/dyn204</ext-link></comment> <object-id pub-id-type="pmid">18832388</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turner</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Jackson</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JPT</given-names></name>. <article-title>Predictive distributions for between-study heterogeneity and simple methods for their application in Bayesian meta-analysis.</article-title> <source>Statistics in Medicine</source>. <year>2015</year>;<volume>34</volume>(<issue>6</issue>):<fpage>984</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.6381" xlink:type="simple">10.1002/sim.6381</ext-link></comment> <object-id pub-id-type="pmid">25475839</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rhodes</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JP</given-names></name>. <article-title>Predictive distributions were developed for the extent of heterogeneity in meta-analyses of continuous outcome data</article-title>. <source>Journal of Clinical Epidemiology</source>. <year>2015</year>;<volume>68</volume>(<issue>1</issue>):<fpage>52</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jclinepi.2014.08.012" xlink:type="simple">10.1016/j.jclinepi.2014.08.012</ext-link></comment> <object-id pub-id-type="pmid">25304503</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duval</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tweedie</surname> <given-names>RL</given-names></name>. <article-title>Trim and fill: A simple funnel-plot-based method of testing and adjusting for publication bias in meta-analysis</article-title>. <source>Biometrics</source>. <year>2000</year>;<volume>56</volume>(<issue>2</issue>):<fpage>455</fpage>–<lpage>63</lpage>. <object-id pub-id-type="pmid">10877304</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duval</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tweedie</surname> <given-names>RL</given-names></name>. <article-title>A nonparametric "trim and fill" method of accounting for publication bias in meta-analysis.</article-title> <source>Journal of the American Statistical Association</source>. <year>2000</year>;<volume>95</volume>(<issue>449</issue>):<fpage>89</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/01621459.2000.10473905" xlink:type="simple">10.1080/01621459.2000.10473905</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peters</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Abrams</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Rushton</surname> <given-names>L</given-names></name>. <article-title>Performance of the trim and fill method in the presence of publication bias and between-study heterogeneity</article-title>. <source>Statistics in Medicine</source>. <year>2007</year>;<volume>26</volume>(<issue>25</issue>):<fpage>4544</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.2889" xlink:type="simple">10.1002/sim.2889</ext-link></comment> <object-id pub-id-type="pmid">17476644</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Bushman</surname> <given-names>BJ</given-names></name>. <article-title>Publication bias in psychological science: Comment on Ferguson and Brannick (2012).</article-title> <source>Psychological Methods</source>. <year>2012</year>;<volume>17</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0027128" xlink:type="simple">10.1037/a0027128</ext-link></comment> <object-id pub-id-type="pmid">22369520</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>. <article-title>Estimation of effect size under nonrandom sampling: The effects of censoring studies yielding statistically insignificant mean differences</article-title>. <source>Journal of Educational Statistics</source>. <year>1984</year>;<volume>9</volume>(<issue>1</issue>):<fpage>61</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iyengar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Greenhouse</surname> <given-names>JB</given-names></name>. <article-title>Selection models and the file drawer problem</article-title>. <source>Statistical Science</source>. <year>1988</year>;<volume>3</volume>(<issue>1</issue>):<fpage>109</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/ss/1177013012" xlink:type="simple">10.1214/ss/1177013012</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dear</surname> <given-names>KBG</given-names></name>, <name name-style="western"><surname>Begg</surname> <given-names>CB</given-names></name>. <article-title>An approach for assessing publication bias prior to performing a meta-analysis</article-title>. <source>Statistical Science</source>. <year>1992</year>;<volume>7</volume>(<issue>2</issue>):<fpage>237</fpage>–<lpage>45</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>. <article-title>Modeling publication selection effects in meta-analysis</article-title>. <source>Statistical Science</source>. <year>1992</year>;<volume>7</volume>(<issue>2</issue>):<fpage>246</fpage>–<lpage>55</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vevea</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>. <article-title>A general linear model for estimating effect size in the presence of publication bias.</article-title> <source>Psychometrika</source>. <year>1995</year>;<volume>60</volume>(<issue>3</issue>):<fpage>419</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/bf02294384" xlink:type="simple">10.1007/bf02294384</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Copas</surname> <given-names>JB</given-names></name>. <article-title>What works?: Selectivity models and meta-analysis</article-title>. <source>Journal of the Royal Statistical Society Series A</source> <year>1999</year>;<volume>162</volume>(<issue>1</issue>):<fpage>95</fpage>–<lpage>109</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vevea</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Woods</surname> <given-names>CM</given-names></name>. <article-title>Publication bias in research synthesis: Sensitivity analysis using a priori weight functions</article-title>. <source>Psychological Methods</source>. <year>2005</year>;<volume>10</volume>(<issue>4</issue>):<fpage>428</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/1082-989X.10.4.428" xlink:type="simple">10.1037/1082-989X.10.4.428</ext-link></comment> <object-id pub-id-type="pmid">16392998</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vandekerckhove</surname> <given-names>J</given-names></name>. <article-title>A Bayesian approach to mitigation of publication bias</article-title>. <source>Psychonomic Bulletin and Review</source>. <year>2015</year>:Advance online publication. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-015-0868-6" xlink:type="simple">10.3758/s13423-015-0868-6</ext-link></comment> <object-id pub-id-type="pmid">26126776</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iyengar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Greenhouse</surname> <given-names>JB</given-names></name>. <article-title>Selection models and the file drawer problem</article-title>: <source>Rejoinder. Statistical Science</source>. <year>1988</year>;<volume>3</volume>(<issue>1</issue>):<fpage>133</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref082"><label>82</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Borenstein</surname> <given-names>M.</given-names></name> <chapter-title>Effect sizes for continuous data</chapter-title>. In: <name name-style="western"><surname>Cooper</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Valentine</surname> <given-names>JC</given-names></name>, editors. <source>The Handbook of Research Synthesis and Meta-Analysis</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>; <year>2009</year>. p. <fpage>221</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref083"><label>83</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Fleiss</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Berlin</surname> <given-names>JA</given-names></name>. <chapter-title>Effect sizes for dichotomous data</chapter-title>. In: <name name-style="western"><surname>Cooper</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Valentine</surname> <given-names>JC</given-names></name>, editors. <source>The Handbook of Research Synthesis and Meta-Analysis</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>; <year>2009</year>. p. <fpage>237</fpage>–<lpage>53</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viechtbauer</surname> <given-names>W.</given-names></name> <article-title>Approximate confidence intervals for standardized effect sizes in the two-independent and two-dependent samples design</article-title>. <source>Journal of Educational and Behavioral Statistics</source>. <year>2007</year>;<volume>32</volume>(<issue>1</issue>):<fpage>39</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3102/1076998606298034" xlink:type="simple">10.3102/1076998606298034</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref085"><label>85</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Higgins</surname> <given-names>JPT</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Deeks</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>. <article-title>Measuring inconsistency in meta-analyses</article-title>. <source>British Medical Journal</source>. <year>2003</year>;<volume>327</volume>(<issue>7414</issue>):<fpage>557</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/bmj.327.7414.557" xlink:type="simple">10.1136/bmj.327.7414.557</ext-link></comment> <object-id pub-id-type="pmid">12958120</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref086"><label>86</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rücker</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schwarzer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Carpenter</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Schumacher</surname> <given-names>M</given-names></name>. <article-title>Undue reliance on I2 in assessing heterogeneity may mislead.</article-title> <source>BMC Medical Research Methodology</source>. <year>2008</year>;<volume>8</volume>(<issue>1</issue>):<fpage>79</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1471-2288-8-79" xlink:type="simple">10.1186/1471-2288-8-79</ext-link></comment> <object-id pub-id-type="pmid">19036172</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref087"><label>87</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Patsopoulos</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Evangelou</surname> <given-names>E</given-names></name>. <article-title>Uncertainty in heterogeneity estimates in meta-analyses</article-title>. <source>BMJ</source>. <year>2007</year>;<volume>335</volume>(<issue>7626</issue>):<fpage>914</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/bmj.39343.408449.80" xlink:type="simple">10.1136/bmj.39343.408449.80</ext-link></comment> <object-id pub-id-type="pmid">17974687</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref088"><label>88</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>von Hippel</surname> <given-names>PT</given-names></name>. <article-title>The heterogeneity statistic I2 can be biased in small meta-analyses</article-title>. <source>BMC Medical Research Methodology</source>. <year>2015</year>;<volume>15</volume>:<fpage>35</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12874-015-0024-z" xlink:type="simple">10.1186/s12874-015-0024-z</ext-link></comment> PMC4410499. <object-id pub-id-type="pmid">25880989</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref089"><label>89</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Macaskill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Walter</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Irwig</surname> <given-names>L</given-names></name>. <article-title>A comparison of methods to detect publication bias in meta-analysis</article-title>. <source>Statistics in Medicine</source>. <year>2001</year>;<volume>20</volume>(<issue>4</issue>):<fpage>641</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.698" xlink:type="simple">10.1002/sim.698</ext-link></comment> <object-id pub-id-type="pmid">11223905</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref090"><label>90</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Springate</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Kontopantelis</surname> <given-names>E</given-names></name>. <article-title>Cochrane_scraper: tools for downloading data from the Cochrane Library of Systematic Reviews</article-title>. 1.1.0 ed<year>2014</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref091"><label>91</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loevinger</surname> <given-names>J.</given-names></name> <article-title>The technic of homogeneous tests compared with some aspects of scale analysis and factor analysis</article-title>. <source>Psychological Bulletin</source>. <year>1948</year>;<volume>45</volume>(<issue>6</issue>):<fpage>507</fpage>–<lpage>29</lpage>. <object-id pub-id-type="pmid">18893224</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref092"><label>92</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Raudenbush</surname> <given-names>SW</given-names></name>. <chapter-title>Analyzing effect sizes: Random-effects models</chapter-title>. In: <name name-style="western"><surname>Cooper</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Valentine</surname> <given-names>JC</given-names></name>, editors. <source>The Handbook of Research Synthesis and Meta-Analysis</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>; <year>2009</year>. p. <fpage>295</fpage>–<lpage>315</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref093"><label>93</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paule</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Mandel</surname> <given-names>J</given-names></name>. <article-title>Consensus values and weighting factors</article-title>. <source>Journal of Research of the National Bureau of Standards</source>. <year>1982</year>;<volume>87</volume>(<issue>5</issue>):<fpage>377</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref094"><label>94</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Veroniki</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Jackson</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Viechtbauer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Bender</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bowden</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Knapp</surname> <given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Methods to estimate the between-study variance and its uncertainty in meta-analysis.</article-title> <source>Research Synthesis Methods</source>. <year>2016</year>;<volume>7</volume>(<issue>1</issue>):<fpage>55</fpage>–<lpage>79</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/jrsm.1164" xlink:type="simple">10.1002/jrsm.1164</ext-link></comment> <object-id pub-id-type="pmid">26332144</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref095"><label>95</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Langan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JPT</given-names></name>, <name name-style="western"><surname>Simmonds</surname> <given-names>M</given-names></name>. <article-title>Comparative performance of heterogeneity variance estimators in meta-analysis: A review of simulation studies</article-title>. <source>Research Synthesis Methods</source>. <year>2016</year>;<volume>8</volume>(<issue>2</issue>):<fpage>181</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/jrsm.1198" xlink:type="simple">10.1002/jrsm.1198</ext-link></comment> <object-id pub-id-type="pmid">27060925</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref096"><label>96</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jackson</surname> <given-names>D.</given-names></name> <article-title>The implications of publication bias for meta-analysis' other parameter</article-title>. <source>Statistics in Medicine</source>. <year>2006</year>;<volume>25</volume>(<issue>17</issue>):<fpage>2911</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.2293" xlink:type="simple">10.1002/sim.2293</ext-link></comment> <object-id pub-id-type="pmid">16345059</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref097"><label>97</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Augusteijn</surname> <given-names>HEM</given-names></name>, <name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>The effect of publication bias on the Q-test and assessment of heterogeneity</article-title>. <source>Psychological Methods</source>. in press.</mixed-citation></ref>
<ref id="pone.0215052.ref098"><label>98</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Koenker</surname> <given-names>R.</given-names></name> <source>Quantile regression</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2005</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref099"><label>99</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>J.</given-names></name> <chapter-title>Statistical power analysis for the behavioral sciences</chapter-title>. <edition>2nd ed</edition>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>; <year>1988</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref100"><label>100</label><mixed-citation publication-type="journal" xlink:type="simple"><collab>R Core Team</collab>. <source>R: A language and environment for statistical computing</source>. <year>2018</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref101"><label>101</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viechtbauer</surname> <given-names>W.</given-names></name> <article-title>Conducting meta-analyses in R with the metafor package</article-title>. <source>Journal of Statistical Software</source>. <year>2010</year>;<volume>36</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref102"><label>102</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>. <article-title>puniform: Meta-analysis methods correcting for publication bias</article-title>. 0.1.0 ed<year>2018</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref103"><label>103</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Else-Quest</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Hyde</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Goldsmith</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Van Hulle</surname> <given-names>CA</given-names></name>. <article-title>Gender differences in temperament: A meta-analysis</article-title>. <source>Psychological Bulletin</source>. <year>2006</year>;<volume>132</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.132.1.33" xlink:type="simple">10.1037/0033-2909.132.1.33</ext-link></comment> <object-id pub-id-type="pmid">16435957</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref104"><label>104</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>Examining reproducibility in psychology: A hybrid method for combining a statistically significant original study and a replication</article-title>. <source>Behavior Research Methods</source>. <year>2018</year>;<volume>50</volume>(<issue>4</issue>):<fpage>1515</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13428-017-0967-6" xlink:type="simple">10.3758/s13428-017-0967-6</ext-link></comment> <object-id pub-id-type="pmid">28936638</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref105"><label>105</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>SF</given-names></name>, <name name-style="western"><surname>Kelley</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Maxwell</surname> <given-names>SE</given-names></name>. <article-title>Sample-size planning for more accurate statistical power: A method adjusting sample effect sizes for publication bias and uncertainty</article-title>. <source>Psychological Science</source>. <year>2017</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1547</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617723724" xlink:type="simple">10.1177/0956797617723724</ext-link></comment> <object-id pub-id-type="pmid">28902575</object-id>.</mixed-citation></ref>
<ref id="pone.0215052.ref106"><label>106</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Aert</surname> <given-names>RCM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>Correcting for publication bias in a meta-analysis with the p-uniform* method</article-title>. Manuscript submitted for publication Retrieved from: <ext-link ext-link-type="uri" xlink:href="https://osfio/preprints/bitss/zqjr92018" xlink:type="simple">https://osfio/preprints/bitss/zqjr92018</ext-link>.</mixed-citation></ref>
<ref id="pone.0215052.ref107"><label>107</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Costas</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Meta-assessment of bias in science</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1618569114" xlink:type="simple">10.1073/pnas.1618569114</ext-link></comment> <object-id pub-id-type="pmid">28320937</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref108"><label>108</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D.</given-names></name> <article-title>“Positive” results increase down the hierarchy of the sciences</article-title>. <source>PLoS ONE</source>. <year>2010</year>;<volume>5</volume>(<issue>4</issue>):<fpage>e10068</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0010068" xlink:type="simple">10.1371/journal.pone.0010068</ext-link></comment> <object-id pub-id-type="pmid">20383332</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref109"><label>109</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olsson-Collentine</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>van Assen</surname> <given-names>MALM</given-names></name>. <article-title>Limited evidence for widespread heterogeneity in psychology</article-title>. Manuscript submitted for publication. <year>2019</year>.</mixed-citation></ref>
<ref id="pone.0215052.ref110"><label>110</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Vianello</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hasselman</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Alper</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Many Labs 2: Investigating variation in replicability across samples and settings</article-title>. <source>Advances in Methods and Practices in Psychological Science</source>. <year>2018</year>;<volume>1</volume>(<issue>4</issue>):<fpage>443</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/2515245918810225" xlink:type="simple">10.1177/2515245918810225</ext-link></comment></mixed-citation></ref>
<ref id="pone.0215052.ref111"><label>111</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>US studies may overestimate effect sizes in softer research</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2013</year>;<volume>110</volume>(<issue>37</issue>):<fpage>15031</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1302997110" xlink:type="simple">10.1073/pnas.1302997110</ext-link></comment> <object-id pub-id-type="pmid">23980165</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref112"><label>112</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jackson</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>White</surname> <given-names>IR</given-names></name>, <name name-style="western"><surname>Riley</surname> <given-names>RD</given-names></name>. <article-title>Quantifying the impact of between-study heterogeneity in multivariate meta-analyses</article-title>. <source>Statistics in Medicine</source>. <year>2012</year>;<volume>31</volume>(<issue>29</issue>):<fpage>3805</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/sim.5453" xlink:type="simple">10.1002/sim.5453</ext-link></comment> <object-id pub-id-type="pmid">22763950</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref113"><label>113</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cochran</surname> <given-names>WG</given-names></name>. <article-title>The combination of estimates from different experiments</article-title>. <source>Biometrics</source>. <year>1954</year>;<volume>10</volume>(<issue>1</issue>):<fpage>101</fpage>–<lpage>29</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref114"><label>114</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hardy</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>SG</given-names></name>. <article-title>Detecting and describing heterogeneity in meta-analysis</article-title>. <source>Statistics in Medicine</source>. <year>1998</year>;<volume>17</volume>(<issue>8</issue>):<fpage>841</fpage>–<lpage>56</lpage>. <object-id pub-id-type="pmid">9595615</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref115"><label>115</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viechtbauer</surname> <given-names>W.</given-names></name> <article-title>Hypothesis tests for population heterogeneity in meta-analysis</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>. <year>2007</year>;<volume>60</volume>:<fpage>29</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1348/000711005X64042" xlink:type="simple">10.1348/000711005X64042</ext-link></comment> <object-id pub-id-type="pmid">17535578</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref116"><label>116</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>. <chapter-title>Evidence concerning the consequences of publication and related biases.</chapter-title> In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment and adjustments</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2005</year>. p. <fpage>175</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="pone.0215052.ref117"><label>117</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Citkowicz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vevea</surname> <given-names>JL</given-names></name>. <article-title>A parsimonious weight function for modeling publication bias</article-title>. <source>Psychological Methods</source>. <year>2017</year>;<volume>22</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>41</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/met0000119" xlink:type="simple">10.1037/met0000119</ext-link></comment> <object-id pub-id-type="pmid">28252998</object-id></mixed-citation></ref>
<ref id="pone.0215052.ref118"><label>118</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Dickersin</surname> <given-names>K.</given-names></name> <chapter-title>Publication bias: Recognizing the problem understanding its origins and scope, and preventing harm</chapter-title>. In: <name name-style="western"><surname>Rothstein</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Borenstein</surname> <given-names>M</given-names></name>, editors. <source>Publication bias in meta-analysis: Prevention, assessment and adjustments</source>. <publisher-loc>Chichester, England</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2005</year>. p. <fpage>11</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>