<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="pmc">plosone</journal-id>
      <journal-title-group>
        <journal-title>PLoS ONE</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1932-6203</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PONE-D-12-07837</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pone.0049945</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Control engineering</subject>
            <subj-group>
              <subject>Control systems</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Engineering</subject>
          <subj-group>
            <subject>Bioengineering</subject>
            <subj-group>
              <subject>Biomimetics</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Human factors engineering</subject>
            <subj-group>
              <subject>Man computer interface</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Mechanical engineering</subject>
            <subj-group>
              <subject>Robotics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Behavior</subject>
              <subject>Human relations</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Biotechnology</subject>
          <subject>Computer Science</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A Framework to Describe, Analyze and Generate Interactive Motor Behaviors</article-title>
        <alt-title alt-title-type="running-head">A Framework to Study Interactive Motor Behaviors</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Jarrassé</surname>
            <given-names>Nathanaël</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Charalambous</surname>
            <given-names>Themistoklis</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Burdet</surname>
            <given-names>Etienne</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, United Kingdom</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Institute of Intelligent Systems and Robotics, UPMC - University Pierre et Marie Curie, CNRS - UMR 7222, Paris, France</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Automatic Control Lab, Electrical Engineering Department and ACCESS Linnaeus Center, Royal Institute of Technology (KTH), Stockholm, Sweden</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Ernst</surname>
            <given-names>Marc O.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>Bielefeld University, Germany</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">n.jarrasse@imperial.ac.uk</email> (NJ); <email xlink:type="simple">eburdet@imperial.ac.uk</email> (EB)</corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: NJ EB. Performed the experiments: NJ TC. Analyzed the data: NJ TC EB. Contributed reagents/materials/analysis tools: NJ TC. Wrote the paper: NJ EB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <year>2012</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>30</day>
        <month>11</month>
        <year>2012</year>
      </pub-date>
      <volume>7</volume>
      <issue>11</issue>
      <elocation-id>e49945</elocation-id>
      <history>
        <date date-type="received">
          <day>13</day>
          <month>3</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>19</day>
          <month>10</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2012</copyright-year>
        <copyright-holder>Jarrasse et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>While motor interaction between a robot and a human, or between humans, has important implications for society as well as promising applications, little research has been devoted to its investigation. In particular, it is important to understand the different ways two agents can interact and generate suitable interactive behaviors. Towards this end, this paper introduces a framework for the description and implementation of interactive behaviors of two agents performing a joint motor task. A taxonomy of interactive behaviors is introduced, which can classify tasks and cost functions that represent the way each agent interacts. The role of an agent interacting during a motor task can be directly explained from the cost function this agent is minimizing and the task constraints. The novel framework is used to interpret and classify previous works on human-robot motor interaction. Its implementation power is demonstrated by simulating representative interactions of two humans. It also enables us to interpret and explain the role distribution and switching between roles when performing joint motor tasks.</p>
      </abstract>
      <funding-group>
        <funding-statement>This study was supported by the EU FP7-231724 HUMOUR grant. No additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="13"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Joint action is a fundamental aspect of human life <xref ref-type="bibr" rid="pone.0049945-Sebanz1">[1]</xref>, as we collaborate or interact with peers in most actions. This paper concerns in particular joint actions with <italic>motor interaction</italic>, which stands either for “physical interaction” (which is ambiguous as physics is not restricted to mechanics) or for “haptic interaction” (as haptics concerns (touch and force) sensing while interaction additionally requires a motor action). Many common tasks rely on the motor interaction of two humans, such as sawing, dancing, physical rehabilitation, fighting, mating, carrying a table, etc. <xref ref-type="bibr" rid="pone.0049945-Allport1">[2]</xref> (see some examples in <xref ref-type="fig" rid="pone-0049945-g001">Fig. 1</xref>). As voluntary movement is the defining characteristic of animals, it is plausible that motor interactions are at the basis of all social and communication behaviors <xref ref-type="bibr" rid="pone.0049945-Clark1">[3]</xref>. How humans deal with motor interactions is largely unknown, and has not been systematically studied until recently. In fact, in the last 150 years, human motor control research has been devoted mostly to the study of walking <xref ref-type="bibr" rid="pone.0049945-Marey1">[4]</xref> and free arm movements <xref ref-type="bibr" rid="pone.0049945-Woodworth1">[5]</xref>. It is only in the last 40 years that robotic interfaces have been used to investigate how humans interact with the environment (e.g., <xref ref-type="bibr" rid="pone.0049945-MussaIvaldi1">[6]</xref>–<xref ref-type="bibr" rid="pone.0049945-Burdet1">[8]</xref>) and with each other (e.g., <xref ref-type="bibr" rid="pone.0049945-Reed1">[9]</xref>, <xref ref-type="bibr" rid="pone.0049945-Braun1">[10]</xref>) to perform a variety of tasks.</p>
      <fig id="pone-0049945-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Different tasks requiring interaction between two agents (here represented with Lego® parts and characters).</title>
          <p>From left to right: sawing, lifting a heavy load together, agonistic arm wrestling task and interactive dancing task.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>Understanding how humans interact in tasks requiring motor interaction is an interesting and challenging new field of research, and is critically important to designing robots interacting with humans. Recent years have seen a surge of cooperative robots, such as assistive devices for industry <xref ref-type="bibr" rid="pone.0049945-Akella1">[11]</xref>, robotic wheelchairs to increase the mobility of people with physical or cognitive deficits <xref ref-type="bibr" rid="pone.0049945-Zeng1">[12]</xref>, workstations with haptic feedback which can be used to train surgeons <xref ref-type="bibr" rid="pone.0049945-Nudehi1">[13]</xref>, and robotic systems to increase the amount and intensity of physical therapy after stroke <xref ref-type="bibr" rid="pone.0049945-Balasubramanian1">[14]</xref>.</p>
      <p>Therefore, it becomes necessary to develop tools for characterizing and understanding the nature and the issues of interactive tasks. Having a taxonomy of interaction kinds and strategies would enable us to identify the interaction strategies humans use. This may help us creating robots that react as humans do during motor interaction, as well as efficient human-robot dyads able to use the best of the human and the robot. Therefore, we would like to design <italic>a taxonomy of interactive behaviors that can classify the different kinds of motor interactions, model the agents' behavior and simulate their control</italic>.</p>
      <p>In order to do so, we first reviewed literature on motor interaction behaviors in the fields of human computer interaction (HCI), robotics, psychology and game theory <xref ref-type="bibr" rid="pone.0049945-Jarrass1">[15]</xref>. The main results on taxonomies for motor interactions can be summarised as follows:</p>
      <list list-type="bullet">
        <list-item>
          <p>Some taxonomies from HCI (e.g., <xref ref-type="bibr" rid="pone.0049945-Yanco1">[16]</xref>, <xref ref-type="bibr" rid="pone.0049945-Burghart1">[17]</xref>) can be used for motor interactions, but are not specific to them and difficult to apply in concrete tasks.</p>
        </list-item>
        <list-item>
          <p>Analyses of motor interaction kinds <xref ref-type="bibr" rid="pone.0049945-Reed2">[18]</xref>, <xref ref-type="bibr" rid="pone.0049945-Stefanov1">[19]</xref> have defined roles according to either the trajectory <xref ref-type="bibr" rid="pone.0049945-Evrard1">[20]</xref> or the force <xref ref-type="bibr" rid="pone.0049945-Oguz1">[21]</xref>. Models using both trajectory and force (e.g., <xref ref-type="bibr" rid="pone.0049945-Stefanov2">[22]</xref>) are complex and thus difficult to use.</p>
        </list-item>
        <list-item>
          <p>A few implementations of controllers with flexible behavior have been developed <xref ref-type="bibr" rid="pone.0049945-Evrard1">[20]</xref>, <xref ref-type="bibr" rid="pone.0049945-Oguz1">[21]</xref>, which are based on simplified taxonomies and thus not adapted to all situations. For instance, important motor interactions for humans such as competition have not been considered.</p>
        </list-item>
        <list-item>
          <p>While studies on psychological <xref ref-type="bibr" rid="pone.0049945-Sebanz2">[23]</xref> and social factors <xref ref-type="bibr" rid="pone.0049945-Chartrand1">[24]</xref> influencing joint action focused on kinematic and haptic information exchanges present interesting analyses, they could hardly be used to generate joint motor behaviors.</p>
        </list-item>
      </list>
      <p>These shortcomings of previous taxonomies for motor behaviors prompted us to describe the role distribution during a joint motor action in a simple quantitative way. First, the nature of the task and how it constrains the choice of possible behaviors for each agent and their interactions was studied. Then, the role of each agent was defined through a cost function that it needs to minimize, and the interaction between the two agents arises by their physical coupling. This enables us to use mathematical tools from Game Theory, optimal control and nonlinear adaptive control in order to derive the two partners' motor behavior and adaptation.</p>
      <p>It has been shown in neuroscience studies that humans interact with the environment by minimizing error (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e001" xlink:type="simple"/></inline-formula>) and effort (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e002" xlink:type="simple"/></inline-formula>) <xref ref-type="bibr" rid="pone.0049945-Franklin1">[25]</xref>, <xref ref-type="bibr" rid="pone.0049945-Todorov1">[26]</xref>, which can be modelled as the minimization of the cost function<disp-formula id="pone.0049945.e003"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e003" xlink:type="simple"/><label>(1)</label></disp-formula>Furthermore, when interacting with novel dynamics, humans adapt force, mechanical impedance and trajectory to minimize such a cost function <xref ref-type="bibr" rid="pone.0049945-Burdet2">[27]</xref>–<xref ref-type="bibr" rid="pone.0049945-OSullivan1">[29]</xref>. Similar cost functions will be used to model the interaction of two agents.</p>
      <p>This paper's outline is as follows. A framework for motor interactive tasks and control is first introduced, in the form of a simple taxonomy for the interaction between two agents, physically coupled (directly or through an external object or tool) and conditioned by the tasks they are carrying out. The paper then presents how the taxonomy can be used to classify existing implementations of human-robot motor interaction, and provides an overview of the problems that remain to be addressed. The new taxonomy can also be used to generate appropriate behaviors, as is illustrated in simulations. Finally, possible applications of the framework to other fields like behavioral psychology and agent theory are described.</p>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>A framework for motor interactions</title>
        <p>Game theory <xref ref-type="bibr" rid="pone.0049945-Neumann1">[30]</xref>, which describes and analyzes situations where interactive decisions take place, appears as a natural framework to consider the motor interaction in a human-human, human-robot or robot-robot dyad. Game theory comprises a set of analytical tools to predict the outcome of complex interactions among decision makers, obeying to a strategy based on perceived or measured results. Two-player games, such as the motor interactions considered in this paper, play a fundamental role in game theory because their analysis is straightforward; John von Neumann's minimax theorem <xref ref-type="bibr" rid="pone.0049945-Neumann1">[30]</xref> establishes a unique value of such games.</p>
        <p>Models that address the interaction among individual decision makers are called <italic>games</italic> and the rational decision makers are referred to as <italic>agents</italic> in this paper. Interaction between the agents is represented by the influence that each agent has on the resulting outcome through a cost function representing its objectives. Steady-state conditions in which each player is assumed to know the equilibrium strategies of the other players, and no player has anything to gain by changing only his own strategy unilaterally, known as <italic>Nash equilibria</italic>, can be identified <xref ref-type="bibr" rid="pone.0049945-Nash1">[31]</xref>, <xref ref-type="bibr" rid="pone.0049945-Nash2">[32]</xref>. The interaction tasks can be seen as <italic>differential games</italic>, also called <italic>utility-based games</italic>, where the evolution of the partners' state variables is governed by differential equations. The problem of finding an optimal strategy in a differential game is closely related to optimal control. Note that while game theory has been originally conceived to model conscious (and also rational) decisions of agents, interaction behaviors may be at least in part automatic (i.e. without voluntary control) and sometimes unconscious. Agents behavior may be well described by the mathematical (game theoretical) framework without assuming that they know exactly what they have to do or think about it. However, the reaction to a sudden change that can be seen as irrational is considered as a transition in the system so does not affect its properties (such as existence, uniqueness, etc.).</p>
        <sec id="s2a1">
          <title>Interaction definition</title>
          <p>We consider the interaction of two agents, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e004" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e005" xlink:type="simple"/></inline-formula>, that:</p>
          <list list-type="bullet">
            <list-item>
              <p>generally aim at minimizing their effort <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e006" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e007" xlink:type="simple"/></inline-formula>.</p>
            </list-item>
            <list-item>
              <p>perform separate actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e008" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e009" xlink:type="simple"/></inline-formula> or a common action <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e010" xlink:type="simple"/></inline-formula>, whose performance is rewarded by reinforcement signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e011" xlink:type="simple"/></inline-formula> or evaluated through error measures <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e012" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e013" xlink:type="simple"/></inline-formula>.</p>
            </list-item>
            <list-item>
              <p>are each equipped with multimodal sensors. To simplify the exposition, we will focus on sensors measuring position, force and body contact. Agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e014" xlink:type="simple"/></inline-formula> is able to perceive its own error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e015" xlink:type="simple"/></inline-formula> and estimate the partner's error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e016" xlink:type="simple"/></inline-formula> (denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e017" xlink:type="simple"/></inline-formula>), whereas agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e018" xlink:type="simple"/></inline-formula> perceives <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e019" xlink:type="simple"/></inline-formula> and estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e020" xlink:type="simple"/></inline-formula> (denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e021" xlink:type="simple"/></inline-formula>).</p>
            </list-item>
            <list-item>
              <p>are equipped with actuators able to affect the environment and the other agent with suitable force and mechanical impedance, using a controller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e022" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e023" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e024" xlink:type="simple"/></inline-formula> (<italic>i.e.</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e025" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e027" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e028" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e029" xlink:type="simple"/></inline-formula> denotes the estimate from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e030" xlink:type="simple"/></inline-formula> of the error of the other agent.</p>
            </list-item>
          </list>
          <p>In summary, each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e031" xlink:type="simple"/></inline-formula> has to fulfil a task by minimizing some error (or maximizing some reward) while using minimal metabolic cost. Each <italic>interaction behavior</italic> will arise from the combination of the minimization of the individual cost functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e032" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e033" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e034" xlink:type="simple"/></inline-formula>, and is thus characterized by these two cost functions.</p>
          <p>The nature of the motor interaction between the agents depends on the combination of their personal behaviors, as will be described in more detail in the “<italic>Taxonomy of interactive behaviors</italic>” section of the <xref ref-type="sec" rid="s2">Methods</xref>, and is also constrained by the particular task(s) carried out, which will be described in detail in the “<italic>Divisible vs. interactive tasks</italic>” and “<italic>Agonistic vs. antagonistic tasks</italic>” sub-sections of the <xref ref-type="sec" rid="s2">Methods</xref>. These cost functions can also be used to adapt behavior as will be described in the “<italic>Learning</italic>” paragraph of the <xref ref-type="sec" rid="s3">Results</xref>. The following task description extends the approach of <xref ref-type="bibr" rid="pone.0049945-Vesper1">[33]</xref> about representations and action monitoring supporting joint action.</p>
        </sec>
        <sec id="s2a2">
          <title>Divisible vs. interactive tasks</title>
          <p>We start our description with <italic>divisible tasks</italic>, which are composed of compatible subtasks that can be completed by each agent independently. In some cases the task could be completed by each agent alone, such as painting a house walls together <xref ref-type="bibr" rid="pone.0049945-Bratman1">[34]</xref>, or the task in the left panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref>, where two animals can pull a rope to move a pallet and obtain food. Other divisible tasks have disjunct but complementary subtasks, such as a hybrid force-position controller in which position control and force control are executed independently in separate subspaces <xref ref-type="bibr" rid="pone.0049945-Raibert1">[35]</xref>.</p>
          <fig id="pone-0049945-g002" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g002</object-id>
            <label>Figure 2</label>
            <caption>
              <title>Example of different kinds of tasks two agents can carry out.</title>
              <p>We consider simple tasks in which two animals can pull a rope in order to approach a pallet with food. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e035" xlink:type="simple"/></inline-formula> is a measure of error relative to the target and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e036" xlink:type="simple"/></inline-formula> a reward increasing when the state approaches the target. In the <italic>divisible task</italic>, each agent contributes to his own subtask (i.e., pulling the rope), which helps getting the pallet for both animals. In the <italic>interactive task</italic> the two agents have to collaborate in order to succeed in completing the task. In the <italic>antagonistic task</italic> the performance of one agent is detrimental to the other.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g002" position="float" xlink:type="simple"/>
          </fig>
          <p>In divisible tasks, the two agents do not need to know anything about the other agent in order to succeed in their respective subtask. As the two agents are acting independently, each agent can minimize its own error and effort, which we represent by the same cost function as was found when one human is interacting with the environment <xref ref-type="bibr" rid="pone.0049945-Franklin1">[25]</xref>:<disp-formula id="pone.0049945.e037"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e037" xlink:type="simple"/><label>(2)</label></disp-formula>We name such independent behavior <italic>co-activity</italic>.</p>
          <p>A task in which (at least) one agent needs a partner to carry out its (sub)task is called <italic>interactive</italic>. The Game Theory formalism embraces interactive tasks, in which the activity of one agent affects the other agent. The middle panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref> illustrates an interactive task that has been used to examine the social behavior of animals such as chimpanzes <xref ref-type="bibr" rid="pone.0049945-Crawford1">[36]</xref>, elephants <xref ref-type="bibr" rid="pone.0049945-Drea1">[37]</xref> and hyenas <xref ref-type="bibr" rid="pone.0049945-Plotnik1">[38]</xref>. In this task no animal can succeed in securing the food without the help of its partner. As in an interactive task the agents' behaviors are dependent, thus the behavior is more complex than with a divisible task, and the cost function depends on both agents: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e038" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e039" xlink:type="simple"/></inline-formula>. The rich repertoire of behaviors that can be adopted in interactive tasks is described in subsection “<italic>Taxonomy of interactive behaviors</italic>” of the <xref ref-type="sec" rid="s2">Methods</xref>.</p>
        </sec>
        <sec id="s2a3">
          <title>Agonistic vs. antagonistic tasks</title>
          <p>Both divisible and interactive tasks can be agonistic or antagonistic. In an <italic>antagonistic task</italic>, performance improvement in (at least) one agent is detrimental to the partner, due to conflicting interests, as is illustrated in the right panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref>. An agent's gain (or loss) of utility is exactly balanced by the loss (or gain) of the utility of the other agent. If the total gains of the agents are added up, and the total losses are subtracted, they will sum to zero; that is why these types of interactive tasks are considered as strictly competitive and correspond to zero-sum games in game theory (the total benefit to both players in the game, for every combination of strategies, always adds to zero). Examples of antagonistic tasks include arm wrestling, rope pulling game and fighting. In general, the agents have distinct subtasks and there is no common task.</p>
          <p>In contrary, in <italic>agonistic tasks</italic> improvement in one agent's subtask contributes to the improvement in the common task. This category stains numerous interactive tasks like moving a heavy table together, dancing or mating, where joint action is the only solution to succeed in the task, but also divisible tasks such as hybrid position/force control. Both the left and middle panels of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref> are agonist tasks. In such a case, the task enforces cooperative behavior and these types of interactive tasks correspond to the cooperative games of game theory.</p>
          <p>In summary, tasks are determined by two antagonisms: divisible/interactive, and agonistic/antagonistic. Divisible tasks induce a co-active behavior which will help both agents in agonistic tasks, such as in the left panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref>, and can be mutually detrimental in an antagonist task, such as in the right panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref>. Similarly, interactive tasks can be either agonistic, such in the middle panel of <xref ref-type="fig" rid="pone-0049945-g002">Fig. 2</xref>, or antagonistic, when a Sumo fighter pushes as much as possible against the opponent and suddenly drops the force in order to destabilize him.</p>
        </sec>
      </sec>
      <sec id="s2b">
        <title>Taxonomy of interactive behaviors</title>
        <p>The behaviors adopted to perform interactive tasks can be classified in three main categories: cooperation, collaboration and competition. Competition will be mainly observed during the antagonistic tasks as a noncooperative game, whereas various kinds of cooperation and collaboration will mainly occur during agonistic tasks and will be treated as a cooperative game (the partners are able to form binding commitments). These categories and the associated cost functions are summarized in <xref ref-type="fig" rid="pone-0049945-g003">Fig. 3</xref> and will be described now. Note that the associated cost functions suggest a utility-based game theoretic approach, in which the behavior of the agents depends on the utilities being chosen.</p>
        <fig id="pone-0049945-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Definition of main kinds of behaviors (in interactive tasks) through cost functions.</title>
            <p>For simplicity, the time variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e040" xlink:type="simple"/></inline-formula> was omitted in the cost functions.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g003" position="float" xlink:type="simple"/>
        </fig>
        <sec id="s2b1">
          <title>Competition vs. collaboration</title>
          <p>In a <italic>competition</italic>, both agents focus on their own action and effort, and if necessary impede the other's performance in this purpose:<disp-formula id="pone.0049945.e041"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e041" xlink:type="simple"/><label>(3)</label></disp-formula>In this scheme the two agents may have different goals, such as reaching different targets at the same time with the same object, or the same goal, such as when two children attempt to grasp the same cookie. In contrast, in a <italic>collaboration</italic> both agents jointly try to develop a consensual solution to solve a problem <xref ref-type="bibr" rid="pone.0049945-Dillenbourg1">[39]</xref>, and, as in cooperative games, no agent has incentive to leave the coalition formed and receive a smaller utility. A collaboration is also modelled as a <italic>symmetric behavior</italic> (i.e., the cost function's structure does not change under the permutation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e042" xlink:type="simple"/></inline-formula>), but this time with positive influence on the partner:<disp-formula id="pone.0049945.e043"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e043" xlink:type="simple"/><label>(4)</label></disp-formula>Each agent minimizes its and the partner's error and metabolic cost (i.e., energy, force, etc.).</p>
        </sec>
        <sec id="s2b2">
          <title>Cooperation vs. collaboration</title>
          <p>In a collaboration, there is no a priori roles distribution, but a spontaneous roles distribution depending on the interaction history. Any physical interaction with negotiations and discussions to accommodate others while considering their perspective, belong to this category. In this case “activity is synchronized and coordinated in order to build and maintain a shared conception of a problem” <xref ref-type="bibr" rid="pone.0049945-Roschelle1">[40]</xref>.</p>
          <p>In contrast, a <italic>cooperation</italic> occurs when different roles are ascribed to the agents prior to the beginning of a task and this distribution is not questioned until its completion. While in collaboration the agents work on an even basis, cooperation has an uneven distribution of subtasks or roles during the task <xref ref-type="bibr" rid="pone.0049945-Dillenbourg1">[39]</xref>. Cooperating agents work towards the same end and need each other to complete the task, but are not equal. In fact, cooperation is characterized by an <italic>asymmetric behavior</italic>, in the sense of asymmetry in the cost functions as tested from the permutation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e044" xlink:type="simple"/></inline-formula>.</p>
        </sec>
        <sec id="s2b3">
          <title>Master-slave vs. education</title>
          <p>The most typical asymmetric relationship of a cooperation is the <italic>master-slave</italic> scheme. This behavior is characterized by the following cost functions:<disp-formula id="pone.0049945.e045"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e045" xlink:type="simple"/><label>(5)</label></disp-formula>The master is only considering himself, while the slave considers only (his perception of) the master needs. The above cost functions illustrate the danger of this relation, where the slave does not consider its own effort expense and may eventually lose all its energy.</p>
          <p>We want now to examine the teacher-student relationship. This relation is critical to human society and education, and also to developing service robots. The efficiency of all kinds of virtual reality based training systems (for surgery, sport, etc.) and robot-assisted physical rehabilitation systems will namely depend on a suitable interaction behavior. One may a-priori think that the master-slave scheme applies here as well, with the teacher as master and the student as slave. However, efficient learning schemes suppose that the student is building his own capacities while the teacher is assisting this process. Similarly, 20 years of experience with robot-assisted neurorehabilitation of stroke patients have shown that stroke survivors improve their motor functions only when actively attempting to move, but do not improve when they can rely on the robot to move their arm <xref ref-type="bibr" rid="pone.0049945-Hogan1">[41]</xref>, <xref ref-type="bibr" rid="pone.0049945-Kahn1">[42]</xref>.</p>
          <p>Therefore, the master-slave interaction behavior is not appropriate for education. However, an altered version of an assistance can be considered for the relationship between a teacher and his student, or a sportsman and his coach. A good teacher will try to maximize the student's independence. Therefore, the teacher can minimize his own effort in order to challenge the student, let him perform according to his capabilities and eventually increase them. In the <italic>education behavior</italic>, the cost functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e046" xlink:type="simple"/></inline-formula> of the teacher and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e047" xlink:type="simple"/></inline-formula> of the student are thus defined as:<disp-formula id="pone.0049945.e048"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e048" xlink:type="simple"/><label>(6)</label></disp-formula></p>
          <p>This definition describes the main quality of a good teacher as the capability to maximize student involvement and action. Even if the teacher is an expert in the task (good at minimizing goal error) or wants to help the student, he should not care too much about the task achievement (i.e., adopt the slave role), but let the student try and improve his or her performance. Indeed, “the goal of the teacher is to become obsolete as soon as possible, leaving the pupil to perform the skill on his or her own” <xref ref-type="bibr" rid="pone.0049945-Gillespie1">[43]</xref>.</p>
        </sec>
        <sec id="s2b4">
          <title>Mutual assistance</title>
          <p>Finally, the anecdotical mutual assistance or <italic>reciprocal altruism</italic> <xref ref-type="bibr" rid="pone.0049945-Trivers1">[44]</xref> can also be represented in our taxonomy, using cost function<disp-formula id="pone.0049945.e049"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e049" xlink:type="simple"/><label>(7)</label></disp-formula>This ideal interaction behavior occurs in particular contexts such as the iterative prisoner dilemma and associated strategies such as tit-for-tat <xref ref-type="bibr" rid="pone.0049945-Axelrod1">[45]</xref>, where the interaction strategy is selected by considering long term benefits.</p>
        </sec>
        <sec id="s2b5">
          <title>A tool to interpret switchings between interactive behaviors</title>
          <p>The importance of transitions between distinct behaviors has been emphasized in <xref ref-type="bibr" rid="pone.0049945-MelendezCalderon1">[46]</xref>. The above framework enables us to understand the relations between distinct interaction behaviors in the case of interactive tasks. As illustrated in <xref ref-type="fig" rid="pone-0049945-g004">Fig. 4</xref>, collaboration and competition both involve symmetric behaviors between the partners and distinguish themselves principally by the helpful vs. harmful interaction, i.e., only by a sign change in the cost function. This may suggest how easy it is to switch between these two interactive behaviors, i.e., from ‘love to hate’ or conversely.</p>
          <fig id="pone-0049945-g004" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g004</object-id>
            <label>Figure 4</label>
            <caption>
              <title>Relations between distinct interaction behaviors.</title>
              <p>Such changes are mainly controlled by a higher control layer influencing the choice of the interactive strategy, before the interaction (according to some previous experience of the task completion and learning processes) or during the interaction (through the perception of signals that the central nervous system tries to recognize and interpret in order to predict future action.)</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g004" position="float" xlink:type="simple"/>
          </fig>
          <p>As already mentioned, assistance and education differ only in the energy preservation making the slave an educator, as in Beaumarchais' “Marriage of Figaro” <xref ref-type="bibr" rid="pone.0049945-Beaumarchais1">[47]</xref>, when a clever servant is in fact leading the action and helping the master to change his perspective, which eventually results in a new collaboration. Conversely, a collaboration degenerates into a cooperation when one agent focuses on itself and the other, either obeys in the assistance or accepts to look for the other's task in the education.</p>
          <p>Note that both collaboration and competition require from the agents the capacity to interpret their partner's behavior <xref ref-type="bibr" rid="pone.0049945-Ganesh1">[48]</xref>. Therefore, an autistic agent, which may not possess this capacity, would hardly be able to work in a symmetric collaboration or competition situation. In fact, the interaction of two autistic agents may correspond to co-activity. In a cooperation, an autistic agent could be the master or the student (thus is able to learn), while the complementary roles of slave and teacher would require the capability to interpret the partner's behavior.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>Classification of human-robot interactions</title>
        <p>We now want to examine how human-robot interactions can be classified and interpreted within our framework. Based on the analysis of last two sections, we first developed a logigram to facilitate the classification, which is shown in <xref ref-type="fig" rid="pone-0049945-g005">Fig. 5</xref>. Note that some questions could be asked in a different order, e.g., first those about the agonist/antagonist, and then those about the divisible/interactive alternatives. This scheme is used to classify various human-robot interaction behaviors found in the literature.</p>
        <fig id="pone-0049945-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Determination of motor interaction behavior.</title>
            <p>First the underlying task is determined (green squares). For interactive tasks then the exchanges between the agents determine the type of interaction behavior (blue boxes).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g005" position="float" xlink:type="simple"/>
        </fig>
        <sec id="s3a1">
          <title>Assistance (cooperation)</title>
          <p>The name “robot” stems from slave or serf <xref ref-type="bibr" rid="pone.0049945-Capek1">[49]</xref>, and in fact many projects have developed robotic slaves for assisting humans in performing tasks, e.g., to help lifting and carrying heavy or bulky objects. The most common example is provided by teleoperation systems <xref ref-type="bibr" rid="pone.0049945-Sheridan1">[50]</xref> as well as force extenders or exoskeletons to amplify the physical capabilities of humans <xref ref-type="bibr" rid="pone.0049945-Kazerooni1">[51]</xref>. A force amplifying exoskeleton tries to minimize the human master effort, while it is mechanically connected to the human body and is transferring power to it (in contrast to remote teleoperation). Recent years have seen the development of lower limb extenders, in particular for military applications <xref ref-type="bibr" rid="pone.0049945-Dollar1">[52]</xref>.</p>
          <p>Robots can be designed to assist human beings in specific tasks by providing assistive forces or trajectory corrections <xref ref-type="bibr" rid="pone.0049945-Khatib1">[53]</xref>, or by guiding movements within a restricted workspace <xref ref-type="bibr" rid="pone.0049945-Zeng1">[12]</xref>, <xref ref-type="bibr" rid="pone.0049945-Peshkin1">[54]</xref>. A robotic interface to guide the user's motion along desired directions while preventing motion in undesired directions or regions of the workspace <xref ref-type="bibr" rid="pone.0049945-Rosenberg1">[55]</xref> can be considered as a slave, because it provides appropriate support during action and cannot complete the main task alone. In robotics literature, such robotic aids are encountered as <italic>intelligent assistive devices</italic> (IAD) or simply <italic>robotic lifting assistants</italic>.</p>
          <p>Robots providing an assistance behavior also include the <italic>cobots</italic> or <italic>collaborative robots</italic> described in <xref ref-type="bibr" rid="pone.0049945-Colgate1">[56]</xref>. Despite their name, these robots do not collaborate in the sense of our taxonomy, but are in fact conceived to yield a master-slave behavior. As these cobots track human operator behavior and react accordingly (with for example, a load lifting assistant fitted with an assistance to motions in the plane, provided according to the angular movements of the loading cable <xref ref-type="bibr" rid="pone.0049945-Colgate2">[57]</xref>), they implement assistance behavior rather than co-activity.</p>
          <p>Various platforms, e.g., mobile robots with a robotic arm <xref ref-type="bibr" rid="pone.0049945-Kosuge1">[58]</xref>, which involve a controller to detect the intentions of the human user <xref ref-type="bibr" rid="pone.0049945-Maeda1">[59]</xref>, <xref ref-type="bibr" rid="pone.0049945-Wojtara1">[60]</xref> or the control of multiple slave robots <xref ref-type="bibr" rid="pone.0049945-Kosuge2">[61]</xref>, are other applications of the assistive scheme. Finally, robot teach pendants where the human teacher directly moves the robot that records the motion to reproduce, or imitation learning <xref ref-type="bibr" rid="pone.0049945-Pastor1">[62]</xref> where the robot is moved according to data of human movement recorded in some other way, also correspond to an assistance scheme, because the robot is passively following the human example.</p>
        </sec>
        <sec id="s3a2">
          <title>Education (cooperation)</title>
          <p>As mentioned in subsection “<italic>Taxonomy of interactive behaviors</italic>” of the <xref ref-type="sec" rid="s2">Methods</xref>, a typical example of the education type of interaction is the therapist-patient relationship in physical rehabilitation. For instance, during poststroke neurorehabilitation <xref ref-type="bibr" rid="pone.0049945-Balasubramanian1">[14]</xref>, a therapist will help the stroke survivor to move the arm or the hand adequately, but will decrease motion assistance while the recovery progresses. Haptic interfaces for sport training and rehabilitation robots aim at emulating this behavior. Even if the “passive mode” used in first stage, where the arm is moved by the robot, is similar to an assistance scheme, the “active mode” in which robot is only correcting patient movements “just-as-needed” is similar to an education scheme <xref ref-type="bibr" rid="pone.0049945-Hogan1">[41]</xref>, <xref ref-type="bibr" rid="pone.0049945-Kahn1">[42]</xref>, <xref ref-type="bibr" rid="pone.0049945-Lum1">[63]</xref>, <xref ref-type="bibr" rid="pone.0049945-Crocher1">[64]</xref>.</p>
          <p>In fact, a recent model of motor learning in humans provides a suitable tool to adapt assistance provided in rehabilitation robots and sport trainers. In this model <xref ref-type="bibr" rid="pone.0049945-Franklin1">[25]</xref>, <xref ref-type="bibr" rid="pone.0049945-Emken1">[65]</xref>, <xref ref-type="bibr" rid="pone.0049945-Burdet3">[66]</xref>, force, impedance and trajectory are adapted to minimize motion instability, error and effort. Error minimization ensures that the task will be performed successfully if the human user is not able to do so, but effort minimization makes the robot ‘lazy’ so that the human has to do as much as he or she can. Interestingly, the computational model, based on the gradient descent of a cost function similar to Equ.(1), yields an efficient adaptive controller <xref ref-type="bibr" rid="pone.0049945-Yang1">[28]</xref> (briefly described in the <italic>Learning</italic> section of the <xref ref-type="sec" rid="s3">Results</xref>) that can be implemented on rehabilitation and sport robots <xref ref-type="bibr" rid="pone.0049945-Emken2">[67]</xref>. Assuming that the patient focusses on his or her performance, he or she will, together with the robot trainer, perform according to the education behavior of Equ.(6).</p>
          <p>Educational interaction, where robot is active and corrected by the teacher through motor interaction can further be found in <xref ref-type="bibr" rid="pone.0049945-Calinon1">[68]</xref> where the user helps a humanoid robot reproducing a movement (previously recorded) to refine its gesture by kinaesthetic teaching, or in <xref ref-type="bibr" rid="pone.0049945-Calinon2">[69]</xref> where a robot learns how to perform a collaborative manipulation task through demonstration using a haptic interface. Similarly, Ikemoto <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0049945-Ikemoto1">[70]</xref> developed an algorithm dedicated to robot learning through physical interaction with humans.</p>
        </sec>
        <sec id="s3a3">
          <title>Co-activity</title>
          <p>There are many divisible tasks where robots or humans interact without needing to know what each other is doing, and incidentally interact and succeed in the common task. In fact, separating tasks in independent but complementary subtasks where each of the robot or the human performs well, is in many cases an efficient way to perform joint actions, as no negotiation thus sensory exchange is required, enabling safe and simple solutions without inference.</p>
          <p>For example, the Acrobot robot assistant for bone surgery <xref ref-type="bibr" rid="pone.0049945-Cobb1">[71]</xref>, which constrains surgeon's motion to a predefined region, facilitates surgery without knowledge of the surgical task. Such situations typically arise when the task is decomposed into subtasks carried out by independent controllers. Similarly, simple assistive devices developed to help manufacturing, e.g., to compensate gravity during tool or parts manipulation, use co-activity, as they just compensate load in the vertical direction using actuators or spring systems while leaving the movements on the plane unrestrained.</p>
          <p>Some robots that at first sight appear to rely on a competitive scheme, are actually only using a co-activity scheme, and lead to a fight between the partners because of the divisible and antagonistic nature's task. For example, the electroactive polymers (EAP) actuated arm robot <xref ref-type="bibr" rid="pone.0049945-Kamohara1">[72]</xref> that was able to win a wrestling match against a human opponent for the AMERAH challenge (Arm wrestling Match of EAP Robotic Arm Against Human) only tries to minimize its own error without considering human action.</p>
        </sec>
        <sec id="s3a4">
          <title>Collaboration</title>
          <p>A very limited number of projects have tried to implement interaction beyond simple cooperation, by introducing role switching and continuously adapting interaction, thus allowing robots to collaborate with humans. Collaboration examples include the experiments reported in <xref ref-type="bibr" rid="pone.0049945-Evrard1">[20]</xref>, during which robot behavior is continuously adapted to the human partner, and the study <xref ref-type="bibr" rid="pone.0049945-Oguz1">[21]</xref>, where role distribution is negotiated.</p>
          <p>Recent work has presented a method in which the robot's assistance level, and thus also its role, are continuously adapted according to an estimate of human's disagreement level <xref ref-type="bibr" rid="pone.0049945-Medina1">[73]</xref> or to the magnitude of the partner's contribution, together with a formal analysis of human-robot force cooperation <xref ref-type="bibr" rid="pone.0049945-Mrtl1">[74]</xref>. Another collaboration example consists of implementations of hand-shaking with a robot, because handshake is typically mutual (as illustrated by the fact that a weak and passive hand is felt as weird). A hand shaking robot system providing realistic experiences was developed using a hidden Markov model-based approach that allows the robot to estimate human intentions and adapt its behavior <xref ref-type="bibr" rid="pone.0049945-Wang1">[75]</xref>.</p>
        </sec>
        <sec id="s3a5">
          <title>Competition</title>
          <p>It is hard to find examples of motor competition between humans and robots in the literature. We believe that this is due to the taboo (as expressed by the first Asimov's laws of robotics) that “a robot may not injure a human being or, through inaction, allow a human being to come to harm” <xref ref-type="bibr" rid="pone.0049945-Asimov1">[76]</xref>. This has limited research on the development of controllers designed to physically beat humans, while robots are already superior to humans in chess playing <xref ref-type="bibr" rid="pone.0049945-Newborn1">[77]</xref> and obviously in memory.</p>
          <p>While some studies have been made about robot-robot competition, such as the football Robocup <xref ref-type="bibr" rid="pone.0049945-Kitano1">[78]</xref>, human-robot competitions are only planed, such as the football competition projected in 2050. Recent military projects aimed at designing robotic soldiers and mobile robotic platforms equipped with weapons <xref ref-type="bibr" rid="pone.0049945-Weiner1">[79]</xref> will probably soon exhibit some ability to use their firepower against opponents according to some competitive scheme, even if ethical debate still rages over it <xref ref-type="bibr" rid="pone.0049945-Arkin1">[80]</xref>,<xref ref-type="bibr" rid="pone.0049945-Sparrow1">[81]</xref>.</p>
        </sec>
      </sec>
      <sec id="s3b">
        <title>Simulation of simple motor interactions between two humans</title>
        <p>This section illustrates how our taxonomy can be used to implement interactive tasks using optimal control. It presents a simple simulation of two human agents rigidly fixed to a one degree of freedom pointmass that they have to move from one position to another, using various kinds of interactive behaviors described in subsection “<italic>Taxonomy of interactive behaviors</italic>” of the <xref ref-type="sec" rid="s5">Materials and Methods</xref>. In this interactive agonistic task the two subtasks correspond to the task itself.</p>
        <p>The interaction between two agents the dyad can be seen under a game theoretic framework. The type of interaction (game) depends on the cost of each agent and also on the coupling between them. In the case of cooperation or collaboration, when there is perfect knowledge of the state, then the problem can be transformed into an optimal control problem for each player <xref ref-type="bibr" rid="pone.0049945-Rotkowitz1">[82]</xref>, whereas in the case of antagonistic tasks, the problem can be considered as a utility-based non-cooperative game <xref ref-type="bibr" rid="pone.0049945-Basar1">[83]</xref>.</p>
        <p>Details about the dynamics of the modelled agents, the approach used to translate the cost functions defined in the Table of <xref ref-type="fig" rid="pone-0049945-g003">Fig. 3</xref> into a unified cost function for optimal control, as well as the couplings used in the simulations, are given in the <xref ref-type="sec" rid="s5">Materials and Methods</xref>. The obtained results are presented next. Figures where obtained through the simulation of dyad dynamic interaction on MATLAB (MathWorks®) with the linear-quadratic state-feedback regulator available in the Control System Toolbox.</p>
        <sec id="s3b1">
          <title>Cooperation (assistance) vs. collaboration</title>
          <p>To implement the assistance example, we consider that the metabolic cost is much larger for the master than for the slave, and that the cost of the error of the master is high for both master and slave (see <xref ref-type="sec" rid="s5">Materials and Methods</xref> for the numerical values used). On the other hand, collaboration is defined similarly to a symmetric cooperation but with a common will to reduce both errors and a similar metabolic cost for the two agents.</p>
          <p><xref ref-type="fig" rid="pone-0049945-g006">Fig. 6</xref> compares the object's movement and the force profiles for the cooperation vs. collaboration. Due to the smaller weight of metabolic cost, the slave (in dashed blue) provides most of the required amount of forces, e.g., the ratio of integrated square force is 2.7 between slave and master. Increasing the difference between both agent metabolic costs will accentuate the asymmetry in the relation, but will also tend to increase the movement duration.</p>
          <fig id="pone-0049945-g006" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g006</object-id>
            <label>Figure 6</label>
            <caption>
              <title>Cooperation (assistance) vs. collaboration.</title>
              <p><italic>Left</italic>: the object trajectory is shown (plain line shows object displacement during a collaboration whereas dotted lines during cooperation scenario). The object is initially placed at position 2 meter away from the target that should be reached (position 0). <italic>Right</italic>: the forces applied by each agent on the object to make it reach the target position are shown on the right (plain lines shows force profiles applied by the each partner during the collaboration whereas dotted lines shows the force profiles applied by the master and the slave during an assistance scenario). Similar overall amount of force is needed in both cases, but the symmetric collaboration enables to reach the target faster.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g006" position="float" xlink:type="simple"/>
          </fig>
          <p>In the collaboration case (solid lines in <xref ref-type="fig" rid="pone-0049945-g006">Fig. 6</xref>) the two partners' effort (i.e., the sum of the two integral of the square forces) are similar, leading to a reduction of the individual effort (i.e., integrated square force) and to a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e050" xlink:type="simple"/></inline-formula> reduction of the time to reach <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e051" xlink:type="simple"/></inline-formula> of the movement distance, relatively to the cooperation.</p>
        </sec>
        <sec id="s3b2">
          <title>Education</title>
          <p>The teacher attempts to concurrently minimize his effort and reduce what he perceives from student's error. Two cases were simulated: one where the student is interested in the completion of the task (higher cost of error for the student) and one where the student is lazy, thus not really interested in error minimization (low cost of error for the student) and saves his effort through a higher weight of metabolic cost (see <xref ref-type="sec" rid="s5">Materials and Methods</xref> for the numerical values used).</p>
          <p><xref ref-type="fig" rid="pone-0049945-g007">Fig. 7</xref> compares the performance obtained with the hard working student (solid lines) and with the lazy student (dashed lines). With the hard working student the teacher needs to spend only 0.75 of the student effort (measured by the integral of squared force), while with the lazy student he spends 3.59 times as much effort as the student. The movement is also 1.11 faster with the hardworking student, because the teacher refuses to behave as slave and forces the lazy student to participate.</p>
          <fig id="pone-0049945-g007" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g007</object-id>
            <label>Figure 7</label>
            <caption>
              <title>Cooperation: education scheme with hardworking or lazy student.</title>
              <p><italic>Left</italic>: trajectory of the object during the two scenarios. <italic>Right</italic>: profiles of force applied by each subject to complete the task during the two scenarios (plain lines for the scenario where the student is lazy and mainly relies on the teacher to perform the task, dotted lines for the scenario where student is hardworking). Teacher strategy (cost function) remains the same in the two scenarios. However, although the teacher tries to minimize his involvement in the task, when he is interacting with a lazy student he is forced to provide a significant effort to bring the object on target.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g007" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s3b3">
          <title>Divisible antagonistic task</title>
          <p>In this case, we simulated the <italic>co-activity</italic> scheme with a simple divisible task using a different target position for each agent, i.e., the subtasks are antagonistic. In order to get a clear solving of the simulation, we defined one agent to be stronger than the other through their metabolic costs (see <xref ref-type="sec" rid="s5">Materials and Methods</xref> for the numerical values used).</p>
          <p><xref ref-type="fig" rid="pone-0049945-g008">Fig. 8</xref> illustrates that co-activity, because of the nature of the task which is antagonistic, leads to important increase of the energetic expenditures : force levels increase (up to 7<italic>N</italic>) and non zero asymptotic forces appear (+/− 0.5<italic>N</italic>) even when one of the subject's target is reached (i.e., co-contraction), while the movement duration increases by more than 20% compared to the mean of reaching time obtained with the previous schemes.</p>
          <fig id="pone-0049945-g008" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0049945.g008</object-id>
            <label>Figure 8</label>
            <caption>
              <title>Co-activity during a divisible antagonistic task, with a subject stronger than the other.</title>
              <p><italic>Left</italic>: trajectory of the object during the competition (green), with in red stronger subject's target position and in blue the weaker subject's one. <italic>Right</italic>: force profile applied by each subject during the completion of the task. The stronger subject (red) is able to force the other (blue) to follow him, which leads to non-zero terminal “co-contraction” (level of applied force is non-null at the end of the task).</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0049945.g008" position="float" xlink:type="simple"/>
          </fig>
          <p>Although the behavior may appear as a competition, this is a co-active behavior. Due to the dominance of one subject the game did not end up to an optimal solution for the system or a Nash equilibrium (a state in which none of the two agents is willing to unilaterally change her action) as could be expected in a non-cooperative game.</p>
        </sec>
      </sec>
      <sec id="s3c">
        <title>Learning</title>
        <p>This section illustrates how the cost functions determining the behavior can lead to motor adaptation, and how the taxonomy can be used to determine the control of a sport training robot step-by-step.</p>
        <p>Considering that control is realized as the addition of feedforward (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e052" xlink:type="simple"/></inline-formula>) and feedback (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e053" xlink:type="simple"/></inline-formula>) motor commands:<disp-formula id="pone.0049945.e054"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e054" xlink:type="simple"/><label>(8)</label></disp-formula>we have recently derived a learning law to adapt the feedforward motor command (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e055" xlink:type="simple"/></inline-formula>) along a repeated movement <xref ref-type="bibr" rid="pone.0049945-Yang1">[28]</xref> or in arbitrary movements <xref ref-type="bibr" rid="pone.0049945-Kadiallah1">[84]</xref>, such as to minimize error and effort Equ.(1). For instance, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e056" xlink:type="simple"/></inline-formula> is a linear function of a parameter vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e057" xlink:type="simple"/></inline-formula>, i.e.<disp-formula id="pone.0049945.e058"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e058" xlink:type="simple"/><label>(9)</label></disp-formula>(where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e059" xlink:type="simple"/></inline-formula> is the position vector and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e060" xlink:type="simple"/></inline-formula> its derivative), then the gradient descent minimization of error and effort yields the learning law<disp-formula id="pone.0049945.e061"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e061" xlink:type="simple"/><label>(10)</label></disp-formula>which adapts the feedforward motor command as a function of error <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e062" xlink:type="simple"/></inline-formula>. This extended nonlinear adaptive controller can be used to adapt force and mechanical impedance as demonstrated in <xref ref-type="bibr" rid="pone.0049945-Yang1">[28]</xref>, <xref ref-type="bibr" rid="pone.0049945-Kadiallah1">[84]</xref>.</p>
        <p>Interestingly, all the cost functions in <xref ref-type="fig" rid="pone-0049945-g003">Fig. 3</xref> are formed of error and effort terms, so can be used to learn the own dynamic model or/and the dynamic model of the partner. For instance, if a robotic trainer is used by a human subject to learn a physical task, then the subject will likely modify his or her muscle activations according to Equ.(10) <xref ref-type="bibr" rid="pone.0049945-Franklin2">[85]</xref>, <xref ref-type="bibr" rid="pone.0049945-Tee1">[86]</xref>. If the training robot is controlled and adapted using the same laws, this will yield the education behavior in which the human will be assisted “only as needed”. Note that above cost function can be used with other learning techniques such as reinforcement learning <xref ref-type="bibr" rid="pone.0049945-Rigoux1">[87]</xref>.</p>
        <p>Finally, let us now describe step by step the design of control for a sport training robot, by answering the questions of <xref ref-type="fig" rid="pone-0049945-g005">Fig. 5</xref>. The control subtasks of the user and the robot are not independent, so this is an interactive task. The sport trainer should not harm the user, so this task is agonistic. As the robot has to help the user, so their behaviors will be different and this is thus a cooperation. Finally, we have explained above that the robot should be greedy so as to yield good training, thus we are in the behavior's education type. We can thus implement above adaptive controller on the robot in order to let it promote optimal training of the human user.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>This paper has introduced a generic framework to describe, analyze, generate and adapt motor interaction behaviors, consisting of a classification of the tasks through which subjects interact, and a taxonomy of motor interaction behaviors for two agents such as human-human, human-robot and robot-robot. In this framework, the partners' roles can be determined by answering a few simple questions as it was presented in <xref ref-type="fig" rid="pone-0049945-g005">Fig. 5</xref>. As the study of interaction of a human with the environment and between humans is complex, due to the redundancy brought by the two actors and the possible influence of conscious/high-level processes, and not much experimental material is yet available, we decided to develop this framework using an axiomatic top-down approach. However, some of the behaviors described, in particular the education behavior, are directly based on a successful computational model <xref ref-type="bibr" rid="pone.0049945-Franklin1">[25]</xref> that resulted in a novel interactive controller for robots <xref ref-type="bibr" rid="pone.0049945-Yang1">[28]</xref>. While there are multiple ways to represent motor interaction behaviors, our taxonomy enables us to characterize a wide range of interactive strategies in a simple and extendible approach. This was illustrated by classifying existing human-robot interaction behaviors, and by generating control of typical human-human motor interactions. The concrete application of our description for the design of robot's behaviors will have to address practical issues that are out of the scope of this paper, whose goal is to define the framework and taxonomy. In particular, as for other optimization frameworks, the mathematical solution may require care of the computational aspects.</p>
      <p>From a mathematical point of view, our framework embraces a utility-based Game Theoretic approach, using a set of cost functions to organize, understand and reproduce human motor behaviors of interactions with partners. Once the nature of the underlying task has been characterized, existence and uniqueness of a Nash equilibrium are established from Game Theory. As soon as the task has been formulated, the utility function of each player is chosen based on the assumption that the players will work towards the objective of the task, thus guaranteeing the rationality assumption of the participating players. Game Theory methods yield distributed decision making, allowing players to have different utility functions, and providing the tools to characterize the existence and uniqueness of a Nash equilibrium. It also provides tools to analyze and describe the performance of the system as a whole, though this could also be provided by alternative methods such as Lyapunov stability, contraction mapping or passivity theory. Furthermore, an analysis of the flow exchanges between subjects (using for example a Bond graph representation of the system <xref ref-type="bibr" rid="pone.0049945-Paynter1">[88]</xref>) could be used to identify the roles of each partner and thus, the nature of the interaction.</p>
      <p>For simplicity, our framework omitted noise in the perception of own and partner's error or energy expenditure, though these may be key factors to explain switchings between multiple strategies <xref ref-type="bibr" rid="pone.0049945-Paynter1">[88]</xref> that can occur during a task completion. Similarly, we did not consider how the history of interaction may influence a current interaction behavior <xref ref-type="bibr" rid="pone.0049945-Ganesh2">[89]</xref> and subject's prediction capability.</p>
      <p>The taxonomy of this paper and its simple approach based on cost functions to describe interacting agents could also be used in different fields, other than motor interaction between a human and a robot. In neuroscience and medicine for instance, it could help interpreting pathological interactive motor behaviors (e.g., autistic behavior) through simulations of altered perception of the partners' action or one own action. Replacing “motor error” by the “market share to gain” and “energy expenditure” by “investments” could bring a clear formalism of company strategies and policies <xref ref-type="bibr" rid="pone.0049945-Polenske1">[90]</xref>. While these fields have used Game Theory, our taxonomy provides a fine characterization of the different roles which is not explicitly contained in general Game Theory. Finally, the simplicity of the adopted mathematical framework makes it suitable for use in philosophy and experimental psychology, offering computational tools for experiments, simulations and validations in the field of theory of action.</p>
    </sec>
    <sec id="s5" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s5a">
        <title>Simulation model</title>
        <p>To illustrate how the cost functions of <xref ref-type="fig" rid="pone-0049945-g003">Fig. 3</xref> can generate interactive behaviors, we simulate two human agents <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e063" xlink:type="simple"/></inline-formula> moving a pointmass <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e064" xlink:type="simple"/></inline-formula> along a single axis according to the applied forces <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e065" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e066" xlink:type="simple"/></inline-formula>. Interaction between the agents is realized through the application of forces on the rigid object.</p>
        <sec id="s5a1">
          <title>Arm dynamics of one agent</title>
          <p>A simple model of the arm dynamics can be developed by assuming that the pointmass <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e067" xlink:type="simple"/></inline-formula> is moved along the axis by the combined action of all muscles of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e068" xlink:type="simple"/></inline-formula> represented by the force <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e069" xlink:type="simple"/></inline-formula>, thus:<disp-formula id="pone.0049945.e070"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e070" xlink:type="simple"/><label>(11)</label></disp-formula><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e071" xlink:type="simple"/></inline-formula> is computed from the control signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e072" xlink:type="simple"/></inline-formula> using the model of <xref ref-type="bibr" rid="pone.0049945-Winter1">[91]</xref>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e073" xlink:type="simple"/></inline-formula> is the time. This muscle model is a second-order linear filter, that can be written as two first-order filters by using an auxiliary variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e074" xlink:type="simple"/></inline-formula><disp-formula id="pone.0049945.e075"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e075" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e076" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e077" xlink:type="simple"/></inline-formula> are the time constants for agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e078" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e079" xlink:type="simple"/></inline-formula> be the ‘hand’ position of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e080" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e081" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e082" xlink:type="simple"/></inline-formula> the corresponding velocity, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e083" xlink:type="simple"/></inline-formula> the ‘arm’ mass. Using the discrete-time transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e084" xlink:type="simple"/></inline-formula><disp-formula id="pone.0049945.e085"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e085" xlink:type="simple"/></disp-formula>the dynamics of one agent moving the mass <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e086" xlink:type="simple"/></inline-formula> are:<disp-formula id="pone.0049945.e087"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e087" xlink:type="simple"/><label>(13)</label></disp-formula>Defining the error to the target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e088" xlink:type="simple"/></inline-formula> as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e089" xlink:type="simple"/></inline-formula>, the dynamic equation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e090" xlink:type="simple"/></inline-formula> becomes:<disp-formula id="pone.0049945.e091"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e091" xlink:type="simple"/><label>(14)</label></disp-formula>Representing the current state of the discrete-time system for each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e092" xlink:type="simple"/></inline-formula> manipulating the same object as<disp-formula id="pone.0049945.e093"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e093" xlink:type="simple"/><label>(15)</label></disp-formula>(because in our simulations the different subjects are applying forces on one single rigid object and thus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e094" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e095" xlink:type="simple"/></inline-formula>), the state of each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e096" xlink:type="simple"/></inline-formula> yields<disp-formula id="pone.0049945.e097"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e097" xlink:type="simple"/><label>(16)</label></disp-formula>with<disp-formula id="pone.0049945.e098"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e098" xlink:type="simple"/></disp-formula>The <italic>linear</italic> optimal gains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e099" xlink:type="simple"/></inline-formula> can be found via a Linear-Quadratic regulator (LQR), thus the input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e100" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pone.0049945.e101"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e101" xlink:type="simple"/><label>(17)</label></disp-formula>For a linear system with white Gaussian noise optimal gains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e102" xlink:type="simple"/></inline-formula> could be computed using Linear-Quadratic-Gaussian (LQG) control (though this is considered out of the scope of this paper). The cost function for each agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e103" xlink:type="simple"/></inline-formula> consists of the quadratic function<disp-formula id="pone.0049945.e104"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e104" xlink:type="simple"/><label>(18)</label></disp-formula>where<disp-formula id="pone.0049945.e105"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e105" xlink:type="simple"/></disp-formula>The optimal gain at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e106" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pone.0049945.e107"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e107" xlink:type="simple"/><label>(19)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e108" xlink:type="simple"/></inline-formula> is the solution to the associated discrete-time Riccati equation:<disp-formula id="pone.0049945.e109"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e109" xlink:type="simple"/><label>(20)</label></disp-formula>provided <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e110" xlink:type="simple"/></inline-formula> is controllable, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e111" xlink:type="simple"/></inline-formula> is positive definite and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e112" xlink:type="simple"/></inline-formula> is semi-positive definite.</p>
        </sec>
        <sec id="s5a2">
          <title>Dyad's dynamics</title>
          <p>The state-space equation of both agent yields<disp-formula id="pone.0049945.e113"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e113" xlink:type="simple"/></disp-formula><disp-formula id="pone.0049945.e114"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e114" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e115" xlink:type="simple"/></inline-formula> is the state vector of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e116" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e117" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e118" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e119" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e120" xlink:type="simple"/></inline-formula> are defined below. Hence<disp-formula id="pone.0049945.e121"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e121" xlink:type="simple"/><label>(21)</label></disp-formula>with<disp-formula id="pone.0049945.e122"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e122" xlink:type="simple"/></disp-formula>This representation allows treatment of a general class of problems with different initial positions, errors, velocities, etc. For interaction through a rigid body<disp-formula id="pone.0049945.e123"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e123" xlink:type="simple"/><label>(22)</label></disp-formula>In A we can identify<disp-formula id="pone.0049945.e124"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e124" xlink:type="simple"/></disp-formula><disp-formula id="pone.0049945.e125"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e125" xlink:type="simple"/></disp-formula>such that the interaction is realized through the non-zero component in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e126" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e127" xlink:type="simple"/></inline-formula>. The cost function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e128" xlink:type="simple"/></inline-formula> for each agent is again given by<disp-formula id="pone.0049945.e129"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e129" xlink:type="simple"/><label>(23)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e130" xlink:type="simple"/></inline-formula> describes the kind of interaction and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e131" xlink:type="simple"/></inline-formula> the strategy.</p>
          <p>As aforementioned, since the task involves the interaction between two agents, a utility-based game theoretic framework could be employed in order to analyze the behavior of the agents as a dyad, and also the performance of each agent. However, in a joint cooperative or collaborative task the optimal strategy for the two agents can be determined using optimal control on the joint cost for the task's implementation.</p>
        </sec>
        <sec id="s5a3">
          <title>Simulation parameters</title>
          <p>The simulations shown in the <xref ref-type="sec" rid="s3">Results</xref> use a mass of 1 <italic>kg</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e132" xlink:type="simple"/></inline-formula><italic>s</italic> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e133" xlink:type="simple"/></inline-formula>. The components in the diagonal of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e134" xlink:type="simple"/></inline-formula> matrix were: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e135" xlink:type="simple"/></inline-formula>. Let the cost function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e136" xlink:type="simple"/></inline-formula> of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e137" xlink:type="simple"/></inline-formula> be defined as the diagonal matrix:<disp-formula id="pone.0049945.e138"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0049945.e138" xlink:type="simple"/><label>(24)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e139" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e140" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e141" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e142" xlink:type="simple"/></inline-formula>.</p>
          <p>Tuning the values of the elements of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e143" xlink:type="simple"/></inline-formula> allows to directly modify the values of the gains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e144" xlink:type="simple"/></inline-formula> used in all the cost functions of the framework to define the different interactive kinds: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e145" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e146" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e147" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e148" xlink:type="simple"/></inline-formula>. Thus, simulating the different interaction cases is performed by tuning the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e149" xlink:type="simple"/></inline-formula>.</p>
          <p>For example, to simulate the assistance behavior, the slave motion is defined by the cost function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e150" xlink:type="simple"/></inline-formula> and the master behavior by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e151" xlink:type="simple"/></inline-formula>. The slave, only interested in minimizing the master error and energy will thus have very small cost values for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e152" xlink:type="simple"/></inline-formula> (the cost of his own trajectory and velocity error) and (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e153" xlink:type="simple"/></inline-formula> (the cost of his own force) and high cost values for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e154" xlink:type="simple"/></inline-formula> (the cost of his own trajectory and velocity error) and (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e155" xlink:type="simple"/></inline-formula>. The master will only care for his own trajectory and energy and thus will have a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e156" xlink:type="simple"/></inline-formula> matrix characterized by null values for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e157" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e158" xlink:type="simple"/></inline-formula>.</p>
          <p>The simulation of the divisible antagonistic task shown in the <xref ref-type="sec" rid="s3">Results</xref> uses the same mathematical framework previously defined. However the simulation model is adapted to allow the use of two different errors, by adding an offset on one of the position feedback through <xref ref-type="disp-formula" rid="pone.0049945.e121">Equ. 21</xref>.</p>
          <p>Then, for each case:</p>
          <list list-type="bullet">
            <list-item>
              <p>Assistance:</p>
              <list list-type="simple">
                <list-item>
                  <p><italic>slave:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e159" xlink:type="simple"/></inline-formula></p>
                </list-item>
                <list-item>
                  <p><italic>master:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e160" xlink:type="simple"/></inline-formula></p>
                </list-item>
              </list>
            </list-item>
            <list-item>
              <p>Collaboration:</p>
              <list list-type="simple">
                <list-item>
                  <p><italic>partner 1:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e161" xlink:type="simple"/></inline-formula></p>
                </list-item>
                <list-item>
                  <p><italic>partner 2:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e162" xlink:type="simple"/></inline-formula></p>
                </list-item>
              </list>
            </list-item>
            <list-item>
              <p>Education:</p>
              <list list-type="simple">
                <list-item>
                  <p><italic>teacher:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e163" xlink:type="simple"/></inline-formula></p>
                </list-item>
                <list-item>
                  <p><italic>lazy student:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e164" xlink:type="simple"/></inline-formula></p>
                </list-item>
                <list-item>
                  <p><italic>hardworking student:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e165" xlink:type="simple"/></inline-formula></p>
                </list-item>
              </list>
            </list-item>
            <list-item>
              <p>Co-activity (divisible antagonistic task):</p>
              <list list-type="simple">
                <list-item>
                  <p><italic>subject:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e166" xlink:type="simple"/></inline-formula></p>
                </list-item>
                <list-item>
                  <p><italic>stronger subject:</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0049945.e167" xlink:type="simple"/></inline-formula></p>
                </list-item>
              </list>
            </list-item>
          </list>
          <p>Figures shown in <xref ref-type="sec" rid="s3">Results</xref> were generated by simulating the detailed dyad's dynamic on MATLAB (MathWorks®), through the use of the linear-quadratic (LQ) state-feedback regulator for discrete-time state-space system.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors would like to thank Alejandro Melendez-Calderon, Ganesh Gowrishankar and the partners of the HUMOUR project for fruitful discussions.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0049945-Sebanz1">
        <label>1</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sebanz N (2007) Understanding Human Ability For Joint Action.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Allport1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allport</surname><given-names>F</given-names></name> (<year>1920</year>) <article-title>Social psychology</article-title>. <source>Psychological Bulletin</source> <volume>17</volume>: <fpage>85</fpage>–<lpage>94</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Clark1">
        <label>3</label>
        <mixed-citation publication-type="other" xlink:type="simple">Clark H (1996) Using language, volume 23. Cambridge University Press, 452 pp.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Marey1">
        <label>4</label>
        <mixed-citation publication-type="other" xlink:type="simple">Marey E (1894) Le mouvement. G. Masson.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Woodworth1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woodworth</surname><given-names>R</given-names></name> (<year>1899</year>) <article-title>The accuracy of voluntary movement</article-title>. <source>Psychological Review</source> <volume>3</volume>: <fpage>11</fpage>–<lpage>19</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-MussaIvaldi1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mussa-Ivaldi</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hogan</surname><given-names>N</given-names></name> (<year>1985</year>) <article-title>Neural, mechanical, and geometric factors subserving arm posture in humans</article-title>. <source>Journal of Neuroscience</source> <volume>51</volume>: <fpage>2732</fpage>–<lpage>2743</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Shadmehr1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Mussa-Ivaldi</surname><given-names>F</given-names></name> (<year>1994</year>) <article-title>Adaptive representation of dynamics during learning of a motor task</article-title>. <source>Journal of Neuroscience</source> <volume>14</volume>: <fpage>3208</fpage>–<lpage>3224</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Burdet1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Osu</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Franklin</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Milner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>The central nervous system stabilizes unstable dynamics by learning optimal impedance</article-title>. <source>Nature</source> <volume>414</volume>: <fpage>446</fpage>–<lpage>449</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Reed1">
        <label>9</label>
        <mixed-citation publication-type="other" xlink:type="simple">Reed K, Peshkin M, Hartmann M, Patton J, Vishton P, <etal>et al</etal>.. (2006) Haptic cooperation between people, and between people and machines. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems. pp. 2109–2114.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Braun1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Braun</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Ortega</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wolpert</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>Nash equilibria in multi-agent motor interactions</article-title>. <source>PLoS Computational Biology</source> <volume>5</volume>: <fpage>e1000468</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Akella1">
        <label>11</label>
        <mixed-citation publication-type="other" xlink:type="simple">Akella P, Peshkin M, Colgate E, Wannasuphoprasit W, Nagesh N, <etal>et al</etal>.. (1999) Cobots for the automobile assembly line. In: Proceedings of the IEEE International Conference on Robotics &amp; Automation. volume 1, pp. 728–733.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Zeng1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeng</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Teo</surname><given-names>C</given-names></name> (<year>2009</year>) <article-title>Evaluation of a collaborative wheelchair system in cerebral palsy and traumatic brain injury users</article-title>. <source>Neurorehabilitation and Neural Repair</source> <volume>23</volume>: <fpage>494</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Nudehi1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nudehi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mukherjee</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Ghodoussi</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>A shared-control approach to haptic interface design for minimally invasive telesurgical training</article-title>. <source>IEEE Transactions on Control Systems Technology</source> <volume>13</volume>: <fpage>588</fpage>–<lpage>592</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Balasubramanian1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balasubramanian</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Klein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Robot-assisted rehabilitation of hand function</article-title>. <source>Current Opinion in Neurology</source> <volume>23</volume>: <fpage>661</fpage>–<lpage>70</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Jarrass1">
        <label>15</label>
        <mixed-citation publication-type="other" xlink:type="simple">Jarrassé N, Sanguineti V, Burdet E (2012) Robots will no longer be slaves Submitted.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Yanco1">
        <label>16</label>
        <mixed-citation publication-type="other" xlink:type="simple">Yanco H, Drury J (2002) A taxonomy for human-robot interaction. In: Proceedings of the AAAI Fall Symposium on Human-Robot Interaction. pp. 111–119.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Burghart1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burghart</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Yigit</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kerpa</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Osswald</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Woern</surname><given-names>H</given-names></name> (<year>2002</year>) <article-title>Concept for human robot co-operation integrating artificial haptic perception</article-title>. <source>Intelligent Autonomous Systems</source> <fpage>38</fpage>–<lpage>45</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Reed2">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reed</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Peshkin</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Physical collaboration of human-human and human-robot teams</article-title>. <source>IEEE Transactions on Haptics</source> <volume>1</volume>: <fpage>108</fpage>–<lpage>120</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Stefanov1">
        <label>19</label>
        <mixed-citation publication-type="other" xlink:type="simple">Stefanov N, Peer A, Buss M (2010) Online intention recognition for computer-assisted teleoperation. In: Proceedings of the IEEE International Conference on Robotics and Automation. pp. 233–239.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Evrard1">
        <label>20</label>
        <mixed-citation publication-type="other" xlink:type="simple">Evrard P, Kheddar A (2009) Homotopy switching model for dyad haptic interaction in physical collaborative tasks. In: Proceedings of the IEEE EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. pp. 45–50.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Oguz1">
        <label>21</label>
        <mixed-citation publication-type="other" xlink:type="simple">Oguz S, Kucukyilmaz A, Sezgin T, Basdogan C (2010) Haptic negotiation and role exchange for collaboration in virtual environments. In: Proceedings of the IEEE Haptics Symposium. pp. 371–378.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Stefanov2">
        <label>22</label>
        <mixed-citation publication-type="other" xlink:type="simple">Stefanov N, Peer A, Buss M (2009) Role determination in human-human interaction. In: Proceedings of the Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. pp. 51–56.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Sebanz2">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sebanz</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Bekkering</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Knoblich</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Joint action: bodies and minds moving together</article-title>. <source>Trends in Cognitive Sciences</source> <volume>10</volume>: <fpage>70</fpage>–<lpage>76</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Chartrand1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chartrand</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Bargh</surname><given-names>J</given-names></name> (<year>1999</year>) <article-title>The chameleon effect: The perception-behavior link and social interaction</article-title>. <source>Journal of Personality and Social Psychology</source> <volume>76</volume>: <fpage>893</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Franklin1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franklin</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Tee</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Osu</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Chew</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>CNS learns stable, accurate, and efficient movements using a simple algorithm</article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>: <fpage>11165</fpage>–<lpage>73</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Todorov1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todorov</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Jordan</surname><given-names>M</given-names></name> (<year>2002</year>) <article-title>Optimal feedback control as a theory of motor coordination</article-title>. <source>Nature Neuroscience</source> <volume>5</volume>: <fpage>30</fpage>–<lpage>34</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Burdet2">
        <label>27</label>
        <mixed-citation publication-type="other" xlink:type="simple">Burdet E, Ganesh G, Albu-Schaeffer A, Yang C (2010) Interaction force, impedance and trajectory adaptation: by humans, for robots. In: Proceedings of the International Symposium on Experimental Robotics.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Yang1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Ganesh</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Haddadin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Parusel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Albu-Schaeffer</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Human-like Adaptation of Force and Impedance in Stable and Unstable Interactions</article-title>. <source>IEEE Transaction on Robotics</source> <volume>27</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-OSullivan1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Sullivan</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Diedrichsen</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Dissociating variability and effort as determinants of coordination</article-title>. <source>Plos Computational Biology</source> <volume>5</volume>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Neumann1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neumann</surname><given-names>J</given-names></name> (<year>1928</year>) <article-title>Zur Theorie der Gesellschaftsspiele</article-title>. <source>Mathematische Annalen</source> <volume>100</volume>: <fpage>295</fpage>–<lpage>320</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Nash1">
        <label>31</label>
        <mixed-citation publication-type="other" xlink:type="simple">Nash J (1950) Equilibrium Points in N-Person Games. In: Proceedings of the National Academy of Sciences of the United States of America. volume 36, pp. 48–49.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Nash2">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nash</surname><given-names>J</given-names></name> (<year>1951</year>) <article-title>Non-Cooperative Games</article-title>. <source>The Annals of Mathematics</source> <volume>54</volume>: <fpage>286</fpage>–<lpage>295</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Vesper1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vesper</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Butterfill</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Knoblich</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sebanz</surname><given-names>N</given-names></name> (<year>2010</year>) <article-title>A minimal architecture for joint action</article-title>. <source>Neural Networks</source> <volume>23</volume>: <fpage>998</fpage>–<lpage>1003</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Bratman1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bratman</surname><given-names>M</given-names></name> (<year>1992</year>) <article-title>Shared cooperative activity</article-title>. <source>Philosophical Review</source> <volume>101</volume>: <fpage>327</fpage>–<lpage>341</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Raibert1">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raibert</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Craig</surname><given-names>J</given-names></name> (<year>1981</year>) <article-title>Hybrid Position/Force Control of Manipulators</article-title>. <source>Journal of Dynamic Systems, Measurement, and Control</source> <volume>103</volume>: <fpage>126</fpage>–<lpage>133</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Crawford1">
        <label>36</label>
        <mixed-citation publication-type="other" xlink:type="simple">Crawford M (1937) The Cooperative Solving of Problems by Young Chimpanzees. Johns Hopkins Press.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Drea1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Drea</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Carter</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Cooperative problem solving in a social carnivore</article-title>. <source>Animal Behaviour</source> <volume>78</volume>: <fpage>967</fpage>–<lpage>977</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Plotnik1">
        <label>38</label>
        <mixed-citation publication-type="other" xlink:type="simple">Plotnik J, Lair R, Suphachoksahakun W, de Waal F (2011) Elephants know when they need a helping trunk in a cooperative task. In: Proceedings of the National Academy of Sciences. volume 108, pp. 5116–5121.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Dillenbourg1">
        <label>39</label>
        <mixed-citation publication-type="other" xlink:type="simple">Dillenbourg P, Baker M, Blaye A (1996) The evolution of research on collaborative learning. In: Learning in Humans and Machines, London: Pergamon. pp. 189–211.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Roschelle1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roschelle</surname><given-names>J</given-names></name> (<year>1994</year>) <article-title>The construction of shared knowledge in collaborative problem solving</article-title>. <source>NATO ASI Series F Computer</source> <fpage>69</fpage>–<lpage>97</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Hogan1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hogan</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Krebs</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Rohrer</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Palazzolo</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dipietro</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Motions or muscles? Some behavioral factors underlying robotic assistance of motor recovery</article-title>. <source>Journal of Rehabilitation Research and Development</source> <volume>43</volume>: <fpage>605</fpage>–<lpage>618</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kahn1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kahn</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Lum</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Rymer</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Reinkensmeyer</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Robot-assisted movement training for the stroke-impaired arm: Does it matter what the robot does?</article-title> <source>Journal of Rehabilitation Research and Development</source> <volume>43</volume>: <fpage>619</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Gillespie1">
        <label>43</label>
        <mixed-citation publication-type="other" xlink:type="simple">Gillespie R, O'Modhrain M, Tang P, Zaretzky D, Pham C (1998) The virtual teacher. In: Proceedings of the ASME Dynamic Systems and Control Division. volume 64, pp. 171–178.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Trivers1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trivers</surname><given-names>R</given-names></name> (<year>1971</year>) <article-title>The evolution of reciprocal altruism</article-title>. <source>Quarterly Review of Biology</source> <volume>46</volume>: <fpage>35</fpage>–<lpage>57</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Axelrod1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Axelrod</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hamilton</surname><given-names>W</given-names></name> (<year>1981</year>) <article-title>The evolution of cooperation</article-title>. <source>Science</source> <volume>211</volume>: <fpage>1390</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-MelendezCalderon1">
        <label>46</label>
        <mixed-citation publication-type="other" xlink:type="simple">Melendez-Calderon A (2011) Investigating sensory-motor interactions to shape rehabilitation. Ph.D. thesis, Imperial College of Science, Technology and Medicine, UK.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Beaumarchais1">
        <label>47</label>
        <mixed-citation publication-type="other" xlink:type="simple">Beaumarchais P (1778) Le Mariage de Figaro.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Ganesh1">
        <label>48</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ganesh G, Osu R, Yoshioka T, Kawato M, Burdet M (2012) Practice together makes perfect: physical interaction with a partner improves individual motor performance Submitted.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Capek1">
        <label>49</label>
        <mixed-citation publication-type="other" xlink:type="simple">Capek K (1920) RUR - Rossum's Universal Robots : Rossumovi univerzln roboti. Aventinum.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Sheridan1">
        <label>50</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sheridan T (1992) Telerobotics, automation, and human supervisory control. MIT press.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kazerooni1">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kazerooni</surname><given-names>H</given-names></name> (<year>1990</year>) <article-title>Human-robot interaction via the transfer of power and information signals</article-title>. <source>IEEE Transactions on Systems, Man and Cybernetics</source> <volume>20</volume>: <fpage>450</fpage>–<lpage>463</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Dollar1">
        <label>52</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dollar</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Herr</surname><given-names>H</given-names></name> (<year>2008</year>) <article-title>Lower Extremity Exoskeletons and Active Orthoses: Challenges and State-of-the-Art</article-title>. <source>IEEE Transactions on Robotics</source> <volume>24</volume>: <fpage>144</fpage>–<lpage>158</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Khatib1">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Khatib</surname><given-names>O</given-names></name> (<year>1999</year>) <article-title>Autonomous Systems Mobile manipulation: The robotic assistant</article-title>. <source>Robotics and Autonomous Systems</source> <volume>26</volume>: <fpage>175</fpage>–<lpage>183</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Peshkin1">
        <label>54</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peshkin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Colgate</surname><given-names>J</given-names></name> (<year>2001</year>) <article-title>Cobot architecture</article-title>. <source>IEEE Transactions on Robotics and Automation</source> <volume>17</volume>: <fpage>377</fpage>–<lpage>390</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Rosenberg1">
        <label>55</label>
        <mixed-citation publication-type="other" xlink:type="simple">Rosenberg L (1993) Virtual fixtures: Perceptual tools for telerobotic manipulation. In: Proceedings of the Virtual Reality Annual International Symposium. pp. 76–82.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Colgate1">
        <label>56</label>
        <mixed-citation publication-type="other" xlink:type="simple">Colgate J, Edward J, Peshkin M (1996) Cobots: Robots for collaboration with human operators. In: Proceedings of the International Mechnical Engineering Congress and Exhibition. volume 58, pp. 433–39.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Colgate2">
        <label>57</label>
        <mixed-citation publication-type="other" xlink:type="simple">Colgate J, Peshkin M, Klostermeyer S (2003) Intelligent assist devices in industrial applications: a review. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). pp. 2516–2521.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kosuge1">
        <label>58</label>
        <mixed-citation publication-type="other" xlink:type="simple">Kosuge K, Hirata Y (2004) Human-Robot Interaction. In: Proceedings of the IEEE International Conference on Robotics and Biomimetics. pp. 8–11.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Maeda1">
        <label>59</label>
        <mixed-citation publication-type="other" xlink:type="simple">Maeda Y, Hara T, Arai T (2001) Human-robot cooperative manipulation with motion estimation. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems. volume 4, pp. 2240–2245.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Wojtara1">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wojtara</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Uchihara</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Murayama</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Shimoda</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sakai</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Human-robot collaboration in precise positioning of a three-dimensional object</article-title>. <source>Automatica</source> <volume>45</volume>: <fpage>333</fpage>–<lpage>342</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kosuge2">
        <label>61</label>
        <mixed-citation publication-type="other" xlink:type="simple">Kosuge K, Yoshida H, Taguchi D, Fukuda T, Hariki K, <etal>et al</etal>.. (1994) Robot-human collaboration for new robotic applications. In: Proceedings of the IEEE Conference of Industrial Electronics. pp. 713–718.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Pastor1">
        <label>62</label>
        <mixed-citation publication-type="other" xlink:type="simple">Pastor P, Kalakrishnan M, Chitta S, Theodorou E (2011) Skill Learning and Task Outcome Prediction for Manipulation. In: Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). pp. 3828–3834.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Lum1">
        <label>63</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lum</surname><given-names>P</given-names></name> (<year>2002</year>) <article-title>Robot-assisted movement training compared with conventional therapy techniques for the rehabilitation of upper-limb motor function after stroke</article-title>. <source>Archives of Physical Medicine and Rehabilitation</source> <volume>83</volume>: <fpage>952</fpage>–<lpage>959</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Crocher1">
        <label>64</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crocher</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Sahbani</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Robertson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Roby-Brami</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Morel</surname><given-names>G</given-names></name> (<year>2012</year>) <article-title>Constraining upper-limb synergies of hemiparetic patients using a robotic exoskeleton in the perspective of neuro-rehabilitation</article-title>. <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source> <volume>20</volume>: <fpage>247</fpage>–<lpage>257</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Emken1">
        <label>65</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Emken</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Benitez</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sideris</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bobrow</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Reinkensmeyer</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Motor Adaptation as a Greedy Optimization of Error and Effort</article-title>. <source>Journal of Neurophysiology</source></mixed-citation>
      </ref>
      <ref id="pone.0049945-Burdet3">
        <label>66</label>
        <mixed-citation publication-type="other" xlink:type="simple">Burdet E, Ganesh G, Yang C, Albu-Schaeffer A (2010) Learning Interaction Force, Impedance and Trajectory: by Humans, for Robots. In: Proceedings of the International Symposium on Experimental Robotics.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Emken2">
        <label>67</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Emken</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Benitez</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Reinkensmeyer</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Human-robot cooperative movement training: learning a novel sensory motor transformation during walking with robotic assistance-as-needed</article-title>. <source>Journal of Neuroengineering and Rehabilitation</source> <fpage>4</fpage>–<lpage>8</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Calinon1">
        <label>68</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calinon</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Billard</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Incremental learning of gestures by imitation in a humanoid robot</article-title>. <source>Proceeding of the ACM/IEEE international Conference on Human-Robot Interaction</source> <fpage>255</fpage>–<lpage>263</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Calinon2">
        <label>69</label>
        <mixed-citation publication-type="other" xlink:type="simple">Calinon S, Evrard P, Gribovskaya E, Billard A, Kheddar A (2009) Learning collaborative manipulation tasks by demonstration using a haptic interface. In: International Conference on Advanced Robotics, 2009. ICAR 2009. pp. 1–6.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Ikemoto1">
        <label>70</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ikemoto S, Amor B, Minato T, Ishiguro H, Jung B (2009) Physical interaction learning: Behavior adaptation in cooperative human-robot tasks involving physical contact. In: Proceedings of the International Symposium on Robot and Human Interactive Communication (ROMAN). pp. 504–509.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Cobb1">
        <label>71</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cobb</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Henckel</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Gomes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Harris</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Jakopec</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Hands-on robotic unicompartmental knee replacement: a prospective, randomised controlled study of the acrobot system</article-title>. <source>Journal of Bone and Joint Surgery-British Volume</source> <volume>88</volume>: <fpage>188</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kamohara1">
        <label>72</label>
        <mixed-citation publication-type="other" xlink:type="simple">Kamohara S, Takagi H, Takeda T (1997) Control rule acquisition for an arm wrestling robot. In: Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation. pp. 4227–4231.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Medina1">
        <label>73</label>
        <mixed-citation publication-type="other" xlink:type="simple">Medina J, Lee D, Hirche S (2012) Risk-sensitive optimal feedback control for haptic assistance. In: 2012 IEEE International Conference on Robotics and Automation (ICRA). pp. 1025–1031.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Mrtl1">
        <label>74</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mrtl</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lawitzky</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kucukyilmaz</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sezgin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Basdogan</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The role of roles: Physical cooperation between humans and robots</article-title>. <source>The International Journal of Robotics Research</source></mixed-citation>
      </ref>
      <ref id="pone.0049945-Wang1">
        <label>75</label>
        <mixed-citation publication-type="other" xlink:type="simple">Wang Z, Peer A, Buss M (2009) An HMM approach to realistic haptic human-robot interaction. In: Proceedings of the EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. pp. 374–379.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Asimov1">
        <label>76</label>
        <mixed-citation publication-type="other" xlink:type="simple">Asimov I (1950) Runaround. Doubleday &amp; Company.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Newborn1">
        <label>77</label>
        <mixed-citation publication-type="other" xlink:type="simple">Newborn M (1997) Kasparov Vs. Deep Blue: Computer Chess Comes of Age. Springer-Verlag.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kitano1">
        <label>78</label>
        <mixed-citation publication-type="other" xlink:type="simple">Kitano H, AsadaM, Kuniyoshi Y, Noda I, Osawa E (1997) Robocup: The robot world cup initiative. In: Proceedings of the International Conference on Autonomous Agents. pp. 340–347.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Weiner1">
        <label>79</label>
        <mixed-citation publication-type="other" xlink:type="simple">Weiner T (2005) A New Model Army Soldier Rolls Closer to the Battlefield. The New York Times, 16th of February.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Arkin1">
        <label>80</label>
        <mixed-citation publication-type="other" xlink:type="simple">Arkin R (2008) Governing lethal behavior: embedding ethics in a hybrid deliberative/reactive robot architecture. In: Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction. pp. 121–128.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Sparrow1">
        <label>81</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sparrow</surname><given-names>R</given-names></name> (<year>2007</year>) <article-title>Killer Robots</article-title>. <source>Journal of Applied Philosophy</source> <volume>24</volume>: <fpage>62</fpage>–<lpage>77</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Rotkowitz1">
        <label>82</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rotkowitz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lall</surname><given-names>S</given-names></name> (<year>2005</year>) <article-title>A characterization of convex problems in decentralized control</article-title>. <source>IEEE Transactions on Automatic Control</source> <volume>50</volume>: <fpage>1984</fpage>–<lpage>1996</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Basar1">
        <label>83</label>
        <mixed-citation publication-type="other" xlink:type="simple">Basar T, Olsder G (1998) Dynamic Noncooperative Game Theory. SIAM.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Kadiallah1">
        <label>84</label>
        <mixed-citation publication-type="other" xlink:type="simple">Kadiallah A, Liaw G, Kawato M, Franklin D, Burdet E (2012) Impedance control is selectively tuned to multiple directions of movement. In: Journal of Neurophysiology. pp. 2737–2748.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Franklin2">
        <label>85</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franklin</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Tee</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Osu</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Chew</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>CNS learns stable, accurate, and efficient movements using a simple algorithm</article-title>. <source>The Journal of Neuroscience</source> <volume>28</volume>: <fpage>11165</fpage>–<lpage>73</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Tee1">
        <label>86</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tee</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Franklin</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Milner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Concurrent adaptation of force and impedance in the redundant muscle system</article-title>. <source>Biological Cybernetics</source> <volume>102</volume>: <fpage>31</fpage>–<lpage>44</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Rigoux1">
        <label>87</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoux</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Guigon</surname><given-names>E</given-names></name> (<year>2012</year>) <article-title>A model of reward- and effort-based optimal decision making and motor control</article-title>. <source>PLoS Computational Biology</source> <volume>8</volume>: <fpage>e1002716</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Paynter1">
        <label>88</label>
        <mixed-citation publication-type="other" xlink:type="simple">Paynter H (1961) Analysis and design of engineering systems: class notes for M.I.T. course 2,751. M.I.T. Press.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Ganesh2">
        <label>89</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ganesh</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Albu-Schaeffer</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Haruno</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Burdet</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Biomimetic motor behavior for simultaneous adaptation of force, impedance and trajectory in interaction tasks</article-title>. <source>Proceedings of the IEEE International Conference on Robotics and Automation</source> <fpage>2705</fpage>–<lpage>2711</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Polenske1">
        <label>90</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Polenske</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>Competition, Collaboration and Cooperation: An Uneasy Triangle in Networks of Firms and Regions</article-title>. <source>Regional Studies</source> <volume>38</volume>: <fpage>1029</fpage>–<lpage>1043</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0049945-Winter1">
        <label>91</label>
        <mixed-citation publication-type="other" xlink:type="simple">Winter D (1990) Biomechanics and motor control of human movement. Wiley, 344 pp.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>