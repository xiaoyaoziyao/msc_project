<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-14-13866</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0099841</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Systems science</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Evolutionary algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Research and analysis methods</subject><subj-group><subject>Computational techniques</subject><subj-group><subject>Evolutionary computation</subject></subj-group></subj-group><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Influences of Agents with a Self-Reputation Awareness Component in an Evolutionary Spatial IPD Game</article-title>
<alt-title alt-title-type="running-head">Agents with a Self-Reputation Awareness Component in an IPD Game</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Huang</surname><given-names>Chung-Yuan</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>Chun-Liang</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Department of Computer Science and Information Engineering, School of Electrical and Computer Engineering, College of Engineering, Chang Gung University, Taoyuan, Taiwan, Republic of China</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>Matjaz</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Maribor, Slovenia</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">cllee@mail.cgu.edu.tw</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: CYH CLL. Performed the experiments: CYH CLL. Analyzed the data: CYH CLL. Contributed reagents/materials/analysis tools: CYH CLL. Contributed to the writing of the manuscript: CYH CLL.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>19</day><month>6</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>6</issue>
<elocation-id>e99841</elocation-id>
<history>
<date date-type="received"><day>27</day><month>3</month><year>2014</year></date>
<date date-type="accepted"><day>17</day><month>5</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Huang, Lee</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Iterated prisoner’s dilemma (IPD) researchers have shown that strong positive reputations plus an efficient reputation evaluation system encourages both sides to pursue long-term collaboration and to avoid falling into mutual defection cycles. In agent-based environments with reliable reputation rating systems, agents interested in maximizing their private interests must show concern for other agents as well as their own self-reputations–an important capability that standard IPD game agents lack. Here we present a novel learning agent model possessing self-reputation awareness. Agents in our proposed model are capable of evaluating self-behaviors based on a mix of public and private interest considerations, and of testing various solutions aimed at meeting social standards. Simulation results indicate multiple outcomes from the addition of a small percentage of self-reputation awareness agents: faster cooperation, faster movement toward stability in an agent society, a higher level of public interest in the agent society, the resolution of common conflicts between public and private interests, and a lower potential for rational individual behavior to transform into irrational group behavior.</p>
</abstract>
<funding-group><funding-statement>This work was supported in part by the High Speed Intelligent Communication (HSIC) research center, Chang Gung University, Taiwan, R.O.C. and by grants from the Republic of China National Science Council (NSC-102-2221-E-182-052 and NSC-102-2221-E-182-034). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="12"/></counts><custom-meta-group><custom-meta id="data-availability" xlink:type="simple"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. Data available on request.</meta-value></custom-meta></custom-meta-group></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Reputation provides a foundation for game theorists to analyze ways that past behaviors of social participants affect the behaviors and strategies of iterated prisoner’s dilemma (IPD) game opponents. According to Nowak <xref ref-type="bibr" rid="pone.0099841-Nowak1">[1]</xref>, the five mechanisms that promote cooperative behaviors are kin selection, direct reciprocity, indirect reciprocity, network reciprocity, and group selection. Reputation can be analyzed as a common form of indirect reciprocity based on knowing a player’s history with other players. It is a well-studied mechanism that sustains cooperation in evolutionary IPD games. For other examples see Fu <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0099841-Fu1">[2]</xref> and Wang <italic>et al.</italic> <xref ref-type="bibr" rid="pone.0099841-Wang1">[3]</xref>. Using the game as a social interaction model, participants who always choose to cooperate with opponents can be described as having good reputations, but participants who always defect are viewed as having damaged reputations. Participants who establish good reputations tend to receive trust, praise, and other positive feedback from their partners; those with poor reputations do not. We believe that the combination of a positive reputation and accurate reputation evaluation system can encourage two parties to pursue long-term collaboration and to avoid falling into mutual defection cycles, even when faced with short-term sacrifices.</p>
<p>Reputation-related behaviors and strategies have meaning for online commerce. Web 3.0 is supporting a growing number of Internet platforms and commercial applications that use intelligent agent architectures in support of complex online tasks such as auto-bidding on auction websites, placing Internet stock transaction orders, and shopping for cheaper e-commerce products and services <xref ref-type="bibr" rid="pone.0099841-Chen1">[4]</xref>–<xref ref-type="bibr" rid="pone.0099841-Wellman1">[6]</xref>. Web 3.0 researchers are therefore experimenting with artificial intelligence (AI) techniques to help intelligent agents “live” in Internet communities in ways that resemble how humans live in real-world communities <xref ref-type="bibr" rid="pone.0099841-Gutowska1">[7]</xref>–<xref ref-type="bibr" rid="pone.0099841-Tasner1">[10]</xref>. However, because of Internet agent properties such as anonymity, mobility, and multiple identities <xref ref-type="bibr" rid="pone.0099841-Garfinkel1">[11]</xref>, <xref ref-type="bibr" rid="pone.0099841-Hogg1">[12]</xref>, the use of intelligent agents raises serious game-based and theoretical issues involving cooperation and defection scenarios and conflicts between public and private interests <xref ref-type="bibr" rid="pone.0099841-Axelrod1">[13]</xref>–<xref ref-type="bibr" rid="pone.0099841-Ramchurn1">[15]</xref>. In their current form, intelligent agents do not have to worry about maintaining positive self-images, saving face, or being victims of acts of vengeance associated with fraudulent and defective behaviors commonly found in Web 3.0 e-commerce activities. Since they only care about private interests, they are unlikely to cooperate with other intelligent agents in support of group interests, thus increasing the potential for falling into cycles of never-ending mutual defection <xref ref-type="bibr" rid="pone.0099841-Mintz1">[16]</xref>.</p>
<p>Several agent-based computational simulation researchers have shown that determining game strategies and behaviors based on an opponent’s reputation is an effective solution that may increase the desire to cooperate <xref ref-type="bibr" rid="pone.0099841-Fu1">[2]</xref>, <xref ref-type="bibr" rid="pone.0099841-Ramchurn1">[15]</xref>, <xref ref-type="bibr" rid="pone.0099841-Carter1">[17]</xref>–<xref ref-type="bibr" rid="pone.0099841-Wang6">[26]</xref>. When one intelligent agent is required to cooperate with an unfamiliar agent to complete a task, a reputation rating system can have great utility in determining the unfamiliar agent’s trustworthiness <xref ref-type="bibr" rid="pone.0099841-Bromley1">[27]</xref>, <xref ref-type="bibr" rid="pone.0099841-Kreps1">[28]</xref>. However, a clustering effect resulting in decreased public interest may occur if all agents in a system simultaneously search for other agents with good reputations. This seems inevitable, since agents with good reputations only want to work with other reputable agents. In contrast, agents lacking good reputations must spend a great deal of time performing partner searches because they are in the awkward position of being rejected by ideal partners, in many cases without self-knowledge of their poor or unspecified reputations <xref ref-type="bibr" rid="pone.0099841-Axelrod1">[13]</xref>, <xref ref-type="bibr" rid="pone.0099841-Adler1">[29]</xref>–<xref ref-type="bibr" rid="pone.0099841-Sachs1">[34]</xref>. Further, if a reputable agent only cares about other agents’ reputations but lacks self-knowledge of its own reputation, it may try to maximize its private interests using behaviors that end up harming other agents, thus causing damage to its existing reputation. Accordingly, any multi-agent system with a reputation-rating scheme must contain a method so that agents interested in maximizing their private interests can exhibit concern for other agents as well as their own reputations.</p>
<p>Our proposed agent model is equipped with a self-reputation awareness component (SRAC) that learns and evolves during spatial IPD games involving two-dimensional social interaction networks. The SRAC agents in our model are capable of evaluating their behaviors based on a mix of public and private interest considerations, and of testing various solutions aimed at meeting and maintaining social standards. Self-reputation awareness helps new agents quickly learn that private interest maximization is best achieved via long-term cooperation with partners, which also serves to enhance their own reputations and to support their wishes for ideal partners in the future. In other words, agents with self-reputation awareness that show concern for their reputations are more likely to be self-adaptive, to evaluate their reputations based on their partners’ evaluations, and to determine the best strategies and behaviors for achieving both long- and short-term goals. According to our IPD simulation experiment results, as long as an artificial society has a small percentage of agents with this capability for self-reputation awareness, there will be faster cooperation, faster movement toward stability in an agent society, greater public interest in the agent society, resolutions of common conflicts between public and private interests, and decreased potential for rational individual behavior to change into irrational group behavior.</p>
<sec id="s1a">
<title>Related Works</title>
<p>Self-awareness, a psychological process in which attention is directed at oneself <xref ref-type="bibr" rid="pone.0099841-Baumeister1">[35]</xref>, is a foundation for personality development and modification that affects all human behaviors. According to theorists, when humans achieve strong states of self-awareness, they tend to consider whether characteristics and behaviors such as personality, abilities, desires, needs, comportment, and values are appropriate <xref ref-type="bibr" rid="pone.0099841-Aronson1">[31]</xref>, <xref ref-type="bibr" rid="pone.0099841-Peacocke1">[36]</xref>, <xref ref-type="bibr" rid="pone.0099841-Phillips1">[37]</xref>. Subsequent actions are thought to be more likely to reduce self-discrepancies and to meet inner identity standards established by important others, as well as societal and cultural values <xref ref-type="bibr" rid="pone.0099841-Carver1">[38]</xref>. In other words, an intact sense of self-awareness supports a complete understanding of one’s own behavior in terms of right/wrong, good/bad, and value based on societal standards <xref ref-type="bibr" rid="pone.0099841-Noe1">[39]</xref>. This capability is helpful for learning skills and adjusting strategies for interacting with others. Internally, one can recognize emotions, motivations, interests, and desires, increase self-identification, and achieve self-realization. Without this capability, one’s behaviors will often be triggered by strong momentary emotions without considering potential consequences <xref ref-type="bibr" rid="pone.0099841-Aronson1">[31]</xref>. Those individuals who are incapable of understanding the emotions and ideas of others are much more likely to expose their own shortcomings or to show off their strengths without contemplating the appropriateness of doing so.</p>
<p>In contrast to human models, the focus of learning and attention for intelligent agents has always been the external environment <xref ref-type="bibr" rid="pone.0099841-Russell1">[40]</xref>. The world model gradually established during an agent’s learning process is a miniature of its external environment. The purpose of such a model is to maintain relationships between stimulation signals from external environments and behavioral reactions <xref ref-type="bibr" rid="pone.0099841-Sutton1">[41]</xref>. Based on physical environment and the presence of other agents, and using specific learning methods such as artificial neural networks, genetic algorithms, and fuzzy rule-based systems, agents continuously adjust their internal strategies, learn various skills <xref ref-type="bibr" rid="pone.0099841-Mitchell1">[42]</xref>, <xref ref-type="bibr" rid="pone.0099841-Mitchell2">[43]</xref>, and find problem solutions that satisfy user needs or fulfill assigned tasks <xref ref-type="bibr" rid="pone.0099841-Dobbyn1">[44]</xref>, <xref ref-type="bibr" rid="pone.0099841-Huang1">[45]</xref>.</p>
<p>There are at least five advantages to equipping intelligent agents with a self-awareness capability: (a) compatibility with previous AI agent-learning frameworks, thereby supporting the expansion of existing cognitive structures so as to enhance agent learning outcomes and support searches for fast problem-solving strategies; (b) the introduction of self-consciousness so that agents, using mechanisms that connect external stimulation signals with behavioral reactions, can consider and integrate the mutual needs of or feedback from other agents that they interact with; (c) agent use of private and public self-consciousness for detecting its own behavioral reactions, differences, and discrepancies between internal and external standards, and for exploring means for improvement that may decrease such discrepancies, increase learning performance, and satisfy such standards; (d) support for understanding and recording the dynamic characteristics of their external environments, and in revising and adjusting internal standards or states accordingly; and (e) support for establishing artificial societies and agent cognitive and learning models that are similar to the ways that real societies operate <xref ref-type="bibr" rid="pone.0099841-Dobbyn1">[44]</xref>, <xref ref-type="bibr" rid="pone.0099841-Kawamura1">[46]</xref>, <xref ref-type="bibr" rid="pone.0099841-Markus1">[47]</xref>.</p>
</sec><sec id="s1b">
<title>Spatial IPD Simulator and SRAC Agent Model</title>
<p>Our adaptive agent model contains a self-reputation awareness component (SRAC) based on a mix of social expectation strategies and a reputation evaluation procedure for resolving ongoing conflicts between public and individual private interests in an agent society. It is our belief that an awareness capability that allows agents to reflect on their self-reputations will result in more and faster collaborative behaviors and social benefits. To assess the effects of mixing SRAC and non-SRAC agents on the evolutionary dynamics of IPD games, we used the Java programming language to develop a general-purpose and extendable evolutionary spatial IPD simulator suitable for detailed numerical experimentation and classroom demonstrations. As shown in the screen-shot of <xref ref-type="supplementary-material" rid="pone.0099841.s001">Appendix S1</xref>, the IPD simulator is suitable for all common operating systems containing the Java virtual machine, including Linux, Mac OS X, and Windows. Executable files are available in a shared Google drive folder (<ext-link ext-link-type="uri" xlink:href="https://drive.google.com/folderview?id=0B2C9hdWHlsqHbzNadVdGMGZxZkk&amp;usp=sharing" xlink:type="simple">https://drive.google.com/folderview?id=0B2C9hdWHlsqHbzNadVdGMGZxZkk&amp;usp=sharing</ext-link>); for source code that matches specific research requirements, contact the corresponding author.</p>
<p>The simulation flow consists of four steps:<disp-formula id="pone.0099841.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0099841.e001" xlink:type="simple"/></disp-formula></p>
<p>In Step 1, all parameters and evolutionary computation operators must be reset to default or user-required settings. The default settings allow first-time simulation users to quickly execute simple and understandable demonstrations. We categorized individual parameters as IPD game, social interaction network, or evolutionary computation. The first category includes the total number of interactions between an agent and its opponent (<italic>q</italic>), agent memory capacity (<italic>c</italic>), and agent strategy length (<italic>l</italic>). The social interaction network category includes the width (<italic>W</italic>) and height (<italic>H</italic>) of a two-dimensional social network, total number of nodes (<italic>v</italic>) and edges (<italic>e</italic>), neighborhood pattern (<italic>P</italic>), network type (<italic>T</italic>), and edge rewiring probability (<italic>ρ</italic>). The evolutionary computation category includes crossover rate (<italic>P<sub>c</sub></italic>), mutation rate (<italic>P<sub>m</sub></italic>), and total number of generations for each experiment (<italic>MAX_G</italic>). We used the following default values: <italic>q</italic> = 100, <italic>c</italic> = 1, <italic>l</italic> = 4, <italic>W</italic> = 50, <italic>H</italic> = 50, <italic>v</italic> = 2500, <italic>e</italic> = 10,000, <italic>P</italic> = Moore neighborhood and periodic boundary condition, <italic>P<sub>c</sub></italic> = 0.7, <italic>P<sub>m</sub></italic> = 0.01, and <italic>MAX_G</italic> = 100. The default configuration of the <italic>P</italic> neighborhood pattern parameter ensures that all nodes have equal numbers of neighboring nodes, and that each node establishes connections with its eight surrounding nodes to form tightly clustered groups.</p>
<p>Following initialization and parameter setting according to experimental requirements, a specific two-dimensional <italic>W</italic>×<italic>H</italic> social interaction network consisting of <italic>v</italic> nodes and <italic>e</italic> edges can be established according to the <italic>T</italic> parameter value. Each social interaction network node represents an IPD agent that is assigned a randomly generated memory-<italic>c</italic> deterministic strategy. Each edge represents a single IPD interaction relationship between two agents that are labeled as neighbors. Each IPD agent has an average of 2<italic>e</italic>/<italic>v</italic> neighbor opponents.</p>
<p>The <italic>T</italic> parameter can be set as either a cellular automata with high degrees of local clustering and separation, or a small-world network with a high degree of local clustering and low degree of separation. Cellular automata are widely used computational social science investigations of the large-scale outcomes of millions of small-scale events, and for creating visually striking patterns. Small-world networks, which are considered similar to human social networks, serve as the underlying foundations of social simulation models that are said to have high levels of reliability. To compare simulation results for the two network types, we stipulated that the numbers of nodes and edges in each must be equal. To satisfy this condition, if the <italic>T</italic> parameter is designated as small-world, the simulation is programmed to initially generate a two-dimensional cellular automata according to the <italic>P</italic> (neighborhood pattern) parameter configuration, and then to use a predetermined edge rewiring probability <italic>ρ</italic> (default: 1%) to determine whether or not individual edges must be rewired. If rewiring is necessary, either one of the two original nodes (one on each side of an edge) is discarded and replaced with a new, randomly selected node.</p>
<p>In Step 4a, for the sake of simplicity but without loss of generality, we used three IPD agent assumptions: (a) Agent <italic>A<sub>i</sub></italic> has <italic>n</italic> opponents, meaning that opponents <italic>O<sub>i</sub></italic> =  (<italic>o<sub>i,0</sub></italic>, <italic>o<sub>i,1</sub></italic>, …, <italic>o<sub>i,n−1</sub></italic>)<sup>g</sup> during generation <italic>g</italic>, with <italic>o<sub>i,j</sub></italic> representing the <italic>j</italic>th opponent of <italic>A<sub>i</sub></italic>. (b) Agent <italic>A<sub>i</sub></italic> plays <italic>q</italic> IPD game rounds with each opponent during each generation. (c) The <italic>af<sub>i</sub></italic> fitness value of agent <italic>A<sub>i</sub></italic> equals the average of all payoffs received by that agent during rounds played within one generation. This value serves as an indication of its performance compared to others in the same agent population.</p>
<p>The IPD game payoff matrix used in Step 4a is shown in <xref ref-type="table" rid="pone-0099841-t001">Table 1</xref>. As indicated, <italic>R</italic> = 3 represents the reward for mutual cooperation, <italic>T</italic> = 5 one party’s temptation to defect, <italic>S</italic> = 0 the “sucker’s payoff”, and <italic>P</italic> = 1 the punishment for mutual defection. Two conditions for generating a prisoner’s dilemma are <italic>T</italic>&gt;<italic>R</italic>&gt;<italic>P</italic>&gt;<italic>S</italic> and 2<italic>R</italic>&gt;<italic>T</italic>+<italic>S</italic>. The first guarantees that two rational agents will simultaneously betray each other after understanding that <italic>T</italic>&gt;<italic>R</italic> and <italic>P</italic>&gt;<italic>S</italic>, and therefore follow the second best choice, which is mutual defection (<italic>P</italic>, <italic>P</italic>). According to the second condition, prisoners cannot escape the same predicament by taking turns betraying each other–in other words, benefits for mutual betrayal are not as good as for mutual cooperation. Accordingly, each agent must rely on past behaviors to formulate strategies that optimize long-term benefits.</p>
<table-wrap id="pone-0099841-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.t001</object-id><label>Table 1</label><caption>
<title>IPD game payoff matrix.</title>
</caption><alternatives><graphic id="pone-0099841-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td colspan="2" align="left" rowspan="1"/>
<td colspan="2" align="left" rowspan="1">Player B</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1"/>
<td align="left" rowspan="1" colspan="1">Cooperation (C)</td>
<td align="left" rowspan="1" colspan="1">Defection (D)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Player A</bold></td>
<td align="left" rowspan="1" colspan="1"><bold>Cooperation (C)</bold></td>
<td align="left" rowspan="1" colspan="1">R = 3<bold>,</bold> R = 3</td>
<td align="left" rowspan="1" colspan="1">T = 5<bold>,</bold> S = 0</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><bold>Defection (D)</bold></td>
<td align="left" rowspan="1" colspan="1">S = 0<bold>,</bold> T = 5</td>
<td align="left" rowspan="1" colspan="1">P = 1<bold>,</bold> P = 1</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Numbers in each cell are payoffs for both players, with player A’s payoff listed first in each pair.</p></fn></table-wrap-foot></table-wrap>
<p>The default strategy in our model is memory-1 deterministic, with agents remembering the behaviors of their opponents in preceding rounds. There are only four possible combinations: both cooperate (expressed as CC), one cooperates and the other defects (CD), one defects and the other cooperates (DC), and both defect (DD). Thus, the memory-1 deterministic strategy can be expressed as the four-value tuple (<italic>S<sub>cc</sub></italic>, <italic>S<sub>cd</sub></italic>, <italic>S<sub>dc</sub></italic>, <italic>S<sub>dd</sub></italic>): if an agent’s memory of the preceding round is CC, then it will choose <italic>S<sub>cc</sub></italic> when responding to an opponent. Since responses are limited to either cooperation (C) or defection (D), a memory-1 deterministic strategy consists of 16 (2<sup>4</sup>) possible combinations of moves. Among these, <italic>S<sub>0</sub></italic> =  (C, C, C, C) is known as the “yes-man” (YM) strategy, <italic>S<sub>5</sub></italic> =  (C, D, C, D) the “tit-for-tat” (TFT) strategy, <italic>S<sub>6</sub></italic> =  (C, D, D, C) the “win-stay, lose-shift” (WS/LS) strategy, and <italic>S<sub>15</sub></italic> =  (D, D, D, D) the “scoundrel” (S) strategy. These four strategies have attracted considerable research interest. The WS/LS strategy applies Pavlovian psychological theory in proposing that an agent will adhere to one strategy until its income goes below a threshold, after which it switches to the opposite strategy <xref ref-type="bibr" rid="pone.0099841-Liu1">[48]</xref>. In the TFT strategy, an agent always chooses cooperation during the first round of a game, and then imitates its opponent’s strategy in subsequent rounds.</p>
<p>In Step 4b, each agent initially uses the evaluation algorithm described in <xref ref-type="supplementary-material" rid="pone.0099841.s002">Appendix S2</xref> to give its opponent a relative reputation score at the end of each generation, based on the mean and standard deviation of the number of cooperative moves made by its opponents during one generation. By applying this relative reputation evaluation algorithm, the two algorithms proposed in <xref ref-type="supplementary-material" rid="pone.0099841.s003">Appendix S3</xref> can be used to respectively compute an agent’s relative fitness and self-reputation levels in the contexts of its opponents.</p>
<p>As shown in <xref ref-type="fig" rid="pone-0099841-g001">Figure 1</xref> and Step 4c of the pseudo-code of our IPD simulation, fitness and self-reputation levels are categorized as high, medium, or low, resulting in nine possible interaction types between an SRAC agent and its opponent. As an example, a SRAC agent with a high degree of fitness and low degree of self-reputation usually adheres to an always-betray or similar “villain” strategy that cannot produce a higher public good value, since it diminishes the ability of other agents to pursue their own interests. Therefore, SRAC agents must be taught that an always-betray strategy will negatively affect their reputations. By referring to and learning from their opponents’ positive performance strategies that conform to social expectations, SRAC agents can achieve higher levels of fitness and self-reputation.</p>
<fig id="pone-0099841-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g001</object-id><label>Figure 1</label><caption>
<title>Agent fitness scores plotted against a self-reputation index matrix.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g001" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s2">
<title>Results and Discussion</title>
<p>Our first task was to analyze the results of IPD game simulations using cellular automata and without adding any SRAC agents (<xref ref-type="fig" rid="pone-0099841-g002">Figs. 2</xref>, <xref ref-type="fig" rid="pone-0099841-g003">3</xref> and <xref ref-type="fig" rid="pone-0099841-g004">4</xref>). The first 99 generations can be divided into five stages based on the evolutionary dynamics and spatial distributions of agent-adopted strategies. During the first stage (generations 0–3), our proposed model starts with a pool of randomly generated strategies adopted by individual agents being evenly distributed throughout the cellular automata (<xref ref-type="fig" rid="pone-0099841-g004">Fig. 4a</xref>). During the second stage (4–10), agents tend to give in to the temptations of maximizing their private interests and use the S strategy. As stated earlier, when a majority of agents adopt that strategy, the entire community eventually enters a cycle in which overall and individual private benefits rapidly decrease (<xref ref-type="fig" rid="pone-0099841-g002">Figs. 2</xref> and <xref ref-type="fig" rid="pone-0099841-g003">3b</xref>). In cellular automata, if the majority of an agent’s adjacent neighbors adopt the S strategy, then the agent in the center is forced to adopt the same strategy in order to survive (<xref ref-type="fig" rid="pone-0099841-g004">Figs. 4b and 4c</xref>).</p>
<fig id="pone-0099841-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g002</object-id><label>Figure 2</label><caption>
<title>Average payoffs for all agents in cellular automata without adding SRAC agents.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g002" position="float" xlink:type="simple"/></fig><fig id="pone-0099841-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g003</object-id><label>Figure 3</label><caption>
<title>Evolutionary dynamics and average payoffs for four IPD strategies in cellular automata without adding SRAC agents.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g003" position="float" xlink:type="simple"/></fig><fig id="pone-0099841-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g004</object-id><label>Figure 4</label><caption>
<title>Spatial distributions of 16 memory-1 deterministic IPD strategies in cellular automata without adding SRAC agents.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g004" position="float" xlink:type="simple"/></fig>
<p>During the third stage (11–20), agents wanting to move away from the S strategy are likely to move toward a TFT strategy (<xref ref-type="fig" rid="pone-0099841-g003">Fig. 3a</xref>). In addition to confronting S strategy agents, this action also supports cooperation with agents who adopt either the YM or TFT strategies. The spatial clustering effect is also known as network reciprocity <xref ref-type="bibr" rid="pone.0099841-Nowak1">[1]</xref>, <xref ref-type="bibr" rid="pone.0099841-Nowak2">[49]</xref>. Network reciprocity is receiving attention from physics researchers <xref ref-type="bibr" rid="pone.0099841-Wang4">[24]</xref>–<xref ref-type="bibr" rid="pone.0099841-Wang6">[26]</xref>, <xref ref-type="bibr" rid="pone.0099841-Perc1">[50]</xref>–<xref ref-type="bibr" rid="pone.0099841-Wang9">[54]</xref>. <xref ref-type="fig" rid="pone-0099841-g004">Figures 4c and 4d</xref> illustrate a scenario in which TFT strategy agents gradually increase in number and cluster in a manner that surrounds and restricts agents who adopt the S strategy.</p>
<p>The number of TFT strategy agents declines during the fourth stage (21–40). Due to an asymmetry problem involving memories of previous encounters, these agents start to defect and stop trusting each other, resulting in less clustering over large areas. However, as shown in <xref ref-type="fig" rid="pone-0099841-g004">Figures 4d and 4e</xref>, some TFT strategy agents continue to surround S strategy agents to ensure that the latter do not expand to the point of overwhelming the former. Note also that as clusters of TFT strategy agents start to break up and decrease in size, the number of agents that adopt the WS/LS strategy increases (<xref ref-type="fig" rid="pone-0099841-g003">Fig. 3a</xref>) <xref ref-type="bibr" rid="pone.0099841-Nowak1">[1]</xref>. Since WS/LS strategy agents do not have asymmetric memory problems regarding previous encounters (which increases the potential for breaking promises), and since those same agents generally move toward mutual collaboration, their numbers and tendency to cooperate gradually increase.</p>
<p>During the fifth stage (41–100), strategy evolution enters a state of “dynamic stability”–a term we use to describe a long period of repetition. Within clusters of WS/LS strategy agents, the number of YM strategy agents gradually increases (<xref ref-type="fig" rid="pone-0099841-g004">Figs. 4e and 4f</xref>). Agents who adopt either the YM or WS/LS strategies interact in ways that benefit both sides. However, in reaction to this increase, some agents take advantage of the situation by reverting to the S strategy, which reduces (and in some cases eliminates) clusters of agents that adopt the all-cooperation strategy. This scenario, which is often found in human societies, increases the potential for damage from internal mutation and external invasions.</p>
<p>Average payoff curves from our IPD simulations using 0% (baseline), 10%, 30%, 50% and 100% SRAC agents are shown in <xref ref-type="fig" rid="pone-0099841-g005">Figures 5</xref> (cellular automata) and 6 (small-world network). Initial parameter settings were identical. As indicated by the red average payoff curves in the two figures, the overall network community clearly benefited when all agents possessed the capacity for self-reputation awareness, with a state of dynamic stability achieved within very few generations. However, since such a situation is not possible in the real world, we focused on the effects of adding a small number of SRAC agents to an otherwise unaltered environment. According to the blue (10%) and green (30%) average payoff curves, adding a small number of SRAC agents exerted a significant influence, regardless of social interaction network type. Specifically, they suppressed growth in the number of agents who adopted the S strategy, prevented the initiation of a cycle in which all agents expressed betrayal and retaliatory behaviors, and helped resolve conflicts between society-wide benefits and individual private interests so that cooperation gained acceptance as mainstream behavior.</p>
<fig id="pone-0099841-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g005</object-id><label>Figure 5</label><caption>
<title>Comparisons of (a) average payoffs and (b) spatial distributions of 16 memory-1 deterministic game strategies at the twenty-first generation triggered by the addition of different percentages of SRAC agents in cellular automata.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g005" position="float" xlink:type="simple"/></fig>
<p>The average payoff curves in <xref ref-type="fig" rid="pone-0099841-g005">Figures 5</xref> and <xref ref-type="fig" rid="pone-0099841-g006">6</xref> are similar because small-world networks contain many random long-distance shortcuts that reduce network separation. There are at least two reasons for a lack of strategic clustering: these shortcuts produce very low degrees of separation (approximately log <italic>v</italic>, with <italic>v</italic> representing the total number of nodes), and they significantly increase complexity in terms of agent interactions and indirect influences. Note that the influence of a single game strategy can result in increased evolutionary diffusion and the increased containment of other agents. Combined, these factors accelerate the movement toward dynamic stability.</p>
<fig id="pone-0099841-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g006</object-id><label>Figure 6</label><caption>
<title>Comparisons of (a) average payoffs and (b) spatial distributions of 16 memory-1 deterministic game strategies at the twenty-first generation triggered by the addition of different percentages of SRAC agents to small-world networks.</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g006" position="float" xlink:type="simple"/></fig>
<p>Agents who follow a YM strategy are the most likely to be taken advantage of by agents who use tactics associated with a S strategy. In contrast, TFT strategy agents find it easy to cooperate with YM and to attack S strategy agents. However, due to memory asymmetry problems regarding previous encounters, interacting TFT strategy agents may express negative behaviors such as breaking promises for an extended time period. Finally, we found that WS/LS strategy agents tended to change their behaviors as soon as benefits from doing so became obvious.</p>
<p>We analyzed the evolutionary dynamics (<xref ref-type="fig" rid="pone-0099841-g007">Fig. 7</xref>) and average payoffs (<xref ref-type="fig" rid="pone-0099841-g008">Fig. 8</xref>) of the four strategies in terms of three SRAC agent mixes–0% (<xref ref-type="fig" rid="pone-0099841-g007">Figs. 7a, 7d</xref>, <xref ref-type="fig" rid="pone-0099841-g008">8a, and 8d</xref>, control group), 100% (<xref ref-type="fig" rid="pone-0099841-g007">Figs. 7b</xref> 7e, 8b, and 8e), and 10% (<xref ref-type="fig" rid="pone-0099841-g007">Figs. 7c, 7f</xref>, <xref ref-type="fig" rid="pone-0099841-g008">8c, and 8f</xref>); all other parameter settings were identical. Using cellular automata with 0% SRAC agents resulted in roughly equal numbers of agents adopting each of the four strategies at the beginning of every simulation (<xref ref-type="fig" rid="pone-0099841-g007">Fig. 7a</xref>). After three generations, the number of agents adopting the S strategy increased rapidly, and the number of agents adopting the YM or WS/LS strategies decreased slightly. Agents adopting the TFT strategy emerged when the number of S strategy agents reached a certain threshold. As described earlier, they confronted and suppressed agents adopting the S strategy, and collaborated with agents adopting the YM and WS/LS strategies. After twenty generations, the number of agents adopting the TFT strategy surpassed the number of agents adopting the S strategy, resulting in a sharp decrease in agents adopting the S strategy. The number of agents adopting the WS/LS strategy steadily increased after thirty generations; after sixty generations, the number of agents adopting the TFT strategy fell below the number of agents adopting the S strategy, and the simulated agent society entered a state of dynamic stability. The numbers of agents adopting the WS/LS and YM strategies did not change, and a balance was achieved in the growth and decline of agents adopting the S and TFT strategies.</p>
<fig id="pone-0099841-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g007</object-id><label>Figure 7</label><caption>
<title>Evolutionary dynamics of four IPD strategies in cellular automata (a, b, c) and small-world networks (d, e, f).</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g007" position="float" xlink:type="simple"/></fig><fig id="pone-0099841-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0099841.g008</object-id><label>Figure 8</label><caption>
<title>Average payoffs for four IPD strategies in cellular automata (a, b, c) and small-world networks (d, e, f).</title>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0099841.g008" position="float" xlink:type="simple"/></fig>
<p>As shown in <xref ref-type="fig" rid="pone-0099841-g007">Figure 7d</xref>, early evolutionary growth and decline rates for all four strategies in two-dimensional small-world networks with 0% SRAC agents were similar to those shown in <xref ref-type="fig" rid="pone-0099841-g007">Figure 7a</xref>. After thirty generations, the number of agents adopting the S strategy reached a saturation point and remained at a fixed number that was significantly higher than that observed for the cellular automata. Due to the small-world network’s low degree of separation characteristic, the numbers of agents adopting each of the four strategies reached a state of dynamic stability between the fiftieth and sixtieth generations.</p>
<p><xref ref-type="fig" rid="pone-0099841-g007">Figure 7c</xref> presents data on simulations involving cellular automata and the 10% addition of SRAC agents. Compared to <xref ref-type="fig" rid="pone-0099841-g007">Figure 7a</xref> (0% SRAC agents), the peak number of agents adopting the S strategy was not as great–a 150-agent difference. <xref ref-type="fig" rid="pone-0099841-g007">Figures 7d and 7f</xref> illustrate data for 0% and 10% additions of SRAC agents, respectively; here the difference in the peak number of agents adopting the S strategy was 60. Note also that following the 10% addition of SRAC agents, the number of agents adopting a WS/LS strategy surpassed the number of agents adopting the S or TFT strategies during generations 47 through 80 (<xref ref-type="fig" rid="pone-0099841-g007">Fig. 7c</xref>), but after the 80th generation those agents adopting the WS/LS strategy could not successfully resist agents adopting the S strategy, even though their numbers had increased. As a result, the number of agents adopting the WS/LS strategy started to decline to a stable level.</p>
<p><xref ref-type="fig" rid="pone-0099841-g007">Figure 7b</xref> presents data for a cellular automata consisting of 100% SRAC agents. Since S agents quickly discovered that their strategy was inappropriate for fulfilling social expectations, during the early evolutionary stages they all used their self-adjustment mechanisms to adopt other strategies to meet the expectations of adjacent agents. Starting at the third or fourth generation, the number of agents adopting the S strategy dropped to zero, and no new S strategy-adopting agents emerged for the rest of the simulation. The number of agents adopting the other three strategies also quickly stabilized without additional changes. Again, all parameters in <xref ref-type="fig" rid="pone-0099841-g007">Figures 7b and 7e</xref> were identical; the evolutionary dynamics of the four strategies in the two types of social interaction networks were also virtually identical. The only significant difference was the presence of random long-distance shortcuts in the two-dimensional small-world network. Due to increased sensitivity, even small changes in a single agent’s strategy were capable of influencing the entire network. However, due to the low degree of separation characteristic of small-world networks, a new state of dynamic stability was quickly reestablished.</p>
</sec><sec id="s3">
<title>Conclusion</title>
<p>In this paper we described our proposal for a self-reputation awareness model in which agents are given the ability to calculate and interpret their self-reputation levels, and to adjust their IPD game strategies accordingly. Our primary conclusions are (a) the model successfully encourages strategy adjustments to achieve an optimum balance between self-reputation and private interests, thus increasing the likelihood that an agent will suppress its betrayal behavior and defection strategy in order to increase cooperation with other agents; and (b) compared to other models, overall cooperative behavior in our proposed model is likely to emerge much faster.</p>
<p>Our proposed SRAC agent model incorporates numerous features taken from AI, cognitive psychology, economics, and the social/behavioral sciences. AI researchers have generally overlooked the learning processes through which individuals enact self-awareness mechanisms. Based on our experimental results, we believe that integrating a self-reputation awareness component into agent architectures not only brings the behaviors and interaction patterns of agents into closer agreement with those of real people, but also provides a novel agent architecture to help agent-based simulations more accurately reflect actual societal operations. It is our hope that this self-reputation awareness component will support the efforts of smart object researchers interested in improving internal cognition and external learning capability in intelligent agents. In terms of cognitive psychology, our proposed SRAC agents can utilize personality traits to enhance their self-understanding and self-identity, thus promoting self-realization. The model also offers a novel approach to the IPD game: as long as a small number of SRAC agents are added to an IPD scenario, public good/private interest conflicts can be resolved, agent cooperation can be increased, and overall societal benefits can be enhanced. Finally, in terms of social/behavioral sciences, observing clustering behaviors allows for greater understanding of how self-reputation awareness can influence evolutionary dynamics and average payoffs in artificial agent societies.</p>
</sec><sec id="s4">
<title>Supporting Information</title>
<supplementary-material id="pone.0099841.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pone.0099841.s001" position="float" xlink:type="simple"><label>Appendix S1</label><caption>
<p><bold>User interface for our evolutionary spatial IPD simulator.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material><supplementary-material id="pone.0099841.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pone.0099841.s002" position="float" xlink:type="simple"><label>Appendix S2</label><caption>
<p><bold>Pseudo-code to evaluate the relative reputation scores of the agent’s opponents.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material><supplementary-material id="pone.0099841.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pone.0099841.s003" position="float" xlink:type="simple"><label>Appendix S3</label><caption>
<p><bold>Pseudo-code to compute the agent’s relative fitness and self-reputation levels.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0099841-Nowak1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name> (<year>2006</year>) <article-title>Five rules for the evolution of cooperation</article-title>. <source>Science</source> <volume>314(5805)</volume>: <fpage>1560</fpage>–<lpage>1563</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Fu1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fu</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hauert</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name> (<year>2008</year>) <article-title>Reputation-based partner choice promotes cooperation in social networks</article-title>. <source>Phys Rev E</source> <volume>78(2)</volume>: <fpage>026117</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Yin</surname><given-names>ZY</given-names></name>, <name name-style="western"><surname>Xia</surname><given-names>CY</given-names></name> (<year>2012</year>) <article-title>Inferring reputation promotes the evolution of cooperation in spatial social dilemma games</article-title>. <source>PLoS One</source> <volume>7(7)</volume>: <fpage>e40218</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Chen1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>SH</given-names></name>, <name name-style="western"><surname>Yeh</surname><given-names>CH</given-names></name> (<year>2001</year>) <article-title>Evolving traders and the business school with genetic programming: A new architecture of the agent-based artificial stock market</article-title>. <source>J Econ Dyn Control</source> <volume>25(3)</volume>: <fpage>363</fpage>–<lpage>393</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Maes1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Guttman</surname><given-names>RH</given-names></name>, <name name-style="western"><surname>Moukas</surname><given-names>AG</given-names></name> (<year>1999</year>) <article-title>Agents that buy and sell</article-title>. <source>Commun ACM</source> <volume>42(3)</volume>: <fpage>81</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wellman1"><label>6</label>
<mixed-citation publication-type="book" xlink:type="simple">Wellman MP, Greenwald A, Stone P (2007) Autonomous bidding agents: Strategies and lessons from the trading agent competition. Massachusetts: MIT Press. 238 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Gutowska1"><label>7</label>
<mixed-citation publication-type="other" xlink:type="simple">Gutowska A, Sloane A (2010) Modelling the B2C marketplace: evaluation of a reputation metric for e-Commerce. In: Cordeiro J, Filipe J, editors. Web Information Systems and Technologies. Springer Berlin Heidelberg. 212–226.</mixed-citation>
</ref>
<ref id="pone.0099841-Hendler1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hendler</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Web 3.0 emerging</article-title>. <source>Computer</source> <volume>42(1)</volume>: <fpage>111</fpage>–<lpage>113</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Morris1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morris</surname><given-names>RD</given-names></name> (<year>2011</year>) <article-title>Web 3.0: implications for online learning</article-title>. <source>TechTrends</source> <volume>55(1)</volume>: <fpage>42</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Tasner1"><label>10</label>
<mixed-citation publication-type="book" xlink:type="simple">Tasner M (2010) Marketing in the moment: the practical guide to using Web 3.0 marketing to reach your customers first. New Jersey: FT Press. 239 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Garfinkel1"><label>11</label>
<mixed-citation publication-type="book" xlink:type="simple">Garfinkel S, Spafford G (2002) <italic>Web security, privacy and commerce</italic>. California: O’Reilly Media. 800 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Hogg1"><label>12</label>
<mixed-citation publication-type="book" xlink:type="simple">Hogg J (2006) Web service security: Scenarios, patterns, and implementation guidance for Web Services Enhancements (WSE) 3.0. California: O’Reilly Media. 380 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Axelrod1"><label>13</label>
<mixed-citation publication-type="book" xlink:type="simple">Axelrod RM (1997) The complexity of cooperation: Agent-based models of competition and collaboration. New Jersey: Princeton University Press. 248 p.</mixed-citation>
</ref>
<ref id="pone.0099841-McGillivray1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McGillivray</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>A</given-names></name> (<year>2000</year>) <article-title>Trust and cooperation through agent-specific punishments</article-title>. <source>Int Organ</source> <volume>54(4)</volume>: <fpage>809</fpage>–<lpage>824</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Ramchurn1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramchurn</surname><given-names>SD</given-names></name>, <name name-style="western"><surname>Huynh</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Jennings</surname><given-names>NR</given-names></name> (<year>2004</year>) <article-title>Trust in multi-agent systems</article-title>. <source>Knowl Eng Rev</source> <volume>19(1)</volume>: <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Mintz1"><label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">Mintz AP (2002) <italic>Web of deception: misinformation on the Internet</italic>. New Jersey: Information Today, Inc. 278 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Carter1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carter</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bitting</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ghorbani</surname><given-names>AA</given-names></name> (<year>2002</year>) <article-title>Reputation formalization for an information–sharing multi–agent system</article-title>. <source>Comput Intell</source> <volume>18(4)</volume>: <fpage>515</fpage>–<lpage>534</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Josang1"><label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Josang A (1999) Trust-based decision making for electronic transactions. Proceedings of the Fourth Nordic Workshop on Secure Computer Systems, 496–502.</mixed-citation>
</ref>
<ref id="pone.0099841-Liang1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Yajun</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Mei</surname><given-names>Q</given-names></name> (<year>2009</year>) <article-title>A reputation-based trust evaluation model for P2P. E-Commerce</article-title>. <source>International Journal of Distributed Sensor Networks</source> <volume>5(1)</volume>: <fpage>39</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-McKnight1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKnight</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Chervany</surname><given-names>NL</given-names></name> (<year>2002</year>) <article-title>What trust means in e-commerce customer relationships: an interdisciplinary conceptual typology</article-title>. <source>International Journal of Electronic Commerce</source> <volume>6</volume>: <fpage>35</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Resnick1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Resnick</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Zeckhauser</surname><given-names>R</given-names></name> (<year>2002</year>) <article-title>Trust among strangers in Internet transactions: Empirical analysis of eBay’s reputation system</article-title>. <source>Advances in Applied Microeconomics</source> <volume>11</volume>: <fpage>127</fpage>–<lpage>157</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang2"><label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Wang W, Zeng G, Yuan L (2006) A reputation multi-agent system in semantic web. In: Shi ZZ, Sadananda R, editors. Agent Computing and Multi-Agent Systems. Springer Berlin Heidelberg. 211–219.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang3"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>KJ</given-names></name> (<year>2008</year>) <article-title>Reputation-oriented trustworthy computing in e-commerce environments</article-title>. <source>IEEE Internet Comput</source> <volume>12(4)</volume>: <fpage>55</fpage>–<lpage>59</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang4"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Evolution of public cooperation on interdependent networks: The impact of biased utility functions</article-title>. <source>Europhys Lett</source> <volume>97(4)</volume>: <fpage>48001</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang5"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Percolation threshold determines the optimal population density for public cooperation</article-title>. <source>Phys Rev E</source> <volume>85(3)</volume>: <fpage>037101</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang6"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>If players are sparse social dilemmas are too: Importance of percolation for evolution of cooperation</article-title>. <source>Sci Rep</source> <volume>2(369)</volume>: <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Bromley1"><label>27</label>
<mixed-citation publication-type="book" xlink:type="simple">Bromley DB (1993) <italic>Reputation, image and impression management</italic>. New Jersey: John Wiley &amp; Sons. 312 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Kreps1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kreps</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>R</given-names></name> (<year>1982</year>) <article-title>Reputation and imperfect information</article-title>. <source>J Econ Theory</source> <volume>27(2)</volume>: <fpage>253</fpage>–<lpage>279</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Adler1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adler</surname><given-names>E</given-names></name> (<year>1992</year>) <article-title>The emergence of cooperation: national epistemic communities and the international evolution of the idea of nuclear arms control</article-title>. <source>International Organization</source> <volume>46(1)</volume>: <fpage>101</fpage>–<lpage>145</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Arnold1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arnold</surname><given-names>R</given-names></name> (<year>1987</year>) <article-title>The evolution of cooperation</article-title>. <source>The Review of Austrian Economics</source> <volume>1(1)</volume>: <fpage>227</fpage>–<lpage>229</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Aronson1"><label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">Aronson E, Wilson TD, Akert RM (2010) <italic>Social psychology</italic> (7th Ed.). London: Pearson. 624 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Leimar1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leimar</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Hammerstein</surname><given-names>P</given-names></name> (<year>2001</year>) <article-title>Evolution of cooperation through indirect reciprocity. Proc. R. Soc</article-title>. <source>B</source> <volume>268(1468)</volume>: <fpage>745</fpage>–<lpage>753</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Maskin1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Maskin E (2009) Evolution, cooperation, and repeated games. In: Levin SA, editors. Games, Groups, and the Global Good. Springer Berlin Heidelberg. 79–84.</mixed-citation>
</ref>
<ref id="pone.0099841-Sachs1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sachs</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Mueller</surname><given-names>UG</given-names></name>, <name name-style="western"><surname>Wilcox</surname><given-names>TP</given-names></name>, <name name-style="western"><surname>Bull</surname><given-names>JJ</given-names></name> (<year>2004</year>) <article-title>The evolution of cooperation</article-title>. <source>Q Rev Biol</source> <volume>79(2)</volume>: <fpage>135</fpage>–<lpage>160</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Baumeister1"><label>35</label>
<mixed-citation publication-type="book" xlink:type="simple">Baumeister RF (1999) <italic>The self in social psychology</italic>. Hove: Psychology Press. 492 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Peacocke1"><label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">Peacocke C (2009) Mental action and self-awareness (II): Epistemology. In O’Brien L, Soteriou M, editors. <italic>Mental Actions</italic>. Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pone.0099841-Phillips1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Phillips</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Silvia</surname><given-names>PJ</given-names></name> (<year>2005</year>) <article-title>Self-awareness and the emotional consequences of self-discrepancies</article-title>. <source>Pers Soc Psychol Bull</source> <volume>31(5)</volume>: <fpage>703</fpage>–<lpage>713</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Carver1"><label>38</label>
<mixed-citation publication-type="book" xlink:type="simple">Carver CS, Scheier MF (1981) Attention and self-regulation: A control-theory approach to human behavior. New York: Springer-Verlag. 403 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Noe1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Noe</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ferri</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Caballero</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Villodre</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sanchez</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Self-awareness after acquired brain injury</article-title>. <source>J Neurol</source> <volume>252(2)</volume>: <fpage>168</fpage>–<lpage>175</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Russell1"><label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">Russell S, Norvig P (2009) <italic>Artificial intelligence: A modern approach (3rd Ed.)</italic>. New Jersey: Prentice Hall. 1152 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Sutton1"><label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">Sutton RS, Barto AG (1998) <italic>Introduction to reinforcement learning</italic>. Massachusetts: MIT Press. 342 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Mitchell1"><label>42</label>
<mixed-citation publication-type="book" xlink:type="simple">Mitchell TM (1997) <italic>Machine learning</italic>, Massachusetts: McGraw-Hill. 432 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Mitchell2"><label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">Mitchell M (1998) <italic>An introduction to genetic algorithms</italic>. Massachusetts: MIT Press. 221 p.</mixed-citation>
</ref>
<ref id="pone.0099841-Dobbyn1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dobbyn</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Stuart</surname><given-names>S</given-names></name> (<year>2003</year>) <article-title>The self as an embedded agent</article-title>. <source>Minds and Machines</source> <volume>13(2)</volume>: <fpage>187</fpage>–<lpage>201</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Huang1"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Huang CY, Sun CT (2004) Parameter adaptation within co-adaptive learning classifier systems. Proceedings of the 6th Annual Genetic and Evolutionary Computation Conference, Washington, USA, 774–784.</mixed-citation>
</ref>
<ref id="pone.0099841-Kawamura1"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Kawamura K, Noelle DC, Hambuchen KA, Rogers TE, Turkay E (2003) A multi-agent approach to self-reflection for cognitive robotics. Proceedings of the 11th International Conference on Advanced Robotics, Coimbra, Portugal, 568–575.</mixed-citation>
</ref>
<ref id="pone.0099841-Markus1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markus</surname><given-names>H</given-names></name> (<year>1977</year>) <article-title>Self-schemata and processing information about the self</article-title>. <source>J Pers Soc Psychol</source> <volume>35(2)</volume>: <fpage>63</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Liu1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Win-stay-lose-learn promotes cooperation in the spatial prisoner’s dilemma game</article-title>. <source>PLoS One</source> <volume>7(2)</volume>: <fpage>e30689</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Nowak2"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>May</surname><given-names>RM</given-names></name> (<year>1993</year>) <article-title>The spatial dilemmas of evolution</article-title>. <source>Int J Bifurcat Chaos</source> <volume>3(1)</volume>: <fpage>35</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Perc1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Coevolutionary games–a mini review</article-title>. <source>BioSystems</source> <volume>99(2)</volume>: <fpage>109</fpage>–<lpage>125</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Santos1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Santos</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>Pacheco</surname><given-names>JM</given-names></name> (<year>2005</year>) <article-title>Scale-free networks provide a unifying framework for the emergence of cooperation</article-title>. <source>Phys Rev Lett</source> <volume>95(9)</volume>: <fpage>098104</fpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang7"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Interdependent network reciprocity in evolutionary games</article-title>. <source>Sci Rep</source> <volume>3(1183)</volume>: <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang8"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Optimal interdependence between networks for the evolution of cooperation</article-title>. <source>Sci Rep</source> <volume>3(2470)</volume>: <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pone.0099841-Wang9"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2014</year>) <article-title>Rewarding evolutionary fitness with links between populations promotes cooperation</article-title>. <source>J Theor Biol</source> <volume>349</volume>: <fpage>50</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>