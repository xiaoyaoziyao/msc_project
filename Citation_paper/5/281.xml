<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="pmc">plosone</journal-id>
      <journal-title-group>
        <journal-title>PLoS ONE</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1932-6203</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PONE-D-12-38643</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pone.0056016</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Evolutionary modeling</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Evolutionary biology</subject>
            <subj-group>
              <subject>Evolutionary processes</subject>
              <subj-group>
                <subject>Coevolution</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Evolutionary theory</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Computer modeling</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied mathematics</subject>
            <subj-group>
              <subject>Game theory</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Decision theory</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Physics</subject>
          <subj-group>
            <subject>Interdisciplinary physics</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Behavior</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Computer Science</subject>
          <subject>Evolutionary Biology</subject>
          <subject>Physics</subject>
          <subject>Mathematics</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Short Versus Long Term Benefits and the Evolution of Cooperation in the Prisoner's Dilemma Game</article-title>
        <alt-title alt-title-type="running-head">Time Horizons and the Evolution of Cooperation</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Brede</surname>
            <given-names>Markus</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line>Department of Electronics and Computer Science, University of Southampton, Southampton, Hampshire, United Kingdom</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Perc</surname>
            <given-names>Matjaz</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>University of Maribor, Slovenia</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">Brede.Markus@gmail.com</email></corresp>
        <fn fn-type="conflict">
          <p>The author has declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: MB. Performed the experiments: MB. Analyzed the data: MB. Contributed reagents/materials/analysis tools: MB. Wrote the paper: MB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>11</day>
        <month>2</month>
        <year>2013</year>
      </pub-date>
      <volume>8</volume>
      <issue>2</issue>
      <elocation-id>e56016</elocation-id>
      <history>
        <date date-type="received">
          <day>12</day>
          <month>12</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>9</day>
          <month>1</month>
          <year>2013</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Brede</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>In this paper I investigate the evolution of cooperation in the prisoner's dilemma when individuals change their strategies subject to performance evaluation of their neighbours over variable time horizons. In the monochrome setting, in which all agents per default share the same performance evaluation rule, weighing past events strongly dramatically enhances the prevalence of cooperators. For co-evolutionary models, in which evaluation time horizons and strategies can co-evolve, I demonstrate that cooperation naturally associates with long-term evaluation of others while defection is typically paired with very short time horizons. Moreover, considering the continuous spectrum in between enhanced and discounted weights of past performance, cooperation is optimally supported when cooperators neither give enhanced weight to past nor more recent events, but simply average payoffs. Payoff averaging is also found to emerge as the dominant strategy for cooperators in co-evolutionary models, thus proposing a natural route to the evolution of cooperation in viscous populations.</p>
      </abstract>
      <funding-group>
        <funding-statement>The author has no support or funding to report.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="9"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Altruism is a widely observed phenomenon in the social sciences, biology and economics and one might even argue that it is the fundamental characteristics that holds human society together. Its emergence and sustainability in populations of self-interested agents is conveniently modelled in the framework of evolutionary game theory <xref ref-type="bibr" rid="pone.0056016-Weibull1">[1]</xref>. Among with public goods games and the snowdrift game, the probably most widely studied example in the field is the prisoner's dilemma game, describing the simultaneous decision making of two individuals in a conflict situation, in which two options typically labelled “C” (for cooperate) and (“D”) for defect are available. Depending on the mutual choices, agents receive a payoff of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e001" xlink:type="simple"/></inline-formula> for mutual cooperation, defect against cooperate receives <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e002" xlink:type="simple"/></inline-formula> vs. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e003" xlink:type="simple"/></inline-formula> for the cooperator, and the payoff for mutual defection is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e004" xlink:type="simple"/></inline-formula>. In the prisoner's dilemma these payoffs are ranked <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e005" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e006" xlink:type="simple"/></inline-formula>, such that independent of the opponent's strategy defection always yields a higher payoff than cooperation. In contrast, mutual cooperation yields the highest combined payoff for the group. This raises the question: How can maximum group outcomes be achieved even though it is beneficial for the individual to defect?</p>
      <p>Many previous works have addressed this question in various contexts. Nowak <xref ref-type="bibr" rid="pone.0056016-Nowak1">[2]</xref> classifies possibile solutions into five categories, amongst which are mechanisms like kin selection, group selection, direct and indirect reciprocity and network reciprocity. Starting with studies of spatial graphs <xref ref-type="bibr" rid="pone.0056016-Nowak2">[3]</xref> which have later been extended to small world <xref ref-type="bibr" rid="pone.0056016-Abramson1">[4]</xref> and scale-free networks <xref ref-type="bibr" rid="pone.0056016-Santos1">[5]</xref> particularly the latter has found much interest in the literature in recent years, see <xref ref-type="bibr" rid="pone.0056016-Hauert1">[6]</xref>–<xref ref-type="bibr" rid="pone.0056016-Perc1">[8]</xref> for reviews. Network reciprocity describes a “viscous” population, i.e. a situation in which individuals can only interact with a fixed set of partners and not with the whole group. Cooperation can survive to some extent, because cooperators can positively assort, thus shielding themselves from invasions of defectors. In spite of this, in the asynchronous model with probabilistic updating on spatial lattices only very limited propertions of cooperators can survive.</p>
      <p>Cooperation through network reciprocity can be further supported by opponent selection mechanisms that enhance the shielding of clusters of cooperators <xref ref-type="bibr" rid="pone.0056016-Cao1">[9]</xref>, <xref ref-type="bibr" rid="pone.0056016-Brede1">[10]</xref> or by including various forms of heterogeneity into the models. Some such examples of cooperation supporting heterogeneity are network heterogeneity <xref ref-type="bibr" rid="pone.0056016-Abramson1">[4]</xref>, <xref ref-type="bibr" rid="pone.0056016-Santos1">[5]</xref>, <xref ref-type="bibr" rid="pone.0056016-Masuda1">[11]</xref> payoff noise <xref ref-type="bibr" rid="pone.0056016-Perc2">[12]</xref>, <xref ref-type="bibr" rid="pone.0056016-Tanimoto1">[13]</xref>, quenched noise in payoffs <xref ref-type="bibr" rid="pone.0056016-Perc3">[14]</xref>, and various forms of unevenness in strategy pass, like learning and teaching <xref ref-type="bibr" rid="pone.0056016-Szolnoki1">[15]</xref>, aspirations <xref ref-type="bibr" rid="pone.0056016-Wang1">[16]</xref>, <xref ref-type="bibr" rid="pone.0056016-Perc4">[17]</xref> or others <xref ref-type="bibr" rid="pone.0056016-Brede2">[18]</xref>.</p>
      <p>Over the last couple of years the focus in the field has increasingly shifted to co-evolutionary models, see <xref ref-type="bibr" rid="pone.0056016-Perc1">[8]</xref> for a review. In these models an evolution of individual-specific traits at a timescale comparable to the timescale of the spread of game strategies is considered. Examples are studies on co-evolving networks <xref ref-type="bibr" rid="pone.0056016-Zimmermann1">[19]</xref>–<xref ref-type="bibr" rid="pone.0056016-VanSegbroeck1">[21]</xref>, but more recently also investigations of co-evolving noise levels <xref ref-type="bibr" rid="pone.0056016-Szolnoki2">[22]</xref>, aspirations <xref ref-type="bibr" rid="pone.0056016-Perc4">[17]</xref>, learning and teaching <xref ref-type="bibr" rid="pone.0056016-Szolnoki3">[23]</xref>, <xref ref-type="bibr" rid="pone.0056016-Tanimoto2">[24]</xref> or co-evolving update rules <xref ref-type="bibr" rid="pone.0056016-Moyano1">[25]</xref>, which have served as a major inspiration for the present paper.</p>
      <p>Recently, Chadefaux and Helbing <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref> proposed a mechanism of wealth accumulation to support cooperation. In their model wealth is created endogenously from game interactions. Agents accumulate payoffs indefinetely by playing games with stakes that are proportional to an agent's accumulated wealth. The authors report that cooperation is maximally supported when agents risk their entire wealth in every encounter whereas support for cooperation is rather low when small proportions of wealth are at stake. Risking a fixed stake of payoff in every encounter allows for an over-exponential growth of total wealth between cooperators and the study thus links wealth accumulation to (extremely) uneven endogenously created distributions of payoff and wealth.</p>
      <p>In many ways <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref> is also the starting point of this paper. I propose a model in which agents consider differently weighted accumulated (and suitably normalized) payoffs of their opponents as the basis of decisions for strategy adoption. Suitable normalization of payoffs and constant payoffs in the game exclude the mechanism of wealth heterogeneity described in <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref> as the mechanism responsible for cooperation.</p>
      <p>A weighting scheme of past and present payoff can be regarded as an agent's perspective on performance evaluation. I then proceed by considering prespectives and game strategies as co-evolutionary: agents can adopt their neighbours' game strategies (cooperate or defect), but can also adapt their perspective, i.e. the rule through which they evaluate a neighbour's success.</p>
      <p>Specifically, I aim to answer two questions in this paper: (i) is the supporting effect of accumulation necessarily related to unevenness in wealth (or fitness)? and (ii): what is the influence of different ways to weigh past and present payoffs on cooperation? Can agent's perspectives and strategies co-evolve in such a way that cooperation is supported? After explaining the details of the model, I proceed to address the first question in the next section. Following from this, the co-evolution of strategies and perspectives is investigated and the results are summarized and discussed in the context of the literature in the concluding section.</p>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <p>More specifically, I consider a set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e007" xlink:type="simple"/></inline-formula> agents which are located on a spatial lattice with von Neumann neighbourhoods. Agents are engaged in a prisoner's dilemma game with their nearest spatial neighbours and can play either one of two pure strategies: cooperate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e008" xlink:type="simple"/></inline-formula>) or defect (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e009" xlink:type="simple"/></inline-formula>). I follow a large portion of the literature and parameterize the game via<disp-formula id="pone.0056016.e010"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0056016.e010" xlink:type="simple"/><label>(1)</label></disp-formula>thus leaving parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e011" xlink:type="simple"/></inline-formula> to control the dilemma strength. As usual, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e012" xlink:type="simple"/></inline-formula> the dilemma setting is weak and for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e013" xlink:type="simple"/></inline-formula> cose to one the strongest conflict between individual and group interests is found.</p>
      <p>In every round of the evolutionary game, a randomly picked focus agent, say <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e014" xlink:type="simple"/></inline-formula>, and a randomly selected neighbour, say <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e015" xlink:type="simple"/></inline-formula>, of the focus agent play a one-off prisoner's dilemma game against each of their respective neighbours. This determines their instantaneous payoffs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e016" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e017" xlink:type="simple"/></inline-formula>. In a next step, the focus agent can adapt its strategy. This is modelled in the typical way how imitation dynamics are represented in evolutionary games, i.e. agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e018" xlink:type="simple"/></inline-formula> will adopt the strategy of agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e019" xlink:type="simple"/></inline-formula> according to a probabilistic rule <xref ref-type="bibr" rid="pone.0056016-Szab2">[27]</xref><disp-formula id="pone.0056016.e020"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0056016.e020" xlink:type="simple"/><label>(2)</label></disp-formula>where the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e021" xlink:type="simple"/></inline-formula> gives the noise in the strategy updating process. Thus, agents will typically adopt strategies of neighbours whose performance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e022" xlink:type="simple"/></inline-formula> they value more highly than their own. Performance in the game is evaluated over a time horizon of the last <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e023" xlink:type="simple"/></inline-formula> game interactions according to differently weighted current and past payoffs via<disp-formula id="pone.0056016.e024"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0056016.e024" xlink:type="simple"/><label>(3)</label></disp-formula>In <xref ref-type="disp-formula" rid="pone.0056016.e024">equation (3)</xref> the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e025" xlink:type="simple"/></inline-formula> represents a discount/interest rate of past interactions. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e026" xlink:type="simple"/></inline-formula> a player's evaluation time horizon is effectively shorter than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e027" xlink:type="simple"/></inline-formula> and the effect of past game outcomes on the performance measure is low. Contrariwise, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e028" xlink:type="simple"/></inline-formula> corresponds to a strongly weighted past such that performance is mainly determined by the past and the influence of the latest game interactions of a player is negligible. The limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e029" xlink:type="simple"/></inline-formula> corresponds to a simple average that neither discounts nor exaggerates past events. Also note the normalization factor in <xref ref-type="disp-formula" rid="pone.0056016.e024">Eq. (3)</xref> which ensures <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e030" xlink:type="simple"/></inline-formula>, thus allowing the consistent treatment of noise in strategy propagation.</p>
      <p>There are two straightforward interpretations of the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e031" xlink:type="simple"/></inline-formula>. First, one can assume that the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e032" xlink:type="simple"/></inline-formula> is determined externally and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e033" xlink:type="simple"/></inline-formula> is more or less equal for all agents. In the limit of low noise values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e034" xlink:type="simple"/></inline-formula> this case corresponds to a biological scenario similar to the model of wealth accumulation described in <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref> (but notice the important difference that the agent's stakes in the game are independent of payoff in the present model!). Agents accumulate payoff over some time horizon given by the discount rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e035" xlink:type="simple"/></inline-formula> after which they can replicate. The success of their game strategies is only evaluated at this point in time. Importantly, the typical number of game interactions before payoffs are evaluated is given by the discount factor. Realistic scenarios are such with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e036" xlink:type="simple"/></inline-formula> describing growth subject to depreciation, but also <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e037" xlink:type="simple"/></inline-formula> might be realistic for some organisms for which events in early life are very important to determine later fitness. The scenario of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e038" xlink:type="simple"/></inline-formula> might also be interpreted as a growth process subject to decay at rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e039" xlink:type="simple"/></inline-formula>, e.g.<disp-formula id="pone.0056016.e040"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0056016.e040" xlink:type="simple"/><label>(4)</label></disp-formula>and strategy spread or replication which occurs at timescales much longer than those of the growth process.</p>
      <p>The second interpretation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e041" xlink:type="simple"/></inline-formula> is that it reflects an agents' perspective. As such it would have to be considered as agent-specific. Agents with low <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e042" xlink:type="simple"/></inline-formula> are short-termers: they will adopt strategies from others who did better than themselves in the last interaction. Agents with larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e043" xlink:type="simple"/></inline-formula> increasingly base their evaluation on past as well as on present behaviour and agents with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e044" xlink:type="simple"/></inline-formula> are agents that value past interactions more highly than present ones. In this setting it is natural to consider a scenario in which agents can change their perspectives as well as their game strategies. Realistically, perspective changes will occur at a slower timescale than game strategy adaptations.</p>
      <p>In the first interpretation, to which I refer as monochrome models, the discount factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e045" xlink:type="simple"/></inline-formula> is externally set to an equal value for all agents in the game. In this setting, with a probability given by <xref ref-type="disp-formula" rid="pone.0056016.e024">equation (3)</xref> the focus agent will only adopt the reference agent's game strategy when updating. In the second setting, that I refer to as co-evolutionary, agents will adapt their game strategies as well as their perspectives, both occuring with the probability given by <xref ref-type="disp-formula" rid="pone.0056016.e024">Eq. (3)</xref>.</p>
      <p>In more detail, simulation experiments are carried out on lattices of varying sizes according to the following rules</p>
      <list list-type="bullet">
        <list-item>
          <p>Start with a random allocation of strategies to sites such that 50% of agents are cooperators and 50% are defectors. For every agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e046" xlink:type="simple"/></inline-formula> the entire payoff histories <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e047" xlink:type="simple"/></inline-formula> are set to the payoffs achieved in the initial population.</p>
        </list-item>
        <list-item>
          <p>In an asynchronous updating procedure, a focus agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e048" xlink:type="simple"/></inline-formula> and a reference agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e049" xlink:type="simple"/></inline-formula> are selected and their respective current payoffs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e050" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e051" xlink:type="simple"/></inline-formula> are determined and stored in their payoff histories. Only payoffs over the last <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e052" xlink:type="simple"/></inline-formula> timesteps are stored and any information about past payoff beyond this is not taken into account.</p>
        </list-item>
        <list-item>
          <p>The performance measures <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e053" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e054" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e055" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e056" xlink:type="simple"/></inline-formula> according to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e057" xlink:type="simple"/></inline-formula>'s perspective are determined. With probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e058" xlink:type="simple"/></inline-formula> agent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e059" xlink:type="simple"/></inline-formula> adopts the strategy (and possibly perspective) of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e060" xlink:type="simple"/></inline-formula>.</p>
        </list-item>
        <list-item>
          <p>Iterate steps (ii) and (iii) over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e061" xlink:type="simple"/></inline-formula> sweeps over the full lattice until a quasistationary state has been reached and then average statistics over another <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e062" xlink:type="simple"/></inline-formula> sweeps to determine the stationary number of cooperators <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e063" xlink:type="simple"/></inline-formula>.</p>
        </list-item>
      </list>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>The case of monochrome discounting</title>
        <p>In this section I will consider the case that all agents share the same interest/discount parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e064" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pone-0056016-g001">Figure 1</xref> shows a typical trajectory for the evolution of cooperation in a tough dilemma situation (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e065" xlink:type="simple"/></inline-formula>) when strategy spread is influenced by memory of past payoffs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e066" xlink:type="simple"/></inline-formula>). Illustrations of typical arrangements of cooperators and defectors at the various stages of the evolution are given in <xref ref-type="fig" rid="pone-0056016-g002">Fig. 2</xref>. Starting with a random allocation of cooperators and defectors, the evolution follows the known pattern: defectors can earn the highest payoffs in random arrangements and consequently they spread over a large part of the lattice, such that only little pockets of cooperators remain. Once an ordered arrangement of cooperators and defectors has been reached, clusters of cooperators may start to expand again until an equilibrium between cooperators and defectors is reached.</p>
        <fig id="pone-0056016-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Evolution of the concentration of cooperators over time.</title>
            <p>Parameter choices are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e067" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e068" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e069" xlink:type="simple"/></inline-formula> and simulations were performed on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e070" xlink:type="simple"/></inline-formula> lattice. Trajectories are averaged over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e071" xlink:type="simple"/></inline-formula> runs, dashed lines indicate two times the standard deviation.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g001" position="float" xlink:type="simple"/>
        </fig>
        <fig id="pone-0056016-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Snapshots of agent configurations on a</title>
            <p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e072" xlink:type="simple"/></inline-formula> <bold>lattice.</bold> The snapshots were taken after <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e073" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e074" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e075" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e076" xlink:type="simple"/></inline-formula> full update sweeps. Parameters are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e077" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e078" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e079" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g002" position="float" xlink:type="simple"/>
        </fig>
        <p>Crucially, however, when strategy spread is based on the immediately preceding payoff earnings, coexistence equilibria between cooperators and defectors are only possible for very weak dilemma strengths. This case corresponds to a discount rate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e080" xlink:type="simple"/></inline-formula> in my parameterization. For the noise level and neighbourhood specifications used in the above simulations, a second order phase transition is found at a critical value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e081" xlink:type="simple"/></inline-formula>. This transition belongs to the universality class of directed percolation <xref ref-type="bibr" rid="pone.0056016-Hauert1">[6]</xref>, <xref ref-type="bibr" rid="pone.0056016-Szab2">[27]</xref>. In typical simulations based on updating of recent payoffs (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e082" xlink:type="simple"/></inline-formula>) this critical dilemma strength at which cooperators go extinct is found at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e083" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0056016-Hauert1">[6]</xref>. In stark contrast, the simulations illustrated in the panels of <xref ref-type="fig" rid="pone-0056016-g001">Figs 1</xref> and <xref ref-type="fig" rid="pone-0056016-g002">2</xref> indicate that if updating takes account of past game outcomes, cooperation can survive for much larger dilemma strengths than expected.</p>
        <p>By presenting a more thorough investigation of phase boundaries, the panels of <xref ref-type="fig" rid="pone-0056016-g003">figure 3</xref> reinforce this point. The data illustrate that the support for cooperation grows systematically, when more and more emphasis is placed on the evaluation of past payoffs. A more detailed analysis of the phase transitions where cooperation or defection die out is given in the bottom panel of the figure. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e084" xlink:type="simple"/></inline-formula> cooperation dies out and defection dominates, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e085" xlink:type="simple"/></inline-formula> cooperation dominates and in between for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e086" xlink:type="simple"/></inline-formula> mixed equilibria of cooperators and defectors are possible (cf. the regions labelled “C”, “D”, and “C+D” in <xref ref-type="fig" rid="pone-0056016-g003">Fig. 3</xref>). The detailed analysis of the phase transitions reveals that for choices of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e087" xlink:type="simple"/></inline-formula> slightly greater than one, cooperation can even dominate over the entire range of dilemma strength, thus resolving the dilemma in any situation!</p>
        <fig id="pone-0056016-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Dependence of the frequency of cooperation on the dilemma strength.</title>
            <p>(left) Dependence of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e088" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e089" xlink:type="simple"/></inline-formula> for various values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e090" xlink:type="simple"/></inline-formula> (see legend) for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e091" xlink:type="simple"/></inline-formula> on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e092" xlink:type="simple"/></inline-formula> square lattice. (right) Phase diagram depicting the extinction threshold of cooperation (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e093" xlink:type="simple"/></inline-formula>) and the extinction threshold of defection (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e094" xlink:type="simple"/></inline-formula>) depending on the timescale of payoff evaluation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e095" xlink:type="simple"/></inline-formula> for a square lattice with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e096" xlink:type="simple"/></inline-formula>. Error bars are smaller than the size of the symbols. Notice, that cooperation can always dominate if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e097" xlink:type="simple"/></inline-formula> is slightly larger than one.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g003" position="float" xlink:type="simple"/>
        </fig>
        <p>What is the reason for the strong support for cooperation from the evaluation of past payoff? To understand this, consider a defector at the boundary of a cluster of cooperators. In a typical configuration, such a defector exploits a number of cooperators at the cluster's boundary and thus achieves a larger payoff than most cooperators in its neighbourhood. However, discounting payoff essentially introduces a delay between the start of the exploitation of the cooperators by the defector at the boundary and the time when this exploitation becomes visible in the payoff histories. Hence, there is a period of time during which the effective performances of the cooperators at the boundary appear superior due to good past payoff results (when they were still surrounded by cooperators) and thus, even though a boundary defector may have obtained larger payoffs in the recent past, it cannot immediately invade surrounding cooperators. Clearly, this delay slows down the spread of defectors and thus promotes the spread of cooperators. The delay until most recent payoffs become effective in agent's performances is related to the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e098" xlink:type="simple"/></inline-formula>. Larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e099" xlink:type="simple"/></inline-formula> implies a longer delay. Hence, following this argument one also expects that the support for cooperation grows with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e100" xlink:type="simple"/></inline-formula> which is corroborated by simulation results, cf. <xref ref-type="fig" rid="pone-0056016-g003">Fig. 3</xref>.</p>
        <p>If one follows the interpretation of discounting as a rate of depreciation in a growth process, the above result demonstrates a remarkably strong enhancement of network reciprocity if updating is based on a measure that combines current and past payoff. This support becomes the larger the more emphasis is put on payoff events farther in the past. However, already close to equally weighing past and current payoff can allow the dominance of cooperation over the entire range of dilemma strengths.</p>
        <p>It is also worthwhile to emphasise that this support for cooperation is achieved without the extreme wealth heterogeneity that is fundamental to cooperation in the model of <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref>. In the present model the stakes in the game are independent of past success and wealth distributions of cooperators and defectors are the same as in the typical evolutionary prisoner's dilemma game on a square lattice.</p>
        <p>If one follows the second interpretation of discounting as a subjective performance measure of individuals, the above results immediately raises the question if perspectives that support cooperation are evolutionarily stable. In other words, can low discounting survive or even dominate in a population of self interested agents? I address this question in the next section.</p>
      </sec>
      <sec id="s3b">
        <title>Co-evolution of cooperation and perspectives</title>
        <sec id="s3b1">
          <title>Continuously varying perspectives</title>
          <p>In this section I consider a model in which agents can inherit the perspective of the reference agent when adopting its game strategy. As before, simulations are initialized with random allocations of 50% cooperators and 50% defectors, but now agents are also assigned a perspective <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e101" xlink:type="simple"/></inline-formula> chosen from a uniform distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e102" xlink:type="simple"/></inline-formula>. To account for mutations, in some cases perspectives are slightly modified when they are adopted. Technically, this is implemented as a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e103" xlink:type="simple"/></inline-formula> chance that a small random number from the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e104" xlink:type="simple"/></inline-formula> is added to the adopted perspective. Boundary conditions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e105" xlink:type="simple"/></inline-formula> are strictly enforced in this process. Furthermore, I also consider the role of mutations when strategies are passed on between agents. In such a case, with a small rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e106" xlink:type="simple"/></inline-formula>, agents adopt a randomly selected game strategy and a randomly selected new perspective.</p>
          <p>By recording stationary distributions of perspectives (top) and giving statistics of the frequencies with which agents with a certain perspective are cooperators (bottom), <xref ref-type="fig" rid="pone-0056016-g004">figure 4</xref> summarizes typical simulation outcomes on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e107" xlink:type="simple"/></inline-formula> torus for situations with and without mutations. In both cases, a clear separation of agents into two groups becomes apparent. One peak of the bimodal distribution of perspectives corresponds to agents who almost always defect, the second to agents who almost always cooperate (cf. bottom panels of <xref ref-type="fig" rid="pone-0056016-g004">Fig. 4</xref>).</p>
          <fig id="pone-0056016-g004" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g004</object-id>
            <label>Figure 4</label>
            <caption>
              <title>An illustration of the stationary states in the co-evolution of perspectives and strategies.</title>
              <p>The panels give distribitions of evolved perspectives (top) and the dependence of the average frequency of cooperators on perspectives (bottom). The figures show results from simulations on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e108" xlink:type="simple"/></inline-formula> torus with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e109" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e110" xlink:type="simple"/></inline-formula>. In the right hand panels a small chance (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e111" xlink:type="simple"/></inline-formula>) of misperception when adopting another agent's strategies is included. In case of a misperception, an agent adopts the opposite of the game strategy of the reference agent and chooses a new perspective uniformly at random from the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e112" xlink:type="simple"/></inline-formula>. Without misperceptions around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e113" xlink:type="simple"/></inline-formula> of agents are cooperators, with misperceptions only around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e114" xlink:type="simple"/></inline-formula> are cooperators.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g004" position="float" xlink:type="simple"/>
          </fig>
          <p>If mutations are included, the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e115" xlink:type="simple"/></inline-formula>-values for defectors becomes much broader and a further distinction between two classes of defectors becomes apparent. Agents with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e116" xlink:type="simple"/></inline-formula> are almost always defectors, whereas agents with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e117" xlink:type="simple"/></inline-formula> tend to be defectors, but have an around 15% chance of being a cooperator.</p>
          <p>Further experiments for changing levels of noise in strategy propagation demonstrate that the location of the defector peak at around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e118" xlink:type="simple"/></inline-formula> is an artifact of the level of noise in strategy propagation. In fact, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e119" xlink:type="simple"/></inline-formula> one finds a much sharper first defector peak at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e120" xlink:type="simple"/></inline-formula>. Noise in strategy propagation and neutral drift of perspectives in the large areas of the lattice occupied by defectors then allow for the survival of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e121" xlink:type="simple"/></inline-formula> defectors.</p>
          <p>It is instructive to investigate a further extension of the model and allow memory lengths to co-evolve with strategies and perspectives. Since defectors make little use of past information, memory lengths of defectors are subject to random drift while memory lengths of cooperators keep increasing until the marginal benefit of further increases is counteracted by the noise level in strategy propagation. In real-world situations memory is often associated with a cost. Including such a cost per unit of time in memory, memory lengths of defectors quickly converge to zero. In contrast, memory lengths of cooperators reach an equilibrium at which the costs of memory balance the advantages for strategy spread. <xref ref-type="fig" rid="pone-0056016-g005">Figure 5</xref> illustrates data gleaned from simulation experiments with co-evolving memory lengths, perspectives, and game strategies. The first panel gives the dependence of stationary memory length of cooperators on costs, the second the corresponding stationary perspectives and the third the stationary densities of cooperators. In all shown cases a coexistence equilibrium of cooperators and defectors could be reached. This becomes impossible above some cost threshold, at which memory becomes too costly for cooperators to allow for meaningful long-term evaluation.</p>
          <fig id="pone-0056016-g005" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g005</object-id>
            <label>Figure 5</label>
            <caption>
              <title>Dependence of evolved memory lengths of cooperators, discount factors of cooperators, and density of cooperators on costs per unit of memory.</title>
              <p>The setup is the same as for the previous figure, but <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e122" xlink:type="simple"/></inline-formula>. Timescales are bounded by an upper limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e123" xlink:type="simple"/></inline-formula>, and simulations were performed on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e124" xlink:type="simple"/></inline-formula> torus using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e125" xlink:type="simple"/></inline-formula>.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g005" position="float" xlink:type="simple"/>
          </fig>
          <p>The above experiments give a clear indication that a consensus of perspectives in the population is not an evolutionarily stable outcome. Instead, defectors have a natural tendency to employ a short time perspective, whereas cooperators are natural long-term evaluators. Interestingly, however, the evolutionarily stable (and optimal as we will see in subsection) outcome for cooperators is not an overly strong emphasis on the past which was found to be a strong enhancer of cooperation in the monochrome case. Instead, perspectives of cooperators are stabilized at around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e126" xlink:type="simple"/></inline-formula> which corresponds to taking averages of past payoff.</p>
          <p>This distinction of optimal perspectives for cooperators and defectors can be understood by a simple argument. As argued in the previous subsection, defectors who evaluate past performances when updating strategy are affected by the delay between suboptimal immediate payoffs and when they become effective in payoff histories. In their perspective, cooperators at the boundary of a cluster of cooperators appear to have larger payoffs and hence they are likely to adopt the strategy of cooperators. In contrast, defectors who only evaluate short term payoffs are unaffected. Short term defectors perceive their payoffs as larger than those of boundary cooperators and cannot easily be invaded by them. However, in the view of long term cooperators, the payoffs of short term defectors at first also appear inferior and cooperators will not immediately adopt the defect strategy. This mismatch in perspectives delays the spread of defectors and gives support to cooperation, albeit not as much as for monochrome long term evaluation in a population.</p>
          <p>Why is averaging (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e127" xlink:type="simple"/></inline-formula>) the stable strategy for cooperators? I have argued before that longer time horizons are essential for cooperators to survive. What remains to be answered is why <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e128" xlink:type="simple"/></inline-formula> is not a stable perspective for cooperators. To understand this, note that clusters of cooperators are constantly in flux: they expand in some directions and shrink in others due to the invasion of defectors. Hence, cooperators are often surrounded by other cooperators, but might sometimes also be at the boundary and hence prone to exploitation by defectors. In case of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e129" xlink:type="simple"/></inline-formula>, such exploitation events in the past life of a cooperator can occasionally be exaggerated, thus making the cooperator prone to adopt the strategy of a defector. In contrast, averaging (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e130" xlink:type="simple"/></inline-formula>) prevents the impact of chance highlights of specific events in the payoff history and only cooperators who consistently happened to be at a boundary are prone to invasion of the defect strategy.</p>
        </sec>
        <sec id="s3b2">
          <title>Averaging in the face of short term defection: When can cooperation survive?</title>
          <p>In the previous subsection I have demonstrated that cooperators naturally align themselves with performance measures that average over time, whereas defectors tend to evaluate payoff at a very short term basis. This underlines that (in the absence of substantial levels of noise) perspectives in co-evolutionary models will fixate at only two distinct values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e131" xlink:type="simple"/></inline-formula>. For a systematic exploration of the sustainability of cooperation in the presence of two possible perspectives I consider a discrete model. Perspectives are co-evolutionary with strategies as before, but only two perspectives, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e132" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e133" xlink:type="simple"/></inline-formula> can be assumed.</p>
          <p><xref ref-type="fig" rid="pone-0056016-g006">Figures 6</xref> and <xref ref-type="fig" rid="pone-0056016-g007">7</xref> illustrate typical scenarios in the evolution of cooperation in the above case and several stages in the evolution can be discerned. Initially, long term horizons grow to dominance in both the cooperator and defector populations. In the first case this is the scenario described in the previous subsection. In the case of defectors, the initial long-term horizons are related to the initial payoff bonanza for defectors in random allocations of cooperators and defectors. Long time horizons dominate, because they can lock in a memory of the initially high payoffs reminiscent of the initial conditions. However, when simulation times approach the memory time horizon of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e134" xlink:type="simple"/></inline-formula>, this memory starts to fade and cooperators can invade the large areas of long term time horizon defectors. Pockets of short term defectors are the only defectors that eventually survive and a fluctuating steady state pattern of long term evaluating cooperators and short term evaluating defectors is approached.</p>
          <fig id="pone-0056016-g006" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g006</object-id>
            <label>Figure 6</label>
            <caption>
              <title>Snapshots of agent configurations illustrating the co-evolution of perspectives and strategies.</title>
              <p>The snapshots are taken after 3,20,40,70,100 and 1000 sweeps (left to right) with parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e135" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e136" xlink:type="simple"/></inline-formula>. Cooperators are blue, defectors red, darkness of the colour indicates perspective, dark indicates long term (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e137" xlink:type="simple"/></inline-formula>) and bright indicates short term (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e138" xlink:type="simple"/></inline-formula>. See <xref ref-type="fig" rid="pone-0056016-g007">fig. 7</xref> for averaged trajectories.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g006" position="float" xlink:type="simple"/>
          </fig>
          <fig id="pone-0056016-g007" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g007</object-id>
            <label>Figure 7</label>
            <caption>
              <title>Co-evolution of perspectives and cooperation for</title>
              <p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e139" xlink:type="simple"/></inline-formula><bold>,</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e140" xlink:type="simple"/></inline-formula> <bold>on a</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e141" xlink:type="simple"/></inline-formula> <bold>lattice.</bold> The lines give trajectories for the (i) average density of cooperators, (ii) average perspective of cooperators, and (ii) average perspective of defectors. Trajectories have been averaged over 100 simulation runs and the dotted lines give two times the standard deviation.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g007" position="float" xlink:type="simple"/>
          </fig>
          <p><xref ref-type="fig" rid="pone-0056016-g008">Figure 8</xref> gives data for the phase boundaries between cooperation and defection for the two perspective scenario. The first panel gives the dependence of equilibrium concentrations of cooperators on the dilemma strength for various choices of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e142" xlink:type="simple"/></inline-formula>. In no case can cooperators dominate the population (in contrast to the monochrome setting discussed previously), but coexistence equilibria of cooperators and defectors are still possible even for rather tough dilemma situations. The data clearly demonstrate that the support for cooperation is maximized very close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e143" xlink:type="simple"/></inline-formula>, i.e. the perspective that averages payoff. This finding is reinforced by an analysis of the extinction threshold for the mixed phase given in the bottom panel of <xref ref-type="fig" rid="pone-0056016-g008">Fig. 8</xref>. The extinction thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e144" xlink:type="simple"/></inline-formula> have a sharp peak around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e145" xlink:type="simple"/></inline-formula>. Exaggerating recent or past events in payoff histories strongly reduces support for cooperation and for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e146" xlink:type="simple"/></inline-formula> the extinction thresholds quickly approach the known phase boundary <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e147" xlink:type="simple"/></inline-formula> for spatial lattices with von Neumann neighbourhoods <xref ref-type="bibr" rid="pone.0056016-Hauert1">[6]</xref>.</p>
          <fig id="pone-0056016-g008" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g008</object-id>
            <label>Figure 8</label>
            <caption>
              <title>Dependence of cooperation on the dilemma strength when strategies and perspectives co-evolve.</title>
              <p>(left) Dependence of the fraction of cooperators on the dilemma strength <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e148" xlink:type="simple"/></inline-formula> for various values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e149" xlink:type="simple"/></inline-formula> (see legend) for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e150" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e151" xlink:type="simple"/></inline-formula> on a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e152" xlink:type="simple"/></inline-formula> square lattice. Notice, that the optimal perspective for cooperation is no longer the largest possible value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e153" xlink:type="simple"/></inline-formula> as in <xref ref-type="fig" rid="pone-0056016-g003">Fig. 3</xref>, but cooperation is maximized near <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e154" xlink:type="simple"/></inline-formula>. (right) Phase diagram depicting the extinction threshold of cooperation depending on the largest timescale of payoff evaluation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e155" xlink:type="simple"/></inline-formula> (while <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e156" xlink:type="simple"/></inline-formula>) for a square lattice with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e157" xlink:type="simple"/></inline-formula>. Error bars are smaller than the size of the symbols.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g008" position="float" xlink:type="simple"/>
          </fig>
          <p>We thus see that cooperation not only naturally associates with an ‘averaging’ perspective, but averaging is indeed also the perspective that maximizes support for cooperation. Strictly speaking, the above experiments only demonstrate this for competition between a long term perspective and basing performance on payoffs from the last game interaction (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e158" xlink:type="simple"/></inline-formula>). Some further experiments clarify the situation for competition between arbitrary perspectives, cf. the map plot of <xref ref-type="fig" rid="pone-0056016-g009">Fig. 9</xref>. These results clearly highlight that over a large range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e159" xlink:type="simple"/></inline-formula>) values cooperation is maximized when it can associate with averaging. In fact, this is always the case, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e160" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e161" xlink:type="simple"/></inline-formula>. Only if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e162" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e163" xlink:type="simple"/></inline-formula> the scenario described in the previous subsection applies. In this regime, cooperation grows the larger the value of delta.</p>
          <fig id="pone-0056016-g009" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g009</object-id>
            <label>Figure 9</label>
            <caption>
              <title>Dependence of cooperation on the choice of perspectives for</title>
              <p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e164" xlink:type="simple"/></inline-formula> <bold>and</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e165" xlink:type="simple"/></inline-formula> <bold>on a</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e166" xlink:type="simple"/></inline-formula> <bold>torus.</bold> Support for cooperation generally grows, the larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e167" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e168" xlink:type="simple"/></inline-formula>, but if one of the perspectives is smaller than one, cooperation is optimally supported if the other perspective averages payoff histories (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e169" xlink:type="simple"/></inline-formula>).</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g009" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s3b3">
          <title>Coupling between strategy and perspective pass</title>
          <p>In the previous subsection it has been assumed that game strategies and perspectives are passed on simultaneously when an agent imitates another. How important is this tight coupling between the passing on of strategy and perspective? To investigate this problem, a further modification of the original models is introduced. Now, if a focus agent decides to imitate a reference agent, game strategy and perspective are imitated probabilistically. Three situations need to be distinguished. In the first, with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e170" xlink:type="simple"/></inline-formula> the focus agent will only copy the game strategy of its reference. In the second, with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e171" xlink:type="simple"/></inline-formula> it will only copy its reference's perspective and in the remaining cases (i.e. with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e172" xlink:type="simple"/></inline-formula>) both, game strategy and perspective, are passed on. This description allows an exploration of the influence of the timescales of strategy and perspective spread as well as of the role of the coupling between strategy and perspective pass.</p>
          <p>Simulations have been carried out for an exhaustive exploration of the parameter space spanned by the probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e173" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e174" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e175" xlink:type="simple"/></inline-formula>. By giving the average prevalence of cooperators and average perspectives of cooperators and defectors, <xref ref-type="fig" rid="pone-0056016-g010">Figure 10</xref> visualizes the results. Two dilemma strengths are analysed in the figure, a very tough dilemma setting with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e176" xlink:type="simple"/></inline-formula> (top panels) and a lower setting with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e177" xlink:type="simple"/></inline-formula> (bottom panels). Three observations stand out.</p>
          <fig id="pone-0056016-g010" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pone.0056016.g010</object-id>
            <label>Figure 10</label>
            <caption>
              <title>Dependence of cooperation, average perspectives of cooperators and average perspectives of defectors (left to right) on evolutionary timescales.</title>
              <p>Simulations are for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e178" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e179" xlink:type="simple"/></inline-formula> (top) on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e180" xlink:type="simple"/></inline-formula> and for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e181" xlink:type="simple"/></inline-formula> (bottom). In the plots of average perspectives of cooperators and defectors black regions indicate the absence of cooperation or defection.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0056016.g010" position="float" xlink:type="simple"/>
          </fig>
          <p>First, tight coupling between game strategy pass and perspective pass (bottom right corner) impede the spread of cooperation. In this regime defectors can associate with short term evaluation and thus – by a mismatch of perspectives as argued before – inhibit the spread of cooperators. In the case of looser coupling in strategy and perspective pass, this association becomes less strict. Whereas surviving cooperators are still always associated with long-term evaluation, increasingly more long-term evaluating defectors exist. In a scenario of monochrome long-term perspectives, however, cooperation finds much more support, see section.</p>
          <p>Second, also very fast strategy pass does not benefit cooperation, because it slows down the spread of perspectives and thus allows the separation of typical perspectives of cooperators and defectors (see top corner in <xref ref-type="fig" rid="pone-0056016-g010">Fig. 10</xref>).</p>
          <p>The third observation from <xref ref-type="fig" rid="pone-0056016-g010">Fig. 10</xref> is that when rates of strategy pass are much slower than rates of perspective pass defection is favoured. To see this, recall that long-term evaluation benefits cooperation, because there is a delay between the start of the exploitation by defectors and the time when this exploitation becomes apparent in effective payoffs. During this time interval defectors are prone to invasion by cooperators, but cooperators are ‘protected’ from invasion by defectors through their payoff histories. Very slow game strategy pass reduces this advantage, since for the spread of game strategies payoff histories have an effective length of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0056016.e182" xlink:type="simple"/></inline-formula>. Hence the respective delay times become shorter. Incidentally, this also strongly increases the pressure towards an evolution of longer memory lengths if memory lengths are allowed to co-evolve with strategies.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>In this paper I have investigated the impact of performance evaluation subject to variable time horizons and different discounting schemes on the evolution of cooperation in the prisoner's dilemma. I demonstrate that accounting for past success when updating strategies can strongly influence network reciprocity. Support for cooperation by network reciprocity is found to grow, the stronger past payoffs are weighted when evaluating the performance of an agent in the game. The finding helps to disentangle the effects of wealth heterogeneity and payoff accumulation described in <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref>. The present model demonstrates that cooperation can be supported by an accumulation scheme without the endogenous generation of extremely uneven wealth distributions as in <xref ref-type="bibr" rid="pone.0056016-Chadefaux1">[26]</xref>. In some ways, one may see this as similar to the effect of a discrepancy between strategy adaptation speeds and game speeds described in <xref ref-type="bibr" rid="pone.0056016-Tanimoto3">[28]</xref> or the possibility that an inferior strategy with long memory can sometimes beat a superior strategy with short memory described in a somewhat different context in <xref ref-type="bibr" rid="pone.0056016-A1">[29]</xref>.</p>
      <p>More importantly, I have demonstrated that low discounting is not an evolutionarily stable strategy. In co-evoluationary settings, one typically finds that defectors associate with very short term evaluation rules whereas cooperators tend to be long term evaluators. The scenario is thus in some regards similar to an essential innovation in the model of <xref ref-type="bibr" rid="pone.0056016-VanSegbroeck1">[21]</xref>: even though agents engage in the same game they have the ability to perceive this game differently.</p>
      <p>The presence of short-term evaluating defectors destabilizes the arrangement of long-term evaluating cooperators. Due to the fluctuating nature of clusters of cooperators, very strong emphases on past payoffs are no longer the best evaluation rule for cooperators. Instead cooperation typically associates with averaging, i.e. equally weighing past and present game outcomes. Simulation experiments underline that averaging is the evolutionarily stable strategy for cooperation in the face of short term evaluating defection.</p>
      <p>Interestingly, the averaging performance evaluation rule also maximizes the support for cooperation in co-evolutionary settings. A careful investigation of phase boundaries shows that the co-evolution of performance evaluation rules and game strategies strongly reduces the support that cooperation can gain from long-term evaluation. Consequently, phases in which cooperation dominates the entire system are no longer possible on square lattices. However, mixed equilibria between short term defectors and averaging cooperators are still possible, extending the range of dilemma strengths in which cooperation can survive well beyound the extinction thresholds of cooperation in the standard setting <xref ref-type="bibr" rid="pone.0056016-Hauert1">[6]</xref>.</p>
      <p>The described separation of performance evaluation rules for cooperators and defectors is affected by the details of strategy and performance evaluation rule updating. Tight coupling in the spread of both traits as well as timescales for game strategy spread much faster than those of the spread of the performance evaluation rule favour this separation. One might argue that the latter corresponds to socially realistic situations when individuals change their behaviour at a timescale much faster than the timescale at which they modify their underlying belief set. The separation of performance evaluation rules between defectors and cooperators vanishes, if strategies and performance rules evolve at similar timescales and are inherited independent of each other.</p>
      <p>Even though the behavioural model investigated in this paper is extremely simple, it is tempting to speculate about the wider societal implications of the presented results. The present paper suggests that short term evaluation is a hallmark of defectors, i.e. behavioural strategies that benefit the individual at the cost of society. Inducements to base the evaluation of business leaders on long term performance have long been discussed in the media. The presented results seem to suggest that this would not only lead to a fairer society, but that it might also strengthen cooperative (i.e. group-benefitting) behaviour in society.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>The author acknowledges the use of the IRIDIS High Performance Computing Facility, and associated support services at the University of Southampton, in the completion of this work.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0056016-Weibull1">
        <label>1</label>
        <mixed-citation publication-type="other" xlink:type="simple">Weibull J (1996) Evolutionary game theory. Cambridge, MA: MIT University Press.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Nowak1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name> (<year>2006</year>) <article-title>Five rules for the evolution of cooperation</article-title>. <source>Science</source> <volume>314</volume>: <fpage>1560</fpage>–<lpage>1563</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Nowak2">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>M</surname><given-names>MR</given-names></name> (<year>1992</year>) <article-title>Evolutionary games and spatial chaos</article-title>. <source>Nature</source> <volume>359</volume>: <fpage>826</fpage>–<lpage>829</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Abramson1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abramson</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kuperman</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Social games in a social network</article-title>. <source>Phys Rev E</source> <volume>63</volume>: <fpage>030901</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Santos1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Santos</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>Rodrigues</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pacheco</surname><given-names>J</given-names></name> (<year>2006</year>) <article-title>Graph topology plays a determinant role in the evolution of cooperation</article-title>. <source>Proc R Soc B</source> <volume>273</volume>: <fpage>51</fpage>–<lpage>55</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Hauert1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hauert</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Szabó</surname><given-names>G</given-names></name> (<year>2004</year>) <article-title>Game theory and physics</article-title>. <source>Am J Phys</source> <volume>73</volume>: <fpage>405</fpage>–<lpage>414</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Szab1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szabó</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Fath</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Evolutionary games on graphs</article-title>. <source>Phys Rep</source> <volume>446</volume>: <fpage>97</fpage>–<lpage>216</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Perc1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Coevolutionary games - a mini review</article-title>. <source>BioSystems</source> <volume>99</volume>: <fpage>109</fpage>–<lpage>125</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Cao1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cao</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Ohtsuki</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kazuyuki</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Evolution of cooperation on adaptively weighted networks</article-title>. <source>J Theor Biol</source> <volume>272</volume>: <fpage>8</fpage>–<lpage>15</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Brede1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brede</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Playing against the fittest: A simple strategy that promotes the emergence of cooperation</article-title>. <source>EPL</source> <volume>94</volume>: <fpage>30003</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Masuda1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Masuda</surname><given-names>N</given-names></name> (<year>2007</year>) <article-title>Participation costs dismiss the advantage of heterogenous networks in the evolution of cooperation</article-title>. <source>Proc R Soc B</source> <volume>274</volume>: <fpage>1815</fpage>–<lpage>1821</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Perc2">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Coherence resonance in a spatial prisoner's dilemma game</article-title>. <source>New J Phys</source> <volume>8</volume>: <fpage>022</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Tanimoto1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tanimoto</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>Promotion of cooperation by payoff noise in a 2×2 game</article-title>. <source>Phys Rev E</source> <volume>76</volume>: <fpage>041130</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Perc3">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Social diversity and promotion of cooperation in the spatial prisoner's dilemma game</article-title>. <source>Phys Rev E</source> <volume>77</volume>: <fpage>011904</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Szolnoki1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Szabó</surname><given-names>G</given-names></name> (<year>2007</year>) <article-title>Cooperation enhanced by inhomogeneous activity of teaching for evolutionary prisoner's dilemma game</article-title>. <source>EPL</source> <volume>77</volume>: <fpage>30004</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Wang1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Aspiring to the fittest and promotion of cooperation in the prisoner's dilemma game</article-title>. <source>Phys Rev E</source> <volume>82</volume>: <fpage>002115</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Perc4">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perc</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name> (<year>2010</year>) <article-title>Heterogenous aspirations promote cooperation in the prisoner's dilemma game</article-title>. <source>PLoS ONE</source> <volume>5</volume>: <fpage>e15117</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Brede2">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brede</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>The evolution of cooperation on correlated payoff landscapes</article-title>. <source>Artificial Life</source> <volume>17</volume>: <fpage>365</fpage>–<lpage>373</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Zimmermann1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zimmermann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Eguíluz</surname><given-names>VM</given-names></name> (<year>2005</year>) <article-title>Cooperation, social networks, and the emergence of leadership in a prisoner's dilemma game with adaptive local interactions</article-title>. <source>Phys Rev E</source> <volume>72</volume>: <fpage>056118</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Santos2">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Santos</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Pacheco</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lenaerts</surname><given-names>T</given-names></name> (<year>2006</year>) <article-title>Cooperation prevails when individuals adjust their social ties</article-title>. <source>PLoS Comput Biol</source> <volume>2</volume>: <fpage>1284</fpage>–<lpage>1291</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-VanSegbroeck1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Segbroeck</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Santos</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>Lenaerts</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Pacheco</surname><given-names>JM</given-names></name> (<year>2009</year>) <article-title>Reacting differently to adverse ties promotes cooperation in social networks</article-title>. <source>Phys Rev Lett</source> <volume>102</volume>: <fpage>058105</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Szolnoki2">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Vukov</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Szabó</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>Selection of noise level in strategy adoption for spatial social dilemmas</article-title>. <source>Phys Rev E</source> <volume>80</volume>: <fpage>056112</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Szolnoki3">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szolnoki</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Perc</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Coevolution of teaching activity promotes cooperation</article-title>. <source>New J Phys</source> <volume>10</volume>: <fpage>043036</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Tanimoto2">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tanimoto</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Brede</surname><given-names>Jand</given-names></name>, <name name-style="western"><surname>Yamauchi</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Network reciprocity by coexisting learning and teaching strategies</article-title>. <source>Phys Rev E</source> <volume>85</volume>: <fpage>032101</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Moyano1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moyano</surname><given-names>LG</given-names></name>, <name name-style="western"><surname>Sánchez</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Evolving learning rules and emergence of cooperation in spatial prisoner's dilemma</article-title>. <source>J Theor Biol</source> <volume>259</volume>: <fpage>85</fpage>–<lpage>95</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Chadefaux1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chadefaux</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Helbing</surname><given-names>D</given-names></name> (<year>2010</year>) <article-title>How wealth accumultion can promote cooperation</article-title>. <source>PLoS ONE</source> <volume>5</volume>: <fpage>e13471</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Szab2">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szabó</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Toke</surname><given-names>C</given-names></name> (<year>1998</year>) <article-title>Evolutionary prisoner's dilemma game on a square lattice</article-title>. <source>Phys Rev E</source> <volume>58</volume>: <fpage>69</fpage>–<lpage>73</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-Tanimoto3">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tanimoto</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Influence of strategy adaptation speed on network reciprocity for evolutionary prisoner's dilemma games</article-title>. <source>Sociobiology</source> <volume>58</volume>: <fpage>315</fpage>–<lpage>325</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0056016-A1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>A</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Mehta</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Dynamics of competitive learning: The role of updates and memory</article-title>. <source>Phys Rev E</source> <volume>85</volume>: <fpage>011134</fpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>