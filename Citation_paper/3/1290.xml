<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
   <journal-meta>
      <journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="pmc">plosone</journal-id>
      <journal-title-group>
         <journal-title>PLoS ONE</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1932-6203</issn>
      <publisher>
         <publisher-name>Public Library of Science</publisher-name>
         <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
   </journal-meta>
   <article-meta>
      <article-id pub-id-type="publisher-id">PONE-D-13-05712</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pone.0062789</article-id>
      <article-categories>
         <subj-group subj-group-type="heading">
            <subject>Research Article</subject>
         </subj-group>
<subj-group subj-group-type="Discipline-v2"><subject>Biology</subject>
<subj-group>
<subject>Anatomy and physiology</subject>
<subj-group>
<subject>Neurological system</subject>
<subj-group>
<subject>Neural pathways</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group>
<subject>Computational biology</subject>
<subj-group>
<subject>Computational neuroscience</subject>
</subj-group>
</subj-group>
<subj-group>
<subject>Neuroscience</subject>
<subj-group>
<subject>Cellular neuroscience</subject>
<subj-group>
<subject>Neuronal morphology</subject>
</subj-group>
</subj-group>
<subj-group>
<subject>Computational neuroscience</subject>
<subject>Neuroimaging</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v2"><subject>Medicine</subject>
<subj-group>
<subject>Diagnostic medicine</subject>
<subj-group>
<subject>Clinical neurophysiology</subject>
</subj-group>
</subj-group>
<subj-group>
<subject>Neurology</subject>
<subj-group>
<subject>Neuroimaging</subject>
</subj-group>
</subj-group>
<subj-group>
<subject>Radiology</subject>
<subj-group>
<subject>Diagnostic radiology</subject>
<subj-group>
<subject>Magnetic resonance imaging</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
      </article-categories>
      <title-group>
         <article-title>A Hybrid CPU-GPU Accelerated Framework for Fast Mapping of High-Resolution Human Brain Connectome</article-title>
         <alt-title alt-title-type="running-head">Hybrid Accelerated Framework for Brain Connectome</alt-title>
      </title-group>
      <contrib-group>
         <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
            <name name-style="western"><surname>Wang</surname>
<given-names>Yu</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
            <name name-style="western"><surname>Du</surname>
<given-names>Haixiao</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
            <name name-style="western"><surname>Xia</surname>
<given-names>Mingrui</given-names>
            </name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Ren</surname>
<given-names>Ling</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Xu</surname>
<given-names>Mo</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Xie</surname>
<given-names>Teng</given-names>
            </name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Gong</surname>
<given-names>Gaolang</given-names>
            </name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Xu</surname>
<given-names>Ningyi</given-names>
            </name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Yang</surname>
<given-names>Huazhong</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>He</surname><given-names>Yong</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref>
         </contrib>
      </contrib-group>
      <aff id="aff1"><label>1</label><addr-line>Department of Electronic Engineering, Tsinghua University, Beijing, China</addr-line></aff>
      <aff id="aff2"><label>2</label><addr-line>State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China</addr-line></aff>
      <aff id="aff3"><label>3</label><addr-line>Microsoft Research Asia, Beijing, China</addr-line></aff>
      <contrib-group>
         <contrib contrib-type="editor" xlink:type="simple">
            <name name-style="western"><surname>Valdes-Sosa</surname>
<given-names>Pedro Antonio</given-names>
            </name><role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
         </contrib>
      </contrib-group>
      <aff id="edit1"><addr-line>Cuban Neuroscience Center, Cuba</addr-line></aff>
      <author-notes>
         <corresp id="cor1">* E-mail: <email xlink:type="simple">yong.he@bnu.edu.cn</email></corresp>
         <fn fn-type="conflict">
            <p>NX is employed by Microsoft Research Asia. There are no patents, products in development or marketed products to declare. This does not alter the authors’ adherence to all the PLOS ONE policies on sharing data and materials, as detailed online in the guide for authors.</p>
         </fn>
         <fn fn-type="con">
            <p>Conceived and designed the experiments: YW NX HY YH. Performed the experiments: YW HD M. Xia LR M. Xu TX. Analyzed the data: YW HD M. Xia LR M. Xu. Contributed reagents/materials/analysis tools: YW GG NX HY YH. Wrote the paper: YW HD M. Xia LR M. Xu GG YH.</p>
         </fn>
      </author-notes>
      <pub-date pub-type="collection">
         <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
         <day>10</day>
         <month>5</month>
         <year>2013</year>
      </pub-date>
      <volume>8</volume>
      <issue>5</issue>
      <elocation-id>e62789</elocation-id>
      <history>
         <date date-type="received">
            <day>6</day>
            <month>2</month>
            <year>2013</year>
         </date>
         <date date-type="accepted">
            <day>19</day>
            <month>3</month>
            <year>2013</year>
         </date>
      </history>
      <permissions>
         <copyright-year>2013</copyright-year>
         <copyright-holder>Wang et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
      <abstract>
         <p>Recently, a combination of non-invasive neuroimaging techniques and graph theoretical approaches has provided a unique opportunity for understanding the patterns of the structural and functional connectivity of the human brain (referred to as the human brain connectome). Currently, there is a very large amount of brain imaging data that have been collected, and there are very high requirements for the computational capabilities that are used in high-resolution connectome research. In this paper, we propose a hybrid CPU-GPU framework to accelerate the computation of the human brain connectome. We applied this framework to a publicly available resting-state functional MRI dataset from 197 participants. For each subject, we first computed Pearson’s Correlation coefficient between any pairs of the time series of gray-matter voxels, and then we constructed unweighted undirected brain networks with 58 k nodes and a sparsity range from 0.02% to 0.17%. Next, graphic properties of the functional brain networks were quantified, analyzed and compared with those of 15 corresponding random networks. With our proposed accelerating framework, the above process for each network cost 80∼150 minutes, depending on the network sparsity. Further analyses revealed that high-resolution functional brain networks have efficient small-world properties, significant modular structure, a power law degree distribution and highly connected nodes in the medial frontal and parietal cortical regions. These results are largely compatible with previous human brain network studies. Taken together, our proposed framework can substantially enhance the applicability and efficacy of high-resolution (voxel-based) brain network analysis, and have the potential to accelerate the mapping of the human brain connectome in normal and disease states.</p>
      </abstract>
      <funding-group>
         <funding-statement>This work was supported by the Microsoft Research Asia, National Basic Research Program of China (973) (Grant No. 2013CB531004), Beijing Natural Science Foundation (Grant No. Z111107067311036), Natural Science Foundation of China (Grant No. 81030028) and National Science Fund for Distinguished Young Scholars (Grant No. 81225012). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
<counts>
<page-count count="14"/>
</counts>
</article-meta>
</front>
<body>
   <sec id="s1">
      <title>Introduction</title>
      <p>In recent years, increasing attention has been paid to the structural and functional connectivity patterns of the human brain, i.e., the human connectome <xref ref-type="bibr" rid="pone.0062789-Sporns1">[1]</xref>. An important and promising way to study the human connectome is to combine non-invasive neuroimaging techniques (e.g., structural MRI, functional MRI, and diffusion MRI) and graph theoretical approaches (for reviews, see <xref ref-type="bibr" rid="pone.0062789-Bullmore1">[2]</xref>–<xref ref-type="bibr" rid="pone.0062789-Stam1">[5]</xref>). Under this framework, the brain is modeled as a complex network that contains a large quantity of nodes and connections. The brain nodes are usually defined by imaging voxels or regions of interest (ROIs); the brain edges are defined by measuring the structural or functional association between the nodes based on neuroimaging data. Once the brain networks are constructed, various graph-based metrics can be used to measure the underlying topological properties of the networks, such as small-worldness, network efficiency, modules, and hubs. To date, graph theoretical analysis of neuroimaging data has been widely used to study the topological architecture of the human brain connectome in normal adults <xref ref-type="bibr" rid="pone.0062789-Achard1">[6]</xref>–<xref ref-type="bibr" rid="pone.0062789-Salvador1">[13]</xref>, during development <xref ref-type="bibr" rid="pone.0062789-Dosenbach1">[14]</xref>–<xref ref-type="bibr" rid="pone.0062789-Yap1">[18]</xref> and throughout the aging process<xref ref-type="bibr" rid="pone.0062789-Achard1">[6]</xref>, <xref ref-type="bibr" rid="pone.0062789-Chen1">[19]</xref>–<xref ref-type="bibr" rid="pone.0062789-Zhu1">[22]</xref>. Moreover, these methods have also been used to reveal topological alterations of neurological and psychiatric diseases such as Alzheimer’s disease <xref ref-type="bibr" rid="pone.0062789-He4">[23]</xref>–<xref ref-type="bibr" rid="pone.0062789-Supekar1">[25]</xref>, schizophrenia <xref ref-type="bibr" rid="pone.0062789-Bassett1">[26]</xref>–<xref ref-type="bibr" rid="pone.0062789-Zalesky1">[28]</xref>, and depression <xref ref-type="bibr" rid="pone.0062789-Zhang1">[29]</xref>.</p>
      <p>In spite of these advances, there are many unresolved issues in the human brain connectome field. One such issue is the required high computational capability that results from the following factors. 1) Network size. The size of the brain networks keeps increasing with the spatial resolution of the imaging techniques. This increase leads to an almost unacceptable running time for the construction and analysis of voxel-based brain networks (the order of 10<sup>4</sup> nodes) on a single CPU because the running time of most graph theoretic algorithms increases super-linearly with the network size. 2) Datasets. The increasing number and size of datasets are generated in the community, for example, from the 1000 Functional Connectomes Project (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/fcon_1000/" xlink:type="simple">www.nitrc.org/projects/fcon_1000/</ext-link>). The increase in the number of subjects is important for the statistical power of the analysis results but leads to an increase in the running time. 3) Repeated experiments. To investigate the effects of the empirical parameters (e.g., network thresholding) and the preprocessing steps (e.g., global signal removal and head motion) on the network analysis results, brain network construction and analysis processes are usually performed many times. 4) Random network calculation. Some topological parameters (e.g., small-world and modular analysis) involve the characterization of many matched random networks, which requires extra computation. All of these factors lead to the computational intractability of high-resolution brain network analysis.</p>
      <p>Given the limitations of the available computational power, several compromises have been widely used in human connectome studies. For example, a number of researchers have employed a small number of ROIs to define the network nodes <xref ref-type="bibr" rid="pone.0062789-Gong1">[8]</xref>–<xref ref-type="bibr" rid="pone.0062789-Meunier1">[30]</xref> or have down-sampled the imaging data into a coarse level <xref ref-type="bibr" rid="pone.0062789-Buckner1">[7]</xref>, <xref ref-type="bibr" rid="pone.0062789-Yuan1">[31]</xref>, <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel1">[32]</xref>. Obviously, ROI-based networks are quite sensitive to the choice of brain parcellation, which raises an extra issue for the ROI definition <xref ref-type="bibr" rid="pone.0062789-Zalesky1">[28]</xref>, <xref ref-type="bibr" rid="pone.0062789-Wang1">[33]</xref>. Moreover, this type of low-resolution networks also leads to the loss of some important connectivity information <xref ref-type="bibr" rid="pone.0062789-Hayasaka1">[34]</xref>, especially for regions that contain multiple sub-divisions (e.g., precuneus <xref ref-type="bibr" rid="pone.0062789-Margulies1">[35]</xref>). Notably, voxel-based networks have the highest resolution and have naturally-defined brain nodes (i.e., voxels) and, therefore, can overcome the above limitations of ROI-based networks. However, voxel-based network analysis requires a very large computing capability because of having a very large network size (approximately 58 K). Thus far, very few studies have used voxel-level brain networks; these studies mainly focused on graph theoretical metrics that had a lower computational complexity (e.g., nodal degree) <xref ref-type="bibr" rid="pone.0062789-Buckner1">[7]</xref>, <xref ref-type="bibr" rid="pone.0062789-Tomasi1">[36]</xref>, <xref ref-type="bibr" rid="pone.0062789-Zuo1">[37]</xref>. The graph theoretic properties that had high computational loads (e.g., small-worldness, modular structure and network efficiency) are rarely studied in high-resolution voxel-based brain networks.</p>
      <p>Recent advances in Graphics Processing Units (GPUs) provide a promising solution to the above-mentioned difficulties. GPUs were originally intended for the fast manipulation and display of graphics. Graphics processing has three key characteristics <xref ref-type="bibr" rid="pone.0062789-Rixner1">[38]</xref>: a large amount of parallelism, little data reuse, and a high computation-to-memory access ratio. Therefore, GPUs are designed with a many-core architecture that favors massively data-parallel computing but that has a small cache and simple flow control. At the turn of this century, researchers proposed that GPUs could also be applied to a broad range of general-purpose applications other than graphics processing. Over the past decade, GPUs have proven to be useful in many general-purpose computing fields, such as scientific computation, video coding and encoding and pattern recognition. Many graph theoretical algorithms can benefit from GPU acceleration because of the high degree of parallelism in these algorithms. Nevertheless, these facts do not imply that GPUs always outperform CPUs in network analysis. For example, a GPU is less efficient than a CPU when calculating the clustering coefficients and the characteristic path length for some sparse graphs. Therefore, it is desirable to combine CPUs and GPUs to obtain better performance.</p>
      <p>In this study, we proposed a heterogeneous platform comprising multi-core CPUs and GPUs to accelerate the graph theoretical algorithms that are used in high-resolution (voxel-based) functional brain network analysis. The acceleration framework mainly included the construction of voxel-based brain networks and graph-theory analysis. To test our platform, we obtained a set of high-resolution functional brain networks with ∼58 K nodes and a sparsity range from 0.023% to 0.151%. We then analyzed a variety of global (e.g., clustering coefficient, shortest path length, small-worldness, efficiency and modules) and regional (e.g., nodal degree) network characteristics and compared them with the average metrics of 15 random networks. The entire process for one network was completed in 80∼150 minutes, depending on the network sparsity.</p>
      <sec id="s1a">
         <title>GPU Programming Model and Architecture</title>
         <p>In this section, we briefly introduce the CUDA programming model for GPUs and the hybrid CPU-GPU hardware platform (illustrated in <xref ref-type="fig" rid="pone-0062789-g001">Fig. 1</xref>). When introducing the GPU architecture, we take NVIDIA Geforce GTX 580 GPU as an example.</p>
         <fig id="pone-0062789-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g001</object-id><label>Figure 1</label>
            <caption>
               <title>CPU-GPU hybrid hardware platform.</title>
               <p>The communication between the host (CPU) and device (GPU) is through a PCI-e bus.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g001" position="float" xlink:type="simple"/></fig>
         <p>CUDA (Computing Unified Device Architecture) is a parallel computing platform and programming model created by NVIDIA; it leverages the parallel compute engine in NVIDIA GPUs to solve many complex computational problems in a more efficient way than on a CPU (<ext-link ext-link-type="uri" xlink:href="http://www.nvidia.com/object/cuda_home_new.html" xlink:type="simple">www.nvidia.com/object/cuda_home_new.html</ext-link>). A typical GPU program includes three main steps: copying data from CPU memory to GPU memory, GPU kernel executions, and reading data back from GPU memory to CPU memory. A kernel, representing a function running on a GPU, is executed by a number of threads. The thread hierarchy - threads are grouped into blocks, and blocks are organized into a grid - enables efficient cooperation between threads and a hierarchical mechanism of memory access. For example, threads within the same block can share data through shared memory with low latency and can synchronize their execution, while all of the threads have their own register, and share the <italic>global memory</italic>. Threads within a thread-block can be identified using thread indices (called <italic>threadIdx</italic>).</p>
         <p>A GPU consists of an array of <italic>Streaming Multiprocessors</italic> (SMs,16 SMs for GTX 580), each executing one or more block(s) concurrently. In a <italic>Streaming Multiprocessor</italic>, there are a number of <italic>processing units</italic> (32 processing units for GTX 580), each executing several threads concurrently. The <italic>Streaming Multiprocessors</italic> schedule threads in an SIMD-manner (Single Instruction Multiple Data). An on-chip <italic>local memory</italic> or <italic>shared memory</italic>, enabling local data shares, and a register file are available on each of the <italic>Streaming Multiprocessors</italic>. Using registers and local memory or shared memory is typically an order of magnitude faster than accessing global memory, which is one order of magnitude faster again than accessing CPU memory. (CUDA Programming Guide from <ext-link ext-link-type="uri" xlink:href="http://developer.nvidia.com/" xlink:type="simple">http://developer.nvidia.com/</ext-link>).</p>
         <p>With far more processing cores than CPUs, GPUs possess much higher computational capability and also higher memory bandwidth. However, even for an algorithm with considerable parallelism, it is not always easy to achieve the full potential of a GPU. A series of modifications must be made to adapt the algorithms to the specific GPU architecture. Usually, two considerations are crucial to the performance: 1) a sufficient number of concurrent threads must be invoked to fully utilize the numerous cores on the GPU; 2) the accesses must be minimized to slow the memory and to use fast memory when possible.</p>
      </sec>
   </sec>
   <sec id="s2" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s2a">
         <title>Data Acquisition and Preprocessing</title>
         <p>The dataset was downloaded from the 1000 Functional Connectomes Project (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/fcon_1000/" xlink:type="simple">www.nitrc.org/projects/fcon_1000/</ext-link>), which is a worldwide multi-site project with fMRI data sharing for the imaging community. The dataset we used was from Dr. Yu-Feng Zang, Beijing. The resting-state images were acquired from 198 healthy right-handed volunteers, comprising 76 males and 122 females, age 21.2±3.3 years (ranging from 18 to 26 years old). We excluded one subject’s data because of an orienting error during scanning. Each participant signed a written informed consent before the scanning. The study was approved by the Institutional Review Board of the Beijing Normal University Imaging Center for Brain Research.</p>
         <p>The acquisition was performed on a <italic>Siemens 3</italic> <italic>T</italic> scanner. For each participant, functional images were scanned using the following parameters: time points = 225, repetition time = 2000 <italic>ms</italic>, echo time = 30 <italic>ms</italic>, in-plane resolution = 3.125 <italic>mm</italic>×3.125 <italic>mm</italic>, slice thickness = 3 <italic>mm</italic>, number of slices = 33, section gap = 0.6 <italic>mm</italic>, flip angle = 90°, and field of view = 200 <italic>mm</italic>×200 <italic>mm</italic>. The participants were instructed to close their eyes and stay awake during the scanning.</p>
         <p>All of the image preprocessing was conducted using DPARSF <xref ref-type="bibr" rid="pone.0062789-Yan1">[39]</xref> and SPM5 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/" xlink:type="simple">www.fil.ion.ucl.ac.uk/spm/</ext-link>). The first 10 volumes on each participant were removed because of signal equilibrium and to allow the participants’ adaptation to the scanning noise. The following preprocessing steps included slice timing, realignment, normalization into standard MNI space with EPI as a template and resampled to voxel size 3 <italic>mm</italic>×3 <italic>mm</italic>×3 <italic>mm</italic>, detrend, and a band-pass filtering from 0.01 to 0.08 Hz. Furthermore, several frequently used noise reduction strategies were utilized, including the regression of white matter (WM), cerebrospinal fluid (CSF), global mean signal time courses, and head-motion profiles. To restrict subsequent functional analysis within gray matter tissues, we generated a gray matter mask as follows. First, we resampled the gray matter tissue probability map provided by SPM5 into 3 <italic>mm</italic>×3 <italic>mm</italic>×3 <italic>mm</italic> resolution. Then we binarized the resampled probability map by a threshold of 0.2, which resulted in a gray matter mask of 58523 voxels.</p>
      </sec>
      <sec id="s2b">
         <title>The Proposed Hybrid CPU-GPU Framework</title>
         <p>Our proposed CPU-GPU framework comprises two main parts: network construction and network analysis (for the work flow, see <xref ref-type="fig" rid="pone-0062789-g002">Fig. 2</xref>). The inputs of our system were the pre-processed fMRI data in NIfTI format of each subject. In the network construction, the first step was to calculate Pearson’s Correlation <xref ref-type="bibr" rid="pone.0062789-Rodgers1">[40]</xref> coefficients for every pair of voxels, to obtain a correlation matrix for each subject. These correlation matrices were then “binarized” (details presented in the section on Network construction) into Boolean adjacency matrices. In the network analysis, we computed several graphic characteristics, including the nodal degree, the clustering coefficient, the characteristic path length, the global efficiency and the modular structure. The definition of these network characteristics can be found in many studies <xref ref-type="bibr" rid="pone.0062789-Wang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0062789-Rubinov1">[41]</xref>. Pearson’s Correlation, modular detection and APSP were accelerated with GPUs, and the other processes were accelerated with multi-core CPUs (<xref ref-type="fig" rid="pone-0062789-g002">Fig. 2</xref>). For the CPU programs, we used an Intel(R) Core(TM) i7-3770 quad-core CPU @ 3.4 GHz with 32 GB RAM. For the GPU programs, we used the NVIDIA Geforce GTX 580, with the CUDA Toolkit v4.2 and the GPU computing SDK v4.2 (<ext-link ext-link-type="uri" xlink:href="http://developer.nvidia.com/cuda/cuda-downloads" xlink:type="simple">http://developer.nvidia.com/cuda/cuda-downloads</ext-link>). The operating system was Windows 7.</p>
         <fig id="pone-0062789-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g002</object-id><label>Figure 2</label>
            <caption>
               <title>The work flow of the proposed framework.</title>
               <p>There are four steps: data acquisition, image preprocessing, network construction and network analysis. We accelerate the latter two steps (shown in detail in the two blocks at the bottom). In network construction, correlation matrices for each subject are obtained by calculating Pearson’s Correlation coefficients. These correlation matrices are then “binarized” into adjacency matrices. In network analysis, several characteristics are calculated. Procedures denoted in green (i.e., Pearson’s Correlation, Partition and APSP) are accelerated with the GPU. Other procedures are implemented with multi-threads on a multi-core CPU.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g002" position="float" xlink:type="simple"/></fig>
      </sec>
      <sec id="s2c">
         <title>Network Construction</title>
         <sec id="s2c1">
            <title>1) Pearson’s Correlation</title>
            <p>For the voxel pair (<italic>v<sub>i</sub></italic>, <italic>v</italic><sub>j</sub>), Pearson’s correlation <xref ref-type="bibr" rid="pone.0062789-Rodgers1">[40]</xref> between the time series of the pair is defined as follows:<disp-formula id="pone.0062789.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e001" xlink:type="simple"/></disp-formula>where column vector <italic>v<sub>i</sub></italic> denoted the time series of voxel <italic>i</italic>, was the average of the series of voxel <italic>i</italic>, and all of the Σ symbols denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e002" xlink:type="simple"/></inline-formula>, i.e., summing along the whole time series (<italic>L</italic> was the length of the time series). First, we normalized the fMRI time series, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e003" xlink:type="simple"/></inline-formula>, <bold>U</bold> = (<italic>u<sub>1</sub></italic>, <italic>u<sub>2</sub></italic>, …, <italic>u<sub>N</sub></italic>) was the aggregate of the normalized time series. The whole pair-wise correlation matrix for the <italic>N</italic> voxels was computed by a matrix multiplication <bold>R</bold> = <bold>U</bold><sup>T</sup><bold>U</bold>. Matrix multiplication is very efficient on a GPU, e.g., 645 Gflop/s (Giga floating-point operations per second) on the NVIDIA Fermi GPUs (e.g., the Geforce GTX 580) <xref ref-type="bibr" rid="pone.0062789-Nath1">[42]</xref>. Because the sizes of the voxel-based brain networks were very large, the correlation matrix <bold>R</bold> sometimes exceeded the GPU memory. To address this problem, we divided the matrix <bold>U</bold> into <italic>m</italic> blocks, using a preset block size (e.g., 3072×3072) <bold>U = (U<sub>1</sub>, U<sub>2</sub>, …,U<sub>m</sub>)</bold>, which implies that</p>
            <p><disp-formula id="pone.0062789.e004"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e004" xlink:type="simple"/></disp-formula></p>
            <p>In this way, our platform could handle networks of any size and was not limited by the graphic memory. One block is calculated each time. Once a block was transferred back to the CPU, the GPU started calculating the next block. Considering the symmetry of the correlation matrix, only the upper half of the matrix must be calculated.</p>
         </sec>
         <sec id="s2c2">
            <title>2) Adjacency matrix construction</title>
            <p>The aim of this study is to illustrate the contribution of many-core computing systems (GPUs) to voxel-based brain network analysis. Instead of investigating the discrepancy between subjects, we focused on the brain network properties that people have in common. Thus, we averaged the correlation matrices of the 197 subjects. Then, we used a set of thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e005" xlink:type="simple"/></inline-formula> to binarize the mean correlation matrix to obtain a set of sparse, unweighted networks, or adjacency matrices. Specifically,<disp-formula id="pone.0062789.e006"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e006" xlink:type="simple"/></disp-formula>where <italic>A</italic> was the adjacency matrix and <italic>R</italic> was the mean correlation matrix. The range of thresholds controlled the sparsity of the network <italic>S</italic> to satisfy <italic>S<sub>1</sub>&lt; S&lt;S<sub>2</sub></italic>. The lower bound <italic>S</italic><sub>1</sub> was determined by the average degree. To maintain estimable small world properties of the network, the average degree <italic>k</italic> should satisfy <italic>k</italic>&gt;log(<italic>N</italic>), where <italic>N</italic> was the number of voxels in the network, and in this case, <italic>N</italic> is 58523. Therefore, <italic>S</italic><sub>1</sub> could be calculated as</p>
            <p><disp-formula id="pone.0062789.e007"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e007" xlink:type="simple"/></disp-formula></p>
            <p>The upper bound <italic>S</italic><sub>2</sub> was determined by the threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e008" xlink:type="simple"/></inline-formula>, which corresponds to the significance level of 0.05 (Bonferroni-corrected). From the calculation, <italic>S</italic><sub>1</sub> and <italic>S</italic><sub>2</sub> were 0.019% and 0.174%, respectively, and the corresponding threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e009" xlink:type="simple"/></inline-formula> ranged from 0.43 to 0.73. For convenience, we chose the following six thresholds, 0.45, 0.5, 0.55, 0.6, 0.65, and 0.7, and thus obtained unweighted networks with corresponding sparsities of 0.151%, 0.098%, 0.067%, 0.047%, 0.033%, and 0.023%.</p>
         </sec>
      </sec>
      <sec id="s2d">
         <title>Network Analysis</title>
         <p>Here, we calculated the nodal degree, and the clustering coefficient (<italic>Cp</italic>), the characteristic path length (<italic>Lp</italic>) for the unweighted brain networks. These characteristics reveal interesting properties of functional brain networks such as the small-world property and the degree distribution. Notably, <italic>Lp</italic> relies on the results of All-Pairs Shortest Path (APSP), one of the most time-consuming steps in voxel-based brain network analysis. We specifically introduce the acceleration for APSP into the section on Network Analysis, in which different APSP algorithms were adopted for networks of different sizes and sparsities. Another time-consuming step in brain network analysis is modular detection. Our GPU acceleration for modular detection is presented in the section on Network Analysis.</p>
         <sec id="s2d1">
            <title>1) All-pairs shortest paths calculation</title>
            <p>There are two main classes of APSP algorithms. One class is Johnson’s algorithm <xref ref-type="bibr" rid="pone.0062789-Johnson1">[43]</xref>, which is based on single-source shortest path algorithms, such as the Dijkstra algorithm <xref ref-type="bibr" rid="pone.0062789-Dijkstra1">[44]</xref> and the Bellman-Ford algorithm <xref ref-type="bibr" rid="pone.0062789-Bellman1">[45]</xref>. When applied to unweighted graphs, Johnson’s algorithm reduces to Breadth-First Search (BFS). Johnson’s algorithm and BFS are efficient with sparse graphs but perform poorly with dense graphs. The other class is the Floyd-Warshall (FW) algorithm <xref ref-type="bibr" rid="pone.0062789-Floyd1">[46]</xref>, <xref ref-type="bibr" rid="pone.0062789-Warshall1">[47]</xref>, which, unlike Johnson’s algorithm, has <italic>O</italic>(<italic>N</italic><sup>3</sup>) time complexity (which is irrelevant to the network sparsity) and favors dense networks. The blocked FW algorithm <xref ref-type="bibr" rid="pone.0062789-Venkatamaran1">[48]</xref> is an improved version of the basic FW algorithm and is more suitable for parallelization. Considering that the brain networks are usually modeled at different sparsities, both of these algorithms are useful. We provide both of the algorithms in our toolbox to allow users to be able to make an optimal choice according to the network sparsity that they have. In this study, we implemented both the multi-thread BFS on multi-core CPUs and the blocked FW algorithm on GPUs, and we set aside the study of the GPU acceleration for BFS for future work. The implementation of the multi-thread BFS on CPUs was straightforward. All of the threads traversed across all of the graph vertices as source points. Each thread was responsible for its proportion of source nodes and found the adjacent and unvisited vertices iteratively. It is worth noting that sorting the vertices according to their degree will benefit the load balance between different threads.</p>
            <p>In the blocked FW algorithm, the whole adjacency matrix was first converted to an <italic>N</italic>×<italic>N</italic> cost matrix C, where <italic>N</italic> was the number of voxels. C<italic><sub>ij</sub></italic> was the distance from voxel <italic>i</italic> to voxel <italic>j</italic>, or ∞ if there was no such path. Then, the cost matrix was divided into <italic>r n</italic>×<italic>n</italic> sub-blocks, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e010" xlink:type="simple"/></inline-formula>. The outer loop iterated over the <italic>r</italic> primary blocks (the blocks along the diagonal of the matrix). Each round was divided into three sequential phases. <xref ref-type="fig" rid="pone-0062789-g003">Fig. 3(a)</xref> shows to which phase each block belonged. Each block was updated in a similar fashion as in the basic FW algorithm <xref ref-type="bibr" rid="pone.0062789-Floyd1">[46]</xref>, <xref ref-type="bibr" rid="pone.0062789-Warshall1">[47]</xref>, which is specifically the following:<disp-formula id="pone.0062789.e011"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e011" xlink:type="simple"/></disp-formula>where element (<italic>k</italic>, <italic>k</italic>) was in the primary block. Updating a block required two source blocks, as shown in <xref ref-type="fig" rid="pone-0062789-g003">Fig. 3(b)</xref>, (1) the block in the same column as itself and in the same row as the primary block, denoted with vertical lines, and (2) the block in the same row as itself and in the same column as the primary block, denoted with horizontal lines. The basic operations in the blocked FW algorithm is similar to matrix multiplication <xref ref-type="bibr" rid="pone.0062789-DAlberto1">[49]</xref> or is referred to as generalized matrix multiplication. Following the ideas of generalized matrix multiplication (GEMM), the blocked FW algorithm could also be implemented efficiently on GPUs. Matsumoto implemented the APSP using blocked FW algorithm on GPUs <xref ref-type="bibr" rid="pone.0062789-Matsumoto1">[50]</xref>.</p>
            <fig id="pone-0062789-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g003</object-id><label>Figure 3</label>
               <caption>
                  <title>The process of the blocked Floyd-Warshall algorithm in a round.</title>
                  <p>(a) Illustration of which phase each block belongs to. In a certain round, Phase 1 is a primary block. Blocks that share the same row or the same column with the primary blocks are in Phase 2. All of the other blocks are in Phase 3. (b) Updating the dotted block requires two source blocks: 1) the block in the same column as itself and in the same row as the primary block, denoted with vertical lines, and 2) the block in the same row with itself and in the same column with the primary block, denoted with horizontal lines. Because we store only the upper block triangular matrix, some source blocks in Phase 3 do not exist, in which case we transpose the corresponding existing blocks to serve as the source blocks.</p>
               </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g003" position="float" xlink:type="simple"/></fig>
            <p>We further proposed two optimizations. First, Phase 1 in the blocked FW algorithm was the basic FW algorithm. However, to represent all of the computation with generalized matrix multiplication, another algorithm with <italic>O</italic>(<italic>n</italic><sup>3</sup>log<sub>2</sub><italic>n</italic>) time complexity was adopted in <xref ref-type="bibr" rid="pone.0062789-Matsumoto1">[50]</xref>. Actually, it is more efficient to apply the blocked FW algorithm again for Phase 1. In this way, we did not bring in any extra computation. Second, the brain has often been modeled as a symmetric network. In this case, only the upper half of the cost matrix must be updated, which means that only <italic>r</italic>(<italic>r+</italic>1)<italic>/</italic>2 blocks must be updated in each round. However, if only the upper half matrix was maintained, then some source blocks did not exist (see <xref ref-type="fig" rid="pone-0062789-g003">Fig. 3(b)</xref>), and we needed to transpose the blocks at the symmetric location.</p>
         </sec>
         <sec id="s2d2">
            <title>2) Modular detection</title>
            <p>There are currently several modular detection methods that are applicable to un-weighted networks. A random-walk-based method was introduced in <xref ref-type="bibr" rid="pone.0062789-Pons1">[51]</xref>, and was used to identify modules in voxel-level brain networks in <xref ref-type="bibr" rid="pone.0062789-Valencia1">[52]</xref>. A greedy algorithm was presented in <xref ref-type="bibr" rid="pone.0062789-Newman1">[53]</xref>, and was used to uncover the modular structure in region-based brain networks in <xref ref-type="bibr" rid="pone.0062789-He3">[12]</xref>. The algorithm we chose for modular detection was the eigenvector-based spectral partition method <xref ref-type="bibr" rid="pone.0062789-Newman2">[54]</xref>. This algorithm was more precise compared to the others but, at the same time, involved much more computation than the above approximate algorithms. Our GPU implementation greatly accelerated this algorithm and made it applicable to very large graphs. The idea of modular detection is to find groups of nodes that have many inner-group connections and relatively few inter-group connections. A benefit function <italic>Q</italic> was introduced to judge the network’s modularity, which was defined as follows:<disp-formula id="pone.0062789.e012"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e012" xlink:type="simple"/></disp-formula>where <italic>A<sub>ij</sub></italic> was an element of the binary adjacency matrix; <italic>P<sub>ij</sub></italic> was the probability for an edge to fall between every pair of vertices <italic>i, j</italic>; <italic>g<sub>i</sub></italic> indicated the community to which vertex <italic>i</italic> belongs; <italic>δ</italic>(<italic>g<sub>i</sub></italic>, <italic>g<sub>j</sub></italic>) was 1 if <italic>g<sub>i</sub></italic> = <italic>g<sub>i</sub></italic> and 0 otherwise; and <italic>m</italic> was the number of edges in the network. <italic>P<sub>ij</sub></italic> could be defined as <italic>P<sub>ij</sub></italic> = <italic>k<sub>i</sub> k<sub>j/</sub></italic>2<italic>m</italic> where <italic>k<sub>i</sub></italic> was the degree of node <italic>i</italic>. The problem then became finding the best division that maximized <italic>Q</italic>. Newman has proven <xref ref-type="bibr" rid="pone.0062789-Newman2">[54]</xref> that the best division could be obtained from the eigenvector that corresponds to the most positive eigenvalue of <bold>B</bold>, a real symmetric matrix called the modularity matrix, with its elements <italic>B<sub>ij</sub></italic> = <italic>A<sub>ij</sub></italic> – <italic>P<sub>ij</sub></italic>. Thus,</p>
            <p><disp-formula id="pone.0062789.e013"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e013" xlink:type="simple"/></disp-formula></p>
            <p>The power method <xref ref-type="bibr" rid="pone.0062789-Mohsen1">[55]</xref> was used to obtain the most positive eigenvalue of <bold>B</bold> and its corresponding eigenvector. In the power method, we started with a random initial <bold>x<sub>0</sub></bold> and iteratively multiplied it with <bold>B</bold> to obtain<disp-formula id="pone.0062789.e014"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0062789.e014" xlink:type="simple"/></disp-formula></p>
            <p>Therefore, the core operations of Newman’s spectral partition method were some basic matrix and vector operations, such as sparse matrix multiplication and the vector dot product. These operations had a high parallelism and were very suitable for GPU implementation. We constructed a GPU runtime library of these linear algebra algorithms to accelerate the power method on the GPUs.</p>
            <p>After the eigenvector computation, the networks were divided into two groups according to the signs of each element in the eigenvector. Brain networks, however, are unlikely to have only two communities. A modified algorithm for handling the multiple divisions is also described in <xref ref-type="bibr" rid="pone.0062789-Newman2">[54]</xref>. We set up a division queue on the CPU for the task scheduling. The whole partition flow is illustrated in <xref ref-type="fig" rid="pone-0062789-g004">Fig. 4</xref>. First, the whole network was enqueued as a single module. Then, we iteratively performed the following steps: dequeued a module; used the power method on the GPU to obtain the best division in this module, i.e., the eigenvector <bold>x</bold> of the most positive eigenvalue <italic>β</italic>; if <italic>β</italic> &gt;0, which meant that this division would increase the benefit function <italic>Q</italic>, we divided the current module and enqueued the two new modules and did nothing if <italic>β</italic> &lt;0. The entire division process finished when the queue became empty. A detailed description of our workflow, GPU implementation for sparse matrix vector multiplication and power method as well as more detailed optimization can be found in our previous work <xref ref-type="bibr" rid="pone.0062789-Wu2">[56]</xref>.</p>
            <fig id="pone-0062789-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g004</object-id><label>Figure 4</label>
               <caption>
                  <title>Flow Chart of our GPU implementation of Newman’s Modular Detection Algorithm.</title>
                  <p>Each time, a module is dequeued. If <italic><sub>β</sub></italic> &gt;0, the module is divided and the two new modules are enqueued. Repeat the process until the queue becomes empty.</p>
               </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g004" position="float" xlink:type="simple"/></fig>
         </sec>
      </sec>
   </sec>
   <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
         <title>Speedup and Performance</title>
         <p>Our GPU-based Pearson’s correlation, Floyd-Warshall algorithm and modular detection on networks with ∼58 K nodes and ∼1.7 G possible edges were much more efficient than the traditional single-thread CPU implementation (<xref ref-type="table" rid="pone-0062789-t001">Table 1</xref>). Network construction using Pearson’s correlation on GPUs was finished in 3 seconds, which was 116 times faster than the traditional single-thread CPU implementation.</p>
         <table-wrap id="pone-0062789-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.t001</object-id><label>Table 1</label>
            <caption>
               <title>A comparison of the time consumed between our hybrid framework and a single-thread CPU implementation.</title>
            </caption><alternatives><graphic id="pone-0062789-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.t001" xlink:type="simple"/><table>
               <colgroup span="1">
                  <col align="left" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
               </colgroup>
               <thead>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Sparsity</td>
                     <td align="left" rowspan="1" colspan="1">0.023%</td>
                     <td align="left" rowspan="1" colspan="1">0.033%</td>
                     <td colspan="2" align="left" rowspan="1">0.047%</td>
                     <td colspan="2" align="left" rowspan="1">0.067%</td>
                     <td colspan="2" align="left" rowspan="1">0.098%</td>
                     <td align="left" rowspan="1" colspan="1">0.151%</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td colspan="10" align="left" rowspan="1"><bold>Pearson’s Correlation (for each subject)</bold></td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">GPU</td>
                     <td colspan="9" align="left" rowspan="1">2.88</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">single-thread CPU</td>
                     <td colspan="9" align="left" rowspan="1">335</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Speedup</td>
                     <td colspan="9" align="left" rowspan="1">116</td>
                  </tr>
                  <tr>
                     <td colspan="10" align="left" rowspan="1"><bold>All-Pairs-Shortest-Path</bold></td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">GPU BFW</td>
                     <td align="left" rowspan="1" colspan="1">1018.43</td>
                     <td align="left" rowspan="1" colspan="1">1019.57</td>
                     <td align="left" rowspan="1" colspan="1">1018.46</td>
                     <td colspan="2" align="left" rowspan="1">1018.75</td>
                     <td colspan="2" align="left" rowspan="1">1018.60</td>
                     <td colspan="2" align="left" rowspan="1">1021.36</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">1-thread CPU BFW</td>
                     <td colspan="9" align="left" rowspan="1">&gt;2.30×10<sup>5</sup></td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Speedup</td>
                     <td colspan="9" align="left" rowspan="1">&gt;200</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">8-thread BFS</td>
                     <td align="left" rowspan="1" colspan="1">43.10</td>
                     <td align="left" rowspan="1" colspan="1">51.52</td>
                     <td align="left" rowspan="1" colspan="1">60.97</td>
                     <td colspan="2" align="left" rowspan="1">75.06</td>
                     <td colspan="2" align="left" rowspan="1">97.34</td>
                     <td colspan="2" align="left" rowspan="1">130.14</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">1-thread CPU BFS</td>
                     <td align="left" rowspan="1" colspan="1">193.18</td>
                     <td align="left" rowspan="1" colspan="1">225.66</td>
                     <td align="left" rowspan="1" colspan="1">274.90</td>
                     <td colspan="2" align="left" rowspan="1">350.44</td>
                     <td colspan="2" align="left" rowspan="1">441.78</td>
                     <td colspan="2" align="left" rowspan="1">572.53</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Speedup</td>
                     <td align="left" rowspan="1" colspan="1">4.48</td>
                     <td align="left" rowspan="1" colspan="1">4.38</td>
                     <td align="left" rowspan="1" colspan="1">4.51</td>
                     <td colspan="2" align="left" rowspan="1">4.67</td>
                     <td colspan="2" align="left" rowspan="1">4.54</td>
                     <td colspan="2" align="left" rowspan="1">4.40</td>
                  </tr>
                  <tr>
                     <td colspan="10" align="left" rowspan="1"><bold>Modular Detection</bold></td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">GPU</td>
                     <td align="left" rowspan="1" colspan="1">220.45</td>
                     <td align="left" rowspan="1" colspan="1">68.59</td>
                     <td align="left" rowspan="1" colspan="1">181.45</td>
                     <td colspan="2" align="left" rowspan="1">193.80</td>
                     <td colspan="2" align="left" rowspan="1">189.73</td>
                     <td colspan="2" align="left" rowspan="1">218.67</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">1-thread CPU</td>
                     <td align="left" rowspan="1" colspan="1">373.56</td>
                     <td align="left" rowspan="1" colspan="1">149.91</td>
                     <td align="left" rowspan="1" colspan="1">419.15</td>
                     <td colspan="2" align="left" rowspan="1">457.06</td>
                     <td colspan="2" align="left" rowspan="1">448.97</td>
                     <td colspan="2" align="left" rowspan="1">568.29</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Speedup</td>
                     <td align="left" rowspan="1" colspan="1">1.70</td>
                     <td align="left" rowspan="1" colspan="1">2.19</td>
                     <td align="left" rowspan="1" colspan="1">2.31</td>
                     <td colspan="2" align="left" rowspan="1">2.36</td>
                     <td colspan="2" align="left" rowspan="1">2.37</td>
                     <td colspan="2" align="left" rowspan="1">2.60</td>
                  </tr>
               </tbody>
            </table></alternatives>
            <table-wrap-foot>
               <fn id="nt101">
                  <label/>
                  <p>Note: BFW, Blocked Floyd-Warshall; BFS, Breadth First Search;The running time is given in seconds.</p>
               </fn>
            </table-wrap-foot>
         </table-wrap>
         <p>The blocked Floyd-Warshall algorithm was employed to calculate APSP and <italic>Lp</italic> on the GPUs. This procedure cost approximately 1019 seconds in all of the six sparsities, which was at least 200 times faster than the single-thread CPU implementation. We also tested another algorithm for APSP calculations called the BFS algorithm, on a quad-core CPU with 8 threads, which cost 43.1, 51.5, 61.0, 75.1, 97.3 and 130.1 seconds for networks with sparsities of 0.023%, 0.033%, 0.047%, 0.067%, 0.098% and 0.151%, respectively. Furthermore, the time complexity of this method was O(M), where M was the number of edges in a network, because the algorithm must access almost every edge in the network, and thus, with the same number of nodes, the sparsity of a network impacts the running time in a linear way. On the other hand, the running time of the blocked FW algorithm remained unchanged under different sparsities (<xref ref-type="fig" rid="pone-0062789-g005">Fig. 5</xref>). The fitted curve of the running time verses the network sparsity has suggested that for networks (on a scale of ∼58 K nodes) with a sparsity lower than 2%, 8-thread BFS on the quad-core CPU was faster; otherwise, the GPU for the blocked FW was faster.</p>
         <fig id="pone-0062789-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g005</object-id><label>Figure 5</label>
            <caption>
               <title>Performance of different APSP algorithms on different platforms.</title>
               <p>The blue line corresponds to the 8-thread BFS algorithm on the quad-core CPU, which is suitable for sparse networks. Its running time is proportional to the sparsity. The black line corresponds to the blocked FW algorithm on the GPU, which is suitable for dense networks. Its running time is irrelevant to the sparsity. The intersection point of the two lines is approximately where the sparsity equals 2%. This criterion is guidance for making the choice.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g005" position="float" xlink:type="simple"/></fig>
         <p>Modular detection on the GPUs cost 220.45, 68.59, 181.45, 193.80, 189.73 and 218.67 seconds for networks with sparsities of 0.023%, 0.033%, 0.047%, 0.067%, 0.098% and 0.151%, respectively. The speedup over a single-thread implementation on the CPU ranged from 1.6 to 2.6 times, mainly depending on the sparsity of the networks. Usually, the speedup was greater on the denser networks because of the larger advantage of the GPU against the CPU when multiplying vectors with a denser matrix (sparse matrix vector multiplication is the most frequent operation in Newman’s modular detection algorithm).</p>
         <p>Because of the different advantages of the CPU and the GPU in different procedures, we proposed a CPU/GPU hybrid framework for brain network analysis (<xref ref-type="table" rid="pone-0062789-t002">Table 2</xref>). Consider the network with a 0.151% sparsity, for example. First, the Pearson’s correlation was performed on the GPU and cost 2.9 seconds to obtain a correlation matrix on one individual. Then, a group matrix was calculated by averaging the correlation matrix across all of the subjects on the CPU. Next, 7.5 seconds were spent for the calculation of <italic>Cp</italic> on the quad-core CPU. Additionally, <italic>Lp</italic> was calculated on the quad-core CPU using 8-thread BFS, which cost 130.14 seconds because of the low network sparsity. (The GPU FW algorithm would be employed instead if the sparsities of the network were greater than 2%; See <xref ref-type="fig" rid="pone-0062789-g005">Fig. 5</xref>.) Finally, modular detection was performed on the GPU, which cost 218.67 seconds. In the calculation of <italic>Cp</italic>, <italic>Lp</italic> and modular detection for random networks, Maslov random networks <xref ref-type="bibr" rid="pone.0062789-Maslov1">[57]</xref> were generated by a single thread on the CPU (generation only, calculation excluded), which cost approximately 18 seconds to generate one random network. For the chosen hardware and the running time of each procedure under other sparsities, see <xref ref-type="table" rid="pone-0062789-t002">Table 2</xref> for details.</p>
         <table-wrap id="pone-0062789-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.t002</object-id><label>Table 2</label>
            <caption>
               <title>Running time for computing each network metric on the CPU, GPU and CPU-GPU hybrid.</title>
            </caption><alternatives><graphic id="pone-0062789-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.t002" xlink:type="simple"/><table>
               <colgroup span="1">
                  <col align="left" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
                  <col align="center" span="1"/>
               </colgroup>
               <thead>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Network Metrics</td>
                     <td align="left" rowspan="1" colspan="1">Hardware</td>
                     <td colspan="7" align="left" rowspan="1">Sparsity</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1"/>
                     <td align="left" rowspan="1" colspan="1"/>
                     <td align="left" rowspan="1" colspan="1">0.023%</td>
                     <td align="left" rowspan="1" colspan="1">0.033%</td>
                     <td align="left" rowspan="1" colspan="1">0.047%</td>
                     <td align="left" rowspan="1" colspan="1">0.067%</td>
                     <td colspan="2" align="left" rowspan="1">0.098%</td>
                     <td align="left" rowspan="1" colspan="1">0.151%</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Correlation</td>
                     <td align="left" rowspan="1" colspan="1">GPU</td>
                     <td colspan="7" align="left" rowspan="1">∼2.88 (*197 subjects)</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Degree</td>
                     <td align="left" rowspan="1" colspan="1">CPU</td>
                     <td align="left" rowspan="1" colspan="1">&lt;10<sup>−3</sup></td>
                     <td align="left" rowspan="1" colspan="1">&lt;10<sup>−3</sup></td>
                     <td align="left" rowspan="1" colspan="1">&lt;10<sup>−3</sup></td>
                     <td align="left" rowspan="1" colspan="1">&lt;10<sup>−3</sup></td>
                     <td align="left" rowspan="1" colspan="1">&lt;10<sup>−3</sup></td>
                     <td colspan="2" align="left" rowspan="1">&lt;10<sup>−3</sup></td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1"><italic>Cp</italic></td>
                     <td align="left" rowspan="1" colspan="1">CPU</td>
                     <td align="left" rowspan="1" colspan="1">6.3</td>
                     <td align="left" rowspan="1" colspan="1">6.2</td>
                     <td align="left" rowspan="1" colspan="1">6.3</td>
                     <td align="left" rowspan="1" colspan="1">6.3</td>
                     <td align="left" rowspan="1" colspan="1">6.7</td>
                     <td colspan="2" align="left" rowspan="1">7.5</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1"><italic>Lp</italic></td>
                     <td align="left" rowspan="1" colspan="1">Hybrid</td>
                     <td align="left" rowspan="1" colspan="1">43.10</td>
                     <td align="left" rowspan="1" colspan="1">51.52</td>
                     <td align="left" rowspan="1" colspan="1">60.97</td>
                     <td align="left" rowspan="1" colspan="1">75.06</td>
                     <td align="left" rowspan="1" colspan="1">97.34</td>
                     <td colspan="2" align="left" rowspan="1">130.14</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Modular detection</td>
                     <td align="left" rowspan="1" colspan="1">GPU</td>
                     <td align="left" rowspan="1" colspan="1">220.45</td>
                     <td align="left" rowspan="1" colspan="1">68.59</td>
                     <td align="left" rowspan="1" colspan="1">181.45</td>
                     <td align="left" rowspan="1" colspan="1">193.80</td>
                     <td align="left" rowspan="1" colspan="1">189.73</td>
                     <td colspan="2" align="left" rowspan="1">218.67</td>
                  </tr>
                  <tr>
                     <td align="left" rowspan="1" colspan="1">Maslov rewiring</td>
                     <td align="left" rowspan="1" colspan="1">CPU</td>
                     <td align="left" rowspan="1" colspan="1">204.9</td>
                     <td align="left" rowspan="1" colspan="1">211.8</td>
                     <td align="left" rowspan="1" colspan="1">214.9</td>
                     <td align="left" rowspan="1" colspan="1">224.7</td>
                     <td align="left" rowspan="1" colspan="1">238.9</td>
                     <td colspan="2" align="left" rowspan="1">270.0</td>
                  </tr>
               </tbody>
            </table></alternatives>
            <table-wrap-foot>
               <fn id="nt102">
                  <label/>
                  <p>Note: The running time is given in seconds. The running time of the Maslov rewiring represents the total time for constructing 15 random networks.</p>
               </fn>
            </table-wrap-foot>
         </table-wrap>
         <p>Our framework has greatly accelerated the process of brain network analysis. For a network with ∼58 K nodes and ∼1.7 G possible edges, the total running time for the network construction and characteristics analysis including small-worldness, degree and modularity (comparing to 15 degree-matched random networks when needed) were approximately 80∼150 minutes, which corresponded to sparsities from 0.023% to 0.151%. In contrast, the same process executed by a single thread would cost approximately 20 to 25 hours on a CPU. Our hybrid framework saved a tremendous amount of time and energy for such a graph theoretical network analysis method.</p>
      </sec>
      <sec id="s3b">
         <title>Network Characteristics</title>
         <sec id="s3b1">
            <title>1) Small-world properties</title>
            <p>We calculated the clustering coefficient and characteristic path length of the voxel-based functional brain networks under all six sparsities (the geometric average of <italic>Cp</italic> was 0.41, ranging from 0.27 to 0.50, and the geometric average of <italic>Lp</italic> was 13.47, ranging from 22.3 to 7.6) and the corresponding nodes, mean degree and degree distribution matched the random networks (the geometric average <italic>Lp<sub>rand</sub></italic> was 3.33, ranging from 4.29 to 2.73). The clustering coefficients of the functional brain networks were much higher than those of the random networks (the geometric average of <italic>γ</italic> was 220.5, ranging from 580 to 67). On the other hand, although the characteristic path lengths of the functional brain networks were revealed to be higher than those of the random networks in the extremely sparse situation, <italic>Lp</italic> was approximately equal in both the functional brain networks and the random networks across most of the sparsities (the geometric average of <italic>λ</italic> was 4.04, ranging from 5.21 to 2.79). In general, our results from the network analysis suggested that voxel-based functional brain networks exhibited significant small-world properties when compared to those random networks that had the same number of nodes, mean degree and degree distribution (the averaged <italic>σ</italic> was 54.5, ranging from 111.3 to 24.0; see <xref ref-type="table" rid="pone-0062789-t003">Table 3</xref>).</p>
            <table-wrap id="pone-0062789-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.t003</object-id><label>Table 3</label>
               <caption>
                  <title>Small-world properties of brain networks, and a comparison with random networks.</title>
               </caption><alternatives><graphic id="pone-0062789-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.t003" xlink:type="simple"/><table>
                  <colgroup span="1">
                     <col align="left" span="1"/>
                     <col align="center" span="1"/>
                     <col align="center" span="1"/>
                     <col align="center" span="1"/>
                     <col align="center" span="1"/>
                     <col align="center" span="1"/>
                     <col align="center" span="1"/>
                  </colgroup>
                  <thead>
                     <tr>
                        <td align="left" rowspan="1" colspan="1">Sparsity (<italic>S</italic>)</td>
                        <td align="left" rowspan="1" colspan="1">0.023</td>
                        <td align="left" rowspan="1" colspan="1">0.033</td>
                        <td align="left" rowspan="1" colspan="1">0.047</td>
                        <td align="left" rowspan="1" colspan="1">0.067</td>
                        <td align="left" rowspan="1" colspan="1">0.098</td>
                        <td align="left" rowspan="1" colspan="1">0.151</td>
                     </tr>
                  </thead>
                  <tbody>
                     <tr>
                        <td colspan="7" align="left" rowspan="1">Clustering Coefficient</td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>Cp</italic></td>
                        <td align="left" rowspan="1" colspan="1">0.27</td>
                        <td align="left" rowspan="1" colspan="1">0.37</td>
                        <td align="left" rowspan="1" colspan="1">0.43</td>
                        <td align="left" rowspan="1" colspan="1">0.46</td>
                        <td align="left" rowspan="1" colspan="1">0.48</td>
                        <td align="left" rowspan="1" colspan="1">0.50</td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>Cp<sub>rand</sub></italic>± std</td>
                        <td align="left" rowspan="1" colspan="1">4.72×10<sup>−4</sup>±2.0×10<sup>−5</sup></td>
                        <td align="left" rowspan="1" colspan="1">8.07×10<sup>−4</sup>±1.3×10<sup>−5</sup></td>
                        <td align="left" rowspan="1" colspan="1">1.41×10<sup>−3</sup>±2.1×10<sup>−5</sup></td>
                        <td align="left" rowspan="1" colspan="1">2.44×10<sup>−4</sup>±1.6×10<sup>−5</sup></td>
                        <td align="left" rowspan="1" colspan="1">4.28×10<sup>−3</sup>±1.6×10<sup>−5</sup></td>
                        <td align="left" rowspan="1" colspan="1">7.47×10<sup>−3</sup>±1.5×10<sup>−5</sup></td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>γ</italic></td>
                        <td align="left" rowspan="1" colspan="1">580</td>
                        <td align="left" rowspan="1" colspan="1">458</td>
                        <td align="left" rowspan="1" colspan="1">305</td>
                        <td align="left" rowspan="1" colspan="1">189</td>
                        <td align="left" rowspan="1" colspan="1">112</td>
                        <td align="left" rowspan="1" colspan="1">67</td>
                     </tr>
                     <tr>
                        <td colspan="7" align="left" rowspan="1">Characteristic Path Length</td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>Lp</italic></td>
                        <td align="left" rowspan="1" colspan="1">22.32</td>
                        <td align="left" rowspan="1" colspan="1">18.77</td>
                        <td align="left" rowspan="1" colspan="1">15.28</td>
                        <td align="left" rowspan="1" colspan="1">12.29</td>
                        <td align="left" rowspan="1" colspan="1">9.94</td>
                        <td align="left" rowspan="1" colspan="1">7.64</td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>Lp<sub>rand</sub></italic>± std</td>
                        <td align="left" rowspan="1" colspan="1">4.29±× 10<sup>−4</sup></td>
                        <td align="left" rowspan="1" colspan="1">3.80±2.3×10<sup>−4</sup></td>
                        <td align="left" rowspan="1" colspan="1">3.42±1.5×10<sup>−4</sup></td>
                        <td align="left" rowspan="1" colspan="1">3.10±2.2×10<sup>−4</sup></td>
                        <td align="left" rowspan="1" colspan="1">2.90±1.6×10<sup>−4</sup></td>
                        <td align="left" rowspan="1" colspan="1">2.74±5.8×10<sup>−4</sup></td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>λ</italic></td>
                        <td align="left" rowspan="1" colspan="1">5.21</td>
                        <td align="left" rowspan="1" colspan="1">4.94</td>
                        <td align="left" rowspan="1" colspan="1">4.47</td>
                        <td align="left" rowspan="1" colspan="1">3.96</td>
                        <td align="left" rowspan="1" colspan="1">3.42</td>
                        <td align="left" rowspan="1" colspan="1">2.79</td>
                     </tr>
                     <tr>
                        <td colspan="7" align="left" rowspan="1">Small-worldness</td>
                     </tr>
                     <tr>
                        <td align="left" rowspan="1" colspan="1"><italic>σ</italic></td>
                        <td align="left" rowspan="1" colspan="1">111.3</td>
                        <td align="left" rowspan="1" colspan="1">92.7</td>
                        <td align="left" rowspan="1" colspan="1">68.2</td>
                        <td align="left" rowspan="1" colspan="1">47.7</td>
                        <td align="left" rowspan="1" colspan="1">32.7</td>
                        <td align="left" rowspan="1" colspan="1">24.0</td>
                     </tr>
                  </tbody>
               </table></alternatives>
               <table-wrap-foot>
                  <fn id="nt103">
                     <label/>
                     <p>Note: <italic>Cp</italic>, the average clustering coefficient of all of the nodes in the brain network; <italic>Cp<sub>rand</sub></italic>, the average clustering coefficient of all of the nodes in the Malslov rewiring random networks; <italic>γ = Cp/Cp<sub>rand</sub></italic>, <italic>Lp</italic>, the characteristic path length of the brain network; <italic>Lp<sub>rand</sub></italic>, the characteristic path length of the Maslov random networks; <italic>λ = Lp/Lp<sub>rand</sub></italic>; and <italic>σ</italic> = <italic>γ/λ</italic>. All of the results of the random networks are the average of 15 random networks, with the standard deviations given in brackets.</p>
                  </fn>
               </table-wrap-foot>
            </table-wrap>
         </sec>
         <sec id="s3b2">
            <title>2) Modularity</title>
            <p>The modularity coefficients of the real brain network were relatively stable for different sparsities, while those of the random networks decreased monotonically when the sparsity threshold increased. Furthermore, the real brain network showed significant non-random modular structure over each sparsity threshold when compared to random networks. The mean modularity coefficient <italic>Q</italic> was 0.81±0.064 in real brain networks and the corresponding mean Z score was 13.72±1.06. These results demonstrated that there was significant non-random modular organization of the voxel-based resting-state fMRI functional human brain networks. We further visualized the modular structure onto smoothed brain surfaces for every sparsity threshold (<xref ref-type="fig" rid="pone-0062789-g006">Fig. 6</xref>). A total of 46 to 52 modules were detected at most of the sparsities (only 22 modules detected in <italic>S</italic> = 0.033%). Each of these modules was assigned a different color, with which most of the brain regions in the classic atlas can be identified. The characteristic areas included the medial prefrontal cortex, the dorsal lateral frontal cortex, the sensory motor area, the supplementary motor area, the dorsal and ventral precuneus, the anterior and posterior inferior parietal lobule, the medial and lateral temporal cortex and temporal pole, the visual cortex, and the anterior and posterior insular.</p>
            <fig id="pone-0062789-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g006</object-id><label>Figure 6</label>
               <caption>
                  <title>The modular structure of brain networks under six sparsities.</title>
                  <p>The brain is divided into 48, 22, 46, 46, 46, and 52 modules with Q = 0.88, 0.72, 0.86, 0.84, 0.81, and 0.74 in real networks and with a sparsity of 0.023%, 0.033%, 0.047%, 0.067%, 0.098%, and 0.151%, respectively. This figure was visualized with the BrainNet Viewer (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/bnv/" xlink:type="simple">http://www.nitrc.org/projects/bnv/</ext-link>).</p>
               </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g006" position="float" xlink:type="simple"/></fig>
         </sec>
         <sec id="s3b3">
            <title>3) Degree distribution and hubs</title>
            <p>We further examined the degree distribution of voxel-based functional brain networks. The degree distribution of the brain networks (<xref ref-type="fig" rid="pone-0062789-g007">Fig. 7</xref>) fitted a power law scaling well, decaying as <italic>p</italic>(k) ∼ <italic>ck</italic><sup>−<italic>γ</italic></sup> on a log-log plot, with an estimated exponent <italic>γ</italic> ranging from 2.16 (<italic>S</italic> = 0.151%) to 4.16 (<italic>S</italic> = 0.023%). This power law indicated that the voxel-based function brain networks were scale-free, with a small number of brain regions having many connections with most other regions. Aside from the degree distribution, we also pay close attention to those nodes that have a high degree of connectivity, which are often considered to be hub regions <xref ref-type="bibr" rid="pone.0062789-Buckner1">[7]</xref>, <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel2">[58]</xref>. Here, voxels with a degree that is one standard deviation above the average degree are defined as hub-voxels. Several brain regions were identified stably over all of the sparsity thresholds. These regions belonged mainly to the default mode network (DMN), including the bilateral precuneus (PCUN) and posterior cingulate cortex (PCC), the medial prefrontal cortex (MPFC), the lateral prefrontal cortex (LPFC), and the inferior parietal lobule (IPL) (containing the angular gyrus and the supramarginal gyrus). Additionally, we found a higher connecting degree in the medial visual cortex and the sensorimotor cortex. Parts of the bilateral visual cortex were also identified (<xref ref-type="fig" rid="pone-0062789-g008">Fig. 8</xref>).</p>
            <fig id="pone-0062789-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g007</object-id><label>Figure 7</label>
               <caption>
                  <title>Distribution of the nodal degree under 6 sparsities (log-log plot).</title>
                  <p>Panel (a)∼(f) are the degree distribution and the fitting result of the network with a sparsity of 0.023%, 0.033%, 0.047%, 0.067%, 0.098%, and 0.151%, respectively. The spot lines reflect the probability of finding a node connected to a given number of neighbors; the red solid lines indicate the curve fitted results of the power law <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0062789.e015" xlink:type="simple"/></inline-formula>. The estimated exponent <italic>γ</italic> under 6 sparsities are 4.16, 3.21, 2.80, 2.61, 2.46 and 2.16, respectively.</p>
               </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g007" position="float" xlink:type="simple"/></fig>
            <fig id="pone-0062789-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0062789.g008</object-id><label>Figure 8</label>
               <caption>
                  <title>The degree of voxels near the cerebral cortex under different sparsities.</title>
                  <p>Nodes that have a much higher degree than average are considered to be potential hub-voxels. We mark the voxels with degrees that are one standard deviation above the mean. Voxels with a higher degree are in yellow, and voxels with a lower degree are in red. Across different sparsities, some hub-areas are stable, including the bilateral precuneus (PCUN) and posterior cingulate cortex (PCC), the medial prefrontal cortex (MPFC), the lateral prefrontal cortex (LPFC), and the inferior parietal lobule (IPL) (containing the angular gyrus and the supramarginal gyrus). This figure was visualized with the BrainNet Viewer (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/bnv/" xlink:type="simple">http://www.nitrc.org/projects/bnv/</ext-link>).</p>
               </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0062789.g008" position="float" xlink:type="simple"/></fig>
         </sec>
      </sec>
   </sec>
   <sec id="s4">
      <title>Discussion</title>
      <p>We have presented a CPU-GPU hybrid framework for accelerating the construction and analysis of voxel-based functional brain networks. Taking advantage of the super data-parallel computing capability of GPUs, our hybrid framework greatly reduced the computational time compared to the traditional CPU platform, and finished the prohibitive computation in an acceptable amount of time. With the proposed framework, we analyzed the group brain networks that were constructed from 197 subjects and revealed small-world properties and modular structure in the voxel-based functional brain networks. Furthermore, highly connected hubs were observed in the medial frontal, parietal and occipital cortex regions.</p>
      <sec id="s4a">
         <title>CPU-GPU Hybrid Framework</title>
         <p>Researchers are focusing more attention on brain network analysis. At the same time, the computation budget of brain network analysis is becoming heavier because of the growing quantity of subjects in datasets and the increasing resolution used when constructing brain networks from a coarse to a fine granularity level. Therefore, an efficient, accessible and scalable computational platform is required for brain network analysis.</p>
         <p>Our hybrid framework was set up with multi-core CPUs and GPUs. CPUs and GPUs have different design philosophies. A large amount of CPU chip area is dedicated to caching and branch prediction <xref ref-type="bibr" rid="pone.0062789-Owens1">[59]</xref>. In contrast, GPUs devote more transistors to data-parallel arithmetic operations and have far more processing elements and a higher memory bandwidth. We accelerated the correlation calculation, the APSP calculation and modular detection with GPUs because these algorithms have a large amount of parallelism and do not require complex flow control which is suitable for using GPU calculations. For these three procedures, we achieved promising speedups (1.6∼2.6x for modular detection, above 100x for the other two) over a single-thread C/C++ implementation on a CPU. It is worth mentioning that CPU vendors provide high-performance math libraries, such as Intel MKL and AMD ACML. Routines in these libraries are highly optimized and can be up to 10 times more efficient than our C/C++ implementation. These routines can assist during some of the brain network analysis procedures, e.g., Pearson’s correlation and modular detection, because they can be expressed as basic linear algebra subprograms (BLAS). With the aid of high performance math libraries, CPUs can achieve similar performance to GPUs in modular detection; however, for Pearson’s correlation, the CPU implementation is still slower than the GPU implementation. Other procedures, such as APSP and the calculation of betweenness, cannot take advantage of the math libraries, and it is extremely difficult for typical developers to achieve the best performance for CPUs (such as the vendor-provided libraries).</p>
         <p>Another possible solution to the very large amount of computation required is large-scale clusters. However, large-scale clusters often reside at computing centers and are not easily accessible to most researchers. In contrast, the hardware used in our framework is a personal computer equipped with a GPU as an accelerator. Our framework also has the advantage of having a low cost, a small size and low power consumption, and can be integrated into future MRI machines because of these advantages. At the same time, our framework is also useful if one would like to use clusters for brain network analysis. In the state-of-the-art high-performance clusters, individual nodes often have both CPUs and GPUs (<ext-link ext-link-type="uri" xlink:href="http://www.top500.org/" xlink:type="simple">http://www.top500.org/</ext-link>), which is exactly the architecture our framework is intended to target.</p>
         <p>In the section on Speedup and Performance results, we have presented a performance comparison between our hybrid framework and a single-thread CPU implementation, involving two different algorithms for the calculation of the characteristic path length (<italic>Lp</italic>) and the modular detection algorithm. It is worth noting that the modular detection and blocked FW algorithms implemented on the GPU were not as fast as we expected because of the low range of sparsities in our experiments (the highest sparsity is 0.151% lower than 2%). As shown in <xref ref-type="table" rid="pone-0062789-t001">table 1</xref>, we can find the gradual trend that the modular detection of networks with a higher sparsity can obtain a higher speedup on a GPU compared to a CPU. Also shown in <xref ref-type="fig" rid="pone-0062789-g005">Fig. 5</xref>, the GPU blocked FW algorithm is more suitable for denser networks that have a sparsity higher than 2%. The low range of sparsities in our experiments could be caused by the regression of the global signal and by averaging the correlation coefficient matrix across the subjects. As described in a recent study <xref ref-type="bibr" rid="pone.0062789-Schwarz1">[60]</xref>, the removal of the global brain signal rendered the correlation coefficient <italic>r<sub>ij</sub></italic> (elements from the average correlation matrix of the group of subjects) centered close to zero. Therefore, compared to conditions without any global signal removal and with the same level of threshold <italic>̂r </italic>corresponding to the same level of p-value, we would obtain a lower sparsity. In short, the GPU blocked FW algorithm will have a better performance and help substantially when we analyze brain networks that have high sparsities in future work.</p>
         <p>Our framework is also scalable to a larger network size. For example, in Pearson’s Correlation and the APSP calculation on a GPU, the network is divided into blocks to allow the handling of arbitrarily large networks as long as there is sufficient memory for the CPU to access. In modular detection, although it is difficult to handle networks by each block during the process, only sparse networks, which require little memory, are stored on the GPU, which ensures the scalability of our platform.</p>
      </sec>
      <sec id="s4b">
         <title>Voxel-based and Region-based Brain Network Analysis</title>
         <p>Voxel-based human brain functional networks were constructed and analyzed in this paper. Compared with ROI-based brain networks, voxel-based brain networks have several advantages. First, recent studies have demonstrated that network properties, such as small-worldness, network efficiency and degree distribution, were influenced by the definition of a node <xref ref-type="bibr" rid="pone.0062789-Wang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0062789-Zalesky2">[61]</xref>. Constructing brain networks based on voxels overcomes the difficulties of anatomically or functionally defined brain regions. Second, the low resolution of region-based brain networks might lead to the loss of some important connectivity information <xref ref-type="bibr" rid="pone.0062789-Hayasaka1">[34]</xref>, especially for regions that contain multiple sub-divisions. Many associated cortices involved in multi-functions can be further divided into functionally discrete subdivisions, such as the hippocampus and amygdala region <xref ref-type="bibr" rid="pone.0062789-Amunts1">[62]</xref>, the motor cortex <xref ref-type="bibr" rid="pone.0062789-Jarrell1">[63]</xref>, the lateral parietal cortex <xref ref-type="bibr" rid="pone.0062789-Nelson1">[64]</xref>, and the medial parietal cortex <xref ref-type="bibr" rid="pone.0062789-Margulies1">[35]</xref>. Mixed connectivity information might be involved and lead to confusion when a low resolution atlas is used. Third, voxel-based brain networks provide better spatial localization ability. When a highly connected node is identified, the region-based network can only identify the whole cortex region as a hub; in contrast, a voxel-based network can tell exactly which parts of the cortex serve as hubs <xref ref-type="bibr" rid="pone.0062789-Buckner1">[7]</xref>, <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel2">[58]</xref>, <xref ref-type="bibr" rid="pone.0062789-Zuo2">[65]</xref>. With the above advantages and the progress of computing power, high-resolution brain network analysis will bring a more detailed perspective to human connectome studies.</p>
      </sec>
      <sec id="s4c">
         <title>Biological Findings</title>
         <p>Our results identified the small-world property, modular structure and highly connected hubs in voxel-based functional brain networks during the resting state. The small-world model characterizes the architecture of a network that has both well-connected local neighborhoods (a high clustering-coefficient) and a short topological distance between two long-range nodes (a short characteristic path length). Such a structure is observed in a series of structural and functional connectome studies, in which brain networks were constructed based on regions <xref ref-type="bibr" rid="pone.0062789-Achard1">[6]</xref>, <xref ref-type="bibr" rid="pone.0062789-Salvador1">[13]</xref> and based on voxels <xref ref-type="bibr" rid="pone.0062789-Hayasaka1">[34]</xref>, <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel2">[58]</xref>. These findings indicate that the human brain possesses both local functional specialization and high global communicational integration, which is an optimized organizational pattern of evolution.</p>
         <p>Strongly interconnected sub-networks corresponds to the significant modular structure of brain networks. The modular architecture contributes to various aspects of the functional organization of the human brain, such as efficient local information processing within modules <xref ref-type="bibr" rid="pone.0062789-Kotter1">[66]</xref>, <xref ref-type="bibr" rid="pone.0062789-Sporns3">[67]</xref>, the balance of functional segregation and integration, and high resilience to network node or edge damage <xref ref-type="bibr" rid="pone.0062789-He3">[12]</xref>. We identified several modules combined from brain areas based on voxel-wise functional brain networks using the classic Newman’s spectral method. The segmented brain regions possessed similar but not identical patterns, corresponding to those parcellated cortex areas that are in charge of diverse functions in classical brain anatomy atlases <xref ref-type="bibr" rid="pone.0062789-TzourioMazoyer1">[68]</xref>, <xref ref-type="bibr" rid="pone.0062789-Brodmann1">[69]</xref>. Recent studies, along with the graph theoretical modularity analysis method, also attempted to learn functional brain organization in a voxel-wise way and demonstrated detailed functional segment results in comparison with ROI-based studies <xref ref-type="bibr" rid="pone.0062789-Valencia1">[52]</xref>, <xref ref-type="bibr" rid="pone.0062789-Power1">[70]</xref>. Voxel-based modularity studies might provide a view of the fine-grained scale in the functional network topological organizations, and might offer precise parcellation over the cortex and subcortex.</p>
         <p>The nodal degree is the most common metric that reflects the importance of nodes in terms of direct connections <xref ref-type="bibr" rid="pone.0062789-Buckner1">[7]</xref>. In our study, we used the nodal degree to measure the importance of each voxel in the functional brain network. We identified several brain regions as network hubs, which mostly belonged to the DMN, including PCUN and PCC, MPFC, LPFC, and IPL. These DMN regions, especially the PCUN, the PCC, and the MPFC, have already been demonstrated to be core regions in studies of metabolism <xref ref-type="bibr" rid="pone.0062789-Raichle1">[71]</xref>, anatomical networks <xref ref-type="bibr" rid="pone.0062789-Gong1">[8]</xref>, <xref ref-type="bibr" rid="pone.0062789-Hagmann1">[9]</xref>, <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel3">[72]</xref>, and functional networks <xref ref-type="bibr" rid="pone.0062789-Zuo2">[65]</xref>, <xref ref-type="bibr" rid="pone.0062789-Achard2">[73]</xref>. Our finding verified the inference that the DMN regions play a key role in brain function integration by their various communications with other dispersed brain regions.</p>
         <p>Our results showed that the degree distribution of voxel-based functional brain networks followed a clear power law scale decay, which is indicative of a scale-free network with the existence of richly connected hubs and is coincident with previous voxel-based functional brain network studies <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel2">[58]</xref>, <xref ref-type="bibr" rid="pone.0062789-Eguiluz1">[74]</xref>, <xref ref-type="bibr" rid="pone.0062789-Cecchi1">[75]</xref>. However, truncated power law degree distributions have also been reported from many other brain network studies performed on region-based network constructions, including both the functional networks <xref ref-type="bibr" rid="pone.0062789-Wang1">[33]</xref>, <xref ref-type="bibr" rid="pone.0062789-Achard2">[73]</xref> and structural networks <xref ref-type="bibr" rid="pone.0062789-Gong1">[8]</xref>, <xref ref-type="bibr" rid="pone.0062789-He2">[11]</xref>. The truncated power law networks are less vulnerable to attack than scale-free networks; nevertheless, both networks are robust to random attacks compared to random networks <xref ref-type="bibr" rid="pone.0062789-Achard2">[73]</xref>. The reasons for the reports of these two types of network embedded in the human brain network are currently unclear; however, the scale-free degree distributions were reported only in high spatial resolution network studies <xref ref-type="bibr" rid="pone.0062789-vandenHeuvel2">[58]</xref>, <xref ref-type="bibr" rid="pone.0062789-Eguiluz1">[74]</xref>, <xref ref-type="bibr" rid="pone.0062789-Cecchi1">[75]</xref>. Furthermore, a recent voxel-based functional network study <xref ref-type="bibr" rid="pone.0062789-Hayasaka1">[34]</xref> reported truncated power law degree distributions under a complimentary cumulative distributions fitting. Therefore, we infer that the network degree distribution might be influenced methodologically by the spatial resolution of the nodal definition and the curve-fitting method.</p>
         <p>Furthermore, the above network properties of functional networks in those individuals who have neuropsychiatric disorders often changes <xref ref-type="bibr" rid="pone.0062789-Guye1">[76]</xref>, <xref ref-type="bibr" rid="pone.0062789-Xia1">[77]</xref>. However, because of computational limitations, most of the present studies defined network nodes in the ROI-based level using multifarious atlas or custom-defined ROIs; voxel-based network analyses have rarely been performed. There are still many controversial results in these studies, such as in Alzheimer’s disease <xref ref-type="bibr" rid="pone.0062789-Supekar1">[25]</xref>, <xref ref-type="bibr" rid="pone.0062789-SanzArigita1">[78]</xref>. Considering that the ROI-defined brain regions often comprise functional heterogeneous voxels, the voxel-based network analysis could eliminate the potential methodological confounding factor that arises from the various nodal definitions.</p>
      </sec>
      <sec id="s4d">
         <title>Conclusions</title>
         <p>In this work, we propose a hybrid CPU-GPU framework for human connectome studies. Utilizing the computation power of both types of hardware, the whole process for one network finishes much faster than with traditional methods and takes an acceptable amount of time. The main purpose of our work is to stress that the advancement in parallel computing technologies can make revolutionary contributions to neuroscience research. In the future, we will continue to demonstrate our platform and integrate new modules and methods, such as DTI modeling and fiber tractography <xref ref-type="bibr" rid="pone.0062789-Behrens1">[79]</xref>. We have published our toolbox online at <ext-link ext-link-type="uri" xlink:href="http://www.parabna.weebly.com/" xlink:type="simple">http://www.parabna.weebly.com/</ext-link>. A website is also under construction to provide our results on the 197 subjects’ functional brain networks.</p>
      </sec>
   </sec>
</body>
<back>
   <ref-list>
      <title>References</title>
      <ref id="pone.0062789-Sporns1"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name> (<year>2005</year>) <article-title>The human connectome: A structural description of the human brain</article-title>. <source>PLoS Comput Biol</source> <volume>1</volume>: <fpage>e42</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Bullmore1"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2009</year>) <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat Rev Neurosci</source> <volume>10</volume>: <fpage>186</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-He1"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Graph theoretical modeling of brain connectivity</article-title>. <source>Curr Opin Neurol</source> <volume>23</volume>: <fpage>341</fpage>–<lpage>350</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Sporns2"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2011</year>) <article-title>The human connectome: a complex network</article-title>. <source>Ann N Y Acad Sci</source> <volume>1224</volume>: <fpage>109</fpage>–<lpage>125</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Stam1"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stam</surname><given-names>CJ</given-names></name> (<year>2010</year>) <article-title>Use of magnetoencephalography (MEG) to study functional brain networks in neurodegenerative disorders</article-title>. <source>Journal of the Neurological Sciences</source> <volume>289</volume>: <fpage>128</fpage>–<lpage>134</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Achard1"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Achard</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Efficiency and cost of economical brain functional networks</article-title>. <source>PLoS Comput Biol</source> <volume>3</volume>: <fpage>e17</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Buckner1"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckner</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Sepulcre</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Talukdar</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Krienen</surname><given-names>FM</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Cortical hubs revealed by intrinsic functional connectivity: mapping, assessment of stability, and relation to Alzheimer’s disease</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>1860</fpage>–<lpage>1873</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Gong1"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gong</surname><given-names>G</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Concha</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Lebel</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Gross</surname><given-names>DW</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Mapping anatomical connectivity patterns of human cerebral cortex using in vivo diffusion tensor imaging tractography</article-title>. <source>Cereb Cortex</source> <volume>19</volume>: <fpage>524</fpage>–<lpage>536</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Hagmann1"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagmann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Cammoun</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gigandet</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Meuli</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Honey</surname><given-names>CJ</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Mapping the structural core of human cerebral cortex</article-title>. <source>PLoS Biol</source> <volume>6</volume>: <fpage>e159</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Hagmann2"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagmann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Kurant</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gigandet</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Thiran</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wedeen</surname><given-names>VJ</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Mapping human whole-brain structural networks with diffusion MRI</article-title>. <source>PLoS One</source> <volume>2</volume>: <fpage>e597</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-He2"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>ZJ</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>AC</given-names></name> (<year>2007</year>) <article-title>Small-world anatomical networks in the human brain revealed by cortical thickness from MRI</article-title>. <source>Cereb Cortex</source> <volume>17</volume>: <fpage>2407</fpage>–<lpage>2419</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-He3"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>ZJ</given-names></name>, <name name-style="western"><surname>Yan</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Uncovering intrinsic modular organization of spontaneous brain activity in humans</article-title>. <source>PLoS One</source> <volume>4</volume>: <fpage>e5226</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Salvador1"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Salvador</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Suckling</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Coleman</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Pickard</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Menon</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Neurophysiological architecture of functional magnetic resonance images of human brain</article-title>. <source>Cereb Cortex</source> <volume>15</volume>: <fpage>1332</fpage>–<lpage>1342</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Dosenbach1"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dosenbach</surname><given-names>NUF</given-names></name>, <name name-style="western"><surname>Nardos</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Fair</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Power</surname><given-names>JD</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Prediction of Individual Brain Maturity Using fMRI</article-title>. <source>Science</source> <volume>329</volume>: <fpage>1358</fpage>–<lpage>1361</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Fair1"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fair</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Dosenbach</surname><given-names>NU</given-names></name>, <name name-style="western"><surname>Church</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Miezin</surname><given-names>FM</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>The maturing architecture of the brain’s default network</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>105</volume>: <fpage>4028</fpage>–<lpage>4032</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Fair2"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fair</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Power</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Dosenbach</surname><given-names>NU</given-names></name>, <name name-style="western"><surname>Church</surname><given-names>JA</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Functional brain networks develop from a “local to distributed” organization</article-title>. <source>PLoS Comput Biol</source> <volume>5</volume>: <fpage>e1000381</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Hagmann3"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagmann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Madan</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Cammoun</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Pienaar</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>White matter maturation reshapes structural connectivity in the late developing human brain</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>107</volume>: <fpage>19067</fpage>–<lpage>19072</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Yap1"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yap</surname><given-names>PT</given-names></name>, <name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gilmore</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>W</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Development trends of white matter connectivity in the first years of life</article-title>. <source>PLoS One</source> <volume>6</volume>: <fpage>e24678</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Chen1"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>ZJ</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Rosa-Neto</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Gong</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>AC</given-names></name> (<year>2011</year>) <article-title>Age-related alterations in the modular organization of structural cortical network by using cortical thickness from MRI</article-title>. <source>Neuroimage</source> <volume>56</volume>: <fpage>235</fpage>–<lpage>245</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Wen1"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wen</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zhu</surname><given-names>W</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kochan</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Reppermund</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Discrete neuroanatomical networks are associated with specific cognitive abilities in old age</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>1204</fpage>–<lpage>1212</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Wu1"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wu</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Taki</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kinomura</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Goto</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Age-related changes in topological organization of structural brain networks in healthy individuals</article-title>. <source>Hum Brain Mapp</source> <volume>33</volume>: <fpage>552</fpage>–<lpage>568</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zhu1"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Jin</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Qiu</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Influences of brain development and ageing on cortical interactive networks</article-title>. <source>Clin Neurophysiol</source> <volume>122</volume>: <fpage>278</fpage>–<lpage>283</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-He4"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Structural insights into aberrant topological patterns of large-scale cortical networks in Alzheimer’s disease</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>4756</fpage>–<lpage>4766</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Lo1"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lo</surname><given-names>CY</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>PN</given-names></name>, <name name-style="western"><surname>Chou</surname><given-names>KH</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Diffusion tensor tractography reveals abnormal topological organization in structural cortical networks in Alzheimer’s disease</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>16876</fpage>–<lpage>16885</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Supekar1"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Supekar</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Menon</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Rubin</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Musen</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Greicius</surname><given-names>MD</given-names></name> (<year>2008</year>) <article-title>Network analysis of intrinsic functional brain connectivity in Alzheimer’s disease</article-title>. <source>PLoS Comput Biol</source> <volume>4</volume>: <fpage>e1000100</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Bassett1"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bassett</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Verchinski</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Mattay</surname><given-names>VS</given-names></name>, <name name-style="western"><surname>Weinberger</surname><given-names>DR</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Hierarchical organization of human cortical networks in health and schizophrenia</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>9239</fpage>–<lpage>9248</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Liu1"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Liang</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Hao</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Disrupted small-world networks in schizophrenia</article-title>. <source>Brain</source> <volume>131</volume>: <fpage>945</fpage>–<lpage>961</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zalesky1"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zalesky</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Fornito</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Seal</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Cocchi</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Westin</surname><given-names>CF</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Disrupted axonal fiber connectivity in schizophrenia</article-title>. <source>Biol Psychiatry</source> <volume>69</volume>: <fpage>80</fpage>–<lpage>89</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zhang1"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Kuang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>X</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Disrupted brain connectivity networks in drug-naive, first-episode major depressive disorder</article-title>. <source>Biol Psychiatry</source> <volume>70</volume>: <fpage>334</fpage>–<lpage>342</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Meunier1"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meunier</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Achard</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Morcom</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>Age-related changes in modular organization of human brain functional networks</article-title>. <source>Neuroimage</source> <volume>44</volume>: <fpage>715</fpage>–<lpage>723</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Yuan1"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yuan</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Qin</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Dong</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Altered small-world brain functional networks and duration of heroin use in male abstinent heroin-dependent individuals</article-title>. <source>Neurosci Lett</source> <volume>477</volume>: <fpage>37</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-vandenHeuvel1"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Stam</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Kahn</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Hulshoff Pol</surname><given-names>HE</given-names></name> (<year>2009</year>) <article-title>Efficiency of functional brain networks and intellectual performance</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>7619</fpage>–<lpage>7624</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Wang1"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Zang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Tang</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Parcellation-dependent small-world brain functional networks: a resting-state fMRI study</article-title>. <source>Hum Brain Mapp</source> <volume>30</volume>: <fpage>1511</fpage>–<lpage>1523</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Hayasaka1"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayasaka</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Laurienti</surname><given-names>PJ</given-names></name> (<year>2010</year>) <article-title>Comparison of characteristics between region-and voxel-based network analyses in resting-state fMRI data</article-title>. <source>Neuroimage</source> <volume>50</volume>: <fpage>499</fpage>–<lpage>508</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Margulies1"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Margulies</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Vincent</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Kelly</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lohmann</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Uddin</surname><given-names>LQ</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Precuneus shares intrinsic functional architecture in humans and monkeys</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>: <fpage>20069</fpage>–<lpage>20074</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Tomasi1"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tomasi</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Volkow</surname><given-names>ND</given-names></name> (<year>2010</year>) <article-title>Functional connectivity density mapping</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>107</volume>: <fpage>9885</fpage>–<lpage>9890</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zuo1"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zuo</surname><given-names>XN</given-names></name>, <name name-style="western"><surname>Ehmke</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Mennes</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Imperati</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Castellanos</surname><given-names>FX</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Network centrality in the human functional connectome</article-title>. <source>Cereb Cortex</source> <volume>22</volume>: <fpage>1862</fpage>–<lpage>1875</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Rixner1"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><article-title>Rixner S, Dally WJ, Kapasi UJ, Khailany B, Lopez-Lagunas A, et al</article-title>. <source>A bandwidth-efficient architecture for media processing; 1998 30 Nov-2 Dec</source> <volume>1998</volume>: <fpage>3</fpage>–<lpage>13</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Yan1"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yan</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Zang</surname><given-names>Y</given-names></name> (<year>2010</year>) <article-title>DPARSF: A MATLAB Toolbox for “Pipeline” Data Analysis of Resting-State fMRI</article-title>. <source>Front Syst Neurosci</source> <volume>4</volume>: <fpage>13</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Rodgers1"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodgers</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Nicewander</surname><given-names>WA</given-names></name> (<year>1988</year>) <article-title>13 Ways to Look at the Correlation-Coefficient</article-title>. <source>American Statistician</source> <volume>42</volume>: <fpage>59</fpage>–<lpage>66</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Rubinov1"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubinov</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2010</year>) <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source> <volume>52</volume>: <fpage>1059</fpage>–<lpage>1069</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Nath1"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nath</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Tomov</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Dongarra</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>An Improved Magma Gemm For Fermi Graphics Processing Units</article-title>. <source>Int J High Perform Comput Appl</source> <volume>24</volume>: <fpage>511</fpage>–<lpage>515</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Johnson1"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>DB</given-names></name> (<year>1977</year>) <article-title>Efficient Algorithms for Shortest Paths in Sparse Networks</article-title>. <source>Journal of the Acm</source> <volume>24</volume>: <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Dijkstra1"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dijkstra</surname><given-names>EW</given-names></name> (<year>1959</year>) <article-title>A note on two problems in connexion with graphs</article-title>. <source>Numerische Mathematik</source> <volume>1</volume>: <fpage>269</fpage>–<lpage>271</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Bellman1"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bellman</surname><given-names>RE</given-names></name> (<year>1958</year>) <article-title>On a Routing Problem</article-title>. <source>Quarterly of Applied Mathematics</source> <volume>16</volume>: <fpage>87</fpage>–<lpage>90</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Floyd1"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Floyd</surname><given-names>RW</given-names></name> (<year>1962</year>) <article-title>ALGORITHM-97 - SHORTEST PATH</article-title>. <source>Communications of the Acm</source> <volume>5</volume>: <fpage>345</fpage>–<lpage>345</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Warshall1"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">Warshall S (1962) A Theorem on Boolean Matrices. Journal of the Acm 9: 11–&amp;.</mixed-citation></ref>
      <ref id="pone.0062789-Venkatamaran1"><label>48</label><mixed-citation publication-type="other" xlink:type="simple">Venkatamaran G, Sahni S, Mukhopadhyaya S (2003) A blocked all-pairs shortest-paths algorithm. ACM Journal of Experimental Algorithmics 8.</mixed-citation></ref>
      <ref id="pone.0062789-DAlberto1"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>D’Alberto</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Nicolau</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>R-Kleene: A high-performance divide-and-conquer algorithm for the all-pair shortest path for densely connected networks</article-title>. <source>Algorithmica</source> <volume>47</volume>: <fpage>203</fpage>–<lpage>213</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Matsumoto1"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">Matsumoto K, Nakasato N, Sedukhin SG (2011) Blocked All-Pairs Shortest Paths Algorithm for Hybrid CPU-GPU System; 145–152.</mixed-citation></ref>
      <ref id="pone.0062789-Pons1"><label>51</label><mixed-citation publication-type="other" xlink:type="simple">Pons P, Latapy M (2005) Computing communities in large networks using random walks. In: Yolum PGTGFOC, editor. Computer and Information Sicences - Iscis 2005, Proceedings. 284–293.</mixed-citation></ref>
      <ref id="pone.0062789-Valencia1"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Valencia</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Pastor</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Fernandez-Seara</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Artieda</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Martinerie</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Complex modular structure of large-scale brain networks</article-title>. <source>Chaos</source> <volume>19</volume>: <fpage>023119</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Newman1"><label>53</label><mixed-citation publication-type="other" xlink:type="simple">Newman MEJ (2004) Fast algorithm for detecting community structure in networks. Physical Review E 69.</mixed-citation></ref>
      <ref id="pone.0062789-Newman2"><label>54</label><mixed-citation publication-type="other" xlink:type="simple">Newman MEJ (2006) Finding community structure in networks using the eigenvectors of matrices. Physical Review E 74.</mixed-citation></ref>
      <ref id="pone.0062789-Mohsen1"><label>55</label><mixed-citation publication-type="other" xlink:type="simple">Mohsen A (1978) The Power Method: A Technique for Guiding Structure Analysis and an Approach to Microwave Circuit Synthesis; 433–436.</mixed-citation></ref>
      <ref id="pone.0062789-Wu2"><label>56</label><mixed-citation publication-type="other" xlink:type="simple">Wu D, Wu T, Shan Y, Wang Y, He Y, <etal>et al</etal>.. (2010) Making Human Connectome Faster: GPU Acceleration of Brain Network Analysis. Proceedings 2010 IEEE 16th International Conference on Parallel and Distributed Systems (ICPADS 2010).</mixed-citation></ref>
      <ref id="pone.0062789-Maslov1"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maslov</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sneppen</surname><given-names>K</given-names></name> (<year>2002</year>) <article-title>Specificity and stability in topology of protein networks</article-title>. <source>Science</source> <volume>296</volume>: <fpage>910</fpage>–<lpage>913</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-vandenHeuvel2"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Stam</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Boersma</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hulshoff Pol</surname><given-names>HE</given-names></name> (<year>2008</year>) <article-title>Small-world and scale-free organization of voxel-based resting-state functional connectivity in the human brain</article-title>. <source>Neuroimage</source> <volume>43</volume>: <fpage>528</fpage>–<lpage>539</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Owens1"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Owens</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Luebke</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Govindaraju</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Harris</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Krueger</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>A survey of general-purpose computation on graphics hardware</article-title>. <source>Computer Graphics Forum</source> <volume>26</volume>: <fpage>80</fpage>–<lpage>113</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Schwarz1"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwarz</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>McGonigle</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Negative edges and soft thresholding in complex network analysis of resting state functional connectivity data</article-title>. <source>Neuroimage</source> <volume>55</volume>: <fpage>1132</fpage>–<lpage>1146</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zalesky2"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zalesky</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Fornito</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Harding</surname><given-names>IH</given-names></name>, <name name-style="western"><surname>Cocchi</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Yücel</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Whole-brain anatomical networks: Does the choice of nodes matter?</article-title> <source>Neuroimage</source> <volume>50</volume>: <fpage>970</fpage>–<lpage>983</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Amunts1"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amunts</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kedo</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Kindler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Pieperhoff</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Mohlberg</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Cytoarchitectonic mapping of the human amygdala, hippocampal region and entorhinal cortex: intersubject variability and probability maps</article-title>. <source>Anat Embryol (Berl)</source> <volume>210</volume>: <fpage>343</fpage>–<lpage>352</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Jarrell1"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jarrell</surname><given-names>TA</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Bloniarz</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Brittin</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The connectome of a decision-making neural network</article-title>. <source>Science</source> <volume>337</volume>: <fpage>437</fpage>–<lpage>444</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Nelson1"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nelson</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Power</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Wig</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Miezin</surname><given-names>FM</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>A parcellation scheme for human left lateral parietal cortex</article-title>. <source>Neuron</source> <volume>67</volume>: <fpage>156</fpage>–<lpage>170</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Zuo2"><label>65</label><mixed-citation publication-type="other" xlink:type="simple">Zuo XN, Ehmke R, Mennes M, Imperati D, Castellanos FX, <etal>et al</etal>.. (2011) Network Centrality in the Human Functional Connectome. Cereb Cortex.</mixed-citation></ref>
      <ref id="pone.0062789-Kotter1"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name> (<year>2003</year>) <article-title>Network participation indices: characterizing component roles for information processing in neural networks</article-title>. <source>Neural Netw</source> <volume>16</volume>: <fpage>1261</fpage>–<lpage>1275</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Sporns3"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name> (<year>2000</year>) <article-title>Theoretical neuroanatomy: relating anatomical and functional connectivity in graphs and cortical connection matrices</article-title>. <source>Cereb Cortex</source> <volume>10</volume>: <fpage>127</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-TzourioMazoyer1"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Landeau</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Papathanassiou</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Crivello</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Etard</surname><given-names>O</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>Neuroimage</source> <volume>15</volume>: <fpage>273</fpage>–<lpage>289</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Brodmann1"><label>69</label><mixed-citation publication-type="other" xlink:type="simple">Brodmann K (1909) Vergleichende lokalisationslehre der grobhirnrinde. Barth: Leipzig.</mixed-citation></ref>
      <ref id="pone.0062789-Power1"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Power</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Wig</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>KA</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source> <volume>72</volume>: <fpage>665</fpage>–<lpage>678</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Raichle1"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raichle</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>MacLeod</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Snyder</surname><given-names>AZ</given-names></name>, <name name-style="western"><surname>Powers</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Gusnard</surname><given-names>DA</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>A default mode of brain function</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>98</volume>: <fpage>676</fpage>–<lpage>682</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-vandenHeuvel3"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name> (<year>2011</year>) <article-title>Rich-club organization of the human connectome</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>15775</fpage>–<lpage>15786</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Achard2"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Achard</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Salvador</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Whitcher</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Suckling</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bullmore</surname><given-names>E</given-names></name> (<year>2006</year>) <article-title>A resilient, low-frequency, small-world human brain functional network with highly connected association cortical hubs</article-title>. <source>J Neurosci</source> <volume>26</volume>: <fpage>63</fpage>–<lpage>72</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Eguiluz1"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eguiluz</surname><given-names>VM</given-names></name>, <name name-style="western"><surname>Chialvo</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Cecchi</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Baliki</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Apkarian</surname><given-names>AV</given-names></name> (<year>2005</year>) <article-title>Scale-free brain functional networks</article-title>. <source>Phys Rev Lett</source> <volume>94</volume>: <fpage>018102</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Cecchi1"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cecchi</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Rao</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Centeno</surname><given-names>MV</given-names></name>, <name name-style="western"><surname>Baliki</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Apkarian</surname><given-names>AV</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Identifying directed links in large scale functional networks: application to brain fMRI</article-title>. <source>BMC Cell Biol</source> <volume>8</volume> Suppl 1<fpage>S5</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Guye1"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guye</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bettus</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Bartolomei</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Cozzone</surname><given-names>PJ</given-names></name> (<year>2010</year>) <article-title>Graph theoretical analysis of structural and functional connectivity MRI in normal and pathological brain networks</article-title>. <source>MAGMA</source> <volume>23</volume>: <fpage>409</fpage>–<lpage>421</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Xia1"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xia</surname><given-names>M</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name> (<year>2011</year>) <article-title>Magnetic resonance imaging and graph theoretical analysis of complex brain networks in neuropsychiatric disorders</article-title>. <source>Brain Connect</source> <volume>1</volume>: <fpage>349</fpage>–<lpage>365</lpage>.</mixed-citation></ref>
      <ref id="pone.0062789-SanzArigita1"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sanz-Arigita</surname><given-names>EJ</given-names></name>, <name name-style="western"><surname>Schoonheim</surname><given-names>MM</given-names></name>, <name name-style="western"><surname>Damoiseaux</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Rombouts</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Maris</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Loss of ‘small-world’ networks in Alzheimer’s disease: graph analysis of FMRI resting-state functional connectivity</article-title>. <source>PLoS One</source> <volume>5</volume>: <fpage>e13788</fpage>.</mixed-citation></ref>
      <ref id="pone.0062789-Behrens1"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Jenkinson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Johansen-Berg</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Nunes</surname><given-names>RG</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Characterization and propagation of uncertainty in diffusion-weighted MR imaging</article-title>. <source>Magn Reson Med</source> <volume>50</volume>: <fpage>1077</fpage>–<lpage>1088</lpage>.</mixed-citation></ref>
   </ref-list>
</back>
</article>