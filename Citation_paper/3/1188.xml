<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-41893</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0087738</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine</subject><subj-group><subject>Public health</subject><subj-group><subject>Environmental health</subject><subject>Occupational and industrial health</subject><subject>Socioeconomic aspects of health</subject></subj-group></subj-group><subj-group><subject>Toxicology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Science policy</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Research validity</subject><subj-group><subject>Reproducibility</subject><subject>Research errors</subject></subj-group></subj-group><subj-group><subject>Research reporting guidelines</subject></subj-group></subj-group><subj-group><subject>Research laboratories</subject><subj-group><subject>Company laboratories</subject><subject>University laboratories</subject></subj-group></subj-group><subj-group><subject>Technology regulations</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Social and behavioral sciences</subject><subj-group><subject>Political science</subject><subj-group><subject>Political aspects of health</subject><subject>Public policy</subject></subj-group></subj-group><subj-group><subject>Sociology</subject><subj-group><subject>Sociology of knowledge</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Qualichem <italic>In Vivo</italic>: A Tool for Assessing the Quality of <italic>In Vivo</italic> Studies and Its Application for Bisphenol A</article-title>
<alt-title alt-title-type="running-head">Qualichem <italic>In Vivo</italic></alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Maxim</surname><given-names>Laura</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>van der Sluijs</surname><given-names>Jeroen P.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Institut des Sciences de la Communication du CNRS (UPS 3088), Centre National de la Recherche Scientifique, Paris, France</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Environmental Sciences, Copernicus Institute, Utrecht University, Utrecht, The Netherlands</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Williams</surname><given-names>Cecilia</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Houston, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">laura.maxim@iscc.cnrs.fr</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: LM JVDS. Performed the experiments: LM. Analyzed the data: LM JVDS. Contributed reagents/materials/analysis tools: LM JVDS. Wrote the paper: LM JVDS.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>29</day><month>1</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>1</issue>
<elocation-id>e87738</elocation-id>
<history>
<date date-type="received"><day>14</day><month>10</month><year>2013</year></date>
<date date-type="accepted"><day>29</day><month>12</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Maxim, van der Sluijs</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>In regulatory toxicology, quality assessment of <italic>in vivo</italic> studies is a critical step for assessing chemical risks. It is crucial for preserving public health studies that are considered suitable for regulating chemicals are robust. Current procedures for conducting quality assessments in safety agencies are not structured, clear or consistent. This leaves room for criticism about lack of transparency, subjective influence and the potential for insufficient protection provided by resulting safety standards. We propose a tool called “Qualichem <italic>in vivo</italic>” that is designed to systematically and transparently assess the quality of <italic>in vivo</italic> studies used in chemical health risk assessment. We demonstrate its use here with 12 experts, using two controversial studies on Bisphenol A (BPA) that played an important role in BPA regulation in Europe. The results obtained with Qualichem contradict the quality assessments conducted by expert committees in safety agencies for both of these studies. Furthermore, they show that reliance on standardized guidelines to ensure scientific quality is only partially justified. Qualichem allows experts with different disciplinary backgrounds and professional experiences to express their individual and sometimes divergent views—an improvement over the current way of dealing with minority opinions. It provides a transparent framework for expressing an aggregated, multi-expert level of confidence in a study, and allows a simple graphical representation of how well the study integrates the best available scientific knowledge. Qualichem can be used to compare assessments of the same study by different health agencies, increasing transparency and trust in the work of expert committees. In addition, it may be used in systematic evaluation of <italic>in vivo</italic> studies submitted by industry in the dossiers that are required for compliance with the REACH Regulation. Qualichem provides a balanced, common framework for assessing the quality of studies that may or may not be following standardized guidelines.</p>
</abstract>
<funding-group><funding-statement>This work has been funded by the French Ministry of Ecology in the framework of the PNRPE 2010 programme (URL: <ext-link ext-link-type="uri" xlink:href="http://www.pnrpe.fr/" xlink:type="simple">http://www.pnrpe.fr/</ext-link>), as part of the project “Toolkit for uncertainty and knowledge quality analysis of endocrine disruptors' risk assessments: the case study of Bisphenol A” (DICO-Risk). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Biomedical research has been evaluated using quality assessment frameworks for many years. Existing scales use between 2 and 100 criteria to assess the methodological quality of clinical trials <xref ref-type="bibr" rid="pone.0087738-Lexchin1">[1]</xref>. For example, the Jadad scale provides a 7-point checklist for assessing the quality of clinical trials in pain research <xref ref-type="bibr" rid="pone.0087738-Jadad1">[2]</xref>. The proposed GRADE (Grading of Recommendations, Assessment, Development, and Evaluation) framework evaluates the quality of evidence and strength of recommendations about therapeutic and diagnostic interventions and clinical management strategies <xref ref-type="bibr" rid="pone.0087738-Ansari1">[3]</xref>–<xref ref-type="bibr" rid="pone.0087738-Brozek1">[4]</xref>. Adapted to the Australian context, the FORM framework was created to formulate and grade recommendations in clinical practice guidelines <xref ref-type="bibr" rid="pone.0087738-Hillier1">[5]</xref>.</p>
<p>Transparent and complete reporting is key for assessing the methodological quality of a study. Therefore, there are specific recommendations for reporting (for example) randomized controlled trials <xref ref-type="bibr" rid="pone.0087738-Schulz1">[6]</xref> and observational studies in epidemiology <xref ref-type="bibr" rid="pone.0087738-Vandenbroucke1">[7]</xref>.</p>
<p>Quality assessment frameworks for academic and regulatory toxicology are less developed. Wandall et al. <xref ref-type="bibr" rid="pone.0087738-Wandall1">[8]</xref> made one of the first attempts to identify sources of bias in toxicology, but did not develop a quality assessment framework. Highlighting the importance of adequate reporting for informing policy and scientific practice in animal research, Kilkenny et al. <xref ref-type="bibr" rid="pone.0087738-Kilkenny1">[9]</xref> proposed the ARRIVE (Animals in Research: Reporting <italic>In vivo</italic> Experiments) guideline for reporting <italic>in vivo</italic> studies. The objective of this guideline is to allow in-depth critique of reported quality controls using a framework for including all relevant information about what was done, why and how. However, very few complete frameworks for quality assessment of <italic>in vivo</italic> toxicology studies have been proposed and/or tested. Among them, the Klimisch score <xref ref-type="bibr" rid="pone.0087738-Klimisch1">[10]</xref> defines data quality by three properties: adequacy, relevance and reliability.</p>
<p>Public health in Europe depends critically on effective implementation of the REACH (Registration, Evaluation, Authorisation &amp; restriction of CHemicals) regulation, which concerns the risks of most chemicals on the market. Protection of public health will not be effective without ensuring the data submitted by industry—on which political decisions are based—is of high scientific quality. REACH uses the Klimisch score <xref ref-type="bibr" rid="pone.0087738-ECHA1">[11]</xref> to assess the quality of individual studies. However, the method used to assess a study's adequacy and relevance leaves significant room for subjectivity. It is relatively easy to assess reliability of data arising from standardized tests—in particular OECD or national guidelines and good laboratory practice (GLP). However, the definition of reliability in the Klimisch score disadvantages studies that do not follow standardized guidelines, but are nevertheless scientifically robust; i.e., most of the published academic literature. In REACH, the Klimisch score is often applied by industry itself, when submitting data to health agencies. Industry must assess its own studies or studies from the academic literature. Room for subjectivity in assessing studies may lead to selection bias in choosing and weighting the set of studies that is ultimately used by industry and health agencies to inform decision-making.</p>
<p>Recognizing the lack of precision of the Klimisch categories and the need for a more transparent, harmonized and objective framework for assessing the reliability of the toxicological data submitted under REACH, the ToxRTool was created <xref ref-type="bibr" rid="pone.0087738-Schneider1">[12]</xref>. However, criteria included in frameworks such as ToxRTool or ARRIVE focus on how completely a study is reported rather than on its scientific quality. But, reporting of seemingly straightforward details such as the study species or strain chosen can be a source of scientific debate about, for example, the sensitivity of that species or strain to estrogens <xref ref-type="bibr" rid="pone.0087738-Myers1">[13]</xref>.</p>
<p>Existing tools fail to provide a systematic approach for assessing the quality of <italic>in vivo</italic> studies used to inform policy by institutions charged with implementing regulatory frameworks or responding to requests for policy advice. Examples of such institutions relevant to chemical risks are EFSA (European Food Safety Authority) and ECHA (European Chemicals Agency).</p>
<p>Our paper aims to fill this methodological gap by developing and testing the Qualichem <italic>in vivo</italic> tool (or simply, “Qualichem”). For endocrine disrupters in general and BPA in particular, the challenge is to incorporate divergent views from scientists with affiliations in industry, academia, health agencies at the national and European level, and governments by providing a synthesized view of the global quality of a study. Previous tools like ToxRTool assume that heterogeneity in ratings is not a natural consequence of the differences among respondents (discipline, level of competence on the subject, previous experience, epistemic communities, etc), and that it can be solved if the questions are framed better. This assumption does not reflect real life situations: when evaluating studies of controversial topics like endocrine disrupters, scientists from different disciplinary backgrounds and socio-economic horizons openly disagree. Literature shows that the same raw data can be interpreted differently by different experts in different contexts, which can lead to conflicting conclusions <xref ref-type="bibr" rid="pone.0087738-Rudn1">[14]</xref>. Our approach solves the problem of ToxRTool's unrealistic assumption, as it incorporates the differences among respondents, and allows for a useful representation of the entire range of responses.</p>
<p>Furthermore, Qualichem could be used to include a wider range of studies in risk assessment in a more balanced way. Quality assessment using Qualichem would apply the same criteria to evaluate both industry studies that follow OECD or GLP guidelines and non-standardized academic studies that also provide scientific knowledge that is useful for decision-making.</p>
<p>As industrial chemicals such as BPA are present in many consumer products <xref ref-type="bibr" rid="pone.0087738-ANSES1">[15]</xref>, studies used to create a regulatory framework have the potential to impact the lives of millions of people; as such, assessments of them must be rigorous. Quality assessment is a key step in helping to choose which studies regulatory decisions should be based on.</p>
<p>The role of regulatory science is to provide the best available scientific knowledge at a certain moment, and not the unachievable ideal of “perfect” knowledge. In line with the post-normal science proposal for addressing the robustness of science used to set policy <xref ref-type="bibr" rid="pone.0087738-Funtowicz1">[16]</xref>, the Qualichem tool addresses more than lack of knowledge (epistemological uncertainty), and looks more broadly at the concept of quality, which also includes the following dimensions:</p>
<list list-type="bullet"><list-item>
<p><bold>technical:</bold> incorporates technical errors caused by imprecise instruments or measurement methods.</p>
</list-item><list-item>
<p><bold>methodological:</bold> incorporates whether and how researchers use the best available scientific knowledge and practices in drafting the research protocol, make assumptions when knowledge is lacking or choose among several available methods for assessing a parameter.</p>
</list-item><list-item>
<p><bold>normative:</bold> incorporates interpretation of raw data and conclusions about the level of evidence provided by that data.</p>
</list-item><list-item>
<p><bold>communication:</bold> incorporates how completely and understandably the research is reported.</p>
</list-item></list>
<p>Compared with the current framework for evaluation that is commonly used in regulatory chemical risk assessment <xref ref-type="bibr" rid="pone.0087738-ECHA1">[11]</xref>, our definition of quality covers both <italic>relevance</italic> and <italic>reliability</italic>. In addition, quality includes aspects related to the interpretation and communication of the results, and to technical aspects of measurement, e.g., analytical techniques. Most importantly, the concept of quality highlights the importance of the knowledge production process—which directly influences the robustness and usefulness of scientific results used for a particular decision-making situation—instead of focusing on the results alone. Our approach aligns with previous work on knowledge quality assessment (KQA) tools, which are essential for timely and adequate policy responses in situations of risk governance <xref ref-type="bibr" rid="pone.0087738-VanderSluijs1">[17]</xref> and for responding to the credibility crisis of science used to set controversial policy <xref ref-type="bibr" rid="pone.0087738-Vander1">[18]</xref>–<xref ref-type="bibr" rid="pone.0087738-Maxim1">[19]</xref>. We draw on previous experience with the KQA tool NUSAP (Numeral, Unit, Spread, Assessment, Pedigree) <xref ref-type="bibr" rid="pone.0087738-VanderSluijs2">[20]</xref>, already used to assess the quality of estimates of NO<sub>x</sub>, SO<sub>2</sub>, NH<sub>3</sub> <xref ref-type="bibr" rid="pone.0087738-VanGijlswijk1">[21]</xref> and volatile organic compound emissions <xref ref-type="bibr" rid="pone.0087738-VanderSluijs3">[22]</xref> in the Netherlands and to assess health risks from tropospheric ozone <xref ref-type="bibr" rid="pone.0087738-Kloprogge1">[23]</xref> emissions from a waste incinerator <xref ref-type="bibr" rid="pone.0087738-Craye1">[24]</xref>; and from electromagnetic fields from overhead power lines <xref ref-type="bibr" rid="pone.0087738-DeJong1">[25]</xref>.</p>
<p>The objective of Qualichem is to provide a systematic and transparent framework to assess the quality of studies used in regulatory chemical risk assessment (<xref ref-type="sec" rid="s2">Materials and methods</xref>). To validate this tool, it was tested with relevant academic and health agency scientists, and its applicability checked using both short (several pages) and long (4,000 pages) studies (Results). Other objectives of this paper are to 1) compare the quality criteria addressed in our tool with those previously used by European institutions that provide expertise on the risk of BPA and by the OECD and OPPTS standardized guidelines relevant to the two BPA studies evaluated here (sections 3.2. and 3.3.), 2) examine whether some criteria hold more weight in determining the final quality of a study (section 3.4), and 3) examine whether quality assessments are influenced by the disciplinary background and publication history of the respondents (section 3.5).</p>
</sec><sec id="s2" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s2a">
<title>Ethics statement</title>
<p>This study did not involve patients, and written consent was not required. Consent to participate was voluntary and was obtained by email. Anonymity and confidentiality of the interviews were guaranteed to all participants. The interview protocol has been sent to participants before the meeting. The participant was then asked to give oral consent and to allow audio recording of the interview. We did conduct research outside our country of residence but approaching local authorities was not needed because interviewees' institutional information were not used for our project. The ethics evaluation committee of Inserm (IORG0003254, FWA00005831), the Institutional Review Board (IRB00003888) of the French Institute of medical research and Health, approved the study protocol, including the information sheet on the expert profile and the oral consent procedure (Opinion number 13-123).</p>
</sec><sec id="s2b">
<title>2.1. The quality criteria: an original typology</title>
<p>We developed the typology of quality criteria (<xref ref-type="supplementary-material" rid="pone.0087738.s001">Text S1</xref>) iteratively, following the main steps of the process of knowledge production of <italic>in vivo</italic> studies; using ECHA's guidelines for the evaluation of information <xref ref-type="bibr" rid="pone.0087738-ECHA1">[11]</xref>; analysis of study criticism expressed by scientists (e.g., <xref ref-type="bibr" rid="pone.0087738-Myers1">[13]</xref>, <xref ref-type="bibr" rid="pone.0087738-vomSaal1">[26]</xref>) or safety agencies like EFSA; previous literature on reporting <italic>in vivo</italic> studies <xref ref-type="bibr" rid="pone.0087738-Kilkenny1">[9]</xref>, <xref ref-type="bibr" rid="pone.0087738-Schneider1">[12]</xref> and on sources that look at heterogeneity in expert judgments <xref ref-type="bibr" rid="pone.0087738-Wandall1">[8]</xref>, <xref ref-type="bibr" rid="pone.0087738-Rudn1">[14]</xref>, authors' personal experiences with regulatory documents and authors' expertise in a safety agency. In these sources, we identified the criteria used to criticize, argue in favor of, or evaluate the scientific robustness of <italic>in vivo</italic> studies. We considered the various lines of argumentation identified as expressions of expert judgments about <italic>in vivo</italic> studies, and that were therefore relevant criteria to include in our typology.</p>
<p>To check the robustness of our typology and incorporate feedback from the scientists interviewed, our interview protocol contained a final question about the need to exclude criteria or to include new ones.</p>
<p>We tested the typology with 12 scientists in academia and health agencies—a sample that is in line with the current literature on expert elicitation <xref ref-type="bibr" rid="pone.0087738-Knol1">[27]</xref> that recommends 6 to 12 experts. A thirteenth expert validated the typology but his responses have been excluded from the Qualichem analysis. He only had time to give a general assessment of the study and did not use the proposed Likert scale. Due to lack of time, two of the twelve experts responded only to the questions referring to the criteria in the “Protocol” part of our typology (<xref ref-type="table" rid="pone-0087738-t001">Table 1</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s001">Text S1</xref>). We used two case studies—a journal article (Tyl et al., 2002) <xref ref-type="bibr" rid="pone.0087738-Tyl1">[28]</xref> and a 4,000-page report (Stump, 2009) <xref ref-type="bibr" rid="pone.0087738-Stump1">[29]</xref>—to test if our protocol can be used within a reasonable time frame on both short and longer studies. Both studies were funded by the chemical industry, which is common in regulatory assessment of chemical risks.</p>
<table-wrap id="pone-0087738-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.t001</object-id><label>Table 1</label><caption>
<title>Typology of quality criteria for <italic>in vivo</italic> studies.</title>
</caption><alternatives><graphic id="pone-0087738-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Class</td>
<td align="left" rowspan="1" colspan="1">Quality criteria</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1">Protocol Quality Criteria</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1. Substance</td>
<td align="left" rowspan="1" colspan="1">Check of substance properties; check of storage conditions; procedure for obtaining formulations; choice of the control</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2. Experimental animals</td>
<td align="left" rowspan="1" colspan="1">Correspondence between the characteristics of tested animals and the characteristics of exposed humans; choice of test species/strain; handling of experimental animals; monitoring of experimental animals; monitoring of controls</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3. Assay</td>
<td align="left" rowspan="1" colspan="1">Sensitivity of the assay; choice of experimental unit; number of groups tested; number of control groups; robustness of regulatory guidelines; test of a single substance or mixture</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4. Measured effects</td>
<td align="left" rowspan="1" colspan="1">Parameters observed; observation time; biological level observed; precision of effects measurement</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5. Tested exposure</td>
<td align="left" rowspan="1" colspan="1">Toxicokinetic stage for measuring exposure; level of doses tested; exposure duration; number exposure levels; route of administration; precision of exposure measurement; control of confounders</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6. Laboratory procedures and human factors</td>
<td align="left" rowspan="1" colspan="1">Experimenter bias</td>
</tr>
<tr>
<td colspan="2" align="left" rowspan="1">Results Quality Criteria</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7. Results reporting</td>
<td align="left" rowspan="1" colspan="1">Results reporting; graphical data representation; abstract vs. raw data</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8. Results analysis</td>
<td align="left" rowspan="1" colspan="1">Statistical methods used; statistical unit; treatment of data for statistics; statistical power; evaluation of errors, uncertainty, variability</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9. Causal interpretation</td>
<td align="left" rowspan="1" colspan="1">Interpretation of dose-response; biological mechanism; extrapolation from animals to humans; functional relevance of changes</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10. Results interpretation: epistemological context</td>
<td align="left" rowspan="1" colspan="1">Epistemological background</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">11. Results check</td>
<td align="left" rowspan="1" colspan="1">Status of peer-review; coherence with literature</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">12. Results interpretation: expert judgment</td>
<td align="left" rowspan="1" colspan="1">Results vs. raw data; assumptions</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">13. Variability</td>
<td align="left" rowspan="1" colspan="1">Variability</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>Our 45 quality criteria (defined in <xref ref-type="supplementary-material" rid="pone.0087738.s002">Text S2</xref>) are assembled into thirteen different classes (<xref ref-type="table" rid="pone-0087738-t001">Table 1</xref>) that fall into two general categories: “Protocol” and “Results”. The Protocol part of the typology includes quality criteria that are relevant to the technical and methodological aspects of best available scientific knowledge and practices. The Results part includes only two criteria for technical and methodological quality: the results analysis and results check. The remaining results criteria pertain to communicational quality (such as results reporting) and normative quality (such as causal interpretation, interpretation in light of the existing epistemological background, and expert judgment of the level of evidence provided by the results) (<xref ref-type="supplementary-material" rid="pone.0087738.s001">Text S1</xref>).</p>
<p>The number of criteria evolved slightly thorough the interviews, based on comments from the experts. Therefore, some experts did not use the full set of 45 criteria. Four of the 45 criteria were added after interviews with two experts, one more criterion was added after the interview with the third expert, and two additional criteria were added after interviews with the sixth expert. The six remaining experts used the full set of 45 criteria and considered it to be complete.</p>
</sec><sec id="s2c">
<title>2.2. Elicitation protocol</title>
<p>We interviewed each expert respondent individually in either 2012 or 2013. To prepare respondents for the interviews, we pasted relevant text from the study below each question. This saved respondents from having to search the study for the elements needed to answer the question or from using their memory to recall the relevant information, which could lead to imprecise responses.</p>
<p>Both studies claimed to comply with regulatory guidelines, and details of the guidelines that were relevant for assessing the study may not have been reported as part of the study. For this reason, we also copied the elements of the guidelines appropriate to each criterion in the survey.</p>
<p>Each respondent assessed one of the two studies, not both. To assess the quality of each study—specifically, how well they incorporate best scientific knowledge and practices—we presented each respondent with a question related to each of the criteria included in our typology. Elicitation protocols can be provided on demand. For example, the first question of our protocol was: “<italic>Were the substance's properties checked before and during the experiment, in accordance with best scientific practices?</italic>” The text from the study that refers to the check of substance properties was copied below the question. The respondent was invited to answer using a Likert scale (<xref ref-type="table" rid="pone-0087738-t002">Table 2</xref>) and to explain his/her response (<xref ref-type="supplementary-material" rid="pone.0087738.s007">Text S7</xref>).</p>
<table-wrap id="pone-0087738-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.t002</object-id><label>Table 2</label><caption>
<title>Scale used for expert elicitation.</title>
</caption><alternatives><graphic id="pone-0087738-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Answer</td>
<td align="left" rowspan="1" colspan="1">On a scale from 1 to 6, the answer corresponds to the score</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Agree strongly</td>
<td align="left" rowspan="1" colspan="1">6</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Agree moderately</td>
<td align="left" rowspan="1" colspan="1">5</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Agree slightly</td>
<td align="left" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Disagree slightly</td>
<td align="left" rowspan="1" colspan="1">3</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Disagree moderately</td>
<td align="left" rowspan="1" colspan="1">2</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Disagree strongly</td>
<td align="left" rowspan="1" colspan="1">1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">I cannot answer</td>
<td align="left" rowspan="1" colspan="1">CA</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Not applicable</td>
<td align="left" rowspan="1" colspan="1">NA</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>Interviews were recorded and transcribed. We used the transcriptions to analyze the results (Results section, <xref ref-type="supplementary-material" rid="pone.0087738.s003">Text S3</xref> and <xref ref-type="supplementary-material" rid="pone.0087738.s004">Text S4</xref>).</p>
</sec><sec id="s2d">
<title>2.3. Choice of respondents</title>
<p>Respondents were either chosen through an extensive search of international peer-reviewed literature for authors of articles on BPA toxicology, were experts who had participated in BPA working groups in health agencies in Europe or were specialists in BPA and/or endocrine disrupters with expertise relevant to health agencies that were recommended by the scientists involved in our project. We searched all personal and other web pages and then listed disciplinary areas using the exact wording found in these documents, without trying to create exclusive classes. As a result, some disciplinary areas on our list overlap and some encompass others.</p>
<p>Following this process, we contacted 64 scientists by email. Thirteen agreed to participate. Four respondents were employed by safety agencies and nine were academics.</p>
</sec><sec id="s2e">
<title>2.4. Choice of case studies</title>
<p>The controversy over the health risks of BPA repeatedly focuses on the quality assessment methods used in different health agencies, and on the reliance on standardized guidelines rather than academic research to select pivotal studies.</p>
<p>The two studies used as case studies here played an important role in BPA regulation. Tyl et al. (2002) was used as a critical study for choosing the NOAEL for BPA in Europe. Stump (2009) was devised in response to divergent views about BPA neurotoxicity between three Nordic and other European countries; it has been extensively reviewed by an EFSA working group. Tyl et al. (2002) has been considered robust enough to drive regulatory decisions <xref ref-type="bibr" rid="pone.0087738-SCF1">[30]</xref>–<xref ref-type="bibr" rid="pone.0087738-ECB1">[31]</xref>, while Stump (2009) has been considered invalid <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>.</p>
</sec><sec id="s2f">
<title>2.5. Definition of controversial criteria: a measure of aggregated quality</title>
<p>It can be cumbersome and difficult to read a graphical representation of 45 criteria. To facilitate understanding and focus on the most important results, we have defined two categories of criteria: controversial and critical. The subset of criteria that we call controversial or critical is specific to each study assessed with Qualichem; they are not pre-defined as such, but are based on the outcome of the evaluation.</p>
<p>The two categories of criteria, controversial and critical, allow us to distinguish two levels of quality:</p>
<list list-type="bullet"><list-item>
<p><bold>aggregated quality for each criterion</bold>, using the median of the expert respondents' scores; this is an indicator of majority (consensus) views on aspects of study quality.</p>
</list-item><list-item>
<p><bold>level of confidence</bold> for the whole study, using a decision rule based on critical criteria (see below); this is an indicator of divergence between expert respondents, and gives important weight to the scores of critical expert respondents.</p>
</list-item></list>
<p><bold>Controversial criteria</bold> are those for which, on the scale from 1 to 6 (<xref ref-type="table" rid="pone-0087738-t002">Table 2</xref>):</p>
<list list-type="bullet"><list-item>
<p>at least one respondent gave a score of 3 or less, or</p>
</list-item><list-item>
<p>there is a difference of at least two points between any two scores.</p>
</list-item></list>
<p>The graphical representation shows all controversial criteria. All the other criteria—i.e., those that are not controversial according to our definition—received scores of 5 or 6 and were considered to have a high aggregated quality.</p>
<p>The graphical representation was built using a tailored Excel file (<xref ref-type="supplementary-material" rid="pone.0087738.s008">Text S8</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s009">Text S9</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s010">Text S10</xref>). The graphic is divided into three colored areas: red (including scores and median scores &lt;3), orange (for scores and median scores between 3 and 4) and green (for scores and median scores &gt;4). For each criterion, a line covers the full range, from the lowest score to the highest score in the group of responding experts. The median score is represented by an “x” and the interquartile range is represented by a rectangle.</p>
<p><bold>The aggregated quality of an individual criterion</bold> is assigned as follows:</p>
<list list-type="bullet"><list-item>
<p><bold>High aggregated quality</bold>: median in the green area (&gt;4)</p>
</list-item><list-item>
<p><bold>Average aggregated quality</bold>: median in the orange area (ranging from 3 to 4)</p>
</list-item><list-item>
<p><bold>Low aggregated quality</bold>: median in the red area (&lt;3).</p>
</list-item></list>
<p>In other words, if the “x” in <xref ref-type="fig" rid="pone-0087738-g001">figures 1</xref>, <xref ref-type="fig" rid="pone-0087738-g002">2</xref> and <xref ref-type="fig" rid="pone-0087738-g003">3</xref>, is in the red area, the aggregated quality of the criterion is low. If the “x” is in the orange area, the aggregated quality is average, and if it is in the green area the aggregated quality is high.</p>
<fig id="pone-0087738-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.g001</object-id><label>Figure 1</label><caption>
<title>Quality assessment of Tyl et al. (2002), using Qualichem with eight respondents.</title>
<p>For the study of Tyl et al. (2002), of the 45 criteria, the figure represents only the 35 controversial criteria out of the total set of 45 criteria. The remaining 10 criteria were not controversial according to our definition; they received scores of 5 or 6 and were considered to be of high aggregated quality. The figure is divided in three colored areas: red (including scores and medians &lt;3), orange (for scores and medians between 3 and 4) and green (for scores and medians &gt;4). A line covers the full range, from the lowest score to the highest score in the group of responding experts. The median of the scores is represented by an “x” and the interquartile range is represented by a rectangle. If the median (x) is in the red area, the aggregated quality of the criterion is low. If the median is in the orange area, the aggregated quality is average. If the median is in the green area, the aggregated quality is high. The interquartile range is an indicator of inter-expert heterogeneity. Thirty of the 35 controversial criteria were of high aggregated quality (the median is in the green area). Of the five remaining criteria, three were of average aggregated quality (the median in the orange area) and two were of low aggregated quality (the median is in the red area).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.g001" position="float" xlink:type="simple"/></fig><fig id="pone-0087738-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.g002</object-id><label>Figure 2</label><caption>
<title>Quality assessment of Stump (2009), using Qualichem with four respondents.</title>
<p>For the report of Stump (2009), of the possible 45, the figure represents only the 16 controversial criteria. All the other criteria—those that are not controversial according to our definition—received scores of 5 or 6 and were considered as having a high aggregated quality. The figure is divided in three colored areas: red (including scores and medians &lt;3), orange (for scores and medians between 3 and 4) and green (for scores or medians &gt;4). A line covers the full range from the lowest score to the highest score in the group of responding experts. The median of the scores is represented by an “x” and the interquartile range is represented with a rectangle. If the median (x) is in the red area, the aggregated quality of the criterion is low. If the median is in the orange area, the aggregated quality is average. If the median is in the green area, the aggregated quality is high. The interquartile range is an indicator of inter-expert heterogeneity. Nine of the 16 controversial criteria were of high aggregated quality (median fell in the green area). The remaining 7 criteria were all of average aggregated quality (median fell in the orange area).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.g002" position="float" xlink:type="simple"/></fig><fig id="pone-0087738-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.g003</object-id><label>Figure 3</label><caption>
<title>Relative importance of the Qualichem quality criteria to the global quality of the study.</title>
<p>Eight of the twelve respondents agreed to select a subset of up to 15 criteria that they considered to be the most important for the quality of <italic>in vivo</italic> study results. The figure shows the combined 39 criteria chosen by these eight experts. The vertical axis represents the 39 criteria, and the horizontal axis represents the percentage of respondents that selected each criterion.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.g003" position="float" xlink:type="simple"/></fig>
<p>The interquartile range shown with a rectangle on the graphical representation is another indicator of inter-expert heterogeneity.</p>
<p><bold>Critical criteria</bold> are a subset of controversial criteria, and are used to calculate a multi-expert aggregated level of confidence in the study. The term “level of confidence” has a very precise meaning in statistics; however, in this paper we use “level of confidence” to referring to the quality of <italic>in vivo</italic> studies. We used this wording because our experience is that this formulation is easy to understand and is common wording for experts in health agencies <xref ref-type="bibr" rid="pone.0087738-ANSES1">[15]</xref>.</p>
</sec><sec id="s2g">
<title>2.6. Definition of critical criteria: a measure of the level of confidence in a study</title>
<p>A higher quality study will have high scores on more criteria. Depending on the scores given by the respondents, some criteria might play a greater role than others in determining the overall quality of the study. <bold>Critical criteria</bold> are defined as those controversial criteria of which the scores meet at least one of the following conditions:</p>
<list list-type="bullet"><list-item>
<p>they are very heterogeneous—there is a difference of 4 or 5 points between any two respondents (the maximum possible difference between the scores of two respondents is 5);</p>
</list-item><list-item>
<p>they are very low scores—at least one respondent gave a score of 1; or</p>
</list-item><list-item>
<p>they show low or average aggregated quality—the median of scores is ≤4 (the “x” in the red or orange area, <xref ref-type="fig" rid="pone-0087738-g001">Fig. 1</xref> and <xref ref-type="fig" rid="pone-0087738-g002">2</xref>).</p>
</list-item></list>
<p>To define an <bold>overall level of confidence in a study</bold>, we established a decision rule based on the number of critical criteria. A study has:</p>
<list list-type="bullet"><list-item>
<p><bold>a high level of confidence</bold> if less than one-third of criteria (≤14/45) are critical</p>
</list-item><list-item>
<p><bold>an average level of confidence</bold> if between one-third and two-thirds of criteria (15 to 30/45) are critical</p>
</list-item><list-item>
<p><bold>a low level of confidence</bold> if more than two-thirds of criteria (≥31/45) are critical</p>
</list-item></list>
<p>This decision rule is based in the assumption that all criteria have an equal weight, which may not be valid (see discussion). Additional decision rules could be established, and testing these decision rules could be the object of further research, before the method is standardized.</p>
</sec><sec id="s2h">
<title>2.7. Relative weights of different Qualichem criteria</title>
<p>We assessed the relative weight of each Qualichem criteria in determining the overall (aggregated) quality of the studies. Our respondents were given two options: a) indicate that all criteria are equally important, and b) choose a maximum of 15 criteria that are the most important for the overall quality of the results.</p>
</sec><sec id="s2i">
<title>2.8. Influence of experts' affiliation and background/expertise on the use of Qualichem</title>
<p>Each of the respondents was asked to fill in an “expert profile” (<xref ref-type="supplementary-material" rid="pone.0087738.s005">Text S5</xref>) designed to identify their discipline, their publication activity (particularly on BPA and endocrine disrupters), the nature of their knowledge of BPA (i.e., experimental and/or theoretical), whether their expertise is specialized on BPA and/or endocrine disrupters or generalized on toxicology or other areas, and their institutional affiliation and financial links with industry.</p>
<p>We did not expect a statistical correlation between respondents' characteristics and their responses. However, these characteristics could influence their expert judgments about study quality. For the purpose of comparison, we isolated and graphically represented affiliation or disciplinary clusters in a separate figure. We created this representation for the respondents who included “endocrinology” or “endocrine toxicology” among their fields of competence. Also, we compared the results of this cluster, i.e., criteria in the red/orange area, with the results obtained on all the respondents together. Significant, easy-to-observe differences can be interpreted as an indication of the influence of discipline/affiliation/interests.</p>
<p>For the future use of Qualichem, any other disciplinary, conflicting interests or affiliation clusters can be similarly isolated and compared. Such a separation can be done easily using the internet-based version of Qualichem available at URL: <ext-link ext-link-type="uri" xlink:href="http://www.qualichem.cnrs.fr/" xlink:type="simple">http://www.qualichem.cnrs.fr/</ext-link>.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>3.1. Two <italic>in vivo</italic> case studies that assess the effects of BPA</title>
<p>This section presents the Qualichem results for the two case studies: Tyl et al. (2002) and Stump (2009).</p>
<p>As a reminder, the graphical representations of Qualichem (<xref ref-type="fig" rid="pone-0087738-g001">Fig. 1</xref> and <xref ref-type="fig" rid="pone-0087738-g002">2</xref>) include only controversial criteria. The assessment of the level of confidence in a study using Qualichem is based on the subset of those controversial criteria that are considered critical.</p>
<p>The average length of an interview was two hours—about 90 minutes of that was required to fill out the Qualichem survey. We assume an additional two to four hours was required for the respondent to read the study before the meeting. However, in some cases, the time for analyzing some particular studies might be much longer, e.g., when re-analysis of original raw data is done. However, we estimate that this applies to particular situations and is not the regular case of peer-reviews.</p>
<sec id="s3a1">
<title>3.1.1. Qualichem in vivo for Tyl et al., 2002</title>
<p><xref ref-type="fig" rid="pone-0087738-g001">Figure 1</xref> represents the application of Qualichem to the Tyl et al. (2002) study—eight respondents participated (<xref ref-type="supplementary-material" rid="pone.0087738.s008">Text S8</xref>). The respondents provided justification for why they assigned a score to each criterion, and these are presented in <xref ref-type="supplementary-material" rid="pone.0087738.s003">Text S3</xref>. Our goal was to synthesize their explanations without critically commenting on them. For example, bibliographic references were not included unless the respondents themselves provided them.</p>
<p>Of the possible 45, 35 controversial criteria were identified using Qualichem. In most cases in which a six was assigned to a criterion, it was either because the study respected regulatory guidelines or because a respondent had personal experience with relevant current practice.</p>
<p>The median score for a given criterion, as a reminder, represents its aggregated quality. Thirty of the 35 controversial criteria were of high aggregated quality (the median is in the green area). Of the five remaining criteria, three were of average aggregated quality (the median is between 3 and 4 and in the orange area) and two were of low aggregated quality (the median is in the red area).</p>
<p>Twenty-seven of the controversial criteria were also identified as critical, which is more than one-third of the 45 criteria. As such, confidence in Tyl et al. (2002) can be considered average. This contradicts official evaluations of this study by the Scientific Committee on Food <xref ref-type="bibr" rid="pone.0087738-SCF1">[30]</xref> and the European Chemicals Bureau (ECB) <xref ref-type="bibr" rid="pone.0087738-ECB1">[31]</xref>, who considered it a very good quality, “pivotal” study, and suitable to use to determine the NOAEL of BPA.</p>
</sec><sec id="s3a2">
<title>3.1.2. Qualichem in vivo for Stump (2009)</title>
<p><xref ref-type="fig" rid="pone-0087738-g002">Figure 2</xref> represents the application of Qualichem to the report by Stump (2009) (<xref ref-type="supplementary-material" rid="pone.0087738.s009">Text S9</xref>). Despite the large number of competent scientists contacted by email (64), only four respondents agreed to participate. Because the objective was to test the tool, it is not the number of experts for each case study that is important, but the total number of experts that participated in testing Qualichem. The total number was twelve, which is well within the typical goal range in expert elicitation studies (6 to 12 experts <xref ref-type="bibr" rid="pone.0087738-Knol1">[27]</xref>).</p>
<p>The respondents provided justification for why they assigned a score to each criterion, and these are presented uncritically in <xref ref-type="supplementary-material" rid="pone.0087738.s003">Text S3</xref>.</p>
<p>Of the possible 45, 16 controversial criteria were identified using Qualichem. Nine of these controversial criteria were of high aggregated quality (median fell in the green area). The remaining seven were all of average aggregated quality (median fell in the orange area).</p>
<p>All 16 of the controversial quality criteria were also identified as critical. Because between one-third and two-thirds of the criteria were critical, the study can be labeled as providing an average level of confidence, according to our decision rule. This characterization contradicts the evaluation made by the EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>, who rejected the study.</p>
</sec><sec id="s3a3">
<title>3.1.3. Two levels of quality</title>
<p>We distinguished two levels of quality, i.e., aggregated quality and level of confidence for the whole study. They provide a way to represent both majority and minority opinions, and they should be read together. For both studies, most criteria show high aggregated quality (median in the green area), which indicates that most scores were favorable. However, both studies also receive only an average level of confidence, which shows that minority opinions are numerous and important.</p>
<p>In the next section, we compare the criteria used by SCF, ECB or EFSA with those of the Qualichem typology to explore the reasons behind their contradictory evaluations for the two studies.</p>
</sec></sec><sec id="s3b">
<title>3.2. Assessment of study quality in safety agencies</title>
<p>Though these two studies may have been assessed by national health agencies, we focused on comparing Qualichem with quality assessments done by European institutions. These institutions play an essential role in advising decision-making on regulatory values for exposure to BPA in European countries, and it is relatively easy to access their documents.</p>
<sec id="s3b1">
<title>3.2.1. Tyl et al. (2002)</title>
<p>The Tyl study was used in the Opinion of the Scientific Committee on Food <xref ref-type="bibr" rid="pone.0087738-SCF1">[30]</xref> as a pivotal study for deriving an NOAEL for BPA. This study was thought to be of good quality because of its long observation time, use of a high number of doses, and inclusion of parameters specific to endocrine disruptors such as anogenital distance, acquisition of puberty, estrous cyclicity, sperm parameters and nipple retention in males. The effects on body weight and some organ weights seen by the authors at 50 mg/kg bw/day were considered to be relevant; therefore, the NOAEL was set at 5 mg/kg bw/day. No quality weakness was highlighted in the SCF assessment of the study.</p>
<p>Just one year later, the ECB reinterpreted the raw data, leading to a change in the NOAEL. In opposition to the SCF <xref ref-type="bibr" rid="pone.0087738-SCF1">[30]</xref>, the ECB excluded the effects found at 50 mg/kg bw/day by considering them not “<italic>consistent</italic>” <xref ref-type="bibr" rid="pone.0087738-ECB1">[31]</xref> (p. 180). The ECB concluded that “<italic>overall, this study showed 500 mg/kg bisphenol-A causes a reduction in the number of pups per litter</italic>” and that “<italic>the NOAEL for both parental and reproductive toxicity is 50 mg/kg/day</italic>”. The ECB considered the study of high quality, and referred to it as “<italic>well conducted and reported</italic>” (pp. 179), “<italic>comprehensive, good-quality multigeneration</italic>” investigation, and also referred to the use of an OECD guideline (p. 214). An illustrative detail is that this reference to the OECD two-generation reproduction toxicity study guideline (probably OECD 416) is incorrect, because the study actually followed an OPPTS guideline <xref ref-type="bibr" rid="pone.0087738-US1">[34]</xref>, and the two guidelines are not identical.</p>
<p>The 2006 EFSA report confirmed the NOAEL of 5 mg/kg bw/day, which was considered adequate and in accordance with a more recent, modified OECD 416-guideline study on mice <xref ref-type="bibr" rid="pone.0087738-Tyl2">[35]</xref>. The EFSA Panel considered that this NOAEL, “<italic>identified in the SCF evaluation of 2002 is still valid</italic>” <xref ref-type="bibr" rid="pone.0087738-EFSA3">[36]</xref> (p. 6).</p>
</sec><sec id="s3b2">
<title>3.2.2. Stump (2009)</title>
<p>In contrast to the Tyl study, for which detailed analysis of the strengths and weaknesses of the study is not available in regulatory documents, EFSA dedicated a whole report to the Stump study. Below, we compare quality criteria addressed by these documents with the results produced with Qualichem.</p>
<p>For six of the 16 critical quality criteria identified with Qualichem, similar assessments were done in_the EFSA reports <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>:</p>
<list list-type="bullet"><list-item>
<p>Regarding the <bold>sensitivity of the assay</bold>, the Biel maze was characterized as not having the “<italic>potential to demonstrate equivalence of BPA compared to a control</italic>”, because EFSA's Assessment and Methodology Unit revealed “<italic>an extreme high variability, not only in the study data for the PND62 trials, but also in the data for PND22. This variability might be due to other non-modelled or not-possible-to model aspects of the experimental design or execution of the experiment</italic>”. However, in contrast to Qualichem, this criterion was given very high weight by the EFSA working group—decisive over all the others—and was considered sufficient for declaring: “<italic>therefore, this study should be considered as inconclusive</italic>” <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref> (pp. 25).</p>
</list-item><list-item>
<p>The <bold>choice of the parameters observed</bold> was also found to be incomplete by the EFSA working group (WG), whose experts identified missing aspects of behavior related to anxiety, avoidance learning, schedule-controlled behavior, sexual dimorphic behavior and impulsiveness. Nevertheless, the WG considered this criterion less important than the sensitivity of the assay, as it was considered not sufficient to invalidate the study. Qualichem scores for this criterion ranged from 1 to 6, with the median in the orange area (4).</p>
</list-item><list-item>
<p>The <bold>interpretation of results as compared to raw data</bold> was comparable between Qualichem, (scores from 1 to 6) and EFSA. Those aspects where a difference between the raw data and the authors' interpretation was identified—namely, effects of BPA on gross motor movements; convulsions and seizures; and censored and variable data on learning and memory from the Biel maze <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref> were declared inconclusive and the respective parts of the study were considered unusable.</p>
</list-item><list-item>
<p>The <bold>epistemological background</bold> was found to be lacking mechanistic knowledge, in particular on the interaction between BPA and estrogen receptors <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>. Qualichem produced a similar result, with the median score in the orange area (3).</p>
</list-item><list-item>
<p>The treatment of <bold>assumptions</bold> was both a critical quality criterion in Qualichem (<xref ref-type="fig" rid="pone-0087738-g002">Fig. 2</xref>) and repeatedly addressed by EFSA. Qualichem respondents were not very precise, but expressed that assumptions were not reported adequately. On the contrary, EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref> was very specific (pp. 7), stating that the analysis was “<italic>based on very general hypotheses</italic>” about the categorical variables of the model, the effects were potentially random, and the shape of the distribution of the response variable may not have been normal.</p>
</list-item><list-item>
<p>One of the most important critiques brought by the EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref> reports was about <bold>variability</bold>. In the learning and memory results, the variability was considered too high for any conclusion to be drawn. In contrast, the expected variability in motor activity between males and females was not found. Variability also seems to have been considered very important for rejecting the whole study. One of the Qualichem respondents gave a minimal score of 1 for this criterion, while the other three assigned scores of 5 or 6.</p>
</list-item></list>
<p>As well, the value of seven other quality criteria assigned by EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref> opposed our Qualichem results:</p>
<list list-type="bullet"><list-item>
<p>For the <bold>choice of the control</bold>, our four respondents felt that a negative control was justified, and assigned scores of 5 (1 respondent) and 6 (three respondents). In contrast, EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref> considered that “<italic>an oestrogenic reference compound was not included. Therefore, sensitivity of the test parameters to oestrogenic substances has not been demonstrated</italic>” (pp. 19). Similarly, EFSA (2010b) considers that “<italic>as no positive control group was inserted in the Stump et al. (2010) study it is not possible to know if a positive effect could have been statistically picked up if one truly existed”</italic> (pp. 6). However, this continues with another statement, more in line with Qualichem responses: “<italic>however, it should be noted that no generally accepted reference compounds are available for this purpose</italic>” (pp. 22). The Stump (2009) study was published in 2010 in the journal Toxicological Sciences <xref ref-type="bibr" rid="pone.0087738-Stump2">[37]</xref>.</p>
</list-item><list-item>
<p><bold>Results reporting</bold> was often criticized by EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>, referencing incomplete data for surface righting response, ambulatory count, or random effects for litter on PND62. Furthermore, some aspects of the protocol are not clear; for example, the definition of “errors” in the Biel maze <xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>. Two Qualichem respondents gave maximal scores of 6, saying they felt the data reporting was exhaustive. The other two gave scores of 5, noting the statistical methods used were complex and difficult to understand. These high scores indicate that reporting was not considered to be a critical quality criterion by the Qualichem respondents. The EFSA WG did not quantify this criterion so it is difficult to compare the importance given to it.</p>
</list-item><list-item>
<p><bold>The choice and treatment of data for statistical analysis</bold> and <bold>the choice of the statistical method</bold> were heavily criticized by the EFSA experts because of the lack of statistical treatment of the time-to-escape data, the data for long-term memory effects, and of data censoring. EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref> considered that “<italic>the Biel maze had not been appropriately statistically analyzed and therefore conclusions drawn from the results of these analyses cannot be relied upon</italic>” (pp. 4). Furthermore, pooling the results diluted the possibility of finding effects at some specific moments in time. With regard to data treatment, two of the Qualichem respondents declined to answer due to a lack of specific statistical competence. The two others gave maximal scores. Three Qualichem respondents answered the question about the choice of statistical analysis. One assigned a 2, giving arguments similar to EFSA's. The two other were uncritical, giving scores of 5 and 6.</p>
</list-item><list-item>
<p>The EFSA WG considered the <bold>graphical representation of the data</bold> inadequate for some results from the Biel maze test, saying it impeded interpretation and comparison of the slopes. In contrast, all four Qualichem respondents gave maximal scores for this question.</p>
</list-item><list-item>
<p>EFSA also considered <bold>the choice of the observation time</bold> insufficient (3 minutes for the Biel maze) <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref>–<xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>. All four Qualichem respondents gave maximal scores, referencing the total time of observation in the experiment (three generation, but ignoring the time of observation for particular parameters).</p>
</list-item><list-item>
<p><bold>Coherence with other studies</bold> was considered absent for popcorn seizures and therefore a sufficient reason to cast “<italic>doubt on the relevance of this observation</italic>” <xref ref-type="bibr" rid="pone.0087738-EFSA1">[32]</xref> (p. 28). Both the study by Stump and the rest of the existing literature on neurobehavioral toxicity were considered too low quality to be used to assess the effects of BPA. Three of the Qualichem respondents gave maximal scores, indicating that they considered the results of the study in line with other robust published results. Two respondents did not provide justification for their scores, but a third said that the Stump study was in line with other robust studies, even if it contradicted other studies considered to be of low quality. The fourth respondent could not answer, arguing that no other comparable study, in terms of number of animals and doses employed, was available in the literature.</p>
</list-item><list-item>
<p><bold>Experimenter's bias</bold> was potentially associated with the imprecise definition of “error” in the Biel maze test. According to EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA2">[33]</xref>, “<italic>this definition is imprecise as it could be subject to different interpretations</italic>” (pp. 6). None of the Qualichem respondents noted this.</p>
</list-item></list>
<p>A criterion of “reproducibility” was used by EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA3">[36]</xref> to argue for rejecting studies that indicate low dose effects of BPA: “the Panel considered that low-dose effects of BPA in rodents have not been demonstrated in a robust and reproducible way, such that they could be used as pivotal studies for risk assessment” (p. 4). This criterion has been defined rather vaguely: “low-dose effects on specific biological endpoints have been reported in some studies, but were not replicated in others” (p. 43). We have tested the use of “reproducibility” for assessing the quality of a study including a specific question in our Qualichem protocol. However, it was very difficult or impossible for our respondents to answer that question. They considered that studies could not be identically reproduced in toxicology, because the particular conditions of a specific experiment cannot be identically reproduced in another, even if an explicit aim is to confirm the results. Furthermore, toxicologists have no incentives to repeat previous studies, given that publication criteria and research funding are based on originality. The meaning given by EFSA <xref ref-type="bibr" rid="pone.0087738-EFSA3">[36]</xref> to reproducibility and the rationale for giving this criterion significant weight in its assessment of the low dose literature therefore remains unclear.</p>
<p>There were no quality criteria discussed in any of the SCF, ECB or EFSA reports above that was not dealt with in our typology.</p>
</sec></sec><sec id="s3c">
<title>3.3. Are Qualichem criteria already addressed in existing guidelines and in REACH?</title>
<p>Tyl et al. (2002) meets the OPPTS 870.3800 standardized guideline on reproductive toxicity <xref ref-type="bibr" rid="pone.0087738-US1">[34]</xref>, corresponding to OECD 416 <xref ref-type="bibr" rid="pone.0087738-OECD1">[38]</xref>. Stump (2009) claims to comply with the guidelines OECD 426 <xref ref-type="bibr" rid="pone.0087738-OECD2">[39]</xref> and OPPTS 870.6300 <xref ref-type="bibr" rid="pone.0087738-US2">[40]</xref> on developmental neurotoxicity. For certain Qualichem quality criteria, these standardized guidelines indicate best practices. For others, the guidelines vary. They may be flexible and leave choice of method to the discretion of the experimenters, address methodology briefly without giving precise indications, ask experimenters to report “what” they do but not prescribe “how” it should be done, or not address methodology at all.</p>
<p>In <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref>, we identify the Qualichem quality criteria that are addressed (with varying levels of precision) in the four standardized guidelines relevant for the two studies. In addition, we compared Qualichem criteria with information that REACH demands of industry and with the classes the ARRIVE guideline recommend for the scientific communication of <italic>in vivo</italic> studies <xref ref-type="bibr" rid="pone.0087738-Kilkenny1">[9]</xref>. This comparison also aimed to check the assumption, made by some of our respondents, that respecting regulatory guidelines ensures scientific quality for an <italic>in vivo</italic> study. As <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref> shows (summarized in <xref ref-type="table" rid="pone-0087738-t003">table 3</xref>), this assumption is not realistic—only some quality criteria are addressed in a precise way in standardized guidelines, with clear experimentation procedures to follow. Other quality criteria either depend on the choices made by experimenters or are not addressed at all. Finally, GLP <xref ref-type="bibr" rid="pone.0087738-OECD3">[41]</xref>–<xref ref-type="bibr" rid="pone.0087738-OECD4">[42]</xref> only allows traceability of laboratory procedures and limits the possibility of fraud in private laboratories <xref ref-type="bibr" rid="pone.0087738-Myers1">[13]</xref>, but it is not a standard of scientific quality.</p>
<table-wrap id="pone-0087738-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.t003</object-id><label>Table 3</label><caption>
<title>Comparison between Qualichem and other reporting and/or quality assessment frameworks.</title>
</caption><alternatives><graphic id="pone-0087738-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Reporting and/or quality assessment framework</td>
<td align="left" rowspan="1" colspan="1">REACH registration, on-line version</td>
<td align="left" rowspan="1" colspan="1">OECD 416 guideline</td>
<td align="left" rowspan="1" colspan="1">OECD 426 guideline</td>
<td align="left" rowspan="1" colspan="1">OPPTS 870.3800 guideline</td>
<td align="left" rowspan="1" colspan="1">OPPTS 870.6300 guideline</td>
<td align="left" rowspan="1" colspan="1">GLP</td>
<td align="left" rowspan="1" colspan="1">Expert committees in safety agencies (SCF, ECB, EFSA)</td>
<td align="left" rowspan="1" colspan="1">ARRIVE guideline</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Number of criteria addressed in each framework, out of the 45 Qualichem criteria</td>
<td align="left" rowspan="1" colspan="1">22/45</td>
<td align="left" rowspan="1" colspan="1">20/45</td>
<td align="left" rowspan="1" colspan="1">25/45</td>
<td align="left" rowspan="1" colspan="1">16/45</td>
<td align="left" rowspan="1" colspan="1">17/45</td>
<td align="left" rowspan="1" colspan="1">18/45</td>
<td align="left" rowspan="1" colspan="1">21/45</td>
<td align="left" rowspan="1" colspan="1">21/45</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>There are no quality criteria in documents produced by expert groups or in the OECD 416, OECD 426, OPPTS 870.3800, OPPTS 870.6300 or GLP guidelines that are not in Qualichem (<xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref>). This is related to the method used for developing Qualichem criteria—it began with criteria already present in safety agency reports, and completed them based on analysis of public criticism made by other stakeholders and on feedback from our respondents.</p>
</sec><sec id="s3d">
<title>3.4. Relative importance of the different criteria for the global quality of the study</title>
<p>We assessed the relative importance of the different Qualichem criteria in determining the final quality of the studies. Four respondents chose option a) indicate that all criteria are equally important, and eight chose option b) select a maximum of 15 criteria that are the most important for the final quality of the results.</p>
<p><xref ref-type="fig" rid="pone-0087738-g003">Figure 3</xref> shows the 39 criteria chosen by at least one of the eight respondents who chose option b, in percentage of respondents that considered each criterion important.</p>
<p>75% or more of the respondents considered 8 of the 45 quality criteria as high priority, 60% or more of the respondents considered 18 criteria as high priority and 50% or more of the respondents considered 31 criteria as high priority.</p>
</sec><sec id="s3e">
<title>3.5. Influence of respondents' disciplinary background and publication history on their quality assessments</title>
<p>Four respondents were employed by safety agencies and the other eight were academics. Nine were, at some time, part of official expert committees involved in the assessment of BPA at different levels and in different countries in Europe. We did not have information about participation in expert committees for two respondents. Among the 12 respondents, three had not published on BPA in a peer-reviewed journal since 2006. We were not able to access a list of publications for another three (one academic and two employees of safety agencies). Six others have published at least one article addressing BPA at different levels of detail, in a peer-reviewed journal, since 2006. <xref ref-type="fig" rid="pone-0087738-g004">Figure 4</xref> shows the disciplinary areas of the respondents—they were allowed to select multiple options.</p>
<fig id="pone-0087738-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.g004</object-id><label>Figure 4</label><caption>
<title>Disciplines of Qualichem respondents.</title>
<p>The vertical axis represents the disciplinary areas chosen by the experts. The horizontal axis represents the number of experts who chose each disciplinary area to describe his/her work.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.g004" position="float" xlink:type="simple"/></fig>
<p>Interestingly, three of the four respondents who work in safety agencies gave scores under 5 for the criterion “Robustness of regulatory guidelines”. The fourth was the only respondent who gave maximal scores to all quality criteria for the study assessed. This person reiterated that following a guideline is in itself a guarantee of quality, and noted that he knew the work of the people who conducted the study and trusted them. One academic scientist made a similar statement, saying that following a guideline is a sufficient guarantee of scientific quality—this person gave only one score of less than 5, for “general state of scientific knowledge”. The number of quality criteria assigned scores under 5 was similar for the safety agency and academic respondents, indicating similar levels of criticism.</p>
<p>The three most critical respondents gave scores lower than 5 to 14, 15 and 21 quality criteria. These were also the only respondents who included “endocrinology” or “endocrine toxicology” among their fields of competence. Representation of Qualichem (<xref ref-type="fig" rid="pone-0087738-g005">Figure 5</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s010">Text S10</xref>) for only two of these academic scientists (they assessed Tyl et al. [2002]) shows that the number of controversial criteria (30 vs 35) and critical criteria (25 vs 26) for these two respondents combined is similar to those given by the eight respondents together. However, the number of quality criteria that fall in the orange or red areas is much higher for these two respondents than for all respondents together: 16 vs 3 in the orange area, 9 vs 2 in the red area, and only 5 vs 30 in the green area. This indicates lower levels of aggregated quality for these criteria, compared to the eight respondents together.</p>
<fig id="pone-0087738-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0087738.g005</object-id><label>Figure 5</label><caption>
<title>Quality assessment by two endocrinologists using Qualichem to evaluate Tyl et al. (2002).</title>
<p>For the study of Tyl et al. (2002), of the 45 criteria, the figure represents only the 30 controversial criteria for the two respondents who included “endocrinology” or “endocrine toxicology” among their fields of competence. The figure is divided into three colored areas: red (including scores and medians &lt;3), orange (for scores and medians between 3 and 4) and green (for scores and medians &gt;4). A line covers the full range from the lowest score to the highest score in the group of responding experts. The median of the scores is represented by an “x” and the interquartile range is represented by a rectangle. If the median (x) is in the red area, the aggregated quality of the criterion is low. If the median is in the orange area, the aggregated quality is average. If the median is in the green area, the aggregated quality is high. The interquartile range is an indicator of inter-expert heterogeneity. The number of criteria that fell in the orange or red areas is much higher for these two respondents than for all respondents together: 16 vs 3 in the orange area, 9 vs 2 in the red area, and only 5 vs 30 in the green area. This indicates lower levels of aggregated quality for these criteria, compared to the 8 respondents together.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0087738.g005" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s4">
<title>Discussion</title>
<sec id="s4a">
<title>4.1. Heterogeneity in experts' quality assessments and working procedures in safety agencies</title>
<p>Our results show substantial heterogeneity among scientists in how they evaluate the quality of a study using the same criteria, and also differences between Qualichem assessments and those done by previous expert committees. This heterogeneity is not accounted for in an appropriate manner in current working procedures used by expert committees in health agencies.</p>
<p>A number of factors could explain these differences. Experts may not have time to familiarize themselves with the important details of a study, may view quality differently or may just be wrong. Pragmatic considerations related to lack of time or resources can also influence how thoroughly a study's quality is evaluated.</p>
<p>In expert groups, consensus-based procedures sometimes favor strong personalities who take the lead in collective discussions—important minority opinions can be lost in the process of reaching a common position. Individuals can also be reluctant to express critical opinions in a group context, in particular when those opinions disagree with the group majority and/or president—a phenomenon called “the spiral of silence” <xref ref-type="bibr" rid="pone.0087738-NoelleNeumann1">[43]</xref>. When individual views are not heard or expressed, the overall quality of an expert group's work can be compromised. A minority opinion in an expert committee is not necessarily a minority opinion in science, but could result from the criteria used for selecting experts, which could favour certain disciplines and competences over others. Furthermore, communicating the result of a quality assessment as a consensus masks certain quality problems, and can cause decision-makers to view a study's results as being stronger than they really are.</p>
<p>The institutional context of certain safety agencies, despite recent efforts, favors consensus and remains resistant to minority opinions. We know of two examples within our personal contacts of situations at EFSA in which one expert wanted to express a minority opinion but was discouraged from doing so. Qualichem avoids these problems by providing two indicators of quality: a majority-based indicator for each criterion (aggregated quality) and a multi-expert, aggregated level of confidence in a study. This allows each individual in an expert group to communicate his/her critical position, even if this position is minority.</p>
</sec><sec id="s4b">
<title>4.2. Lowering subjectivity in regulatory quality assessments</title>
<p>The current regulatory framework in Europe (e.g., REACH and the Regulation (EC) no 1107/2009 concerning placement of plant protection products on the market) demands that industry assess the risks of the chemicals it produces. Therefore, industry studies are frequently considered by health agencies. Research has repeatedly confirmed that conflicts of interest can bias results in favor of a study's sponsor <xref ref-type="bibr" rid="pone.0087738-Bekelman1">[44]</xref>, <xref ref-type="bibr" rid="pone.0087738-Lexchin1">[1]</xref>. The ability of health agencies to evaluate work done by industry would benefit from rigorous quality assessment, with comparable criteria to evaluate both academic and industry studies and clear evaluation methods—an improvement over relying on fuzzy “expert judgment”. Of course, providing a score from a scale without explanatory arguments can be as subjective as any other unstructured “expert judgment”. For this reason, the Qualichem protocol requires respondents to support their choice of score for each quality criterion with one or more arguments that are documented together with the score (<xref ref-type="supplementary-material" rid="pone.0087738.s007">Text S7</xref>).</p>
<p>Furthermore, Qualichem could be further improved by adding a requirement that respondents provide scientific references from the peer-reviewed literature, where available, to support their choice of scores. There are currently unstandardized practices in health agencies on referencing expert arguments <xref ref-type="bibr" rid="pone.0087738-Maxim2">[45]</xref>. However, expert judgment can be erroneous or biased if arguments are not referenced by peer-reviewed literature—a phenomenon that tends to be important in socio-politically controversial cases <xref ref-type="bibr" rid="pone.0087738-Maxim3">[46]</xref>.</p>
<p>The advantage of Qualichem is that it represents each quality criterion, which cannot be understood solely from a narrative description such as is presented in the SCF, ECB and EFSA reports. Furthermore, Qualichem provides a common framework that applies the same quality criteria for each study assessed and allows for quick comparison between studies and between health agencies, as shown here for our two cases. Indeed, without a common background for assessing the quality of available knowledge, different expert committees can reach opposite conclusions (e.g., “risk to all or none”) based on the same data <xref ref-type="bibr" rid="pone.0087738-Beronius1">[47]</xref>. Such situations fuel controversies, create doubt and suspicion, reduce the legitimacy of official risk assessments, give an impression of lack of transparency, waste public money by necessitating multiple expert groups, and delay decision-making.</p>
<p>In the framework of REACH, a structured assessment of the quality of the studies submitted by industry could reduce the potential influence of conflicts of interest and provide a systematic approach that could facilitate the work of health agencies. It is currently difficult to access the original industry studies. Indeed, safety agencies do not have systematic access to the complete reports of the all studies communicated by industry in their registration dossiers. To access these full reports, safety agencies must sometimes negotiate with industry and ask for them. But, there is no guarantee that industry will provide the full reports. Access to raw data for re-analysis is even more problematic. Furthermore, some study reports can be quite thick, and raw data and results are not always reported in an understandable manner, which can significantly delay the process of evaluating a study. A summary of the most relevant information contained in a report is essential to efficiently shorten the time for evaluating its quality.</p>
<p>In the on-line version of REACH registration, industry can submit their studies according to a pre-established framework that includes administrative data, data source, <xref ref-type="sec" rid="s2">materials and methods</xref> (i.e., test type, test guideline, GLP compliance, test materials, test animals), administration/exposure, examinations, results and discussions, further observations and conclusions. As shown in <xref ref-type="table" rid="pone-0087738-t003">Table 3</xref> and <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref>, the information currently provided in the on-line version of REACH registration dossiers for the two studies assessed includes only half of the Qualichem criteria. If information on all the Qualichem criteria were available online, an industry study could be more easily reviewed.</p>
<p>Qualichem for <italic>in vivo</italic> studies is based a generic procedure for developing quality assessment instruments and can be generalized to other types of regulatory productions. Currently, we are testing similar tools for epidemiologic studies, for risk assessment reports produced by health agencies, and for exposure characterization.</p>
<p>Finally, Qualichem provides a basis for precise, reproducible and transparent assessment that could replace the Klimisch scores, which are currently subject to significant subjectivity and a confusing valuation procedure <xref ref-type="bibr" rid="pone.0087738-Schneider1">[12]</xref>.</p>
</sec><sec id="s4c">
<title>4.3. Quality assessment and standardized guidelines</title>
<p>Currently, regulatory guidelines and the GLP standard are given important weight in assessing the quality of studies in regulatory toxicology. While two of twelve respondents of our study stated from the very beginning of the interviews that respect of regulatory guidelines is an undisputable guarantee of scientific quality, in-depth evaluation led to very different quality assessments for the others. A study that respects regulatory guidelines can still present quality failures that can be judged important by certain scientists (<xref ref-type="fig" rid="pone-0087738-g001">Figures 1</xref> and <xref ref-type="fig" rid="pone-0087738-g002">2</xref>). Furthermore, regulatory guidance does not address several criteria that scientists consider important for assessing the quality of studies (<xref ref-type="table" rid="pone-0087738-t003">Table 3</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref>). For other criteria, required standards are designed to ensure the quality of work at a gross level; however, they do not account for the relevant particularities of specific substances, such as parameters for measuring neurotoxicity. Most of the criteria that are not well addressed in regulatory guidelines were considered by our Qualichem respondents as having an important weight for the final quality of the study (<xref ref-type="fig" rid="pone-0087738-g003">Figure 3</xref> and <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref>): control of confounders; correspondence between the experimental animals and humans; interpretation of the functional relevance of behavioral, morphologic, histological, molecular or biochemical changes; analysis of errors, uncertainty and limitations; sensitivity of the assay; status of peer-review; interpretation of raw data; choice of the toxicokinetic level for measuring exposure; data treatment for statistics; graphical representation; statistical power; precision of exposure measurement; analysis of assumptions; analysis and reporting of variability.</p>
<p>Indeed, regulatory guidelines change very slowly. For example, development of the OECD 426 guideline took 12 years <xref ref-type="bibr" rid="pone.0087738-Makris1">[48]</xref>. Their objective is not to reflect the best scientific knowledge, but to offer a science-based political compromise among OECD member states. For this reason, there is significant potential for a gap between some OECD guidelines and rapidly advancing scientific knowledge. This is currently one of the major reasons for sociopolitical controversy about endocrine disrupters. In addition, the guidelines allow flexibility about certain aspects of the experimental protocol and leave the experimenter open to interpret the current state of scientific knowledge. However, this flexibility also allows room for experimenters to be wrong or to choose a level of scientific robustness that does not reflect available knowledge.</p>
<p>Furthermore, most academic studies that could be useful for decision-making do not follow OECD or GLP guidelines and therefore start off significantly disadvantaged when it comes to regulatory assessment of the study's quality. Robust science-based decision-making requires a more balanced playing field that considers both industry and academic studies. Systematic evaluation of studies as they relate to the current state of scientific knowledge is needed for well-informed decision-making, and to overcome the inevitable time delays in adapting OECD guidelines. Safety agencies do this kind of evaluation, but not in a systematic, transparent and comparable way from one agency to another.</p>
<p>Guidelines have a good regulatory reputation for providing scientific quality <xref ref-type="bibr" rid="pone.0087738-Myers1">[13]</xref>. For example, the Klimisch score calculates four levels of reliability for a study: reliable without restrictions, reliable with restrictions, not reliable, not assignable. The highest score for reliability (reliable without restrictions) is received by studies that were carried out according to standardized testing guidelines.</p>
<p>However, standardized guidelines only partially deserve this reputation (see <xref ref-type="table" rid="pone-0087738-t003">Table 3</xref>, <xref ref-type="supplementary-material" rid="pone.0087738.s006">Text S6</xref> and respondents' criticism on the “robustness of regulatory guidelines” in <xref ref-type="fig" rid="pone-0087738-g001">Fig. 1</xref> and <xref ref-type="fig" rid="pone-0087738-g002">2</xref>). This finding is in line with previous literature that suggests that some endpoints of the OECD 426 guideline, such as assessment of cognitive and sensory dysfunction, are not adequately sensitive while others are overly sensitive. In addition, specific endpoints like social behavior, pharmacokinetics and neurochemistry are lacking, and there is significant variability in the endpoints that are defined, like motor activity <xref ref-type="bibr" rid="pone.0087738-Makris1">[48]</xref>. The use of standardized guidelines as a major indication of scientific quality is currently controversial <xref ref-type="bibr" rid="pone.0087738-Makris1">[48]</xref> <xref ref-type="bibr" rid="pone.0087738-Myers1">[13]</xref>.</p>
<p>For all these reasons, the use of standardized guidelines should not replace scientific quality assessment, but should be considered in a complementary way, as we have suggested in our interview protocols.</p>
</sec><sec id="s4d">
<title>4.4. Relative weights of criteria in quality assessment</title>
<p>The weight of the same criterion could differ between studies and contexts, e.g., academic publication or regulatory assessment. An approach that asks respondents to weight each criterion, in addition to their Likert score, could be developed and tested in further work.</p>
<p>Also, the calculation of the level of confidence could depend on the number of respondents involved, as our algorithm to identify critical criteria gives important weight to each individual respondent.</p>
<p>There are several reasons for the contradictions between our Qualichem assessment and the evaluations made by SCF, ECB and EFSA. We showed that quality criteria used by official expert bodies differ from, and represent only a subset of, those included in Qualichem. Also, previous expert groups analyzed in this paper gave different weights to certain criteria than did Qualichem respondents.</p>
<p>In addition, group dynamics and procedures in official consensus-based expert groups leave only limited space for individual experts to express their insights on uncertainties and for these to be incorporated in the group's final conclusion. Qualichem keeps track of each respondent's criticism and values individual assessments by using the decision rule that defines critical criteria and, in turn, the ultimate level of confidence in a study.</p>
<p>The expert groups that previously evaluated the two studies were inevitably different from Qualichem respondents, in terms of range of disciplinary domains and experience with endocrine disrupters and BPA. Some respondents are likely able to react more to some quality criteria and less to others. Our interviews showed that some respondents were not able to assess all quality criteria and responded “cannot answer”. This assumption is further reinforced by our results (section 3.5) showing significant differences between endocrinologists and other respondents, which reiterates previous results that indicate different approaches to endocrine disrupters in toxicology versus endocrinology <xref ref-type="bibr" rid="pone.0087738-Chateauraynaud1">[49]</xref>.</p>
<p>Evaluation of each of the Qualichem criteria depends on the state of knowledge at the moment of the evaluation. Applying Qualichem at the same time as the expert groups did their reports (2002, 2003 or 2010) would probably have given different results. Therefore, the most important result from our study is the Qualichem method itself; the two case studies have been used primarily to test and demonstrate the method.</p>
<p>Our work is in line with the proposals of Evidence-Based Toxicology <xref ref-type="bibr" rid="pone.0087738-Hartung1">[50]</xref>. Using Qualichem, the level of confidence in a study could be established on a clear and comparable basis, by including the views of all experts involved, including minority views. Respondents could express themselves naturally without needing cumbersome procedures such as “minority opinions”. Reporting both consensus and controversial points could facilitate discussion in expert groups, and allow for easier representation of the quality of studies for health agency employees.</p>
</sec></sec><sec id="s5">
<title>Conclusions</title>
<p>There is currently no clear and reproducible procedure for evaluating the quality of studies in regulatory expertise. Though considering a study of chemical risks valid or rejected can have tremendous consequences on the lives of people exposed to those risks, quality assessment remains unstructured, cannot be compared among expert groups and agencies, and cannot be transparently communicated. Respect of standardized OECD and GLP guidelines is currently considered a token of scientific reliability, but this is becoming more controversial.</p>
<p>We have developed a tool, called Qualichem <italic>in vivo</italic>, to systematically and transparently assess the quality of <italic>in vivo</italic> studies used in chemical health risk assessment. Qualichem was usable for both short (a few pages) and extensive (4,000 page) study reports. For both studies, Qualichem contradicted the quality assessments done by expert committees in safety agencies, and confirmed that standardized guidelines only partly deserve their reputation as providers of scientific quality.</p>
<p>Our study shows four main results:</p>
<list list-type="bullet"><list-item>
<p>the 12 respondents considered the Qualichem criteria as appropriate for quality assessment of <italic>in vivo</italic> studies</p>
</list-item><list-item>
<p>there is important heterogeneity among experts in their quality assessments, which is not well accounted for in current working procedures in health agencies</p>
</list-item><list-item>
<p>standardized guidelines do not appropriately include important quality criteria</p>
</list-item><list-item>
<p>different criteria have different weights for the final quality of a study.</p>
</list-item></list>
<p>Qualichem provides two indicators of quality: a majority-based indicator for each criterion (i.e., aggregated quality) and a multi-expert, aggregated level of confidence in a study that allows each individual in an expert group to communicate his/her critical position, even if this position is a minority one (i.e., the global level of confidence in a study).</p>
<p>Our results indicate different levels of confidence from official quality assessments of two studies. Tyl et al. (2002) has been considered of very good quality by SCF, but the result from Qualichem indicates only an average level of confidence. The study by Stump (2009) was rejected by EFSA, but the Qualichem results also indicate an average level of confidence for the Qualichem respondents. Despite average levels of confidence for both studies, one was considered of good quality whereas the other was considered inconclusive. Comparison between criteria used by official expert committees and Qualichem criteria showed that SCF, ECB and EFSA seemed to prioritize certain criteria over others. However, as weighting was neither transparent nor explicit, it is difficult to assess the relative weight of different criteria, which can give an impression of subjectivity and even bias.</p>
<p>As a structured and transparent way of reporting study quality assessment, Qualichem has the potential to reinforce trust in safety agencies by limiting subjectivity and transparently displaying the experts' choices and assumptions. Furthermore, it makes inter-agency comparison of quality assessments of the same studies possible, by always applying the same set of methods and quality criteria.</p>
</sec><sec id="s6">
<title>Supporting Information</title>
<supplementary-material id="pone.0087738.s001" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s001" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>Typology of quality criteria.</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s002" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s002" position="float" xlink:type="simple"><label>Text S2</label><caption>
<p><bold>Definitions of quality criteria.</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s003" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s003" position="float" xlink:type="simple"><label>Text S3</label><caption>
<p><bold>Analysis of arguments provided with the scores for controversial criteria: Tyl et al. (2002).</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s004" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s004" position="float" xlink:type="simple"><label>Text S4</label><caption>
<p><bold>Analysis of arguments provided with the scores for controversial criteria: Stump (2009).</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s005" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s005" position="float" xlink:type="simple"><label>Text S5</label><caption>
<p><bold>Expert profile.</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s006" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s006" position="float" xlink:type="simple"><label>Text S6</label><caption>
<p><bold>Comparison between quality criteria addressed in Qualichem in vivo and quality criteria addressed in other sources.</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s007" mimetype="application/msword" xlink:href="info:doi/10.1371/journal.pone.0087738.s007" position="float" xlink:type="simple"><label>Text S7</label><caption>
<p><bold>Scale for quality assessment.</bold></p>
<p>(DOC)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s008" mimetype="application/vnd.ms-excel" xlink:href="info:doi/10.1371/journal.pone.0087738.s008" position="float" xlink:type="simple"><label>Text S8</label><caption>
<p><bold>Spreadsheet for Tyl et al. (2002).</bold></p>
<p>(XLS)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s009" mimetype="application/vnd.ms-excel" xlink:href="info:doi/10.1371/journal.pone.0087738.s009" position="float" xlink:type="simple"><label>Text S9</label><caption>
<p><bold>Spreadsheet for Stump (2009).</bold></p>
<p>(XLS)</p>
</caption></supplementary-material><supplementary-material id="pone.0087738.s010" mimetype="application/vnd.ms-excel" xlink:href="info:doi/10.1371/journal.pone.0087738.s010" position="float" xlink:type="simple"><label>Text S10</label><caption>
<p><bold>Spreadsheet for Tyl et al. (2002), scores of two endocrinologists.</bold></p>
<p>(XLS)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We are grateful to the three reviewers for the very useful comments, to David Gee for his continuous flow of excellent ideas and suggestions during many episodes of common work, to Gérard Arnold for careful reading and very helpful remarks, to Céline Vaslin for help with the figures, and to Sharilynn Wardrop for stylistic and linguistic improvements.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0087738-Lexchin1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lexchin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bero</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Djulbegovic</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Clark</surname><given-names>O</given-names></name> (<year>2003</year>) <article-title>Pharmaceutical industry sponsorship and research outcome and quality: systematic review</article-title>. <source>BMJ</source> <volume>326</volume>: <fpage>1167</fpage>–<lpage>1170</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Jadad1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jadad</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Caroll</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Jenkinson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Reynolds</surname><given-names>JM</given-names></name>, <etal>et al</etal>. (<year>1996</year>) <article-title>Assessing the quality of reports of randomized clinical trials: is blinding necessary?</article-title> <source>Control Clin Trials</source> <volume>17</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Ansari1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ansari</surname><given-names>MT</given-names></name>, <name name-style="western"><surname>Tsertsvadze</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Moher</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>Grading Quality of Evidence and Strength of Recommendations: A Perspective</article-title>. <source>PLoS Med</source> <volume>6(9)</volume>: <fpage>e1000151</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Brozek1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brozek</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Akl</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Compalati</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Kreis</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Terraciano</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Grading quality of evidence and strength of recommendations in clinical guidelines. Part 3 of 3. The GRADE approach to developing recommendations</article-title>. <source>Allergy</source> <volume>66</volume>: <fpage>588</fpage>–<lpage>595</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Hillier1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hillier</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Grimmer-Somes</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Merlin</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Middleton</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Salisbury</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>FORM: An Australian method for formulating and grading recommendations in evidence-based clinical guidelines</article-title>. <source>BMC Med Res Methodol</source> <volume>11</volume>: <fpage>23</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Schulz1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schulz</surname><given-names>KF</given-names></name>, <name name-style="western"><surname>Altman</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Moher</surname><given-names>D</given-names></name> (<year>2010</year>) <collab xlink:type="simple">CONSORT group</collab> (<year>2010</year>) <article-title>CONSORT 2010 statement: updated guidelines for reporting parallel group randomized trials</article-title>. <source>PLOS Med</source> <volume>7(3)</volume>: <fpage>e1000251</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Vandenbroucke1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vandenbroucke</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Von Elm</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Altman</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Gøtzsche</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Mulrow</surname><given-names>CD</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Strengthening the reporting of observational studies in epidemiology (STROBE): explanation and elaboration</article-title>. <source>Ann Intern Med</source> <volume>147(8)</volume>: <fpage>W</fpage>–<lpage>163-W-194</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Wandall1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wandall</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hansson</surname><given-names>SO</given-names></name>, <name name-style="western"><surname>Rudèn</surname><given-names>C</given-names></name> (<year>2007</year>) <article-title>Bias in toxicology</article-title>. <source>Arch Toxicol</source> <volume>81</volume>: <fpage>605</fpage>–<lpage>617</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Kilkenny1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kilkenny</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Browne</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Cuthill</surname><given-names>IC</given-names></name>, <name name-style="western"><surname>Emerson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Altman</surname><given-names>DG</given-names></name> (<year>2010</year>) <article-title>Improving Bioscience Research Reporting: The ARRIVE Guidelines for Reporting Animal Research</article-title>. <source>PLoS Biol</source> <volume>8(6)</volume>: <fpage>e1000412</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Klimisch1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klimisch</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Andreae</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Tillmann</surname><given-names>U</given-names></name> (<year>1997</year>) <article-title>A systematic approach for evaluating the quality of experimental toxicological and ecotoxicological data</article-title>. <source>Regul Toxicol Pharmacol</source> <volume>25</volume>: <fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-ECHA1"><label>11</label>
<mixed-citation publication-type="other" xlink:type="simple">ECHA (2011) Guidance on information requirements and chemical safety assessment. Chapter R.4. Evaluation of available information. Helsinki: European Chemicals Agency. <volume>23</volume>  pp.</mixed-citation>
</ref>
<ref id="pone.0087738-Schneider1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneider</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Schwarz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Burkholder</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Kopp-Schneider</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Edler</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>“ToxRTool”</article-title>. a new tool to assess reliability of toxicological data. <source>Toxicol Lett</source> <volume>189</volume>: <fpage>138</fpage>–<lpage>144</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Myers1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Myers</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>vom Saal</surname><given-names>FS</given-names></name>, <name name-style="western"><surname>Akingbemi</surname><given-names>BT</given-names></name>, <name name-style="western"><surname>Arizono</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Belcher</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Why public health agencies cannot depend on good laboratory practices as a criterion for selecting data: the case of bisphenol A</article-title>. <source>Environ Health Perspect</source> <volume>117(3)</volume>: <fpage>309</fpage>–<lpage>315</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Rudn1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rudén</surname><given-names>C</given-names></name> (<year>2001</year>) <article-title>The use and evaluation of primary data in 29 trichloroethylene carcinogen risk assessments</article-title>. <source>Regul Toxicol Pharmacol</source> <volume>34</volume>: <fpage>3</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-ANSES1"><label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">ANSES (Agence Nationale de Sécurité Sanitaire, Alimentation, Environnement, Travail) (2013) Perturbateurs Endocriniens – Évaluation des risques du bisphénol A (BPA) pour la santé humaine. Tome 1. Available: <ext-link ext-link-type="uri" xlink:href="http://www.anses.fr/fr/content/bisph%C3%A9nol-l%E2%80%99anses-met-en-%C3%A9vidence-des-risques-potentiels-pour-la-sant%C3%A9-et-confirme-la" xlink:type="simple">http://www.anses.fr/fr/content/bisph%C3%A9nol-l%E2%80%99anses-met-en-%C3%A9vidence-des-risques-potentiels-pour-la-sant%C3%A9-et-confirme-la</ext-link>. Accessed 2013 Aug 11.</mixed-citation>
</ref>
<ref id="pone.0087738-Funtowicz1"><label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">Funtowicz SO, Ravetz JR (1990) Uncertainty and quality in science for policy. Dordrecht: Kluwer. 229 p.</mixed-citation>
</ref>
<ref id="pone.0087738-VanderSluijs1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>Uncertainty and precaution in environmental management: insights from the UPEM conference</article-title>. <source>Env Mod &amp; Software</source> <volume>22(5)</volume>: <fpage>590</fpage>–<lpage>598</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Vander1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van der</surname><given-names>Sluijs</given-names></name> (<year>2002</year>) <article-title>A way out of the credibility crisis of models used in integrated environmental assessment</article-title>. <source>Futures</source> <volume>34</volume>: <fpage>133</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Maxim1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maxim</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Quality in environmental science for policy: assessing uncertainty as component of policy analysis,</article-title>. <source>Env Sci Pol</source> <volume>14(4)</volume>: <fpage>482</fpage>–<lpage>492</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-VanderSluijs2"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Craye</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Funtowicz</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kloprogge</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Ravetz</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2005a</year>) <article-title>Combining quantitative and qualitative measures of uncertainty in model-based environmental assessment: the NUSAP system</article-title>. <source>Risk anal</source> <volume>25(2)</volume>: <fpage>481</fpage>–<lpage>492</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-VanGijlswijk1"><label>21</label>
<mixed-citation publication-type="book" xlink:type="simple">Van Gijlswijk R, Coenen P, Pulles T, Van der Sluijs J (2004) Uncertainty assessment of NOx, SO2 and NH3 emissions in the Netherlands. Report commissioned by RIVM-TNO. Utrecht: Copernicus Institute for Sustainable Development and Innovation. 102 p.</mixed-citation>
</ref>
<ref id="pone.0087738-VanderSluijs3"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Risbey</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Ravetz</surname><given-names>J</given-names></name> (<year>2005b</year>) <article-title>Uncertainty Assessment of VOC emissions from Paint in the Netherlands</article-title>. <source>Environ Monit Assess</source> <volume>105(1-3)</volume>: <fpage>229</fpage>–<lpage>259</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Kloprogge1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kloprogge</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Petersen</surname><given-names>AC</given-names></name> (<year>2011</year>) <article-title>A method for the analysis of assumptions in model-based environmental assessments</article-title>. <source>Env Mod &amp; Software</source> <volume>26</volume>: <fpage>289</fpage>–<lpage>301</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Craye1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Craye</surname><given-names>MJP</given-names></name>, <name name-style="western"><surname>van der Sluijs</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Funtowicz</surname><given-names>S</given-names></name> (<year>2005</year>) <article-title>A reflexive approach to dealing with uncertainties in environmental health risk science and policy. Int</article-title>. <source>J. of Risk Assessment and Management</source> <volume>5(2)</volume>: <fpage>216</fpage>–<lpage>236</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-DeJong1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Jong</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wardekker</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name> (<year>2012</year>) <article-title>Assumptions in quantitative analyses of health risks of overhead power lines,</article-title>. <source>Environ Sci Pol</source> <volume>16</volume>: <fpage>114</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-vomSaal1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>vom Saal</surname><given-names>FS</given-names></name>, <name name-style="western"><surname>Akingbemi</surname><given-names>BT</given-names></name>, <name name-style="western"><surname>Belcher</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Crain</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Crews</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Flawed Experimental Design Reveals the Need for Guidelines Requiring Appropriate Positive Controls in Endocrine Disruption Research</article-title>. <source>Toxicol Sci</source> <volume>115(2)</volume>: <fpage>612</fpage>–<lpage>613</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Knol1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knol</surname><given-names>AB</given-names></name>, <name name-style="western"><surname>Slottje</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lebret</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>The use of expert elicitation in environmental health impact assessment: a seven step procedure</article-title>. <source>Environ Health</source> <volume>9</volume>: <fpage>19</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Tyl1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tyl</surname><given-names>RW</given-names></name>, <name name-style="western"><surname>Myer</surname><given-names>CB</given-names></name>, <name name-style="western"><surname>Marr</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Thomas</surname><given-names>BF</given-names></name>, <name name-style="western"><surname>Keimowitz</surname><given-names>AR</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Three-Generation Reproductive Toxicity Study of Dietary Bisphenol A in CD Sprague-Dawley Rats</article-title>. <source>Toxicol Sci</source> <volume>68</volume>: <fpage>121</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Stump1"><label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">Stump DG (2009) A dietary developmental neurotoxicity study of Bisphenol A in rats. Study number: WIL-186056. <volume>Vol. 1 of 16</volume>: . 4796 p.</mixed-citation>
</ref>
<ref id="pone.0087738-SCF1"><label>30</label>
<mixed-citation publication-type="other" xlink:type="simple">SCF (2002) Opinion of the Scientific Committee on Food on Bisphenol A. Brussels: European Commission, pp. 7.</mixed-citation>
</ref>
<ref id="pone.0087738-ECB1"><label>31</label>
<mixed-citation publication-type="other" xlink:type="simple">ECB (2003) European Union Risk Assessment Report for 4,4′-isopropylidenediphenol (bisphenol A). Brussels: European Chemicals Bureau. pp. 179–181 and pp. 214–216.</mixed-citation>
</ref>
<ref id="pone.0087738-EFSA1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">EFSA</collab> (<year>2010a</year>) <article-title>Scientific Opinion on Bisphenol A: evaluation of a study investigating its neurodevelopmental toxicity, review of recent scientific literature on its toxicity and advice on the Danish risk assessment of Bisphenol</article-title>. <source>EFSA Journal</source> <volume>8(9)</volume>: <fpage>116</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-EFSA2"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">EFSA</collab> (<year>2010b</year>) <article-title>Statistical re-analysis of the Biel maze data of the Stump et al (2010) study: “Developmental neurotoxicity study of dietary bisphenol A in Sprague-Dawley rats”</article-title>. Scientific report of EFSA. <source>EFSA journal</source> <volume>8(9)</volume>: <fpage>67</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-US1"><label>34</label>
<mixed-citation publication-type="other" xlink:type="simple">U.S EPA (1998a) Health Effects Test Guidelines, OPPTS 870.3800, Reproduction and Fertility Effects (Final Guideline, August 1998). Washington, DC: EPA.  Available: <ext-link ext-link-type="uri" xlink:href="http://www.epa.gov/oppts/pubs/frs/publications/Test_Guidelines/series870.htm" xlink:type="simple">http://www.epa.gov/oppts/pubs/frs/publications/Test_Guidelines/series870.htm</ext-link>. Accessed 2013 Aug 10.</mixed-citation>
</ref>
<ref id="pone.0087738-Tyl2"><label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Tyl RW, Myers CB, Marr MC (2006) Draft Final Report: Two-generation reproductive toxicity evaluation of Bisphenol A (BPA; CAS No. 80-05-7) administered in the feed to CD-1® Swiss mice (modified OECD 416). Research Triangle Park: RTI International Center for Life Sciences and Toxicology.</mixed-citation>
</ref>
<ref id="pone.0087738-EFSA3"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">EFSA</collab> (<year>2006</year>) <article-title>Opinion of the Scientific Panel on Food Additives, Flavourings, Processing Aids and Materials in Contact with Food on a request from the Commission related to 2,2-Bis(4-hydroxyphenyl)propane (bisphenol A)</article-title>. <source>The EFSA journal</source> <volume>428</volume>: <fpage>1</fpage>–<lpage>75</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Stump2"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stump</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Radovsky</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Garman</surname><given-names>RH</given-names></name>, <name name-style="western"><surname>Freshwater</surname><given-names>L</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Developmental neurotoxicity study of dietary bisphenol A in Sprague- Dawley rats</article-title>. <source>Toxicol Sci</source> <volume>115</volume>: <fpage>167</fpage>–<lpage>182</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-OECD1"><label>38</label>
<mixed-citation publication-type="other" xlink:type="simple">OECD (2001) OECD Guidelines for the Testing of Chemicals. Test No. 416: Two-Generation Reproduction Toxicity. Paris: OECD Environment Directorate. Available: <ext-link ext-link-type="uri" xlink:href="http://oberon.sourceoecd.org/vl=692122/cl=21/nw=1/rpsv/ij/oecdjournals/1607310x/v1n4/s26/p1" xlink:type="simple">http://oberon.sourceoecd.org/vl=692122/cl=21/nw=1/rpsv/ij/oecdjournals/1607310x/v1n4/s26/p1</ext-link> Accessed 2013 Aug 10.</mixed-citation>
</ref>
<ref id="pone.0087738-OECD2"><label>39</label>
<mixed-citation publication-type="other" xlink:type="simple">OECD (2007) OECD Guidelines for the Testing of Chemicals. Test No. 426: Developmental Neurotoxicity Study. Paris: OECD Environment Directorate. Available: <ext-link ext-link-type="uri" xlink:href="http://oberon.sourceoecd.org/vl=692122/cl=21/nw=1/rpsv/ij/oecdjournals/1607310x/v1n4/s26/p1" xlink:type="simple">http://oberon.sourceoecd.org/vl=692122/cl=21/nw=1/rpsv/ij/oecdjournals/1607310x/v1n4/s26/p1</ext-link> Accessed 2013 Aug 10.</mixed-citation>
</ref>
<ref id="pone.0087738-US2"><label>40</label>
<mixed-citation publication-type="other" xlink:type="simple">U.S EPA (1998b) Health Effects Test Guidelines: OPPTS 870.6300, Developmental Neurotoxicity Study. EPA 712-C-98–239. August 1998. Washington, DC: EPA. Available: <ext-link ext-link-type="uri" xlink:href="http://www.epa.gov/oppts/pubs/frs/publications/Test_Guidelines/series870.htm" xlink:type="simple">http://www.epa.gov/oppts/pubs/frs/publications/Test_Guidelines/series870.htm</ext-link>. Accessed 2013 Aug 10.</mixed-citation>
</ref>
<ref id="pone.0087738-OECD3"><label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">OECD (1998) OECD Series on Principles of Good Laboratory Practice and Compliance Monitoring, No. 1, OECD Principles of Good Laboratory Practice. Paris: OECD Environment Directorate. Available: <ext-link ext-link-type="uri" xlink:href="http://www.oecd.org/chemicalsafety/testing/oecdseriesonprinciplesofgoodlaboratorypracticeglpandcompliancemonitoring.htm" xlink:type="simple">http://www.oecd.org/chemicalsafety/testing/oecdseriesonprinciplesofgoodlaboratorypracticeglpandcompliancemonitoring.htm</ext-link>. Accessed 2013 May 1.</mixed-citation>
</ref>
<ref id="pone.0087738-OECD4"><label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">OECD (2000) OECD Series on Principles of Good Laboratory Practice and Compliance Monitoring, No. 5 (Revised), Consensus document. Compliance of laboratory suppliers with GLP practices. Paris: OECD Environment Directorate. Available: <ext-link ext-link-type="uri" xlink:href="http://www.oecd.org/chemicalsafety/testing/oecdseriesonprinciplesofgoodlaboratorypracticeglpandcompliancemonitoring.htm" xlink:type="simple">http://www.oecd.org/chemicalsafety/testing/oecdseriesonprinciplesofgoodlaboratorypracticeglpandcompliancemonitoring.htm</ext-link>. Accessed 2013 May 1.</mixed-citation>
</ref>
<ref id="pone.0087738-NoelleNeumann1"><label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">Noelle-Neumann E (1986) The Spiral of Silence. Chicago: University of Chicago Press, 260 p.</mixed-citation>
</ref>
<ref id="pone.0087738-Bekelman1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bekelman</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gross</surname><given-names>CP</given-names></name> (<year>2003</year>) <article-title>Scope and Impact of Financial Conflicts of Interest in Biomedical Research: a Systematic Review</article-title>. <source>JAMA</source> <volume>289(4)</volume>: <fpage>454</fpage>–<lpage>465</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Maxim2"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Maxim L, Van der Sluijs J (2013) Seed-dressing systemic insecticides and honeybees: a challenge for democratic governance of controversies about chemical risks. In: European Environmental Agency, editor. Science and the precautionary principle: lessons for preventing harm. Copenhagen: European Environmental Agency. pp. 401–438. Available: <ext-link ext-link-type="uri" xlink:href="http://www.eea.europa.eu/publications/late-lessons-2" xlink:type="simple">http://www.eea.europa.eu/publications/late-lessons-2</ext-link>. Accessed 2013 Dec 13.</mixed-citation>
</ref>
<ref id="pone.0087738-Maxim3"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maxim</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Van der Sluijs</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Expert explanations of honeybee losses in areas of extensive agriculture in France: Gaucho® compared with other supposed causal factors</article-title>. <source>Environ Res Lett</source> <volume>5(1)</volume>: <fpage>014006</fpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Beronius1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beronius</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rudén</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Håkansson</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hanberg</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Risk to all or none?</article-title> <source>A comparative analysis of controversies in the health risk assessment of Bisphenol A. Reprod Toxicol</source> <volume>29</volume>: <fpage>132</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Makris1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Makris</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Raffaele</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Allen</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bowers</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Hass</surname><given-names>U</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>A retrospective performance assessment of the developmental neurotoxicity study in support of OECD Test Guideline 426</article-title>. <source>Environ Health Perspect</source> <volume>17(1)</volume>: <fpage>17</fpage>–<lpage>25</lpage>.</mixed-citation>
</ref>
<ref id="pone.0087738-Chateauraynaud1"><label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Chateauraynaud F, Debaz J, Fintz M (2011) La dose fait-elle toujours le poison? Une analyse sociologique des mondes de la recherche et de l′expertise à l′épreuve des faibles doses. Paris: GSPR-EHESS-ANSES. <volume>35</volume>  pp.</mixed-citation>
</ref>
<ref id="pone.0087738-Hartung1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartung</surname><given-names>T</given-names></name> (<year>2009</year>) <article-title>Food for thought … on Evidence-Based Toxicology</article-title>. <source>Altex</source> <volume>26(2)</volume>: <fpage>75</fpage>–<lpage>82</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>