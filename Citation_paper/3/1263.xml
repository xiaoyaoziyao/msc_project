<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group>
<journal-title>PLoS ONE</journal-title></journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-13-39410</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0093344</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Neuroanatomy</subject><subj-group><subject>Connectomics</subject></subj-group></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Computing methods</subject><subj-group><subject>Mathematical computing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Image processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine and health sciences</subject><subj-group><subject>Neurology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Mapping Topographic Structure in White Matter Pathways with Level Set Trees</article-title>
<alt-title alt-title-type="running-head">Mapping Neural Topography with Level Set Trees</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kent</surname><given-names>Brian P.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Rinaldo</surname><given-names>Alessandro</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Yeh</surname><given-names>Fang-Cheng</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Verstynen</surname><given-names>Timothy</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Statistics, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States of America</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Department of Psychology and Center for the Neural Basis of Computation, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Herholz</surname><given-names>Karl</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Manchester, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">timothyv@andrew.cmu.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: BK AR FY TV. Performed the experiments: TV. Analyzed the data: BK. Contributed reagents/materials/analysis tools: BK AR FY TV. Wrote the paper: BK AR TV.</p></fn>
</author-notes>
<pub-date pub-type="collection"><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>8</day><month>4</month><year>2014</year></pub-date>
<volume>9</volume>
<issue>4</issue>
<elocation-id>e93344</elocation-id>
<history>
<date date-type="received"><day>25</day><month>9</month><year>2013</year></date>
<date date-type="accepted"><day>4</day><month>3</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Kent et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Fiber tractography on diffusion imaging data offers rich potential for describing white matter pathways in the human brain, but characterizing the spatial organization in these large and complex data sets remains a challenge. We show that level set trees–which provide a concise representation of the hierarchical mode structure of probability density functions–offer a statistically-principled framework for visualizing and analyzing topography in fiber streamlines. Using diffusion spectrum imaging data collected on neurologically healthy controls (N = 30), we mapped white matter pathways from the cortex into the striatum using a deterministic tractography algorithm that estimates fiber bundles as dimensionless streamlines. Level set trees were used for interactive exploration of patterns in the endpoint distributions of the mapped fiber pathways and an efficient segmentation of the pathways that had empirical accuracy comparable to standard nonparametric clustering techniques. We show that level set trees can also be generalized to model pseudo-density functions in order to analyze a broader array of data types, including entire fiber streamlines. Finally, resampling methods show the reliability of the level set tree as a descriptive measure of topographic structure, illustrating its potential as a statistical descriptor in brain imaging analysis. These results highlight the broad applicability of level set trees for visualizing and analyzing high-dimensional data like fiber tractography output.</p>
</abstract>
<funding-group><funding-statement>This research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-10-2-0022. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. This research was also supported by NSF CAREER grant DMS 114967. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Fiber tractography on diffusion weighted imaging (DWI) data can provide a high-resolution map of the anatomical connections between two brain areas <xref ref-type="bibr" rid="pone.0093344-Hagmann1">[1]</xref>. The deterministic variant of fiber tractography generates a set of simulated fiber streamlines that provide rich information about the topographic structure of white matter pathways <xref ref-type="bibr" rid="pone.0093344-Descoteaux1">[2]</xref>–<xref ref-type="bibr" rid="pone.0093344-Wedeen1">[4]</xref>. This method has been used recently to characterize the sheet-like layout of large, myelinated pathways <xref ref-type="bibr" rid="pone.0093344-Wedeen2">[5]</xref>, map the organization of fiber bundles within the same pathway <xref ref-type="bibr" rid="pone.0093344-Greenberg1">[6]</xref>–<xref ref-type="bibr" rid="pone.0093344-Verstynen2">[8]</xref>, identify novel neuroanatomical patterns <xref ref-type="bibr" rid="pone.0093344-Makris1">[9]</xref>–<xref ref-type="bibr" rid="pone.0093344-Catani2">[12]</xref> and quantify the global structural connectivity between large sets of brain regions <xref ref-type="bibr" rid="pone.0093344-Hagmann2">[3]</xref>, <xref ref-type="bibr" rid="pone.0093344-Jarbo1">[13]</xref>, providing a so-called structural “connectome” of the human brain (see Van Essen et al. (2012) <xref ref-type="bibr" rid="pone.0093344-VanEssen1">[14]</xref>). The topography and connectivity of the structural connections identified with fiber tractography have also been shown to relate directly to corresponding functional connectivity <xref ref-type="bibr" rid="pone.0093344-Honey1">[15]</xref> and task-evoked functional dynamics <xref ref-type="bibr" rid="pone.0093344-Greenberg1">[6]</xref>, <xref ref-type="bibr" rid="pone.0093344-Pyles1">[16]</xref>, highlighting the relationship between structure and function in neural systems. Despite these advances, the lack of descriptive metrics for the spatial topography of white matter pathways remains a standing problem with structural connectivity analysis (see Jbabdi et al. (2013) <xref ref-type="bibr" rid="pone.0093344-Jbabdi1">[17]</xref>).</p>
<p>Clustering is a popular method for summarizing the spatial organization of white matter pathways <xref ref-type="bibr" rid="pone.0093344-Moberts1">[18]</xref>, <xref ref-type="bibr" rid="pone.0093344-ODonnell1">[19]</xref>, but clustering is often a difficult and ill-defined task. Many of the proposed approaches, such as fuzzy c-means <xref ref-type="bibr" rid="pone.0093344-Shimony1">[20]</xref>, <xref ref-type="bibr" rid="pone.0093344-Li1">[21]</xref>, spectral clustering <xref ref-type="bibr" rid="pone.0093344-ODonnell2">[22]</xref>, <xref ref-type="bibr" rid="pone.0093344-Jonasson1">[23]</xref>, diffusion maps <xref ref-type="bibr" rid="pone.0093344-Wassermann1">[24]</xref>, local linear embedding <xref ref-type="bibr" rid="pone.0093344-Tsai1">[25]</xref>, geometric clustering <xref ref-type="bibr" rid="pone.0093344-Gerig1">[26]</xref>, <xref ref-type="bibr" rid="pone.0093344-Corouge1">[27]</xref> and white matter atlas matching <xref ref-type="bibr" rid="pone.0093344-Prasad1">[28]</xref>, <xref ref-type="bibr" rid="pone.0093344-Xia1">[29]</xref>, assume there is a single well-defined partition of the data into <italic>K</italic> separate groups, where <italic>K</italic> is presumed known <italic>a priori</italic>. However, when the data are noisy or have a high degree of complexity or spatial heterogeneity, as is often the case in neuroimaging, it is more appropriate to assume the data have multi-scale clustering features that can be captured by a hierarchy of nested partitions of different sizes. These partitions and their hierarchy provide a wealth of information about the data beyond typical clustering results, unburdening the practitioner from the need to guess the “right” number of clusters, providing a global summary of the entire data set and offering the ability to select sub-clusters at different levels of spatial resolution depending on the scientific problem at hand.</p>
<p>There are many well-established hierarchical clustering methods, some of which have been applied to the problem of fiber track segmentation <xref ref-type="bibr" rid="pone.0093344-Ding1">[30]</xref>–<xref ref-type="bibr" rid="pone.0093344-Zhang1">[33]</xref>. However, these methods often suffer from a lack of statistical justification. Single linkage clustering, for example, is known to be inconsistent in dimensions greater than one <xref ref-type="bibr" rid="pone.0093344-Hartigan1">[34]</xref> and suffers from the problem of “chaining” <xref ref-type="bibr" rid="pone.0093344-Moberts1">[18]</xref>. In addition, the dendrograms that result from agglomerative hierarchical clustering do not indicate the optimal number of clusters; the practitioner must specify the desired number of clusters or a threshold at which to cut the dendrogram. Furthermore, the dendrograms that result from these methods are rarely used as statistical descriptors in their own right.</p>
<p>Several recent fiber clustering analyses propose more sophisticated methods that do not require <italic>a priori</italic> knowledge of the number of clusters. Wasserman and Deriche (2008) <xref ref-type="bibr" rid="pone.0093344-Wassermann3">[35]</xref> and Zvitia et al. (2008) <xref ref-type="bibr" rid="pone.0093344-Zvitia1">[36]</xref> use the mean-shift clustering algorithm, which finds clusters that correspond to the modes of an assumed probability density function. Brun et al. (2004) use spectral clustering but avoid choosing a cluster number by doing recursive binary data partitions <xref ref-type="bibr" rid="pone.0093344-Brun1">[37]</xref>. Wang et al. (2011) use a hierarchical Bayesian mixture model over supervoxels to estimate white matter segmentation, with the number of clusters chosen automatically by a Dirichlet process <xref ref-type="bibr" rid="pone.0093344-Wang2">[38]</xref>. Different clustering scales are achieved by defining supervoxels of various sizes. Many of these methods are capable of clustering at multiple data resolutions, but this is generally not the focus and the multi-scale clustering results are typically not exploited for further analysis.</p>
<p>In this article we introduce and apply the principles of high-density clustering <xref ref-type="bibr" rid="pone.0093344-Hartigan2">[39]</xref> for complex fiber tractography from a high-angular resolution form of DWI. We implement a general procedure called the <italic>level set tree</italic> for accurate estimation of nested subsets of high-density data points. Like other agglomerative clustering methods, the output of our procedure is a hierarchy of clusters that can be represented with a dendrogram. But unlike any other hierarchical clustering method, the dendrogram obtained by the level set tree procedure has a direct probabilistic interpretation in terms of underlying probability density function (see next section for details and background). As a result, level set trees provide a means to represent and visualize data arising from complex and high-dimensional distributions that is statistically accurate in the sense of being a faithful encoding of the level sets of a <italic>bona fide</italic> density function. This property extends to any sub-tree of a level set tree, so that with our procedure it is possible to extract subsets of data at multiple resolutions while retaining the same probabilistic faithfulness, effectively allowing for dynamic and multi-scale clustering that does not require advance knowledge of the true number of clusters.</p>
<p>In the context of fiber tractography we show how the level set tree can be used interactively to visualize spatial patterns and to cluster fiber streamlines that are similar in terms of location and shape. Unlike most clustering methods that output a single partition of the data, level set trees encode many different cluster permutations and act as a scaffold for interactive exploration of clustering behavior. We also show how uncertainty can be captured on the level set tree, suggesting the potential for using the tree as a summary statistic of topographic structure. Taken together, our results demonstrate that level set trees offer a solution for describing the topographies found in fiber streamline data sets and provide a fundamentally new way of visualizing and analyzing complex spatial patterns in fiber tractography data sets.</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<sec id="s2a">
<title>Level Set Trees for Densities</title>
<p>Suppose we observe a collection of points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e001" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e002" xlink:type="simple"/></inline-formula> and we want to identify and visualize the spatial organization of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e003" xlink:type="simple"/></inline-formula> without specific knowledge about the data generating mechanism and in particular without any <italic>a priori</italic> information about the number of clusters. To be concrete, think of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e004" xlink:type="simple"/></inline-formula> as the endpoints in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e005" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e006" xlink:type="simple"/></inline-formula> fiber pathways, which we hope to describe in a way that is anatomically meaningful. Clustering is a common approach to this goal, but clustering is typically an ill-defined task because the concept of a cluster is vaguely defined. Our level set tree methodology, in contrast, extends the statistically principled approach to clustering from Hartigan (1975) <xref ref-type="bibr" rid="pone.0093344-Hartigan2">[39]</xref>.</p>
<p>Assume the data points are independent draws from an unknown probability distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e007" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e008" xlink:type="simple"/></inline-formula> with probability density function (hereafter pdf) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e009" xlink:type="simple"/></inline-formula>. That is, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e010" xlink:type="simple"/></inline-formula> is a non-negative function such that the probability of observing a data point inside a subset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e011" xlink:type="simple"/></inline-formula> can be computed as<disp-formula id="pone.0093344.e012"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e012" xlink:type="simple"/><label>(1)</label></disp-formula>where the integral is the Lebesgue integral in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e013" xlink:type="simple"/></inline-formula>-dimensions. From this expression one can see that a set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e014" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e015" xlink:type="simple"/></inline-formula> takes on large values has a high probability of containing many of the sample points. As a result, points in the sample <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e016" xlink:type="simple"/></inline-formula> are likely clustered inside such a set, so it is natural to define clusters as regions of high density <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e017" xlink:type="simple"/></inline-formula>.</p>
<p>To formalize this intuition, fix a threshold value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e018" xlink:type="simple"/></inline-formula> and let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e019" xlink:type="simple"/></inline-formula> be the upper level set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e020" xlink:type="simple"/></inline-formula>, i.e. the set of points whose density values exceed the level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e021" xlink:type="simple"/></inline-formula>. Call the set of connected components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e022" xlink:type="simple"/></inline-formula> the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e023" xlink:type="simple"/></inline-formula>-clusters of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e024" xlink:type="simple"/></inline-formula>. More generally, a high-density cluster of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e025" xlink:type="simple"/></inline-formula> is a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e026" xlink:type="simple"/></inline-formula>-cluster for some <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e027" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e028" xlink:type="simple"/></inline-formula>. Notice that according to this probabilistic definition, the notion of a cluster depends on the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e029" xlink:type="simple"/></inline-formula> and that for a fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e030" xlink:type="simple"/></inline-formula> the corresponding set of clusters will typically not give a partition of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e031" xlink:type="simple"/></inline-formula>. Also, for larger values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e032" xlink:type="simple"/></inline-formula> the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e033" xlink:type="simple"/></inline-formula>-clusters define regions where the ratio of probability content to volume is higher.</p>
<p>A key feature of high-density clusters is the tree property: if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e034" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e035" xlink:type="simple"/></inline-formula> are two high-density clusters, then one is a subset of the other or they are disjoint. This implies that high-density clusters form a hierarchy–the <italic>level set tree of </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e036" xlink:type="simple"/></inline-formula>–that is indexed by the level values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e037" xlink:type="simple"/></inline-formula>. The tree property is extremely advantageous for data analysis for a number of reasons. First, the level set tree can be depicted as a dendrogram, from which the overall hierarchy of clusters of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e038" xlink:type="simple"/></inline-formula> can be visualized across all possible levels of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e039" xlink:type="simple"/></inline-formula>. In fact, one can regard the level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e040" xlink:type="simple"/></inline-formula> as providing a clustering resolution of sorts, with lower values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e041" xlink:type="simple"/></inline-formula> corresponding to larger and coarser clusters and higher values to smaller, more sharply defined clusters. Thus, the dendrogram of level sets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e042" xlink:type="simple"/></inline-formula> provides a multi-scale representation of the clustering characteristics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e043" xlink:type="simple"/></inline-formula>. As a result, the practitioner is free to choose the scale and the number of clusters to extract, depending on the goals of the analysis. Contrast this with many popular clustering algorithms that implicitly use a single-scale approach and demand a choice of the number of clusters. Another advantage of the tree property is that it allows represention and storage of the entire set of cluster inclusions efficiently with a compact data structure that can be easily accessed and queried (see <xref ref-type="table" rid="pone-0093344-t001">Table 1</xref> and its description in the Results section). Finally, the dendrogram can be used in a direct and interactive manner for visualizing and extracting the clusters at various levels of the tree and for exploring the clustering features of a data set. With this approach, one can select a varying number of clusters at the same or different levels of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e044" xlink:type="simple"/></inline-formula> without having to re-run the algorithm.</p>
<table-wrap id="pone-0093344-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.t001</object-id><label>Table 1</label><caption>
<title>Estimated level set tree information for a simple data simulation.</title>
</caption><alternatives><graphic id="pone-0093344-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Node</td>
<td align="left" rowspan="1" colspan="1">Start Level</td>
<td align="left" rowspan="1" colspan="1">End Level</td>
<td align="left" rowspan="1" colspan="1">Start Mass</td>
<td align="left" rowspan="1" colspan="1">End Mass</td>
<td align="left" rowspan="1" colspan="1">Size</td>
<td align="left" rowspan="1" colspan="1">Parent</td>
<td align="left" rowspan="1" colspan="1">Children</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">0.000</td>
<td align="left" rowspan="1" colspan="1">0.005</td>
<td align="left" rowspan="1" colspan="1">0.000</td>
<td align="left" rowspan="1" colspan="1">0.021</td>
<td align="left" rowspan="1" colspan="1">2001</td>
<td align="left" rowspan="1" colspan="1">None</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0093344-Hagmann1">[1]</xref>, <xref ref-type="bibr" rid="pone.0093344-Descoteaux1">[2]</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">0.005</td>
<td align="left" rowspan="1" colspan="1">0.061</td>
<td align="left" rowspan="1" colspan="1">0.021</td>
<td align="left" rowspan="1" colspan="1">0.528</td>
<td align="left" rowspan="1" colspan="1">1309</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pone.0093344-Hagmann2">[3]</xref>, <xref ref-type="bibr" rid="pone.0093344-Wedeen1">[4]</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.005</td>
<td align="left" rowspan="1" colspan="1">0.165</td>
<td align="left" rowspan="1" colspan="1">0.021</td>
<td align="left" rowspan="1" colspan="1">0.998</td>
<td align="left" rowspan="1" colspan="1">649</td>
<td align="left" rowspan="1" colspan="1">0</td>
<td align="left" rowspan="1" colspan="1">[]</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">0.061</td>
<td align="left" rowspan="1" colspan="1">0.167</td>
<td align="left" rowspan="1" colspan="1">0.528</td>
<td align="left" rowspan="1" colspan="1">0.999</td>
<td align="left" rowspan="1" colspan="1">359</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">[]</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.061</td>
<td align="left" rowspan="1" colspan="1">0.172</td>
<td align="left" rowspan="1" colspan="1">0.528</td>
<td align="left" rowspan="1" colspan="1">0.999</td>
<td align="left" rowspan="1" colspan="1">295</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">[]</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p><xref ref-type="fig" rid="pone-0093344-g001">Figure 1</xref> shows how to read and interpret the level set tree from a dendrogram. Panel A shows the pdf for a mixture of three Gaussian distributions and dashed lines representing four values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e045" xlink:type="simple"/></inline-formula>. For each level the solid line segment depicts the corresponding clusters. Note that these are subsets of the real line, even though for illustrative purposes we depict them at the same level as the corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e046" xlink:type="simple"/></inline-formula>. The tree property can be seen in the fact that each high-density cluster is a subset of some cluster portrayed immediately below it but is disjoint from all other clusters at the same level. In panel B the dendrogram of the level set tree is shown; note how the hierarchy of clusters corresponding to the four levels is respected. Branching points correspond exactly to levels at which two or more modes of the pdf, i.e. new clusters, emerge. Each vertical line segment in this panel represents the high-density clusters within a single pdf mode. Line segments that do not branch are considered to be high-density modes, which we call the leaves of the tree. For simplicity, we tend to treat the terms <italic>dendrogram</italic> and <italic>level set tree</italic> as synonymous.</p>
<fig id="pone-0093344-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g001</object-id><label>Figure 1</label><caption>
<title>Illustration of population and sample level set trees.</title>
<p>A) The true pdf is a mixture of three Gaussians (black curve). For each of four example density levels (dotted lines), the high-density clusters are indicated by solid line segments. B) Population level set tree for the density in panel A. The high-density clusters of panel A are found at the intersections of the selected levels (dashed lines) with the tree. C) Estimated density (black curve) based on 2,000 data points sampled from the pdf in panel A. High-density points belonging to the leaves of the sample level set tree in panel D are shown on the horizontal axis and on the estimated density function. D) Level set tree estimate based on the sample in panel C. Leaves are colored to match corresponding points in the sample. For illustration, the trees in this figure are indexed by density levels while all other trees in this article are plotted on the mass scale.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g001" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Estimating Level Set Trees</title>
<p>In practice <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e047" xlink:type="simple"/></inline-formula> is not directly observed and one must use the data <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e048" xlink:type="simple"/></inline-formula> to compute an estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e049" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e050" xlink:type="simple"/></inline-formula>. Under mild assumptions on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e051" xlink:type="simple"/></inline-formula> and if the sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e052" xlink:type="simple"/></inline-formula> is large, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e053" xlink:type="simple"/></inline-formula> is guaranteed to be very close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e054" xlink:type="simple"/></inline-formula> with large probability <xref ref-type="bibr" rid="pone.0093344-Rao1">[40]</xref> and one could use the level set tree of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e055" xlink:type="simple"/></inline-formula> to estimate the level set tree of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e056" xlink:type="simple"/></inline-formula> accurately. Unfortunately, computing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e057" xlink:type="simple"/></inline-formula>-clusters of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e058" xlink:type="simple"/></inline-formula> is computationally infeasible even in small dimensions because finding the connected components of the upper level sets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e059" xlink:type="simple"/></inline-formula> requires evaluation of the function on a dense mesh in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e060" xlink:type="simple"/></inline-formula> and a combinatorial search over all possible paths connecting any two points of such a mesh.</p>
<p>Instead, we propose a computationally tractable algorithm for level set clustering that combines and extends procedures outlined originally by Wishart (1969) <xref ref-type="bibr" rid="pone.0093344-Wishart1">[41]</xref> and more recently by Maier et al. (2009) <xref ref-type="bibr" rid="pone.0093344-Maier1">[42]</xref>, Chaudhuri and Dasgupta (2010) <xref ref-type="bibr" rid="pone.0093344-Chaudhuri1">[43]</xref>, and Kpotufe and von Luxburg (2011) <xref ref-type="bibr" rid="pone.0093344-Kpotufe1">[44]</xref>. At a high level, our algorithm approximates the level set tree of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e061" xlink:type="simple"/></inline-formula> by intersecting the level sets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e062" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e063" xlink:type="simple"/></inline-formula> and then evaluating the connectivity of each set by graph theoretic means. The main method is outlined in <xref ref-type="table" rid="pone-0093344-t002">Table 2:</xref> Algorithm 1, with detailed sub-procedures described in <xref ref-type="table" rid="pone-0093344-t003">Table 3:</xref> Algorithm 3, <xref ref-type="table" rid="pone-0093344-t004">Table 4:</xref> Algorithm 2, and <xref ref-type="table" rid="pone-0093344-t005">Table 5:</xref> Algorithm 4. Our interactive Python toolbox for level set tree construction, analysis, and clustering is called <italic>DEnsity-BAsed CLustering (DeBaCl)</italic> and is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/CoAxLab/DeBaCl" xlink:type="simple">https://github.com/CoAxLab/DeBaCl</ext-link>.</p>
<table-wrap id="pone-0093344-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.t002</object-id><label>Table 2</label><caption>
<title><bold>Algorithm 1.</bold> Conceptual level set tree estimation procedure.</title>
</caption><alternatives><graphic id="pone-0093344-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input</bold>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e064" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e065" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e066" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Output:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e067" xlink:type="simple"/></inline-formula>, a hierarchy of subsets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e068" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e069" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2: <bold>for</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e070" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e071" xlink:type="simple"/></inline-formula> <bold>do</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3:  <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e072" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4:  <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e073" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5:  <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e074" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6: find the connected components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e075" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7: <bold>end for</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e076" xlink:type="simple"/></inline-formula> dendrogram of connected components of graphs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e077" xlink:type="simple"/></inline-formula>, ordered by inclusions.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e078" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10: <bold>return </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e079" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><table-wrap id="pone-0093344-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.t003</object-id><label>Table 3</label><caption>
<title><bold>Algorithm 3.</bold> Compute.knn.graph. Construct a k-nearest neighbor similarity graph.</title>
</caption><alternatives><graphic id="pone-0093344-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e080" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e081" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>output: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e082" xlink:type="simple"/></inline-formula>, a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e083" xlink:type="simple"/></inline-formula>-nearest neighborhood graph.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1: <bold>for</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e084" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e085" xlink:type="simple"/></inline-formula> <bold>do</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2:  <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e086" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e087" xlink:type="simple"/></inline-formula>-nearest neighbor distance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e088" xlink:type="simple"/></inline-formula> among the other sample points.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3: <bold>end for</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e089" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5: <bold>for all</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e090" xlink:type="simple"/></inline-formula> <bold>do</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6: <bold> if</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e091" xlink:type="simple"/></inline-formula> <bold>then</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7:   <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e092" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8:  <bold>end if</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9: <bold>end for</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e093" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">11: <bold>return</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e095" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><table-wrap id="pone-0093344-t004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.t004</object-id><label>Table 4</label><caption>
<title><bold>Algorithm 2.</bold> Compute.knn.density. Compute the k-nearest neighbor density estimate at a sample point.</title>
</caption><alternatives><graphic id="pone-0093344-t004-4" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.t004" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e096" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e097" xlink:type="simple"/></inline-formula>, a sample index.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e098" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Output: </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e099" xlink:type="simple"/></inline-formula>, the knn density estimate for sample point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e100" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e101" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e102" xlink:type="simple"/></inline-formula>-nearest neighbor distance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e103" xlink:type="simple"/></inline-formula> among the other sample points.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>2:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e104" xlink:type="simple"/></inline-formula> volume of the Euclidean unit ball in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e105" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e106" xlink:type="simple"/></inline-formula> is the dimension of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e107" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e108" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4: <bold>return</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e109" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap><table-wrap id="pone-0093344-t005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.t005</object-id><label>Table 5</label><caption>
<title><bold>Algorithm 4.</bold> Prune.tree. Remove small leaf nodes from the level set tree.</title>
</caption><alternatives><graphic id="pone-0093344-t005-5" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.t005" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e110" xlink:type="simple"/></inline-formula>, a hierarchy of subsets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e111" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Input:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e112" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Output:</bold> A pruned tree <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e113" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1: <bold>for all </bold><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e114" xlink:type="simple"/></inline-formula> <bold>do</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2:  if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e115" xlink:type="simple"/></inline-formula> <bold>then</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3:   <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e116" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4: <bold> end if</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5: <bold>end for</bold></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>The first step of our algorithm is to compute a k-nearest neighbor (knn) similarity graph <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e117" xlink:type="simple"/></inline-formula> with nodes corresponding to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e118" xlink:type="simple"/></inline-formula> and edges connecting vertex pairs if either node is one of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e119" xlink:type="simple"/></inline-formula> closest neighbors to the other (<xref ref-type="table" rid="pone-0093344-t003">Table 3:</xref> Algorithm 3). In the second step, we compute a knn density estimator <xref ref-type="bibr" rid="pone.0093344-Maier1">[42]</xref>, <xref ref-type="bibr" rid="pone.0093344-Devroye1">[45]</xref>, which we evaluate only at the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e120" xlink:type="simple"/></inline-formula> sample points (<xref ref-type="table" rid="pone-0093344-t004">Table 4:</xref> Algorithm 2). The parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e121" xlink:type="simple"/></inline-formula> controls the smoothness of the density <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e122" xlink:type="simple"/></inline-formula>; larger values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e123" xlink:type="simple"/></inline-formula> produce smoother and flatter density estimates with small variances but large biases. As a result, choosing a large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e124" xlink:type="simple"/></inline-formula> reduces the chance of finding spurious clusters but makes it harder to detect and separate true clusters that are very close to each other. Choosing a small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e125" xlink:type="simple"/></inline-formula> yields nearly unbiased density estimates with large variances. Based on our experiments and theoretical results (<xref ref-type="bibr" rid="pone.0093344-Rinaldo1">[46]</xref> and <xref ref-type="bibr" rid="pone.0093344-Rinaldo2">[47]</xref>), we tend to favor larger values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e126" xlink:type="simple"/></inline-formula>.</p>
<p>Construction of the level set tree proceeds by ordering the estimated sample densities from smallest to largest and iterating over these values. For each value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e127" xlink:type="simple"/></inline-formula> in this list, the upper level set is:<disp-formula id="pone.0093344.e128"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e128" xlink:type="simple"/><label>(2)</label></disp-formula>In each iteration we construct an upper level similarity graph <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e129" xlink:type="simple"/></inline-formula> by removing the vertices from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e130" xlink:type="simple"/></inline-formula> whose sample points are not in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e131" xlink:type="simple"/></inline-formula>, then finding the connected components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e132" xlink:type="simple"/></inline-formula>.</p>
<p>The level set tree is the compilation of connected components over all values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e133" xlink:type="simple"/></inline-formula>. The final step of tree construction is to prune small components of the tree that occur due to sampling variability or insufficient statistical power (<xref ref-type="table" rid="pone-0093344-t005">Table 5:</xref> Algorithm 4). Pruning merges components that contain fewer than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e134" xlink:type="simple"/></inline-formula> data points into other nearby components. Larger values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e135" xlink:type="simple"/></inline-formula> correspond to more aggressive pruning, where only connected components of large relative size are deemed as separate clusters. On the other hand, setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e136" xlink:type="simple"/></inline-formula> to be very small enhances the resolution of the clustering procedure but increases the chance of seeing spurious clusters.</p>
</sec><sec id="s2c">
<title><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e137" xlink:type="simple"/></inline-formula>-indexing</title>
<p>We defined the level set tree based on density thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e138" xlink:type="simple"/></inline-formula>. Because this indexing is highly dependent on the height of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e139" xlink:type="simple"/></inline-formula> (or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e140" xlink:type="simple"/></inline-formula>), it lacks interpretability (for instance, it is not clear if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e141" xlink:type="simple"/></inline-formula> would be a threshold for high or low density regions). To remove the scale dependence, we instead consider indexing based on probability content rather than density height. Specifically, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e142" xlink:type="simple"/></inline-formula> be a number between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e143" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e144" xlink:type="simple"/></inline-formula> and define<disp-formula id="pone.0093344.e145"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e145" xlink:type="simple"/><label>(3)</label></disp-formula>to be the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e146" xlink:type="simple"/></inline-formula> for which the upper level set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e147" xlink:type="simple"/></inline-formula> has probability content no smaller than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e148" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0093344-Rinaldo2">[47]</xref>. The map <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e149" xlink:type="simple"/></inline-formula> gives a monotonically decreasing one-to-one correspondence between values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e150" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e151" xlink:type="simple"/></inline-formula> and values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e152" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e153" xlink:type="simple"/></inline-formula>. In particular, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e154" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e155" xlink:type="simple"/></inline-formula>. Because this map is monotonic we can define the tree in terms of the probability content <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e156" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e157" xlink:type="simple"/></inline-formula> without changing the topology (i.e. number and ordering of the branches). The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e158" xlink:type="simple"/></inline-formula>-index is not a linear re-indexing of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e159" xlink:type="simple"/></inline-formula>, however, so the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e160" xlink:type="simple"/></inline-formula>-based tree is a deformation in which some branches are dilated and others are compressed. We refer to this probability-based scale as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e161" xlink:type="simple"/></inline-formula>- or mass-indexing.</p>
<p>To estimate an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e162" xlink:type="simple"/></inline-formula>-indexed tree, we index the level sets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e163" xlink:type="simple"/></inline-formula> in a similar way. Specifically, for any <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e164" xlink:type="simple"/></inline-formula>, we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e165" xlink:type="simple"/></inline-formula> to be the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e166" xlink:type="simple"/></inline-formula>-quantile of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e167" xlink:type="simple"/></inline-formula> estimated sample densities. The associated hierarchy of subsets <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e168" xlink:type="simple"/></inline-formula> is computed as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e169" xlink:type="simple"/></inline-formula> varies from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e170" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e171" xlink:type="simple"/></inline-formula>.</p>
<p>We regard <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e172" xlink:type="simple"/></inline-formula>-indexing as more interpretable and useful for several reasons. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e173" xlink:type="simple"/></inline-formula> level of the tree indexes clusters corresponding to the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e174" xlink:type="simple"/></inline-formula> fraction of “most clusterable” data points; in particular, smaller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e175" xlink:type="simple"/></inline-formula> values yield more compact and well-separated clusters. The mass index can be used for de-noising and outlier removal: to eliminate 5% of the data with lowest estimated density, retrieve all the points in the clusters indexed by levels <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e176" xlink:type="simple"/></inline-formula>. Scaling by probability content also enables comparisons of level set trees arising from data sets drawn from different pdfs, possibly in spaces of different dimensions. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e177" xlink:type="simple"/></inline-formula> index is also more effective than the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e178" xlink:type="simple"/></inline-formula> index for representing regions of large probability content but low density and is less affected by small fluctuations in density estimates.</p>
</sec><sec id="s2d">
<title>Pseudo-density Analysis</title>
<p>A fiber track can be thought of as a set of points sampled along a random curve in three dimensions. Although probability distributions for these random functions are well defined, they cannot be represented with pdfs <xref ref-type="bibr" rid="pone.0093344-Billingsley1">[48]</xref>. We can extend level set trees to work with this type of non-Euclidean data by using pseudo-density functions in place of pdfs <xref ref-type="bibr" rid="pone.0093344-Ferraty1">[49]</xref>. Pseudo-densities cannot be used to compute probabilities as in <xref ref-type="disp-formula" rid="pone.0093344.e012">Equation 1</xref>, but they can be regarded as measures of similarity among points and of the overall connectivity of a space.</p>
<p>To compute the sample level set tree for a collection of fiber pathways, we use the knn density estimate as in <xref ref-type="table" rid="pone-0093344-t004">Table 4:</xref> Algorithm 2 but replace the Euclidean distance with a distance relevant to fibers, expunge the term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e179" xlink:type="simple"/></inline-formula> in the knn density calculation, and set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e180" xlink:type="simple"/></inline-formula> arbitrarily to 1. In general this does not yield a <italic>bona fide</italic> density function, but it is sufficient to induce an ordering on the data points based on each point’s proximity to its neighbors.</p>
<p>We measure the proximity of a pair of fibers with max-average-min distance <xref ref-type="bibr" rid="pone.0093344-Zhang2">[50]</xref>, computed using the Dipy Python module’s bundles_distances_mam function <xref ref-type="bibr" rid="pone.0093344-Garyfallidis1">[51]</xref>. Suppose a set of fiber pathways <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e181" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e182" xlink:type="simple"/></inline-formula> is a sequence of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e183" xlink:type="simple"/></inline-formula> points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e184" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e185" xlink:type="simple"/></inline-formula>. The distance between two fibers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e186" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e187" xlink:type="simple"/></inline-formula> is:<disp-formula id="pone.0093344.e188"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e188" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e189" xlink:type="simple"/></inline-formula> is the Euclidean distance between the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e190" xlink:type="simple"/></inline-formula>’th point in fiber <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e191" xlink:type="simple"/></inline-formula> and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e192" xlink:type="simple"/></inline-formula>’th point of fiber <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e193" xlink:type="simple"/></inline-formula>. In practice, points with a small minimum distance to the other fiber are removed from the computation. Intuitively this distance matches each point in fiber <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e194" xlink:type="simple"/></inline-formula> to the closest point in fiber <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e195" xlink:type="simple"/></inline-formula> and <italic>vice versa</italic>, then averages the matched point distances that are sufficiently large.</p>
<p>Once the distance is computed for each pair of fibers, the pseudo-density function is evaluated for each fiber and a similarity graph is constructed. Level set tree construction then follows the procedure in <xref ref-type="table" rid="pone-0093344-t002">Table 2:</xref> Algorithm 1.</p>
</sec><sec id="s2e">
<title>Benchmark Simulations</title>
<p>We compared the performance of level set trees in a traditional clustering task against several popular methods: K-means++ <xref ref-type="bibr" rid="pone.0093344-Arthur1">[52]</xref>, Gaussian mixtures <xref ref-type="bibr" rid="pone.0093344-Hastie1">[53]</xref>, hierarchical agglomeration with the Ward criterion <xref ref-type="bibr" rid="pone.0093344-Hartigan2">[39]</xref>, hierarchical agglomeration with the single linkage criterion <xref ref-type="bibr" rid="pone.0093344-Hastie1">[53]</xref>, spectral <xref ref-type="bibr" rid="pone.0093344-vonLuxburg1">[54]</xref>, diffusion map <xref ref-type="bibr" rid="pone.0093344-Coifman1">[55]</xref>, and DBSCAN <xref ref-type="bibr" rid="pone.0093344-Ester1">[56]</xref>. Each method was given the true number of clusters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e196" xlink:type="simple"/></inline-formula> in order to isolate the effectiveness of the algorithms from the heuristics for choosing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e197" xlink:type="simple"/></inline-formula>. For the sake of comparison we used the <italic>fixed </italic><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e198" xlink:type="simple"/></inline-formula> clustering option with level set trees, even though this ignores the ability of level set trees to automatically choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e199" xlink:type="simple"/></inline-formula>.</p>
<p>Each method was tested in several three-dimensional data simulations with varying degrees of realism. The easiest setting was a mixture of six Gaussian distributions, the medium difficultly scenario was a mixture of three Gaussian distributions and three noisy arcs, and the most difficult test was a resampling from real fiber endpoint data. For the latter scenario, we generated data sets by resampling 5,000 points from a set of 10,000 striatal fiber pathway endpoints (from a single subject) and adding Gaussian noise. True group labels were assigned with a careful application of level set clustering. To further vary the degree of difficulty of the clustering tasks, the group means in each scenario were contracted toward the grand mean by a coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e200" xlink:type="simple"/></inline-formula>, which took 20 values on a grid ranging from 0.1 to 1.2. Finally, for each simulation type and separation coefficient, we drew 20 data sets of 5,000 points each.</p>
<p>Both types of agglomerative hierarchical clustering were implemented with the R hclust function <xref ref-type="bibr" rid="pone.0093344-R1">[57]</xref>. K-means++, Gaussian mixture modeling (GMM), and DBSCAN were implemented with the Python module scikit-learn <xref ref-type="bibr" rid="pone.0093344-Pedregosa1">[58]</xref>. For DBSCAN we set the neighborhood parameter to be the second percentile of all pairwise distances and the level set parameter (i.e. the number of neighbors required for a point to be a core point) to be the first percentile of pairwise distances. Note that DBSCAN does not allow <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e201" xlink:type="simple"/></inline-formula> to be specified, making it difficult to compare to other methods.</p>
<p>We used our own implementations for spectral clustering and diffusion maps. For spectral clustering we constructed a symmetric knn graph on the data, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e202" xlink:type="simple"/></inline-formula> set to one percent of the sample size. The points in the first percentile of degree in this graph were removed as outliers. For diffusion maps we used a complete similarity graph with Gaussian edge weights:<disp-formula id="pone.0093344.e203"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e203" xlink:type="simple"/><label>(5)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e204" xlink:type="simple"/></inline-formula> set to twice the squared median of all pairwise distances <xref ref-type="bibr" rid="pone.0093344-Richards1">[59]</xref>. For both spectral and diffusion map clustering we used the random walk form of normalized graph Laplacian:<disp-formula id="pone.0093344.e205"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e205" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e206" xlink:type="simple"/></inline-formula> is the similarity graph adjacency matrix and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e207" xlink:type="simple"/></inline-formula> is the diagonal degree matrix for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e208" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pone.0093344-vonLuxburg1">[54]</xref>. For diffusion maps the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e209" xlink:type="simple"/></inline-formula>’th eigenvector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e210" xlink:type="simple"/></inline-formula> is scaled by a function of its corresponding eigenvalue <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e211" xlink:type="simple"/></inline-formula>:<disp-formula id="pone.0093344.e212"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e212" xlink:type="simple"/><label>(7)</label></disp-formula>which creates a multi-scale diffusion map <xref ref-type="bibr" rid="pone.0093344-Richards2">[60]</xref>. For spectral clustering and diffusion maps we use K-means++ to cluster the data after it is projected into the eigenspace, and for spectral clustering we use a knn classifier to assign outliers to clusters.</p>
</sec><sec id="s2f">
<title>Comparing Whole-fiber Segmentations</title>
<p>To evaluate the application of the level set tree method to entire fiber streamlines (rather than streamline endpoints), we compared the clustering results for middle frontal gyrus streamlines from two subjects to the output of single linkage hierarchical clustering and K-means clustering. Both comparison methods were computed in DSI Studio (<ext-link ext-link-type="uri" xlink:href="http://dsi-studio.labsolver.org" xlink:type="simple">http://dsi-studio.labsolver.org</ext-link>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e213" xlink:type="simple"/></inline-formula> was first set to be the number of modes identified by the level set tree for each subject, then the largest <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e214" xlink:type="simple"/></inline-formula> clusters were selected in both single linkage and K-means clustering. For single linkage clustering, we measured the distance between a pair of fibers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e215" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e216" xlink:type="simple"/></inline-formula> as <xref ref-type="bibr" rid="pone.0093344-Yeh1">[61]</xref>:<disp-formula id="pone.0093344.e217"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pone.0093344.e217" xlink:type="simple"/><label>(8)</label></disp-formula>The DSI Studio implementation of K-means does not use each point on fiber streamlines, but rather extracts several features: the endpoint coordinates, the middle coordinate, and the streamline length.</p>
</sec><sec id="s2g">
<title>Participants</title>
<p>Twenty male and ten female subjects were recruited from the local Pittsburgh community and the Army Research Laboratory in Aberdeen, Maryland. All subjects were neurologically healthy, with no history of either head trauma or neurological or psychiatric illness. Subjects ranged from 21 to 45 years of age at the time of scanning and four were left handed (2 male, 2 female). Participants provided written informed consent prior to participating in the study. All procedures, including the consent procedure, were approved by the Institutional Review Board (IRB) at Carnegie Mellon University.</p>
</sec><sec id="s2h">
<title>Imaging Acquisition</title>
<p>All thirty participants were scanned on a Siemens Verio 3T system in the Scientific Imaging and Brain Research (SIBR) Center at Carnegie Mellon University using a 32-channel head coil. We collected a 50 min, 257-direction diffusion spectrum imaging (DSI) scan using a twice-refocused spin-echo EPI sequence and multiple q values (TR = 9,916 ms, TE = 157 ms, voxel size  = <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e218" xlink:type="simple"/></inline-formula> mm, FoV  = <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e219" xlink:type="simple"/></inline-formula> mm, b-max = 5,000 s/mm<sup>2</sup>, 51 slices). Minimization of head motion during acquisition was done through a custom designed setup of foam padding within the coil, designed to minimize variance of head motion along the pitch and yaw rotation directions. This setup also included a chin restraint that locked the participant’s head to the receiving coil itself. Preliminary work on resting state EPI images at the imaging center showed that this setup minimized resting head motion to about 1 mm maximum deviation for most subjects.</p>
<p>Scanning at multiple b-values, particularly the high b-values of DSI, can cause different distortion patterns and eddy current artifacts. Applying motion correction (which assumes that these noise sources are stationary across images) can introduce more noise into these data sets. For quality control, the diffusion weighted images were inspected before further analysis. If head motion was present in any of the diffusion weighted images (ring artifact), the whole scan section was discarded. All data used in our study passed the quality control and there was no tractable head motion in the acquired diffusion weighted images.</p>
</sec><sec id="s2i">
<title>Diffusion MRI Reconstruction</title>
<p>All DSI images were processed using a q-space diffeomorphic reconstruction method <xref ref-type="bibr" rid="pone.0093344-Yeh2">[62]</xref>, implemented in DSI Studio. The co-registration was conducted using a non-linear spatial normalization approach <xref ref-type="bibr" rid="pone.0093344-Ashburner1">[63]</xref>, and a total of 16 iterations were used to obtain the spatial mapping function. From here orientation distribution functions (ODFs) were reconstructed to spatial resolution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e220" xlink:type="simple"/></inline-formula> mm and a diffusion sampling length ratio of 1.25. To determine the average tractography space, we generated a template image (the CMU-30 Template) composed of the average whole-brain ODF maps across all 30 subjects. The CMU-30 Template data is available for download from the datasets page at <ext-link ext-link-type="uri" xlink:href="http://www.psy.cmu.edu/~coaxlab/" xlink:type="simple">http://www.psy.cmu.edu/~coaxlab/</ext-link>.</p>
</sec><sec id="s2j">
<title>Fiber Tractography</title>
<p>All fiber tracking was performed using DSI Studio. We used an ODF-streamlined region of interest (ROI) based approach <xref ref-type="bibr" rid="pone.0093344-Yeh3">[64]</xref> similar to that used in previous studies <xref ref-type="bibr" rid="pone.0093344-Verstynen1">[7]</xref>, <xref ref-type="bibr" rid="pone.0093344-Verstynen2">[8]</xref>. Tracks were generated using an ODF-streamline version of the FACT algorithm <xref ref-type="bibr" rid="pone.0093344-Yeh3">[64]</xref>–<xref ref-type="bibr" rid="pone.0093344-Lazar1">[66]</xref>. For our initial test-set analysis, in MNI-space, we mapped two corticostriatal pathways: lateral frontal (middle frontal gyrus to striatum) and orbitofrontal (gyrus rectus to striatum). For tractography analysis on the 30 subject template brain, a whole-brain seeding was used in the tractography process, with 300 seeds per voxel in the whole-brain mask (31,100,100 total). For the fiber endpoint analysis and the test-retest analysis, we only collected 10,000 streamlines per pathway per subject. This was done to minimize processing and computational demands in the level set tree generation process and to make equivalent comparisons across pathways with the same number of samples.</p>
<p>Fiber progression continued with a step size of 1 mm, minimum fiber length of 10 mm, and maximum of 70 mm. To smooth each track, the next directional estimate of each voxel was weighted by 20 percent of the previous moving direction and 80 percent by the incoming direction of the fiber. The tracking was terminated when the relative quantitative anisotropy (QA) for the incoming direction dropped below a preset threshold of 0.2 or exceeded a turning angle of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e221" xlink:type="simple"/></inline-formula>. The CMU-30 template fiber pathways can be downloaded, along with a Python script illustrating level set tree estimation, at <ext-link ext-link-type="uri" xlink:href="http://psy.cmu.edu/~coaxlab/data/kent_plosOne_data/" xlink:type="simple">http://psy.cmu.edu/~coaxlab/data/kent_plosOne_data/</ext-link>.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Visualizing Data with Level Set Trees</title>
<p><xref ref-type="table" rid="pone-0093344-t001">Table 1</xref> displays the information in an example level set tree. The tree is a collection of nodes; each node has start and end <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e222" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e223" xlink:type="simple"/></inline-formula> levels, a parent, children (possibly an empty set), and constituent data points at the node’s start level. This information–particularly the parent-child relationships–is conveyed more effectively with a dendrogram. <xref ref-type="fig" rid="pone-0093344-g001">Figures 1C and 1D</xref> show a density estimate for 2,000 points sampled from a mixture of three Gaussian distributions and the corresponding level set tree estimate. Each vertical line segment of the tree represents the clusters contained in a mode of the estimated pdf; all of these clusters are subsets of the cluster at the start level of the mode.</p>
<p>The tree visualization contains several other pieces of information. The height of each tree branch indicates the prominence of the corresponding density mode. Nodes are sorted so that density modes containing more sample points appear to the left of smaller siblings. The thickness of each tree branch and amount of surrounding whitespace are also proportional to the mass of the corresponding density mode. For example, in <xref ref-type="fig" rid="pone-0093344-g001">Figure 1D</xref>, the first split yields two nodes containing approximately 75% (black node) and 25% (red node) of the mass respectively, so the black segment is thicker and surrounded by whitespace occupying about 75% of the width of the plot.</p>
<p>The mode hierarchy shown in a level set tree is a natural platform for interactively exploring interesting subsets of complicated data; by selecting a tree branch one can zoom in on structurally coherent groups, while largely avoiding overplotting problems. <xref ref-type="fig" rid="pone-0093344-g002">Figures 2</xref> and <xref ref-type="fig" rid="pone-0093344-g003">3</xref> illustrate the use of level set trees for interactive data visualization on a set of endpoint locations from 10,000 streamlines tracked from the lateral frontal cortex to the striatum. <xref ref-type="fig" rid="pone-0093344-g002">Figure 2B</xref> shows each streamline endpoint, color coded by its local density (higher densities are shown in warmer colors). The tree for this data set (<xref ref-type="fig" rid="pone-0093344-g002">Figure 2C</xref>) shows there are two primary clusters, each of which is further separated into well-defined sub-groups.</p>
<fig id="pone-0093344-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g002</object-id><label>Figure 2</label><caption>
<title>Level set tree for corticostriatal fiber endpoint locations.</title>
<p>A) 10,000 streamlines (yellow) mapped from the lateral frontal cortex (middle frontal gyrus) to the striatal nuclei (caudate nucleus, putamen and nucleus accumbens) shown as a gray region of interest (ROI). Data taken from a representative subject. B) Endpoint locations (in millimeters) of the streamlines shown in panel A, colored by estimated density (red is high). C) The corresponding level set tree, which indicates a complex cluster structure in these data. A major split occurs when 10% of the data are excluded from the density upper level set, and each branch of the split has relevant sub-clusters at various resolutions. Note the lack of information in the density level index on this plot, which is a typical outcome.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g002" position="float" xlink:type="simple"/></fig><fig id="pone-0093344-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g003</object-id><label>Figure 3</label><caption>
<title>Exploring data subsets with a level set tree.</title>
<p>A) Striatal endpoints from <xref ref-type="fig" rid="pone-0093344-g002">Figure 2</xref>. Red points are members of a selected node of the level set tree, shown in red in panel B. C) Striatal endpoints belonging to a different mode of the level set tree, shown in panel D.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g003" position="float" xlink:type="simple"/></fig>
<p>In <xref ref-type="fig" rid="pone-0093344-g003">Figure 3</xref> we use the tree to navigate through the data. Selecting the points associated with one of the large primary branches (<xref ref-type="fig" rid="pone-0093344-g003">Figures 3A and 3B</xref>) shows that this high-density region is spatially isolated in a single cluster in the dorsal portion of the striatum, specifically the dorsal caudate nucleus. By zooming in on some of the smaller components of the other primary branch (<xref ref-type="fig" rid="pone-0093344-g003">Figures 3C and 3D</xref>) we see that these are reflected as independent sub-clusters from the first branch, with endpoints in the anterior aspect of the caudate near the shell region of the nucleus, and with local density hierarchies within the cluster (<xref ref-type="fig" rid="pone-0093344-g003">Figure 3D</xref>). This illustrates how, by interacting with the branches of the level set tree, it is possible to characterize local topographic structures at different resolutions that reflect known, anatomically distinct sub-regions of the projections into the caudate <xref ref-type="bibr" rid="pone.0093344-Haber1">[67]</xref>.</p>
</sec><sec id="s3b">
<title>Clustering with Level Set Trees</title>
<p>Level set trees have several useful properties for solving practical clustering problems. Most notably, they provide different ways to obtain cluster labels, some of which do not require <italic>a priori</italic> knowledge of the number of clusters. Level set trees also identify outliers automatically and allow an investigator to visualize many different clustering permutations simultaneously and interactively. <xref ref-type="fig" rid="pone-0093344-g004">Figure 4</xref> shows the output from three different cluster labeling methods applied to the endpoint data shown in <xref ref-type="fig" rid="pone-0093344-g002">Figures 2</xref> and <xref ref-type="fig" rid="pone-0093344-g003">3</xref>.</p>
<fig id="pone-0093344-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g004</object-id><label>Figure 4</label><caption>
<title>Clustering with a level set tree.</title>
<p>A, C, E) Striatal endpoints colored by cluster assignment for three different cluster labeling methods. Gray points are unassigned because their estimated density is too low. Cluster colors match the tree node colors in the panels below. B) Tree nodes corresponding to clusters in panel A. These nodes are selected by cutting across the tree at a desired density or mass level. D) Tree nodes corresponding to clusters in panel C. Each leaf of the tree produces a cluster. F) Tree nodes corresponding to clusters in panel E. The tree is traversed upward from the root (or roots) until the desired number of clusters first appears.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g004" position="float" xlink:type="simple"/></fig>
<p>By construction, the tree is a compilation of connected components at each level of a pdf estimate, so the most straightforward cluster labeling is to retrieve the connected components at a single level (<xref ref-type="fig" rid="pone-0093344-g004">Figures 4A and 4B</xref>). In addition to its definitional nature, this method conveys the most intuitive sense for where the highest density data subsets are located. It also allows the investigator to control the number of points in the clusters; choosing a low mass level produces clusters that contain most of the data, while high mass thresholds produce clusters with only the peaks of the data modes. Finally, this method avoids the need to specify <italic>a priori</italic> the number of clusters, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e224" xlink:type="simple"/></inline-formula>, which must be determined heuristically in many popular clustering methods (K-means, for example).</p>
<p>The drawback of clustering at a single level is that it requires an arbitrary choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e225" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e226" xlink:type="simple"/></inline-formula>. All-mode clustering, which uses each leaf node of a level set tree as a cluster, avoids this choice <italic>and</italic> automatically chooses the number of clusters <xref ref-type="bibr" rid="pone.0093344-Azzalini1">[68]</xref> (<xref ref-type="fig" rid="pone-0093344-g004">Figures 4C and 4D</xref>). This method does remain sensitive to the choice of smoothing and pruning parameters, however. For a given degree of pruning, this method tends to produce more and smaller clusters than level set clustering.</p>
<p>If the clustering task demands a pre-set number of clusters, this can be done with a level set tree by identifying the first <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e227" xlink:type="simple"/></inline-formula> disjoint components to appear in the tree as the level increases from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e228" xlink:type="simple"/></inline-formula>. Unlike K-means (and related methods), there is no guarantee that there will be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e229" xlink:type="simple"/></inline-formula> disjoint nodes in a level set tree (<xref ref-type="fig" rid="pone-0093344-g004">Figures 4E and 4F</xref>).</p>
<p>Each labeling method captures general streamline clusters approximately near macroscopic divisions of the striatal nuclei. For instance, the red branch in each panel of <xref ref-type="fig" rid="pone-0093344-g004">Figure 4</xref> highlights an isolated cluster of prefrontal projections that terminate on the putamen. The remaining clusters on the caudate nucleus also break down into two major sets of endpoints. One set (dark blue in <xref ref-type="fig" rid="pone-0093344-g004">Figures 4A and 4E</xref>, brown and cyan in <xref ref-type="fig" rid="pone-0093344-g004">Figure 4C</xref>) identifies clusters of streamlines that terminate on the tail of the caudate, while the third major set (green and purple in <xref ref-type="fig" rid="pone-0093344-g004">Figure 4A</xref>; orange, green and blue in <xref ref-type="fig" rid="pone-0093344-g004">Figure 4C</xref>; orange, green and purple in <xref ref-type="fig" rid="pone-0093344-g004">Figure 4E</xref>) identifies streamlines terminating about the shell of the caudate nucleus. Thus, the first three branches of the level set tree appear to capture known anatomical sub-divisions of inputs to the striatum, with slight differences in sub-cluster identification depending on the labeling approach used.</p>
<p>Each of these three methods assigns cluster labels to a fraction of the sample, which we call the foreground points. The by-product of this is the intelligent removal of outliers. <xref ref-type="fig" rid="pone-0093344-g004">Figure 4</xref> shows that the size of the foreground and outlier sets varies greatly depending on the choice of cluster labeling method and parameter values. In particular, the all-mode technique tends to create a larger number of small clusters. When a full segmentation is needed, the unlabeled background points can be assigned to a cluster with any classification technique.</p>
<p>Together, the advantages of a level set tree approach–avoiding the need to specify the cluster number, multiple cluster labeling methods, visualization of many cluster permutations, interactive cluster exploration, and automatic outlier identification–allow the practitioner to gain greater insight into the topography of a data set, using fewer assumptions than would be necessary for standard methods.</p>
</sec><sec id="s3c">
<title>Clustering Performance Evaluation</title>
<p>To analyze the effectiveness of level set tree clustering we tested it in a range of simulations against several standard clustering methods. The simulations ranged in difficulty over both the degree of separation of the clusters and the type of data generating process, with the most complex scenario closely mimicking fiber pathway endpoint distributions (see Methods for more detail).</p>
<p>Not surprisingly, for the easiest clustering task–a mixture of six spherical Gaussian distributions–all methods achieved perfect identification of the true clusters when the groups were well separated (<xref ref-type="fig" rid="pone-0093344-g005">Figure 5B</xref>). Single linkage hierarchical clustering had a very high error rate even at medium degrees of separation between clusters, due to the well-studied problem of chaining. The density-based methods DBSCAN and level set trees also required more separation between clusters before achieving the same error rate as parametric methods, possibly due to the challenge of assigning low-density points to clusters.</p>
<fig id="pone-0093344-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g005</object-id><label>Figure 5</label><caption>
<title>Comparison of clustering method accuracy in simulations.</title>
<p>A, C, E) Example draws from each of three simulation scenarios (Gaussians, arcs &amp; Gaussians, and resampled striatal endpoints, from the top), with observations colored by true group label. B, D, E) Error rate for each type of simulation over several degrees of clustering difficulty, created by contracting the groups toward the grand mean by various amounts. For each type of simulation and each degree of difficulty, the mean and standard deviation of classification error are reported for 8 clustering methods: DBSCAN (dbscan), level set tree clustering (density), diffusion maps (diffuse), Gaussian mixture models (gmm), K-means++ (kmeans), hierarchical clustering with single linkage (s.link), spectral clustering (spectral), and hierarchical clustering with linkage by the Ward criterion (ward).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g005" position="float" xlink:type="simple"/></fig>
<p>The results are more difficult to interpret for the moderately difficult simulation scenario with three arcs and three spherical Gaussians (<xref ref-type="fig" rid="pone-0093344-g005">Figure 5D</xref>). Single linkage hierarchical clustering again required the most separation between clusters to achieve highly accurate classification. Spectral clustering was perfect when the clusters were well separated and was as good as any other method when the clusters were very close, but performed poorly at mid-range degrees of separation. The closely related technique of diffusion maps actually became less accurate at large degrees of separation. Level set tree clustering performed poorly for tightly packed clusters, but was comparable to the parametric methods (K-means++, Ward linkage, and GMM) for somewhat- and very well-separated clusters.</p>
<p>In the most realistic setting with resampled real data, the parametric methods performed poorly, achieving only about 70% accuracy, even when the clusters were very well separated (<xref ref-type="fig" rid="pone-0093344-g005">Figure 5F</xref>). Each of the nonparametric methods (level set clustering, DBSCAN, diffusion maps, and spectral clustering) performed best at some degree of separation, making it difficult to identify clearly superior or inferior methods. DBSCAN and level set trees have accuracies somewhat less than 100% even for well-separated clusters, probably due to the problem of assigning low-density points to clusters. A more nuanced classifier for this step in level set tree clustering would likely improve the results for level set trees in particular.</p>
<p>Level set trees enjoy several categorical advantages over methods like spectral clustering and diffusion maps, namely a more intuitive representation of data structure, facilitation of interactive data exploration, a concise representation of many different clustering permutations, and automatic selection of the number of clusters. This experiment suggests level set trees are also at least as accurate in practical clustering tasks, particularly with challenging non-convex clusters.</p>
<p>Finally, we note that we made no attempt to choose the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e230" xlink:type="simple"/></inline-formula> in an optimal manner in our experiments.</p>
</sec><sec id="s3d">
<title>Whole Fiber Segmentation</title>
<p>So far our analysis has focused on level set trees estimated for fiber pathway endpoints, rather than entire fiber pathways. This ignores the rich data contained in the rest of each streamline, data that can provide substantially more information about differences between sets of fibers. To work with whole fiber pathways, we adopted the pseudo-density approach, where the pairwise max-average-min fiber distance was used to rank each streamline according to the spatial proximity of its neighbors (see Methods).</p>
<p>Using this method, we looked at the organization of corticostriatal projections from two areas, the lateral frontal cortex and orbitofrontal cortex, in the 30 subject template brain (<xref ref-type="fig" rid="pone-0093344-g006">Figure 6</xref>). In the lateral frontal cortex we detected seven clusters of streamlines (34,982 foreground fibers out of 51,126 total fibers) that were organized in a consistent, evenly spaced rostral-caudal direction along the middle frontal gyrus (<xref ref-type="fig" rid="pone-0093344-g006">Figure 6A</xref>), an organization that is consistent with previous reports in both the animal and human literatures <xref ref-type="bibr" rid="pone.0093344-Verstynen2">[8]</xref>, <xref ref-type="bibr" rid="pone.0093344-Haber1">[67]</xref>, <xref ref-type="bibr" rid="pone.0093344-Draganski1">[69]</xref>. Each identified cluster reflects regions of high pseudo-density along the middle frontal gyrus. It is important to note that this whole-fiber clustering was able to capture divergent patterns in the white matter pathways. The dark blue and cyan streamlines start in the same region of the middle frontal gyrus, but diverge to different sub-cortical targets (namely, the caudate and putamen). This split is easy to identify in the level set tree by the emergence of an early branching in the tree into two major divisions that reflect caudate versus putamen fibers (<xref ref-type="fig" rid="pone-0093344-g006">Figure 6B</xref>). This provides a clean anatomical segmentation of the fibers despite the fact that these two fiber sets start in the same region of the middle frontal gyrus.</p>
<fig id="pone-0093344-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g006</object-id><label>Figure 6</label><caption>
<title>Level set tree clustering for whole fiber streamlines.</title>
<p><bold>A</bold>) Foreground fibers for the seven selected clusters from the 30 subject template data set for streamlines tracked between the middle frontal gyrus and striatum, shown in both a sagittal and coronal view. Clusters are colored according to an all-mode clustering of the tree. B) The level set tree for data in panel A. Tree leaves are matched to fiber clusters by color. C) Same analysis as shown in A, but for a set of streamlines from the orbitofrontal cortex. Inset shows closeup of fiber streamlines in the striatal ROI mask. D) Level set tree for data shown in panel C. The branch colors of trees in panels B and D match the clusters shown in the streamlines of panels A and C respectively.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g006" position="float" xlink:type="simple"/></fig>
<p>In the projections from the orbitofrontal cortex we identified five mode clusters (<xref ref-type="fig" rid="pone-0093344-g006">Figures 6C and 6D</xref>). Close inspection of the endpoints of these streamlines in the striatum reveals that each cluster forms a striated-like pattern in the caudate that is similar to patterns previously reported in corticostriatal projections <xref ref-type="bibr" rid="pone.0093344-Verstynen2">[8]</xref> (<xref ref-type="fig" rid="pone-0093344-g006">Figure 6C</xref>, inset). These striated formations are thought to reflect the modularized biochemical makeup of the striatum <xref ref-type="bibr" rid="pone.0093344-Graybiel1">[70]</xref>, <xref ref-type="bibr" rid="pone.0093344-Ragsdale1">[71]</xref>. This complex arrangement is difficult to capture with clustering methods that assume convex cluster shapes, but the whole-fiber pseudo-density clustering approach successfully extracts the patterns with minimal assumptions.</p>
<p>As with the fiber endpoint data, we also evaluated the whole-fiber level set tree results against other clustering methods: single linkage hierarchical and K-means. <xref ref-type="fig" rid="pone-0093344-g007">Figures 7A and 7B</xref> show the high-pseudo-density level set tree clusters. The single linkage method identified clusters (<xref ref-type="fig" rid="pone-0093344-g007">Figures 7C and 7D</xref>) that are similar to the high-density clusters of the level set tree result, but the boundary between clusters is less clear in both subjects (see the red, cyan and green clusters in <xref ref-type="fig" rid="pone-0093344-g007">Figure 7C</xref> and compare to <xref ref-type="fig" rid="pone-0093344-g007">Fig. 7A</xref>) for single linkage.</p>
<fig id="pone-0093344-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g007</object-id><label>Figure 7</label><caption>
<title>Comparison of methods for whole-fiber segmentation.</title>
<p>A, B) High-density fiber pathway clusters from the level set tree all-mode method for middle frontal gyrus fibers in two subjects. C, D) Single linkage hierarchical clustering results for the same fiber pathways, with the dendrogram cut to match the same number of clusters in the level set tree result. E, F) K-means clustering results for the sample fiber pathways.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g007" position="float" xlink:type="simple"/></fig>
<p>As expected, the K-means clustering performed much worse than the level set tree and single-linkage approaches (<xref ref-type="fig" rid="pone-0093344-g007">Figures 7E and 7F</xref>). The boundaries between the clusters are even less well defined than with single linkage, particularly for the second subject. Furthermore, there appears to be substantially larger within-cluster variation in the shape of the fiber pathways with K-means than with either of the hierarchical methods. To summarize, in qualitative terms whole-fiber level set tree clustering was able to isolate the high-pseudo-density fiber bundles as well as or better than two off-the-shelf methods.</p>
</sec><sec id="s3e">
<title>Level Set Tree Variability</title>
<p>To assess the stability of the 30 subject template level set trees in <xref ref-type="fig" rid="pone-0093344-g006">Figure 6</xref>, we created a set of trees by subsampling from the original lateral and orbitofrontal fiber streamline data sets and constructing a tree for each subsample. This simulates the variability seen when repeating the tractography on the same data set multiple times. The overlaid tree plots in <xref ref-type="fig" rid="pone-0093344-g008">Figures 8A and 8D</xref> indicate a high degree of stability for the trees built from these subsampled data sets, although it appears there might be slightly less stability for the orbitofrontal set. This conclusion is supported for both ROIs by the mode function overlays (<xref ref-type="fig" rid="pone-0093344-g008">Figures 8B and 8E</xref>) and histograms of mass values where each tree splits (<xref ref-type="fig" rid="pone-0093344-g008">Figures 8C and 8F</xref>). These plots illustrate that the existence of each tree branch is consistent across the subsamples, although there is variation in the mass levels where the branches first appear.</p>
<fig id="pone-0093344-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g008</object-id><label>Figure 8</label><caption>
<title>Repeat reliability for level set tree results for the 30 subject template.</title>
<p>For the middle frontal gyrus ROI, 28 random subsamples of 15,000 fibers were drawn from the total of 51,126 fibers, while 1,500 fibers were drawn for 23 subsamples from the 3,038 total fibers in the rectus. A) All 28 level set trees plotted on the same canvas, illustrating the high degree of similarity between the data structure in the subsamples. B) Histograms of the mass levels of the splits over the whole set of subsample trees. Split mass levels are matched across subsamples by rank order. C) All 28 mode functions plotted together, illustrating that there is little variation in the number of clusters at each mass level. D) All 23 level set trees plotted together. E) Distribution of mass values for splits, matched across subsamples by rank within each sample’s tree. F) All 23 mode functions overlaid.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g008" position="float" xlink:type="simple"/></fig>
<p>The high degree of stability in these subsample trees conveys certainty to the features of the level set trees constructed on the full data set (<xref ref-type="fig" rid="pone-0093344-g006">Figures 6B and 6D</xref>). For example, the left branch of the tree for the lateral frontal projections contains two prominent nodes (red and dark red) that appear when 42 percent of the fibers are in the background (i.e. not in the the upper level set). The fact that this same split occurs in every one of the subsample trees is evidence that such a split exists in the true (but unobserved) distribution of fibers that generated this data set.</p>
<p>On the other hand, data sets that differ even in seemingly small ways can lead to much more variation in the resulting level set trees. For a subset of subjects, fiber streamlines were reconstructed for two separate scans separated by six months. <xref ref-type="fig" rid="pone-0093344-g009">Figure 9</xref> shows the level set trees constructed for the lateral frontal projections from each scan in several example subjects, as well as the foreground clusters produced by all-mode clustering. The foreground clusters reveal that there does tend to be an overall high degree of similarity between the fiber streamline sets across trials, with the exception of one or two well-defined clusters that only appear in one of the two scans (highlighted in gray in <xref ref-type="fig" rid="pone-0093344-g009">Figure 9</xref>).</p>
<fig id="pone-0093344-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0093344.g009</object-id><label>Figure 9</label><caption>
<title>Test-retest comparisons for four subjects, tested six months apart.</title>
<p>Colored streamlines show clusters that were consistently observed at both scan times. Gray streamlines show clusters detected at only one time point. Panels A, C, E, and G show results from the initial scan session. Panels B, D, F, and H show results from the second scanning session six months later.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0093344.g009" position="float" xlink:type="simple"/></fig>
<p>The level set trees likewise reflect similar structure across scans, but the non-overlapping tree nodes exaggerate the apparent differences between trees. For example, panels E and F in <xref ref-type="fig" rid="pone-0093344-g009">Figure 9</xref> show the foreground fiber streamlines and level set trees for two scans of a single subject. The blue, green, cyan, violet, and yellow clusters match well across scans and appear to share very similar topography. However, panel E contains an obvious cluster on the right side of the plot (in gray) that is not present in panel F, while panel F contains its own obvious cluster on the left side of the plot (also in gray) that is not present in panel E. Note that each branch’s (or cluster’s) color was manually defined to match between images of the same subject, but does not necessarily reflect the same branch/cluster identified across subjects. While some of the features of the trees reflect the overall similarity–for example, the number of leaves is the same and the yellow, cyan, and violet clusters are more similar to each other while the blue cluster is much different–the overall shape of the trees is very different.</p>
<p>These variations reflect actual differences between the test and retest data, not just variability of the level set tree procedure. Not only are some clusters present in only one of the two data sets (shown in gray in <xref ref-type="fig" rid="pone-0093344-g009">Figure 9</xref>), but differing tree shapes and branching locations indicate that the probability content and relative hierarchy of even similar-looking clusters is not the same across scans. Despite such marked differences in the test and retest data sets, the output from all-mode clustering retains a very high degree of consistency across scan sessions, demonstrating the robustness of the proposed methodology.</p>
</sec></sec><sec id="s4">
<title>Discussion</title>
<p>White matter pathways have highly complex shapes and spatial organization, making it difficult to summarize their topographic structure. We have shown that level set trees provide a concise representation of this topography by describing the hierarchy of modal regions in the pseudo-density function that describes the probabilistic spatial distribution of a set of fiber pathways. We demonstrated the usefulness of this hierarchy by simultaneously identifying not only major anatomical boundaries in the striatum (e.g., putamen vs. caudate), but also sub-regions within the same nucleus (e.g., shell vs. tail of the caudate; see <xref ref-type="fig" rid="pone-0093344-g004">Figure 4</xref>). Qualitative comparisons of level set trees in repeated subsampling and test-retest experiments highlight the reliability of our results and suggest that level set trees have the potential be used as statistical estimators of fiber streamline topography. Finally, we evaluated the performance of level set trees in several simulations against a suite of standard clustering methods that are commonly used to describe fiber streamline organizational patterns. Level set trees performed as well as any of the clustering methods, although we emphasize that describing fiber pathway topography is not equivalent to fiber pathway clustering. For the former purpose, level set trees have several advantages over traditional clustering techniques: they are statistically principled; they are compact data structures that enable fast retrieval of high-density clusters at any density level; they allow a multi-scale visualization of the cluster patterns in a data set; they are a natural platform for interactive data exploration; and they offer several methods for obtaining particular cluster labels without assuming the number of clusters and with automatic removal of outliers.</p>
<p>Level set trees are traditionally based on an estimate of an unobserved pdf that is assumed to have generated data, a realistic assumption for the endpoints of fiber pathways. We show for this type of data how level set trees can be used to visualize data patterns, interactively explore structurally coherent data subsets, and simultaneously present many different cluster labelings. Where the assumption of a pdf is not realistic, as with infinite-dimensional whole fibers, we extend the method by observing that a pseudo-density estimator (along with a similarity measure) is sufficient for level set tree construction.</p>
<p>Ideally, the level set tree would be used for statistical inference when comparing white matter topographies across populations. For example, one could ask if the organization of fiber streamlines between two brain areas differs in individuals with neurological disorders (e.g., autism) when compared to neurologically healthy controls. By qualitatively demonstrating the reliability of level set tree structure, we highlight this potential of the method. Quantification of the uncertainty in level set trees is an open research problem; the qualitative comparisons shown in this paper as well as other preliminary work in this direction <xref ref-type="bibr" rid="pone.0093344-Rinaldo2">[47]</xref>, <xref ref-type="bibr" rid="pone.0093344-BenHur1">[72]</xref>, <xref ref-type="bibr" rid="pone.0093344-Smith1">[73]</xref> show that level set trees constructed on data drawn from the same distribution tend to be very similar, while trees constructed on data drawn from different distributions tend to be different. This concept of stability is difficult to apply, however, because simply identifying when two trees are similar is also an open research area (one that is beyond the scope of the current project).</p>
<p>An important limitation of our methodology is the selection of tuning parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e231" xlink:type="simple"/></inline-formula> for connectivity and pseudo-density estimation and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pone.0093344.e232" xlink:type="simple"/></inline-formula> for tree pruning (although the choice of cluster number is not required as with most clustering methods). We could choose these parameters based on the optimal values found in the theoretical literature <xref ref-type="bibr" rid="pone.0093344-Rao1">[40]</xref> but these values are only valid in asymptotic regimes and tend to work poorly in practice. As a result, as with much of applied statistics, selecting tuning parameters requires sound empirical judgment. It should be noted, however, that in our experiments the results tend to be robust for a relatively large range of tuning parameter values. Because there are several ways to obtain clusters from level set trees, inserting level set tree methods into an automated data analysis pipeline also requires a choice of cluster labeling method, in addition to the tuning parameters.</p>
<p>Also critical in the application of level set tree methods is the choice of function for measuring the distance between two fiber pathways. For fiber endpoints, Euclidean distance is the obvious choice, but for whole-fiber segmentation there is neither a clearly superior method nor a community-wide standard. The max-average-min distance used in this paper is popular in the fiber segmentation field <xref ref-type="bibr" rid="pone.0093344-ODonnell1">[19]</xref> and performed better than several related distances in a comparison of hierarchical clustering methods in fiber tractography <xref ref-type="bibr" rid="pone.0093344-Moberts1">[18]</xref>. Intuitively, the max-average-min distance is appealing because it incorporates information from many points along each streamline without excessive influence from any single point on either pathway. The max-max-min distance (also known as Hausdorff distance), in contrast, is heavily influenced by single points that stray from the main curve of a fiber, causing fibers to cluster together only if they are extremely similar <xref ref-type="bibr" rid="pone.0093344-Corouge1">[27]</xref>.</p>
<p>Despite these limitations, level set trees are a novel and powerful way to analyze the topography of fiber streamline data sets with minimal <italic>a priori</italic> assumptions. As DWI methodologies improve, the usefulness of this approach for characterizing sub-divisions in anatomical pathways will allow for greater specificity of regions of interest. Originally intended to describe probability density functions, level set trees can be extended to model pseudo-density functions as well, allowing us to apply the trees’ powerful data visualization and clustering tools in the analysis of fiber streamline data sets. This flexibility opens the door for density-based clustering approaches to be used in a variety of neuroimaging analyses beyond white matter tractography. Future work will focus on these extended applications in a neuroimaging context.</p>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pone.0093344-Hagmann1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagmann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Jonasson</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Maeder</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Thiran</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Wedeen</surname><given-names>VJ</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Understanding Diffusion MR Imaging Techniques : From Scalar Diffusion-weighted Imaging to Diffusion Tensor Imaging and Beyond</article-title>. <source>Radiographics</source> <volume>26</volume>: <fpage>205</fpage>–<lpage>224</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Descoteaux1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Descoteaux</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Deriche</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Knösche</surname><given-names>TR</given-names></name>, <name name-style="western"><surname>Anwander</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Deterministic and probabilistic tractography based on complex fibre orientation distributions</article-title>. <source>IEEE transactions on medical imaging</source> <volume>28</volume>: <fpage>269</fpage>–<lpage>86</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Hagmann2"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hagmann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Cammoun</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gigandet</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Meuli</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Honey</surname><given-names>CJ</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Mapping the structural core of human cerebral cortex</article-title>. <source>PLoS biology</source> <volume>6</volume>: <fpage>1479</fpage>–<lpage>1493</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Wedeen1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wedeen</surname><given-names>VJ</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>RP</given-names></name>, <name name-style="western"><surname>Schmahmann</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Benner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Tseng</surname><given-names>WYI</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Diffusion spectrum magnetic resonance imaging (DSI) tractography of crossing fibers</article-title>. <source>NeuroImage</source> <volume>41</volume>: <fpage>1267</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Wedeen2"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wedeen</surname><given-names>VJ</given-names></name>, <name name-style="western"><surname>Rosene</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Dai</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Mortazavi</surname><given-names>F</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The geometric structure of the brain fiber pathways</article-title>. <source>Science (New York, NY)</source> <volume>335</volume>: <fpage>1628</fpage>–<lpage>34</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Greenberg1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenberg</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Verstynen</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Chiu</surname><given-names>YC</given-names></name>, <name name-style="western"><surname>Yantis</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Visuotopic cortical connectivity underlying attention revealed with white-matter tractography</article-title>. <source>The Journal of neuroscience : the official journal of the Society for Neuroscience</source> <volume>32</volume>: <fpage>2773</fpage>–<lpage>82</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Verstynen1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verstynen</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Jarbo</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Pathak</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>In vivo mapping of microstructural somatotopies in the human corticospinal pathways</article-title>. <source>Journal of neurophysiology</source> <volume>105</volume>: <fpage>336</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Verstynen2"><label>8</label>
<mixed-citation publication-type="other" xlink:type="simple">Verstynen TD, Badre D, Jarbo K, Schneider W (2012) Microstructural organizational patterns in the human corticostriatal system. Journal of neurophysiology.</mixed-citation>
</ref>
<ref id="pone.0093344-Makris1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Makris</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Papadimitriou</surname><given-names>GM</given-names></name>, <name name-style="western"><surname>Kaiser</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Sorg</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kennedy</surname><given-names>DN</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Delineation of the middle longitudinal fascicle in humans: a quantitative, in vivo, DT-MRI study</article-title>. <source>Cerebral cortex (New York, NY : 1991)</source> <volume>19</volume>: <fpage>777</fpage>–<lpage>85</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Wang1"><label>10</label>
<mixed-citation publication-type="other" xlink:type="simple">Wang Y, Fernández-Miranda JC, Verstynen T, Pathak S, Schneider W, <etal>et al</etal>.. (2012) Rethinking the Role of the Middle Longitudinal Fascicle in Language and Auditory Pathways. Cerebral Cortex : 1–10.</mixed-citation>
</ref>
<ref id="pone.0093344-Catani1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Catani</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dell’acqua</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Vergani</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Malik</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hodge</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Short frontal lobe connections of the human brain</article-title>. <source>Cortex</source> <volume>48</volume>: <fpage>273</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Catani2"><label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">Catani M, Mesulam MM, Jakobsen E, Malik F, Matersteck A, <etal>et al</etal>.. (2013) A novel frontal pathway underlies verbal fluency in primary progressive aphasia. Brain.</mixed-citation>
</ref>
<ref id="pone.0093344-Jarbo1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jarbo</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Verstynen</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name> (<year>2012</year>) <article-title>In vivo quantification of global connectivity in the human corpus callosum</article-title>. <source>NeuroImage</source> <volume>59</volume>: <fpage>1988</fpage>–<lpage>1996</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-VanEssen1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Essen</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Ugurbil</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Auerbach</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Barch</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>The Human Connectome Project: a data acquisition perspective</article-title>. <source>NeuroImage</source> <volume>62</volume>: <fpage>2222</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Honey1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honey</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Cammoun</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gigandet</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Thiran</surname><given-names>JP</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Predicting human restingstate functional connectivity from structural connectivity</article-title>. <source>PNAS</source> <volume>106</volume>: <fpage>2035</fpage>–<lpage>2040</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Pyles1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pyles</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Verstynen</surname><given-names>TD</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Tarr</surname><given-names>MJ</given-names></name> (<year>2013</year>) <article-title>Explicating the Face Perception Network with White Matter Connectivity</article-title>. <source>PLoS ONE</source> <volume>8</volume>: <fpage>e61611</fpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Jbabdi1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Jbabdi S, Sotiropoulos SN, Behrens TE (2013) The topographic connectome. Current Opinion in Neurobiology : 1–9.</mixed-citation>
</ref>
<ref id="pone.0093344-Moberts1"><label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Moberts B, Vilanova A, Van Wijk JJ (2005) Evaluation of Fiber Clustering Methods for Diffusion Tensor Imaging. IEEE Visualization : 65–72.</mixed-citation>
</ref>
<ref id="pone.0093344-ODonnell1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">O’Donnell LJ, Golby AJ, Westin CF (2013) Fiber clustering versus the parcellation-based connectome. NeuroImage.</mixed-citation>
</ref>
<ref id="pone.0093344-Shimony1"><label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Shimony JS, Snyder AZ, Lori N, Conturo TE (2002) Automated Fuzzy Clustering of Neuronal Pathways in Diffusion Tensor Tracking. Proceedings of the International Society of Magnetic Resonance Imaging in Medicine.</mixed-citation>
</ref>
<ref id="pone.0093344-Li1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Xue</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hunter</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>A hybrid approach to automatic clustering of white matter fibers</article-title>. <source>NeuroImage</source> <volume>49</volume>: <fpage>1249</fpage>–<lpage>58</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-ODonnell2"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Donnell</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Westin</surname><given-names>CF</given-names></name> (<year>2005</year>) <article-title>White matter tract clustering and correspondence in populations</article-title>. <source>Medical image computing and computer-assisted intervention : MICCAI International Conference on Medical Image Computing and Computer-Assisted Intervention</source> <volume>8</volume>: <fpage>140</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Jonasson1"><label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Jonasson L, Hagmann P, Thiran JP, Wedeen VJ (2005) Fiber tracts of high angular resolution diffusion MRI are easily segmented with spectral clustering. Proceedings of the International Society of Magnetic Resonance Imaging in Medicine.</mixed-citation>
</ref>
<ref id="pone.0093344-Wassermann1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Wassermann D, Descoteaux M, Deriche R (2008) Diffusion maps clustering for magnetic resonance q-ball imaging segmentation. International Journal of Biomedical Imaging.</mixed-citation>
</ref>
<ref id="pone.0093344-Tsai1"><label>25</label>
<mixed-citation publication-type="other" xlink:type="simple">Tsai A, Westin CF, Hero AO III, Willsky AS (2007) Fiber Tract Clustering on Manifolds With Dual Rooted-Graphs. In: IEEE Conference on Computer Vision and Pattern Recognition. Minneapolis, MN, 1–6. doi:10.1109/CVPR.2007.383096.</mixed-citation>
</ref>
<ref id="pone.0093344-Gerig1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Gerig G, Gouttard S, Corouge I (2004) Analysis of Brain White Matter via Fiber Tract Modeling. In: Proceedings of the 26th Annual International Conference of the IEEE EMBS. San Francisco, California, United States, 4421–4424.</mixed-citation>
</ref>
<ref id="pone.0093344-Corouge1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Corouge I, Gouttard S, Gerig G (2004) Towards a Shape Model of White Matter Fiber Bundles Using Diffusion Tensor MRI. In: International Symposium on Biomedical Imaging (ISBI). 344–347.</mixed-citation>
</ref>
<ref id="pone.0093344-Prasad1"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Prasad G, Joshi SH, Jahanshad N, Villalon J, Aganj I, <etal>et al</etal>.. (2011) White Matter Tract Analysis in 454 Adults using Maximum Density Paths. MICCAI 2011 Workshop on Computational Diffusion MRI.</mixed-citation>
</ref>
<ref id="pone.0093344-Xia1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xia</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Turken</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Whitfield-Gabrieli</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Gabrieli</surname><given-names>JD</given-names></name> (<year>2005</year>) <article-title>Knowledge-based classification of neuronal fibers in entire brain</article-title>. <source>Medical image computing and computer-assisted intervention : MICCAI International Conference on Medical Image Computing and Computer-Assisted Intervention</source> <volume>8</volume>: <fpage>205</fpage>–<lpage>12</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Ding1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Gore</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>AW</given-names></name> (<year>2003</year>) <article-title>Classification and Quantification of Neuronal Fiber Pathways Using Diffusion Tensor MRI</article-title>. <source>Magnetic Resonance in Medicine</source> <volume>49</volume>: <fpage>716</fpage>–<lpage>721</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Guevara1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guevara</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Poupon</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rivière</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Cointepas</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Descoteaux</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Robust clustering of massive tractography datasets</article-title>. <source>NeuroImage</source> <volume>54</volume>: <fpage>1975</fpage>–<lpage>1993</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Wassermann2"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wassermann</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Bloy</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Kanterakis</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Verma</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Deriche</surname><given-names>R</given-names></name> (<year>2010</year>) <article-title>Unsupervised white matter fiber clustering and tract probability map generation: applications of a Gaussian process framework for white matter fibers</article-title>. <source>NeuroImage</source> <volume>51</volume>: <fpage>228</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Zhang1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Zhang S, Laidlaw DH (2005) DTI Fiber Clustering and Cross-subject Cluster Analysis. Proceedings of the International Society of Magnetic Resonance Imaging in Medicine: 2727.</mixed-citation>
</ref>
<ref id="pone.0093344-Hartigan1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartigan</surname><given-names>JA</given-names></name> (<year>1981</year>) <article-title>Consistency of Single Linkage for High-Density Clusters</article-title>. <source>Journal of the American Statistical Association</source> <volume>76</volume>: <fpage>388</fpage>–<lpage>394</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Wassermann3"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wassermann</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Deriche</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>Simultaneous Manifold Learning and Clustering : Grouping White Matter Fiber Tracts Using a Volumetric White Matter Atlas</article-title>. <source>MICCAI 2008 Workshop - Manifolds in Medical Imaging: Metrics, Learning and</source> <volume>Beyond2</volume> <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Zvitia1"><label>36</label>
<mixed-citation publication-type="other" xlink:type="simple">Zvitia O, Mayer A, Greenspan H (2008) Adaptive Mean-Shift Registration of White Matter Tractographies. 5th IEEE International Symposium on Biomedical Imaging : 692–695.</mixed-citation>
</ref>
<ref id="pone.0093344-Brun1"><label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Brun A, Knutsson H, Park HJ, Shenton ME, Westin CF (2004) Clustering Fiber Traces Using Normalized Cuts. In: Barillot C, Haynor DR, Hellier P, editors, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2004. Springer-Verlag, 368–375.</mixed-citation>
</ref>
<ref id="pone.0093344-Wang2"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Grimson</surname><given-names>WEL</given-names></name>, <name name-style="western"><surname>Westin</surname><given-names>CF</given-names></name> (<year>2011</year>) <article-title>Tractography segmentation using a hierarchical Dirichlet processes mixture model</article-title>. <source>NeuroImage</source> <volume>54</volume>: <fpage>290</fpage>–<lpage>302</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Hartigan2"><label>39</label>
<mixed-citation publication-type="other" xlink:type="simple">Hartigan J (1975) Clustering Algorithms. John Wiley &amp; Sons.</mixed-citation>
</ref>
<ref id="pone.0093344-Rao1"><label>40</label>
<mixed-citation publication-type="other" xlink:type="simple">Rao P (1983) Nonparametric Functional Estimation. Orlando, Florida: Academic Press.</mixed-citation>
</ref>
<ref id="pone.0093344-Wishart1"><label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Wishart D (1969) Mode analysis: a generalization of nearest neighbor which reduces chaining effects. In: Cole AJ, editor, Proceedings of the Colloquium on Numerical Taxonomy held in the University of St. Andrews. 282–308.</mixed-citation>
</ref>
<ref id="pone.0093344-Maier1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maier</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hein</surname><given-names>M</given-names></name>, <name name-style="western"><surname>von Luxburg</surname><given-names>U</given-names></name> (<year>2009</year>) <article-title>Optimal construction of k-nearest-neighbor graphs for identifying noisy clusters</article-title>. <source>Theoretical Computer Science</source> <volume>410</volume>: <fpage>1749</fpage>–<lpage>1764</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Chaudhuri1"><label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Chaudhuri K, Dasgupta S (2010) Rates of convergence for the cluster tree. In: Advances in Neural Information Processing Systems 23. Vancouver, BC, 343–351.</mixed-citation>
</ref>
<ref id="pone.0093344-Kpotufe1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kpotufe</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Luxburg</surname><given-names>UV</given-names></name> (<year>2011</year>) <article-title>Pruning nearest neighbor cluster trees</article-title>. <source>Proceedings of the 28th International Conference on Machine Learning</source> <volume>105</volume>: <fpage>225</fpage>–<lpage>232</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Devroye1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Devroye</surname><given-names>LP</given-names></name>, <name name-style="western"><surname>Wagner</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Devroye</surname><given-names>BYLP</given-names></name> (<year>1977</year>) <article-title>The Strong Uniform Consistency of Nearest Neighbor Density Estimates</article-title>. <source>The Annals of Statistics</source> <volume>5</volume>: <fpage>536</fpage>–<lpage>540</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Rinaldo1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rinaldo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wasserman</surname><given-names>L</given-names></name> (<year>2010</year>) <article-title>Generalized density clustering</article-title>. <source>The Annals of Statistics</source> <volume>38</volume>: <fpage>2678</fpage>–<lpage>2722</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Rinaldo2"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rinaldo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Nugent</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wasserman</surname><given-names>L</given-names></name> (<year>2012</year>) <article-title>Stability of Density-Based Clustering</article-title>. <source>Journal of Machine Learning Research</source> <volume>13</volume>: <fpage>905</fpage>–<lpage>948</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Billingsley1"><label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Billingsley P (2012) Probability and Measure. Wiley.</mixed-citation>
</ref>
<ref id="pone.0093344-Ferraty1"><label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Ferraty F, Vieu P (2006) Nonparametric Functional Data Analysis. Springer.</mixed-citation>
</ref>
<ref id="pone.0093344-Zhang2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Correia</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Laidlaw</surname><given-names>DH</given-names></name> (<year>2008</year>) <article-title>Identifying white-matter fiber bundles in DTI data using an automated proximity-based fiber-clustering method</article-title>. <source>IEEE transactions on visualization and computer graphics</source> <volume>14</volume>: <fpage>1044</fpage>–<lpage>53</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Garyfallidis1"><label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Garyfallidis E, Brett M, Amirbekian B, Nguyen C, Yeh Fc, <etal>et al</etal>.. (2011) Dipy - a novel software library for diffusion MR and tractography. In: 17th Annual Meeting of the Organization for Human Brain Mapping. 1–5.</mixed-citation>
</ref>
<ref id="pone.0093344-Arthur1"><label>52</label>
<mixed-citation publication-type="other" xlink:type="simple">Arthur D, Vassilvitskii S (2007) k-means++: The Advantages of Careful Seeding. In: ACM-SIAM Symposium on Discrete Algorithms. 1027–1035. doi:10.1145/1283383.1283494.</mixed-citation>
</ref>
<ref id="pone.0093344-Hastie1"><label>53</label>
<mixed-citation publication-type="other" xlink:type="simple">Hastie T, Tibshirani R, Friedman J (2009) The Elements of Statistical Learning. Springer, second edition, 510–526. doi:978-0387848570.</mixed-citation>
</ref>
<ref id="pone.0093344-vonLuxburg1"><label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">von Luxburg U (2006) A Tutorial on Spectral Clustering. Technical Report August, Max Planck Institute for Biological Cybernetics, Tuebingen.</mixed-citation>
</ref>
<ref id="pone.0093344-Coifman1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coifman</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Lafon</surname><given-names>S</given-names></name> (<year>2006</year>) <article-title>Diffusion maps</article-title>. <source>Applied and Computational Harmonic Analysis</source> <volume>21</volume>: <fpage>5</fpage>–<lpage>30</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Ester1"><label>56</label>
<mixed-citation publication-type="other" xlink:type="simple">Ester M, Kriegel Hp, Xu X (1996) A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. In: Knowledge Discovery and Data Mining. 226–231.</mixed-citation>
</ref>
<ref id="pone.0093344-R1"><label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">R Core Team (2012) R: A Language and Environment for Statistical Computing. Technical report, R Foundation for Statistical Computing, Vienna, Austria. Available: <ext-link ext-link-type="uri" xlink:href="http://www.r-project.org/" xlink:type="simple">http://www.r-project.org/</ext-link>. doi:3-900051-07-0.</mixed-citation>
</ref>
<ref id="pone.0093344-Pedregosa1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pedregosa</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Varoquaux</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gramfort</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Michel</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname><given-names>B</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Scikit-learn : Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source> <volume>12</volume>: <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Richards1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Richards</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>AB</given-names></name>, <name name-style="western"><surname>Schafer</surname><given-names>CM</given-names></name> (<year>2009</year>) <article-title>Exploiting Low-Dimensional Structure in Astronomical Spectra</article-title>. <source>The Astrophysical Journal</source> <volume>691</volume>: <fpage>32</fpage>–<lpage>42</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Richards2"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Richards</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>AB</given-names></name>, <name name-style="western"><surname>Schafer</surname><given-names>CM</given-names></name> (<year>2009</year>) <article-title>Accurate parameter estimation for star formation history in galaxies using SDSS spectra</article-title>. <source>Monthly Notices of the Royal Astronomical Society</source> <volume>399</volume>: <fpage>1044</fpage>–<lpage>1057</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Yeh1"><label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Yeh FC, Tseng WYI (2010) Automatic Tractography Segmentation by Morphological Continuity Clustering. In: 2International Society for Magnetic Resonance in Imaging, 2010 Annual Meeting.</mixed-citation>
</ref>
<ref id="pone.0093344-Yeh2"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yeh</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>Tseng</surname><given-names>WYI</given-names></name> (<year>2011</year>) <article-title>NTU-90: a high angular resolution brain atlas constructed by q-space diffeomorphic reconstruction</article-title>. <source>NeuroImage</source> <volume>58</volume>: <fpage>91</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Ashburner1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ashburner</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name> (<year>1999</year>) <article-title>Nonlinear Spatial Normalization Using Basis Functions</article-title>. <source>Human Brain Mapping</source> <volume>7</volume>: <fpage>254</fpage>–<lpage>266</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Yeh3"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yeh</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>Wedeen</surname><given-names>VJ</given-names></name>, <name name-style="western"><surname>Tseng</surname><given-names>WYI</given-names></name> (<year>2010</year>) <article-title>Generalized q-sampling imaging</article-title>. <source>IEEE transactions on medical imaging</source> <volume>29</volume>: <fpage>1626</fpage>–<lpage>35</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Basser1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Basser</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Pajevic</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Pierpaoli</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Duda</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Aldroubi</surname><given-names>a</given-names></name> (<year>2000</year>) <article-title>In vivo fiber tractography using DTMRI data</article-title>. <source>Magnetic resonance in medicine : official journal of the Society of Magnetic Resonance in Medicine/Society of Magnetic Resonance in Medicine</source> <volume>44</volume>: <fpage>625</fpage>–<lpage>32</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Lazar1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Weinstein</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Tsuruda</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Hasan</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Arfanakis</surname><given-names>K</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>White matter tractography using diffusion tensor deflection</article-title>. <source>Human brain mapping</source> <volume>18</volume>: <fpage>306</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Haber1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haber</surname><given-names>SN</given-names></name>, <name name-style="western"><surname>Knutson</surname><given-names>B</given-names></name> (<year>2010</year>) <article-title>The reward circuit: linking primate anatomy and human imaging</article-title>. <source>Neuropsychopharmacology : official publication of the American College of Neuropsychopharmacology</source> <volume>35</volume>: <fpage>4</fpage>–<lpage>26</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Azzalini1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Azzalini</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Torelli</surname><given-names>N</given-names></name> (<year>2007</year>) <article-title>Clustering via nonparametric density estimation</article-title>. <source>Statistics and Computing</source> <volume>17</volume>: <fpage>71</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Draganski1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Draganski</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kherif</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Klöppel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Cook</surname><given-names>Pa</given-names></name>, <name name-style="western"><surname>Alexander</surname><given-names>DC</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Evidence for segregated and integrative connectivity patterns in the human Basal Ganglia</article-title>. <source>The Journal of neuroscience : the official journal of the Society for Neuroscience</source> <volume>28</volume>: <fpage>7143</fpage>–<lpage>52</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Graybiel1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graybiel</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Ragsdale</surname><given-names>CW</given-names></name> (<year>1978</year>) <article-title>Histochemically distinct compartments in the striatum of human, monkey, and cat demonstrated by acetylthiocholinesterase staining</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>75</volume>: <fpage>5723</fpage>–<lpage>5726</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-Ragsdale1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ragsdale</surname><given-names>CW</given-names></name>, <name name-style="western"><surname>Graybiel</surname><given-names>AM</given-names></name> (<year>1990</year>) <article-title>A simple ordering of neocortical areas established by the compartmental organization of their striatal projections</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>87</volume>: <fpage>6196</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pone.0093344-BenHur1"><label>72</label>
<mixed-citation publication-type="other" xlink:type="simple">Ben-Hur A, Elisseeff A, Guyon I (2002) A stability based method for discovering structure in clustered data. In: Pacific Symposium on Biocomputing. volume 17, 6–17.</mixed-citation>
</ref>
<ref id="pone.0093344-Smith1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Dubes</surname><given-names>R</given-names></name> (<year>1980</year>) <article-title>Stability of a hierarchical clustering</article-title>. <source>Pattern Recognition</source> <volume>12</volume>: <fpage>177</fpage>–<lpage>187</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>