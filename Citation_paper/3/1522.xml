<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0174910</article-id>
<article-id pub-id-type="publisher-id">PONE-D-16-29007</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Ophthalmology</subject><subj-group><subject>Visual impairments</subject><subj-group><subject>Scotoma</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Eyes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Eyes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Eyes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Eyes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Image processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Ophthalmology</subject><subj-group><subject>Visual impairments</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Computers</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Materials science</subject><subj-group><subject>Materials by structure</subject><subj-group><subject>Amorphous solids</subject><subj-group><subject>Glass</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Evaluation of a gaze-controlled vision enhancement system for reading in visually impaired people</article-title>
<alt-title alt-title-type="running-head">Evaluation of a gaze-controlled vision enhancement system for reading in visually impaired people</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Aguilar</surname>
<given-names>Carlos</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Castet</surname>
<given-names>Eric</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>BCL, Nice Sophia Antipolis Univ, CNRS, Nice, France</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>LPC, Aix Marseille Univ, CNRS, Marseille, France</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>González-Méijome</surname>
<given-names>José M.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Universidade do Minho, PORTUGAL</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>Carlos Aguilar’s (CA) Ph.D. was funded by Essilor International (<ext-link ext-link-type="uri" xlink:href="http://www.essilor.com/fr" xlink:type="simple">http://www.essilor.com/fr</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. This does not alter our adherence to PLOS ONE policies on sharing data and materials.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple"><list-item>
<p><bold>Conceptualization:</bold> EC CA.</p></list-item> <list-item>
<p><bold>Data curation:</bold> EC CA.</p></list-item> <list-item>
<p><bold>Formal analysis:</bold> EC CA.</p></list-item> <list-item>
<p><bold>Funding acquisition:</bold> EC.</p></list-item> <list-item>
<p><bold>Investigation:</bold> CA.</p></list-item> <list-item>
<p><bold>Methodology:</bold> CA EC.</p></list-item> <list-item>
<p><bold>Project administration:</bold> EC.</p></list-item> <list-item>
<p><bold>Resources:</bold> EC.</p></list-item> <list-item>
<p><bold>Software:</bold> CA.</p></list-item> <list-item>
<p><bold>Supervision:</bold> EC.</p></list-item> <list-item>
<p><bold>Validation:</bold> EC.</p></list-item> <list-item>
<p><bold>Visualization:</bold> EC.</p></list-item> <list-item>
<p><bold>Writing – original draft:</bold> EC.</p></list-item> <list-item>
<p><bold>Writing – review &amp; editing:</bold> EC CA.</p></list-item></list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">eric.castet@univ-amu.fr</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>5</day>
<month>4</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<year>2017</year>
</pub-date>
<volume>12</volume>
<issue>4</issue>
<elocation-id>e0174910</elocation-id>
<history>
<date date-type="received">
<day>20</day>
<month>7</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>17</day>
<month>3</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Aguilar, Castet</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pone.0174910"/>
<abstract>
<p>People with low vision, especially those with Central Field Loss (CFL), need magnification to read. The flexibility of Electronic Vision Enhancement Systems (EVES) offers several ways of magnifying text. Due to the restricted field of view of EVES, the need for magnification is conflicting with the need to navigate through text (panning). We have developed and implemented a real-time gaze-controlled system whose goal is to optimize the possibility of magnifying a portion of text while maintaining global viewing of the other portions of the text (condition 1). Two other conditions were implemented that mimicked commercially available advanced systems known as CCTV (closed-circuit television systems)—conditions 2 and 3. In these two conditions, magnification was uniformly applied to the whole text without any possibility to specifically select a region of interest. The three conditions were implemented on the same computer to remove differences that might have been induced by dissimilar equipment. A gaze-contingent artificial 10° scotoma (a mask continuously displayed in real time on the screen at the gaze location) was used in the three conditions in order to simulate macular degeneration. Ten healthy subjects with a gaze-contingent scotoma read aloud sentences from a French newspaper in nine experimental one-hour sessions. Reading speed was measured and constituted the main dependent variable to compare the three conditions. All subjects were able to use condition 1 and they found it slightly more comfortable to use than condition 2 (and similar to condition 3). Importantly, reading speed results did not show any significant difference between the three systems. In addition, learning curves were similar in the three conditions. This proof of concept study suggests that the principles underlying the gaze-controlled enhanced system might be further developed and fruitfully incorporated in different kinds of EVES for low vision reading.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Essilor International</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Aguilar</surname>
<given-names>Carlos</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by a Ph. D. grant from Essilor International (<ext-link ext-link-type="uri" xlink:href="http://www.essilor.com/fr" xlink:type="simple">http://www.essilor.com/fr</ext-link>) to CA. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="11"/>
<table-count count="2"/>
<page-count count="24"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data files are available from the figshare database at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.4499264.v1" xlink:type="simple">https://doi.org/10.6084/m9.figshare.4499264.v1</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>1 - Introduction</title>
<p>Age-related Macular Degeneration (AMD), a severe maculopathy, is the most common cause of low vision and often causes dramatic Central Field Loss (CFL) among elderly people who are therefore constrained to use eccentric viewing [<xref ref-type="bibr" rid="pone.0174910.ref001">1</xref>]. This scotoma in the center of the visual field dramatically disrupts reading performance [<xref ref-type="bibr" rid="pone.0174910.ref002">2</xref>,<xref ref-type="bibr" rid="pone.0174910.ref003">3</xref>]. Reading speed is a key performance measure that has been extensively investigated in low vision reading [<xref ref-type="bibr" rid="pone.0174910.ref004">4</xref>–<xref ref-type="bibr" rid="pone.0174910.ref013">13</xref>]. One major goal of people with CFL is to improve their ability to read text [<xref ref-type="bibr" rid="pone.0174910.ref014">14</xref>]. To achieve this goal, magnifying optical and/or electronic aids are commonly prescribed to help maintain the ability to read [<xref ref-type="bibr" rid="pone.0174910.ref015">15</xref>–<xref ref-type="bibr" rid="pone.0174910.ref017">17</xref>], even though magnification never restores reading speed to the level observed without CFL [<xref ref-type="bibr" rid="pone.0174910.ref018">18</xref>].</p>
<p>Electronic Vision Enhancement Systems (EVES) have a great potential to improve perceptual performance of low vision patients [<xref ref-type="bibr" rid="pone.0174910.ref019">19</xref>,<xref ref-type="bibr" rid="pone.0174910.ref020">20</xref>]: in addition to magnification, they can provide many kinds of visual enhancements [<xref ref-type="bibr" rid="pone.0174910.ref021">21</xref>]. A recent survey indicated that most low vision patients express an interest in image processing technology that could be implemented for television viewing and for computer use [<xref ref-type="bibr" rid="pone.0174910.ref022">22</xref>]. Common commercially-available EVES are closed-circuit televisions (CCTVs). One important limitation of EVES is a reduced field of view with high levels of magnification, an issue which has received considerable attention in the context of low vision reading [<xref ref-type="bibr" rid="pone.0174910.ref023">23</xref>–<xref ref-type="bibr" rid="pone.0174910.ref025">25</xref>]. When reading highly magnified text on a screen, only a portion of the line of text is visible at any moment. A technique, called page navigation, must thus be used to reveal successive parts of the text on the display screen. With a standard stand-mounted CCTV, a page of printed text lies on a movable x-y platform under a video camera. The part of the page that lies in the camera's field of view is displayed on a monitor and can be magnified (whole field magnification with a zooming center coinciding with the monitor center). To navigate through the page, the reader must move the platform either in the x direction to read along the line or in the y direction to jump from one line to the other. The subject can adjust the magnification level with a knob placed somewhere on the device. In clinical practice, patients are usually advised during a preliminary phase to adjust this knob until they feel comfortable (during this phase they do not move the platform). Once this level is found, patients are further advised to keep it constant so that their hands can be used to move the platform. Even when patients are allowed to change magnification during reading, only a very small minority uses this possibility (Burggraaff, personal communication): this was observed during a large-scale investigation of the effects of training when using standard CCTVs in visually impaired adults [<xref ref-type="bibr" rid="pone.0174910.ref026">26</xref>,<xref ref-type="bibr" rid="pone.0174910.ref027">27</xref>].</p>
<p>However, it is likely that keeping the magnification level constant is not the most efficient procedure. This was made clear by Culham et al. in 2004 (p.288): "Variable magnification at a fixed viewing distance should be a valuable feature in a low vision device. The facility of keeping magnification low when appropriate, allows a wider field of view, but the option of providing the patient with an acuity reserve [<xref ref-type="bibr" rid="pone.0174910.ref017">17</xref>] when required should be beneficial."[<xref ref-type="bibr" rid="pone.0174910.ref028">28</xref>]. We agree with this important suggestion. A wide field of view is for instance important when patients make long backward saccades to re-read several words. In contrast, at some other instants, identification of some words might be so difficult that a high level of magnification is necessary [<xref ref-type="bibr" rid="pone.0174910.ref029">29</xref>]. It should be noted here that the need to alternate between global information and more local information does not imply that magnification should be applied to the whole image. This might instead be achieved by magnifying only the local portions of the visual scene that the subject wants to identify. For this purpose, using gaze as a pointer that controls the regions of interest to be magnified seems an interesting possibility. Researchers in the field of human-computer interactions have emphasized the importance of eye-tracking [<xref ref-type="bibr" rid="pone.0174910.ref030">30</xref>], and gaze-controlled magnification systems have already been designed and tested for normally-sighted subjects [<xref ref-type="bibr" rid="pone.0174910.ref031">31</xref>–<xref ref-type="bibr" rid="pone.0174910.ref033">33</xref>]. A typical application of this line of research is to offer an efficient and rapid way to alternate between the global view of a large complex image (say the map of a town) and a local magnified view of details (such as streets). In the present study, we investigated whether this gaze-controlled magnification approach, which has been found successful for foveal vision, might be specifically applied to reading with CFL. We also compared this gaze-controlled “intelligent” local zooming system with two CCTV-like conditions that allowed user-friendly changes of magnification levels.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>2 - Methods</title>
<sec id="sec003">
<title>2.1 – Methods for designing the gaze-controlled visual aid (condition 1)</title>
<p>The gaze-controlled zooming aid was developed as part of a project funded by Essilor International. This project investigates the feasibility and the potential benefits for low vision patients of using an integrated system combining gaze-control functions with see-through glasses. The general principle of our system is to use gaze direction to define a region of interest (ROI)–visible on the screen—that can subsequently be visually enhanced (see flowchart in <xref ref-type="fig" rid="pone.0174910.g001">Fig 1</xref>). We refer to this approach as gaze-controlled "local enhancement". Subjects, if and only if they wish, can trigger this local enhancement by a manual control. In the present work, visual enhancement was a magnification (“zooming”) of the ROI (other more sophisticated kinds of enhancement might also be considered in the future). Several types of eye-controlled zooming interfaces with an additional manual activation have been developed for normally-sighted subjects in the field of human-machine interface [eg. <xref ref-type="bibr" rid="pone.0174910.ref032">32</xref>,<xref ref-type="bibr" rid="pone.0174910.ref033">33</xref>]. These developments are particularly promising in contexts in which traditional mouse and keyboard input may not be available or even feasible, as for the interaction with public displays, multi-display setups, large-sized TV sets or see-through glasses. In the long term, see-through glasses equipped with eye-trackers and appropriate image processing techniques, should be able to allow many types of gaze-based interaction with distant real stimuli or displays. Such systems are heavily investigated in the medical field in order to provide 3-D medical visualization techniques based on augmented reality [<xref ref-type="bibr" rid="pone.0174910.ref034">34</xref>,<xref ref-type="bibr" rid="pone.0174910.ref035">35</xref>]. Overall, it seems that these developments also have a great potential for low vision patients [<xref ref-type="bibr" rid="pone.0174910.ref036">36</xref>] and have therefore been used to guide our work.</p>
<fig id="pone.0174910.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Flowchart of the key principles underlying the gaze-controlled visual aid (condition 1).</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g001" xlink:type="simple"/>
</fig>
<p>The main features of our gaze-contingent system are the following. The first feature concerns the way by which subjects choose the region that they want to magnify. This is achieved by positioning the scotoma on a line of text at the approximate location that the subject wants to magnify. When the scotoma's center location lies on a given line, a fixed-width portion (in letters) of this line of text extending to the left and right of the scotoma is highlighted (<xref ref-type="fig" rid="pone.0174910.g002">Fig 2T2</xref>). This highlighted area is the ROI: it provides a visual feedback to the subject and indicates that this area (including the part hidden by the scotoma) can be magnified and displaced, if needed, by a button press. After a button press, a new region, that we call the Region Of Augmented Vision (ROAV), appears below the scotoma (<xref ref-type="fig" rid="pone.0174910.g002">Fig 2T3</xref>): this new region is a magnified and displaced version of the ROI.</p>
<fig id="pone.0174910.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Schematic illustration of the gaze-contingent visual aid across time at three successive instants.</title>
<p>Note that the gray rectangle (one for each instant) shows only a small portion of the screen. Note also that only one line of text is presented here for clarity. T1/ the scotoma (outlined square) is over an empty region: the Region Of Interest (ROI) thus appears as a rectangle filled with white. The width of the ROI is constant: 16 characters. T2/ the scotoma's center is on a line of text: the ROI now highlights 16 characters whose middle location corresponds to scotoma’s center. Subjects have to decide whether or not they want to trigger an enhancement of the ROI by pressing a button. T3/ After a button press, the Region Of Augmented Vision (ROAV) appears below the scotoma while the initial ROI remains highlighted. As long as the button is pressed, the whole display remains the same and subjects can explore the ROAV with eye movements (see <xref ref-type="fig" rid="pone.0174910.g003">Fig 3</xref>). After button release (not shown here), the ROAV and its corresponding ROI disappear and a new gaze-contingent ROI is displayed based on the new gaze location. In this figure and the following, the artificial scotoma is transparent for visual clarity but it was opaque in the actual experiments.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g002" xlink:type="simple"/>
</fig>
<p>After being displayed, the ROAV remains on the screen as long as the button is pressed, thus allowing the subject to make ocular saccades to explore the ROAV (<xref ref-type="fig" rid="pone.0174910.g003">Fig 3</xref>). When releasing the button, the ROAV and its corresponding ROI disappear; then a new ROI appears with its position defined by the current gaze location. In the present work, the button used for these controls was the central button of a 5-button response box (RESPONSEPixx Handheld—VPixx Technologies). The top and bottom buttons of the box were used to move the text in the vertical direction (only when the ROAV was not displayed).</p>
<fig id="pone.0174910.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Potential continuation of <xref ref-type="fig" rid="pone.0174910.g002">Fig 2</xref>: visual exploration of the Region Of Augmented Vision (ROAV) with two successive ocular fixations.</title>
<p>As long as the ROAV is displayed (i.e. as long as the button is pressed), subjects can make ocular fixations on different parts of the ROAV.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g003" xlink:type="simple"/>
</fig>
<p>To implement the general principles described above, the following parameters are used. The ROI center coincides with the scotoma center. The ROI width is 16 characters so that it appears as two 3-character wide rectangles on each side of the 10° scotoma. The interline size determines the ROI height. When the ROI lies on a character-free region of the background, it appears as a white rectangle. When the ROI contained characters, it appears as a white rectangle containing black characters (highlighting). Character's size within the ROAV is twice as big as that within the ROI.</p>
<p>The example shown in <xref ref-type="fig" rid="pone.0174910.g002">Fig 2(T2) and 2(T3)</xref> does not represent the most common situation. This is a simple case where the ROI contains only full words, so that the mapping between the ROI and the ROAV is straightforward: the ROI contains exactly three words and has been transformed into a 3-word ROAV. In most cases, however, the situation is more complex as the left and right ROI borders are often located within words (<xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref>). In these cases, different rules determining the ROI/ROAV mapping are possible. The point here is that the main goal of these mapping rules is to produce an ROAV containing entire words, i.e. the magnification process never produces "mutilated" words. In contrast, when using a standard lens (optical or electronic), such a magnification-induced mutilation occurs most of the time depending on the lens position with respect to the word (and to the screen border) and on the ratio between word size and lens size (Note that this feature of our system can be generalized to natural images where image processing techniques could be used to segment faces or objects from their background, so that any of these faces or objects would always appear in its entirety once magnified).</p>
<fig id="pone.0174910.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Example of an ROI whose left and right borders are located within words ("cette" and "complexe").</title>
<p>In this particular example, each of these 2 words has more than 50% of its letters within the ROI so that these words are included within the ROAV. Note that the large gray rectangle shows only a small portion of the monitor’s screen.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g004" xlink:type="simple"/>
</fig>
<p>Thus, our algorithm aims at injecting some smartness into the “zooming” process: while the ROI width is constant (16 characters), the ROAV width is not constant because there is no one-to-one mapping between the ROI letters and the ROAV letters. To determine the characters contained within the ROI that will be displayed within the ROAV, the following conditional rules are used. As already explained, the simplest case is represented in <xref ref-type="fig" rid="pone.0174910.g002">Fig 2</xref> where the ROI left border is just before the first letter of the ROI leftmost word ("avait") and the ROI right border is just after the last letter of the ROI rightmost word ("grands"). In this case, the ROAV content is the same as the ROI content, i.e. the ROAV contains the same 16 characters as the ROI. However, in most cases, such a spatial alignment does not occur (as illustrated above in <xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref>) and the following rule is then used. The leftmost and rightmost ROI words are only included in the ROAV if more than 50% of their letters (for each word) are contained within the ROI. This is what happens in <xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref> where the words "cette" and "complexe" are displayed in the ROAV although they were not entirely contained within the ROI (i.e. the width of the ROAV is larger than the 16-character width of the ROI). In contrast, <xref ref-type="fig" rid="pone.0174910.g005">Fig 5</xref> illustrates a different case where the rightmost word ("complètement"), although bridging across the ROI border, is not included within the ROAV. This is because less than 50% of its letters are contained within the ROI. The mapping rule thus creates an ROAV that contains only two full words, (i.e. a smaller width in letters than the ROI width).</p>
<fig id="pone.0174910.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Example of an ROI whose left and right borders are located within words ("cette" and "complètement").</title>
<p>Here, in contrast with the example shown in <xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref>, less than 50% of the rightmost word's letters are contained within the ROI, so that this word ("complètement") is not included within the ROAV. Note that the large gray rectangle shows only a small portion of the monitor’s screen.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g005" xlink:type="simple"/>
</fig>
<p>In the previous examples, the location of the ROAV is always determined by aligning its horizontal center with the horizontal center of the scotoma. However, in some cases, this behavior is not desired. For instance, <xref ref-type="fig" rid="pone.0174910.g006">Fig 6A</xref> shows that the proximity of the left screen border (black bar) would make it impossible to see the first ROAV letters if this rule was blindly applied. The actual ROI/ROAV mapping rules take this problem into account as illustrated in <xref ref-type="fig" rid="pone.0174910.g006">Fig 6B</xref>. Here, the ROAV is entirely visible because its left border has been aligned with the left screen border. These rules apply more generally whenever it is necessary to avoid disappearance of a part of the ROAV as illustrated in <xref ref-type="fig" rid="pone.0174910.g007">Fig 7</xref>. Here, the ROAV cannot be displaced below the scotoma, so that its location is determined by aligning its center and the scotoma's center (note that the choice of this location is arbitrary as the ROAV could have been remapped above the scotoma).</p>
<fig id="pone.0174910.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Example of ROAV adaptation to a monitor’s screen border.</title>
<p>The grey rectangle represents a portion of the screen delimited by the left screen border (vertical black bar). A/ this shows what would happen if the ROAV location was determined without taking into account the presence of the screen border: the first five letters of the word "maisons" would be invisible. B/ To allow full visibility of the ROAV, the mapping rule adjusts the ROAV location by aligning its left border with the left screen border.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g006" xlink:type="simple"/>
</fig>
<fig id="pone.0174910.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Example of ROAV adaptation to a monitor’s screen border across time.</title>
<p>The grey rectangle represents a portion of the screen delimited by the bottom screen border (horizontal black bar). T1/ Same case as in <xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref> except that the scotoma is very close to the bottom of the screen. T2/ After the button press, displaying the ROAV below the scotoma would make it invisible. Therefore, in this case, the ROAV is displayed with its center aligned with the scotoma's center.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>2.2 - Methods for validation of the gaze-controlled visual aid (condition 1)</title>
<p>The gaze-controlled system (condition 1) was compared with two CCTV-like conditions (condition 2 and condition 3) that allowed a rapid and user-friendly change of magnification level at any moment during reading. The two latter interfaces were inspired by commercially available EVES (CCTV magnifiers) that we improved to facilitate and encourage the alternation between different magnification levels. To allow direct comparisons, the three systems were implemented on the same experimental setup with stimuli displayed on the same screen. Systems 2 and 3 aimed at simulating a standard CCTV magnifier and improving its interface. This simulation was implemented on a standard computer where text stored in the computer could be displaced and zoomed either with a mouse or with a response box.</p>
<p>Examples of three conditions are provided in the <italic>Supporting Information</italic> (gaze-contingent visual aid, condition 1, "<xref ref-type="supplementary-material" rid="pone.0174910.s001">S1 Movie</xref>"; improved CCTV, condition 2, "<xref ref-type="supplementary-material" rid="pone.0174910.s002">S2 Movie</xref>"; and CCTV with zoom-induced text reformatting, condition 3, "<xref ref-type="supplementary-material" rid="pone.0174910.s003">S3 Movie</xref>").</p>
<p>Condition 2 (improved standard CCTV condition) ameliorates standard CCTVs in two ways: a/ by moving a mouse (rather than an x-y platform) in order to pan the text, and b/ by using the mouse scroll-wheel (rather than a button located relatively far from the platform) to zoom the text (<xref ref-type="fig" rid="pone.0174910.g008">Fig 8B</xref>). The zooming characteristics in this system are the same as those used in a standard CCTV. Notably, the zooming center always coincides with the monitor's center. One consequence is that the magnification process induces a radial motion of all the words towards the screen borders and consequently a disappearance of all the words close to the four screen’s borders.</p>
<fig id="pone.0174910.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Illustration of the two CCTV-like conditions.</title>
<p>The gray rectangle corresponds to the screen’s viewing area. A/ example of a sentence displayed at the beginning of a trial. The full sentence is visible. B/ Effect of magnification in condition 2. The first sentence’s word (“L’incident”) has been maintained visible in the top left screen corner thanks to panning. Note the disappearance and mutilation of words displayed on the right in the initial display. C/ Effect of magnification in condition 3 (same zooming level as in B/). The first sentence’s word (“L’incident”) has also been maintained in the top left screen corner. Note that all the consecutive words of the sentence (up to “police”) are visible thanks to reformatting.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g008" xlink:type="simple"/>
</fig>
<p>Condition 3 (CCTV with zoom-induced text reformatting) was similar to the second one except that text was reformatted in order to fit horizontally within the monitor’s width whenever the magnification level was changed (<xref ref-type="fig" rid="pone.0174910.g008">Fig 8C</xref>). This reformatting is actually what happens in any word processing software when print size is changed. This possibility has been implemented in a commercially available CCTV device ("column" layout of the myReader2 video magnifier from Humanware) and implies Optical Character Recognition (OCR) before the system can work. In our system, the text to be read is already stored in ascii format in the computer and subjects interact with the text displayed on the computer monitor by pressing one the four outer buttons of a 5-button response box (RESPONSEPixx Handheld—VPixx Technologies). The left and right buttons are respectively used to zoom in and out. The top and bottom buttons are used to move text in the vertical direction. In terms of navigational constraints, the main difference between conditions 2 and 3 is that horizontal panning is not necessary in the third condition.</p>
<sec id="sec005">
<title>Subjects</title>
<p>Ten healthy subjects (5 males), who were not aware of the goals of our study, participated in this work (mean age: 24.3 years old; min: 19; max: 27). They all had a graduate degree (from 2 to 7 years after bachelor degree). They had either normal (8 subjects) or corrected-to-normal vision (2 subjects with mild myopia). Subjects were recruited from January to June 2012 and they received either monetary compensation or class credit for their participation. The study was approved by the University of Aix-Marseille ethical review board and was performed in accordance with the Declaration of Helsinki. All participants gave written informed consent according to the guidelines of the University of Aix-Marseille ethical review board prior to their inclusion in the present study.</p>
</sec>
<sec id="sec006">
<title>Stimuli</title>
<p>Sentences with black characters were displayed in Courier font, a fixed-width font, with double interline spacing. Sentences were displayed within a virtual box (centered in the middle of the screen) whose width and height were respectively 43° and 30°. This was the size of the initial image displayed at the beginning of any trial, i.e. before any modification induced by subjects. Text was left aligned inside the virtual box as for instance in Crossland and Rubin (2006)[<xref ref-type="bibr" rid="pone.0174910.ref037">37</xref>]. At the beginning of each trial (i.e. before any zooming induced by subjects—<xref ref-type="fig" rid="pone.0174910.g008">Fig 8A</xref>), print size was 1°, the value of word acuity at an eccentricity of 6°, a value slightly larger than scotoma's radius [<xref ref-type="bibr" rid="pone.0174910.ref038">38</xref>]. Print size was defined as the visual angle in degrees subtended by a lowercase ‘x’ (x-height) [<xref ref-type="bibr" rid="pone.0174910.ref039">39</xref>].</p>
<p>A text containing one or several sentences, extracted from articles in the French newspapers "le Monde", was displayed on each trial. The original order of the sentences in the article was maintained across trials to increase subjects' motivation to read. The exact number of sentences within each trial was defined by filling the virtual box with as many sentences as possible without splitting the last (or unique) sentence.</p>
</sec>
<sec id="sec007">
<title>Apparatus</title>
<p>Stimuli were displayed on a 21-in. CRT color monitor (GDM-F520, Sony, Japan) with a refresh rate of 100 Hz. Mean luminance of the grey background was 86.2 cd/m². At the viewing distance of 40 cm, the display area of the monitor subtended 51° X 38.3° (1024 X 768 pixels); the “° “symbol refers to degrees of visual angle here and throughout the text. Subjects sat in a reclining chair with their eyes at a distance of 40 cm from the monitor. Their neck was comfortably maintained by a custom-built foam restraint fixed on the chair to minimize head movements. This restraint was adjusted so that it was not in contact with any part of the eyetracker. Subjects viewed the screen with their dominant eye while wearing a patch over the contralateral eye. If the latter eye had not been patched, subjects could have closed (consciously or not) their tracked eye, thus stopping the display of the gaze-contingent scotoma and allowing the contralateral eye to look at the scene without any scotoma. The room was dimly lit.</p>
<p>The monitor was driven by a personal computer (referred to as the ‘‘display computer”) that was running a custom software that we developed with OpenGL and with the PsychoPy library [<xref ref-type="bibr" rid="pone.0174910.ref040">40</xref>,<xref ref-type="bibr" rid="pone.0174910.ref041">41</xref>]. Our custom software also used python functions from the Pylink library provided by SR Research to interact with the eyetracker.</p>
</sec>
<sec id="sec008">
<title>Eye recording and gaze-contingent scotoma</title>
<p>Subjects’ gaze location (along with other eye data) was recorded 500 times per second with an EyeLink II eye tracker (EL II–head-mounted binocular eyetracker–SR Research Ltd., Mississauga, Ontario, Canada) using the head compensation mode. In this mode, the head is free to move within +/- 30° without altering gaze location recording. Eye location was estimated from pupil centroid. The eye tracker was controlled by a Dimension 4700 DELL PC (referred to as the ‘‘Host computer”). Before each experimental block, a 5-point gaze calibration was performed followed by a 5-point validation (left, middle, right, up and down locations). Calibration and/or validation were repeated until the validation error was smaller than 1° on average and smaller than 1.5° for the worst point.</p>
<p>The experimental program, run on the display computer, interacts with the host computer via a high-speed Ethernet link. This connection allows online processing of eye data and gaze-contingent visual stimulation. In order to simulate an artificial macular scotoma, the program measures gaze location and then displays a mask on the monitor at this location [<xref ref-type="bibr" rid="pone.0174910.ref042">42</xref>,<xref ref-type="bibr" rid="pone.0174910.ref043">43</xref>]. In order to improve the spatio-temporal accuracy of our gaze-contingent scotoma [<xref ref-type="bibr" rid="pone.0174910.ref044">44</xref>–<xref ref-type="bibr" rid="pone.0174910.ref046">46</xref>], we used the rules that we described previously [<xref ref-type="bibr" rid="pone.0174910.ref044">44</xref>]. The gaze-contingent scotoma was a 10° square mask whose color (grey) and luminance were the same as those of the background and with invisible borders.</p>
</sec>
<sec id="sec009">
<title>Statistical analyses</title>
<p>Statistical analyses were based on linear mixed-effects models specifying subjects as random factors [<xref ref-type="bibr" rid="pone.0174910.ref047">47</xref>,<xref ref-type="bibr" rid="pone.0174910.ref048">48</xref>]. We used the lmer function—lme4 package [<xref ref-type="bibr" rid="pone.0174910.ref049">49</xref>]—in the R system for statistical computing [<xref ref-type="bibr" rid="pone.0174910.ref050">50</xref>]. We also used the following additional packages for data processing, graphs and tables: ggplot2, dplyr and stargazer. The Akaike Information Criterion (AIC) and likelihood-ratio tests were used to assess an optimal random-effects structure [<xref ref-type="bibr" rid="pone.0174910.ref048">48</xref>]. Likelihood-ratio tests were performed with the anova () function in the lme4 package. In a second step, the significance of fixed effects in the model was assessed in the following way. As the number of degrees of freedom for the t-values of the fixed effects are not exactly known with mixed-effects models, different approximations have been proposed [<xref ref-type="bibr" rid="pone.0174910.ref047">47</xref>,<xref ref-type="bibr" rid="pone.0174910.ref049">49</xref>,<xref ref-type="bibr" rid="pone.0174910.ref051">51</xref>]. However, given the large number of observations in the present study, the t-distribution converges to a normal distribution. Therefore, following standard recommendations, t-values (i.e estimate/standard error) that were larger than 2 in terms of their absolute value were considered as significant–corresponding to a significance level of 5% in a two-tailed test [<xref ref-type="bibr" rid="pone.0174910.ref047">47</xref>,<xref ref-type="bibr" rid="pone.0174910.ref052">52</xref>]. To complement this approach [<xref ref-type="bibr" rid="pone.0174910.ref053">53</xref>–<xref ref-type="bibr" rid="pone.0174910.ref055">55</xref>], we also calculated confidence intervals for the fixed-effects estimates [<xref ref-type="bibr" rid="pone.0174910.ref049">49</xref>]. All these values are reported in relevant tables. Assumptions underlying the models were visually checked with diagnostic plots of residuals [<xref ref-type="bibr" rid="pone.0174910.ref051">51</xref>,<xref ref-type="bibr" rid="pone.0174910.ref056">56</xref>].</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Procedures</title>
<p>On each trial, subjects were instructed to read the text out loud as quickly as they could without making errors and with the goal of understanding the text [<xref ref-type="bibr" rid="pone.0174910.ref057">57</xref>]. Timing started at the instant the text was displayed on the screen—this was triggered by a subject button-press. Subjects then pressed the same button (this stopped the timing and removed the text) when they had read the last word. Subjects were allowed to spell out proper nouns that they did not know and/or that they found difficult to pronounce. None of the texts was read more than once by any subject. To remind subjects that accuracy and comprehension were important, visual feedback was provided at the end of each trial to indicate the number of words that had not been read correctly. In addition, subjects had to orally answer comprehension questions asked by the experimenter every 10 texts on average. If at least one word in the text was read incorrectly, the text was judged as incorrect and excluded from statistical analysis. Reading speed was calculated in ‘‘standard-length words” per minute where each six characters counts as one standard-length word [<xref ref-type="bibr" rid="pone.0174910.ref058">58</xref>].</p>
<p>Each subject performed one training session and 8 experimental sessions (each lasting about 1 hour and performed on different days). These sessions were always performed within three consecutive weeks (except for subject TD for whom the total period was 5 weeks). The training session allowed subjects to get used a/ to reading with a scotoma and b/ to using the three visual aids. This session also allowed us to determine the location that subjects preferred in order to display the ROAV with respect to their scotoma. This was achieved by using a gaze-contingent hemi-field scotoma forcing subjects to use eccentric vision (beyond 5° eccentricity) either in the upper or lower visual hemi-field [<xref ref-type="bibr" rid="pone.0174910.ref059">59</xref>,<xref ref-type="bibr" rid="pone.0174910.ref060">60</xref>]. Ten one-line sentences were read with an upper hemi-field and ten one-line sentences were read with a lower hemi-field. After reading these sentences, subjects were asked to report their preference: results showed that all observed preferred to read with their lower visual hemi-field. The ROAV was therefore displayed for each subject below the scotoma in the experimental sessions. Each experimental session contained the three different conditions of visual aid that were run in randomly interleaved separate blocks. The number of blocks for each session was not specified in advance: subjects with high reading speeds could read more sentences within each one-hour session than slow readers.</p>
</sec>
</sec>
</sec>
<sec id="sec011" sec-type="results">
<title>3 - Results</title>
<sec id="sec012">
<title>3.1 – Implementation of the gaze-controlled system (condition 1)</title>
<p>The gaze-controlled enhanced vision system that was eventually implemented and tested in the present work can be appreciated by watching the movie in the <italic>Supporting Information</italic> (<xref ref-type="supplementary-material" rid="pone.0174910.s001">S1 Movie</xref>). It is based on the following key principles:</p>
<list list-type="order">
<list-item><p>At any moment, the area that can be potentially enhanced (here magnified) is relatively small compared to the screen: this is the Region Of Interest (ROI). The ROI is defined here as a group of adjacent letters. This definition implies some sort of figure/ground segmentation process and thus necessitates either low-level image processing and/or Optical Character Recognition. We believe that initial segmentation of an “intelligent” ROI is an essential feature of our system.</p></list-item>
<list-item><p>The ROI’s location is controlled by the subject (here through gaze) and a visual feedback (highlighting) is constantly provided as to which ROI is currently selected [<xref ref-type="bibr" rid="pone.0174910.ref033">33</xref>].</p></list-item>
<list-item><p>The visual magnification is triggered by a manual control so that subjects decide online whether or not they want to apply it. This is to allow subjects to have full control over the triggering of the visual aid and thus avoid the Midas touch problem [<xref ref-type="bibr" rid="pone.0174910.ref032">32</xref>,<xref ref-type="bibr" rid="pone.0174910.ref061">61</xref>]. The Midas touch problem is a fundamental difficulty faced by any gaze-controlled system: at any moment, the system must decide whether gaze is intended to extract visual information or to activate a specific command. Without this distinction, subjects find that everywhere they look, voluntarily or involuntarily, a new command is triggered.</p></list-item>
<list-item><p>The magnification process is also “smart” in several ways (from Figs <xref ref-type="fig" rid="pone.0174910.g004">4</xref> to <xref ref-type="fig" rid="pone.0174910.g007">7</xref>). Firstly, the ROI is not necessarily magnified as it is. Instead, a Region Of Augmented Vision (ROAV) is calculated from the ROI before the actual magnification. The magnified ROAV can thus contain a number of letters that is different from that of the ROI. The goal of this adaptation is to provide a magnified region (ROAV) containing only full words (<xref ref-type="fig" rid="pone.0174910.g004">Fig 4</xref>). Secondly, the relative location of the ROAV is adapted (depending on the proximity of the screen’s borders) so that it is always fully displayed within the screen.</p></list-item>
</list>
</sec>
<sec id="sec013">
<title>3.2 – Validation of the gaze-controlled system</title>
<p>We first assessed whether and how subjects used the possibilities offered by the three visual aids. For the first condition (gaze-contingent aid), we measured the number of times the button inducing ROAV display was pressed for each trial. We then calculated the ratio between this number and the number of standard-length words, i.e. 6 characters, [<xref ref-type="bibr" rid="pone.0174910.ref058">58</xref>] of the corresponding text. The median value across subjects was 0.45 (1st quartile: 0.26; 3rd quartile: 0.66) indicating that subjects used the aid approximately every two standard-length words. The duration of the ROAV display had a median value of 840 ms (1st quartile: 753; 3rd quartile: 1005) across subjects. The proportion of time spent with the ROAV activated had a median value of 0.33 (1st quartile: 0.15; 3rd quartile: 0.54) across subjects.</p>
<p>Then, for the second and third conditions (simulations of CCTV), we measured for each subject a histogram of the time spent for different print sizes (time was normalized with respect to total duration). From these histograms, we calculated the proportion of time spent for print sizes larger than 1.1° (i.e. larger than initial character size). Results plotted in <xref ref-type="fig" rid="pone.0174910.g009">Fig 9</xref> illustrate the dramatic difference between the two conditions. A mixed-effects analysis showed a significant difference between conditions (est = 0.26, t = 4.99, 95%CI = [0.17, 0.37]; transforming the proportions with an arcsine function did not change the pattern of results). The clear and interesting pattern is that using CCTV with reformatting (condition 3) encourages subjects to magnify text more often: in this mode, all subjects spend more than 50% of the time with a magnification level that is above the initially displayed character size. Note that the proportions reported for conditions 2 and 3 cannot be meaningfully compared with the proportions measured in condition 1 (proportion of time spent with the ROAV activated). In condition 1, proportions reflect the need to trigger the magnification enhancement which corresponds to a unique print size. In contrast, in conditions 2 and 3, subjects can use as many print sizes as they wish.</p>
<fig id="pone.0174910.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Proportion of time spent with print sizes larger than initial size (see <xref ref-type="fig" rid="pone.0174910.g008">Fig 8A</xref>) for the 10 subjects (solid lines) as a function of the two CCTV conditions (2 and 3).</title>
<p>Boxes represent mean proportion (middle thick line) and bootstrapped standard errors for each condition.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g009" xlink:type="simple"/>
</fig>
<p>At the end of the experiments, subjects were asked to give ratings for the 3 systems on a comfort scale with a number from 1 to 10 (with 1 being the least comfortable and 10 being the most comfortable). The mean rating for condition 1 was 7.2 and was not significantly different from the rating for condition 3 (CCTV with reformatting). However, mean rating for condition 2 was significantly smaller (<xref ref-type="table" rid="pone.0174910.t001">Table 1</xref>).</p>
<table-wrap id="pone.0174910.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.t001</object-id>
<label>Table 1</label> <caption><title>Results of the mixed-effects analysis for the comfort ratings.</title> <p>For each effect, the coefficient’s estimates are accompanied by 95% confidence intervals in parentheses and corresponding t-values are displayed on the next line. Reference level: condition 1 (gaze-controlled aid).</p></caption>
<alternatives>
<graphic id="pone.0174910.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="center"><italic>Dependent variable</italic>:</th>
</tr>
<tr>
<th align="left"/>
<th align="center">Comfort rating (1–10)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Intercept (cond.1)</td>
<td align="center">7.2</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(6.6, 7.8)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = 22.1</td>
</tr>
<tr>
<td align="left">Improved CCTV (cond. 2)</td>
<td align="center">-2.1</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(-3.0, -1.2)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = -4.6</td>
</tr>
<tr>
<td align="left">CCTV with reformatting (cond. 3)</td>
<td align="center">-0.5</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(-1.5, 0.4)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = -1.1</td>
</tr>
<tr>
<td align="left">Observations</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Reading speed data were then analysed with mixed-effects model. In the model with the optimal random structure, the slope of the effect of the rank of trials was random across subjects thus allowing for different individual effects of learning or fatigue [<xref ref-type="bibr" rid="pone.0174910.ref047">47</xref>]. The fixed-effects were a/ the type of visual aid, b/ the rank of trials and the interaction between the two effects. The fixed effects of this mixed-effects model are presented in <xref ref-type="table" rid="pone.0174910.t002">Table 2</xref> (left column). The most important result is that reading performance in condition 1 (the reference level) was not worse than in any of the two other conditions. It was actually significantly higher than in condition 2 (improved CCTV without reformatting) although the size of this effect (about 10%) does not seem important from a clinical perspective. And it was not distinguishable from condition 3. Another important result is that we did not find any significant interaction between the conditions and the effect of the rank of trials: the slope of the rank of trials is similar for the three conditions. These interaction effects were therefore removed from the final model (right column in <xref ref-type="table" rid="pone.0174910.t002">Table 2</xref>) inducing a higher estimate for the effect of the rank of trial (as well as slightly higher accuracy for this effect). Note also the smaller values of the goodness-of-fit indices (bottom lines of <xref ref-type="table" rid="pone.0174910.t002">Table 2</xref>) indicating better fits for the final model.</p>
<table-wrap id="pone.0174910.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.t002</object-id>
<label>Table 2</label> <caption><title>Results of the mixed-effects analyses for the fixed effects.</title> <p>For each effect, the coefficient’s estimates are accompanied by 95% confidence intervals in parentheses and corresponding t-values are displayed on the next line. First colum (1) is for the model with the optimal random structure and all the fixed effects. Second column (2) is for the final model, i.e. the same as in the first column but without interaction terms. Reference levels for the analyses are condition 1 (gaze-controlled aid) and mean rank of trials. “:” stands for interaction.</p></caption>
<alternatives>
<graphic id="pone.0174910.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="center" colspan="2"><italic>Dependent variable</italic>:</th>
</tr>
<tr>
<th align="left"/>
<th align="center" colspan="2">Reading Speed (natural log)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"/>
<td align="center">(1)</td>
<td align="center">(2)</td>
</tr>
<tr>
<td align="left">Intercept (cond. 1)</td>
<td align="center">3.7437</td>
<td align="center">3.7425</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(3.5873, 3.8996)</td>
<td align="center">(3.5862, 3.8985)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = 49.0034</td>
<td align="center">t = 48.9984</td>
</tr>
<tr>
<td align="left">Improved CCTV (cond. 2)</td>
<td align="center">-0.1160</td>
<td align="center">-0.1152</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(-0.1661, -0.0659)</td>
<td align="center">(-0.1653, -0.0650)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = -4.5368</td>
<td align="center">t = -4.5028</td>
</tr>
<tr>
<td align="left">CCTV with reformatting (cond. 3)</td>
<td align="center">-0.0064</td>
<td align="center">-0.0054</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(-0.0546, 0.0419)</td>
<td align="center">(-0.0536, 0.0429)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = -0.2585</td>
<td align="center">t = -0.2174</td>
</tr>
<tr>
<td align="left">Rank of trial</td>
<td align="center">0.0022</td>
<td align="center">0.0026</td>
</tr>
<tr>
<td align="left"/>
<td align="center">(0.0003, 0.0041)</td>
<td align="center">(0.0008, 0.0045)</td>
</tr>
<tr>
<td align="left"/>
<td align="center">t = 2.2812</td>
<td align="center">t = 2.9849</td>
</tr>
<tr>
<td align="left">C2:Rank of trial</td>
<td align="center">0.0011</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="center">(-0.0001, 0.0022)</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="center">t = 1.7735</td>
<td align="center"/>
</tr>
<tr>
<td align="left">C3:Rank of trial</td>
<td align="center">0.0004</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="center">(-0.0007, 0.0016)</td>
<td align="center"/>
</tr>
<tr>
<td align="left"/>
<td align="center">t = 0.7367</td>
<td align="center"/>
</tr>
<tr>
<td align="left">Observations</td>
<td align="center">1165</td>
<td align="center">1165</td>
</tr>
<tr>
<td align="left">Log Likelihood</td>
<td align="center">-478.6683</td>
<td align="center">-467.0893</td>
</tr>
<tr>
<td align="left">Akaike Inf. Crit.</td>
<td align="center">977.3366</td>
<td align="center">950.1786</td>
</tr>
<tr>
<td align="left">Bayesian Inf. Crit.</td>
<td align="center">1027.9410</td>
<td align="center">990.6624</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Reading speed data for each trial are shown with symbols in <xref ref-type="fig" rid="pone.0174910.g010">Fig 10</xref> for the subject with the highest intercept value (subject 'CHAR'): reading speed is plotted as a function of the rank of trials and for the 3 conditions. The fixed-effects from the final mixed-effects model (right column in <xref ref-type="table" rid="pone.0174910.t002">Table 2</xref>), which represent the effects at the population level, are represented in <xref ref-type="fig" rid="pone.0174910.g010">Fig 10</xref> with dashed lines. The estimated random effects for this subject (i.e. the conditional means) are shown with solid lines. They are above the fixed-effects lines and their slopes show that this subject had a moderate learning effect over the 9 hours of experiments when compared with the population effect. The reading speed values observed at the end of the experiment are close to 80 words per minute, a high value that can be considered as indicating “fluent” reading for low vision readers [<xref ref-type="bibr" rid="pone.0174910.ref017">17</xref>].</p>
<fig id="pone.0174910.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Results for subject ‘CHAR’ who had the highest reading speed mean.</title>
<p>Symbols show reading speed (note the natural log scale) as a function of the rank of trials and for the 3 conditions (condition 1: black; condition2: red; condition 3: green). Fixed-effects are shown with dashed lines whereas the estimated random effects for this subject (i.e. the conditional means) are shown with solid lines. For visual clarity, an artificial vertical jitter was added between the lines of conditions 1 and 3 to avoid overlapping.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g010" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pone.0174910.g011">Fig 11</xref> offers a graphical summary of all individual random effects (conditional means) estimated from the final mixed-effects model with the same color codes as in <xref ref-type="fig" rid="pone.0174910.g010">Fig 10</xref>. The subject with highest reading speed (“CHAR”) is shown in the top left plot. The other plots are ordered in decreasing order based on the individual intercept reading speeds (from top left to bottom right). In contrast to subject “CHAR”, most subjects have a low reading performance which corresponds to a “spot reading level” [<xref ref-type="bibr" rid="pone.0174910.ref017">17</xref>]. All subjects, except one (“TD”), have estimated random effects with positive slopes indicating overall significant learning. One subject (“MAS”) shows an impressive increase of reading speed by a factor close to 4. At the population level, the fixed effect of the rank of trial has a slope indicating a 30% increase in reading speed over 100 trials.</p>
<fig id="pone.0174910.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0174910.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Fixed-effects and random effects from the final mixed-effects model for all subjects.</title>
<p>Characteristics and layout of this figure are the same as in <xref ref-type="fig" rid="pone.0174910.g010">Fig 10</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.g011" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>4 - Discussion</title>
<p>This proof-of-concept study aimed at evaluating the feasibility of a gaze-controlled visual aid specifically designed for people reading with Central Field Loss (mostly AMD patients). In the present work, Central Field Loss was artificially induced in normally-sighted subjects with a gaze-contingent simulated scotoma (size: 10°). The key principles underlying this new aid are summarized in a flowchart in <xref ref-type="fig" rid="pone.0174910.g001">Fig 1</xref> and were implemented in a standard computer.</p>
<p>The effective use of this system by patients with CFL relies on one main assumption. Patients should be able to use a Preferred Retinal Locus (PRL) in order to fixate a static target [<xref ref-type="bibr" rid="pone.0174910.ref062">62</xref>,<xref ref-type="bibr" rid="pone.0174910.ref063">63</xref>]. This is necessary to allow patients to correctly perform the calibration of the eyetracker at the beginning of experiments (calibration consists in successively fixating static dots scattered across the monitor). Most patients develop such a “fixation”PRL with different time scales [<xref ref-type="bibr" rid="pone.0174910.ref064">64</xref>]. Note that it is still debated whether patients only use this “fixation” PRL or if they use different PRLs when they read text [<xref ref-type="bibr" rid="pone.0174910.ref065">65</xref>–<xref ref-type="bibr" rid="pone.0174910.ref067">67</xref>]. This unsettled issue is not a problem for our system as subjects can explore the ROAV with several eye movements and use one or several PRLs as they wish.</p>
<p>Thus, the main open question which should be a topic for future research concerns the most optimal ways of controlling the ROI with gaze. Research should also establish whether patients should be allowed to choose which kind of gaze/ROI link they prefer. In the present implementation of our system, we chose to use the scotoma’s location to control the ROI because our normally-sigted subjects reported in preliminary experiments that this was the most comfortable option. However, it is possible that this might be different with patients who have used a PRL for a long time. They might possibly prefer to use their “fixation” PRL in order to control the ROI during the reading process. This question is currently investigated in our team.</p>
<p>Our gaze-contingent enhanced vision system is inspired by some important features that have been previously proposed for normally-sighted subjects (e.g. the ‘magic’ or ‘smart’ lens concept), mainly in the human-machine interface literature in the context of zoomable user interfaces (ZUI) with or without gaze control [<xref ref-type="bibr" rid="pone.0174910.ref031">31</xref>–<xref ref-type="bibr" rid="pone.0174910.ref033">33</xref>,<xref ref-type="bibr" rid="pone.0174910.ref068">68</xref>–<xref ref-type="bibr" rid="pone.0174910.ref074">74</xref>]. The idea that gaze-contingent visual enhancement might be used specifically to aid subjects with scotomas has already been proposed [<xref ref-type="bibr" rid="pone.0174910.ref075">75</xref>–<xref ref-type="bibr" rid="pone.0174910.ref079">79</xref>]. The main idea in the proposed algorithms was a “remapping” process that was able to continuously warp and redistribute information being hidden by the scotoma to the still functioning parts of the retina. However, testing these algorithms with three patients having CFL in a reading task produced disappointing results [<xref ref-type="bibr" rid="pone.0174910.ref076">76</xref>]. Informal observation of these "continuous remapping" algorithms in our laboratory suggested to us that the main problem relied on the locations of words that were constantly changing on the screen as the eyes moved, whether these movements were voluntary or not. Subjects reported that words were continuously jumping around so that it was very difficult to integrate information across successive fixations, especially when they tried to fixate a single word. This continuous gaze-induced remapping does not occur in our system as any ROAV (once displayed by a button press) is fixed on the screen. The ROAV thus remains motionless on the screen, whether the eyes move or not, until subjects release the button.</p>
<p>In summary, the development of our gaze-controlled system was guided by both successes and failures of previous studies. Our main goal was to build a system allowing subjects with CFL to alternate easily between a global view of the text and a magnified view of words [<xref ref-type="bibr" rid="pone.0174910.ref028">28</xref>]. Importantly, even during magnification of words (i.e. ROAV display), a significant global view of the text was preserved, thus facilitating navigation in the page [eg. <xref ref-type="bibr" rid="pone.0174910.ref023">23</xref>–<xref ref-type="bibr" rid="pone.0174910.ref025">25</xref>]. In addition, this ROAV was fixed on the screen until its perceptual identification was achieved i.e. until the subject released the button.</p>
<p>This system (condition 1) was compared with two other systems (conditions 2 and 3) whose principles were based on commercially available CCTVs and implemented on the same computer as in condition 1. In the CCTV-like conditions (2 and 3), it was possible to alternate between global presentation of the text and magnification of the whole text (<xref ref-type="fig" rid="pone.0174910.g008">Fig 8</xref>). However, it was impossible to obtain the simultaneous view of global and locally-magnified information as offered in condition 1.</p>
<p>The first important result is that subjects did often alternate between the global and local magnification views offered in the gaze-controlled condition. This is not a trivial result because allowing subjects to modify magnification during reading, even with a user-friendly interface, does not guarantee that they will exploit this possibility. It seems therefore that subjects did not find this possibility either too cumbersome or not helpful. This was also true in the two CCTV-like conditions (2 and 3) with an additional interesting result illustrated in <xref ref-type="fig" rid="pone.0174910.g009">Fig 9</xref>. On average, subjects spent much more time reading with large magnification levels in condition 3 (CCTV with reformatting) than in condition 2 where reformatting was absent (<xref ref-type="fig" rid="pone.0174910.g008">Fig 8</xref>). It seems therefore that reading text with all successive words present on adjacent lines is much preferred by subjects, presumably because it significantly reduces the page navigation problem.</p>
<p>This preference for the reformatting mode (cond. 3) is however not accompanied by a difference in reading speed thus suggesting that the preference is related to reading comfort. This is consistent with the comfort ratings showing that conditions 1 and 3 were rated equally whereas condition 2 was rated with a significantly smaller grade (<xref ref-type="table" rid="pone.0174910.t001">Table 1</xref>). It would be interesting to test in future research if this kind of preference would be reflected by more psychological constructs such as motivation to read or by measures such as productivity, i.e. the time during which subjects manage to read continuously. This kind of productivity difference was observed in a study where only 4.5% of subjects using an optical device were able to read continuously for 40 minutes, while 59.1% of the subjects using handheld CCTVs and 72.7% of the subjects using stand-mounted CCTVs were able to read the full 40 minutes by the end of training [<xref ref-type="bibr" rid="pone.0174910.ref080">80</xref>]. A final important note concerning whether subjects used the magnification modifications is that we made every effort to ensure that these modifications were as user-friendly as possible in the two CCTV-like conditions. Our goal was conservative in that we did not want to create a disadvantage that might have been induced by a poor human-machine interface (cf. the inconvenient placement of the knobs that control magnification in several commercial CCTV systems).</p>
<p>In terms of reading speed, our results show a modest advantage (about 10%) for the gaze-controlled system with respect to the improved CCTV (condition 2) and no difference when compared with the CCTV with reformatting system (condition 3). This result is very encouraging essentially because it shows that the gaze-controlled system fares well with the two other conditions which are considered as the most advanced commercial EVES. In this respect, the absence of interaction between the conditions and the effect of the rank of trials is also important as it shows that learning in condition 1 does not present any specific problems compared to the two CCTV-like conditions.</p>
<p>These encouraging results suggest that the principles implemented in condition 1 have the potential to be improved and extended in different directions. Several features might be considered. In the present study, the enhancement was simply a magnification with a constant level. However, it would probably be helpful to add the possibility of letting subjects use different levels of magnification (up to screen’s size) while the ROAV is displayed. In the case of large levels of magnification, another option to be investigated would be the possibility to adapt the size and format of the ROAV to the size and shape of the display. For instance, with a very large monitor, it would be interesting to study if displaying an ROAV containing two or three lines of text is more efficient than using a single line. And even more sophisticated enhancements might be added. For instance, digital filtering tailored to low vision constraints might be applied within the ROAV [<xref ref-type="bibr" rid="pone.0174910.ref081">81</xref>]. Some low-level visual modifications could easily be implemented within the ROAV with the goal of reducing crowding [<xref ref-type="bibr" rid="pone.0174910.ref082">82</xref>]. For instance, a smooth transition between the ROI and the ROAV might be used instead of an abrupt displacement, which could potentially reduce crowding [<xref ref-type="bibr" rid="pone.0174910.ref083">83</xref>]. Even higher-level modifications induced by automatic text simplification might also be envisaged [<xref ref-type="bibr" rid="pone.0174910.ref029">29</xref>,<xref ref-type="bibr" rid="pone.0174910.ref084">84</xref>,<xref ref-type="bibr" rid="pone.0174910.ref085">85</xref>]: thus, some complex words within an ROAV might be replaced by lower complexity synonyms. The possibilities offered by digital image processing combined with text processing (once OCR has been performed) are actually endless and should be guided by theoretical results concerning our knowledge of limiting factors in low vision reading [<xref ref-type="bibr" rid="pone.0174910.ref015">15</xref>]. In sum, we believe that our condition 1 offers a basic algorithm that could be improved in several ways in order to increase perceptual stability, comfort and overall reading performance.</p>
<p>In addition, the ideas underlying condition 1 might be implemented in very different kinds of setups. For instance, if patients want to use a CCTV-like system, i.e. at a relatively short viewing distance, then gaze-control could be achieved with a remote eyetracker integrated within the CCTV. This kind of setup would remove the constraint of wearing special glasses or helmets that include an eyetracker. Ideally, helpful options already present on CCTVs thanks to text digitalization, such as text reformatting (cf. condition 3), should be combined with our system. Another example concerns the use of new fonts able to improve reading performance [<xref ref-type="bibr" rid="pone.0174910.ref086">86</xref>]. The huge potential of EVES is precisely the ability to additively combine several helpful sources whose benefits are modest when taken individually. Another interesting option with a short viewing distance is that gaze-control could be replaced by a haptic interface. Patients could then select ROIs by pointing at some locations on a touch screen. This could be implemented for instance on tablet computers or e-books readers [<xref ref-type="bibr" rid="pone.0174910.ref087">87</xref>]. Apart from the interface difference (gaze vs. touch), all other features of condition 1 would remain the same. It is difficult to predict if this option would be found comfortable by patients as this would imply many hand pointing movements, but this is an option that would be technically easier to implement.</p>
<p>In addition, it would seem promising to implement the gaze-controlled system in see-through glasses [<xref ref-type="bibr" rid="pone.0174910.ref035">35</xref>]. One of the most promising and challenging future uses of head-mounted displays is in applications in which virtual environments enhance rather than replace real environments [<xref ref-type="bibr" rid="pone.0174910.ref034">34</xref>]. This is referred to as augmented or enhanced reality [<xref ref-type="bibr" rid="pone.0174910.ref088">88</xref>,<xref ref-type="bibr" rid="pone.0174910.ref089">89</xref>]. Convincing evidence suggests that augmented reality has a huge potential to help low vision patients [<xref ref-type="bibr" rid="pone.0174910.ref036">36</xref>,<xref ref-type="bibr" rid="pone.0174910.ref090">90</xref>–<xref ref-type="bibr" rid="pone.0174910.ref093">93</xref>]. In this kind of setup, an important asset of gaze control is that subjects can interact with distant displays (signs in a street or large screens at home) even though using a mouse is not possible [<xref ref-type="bibr" rid="pone.0174910.ref031">31</xref>,<xref ref-type="bibr" rid="pone.0174910.ref032">32</xref>].</p>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>5 - Conclusion</title>
<p>Future research should establish whether low vision patients can learn to efficiently use a gaze-controlled system based on the principles developed in condition 1. Reasons to be optimistic about adaptation abilities of patients rely on converging evidence that perceptual learning processes are still functional with Central Field Loss reading [<xref ref-type="bibr" rid="pone.0174910.ref094">94</xref>–<xref ref-type="bibr" rid="pone.0174910.ref097">97</xref>]. In addition, there is evidence that cortical reorganization processes are active in low vision patients following long-term adaptation to scotomas [<xref ref-type="bibr" rid="pone.0174910.ref098">98</xref>].</p>
</sec>
<sec id="sec016">
<title>Supporting information</title>
<supplementary-material id="pone.0174910.s001" mimetype="video/mp4" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.s001" xlink:type="simple">
<label>S1 Movie</label>
<caption>
<title>Example movie of the gaze-controlled visual aid (condition 1).</title>
<p>(MP4)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0174910.s002" mimetype="video/mp4" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.s002" xlink:type="simple">
<label>S2 Movie</label>
<caption>
<title>Example movie of the improved CCTV (condition 2).</title>
<p>(MP4)</p>
</caption>
</supplementary-material>
<supplementary-material id="pone.0174910.s003" mimetype="video/mp4" position="float" xlink:href="info:doi/10.1371/journal.pone.0174910.s003" xlink:type="simple">
<label>S3 Movie</label>
<caption>
<title>Example movie of the CCTV with reformatting (condition 3).</title>
<p>(MP4)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Anne-Catherine Scherlen and Thierry Villette for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0174910.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neelam</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nolan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chakravarthy</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Beatty</surname> <given-names>S</given-names></name>. <article-title>Psychophysical Function in Age-related Maculopathy</article-title>. <source>Surv Ophthalmol</source>. <year>2009</year>;<volume>54</volume>: <fpage>167</fpage>–<lpage>210</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.survophthal.2008.12.003" xlink:type="simple">10.1016/j.survophthal.2008.12.003</ext-link></comment> <object-id pub-id-type="pmid">19298899</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Measuring reading performance</article-title>. <source>Vision Res</source>. <year>2013</year>;<volume>90</volume>: <fpage>43</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2013.02.015" xlink:type="simple">10.1016/j.visres.2013.02.015</ext-link></comment> <object-id pub-id-type="pmid">23506967</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Vision rehabilitation for patients with age-related macular degeneration</article-title>. <source>Eye</source>. <year>2001</year>;<volume>15</volume>: <fpage>430</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/eye.2001.148" xlink:type="simple">10.1038/eye.2001.148</ext-link></comment> <object-id pub-id-type="pmid">11450769</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bernard</surname> <given-names>J-B</given-names></name>, <name name-style="western"><surname>Arunkumar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>. <article-title>Can reading-specific training stimuli improve the effect of perceptual learning on peripheral reading speed?</article-title> <source>Vision Res</source>. <year>2012</year>;<volume>66</volume>: <fpage>17</fpage>–<lpage>25</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2012.06.012" xlink:type="simple">10.1016/j.visres.2012.06.012</ext-link></comment> <object-id pub-id-type="pmid">22750053</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrèse</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bernard</surname> <given-names>J-B</given-names></name>, <name name-style="western"><surname>Faure</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hoffart</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>Eye movements and reading speed in macular disease: the shrinking perceptual span hypothesis requires and is supported by a mediation analysis</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2014</year>;<volume>55</volume>: <fpage>3638</fpage>–<lpage>3645</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.13-13408" xlink:type="simple">10.1167/iovs.13-13408</ext-link></comment> <object-id pub-id-type="pmid">24833746</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrèse</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bernard</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Hoffart</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Faure</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barouch</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Conrath</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Wet versus dry age-related macular degeneration in patients with central field loss: different effects on maximum reading speed</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2011</year>;<volume>52</volume>: <fpage>2417</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.09-5056" xlink:type="simple">10.1167/iovs.09-5056</ext-link></comment> <object-id pub-id-type="pmid">21228374</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrèse</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bernard</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Hoffart</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Faure</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barouch</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Conrath</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Small effect of interline spacing on maximal reading speed in low-vision patients with central field loss irrespective of scotoma size</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2010</year>;<volume>51</volume>: <fpage>1247</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.09-3682" xlink:type="simple">10.1167/iovs.09-3682</ext-link></comment> <object-id pub-id-type="pmid">19834038</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>ST</given-names></name>. <article-title>The effect of letter spacing on reading speed in central and peripheral vision</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2002</year>;<volume>43</volume>: <fpage>1270</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">11923275</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>, <name name-style="western"><surname>Jarvis</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Woo</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Hanson</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Jose</surname> <given-names>RT</given-names></name>. <article-title>Reading Speed Does Not Benefit from Increased Line Spacing in AMD Patients</article-title>. <source>Optom Vis Sci Off Publ Am Acad Optom</source>. <year>2008</year>;<volume>85</volume>: <fpage>827</fpage>–<lpage>833</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dickinson</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Fotinakis</surname> <given-names>V</given-names></name>. <article-title>The limitations imposed on reading by low vision aids</article-title>. <source>Optom Vis Sci</source>. <year>2000</year>;<volume>77</volume>: <fpage>364</fpage>–<lpage>72</lpage>. <object-id pub-id-type="pmid">10939314</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nguyen</surname> <given-names>NX</given-names></name>, <name name-style="western"><surname>Weismann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Trauzettel-Klosinski</surname> <given-names>S</given-names></name>. <article-title>Improvement of reading speed after providing of low vision aids in patients with age-related macular degeneration</article-title>. <source>Acta Ophthalmol</source>. <year>2009</year>;<volume>87</volume>: <fpage>849</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1755-3768.2008.01423.x" xlink:type="simple">10.1111/j.1755-3768.2008.01423.x</ext-link></comment> <object-id pub-id-type="pmid">19141148</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seiple</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Szlyk</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>McMahon</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Pulido</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fishman</surname> <given-names>GA</given-names></name>. <article-title>Eye-movement training for reading in patients with age-related macular degeneration</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2005</year>;<volume>46</volume>: <fpage>2886</fpage>–<lpage>96</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.04-1296" xlink:type="simple">10.1167/iovs.04-1296</ext-link></comment> <object-id pub-id-type="pmid">16043863</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tarita-Nistor</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Brent</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Steinbach</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Markowitz</surname> <given-names>SN</given-names></name>, <name name-style="western"><surname>González</surname> <given-names>EG</given-names></name>. <article-title>Reading training with threshold stimuli in people with central vision loss: a feasibility study</article-title>. <source>Optom Vis Sci Off Publ Am Acad Optom</source>. <year>2014</year>;<volume>91</volume>: <fpage>86</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elliott</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Trukolo-Ilic</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Strong</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Pace</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Plotkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bevers</surname> <given-names>P</given-names></name>. <article-title>Demographic characteristics of the vision-disabled elderly</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>1997</year>;<volume>38</volume>: <fpage>2566</fpage>–<lpage>2575</lpage>. <object-id pub-id-type="pmid">9375576</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref015"><label>15</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Legge</surname> <given-names>GB</given-names></name>. <source>Psychophysics of Reading in Normal and Low Vision</source>. <publisher-loc>Mahwah, New Jersey, London</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lovie-Kitchin</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Whittaker</surname> <given-names>SG</given-names></name>. <article-title>Prescribing near magnification for low vision patients</article-title>. <source>Clin Exp Optom</source>. <year>1999</year>;<volume>82</volume>: <fpage>214</fpage>–<lpage>224</lpage>. <object-id pub-id-type="pmid">12482267</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Whittaker</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Lovie-Kitchin</surname> <given-names>J</given-names></name>. <article-title>Visual requirements for reading</article-title>. <source>Optom Vis Sci</source>. <year>1993</year>;<volume>70</volume>: <fpage>54</fpage>–<lpage>65</lpage>. <object-id pub-id-type="pmid">8430009</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Mansfield</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>. <article-title>Psychophysics of reading. XVIII. The effect of print size on reading speed in normal peripheral vision</article-title>. <source>Vis Res</source>. <year>1998</year>;<volume>38</volume>: <fpage>2949</fpage>–<lpage>62</lpage>. <object-id pub-id-type="pmid">9797990</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peterson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Wolffsohn</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Rubinstein</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lowe</surname> <given-names>J</given-names></name>. <article-title>Benefits of electronic vision enhancement systems (EVES) for the visually impaired</article-title>. <source>Am J Ophthalmol</source>. <year>2003</year>;<volume>136</volume>: <fpage>1129</fpage>–<lpage>1135</lpage>. <object-id pub-id-type="pmid">14644225</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolffsohn</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Peterson</surname> <given-names>RC</given-names></name>. <article-title>A review of current knowledge on Electronic Vision Enhancement Systems for the visually impaired</article-title>. <source>Ophthalmic Physiol Opt</source>. <year>2003</year>;<volume>23</volume>: <fpage>35</fpage>–<lpage>42</lpage>. <object-id pub-id-type="pmid">12535055</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wiecek</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Jackson</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Dakin</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Bex</surname> <given-names>P</given-names></name>. <article-title>Visual search with image modification in age-related macular degeneration</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2012</year>;<volume>53</volume>: <fpage>6600</fpage>–<lpage>6609</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.12-10012" xlink:type="simple">10.1167/iovs.12-10012</ext-link></comment> <object-id pub-id-type="pmid">22930725</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woods</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Satgunam</surname> <given-names>P</given-names></name>. <article-title>Television, computer and portable display device use by people with central vision impairment</article-title>. <source>Ophthalmic Physiol Opt J Br Coll Ophthalmic Opt Optom</source>. <year>2011</year>;<volume>31</volume>: <fpage>258</fpage>–<lpage>274</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beckmann</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>. <article-title>Psychophysics of reading—XIV. The page navigation problem in using magnifiers</article-title>. <source>Vis Res</source>. <year>1996</year>;<volume>36</volume>: <fpage>3723</fpage>–<lpage>33</lpage>. <object-id pub-id-type="pmid">8977002</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harland</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Luebker</surname> <given-names>A</given-names></name>. <article-title>Psychophysics of reading. XVII. Low-vision performance with four types of electronically magnified text</article-title>. <source>Optom Vis Sci</source>. <year>1998</year>;<volume>75</volume>: <fpage>183</fpage>–<lpage>90</lpage>. <object-id pub-id-type="pmid">9547799</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ortiz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Jobling</surname> <given-names>JT</given-names></name>. <article-title>Reading with a head-mounted video magnifier</article-title>. <source>Optom Vis Sci Off Publ Am Acad Optom</source>. <year>1999</year>;<volume>76</volume>: <fpage>755</fpage>–<lpage>763</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burggraaff</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>van Nispen</surname> <given-names>RMA</given-names></name>, <name name-style="western"><surname>Hoeben</surname> <given-names>FP</given-names></name>, <name name-style="western"><surname>Knol</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>van Rens</surname> <given-names>GHMB</given-names></name>. <article-title>Randomized Controlled Trial on the Effects of Training in the Use of Closed-Circuit Television on Reading Performance</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2012</year>;<volume>53</volume>: <fpage>2142</fpage>–<lpage>2150</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.11-8407" xlink:type="simple">10.1167/iovs.11-8407</ext-link></comment> <object-id pub-id-type="pmid">22427558</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burggraaff</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>van Nispen</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Melis-Dankers</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>van Rens</surname> <given-names>GH</given-names></name>. <article-title>Effects of standard training in the use of closed-circuit televisions in visually impaired adults: design of a training protocol and a randomized controlled trial</article-title>. <source>BMC Health Serv Res</source>. <year>2010</year>;<volume>10</volume>: <fpage>62</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1472-6963-10-62" xlink:type="simple">10.1186/1472-6963-10-62</ext-link></comment> <object-id pub-id-type="pmid">20219120</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Culham</surname> <given-names>LE</given-names></name>, <name name-style="western"><surname>Chabra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Clinical performance of electronic, head-mounted, low-vision devices</article-title>. <source>Ophthalmic Physiol Opt</source>. <year>2004</year>;<volume>24</volume>: <fpage>281</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1475-1313.2004.00193.x" xlink:type="simple">10.1111/j.1475-1313.2004.00193.x</ext-link></comment> <object-id pub-id-type="pmid">15228505</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrèse</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bernard</surname> <given-names>J-B</given-names></name>, <name name-style="western"><surname>Faure</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hoffart</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>Clustering of Eye Fixations: A New Oculomotor Determinant of Reading Speed in Maculopathy</article-title>. <source>Investig Opthalmology Vis Sci</source>. <year>2016</year>;<volume>57</volume>: <fpage>3192</fpage>–<lpage>3202</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mele</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Federici</surname> <given-names>S</given-names></name>. <article-title>A psychotechnological review on eye-tracking systems: towards user experience</article-title>. <source>Disabil Rehabil Assist Technol</source>. <year>2012</year>;<volume>7</volume>: <fpage>261</fpage>–<lpage>281</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3109/17483107.2011.635326" xlink:type="simple">10.3109/17483107.2011.635326</ext-link></comment> <object-id pub-id-type="pmid">22117604</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref031"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Stellmach S, Stober S, Nürnberger A, Dachselt R. Designing Gaze-supported Multimodal Interactions for the Exploration of Large Image Collections. Proceedings of the 1st Conference on Novel Gaze-Controlled Applications. New York, NY, USA: ACM; 2011. p. 1:1–1:8.</mixed-citation></ref>
<ref id="pone.0174910.ref032"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Stellmach S, Dachselt R. Investigating Gaze-supported Multimodal Pan and Zoom. Proceedings of the Symposium on Eye Tracking Research and Applications. New York, NY, USA: ACM; 2012. pp. 357–360.</mixed-citation></ref>
<ref id="pone.0174910.ref033"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Zhai S, Morimoto C, Ihde S. Manual and Gaze Input Cascaded (MAGIC) Pointing. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. New York, NY, USA: ACM; 1999. pp. 246–253.</mixed-citation></ref>
<ref id="pone.0174910.ref034"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Bajura M, Fuchs H, Ohbuchi R. Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient. Proceedings of the 19th Annual Conference on Computer Graphics and Interactive Techniques. New York, NY, USA: ACM; 1992. pp. 203–210.</mixed-citation></ref>
<ref id="pone.0174910.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rolland</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Fuchs</surname> <given-names>H</given-names></name>. <article-title>Optical Versus Video See-Through Head-Mounted Displays</article-title>. in <source>Medical Visualization Presence: Teleoperators and Virtual Environments</source>. <year>2000</year>. pp. <fpage>287</fpage>–<lpage>309</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hicks</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Muhammed</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Worsfold</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Downes</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Kennard</surname> <given-names>C</given-names></name>. <article-title>A Depth-Based Head-Mounted Visual Display to Aid Navigation in Partially Sighted Individuals</article-title>. <source>PLoS ONE</source>. <year>2013</year>;<volume>8</volume>: <fpage>e67695</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0067695" xlink:type="simple">10.1371/journal.pone.0067695</ext-link></comment> <object-id pub-id-type="pmid">23844067</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crossland</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Eye movements and reading in macular disease: Further support for the shrinking perceptual span hypothesis</article-title>. <source>Vis Res</source>. <year>2006</year>;<volume>46</volume>: <fpage>590</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2005.05.015" xlink:type="simple">10.1016/j.visres.2005.05.015</ext-link></comment> <object-id pub-id-type="pmid">16005930</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abdelnour</surname> <given-names>OLA</given-names></name>, <name name-style="western"><surname>Kalloniatis</surname> <given-names>M</given-names></name>. <article-title>Word Acuity Threshold as a Function of Contrast and Retinal Eccentricity</article-title>. <source>Optom Vis Sci</source>. <year>2001</year>;<volume>78</volume>: <fpage>914</fpage>–<lpage>919</lpage>. <object-id pub-id-type="pmid">11780669</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Bigelow</surname> <given-names>CA</given-names></name>. <article-title>Does print size matter for reading? A review of findings from vision science and typography</article-title>. <source>J Vis</source>. <year>2011</year>;<volume>11</volume>: <fpage>1</fpage>–<lpage>22</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peirce</surname> <given-names>J</given-names></name>. <article-title>Generating stimuli for neuroscience using PsychoPy</article-title>. <source>Front Neuroinformatics</source>. <year>2009</year>;<volume>2</volume>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.frontiersin.org/neuroscience/neuroinformatics/paper/10.3389/neuro.11/010.2008/" xlink:type="simple">http://www.frontiersin.org/neuroscience/neuroinformatics/paper/10.3389/neuro.11/010.2008/</ext-link></mixed-citation></ref>
<ref id="pone.0174910.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peirce</surname> <given-names>JW</given-names></name>. <article-title>PsychoPy—Psychophysics software in Python</article-title>. <source>J Neurosci Methods</source>. <year>2007</year>;<volume>162</volume>: <fpage>8</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2006.11.017" xlink:type="simple">10.1016/j.jneumeth.2006.11.017</ext-link></comment> <object-id pub-id-type="pmid">17254636</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bernard</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Scherlen</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>Page mode reading with simulated scotomas: A modest effect of interline spacing on reading speed</article-title>. <source>Vis Res</source>. <year>2007</year>;<volume>47</volume>: <fpage>3447</fpage>–<lpage>59</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2007.10.005" xlink:type="simple">10.1016/j.visres.2007.10.005</ext-link></comment> <object-id pub-id-type="pmid">18053849</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scherlen</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Bernard</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Calabrèse</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>Page mode reading with simulated scotomas: oculo-motor patterns</article-title>. <source>Vis Res</source>. <year>2008</year>;<volume>48</volume>: <fpage>1870</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2008.06.005" xlink:type="simple">10.1016/j.visres.2008.06.005</ext-link></comment> <object-id pub-id-type="pmid">18601944</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aguilar</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>Gaze-contingent simulation of retinopathy: some potential pitfalls and remedies</article-title>. <source>Vis Res</source>. <year>2011</year>;<volume>51</volume>: <fpage>997</fpage>–<lpage>1012</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2011.02.010" xlink:type="simple">10.1016/j.visres.2011.02.010</ext-link></comment> <object-id pub-id-type="pmid">21335024</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Han</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Saunders</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Woods</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Luo</surname> <given-names>G</given-names></name>. <article-title>Trajectory prediction of saccadic eye movements using a compressed exponential model</article-title>. <source>J Vis</source>. <year>2013</year>;<volume>13</volume>.</mixed-citation></ref>
<ref id="pone.0174910.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saunders</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Woods</surname> <given-names>RL</given-names></name>. <article-title>Direct measurement of the system latency of gaze-contingent displays</article-title>. <source>Behav Res Methods</source>. <year>2013</year>; <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baayen</surname> <given-names>RH</given-names></name>. <article-title>Mixed-effects modeling with crossed random effects for subjects and items</article-title>. <source>J Mem Lang</source>. <year>2008</year>;<volume>59</volume>: <fpage>390</fpage>–<lpage>412</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zuur</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Ieno</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Elphick</surname> <given-names>CS</given-names></name>. <article-title>A protocol for data exploration to avoid common statistical problems</article-title>. <source>Methods Ecol Evol</source>. <year>2010</year>;<volume>1</volume>: <fpage>3</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bates</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mächler</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bolker</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Walker</surname> <given-names>S</given-names></name>. <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>J Stat Softw</source>. <year>2015</year>;<volume>67</volume>: <fpage>1</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref050"><label>50</label><mixed-citation publication-type="book" xlink:type="simple"><collab>R Core Team</collab>. <source>R: A Language and Environment for Statistical Computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name> [Internet]. <publisher-loc>Vienna, Austria</publisher-loc>; <year>2016</year>. <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org" xlink:type="simple">http://www.R-project.org</ext-link></mixed-citation></ref>
<ref id="pone.0174910.ref051"><label>51</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Pinheiro</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Bates</surname> <given-names>DM</given-names></name>. <source>Mixed-effects models in S and S-Plus</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2000</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref052"><label>52</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Gelman</surname> <given-names>a</given-names></name>, <name name-style="western"><surname>Hill</surname> <given-names>J</given-names></name>. <source>Data analysis using regression and multilevel/hierarchical models</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cumming</surname> <given-names>G</given-names></name>. <article-title>The New Statistics Why and How</article-title>. <source>Psychol Sci</source>. <year>2014</year>;<volume>25</volume>: <fpage>7</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797613504966" xlink:type="simple">10.1177/0956797613504966</ext-link></comment> <object-id pub-id-type="pmid">24220629</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakagawa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cuthill</surname> <given-names>IC</given-names></name>. <article-title>Effect size, confidence interval and statistical significance: a practical guide for biologists</article-title>. <source>Biol Rev</source>. <year>2007</year>;<volume>82</volume>: <fpage>591</fpage>–<lpage>605</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1469-185X.2007.00027.x" xlink:type="simple">10.1111/j.1469-185X.2007.00027.x</ext-link></comment> <object-id pub-id-type="pmid">17944619</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wasserstein</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Lazar</surname> <given-names>NA</given-names></name>. <article-title>The ASA’s statement on p-values: context, process, and purpose</article-title>. <source>Am Stat</source>. <year>2016</year>; <fpage>00</fpage>–<lpage>00</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref056"><label>56</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>West</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Aiken</surname> <given-names>LS</given-names></name>. <source>Applied multiple regression/correlation analysis for the behavioral sciences. third</source>. <publisher-loc>Mahwah, New Jersey</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>; <year>2003</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fine</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>. <article-title>The role of context in reading with central field loss</article-title>. <source>Optom Vis Sci</source>. <year>1996</year>;<volume>73</volume>: <fpage>533</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">8869984</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref058"><label>58</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Carver</surname> <given-names>RP</given-names></name>. <source>Reading rate: a review of research and theory</source>. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>1990</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fine</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Reading with simulated scotomas: attending to the right is better than attending to the left</article-title>. <source>Vis Res</source>. <year>1999</year>;<volume>39</volume>: <fpage>1039</fpage>–<lpage>48</lpage>. <object-id pub-id-type="pmid">10341954</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petre</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Hazel</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Fine</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>GS</given-names></name>. <article-title>Reading with eccentric fixation is faster in inferior visual field than in left visual field</article-title>. <source>Optom Vis Sci</source>. <year>2000</year>;<volume>77</volume>: <fpage>34</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">10654856</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Velichkovsky</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Rumyantsev</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Morozov</surname> <given-names>MA</given-names></name>. <article-title>New Solution to the Midas Touch Problem: Identification of Visual Commands Via Extraction of Focal Fixations</article-title>. <source>Procedia Comput Sci</source>. <year>2014</year>;<volume>39</volume>: <fpage>75</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crossland</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>. <article-title>The preferred retinal locus in macular disease: toward a consensus definition</article-title>. <source>Retina Phila Pa</source>. <year>2011</year>;<volume>31</volume>: <fpage>2109</fpage>–<lpage>2114</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cummings</surname> <given-names>RW</given-names></name>, <name name-style="western"><surname>Whittaker</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Watson</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Budd</surname> <given-names>JM</given-names></name>. <article-title>Scanning characters and reading with a central scotoma</article-title>. <source>Am J Optom Physiol Opt</source>. <year>1985</year>;<volume>62</volume>: <fpage>833</fpage>–<lpage>43</lpage>. <object-id pub-id-type="pmid">4083327</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheung</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>. <article-title>Functional and cortical adaptations to central vision loss</article-title>. <source>Vis Neurosci</source>. <year>2005</year>;<volume>22</volume>: <fpage>187</fpage>–<lpage>201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523805222071" xlink:type="simple">10.1017/S0952523805222071</ext-link></comment> <object-id pub-id-type="pmid">15935111</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Timberlake</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Sharma</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Grose</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Maino</surname> <given-names>JH</given-names></name>. <article-title>Retinal locus for scanning text</article-title>. <source>J Rehabil Res Dev</source>. <year>2006</year>;<volume>43</volume>: <fpage>749</fpage>–<lpage>60</lpage>. <object-id pub-id-type="pmid">17310424</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Timberlake</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Sharma</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Grose</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Gobert</surname> <given-names>DV</given-names></name>, <name name-style="western"><surname>Gauch</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Maino</surname> <given-names>JH</given-names></name>. <article-title>Retinal location of the preferred retinal locus relative to the fovea in scanning laser ophthalmoscope images</article-title>. <source>Optom Vis Sci</source>. <year>2005</year>;<volume>82</volume>: <fpage>177</fpage>–<lpage>85</lpage>. <object-id pub-id-type="pmid">15767869</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Timberlake</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Essock</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Augliere</surname> <given-names>RA</given-names></name>. <article-title>Reading with a macular scotoma. II. Retinal locus for scanning text</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>1987</year>;<volume>28</volume>: <fpage>1268</fpage>–<lpage>74</lpage>. <object-id pub-id-type="pmid">3610545</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref068"><label>68</label><mixed-citation publication-type="other" xlink:type="simple">Ashmore M, Duchowski AT, Shoemaker G. Efficient Eye Pointing with a Fisheye Lens. Proceedings of Graphics Interface 2005. School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada: Canadian Human-Computer Communications Society; 2005. pp. 203–210. <ext-link ext-link-type="uri" xlink:href="http://dl.acm.org/citation.cfm?id=1089508.1089542" xlink:type="simple">http://dl.acm.org/citation.cfm?id=1089508.1089542</ext-link></mixed-citation></ref>
<ref id="pone.0174910.ref069"><label>69</label><mixed-citation publication-type="other" xlink:type="simple">Bier EA, Stone MC, Pier K, Buxton W, DeRose TD. Toolglass and Magic Lenses: The See-through Interface. Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques. New York, NY, USA: ACM; 1993. pp. 73–80.</mixed-citation></ref>
<ref id="pone.0174910.ref070"><label>70</label><mixed-citation publication-type="other" xlink:type="simple">Büring T, Gerken J, Reiterer H. Usability of Overview-supported Zooming on Small Screens with Regard to Individual Differences in Spatial Ability. Proceedings of the Working Conference on Advanced Visual Interfaces. New York, NY, USA: ACM; 2006. pp. 233–240.</mixed-citation></ref>
<ref id="pone.0174910.ref071"><label>71</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Duchowski</surname> <given-names>AT</given-names></name>. <source>Eye tracking methodology: theory and practice</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="pone.0174910.ref072"><label>72</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Jacob</surname> <given-names>RJK</given-names></name>. <chapter-title>Eye Movement-Based Human-Computer Interaction Techniques: Toward Non-Command Interfaces</chapter-title>. <source>IN ADVANCES IN HUMAN-COMPUTER INTERACTION</source>. <publisher-name>Ablex Publishing Co</publisher-name>; <year>1993</year>. pp. <fpage>151</fpage>–<lpage>190</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacob</surname> <given-names>RJK</given-names></name>. <article-title>The use of eye movements in human-computer interaction techniques: what you look at is what you get</article-title>. <source>ACM Trans Inf Syst</source>. <year>1991</year>;<volume>9</volume>: <fpage>152</fpage>–<lpage>169</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref074"><label>74</label><mixed-citation publication-type="other" xlink:type="simple">Thiede C, Fuchs G, Schumann H. Smart Lenses. Proceedings of the 9th International Symposium on Smart Graphics. Berlin, Heidelberg: Springer-Verlag; 2008. pp. 178–189.</mixed-citation></ref>
<ref id="pone.0174910.ref075"><label>75</label><mixed-citation publication-type="other" xlink:type="simple">Duchowski AT, Eaddy TD. A Gaze-Contingent Display Compensating for Scotomata. P. Alliez and M. Magnor; 2009. pp. 9–12.</mixed-citation></ref>
<ref id="pone.0174910.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ho</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Loshin</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Juday</surname> <given-names>RD</given-names></name>. <article-title>Testing of remapping for reading enhancement for patients with central visual field losses</article-title>. <source>SPIE</source>. <year>1995</year>;<volume>2488</volume>: <fpage>417</fpage>–<lpage>424</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Juday</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Loshin</surname> <given-names>DS</given-names></name>. <article-title>Conformal and other image warping for reading with field defect</article-title>. <source>SPIE Vis Inf Process III</source>. <year>1994</year>;<volume>2239</volume>: <fpage>92</fpage>–<lpage>102</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Juday</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Loshin</surname> <given-names>DS</given-names></name>. <article-title>Human low-vision image warping: channel-matching considerations</article-title>. <source>Visual Information Processing</source>. <year>1992</year>. pp. <fpage>304</fpage>–<lpage>313</lpage>. <ext-link ext-link-type="uri" xlink:href="http://adsabs.harvard.edu/abs/1992SPIE.1705.304J" xlink:type="simple">http://adsabs.harvard.edu/abs/1992SPIE.1705.304J</ext-link></mixed-citation></ref>
<ref id="pone.0174910.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loshin</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Juday</surname> <given-names>RD</given-names></name>. <article-title>The programmable remapper: clinical applications for patients with field defects</article-title>. <source>Optom Vis Sci Off Publ Am Acad Optom</source>. <year>1989</year>;<volume>66</volume>: <fpage>389</fpage>–<lpage>395</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodrich</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Kirby</surname> <given-names>J</given-names></name>. <article-title>A comparison of patient reading performance and preference: optical devices, handheld CCTV (Innoventions Magni-Cam), or stand-mounted CCTV (Optelec Clearview or TSI Genie)</article-title>. <source>Optometry</source>. <year>2001</year>;<volume>72</volume>: <fpage>519</fpage>–<lpage>28</lpage>. <object-id pub-id-type="pmid">11519714</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kwon</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ramachandra</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Satgunam</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mel</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Tjan</surname> <given-names>BS</given-names></name>. <article-title>Contour enhancement benefits older adults with simulated central field loss</article-title>. <source>Optom Vis Sci Off Publ Am Acad Optom</source>. <year>2012</year>;<volume>89</volume>: <fpage>1374</fpage>–<lpage>1384</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levi</surname> <given-names>DM</given-names></name>. <article-title>Crowding—an essential bottleneck for object recognition: a mini-review</article-title>. <source>Vis Res</source>. <year>2008</year>;<volume>48</volume>: <fpage>635</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2007.12.009" xlink:type="simple">10.1016/j.visres.2007.12.009</ext-link></comment> <object-id pub-id-type="pmid">18226828</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref083"><label>83</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Husk</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>D</given-names></name>. <article-title>The effect of motion on crowding: Zooming text</article-title>. <source>J Vis</source>. <year>2015</year>;<volume>15</volume>: <fpage>17</fpage>–<lpage>17</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shardlow</surname> <given-names>M</given-names></name>. <article-title>A Survey of Automated Text Simplification</article-title>. <source>Int J Adv Comput Sci Appl</source>. <year>2014</year>;<volume>4</volume>.</mixed-citation></ref>
<ref id="pone.0174910.ref085"><label>85</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Siddharthan</surname> <given-names>A</given-names></name>. <article-title>A survey of research on text simplification</article-title>. <source>ITL—Int J Appl Linguist</source>. <year>2014</year>;<volume>165</volume>: <fpage>259</fpage>–<lpage>298</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref086"><label>86</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bernard</surname> <given-names>J-B</given-names></name>, <name name-style="western"><surname>Aguilar</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Castet</surname> <given-names>E</given-names></name>. <article-title>A New Font, Specifically Designed for Peripheral Vision, Improves Peripheral Letter and Word Recognition, but Not Eye-Mediated Reading Performance</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>: <fpage>e0152506</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0152506" xlink:type="simple">10.1371/journal.pone.0152506</ext-link></comment> <object-id pub-id-type="pmid">27074013</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref087"><label>87</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crossland</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Silva</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Macedo</surname> <given-names>AF</given-names></name>. <article-title>Smartphone, tablet computer and e-reader use by people with vision impairment</article-title>. <source>Ophthalmic Physiol Opt</source>. <year>2014</year>;<volume>34</volume>: <fpage>552</fpage>–<lpage>557</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/opo.12136" xlink:type="simple">10.1111/opo.12136</ext-link></comment> <object-id pub-id-type="pmid">25070703</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref088"><label>88</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Azuma</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Baillot</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Behringer</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Feiner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Julier</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>MacIntyre</surname> <given-names>B</given-names></name>. <article-title>Recent Advances in Augmented Reality</article-title>. <source>IEEE Comput Graph Appl</source>. <year>2001</year>;<volume>21</volume>: <fpage>34</fpage>–<lpage>47</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref089"><label>89</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Krevelen</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Poelman</surname> <given-names>R</given-names></name>. <article-title>A Survey of Augmented Reality Technologies, Applications and Limitations</article-title>. <source>Int J Virtual Real</source>. <year>2010</year>;<volume>9</volume>: <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref090"><label>90</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hwang</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>. <article-title>An Augmented-Reality Edge Enhancement Application for Google Glass</article-title>. <source>Optom Vis Sci</source>. <year>2014</year>;<volume>91</volume>: <fpage>1021</fpage>–<lpage>1030</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1097/OPX.0000000000000326" xlink:type="simple">10.1097/OPX.0000000000000326</ext-link></comment> <object-id pub-id-type="pmid">24978871</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref091"><label>91</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luo</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>. <article-title>Use of an augmented-vision device for visual search by patients with tunnel vision</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2006</year>;<volume>47</volume>: <fpage>4152</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.05-1672" xlink:type="simple">10.1167/iovs.05-1672</ext-link></comment> <object-id pub-id-type="pmid">16936136</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref092"><label>92</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>. <article-title>Vision multiplexing: an engineering approach to vision rehabilitation device development</article-title>. <source>Optom Vis Sci</source>. <year>2001</year>;<volume>78</volume>: <fpage>304</fpage>–<lpage>15</lpage>. <object-id pub-id-type="pmid">11384008</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref093"><label>93</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woods</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Fetchenheuer</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Vargas-Martin</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name>. <article-title>The impact of non-immersive head-mounted displays (HMD) on the visual field</article-title>. <source>J SID</source>. <year>2003</year>;<volume>11</volume>: <fpage>191</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
<ref id="pone.0174910.ref094"><label>94</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>. <article-title>The Glenn A. Fry Award Lecture 2012: Plasticity of the Visual System Following Central Vision Loss</article-title>. <source>Optom Vis Sci</source>. <year>2013</year>;<volume>90</volume>: <fpage>520</fpage>–<lpage>529</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1097/OPX.0b013e318294c2da" xlink:type="simple">10.1097/OPX.0b013e318294c2da</ext-link></comment> <object-id pub-id-type="pmid">23670125</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref095"><label>95</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>. <article-title>Improving Reading Speed for People with Central Vision Loss through Perceptual Learning</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2011</year>;<volume>52</volume>: <fpage>1164</fpage>–<lpage>1170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/iovs.10-6034" xlink:type="simple">10.1167/iovs.10-6034</ext-link></comment> <object-id pub-id-type="pmid">21087972</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref096"><label>96</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cheung</surname> <given-names>S-H</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>. <article-title>Reading speed in the peripheral visual field of older adults: Does it benefit from perceptual learning?</article-title> <source>Vision Res</source>. <year>2010</year>;<volume>50</volume>: <fpage>860</fpage>–<lpage>869</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2010.02.006" xlink:type="simple">10.1016/j.visres.2010.02.006</ext-link></comment> <object-id pub-id-type="pmid">20156473</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref097"><label>97</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Gage</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>ST</given-names></name>. <article-title>Development of a training protocol to improve reading performance in peripheral vision</article-title>. <source>Vis Res</source>. <year>2010</year>;<volume>50</volume>: <fpage>36</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2009.10.005" xlink:type="simple">10.1016/j.visres.2009.10.005</ext-link></comment> <object-id pub-id-type="pmid">19819251</object-id></mixed-citation></ref>
<ref id="pone.0174910.ref098"><label>98</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chung</surname> <given-names>STL</given-names></name>. <article-title>Cortical Reorganization after Long-Term Adaptation to Retinal Lesions in Humans</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>: <fpage>18080</fpage>–<lpage>18086</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2764-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2764-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24227718</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>